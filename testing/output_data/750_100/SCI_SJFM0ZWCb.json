{
    "title": "SJFM0ZWCb",
    "content": "Unsupervised learning of timeseries data is a challenging problem in machine learning. Unsupervised learning of timeseries data is a challenging problem in machine learning. We propose a novel algorithm, Deep Temporal Clustering (DTC), a fully unsupervised method that integrates dimensionality reduction and temporal clustering in an end-to-end learning framework. The algorithm utilizes an autoencoder for dimensionality reduction and a temporal clustering layer for cluster assignment, optimizing both objectives simultaneously. Different temporal similarity metrics can be used in the clustering layer, and various metrics are compared. The algorithm Deep Temporal Clustering (DTC) integrates dimensionality reduction and temporal clustering for unsupervised learning of timeseries data. It outperforms traditional methods in various domains, showcasing the effectiveness of fully integrated temporal dimensionality reduction and clustering criterion. Unsupervised learning techniques, such as clustering, are used to draw inferences from unlabeled data. Progress in learning complex structures has mainly focused on labeled datasets, with less attention given to high-level features of unlabeled data. Clustering methods organize similar objects into clusters using different metrics for similarity. While successful with static data, extending these techniques to time series data remains a challenge. Clustering techniques have been applied to static data successfully, but extending them to time series data is a challenge. Unsupervised learning of time series data is crucial for various fields like financial trading and medical monitoring. Time series data from different domains vary in properties, features, and dimensionality, making unsupervised time series clustering difficult. Real-world time series data often have temporal gaps and high-frequency noise. The novel algorithm deep temporal clustering (DTC) addresses issues with standard clustering techniques on time series data by transforming it into a low dimensional latent space using a deep autoencoder network. The DTC algorithm is designed to work with any temporal similarity metric. The proposed DTC algorithm utilizes a three-level approach to disentangle data manifolds in time series data. The first level uses a CNN to learn short-time-scale waveforms, the second level uses a BI-LSTM to learn temporal connections across all time scales, and the third level performs non-parametric clustering of BI-LSTM latent representations. The DTC algorithm utilizes a three-level approach to disentangle data manifolds in time series data. The third level performs non-parametric clustering of BI-LSTM latent representations, achieving high performance on various datasets without parameter adjustment. It includes a unique feature to visualize cluster-assignment activations across time, allowing event localization in unlabeled time series data. The study introduces a novel deep learning algorithm for temporal clustering in unlabeled time series data. It focuses on achieving meaningful clustering by formulating an end-to-end approach with an effective latent representation and a integrated similarity metric. This work is the first to apply deep learning in temporal clustering, providing explanations for class assignment based on informative data features. The study introduces a novel deep learning algorithm for temporal clustering in unlabeled time series data, demonstrating superior performance in end-to-end optimization for reconstruction and clustering loss. DTC outperforms existing methods on real-world datasets, focusing on dimensionality reduction and similarity metrics in temporal clustering research. One class of solutions use dimensionality reduction to filter out noise, such as adaptive piecewise constant approximation and nonnegative matrix factorization. However, these approaches may lose long range temporal correlations and relevant features. Another class of solutions focuses on creating a suitable similarity measure for temporal clustering. Some solutions focus on creating a suitable similarity measure for time series clustering by considering features like complexity, correlation, and time warping. The choice of similarity measure significantly impacts clustering results, but without proper dimensionality reduction, optimal clustering results may not be achieved due to the complexity and high dimensionality of time series data. Recent research has shown that transforming time series data into a low dimensional latent space is effective for temporal clustering. However, there is a lack of a general methodology for selecting an appropriate latent space. It is crucial to ensure that the similarity metric used is compatible with the temporal feature space for meaningful clustering results. Previous approaches have combined a stacked autoencoder for dimensionality reduction with a k-means objective for clustering, resulting in superior performance for static data clustering. The proposed DTC method aims to perform unsupervised clustering of temporal sequences using a convolutional autoencoder and a BI-LSTM. The input signal is encoded into a latent space, which is then fed to a temporal clustering layer for clustering into k clusters. The proposed DTC method utilizes a BI-LSTM and a temporal autoencoder (TAE) for unsupervised clustering of temporal sequences. The TAE extracts key short-term features and generates cluster assignments through a temporal clustering layer. Effective latent representation is crucial for the clustering process. The proposed DTC method uses BI-LSTM and a temporal autoencoder for unsupervised clustering of temporal sequences. BI-LSTM captures temporal changes in both directions, reducing input dimensions to a smaller latent space. The clustering layer assigns sequences to clusters based on the BI-LSTM latent representation. Learning in both 1D CNN and BI-LSTM involves minimizing two cost functions alternately. The proposed DTC method utilizes BI-LSTM and a temporal autoencoder for unsupervised clustering of temporal sequences. The learning process in both 1D CNN and BI-LSTM involves minimizing two cost functions alternately. The first cost function ensures the input sequence is well represented after dimensionality reduction, while the second cost function ensures that high-level features separate the sequences into distinct clusters. The clustering metric optimization in the proposed DTC method modifies weights in the BI-LSTM and CNN to separate sequences into distinct clusters based on spatio-temporal behavior. The end-to-end optimization efficiently extracts spatio-temporal features that disentangle high-dimensional manifolds of input dynamics. The proposed DTC method optimizes clustering metrics by modifying weights in BI-LSTM and CNN to separate sequences based on spatio-temporal behavior. End-to-end optimization efficiently extracts features to disentangle high-dimensional input dynamics. Traditional approaches focus on dimensionality reduction and clustering separately, leading to suboptimal separability in latent feature space. Direct comparison shows improved unsupervised categorization with end-to-end optimization. The approach emphasizes end-to-end optimization and utilizes temporal continuity to extract informative features from spatio-temporal data x. The temporal clustering layer involves k centroids w j, initialized using latent signals z i from the TAE. The approach involves using latent signals z i from the TAE to perform hierarchical clustering with complete linkage in feature space Z. Initial centroids estimates w j are obtained through k cut, and then the temporal clustering layer is trained using an unsupervised algorithm that alternates between computing the probability of assignment of input x i to a cluster and updating centroids w j. The approach involves hierarchical clustering using latent signals from the TAE. Centroids are updated based on high confidence assignments using a loss function. Distances from centroids are computed and normalized into probability assignments using a Student's t distribution kernel. In an unsupervised setting, the parameter \u03b1 can be set to 1 for the Students t distribution. The temporal similarity metric siml() is used to calculate distances between the encoded signal z i and centroids w j. A 2 cluster example is illustrated in FIG0, where distances d 1 and d 2 from centroids w 1 and w 2 are computed using a similarity metric and converted into probabilities p 1 and p 2 with a Students t distribution kernel. In this study, various similarity metrics are experimented with, including Complexity Invariant Similarity (CID) which computes similarity based on the euclidean distance corrected by complexity estimation of two series x, y. The core idea of CID is that as complexity differences between series increase, the distance also increases. The complexity of input sequences affects the distance calculation. Correlation based Similarity uses Pearson's correlation, while Auto Correlation based Similarity uses autocorrelation coefficients. The text discusses using autocorrelation coefficients to calculate the distance between latent representations and centroids in a temporal clustering layer. The objective is to minimize KL divergence loss by choosing a target distribution that strengthens high confidence predictions and normalizes losses. This approach is detailed in previous studies BID9 and BID19. Using the target distribution discussed in previous studies BID9 and BID19, the KL divergence loss is computed for joint optimization of clustering and autoencoder. Effective initialization of cluster centroids is crucial as they reflect the data's latent representation. Pretraining the autoencoder parameters ensures a meaningful starting point for the centroids. After pretraining the autoencoder parameters for a meaningful latent representation, cluster centers are initialized using hierarchical clustering. Autoencoder weights and cluster centers are updated using backpropagation mini-batch SGD. Target distribution is also updated during each SGD iteration. This approach prevents solutions from drifting too far from the original input signal, with reconstruction MSE reduction as part of the objective. Similar methods have been used in previous studies BID19 and BID20. The latent representation in the objective aims to minimize clustering and MSE loss. A heatmap-generating network is used to localize data features for classification, following a similar approach used in BID10 for tumor localization in medical images. The network utilizes cluster labels from a DTC network to train a hierarchical convolutional network for classification, generating heatmaps for spatio-temporal inputs. The network generates heatmaps to show relevant parts of spatio-temporal inputs for clustering. Heatmaps are implemented using Python, TensorFlow, and Keras on Nvidia GTX 1080Ti. Higher values in the heatmap indicate event localization, correctly marking time locations. Non-events have low heatmap amplitudes. The DTC algorithm performance is evaluated on various real-world datasets, including UCR Time series Classification Archive datasets and spacecraft magnetometer data from the NASA MMS Mission. The datasets' properties include the number of samples, time steps in each sequence, and class distribution ratio. The magnetospheric plasma environment shows many transient events. The DTC algorithm is evaluated on real-world datasets, including spacecraft magnetometer data from the NASA MMS Mission. FTEs in the magnetospheric plasma environment are detected using the B N component of the magnetic field. The algorithm's results are compared with hierarchical clustering and k-Shape, a state-of-the-art temporal clustering algorithm. The DTC algorithm is a partitional clustering approach that preserves time series shapes and computes centroids under scale and shift invariance. Four similarity metrics were considered: CID, COR, ACF, and EUCL. Expert labels were used for datasets, but the training pipeline was unsupervised. Evaluation metrics included ROC, AUC, and bootstrap sampling of ROC curves. The study used ROC curve and AUC as evaluation metrics, averaging over 5 trials with bootstrap sampling. Parameter optimization was not feasible in unsupervised clustering, so common parameters for DTC were used. The model had 50 filters in the convolution layer, 50 and 1 filters in two Bi-LSTM layers, and a pooling size chosen to keep latent representation size < 100. Weights were initialized with a zero-mean Gaussian distribution. The autoencoder network is pre-trained using the Adam optimizer over 10 epochs. Temporal clustering layer centroids are initialized using hierarchical clustering with complete linkage. The deep architecture is jointly trained for clustering and autoencoder loss until a convergence criterion of 0.1% change in cluster assignment is met. Mini-batch size is set to 64 for both pretraining and end-to-end fine-tuning, with a starting learning rate of 0.1, held constant across all datasets. The baseline algorithms used are parameter free. Results of DTC for three distinct time series from the MMS dataset are shown in FIG1. Activation map profiles correlate well with the location of the bipolar signatures of the events. The algorithm correctly identifies events and non-events based on heatmap activation. The paper highlights the superior performance of joint training of reconstruction loss and clustering loss in the DTC model compared to disjoint training. Direct comparison on the MMS dataset shows an average AUC of 0.93 for joint training vs. 0.88 for disjointed training. In TAB0, a comparison of results from DTC and baseline clustering techniques across various datasets and similarity metrics shows DTC outperforming the baselines. The ROC comparison in FIG2 further demonstrates DTC's robustness and superior performance across datasets of different sizes and domains. In this work, the unsupervised learning of patterns in temporal sequences, event detection, and clustering were addressed. Post-hoc labeling of clusters showed high agreement with human-labeled categories, indicating effective dimensionality reduction. The approach involves mapping natural stimuli to a few-dimensional space using cluster centroids, showing promise for real-world applications. Generalization to multichannel spatio-temporal input is also possible and will be detailed in a separate paper."
}