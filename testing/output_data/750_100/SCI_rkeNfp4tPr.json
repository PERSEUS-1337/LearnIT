{
    "title": "rkeNfp4tPr",
    "content": "Stochastic gradient descent with stochastic momentum is commonly used in nonconvex stochastic optimization, especially for training deep neural networks. The addition of a momentum term biases the parameter update in the direction of the previous change. Empirical evidence suggests that stochastic momentum is beneficial in training deep networks. In training deep networks, stochastic momentum improves convergence time by helping SGD escape saddle points faster and find a second order stationary point more quickly. The ideal momentum parameter should be large (close to 1). SGD with stochastic momentum is a key algorithm in nonconvex optimization and deep learning, widely used in various applications such as computer vision, speech recognition, natural language processing, and reinforcement learning. Empirical findings suggest that a large momentum parameter (close to 1) is ideal for faster convergence and finding stationary points quickly. SGD with stochastic momentum is crucial in optimization and deep learning, showing faster convergence compared to standard SGD. Momentum is widely used in popular adaptive stochastic gradient methods like Adam and AMSGrad. In this paper, a theoretical analysis is provided for SGD with momentum, focusing on setting the momentum parameter \u03b2. The use of momentum in optimization and deep learning has shown faster convergence compared to standard SGD. The theoretical analysis in this paper focuses on stochastic gradient descent (SGD) with momentum, specifically on setting the momentum parameter \u03b2. It is shown that SGD with stochastic momentum can escape saddle points faster than standard SGD, highlighting the benefits of using momentum in optimization and deep learning. The update for stochastic heavy ball momentum involves maintaining a weighted average of stochastic gradients and adjusting the current update in the direction of the momentum. In this paper, the focus is on finding a second-order stationary point for smooth non-convex optimization using stochastic heavy ball momentum in SGD. The goal is to obtain a (\u03b5, \u03b4)-second-order stationary point where the gradient and Hessian matrix conditions are satisfied. This is crucial in the nonconvex optimization community for achieving a global minimum. The paper aims to show the benefit of using momentum in reaching a (\u03b5, \u03b4)-second-order stationary point in nonconvex optimization, following related works targeting approximate second-order stationary points with Lipschitzness assumptions in gradients and Hessian. The dynamic procedure in Algorithm 2 ensures updates with suitable correlation with negative curvature directions of the function f, aiding in escaping saddle points faster. The stochastic momentum satisfies Correlated Negative Curvature (CNC) condition, amplifying the escape signal \u03b3. The stochastic momentum with escape signal \u03b3 helps in escaping saddle points faster by satisfying Correlated Negative Curvature (CNC) condition. A larger momentum parameter \u03b2 can aid in achieving second order stationary points in fewer iterations. The larger momentum parameter \u03b2 helps in escaping saddle points faster in optimization and deep learning. This sheds light on why SGD with momentum enables faster training. The paper uses E t [\u00b7] to represent conditional expectation. A thought experiment provides intuition on the benefit of stochastic momentum in avoiding saddle points. In optimization and deep learning, larger momentum parameter helps escape saddle points faster. Gradient updates may drift slowly away from saddle points, but moving along the direction of the smallest eigenvector guarantees a fast escape. In optimization and deep learning, larger momentum parameter helps escape saddle points faster by moving along the direction of the smallest eigenvector of the Hessian matrix. Daneshmand et al. (2018) studied non-momentum SGD and assumed that each stochastic gradient is strongly non-orthogonal to the direction of large negative curvature, driving updates out of the saddle point region. The present paper focuses on stochastic momentum, where the update direction must be strongly non-orthogonal to the direction of large negative curvature for efficient escape from saddle points. The update direction in stochastic momentum must be strongly non-orthogonal to the direction of large negative curvature for efficient escape from saddle points. Momentum amplifies this effect in successive iterations when the momentum parameter is close to 1, as updates begin to escape a saddle point region for similar reasons. This is illustrated by the correlation between the update direction and negative curvature direction in successive rounds. The text discusses the benefits of stochastic momentum in accelerating the escape process from saddle points. It shows that momentum can speed up the escape by a factor of 1 \u2212 \u03b2, but \u03b2 has constraints. Empirical evidence is provided to demonstrate the advantage of stochastic momentum in solving optimization tasks. The text discusses the benefits of stochastic momentum in accelerating the escape process from saddle points. Two stochastic optimization tasks are constructed, each with significant saddle points. Problem (3) involves a non-convex optimization challenge with a saddle point at the origin. Convergence in function value is plotted for this problem. The text discusses the benefits of stochastic momentum in accelerating the escape process from saddle points during non-convex optimization tasks. Initialization is always set at w0 = 0, with all algorithms using the same step size \u03b7 = 5 \u00d7 10 \u22125. Convergence in relative distance to the true model w * is plotted, capturing progress as the global sign of the objective is unrecoverable. SGD and SGD with momentum are initialized at the origin to escape saddle points before convergence. The text discusses the benefits of stochastic momentum in accelerating convergence in non-convex optimization tasks. Larger choices of \u03b2 significantly accelerate convergence in both objectives, with trajectories escaping saddle points more effectively with large momentum. The heavy ball method, proposed by Polyak in 1964, does not provide a convergence speedup over standard gradient descent in most cases. However, in some scenarios like convex quadratic objectives, an accelerated rate is possible. This is the first empirical finding showing the significant speedup of stochastic momentum in finding optimal solutions in phase retrieval. In the context of the heavy ball method, our work focuses on reaching a second order stationary point by exploiting negative curvature to escape saddle points faster. This approach belongs to the category of specialized algorithms, with pioneer works by Ge et al. (2015) and Jin et al. (2017). Jin et al. (2017) specifically demonstrate the explicit exploitation of negative curvature. Jin et al. (2017) demonstrate that adding isotropic noise helps Gradient Descent escape saddle points and find second order stationary points. Phase retrieval is nonconvex with strict saddle property, where every local minimizer is global up to phase and each saddle has negative curvature. Daneshmand et al. (2018) assume stochastic gradient has Correlated Negative Curvature to aid in escaping saddle points. Our work assumes Correlated Negative Curvature (CNC) for stochastic momentum instead of gradient, comparing results with related works in Appendix A. We assume L-Lipschitz gradient and \u03c1-Lipschitz Hessian, ensuring convergence. Stochastic gradient has bounded noise and momentum norm is bounded. Our analysis of stochastic momentum relies on three key properties, including Almost Positively Aligned with Gradient (APAG) and Almost Positively Correlated with Gradient (APCG). These properties are essential for demonstrating the effectiveness of stochastic momentum in natural settings and standard problems. The stochastic momentum satisfies Almost Positively Correlated with Gradient (APCG) with parameter \u03c4 if there exists a c > 0 such that the momentum term must not be significantly misaligned with the gradient \u2207f (w t ) in expectation. This condition ensures that the bias of the momentum term relative to the gradient of the deterministic function f is not too large. APAG demands that bias relative to \u2207f (w t ) not be too large when gradient is large for algorithm progress. APCG requires momentum term m t to be positively correlated with \u2207f (w t ) in Mahalanobis norm induced by M t. PSD matrix M t measures local curvature of function with respect to SGD trajectory. The study shows empirically that the property of APCG holds on natural problems for a constant c. The analysis of APCG is necessary in saddle regions with significant gradients. The values are reported when the gradient is large, and they are mostly nonnegative. The figures imply that the momentum term should be positively correlated with the gradient for algorithm progress. The analysis shows that SGD with momentum exhibits APAG and APCG properties in experiments, with an observation that expected values may be nonnegative for the phase retrieval problem. The analysis does not require APCG to hold in cases of large gradients or updates at second-order stationary points. GrACE measures alignment between stochastic momentum and gradient, with the first term indicating small or negative values when momentum is stochastic. The analysis shows that SGD with momentum exhibits APAG and APCG properties in experiments, with a focus on the curvature exploitation. A small sum of two terms allows bounding the function value of the next iterate, as shown in Figure 3. The analysis of SGD with momentum shows APAG and APCG properties in experiments, focusing on curvature exploitation. The proof is structured into three cases, leading to a second-order stationary region. Algorithm 2 is analyzed, with a larger step size implemented. The algorithm analyzed in the previous section shows properties of APAG and APCG in experiments, focusing on curvature exploitation. The proof is structured into three cases, leading to a second-order stationary region. The iteration complexity remains constant even with larger step size parameters. The proof in the current section introduces a novel momentum analysis for reaching a second-order stationary point with high probability. The theorem highlights the advantages of using stochastic momentum in SGD, with higher \u03b2 leading to better results. The theorem emphasizes the benefits of using stochastic momentum in SGD, with higher \u03b2 leading to faster convergence to a second-order stationary point by escaping saddle points more efficiently. Constraints on \u03b2 are necessary to prevent it from being too close to 1. In high momentum regime, Algorithm 2 outperforms CNC-SGD in finding second order stationary points faster. Empirical findings show conditions easily met for a wide range of \u03b2 values. In the high momentum regime, Algorithm 2 outperforms CNC-SGD in finding second order stationary points faster. Conditions are easily met for a wide range of \u03b2 values. The process of escaping saddle points by SGD with momentum is analyzed, showing that it takes at most T thred iterations to escape a region with a small gradient but a large negative eigenvalue of the Hessian. The function value decreases by at least F thred on expectation when escaping. The analysis shows that the function value must decrease by at least F thred in T thred iterations on expectation, with larger momentum helping in escaping saddle points faster. The analysis indicates that larger momentum aids in escaping saddle points faster. Lemma 1 provides an upper bound on the expected distance, while Lemma 2 focuses on obtaining a lower bound using the recursive dynamics of SGD with momentum. The proof of Lemma 2 in Appendix D uses quantities defined above. Lemma 3 shows the dominant term in the lower bound for ensuring it exceeds the upper bound of expected distance. Lambda min (H) is less than 0, with v as the corresponding eigenvector of Hessian H. The lower bound in (8) increases with t and \u03b2, growing exponentially in t. To prove the contradiction, we need to show it surpasses the upper bound. Lemma 5 states that if SGD with momentum has the APCG property, then F thred = O( 4 ) and \u03b7 2 T thred \u2264 r 2. In this paper, three properties are identified that guarantee SGD with momentum in reaching a second-order stationary point faster with a higher momentum parameter \u03b2. A greater momentum helps in escaping strict saddle points faster by enlarging the projection to an escape direction. However, ensuring that SGD with momentum has these properties is not clear, and further research is needed to identify conditions that guarantee these properties. The heavy ball method, proposed by Polyak in 1964, does not provide a convergence speedup over standard gradient descent in most cases. Recent research has focused on analyzing the heavy ball method for different classes of optimization problems. Recent research has focused on analyzing the heavy ball method for different classes of optimization problems, including stochastic heavy ball momentum and Nesterov's momentum for smooth non-convex objective functions. The expected gradient norm converges at a rate of O(1/ \u221a t), which is not better than standard SGD. Some works propose variants of stochastic accelerated algorithms with first-order stationary point guarantees, but they do not capture the stochastic heavy ball momentum used in practice. Kidambi et al. (2018) found that for a specific problem, SGD with heavy ball momentum does not achieve the best convergence rate compared to other algorithms. There are specialized algorithms designed to reach a second order stationary point faster by exploiting negative curvature explicitly. The work explores algorithms that exploit negative curvature to escape saddle points faster than standard SGD. Fang et al. (2019) propose average-SGD with a suffix averaging scheme for updates. Iteration complexity results are compared in Table 1. The text discusses the iteration complexity comparison between different algorithms, focusing on the effectiveness of stochastic heavy ball momentum without certain schemes and perturbations. The analysis framework is based on previous work, suggesting the advantage of stochastic momentum in optimization algorithms. In the context of optimization algorithms, stochastic momentum shows advantages in modifying assumptions and algorithms to improve dependency. Lemmas 6, 7, and 8 highlight the benefits of stochastic momentum in decreasing function value and making progress under certain properties. Lemma 7 states that if the step size \u03b7 satisfies a certain condition and SGD with momentum has the APAG property, then the update step w t+1 = w t \u2212 \u03b7m t has a specific property. Lemma 8 discusses the GrACE property of SGD with momentum and its effect on the update step w t+1 = w t \u2212 \u03b7m t. Lemma 1 introduces the step size \u03b7 and discusses the update formula w t+1 = w t - \u03b7m t. It also provides a proof by bounding the conditional expectation. Lemma 2 and Lemma 3 provide a quadratic approximation at time t0 and define various terms related to the approximation. Lemma 2 and Lemma 3 provide a quadratic approximation at time t0 and define various terms related to the approximation. The equations involve updating parameters based on previous values and gradients. Lemma 5 states that if SGD with momentum has the APCG property, then certain inequalities hold. The proof involves following conditions and notations from previous Lemmas and Theorems. Lemma 5 states that certain constraints on parameter \u03b2 must be satisfied for the SGD with momentum to have the APCG property. These constraints ensure that \u03b2 is not too close to 1. The dependence on L, \u03c3, and c in the constraints is artificial and used in the proofs as artifacts of the analysis. Lemma 5 outlines constraints on parameter \u03b2 for SGD with momentum to have the APCG property, ensuring \u03b2 is not near 1. The relevance of \u03c3 is minimal as variance can be increased. Proof involves lemmas from Table 3 and bounding E t0 [ q q,t\u22121 ]. Upper bounds are derived for \u2207f (w t0+k ) \u2212 \u2207f (w t0+s ) and E t0 [ \u2207f (w. The upper bounds for the terms in the optimization problem are derived by analyzing \u03a0 t\u22121 j=s+1 G j 2 and using constraints on parameters like \u03bb and \u03b7. The optimization problem's upper bounds are derived by analyzing \u03a0 t\u22121 j=s+1 G j 2 and using constraints on parameters like \u03bb and \u03b7. The bounds are further refined by considering various inequalities and conditions, leading to a proof of the results. Lemma 12 and Lemma 13 provide lower bounds for E t0 [2\u03b7 q v,t\u22121 , q \u03be,t\u22121 ] and E t0 [2\u03b7 q v,t\u22121 , q m,t\u22121 ] respectively, based on specific conditions and proofs involving coefficients, matrix definitions, and symmetry properties. The matrix product U is symmetric positive semidefinite as long as each G j is. Lower bounding 2\u03b7E t0 [ q v,t\u22121 , q w,t\u22121 ] is proven by the APCG property. This is shown through a series of substitutions and proofs, ultimately completing the proof by contradiction. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation, using upper and lower bounds and leveraging negative curvature. This contradiction is achieved by referencing Lemmas 1, 3, 12, and 13. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation, using upper and lower bounds and leveraging negative curvature. This contradiction is achieved by referencing Lemmas 1, 3, 12, and 13. By choosing T thred large enough, for some constant c > 0, we can guarantee that the inequality holds. Lemma 15 guarantees that a specific event occurs with high probability. The proof involves probabilities of certain events happening and properties of SGD with momentum. The proof of Lemma 15 ensures that uniformly sampling a w from {w kT thred } gives a second order stationary point with high probability. The proof of Lemma 15 guarantees that randomly selecting a w from {w kT thred } results in a second-order stationary point with high probability. This relies on satisfying conditions in (86) and bounding E[f (w (k+1)T thred ) \u2212 f (w kT thred )|\u03a5 k ]. The proof relies on Lemma 15, ensuring that selecting w from {w kT thred} leads to a second-order stationary point with high probability by satisfying specific conditions. Based on Lemma 15 and parameter choices in Table 3, setting T = 2T thred f (w 0 ) \u2212 min w f (w) /(\u03b4F thred ) = O((1 \u2212 \u03b2) log( Lcm\u03c3 2 \u03c1c c h (1\u2212\u03b2)\u03b4\u03b3 ) \u221210 ) will lead to a second-order stationary point. Algorithm 2 outperforms previous methods by not depending on the variance of stochastic gradient, making higher momentum beneficial for faster convergence."
}