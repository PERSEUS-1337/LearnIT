{
    "title": "rygZJ2RcF7",
    "content": "Neural networks struggle to generalize transformations beyond their training data, limiting their ability to extrapolate accurately. A new technique called neuron editing aims to address this issue by learning how neurons encode edits for improved out-of-sample generation. Neuron editing is a technique that uses an autoencoder to decompose dataset variations into neuron activations, allowing for complex transformations with simpler distribution shifts. It is showcased in image domain/style transfer and biological applications like removing batch artifacts and predicting drug synergy. Mathematically modeling the effect of drug treatments to predict synergy between drugs in biology experiments and clinical trials on a small subset of samples. We propose a neural network-based method for learning a general edit function corresponding to treatment in the biological setting. Neural networks offer power and flexibility to transform data distributions, but often overfit to specific datasets, not learning a general edit function. Popular neural network architectures like GANs focus on generating post-treatment data distributions from pre-treatment data. In contrast, we introduce neuron editing, framing the problem as learning an edit function between pre-and post-treatment data versions. This edit function can be applied to other datasets. We use an autoencoder neural network with non-linear activations to learn this edit in the latent space. Initially, we train the autoencoder on the entire dataset, including pre-treatment and post-treatment samples, to transform the data effectively. The autoencoder neural network decomposes data into abstract features to accurately reconstruct it. Neuron editing extracts differences between pre-and post-treatment data to generate synthetic post-treatment data, encoding complex edits in a meaningful space. In this work, edits are made in the ambient space on denoised and meaningful features, which are complex non-linear combinations of input features. The focus is on the autoencoder to model distribution-to-distribution transformations in high-dimensional space efficiently. Working in a lower-dimensional manifold facilitates learning in this context. Research has shown that working in a lower-dimensional manifold with autoencoders can simplify complex effects into distribution shifts, making computations more efficient. Editing the neural network internal layer allows for modeling context dependence, with some neurons showing significant changes between pre- and post-treatment versions. Neurons in the experimental subpopulation show significant changes between pre- and post-treatment versions, while background context neurons have less change. Editing in a low-dimensional internal layer allows for modeling context dependence and editing on a denoised version of the data. The internal layer in an autoencoder allows editing on a denoised version of the data, retaining significant dimensions while discarding noise dimensions. Neuron editing assumes semantic consistency across data, demonstrated in the joint manifold learned by the autoencoder. Neuron editing extrapolates better than generative models on two important criteria: predicted change on extrapolated data resembles predicted change on interpolated data, and editing process produces more complex variation by preserving existing data variation. Neuron editing outperforms generation-based approaches like GANs in predicting changes on extrapolated data and producing complex variations.GANs struggle with these criteria, while neuron editing excels by preserving existing data variation. The decoder learns to undo transformations during training and reconstruct the input unchanged. Neuron editing method is detailed, followed by the extrapolation problem in natural image domain transfer. Two biological applications where extrapolation is essential are discussed: correcting artificial variability introduced by measuring instruments (batch effects) and predicting the combined effects of multiple drug treatments (combinatorial drug effects). GANs learn a transformation that produces equivalent distributions between source (S) and target (T), with properties of being piecewise linear. However, GAN optimization does not behave comparably on both S and T. Instead of learning this transformation directly, a transformation is defined on a learned space. An encoder/decoder pair is trained for this purpose. The encoder/decoder pair E/D is trained to map data into an abstract neuron space with high-level features. Activations from internal layers of the network for inputs from S and T are extracted and transformed using NeuronEdit. NeuronEdit function operates on distributions of activations from network inputs, transforming them based on differences between source and target distributions. The NeuronEdit function transforms input activation distributions based on differences between source and target distributions. It has properties similar to a GAN generator but ensures that editing on the source distribution is the same as on the extrapolation distribution. To apply the transformation to X, activations from the internal layer computed by the encoder are extracted. The NeuronEdit function transforms input activation distributions based on differences between source and target distributions, similar to a GAN generator. Activations from the internal layer computed by the encoder are extracted to cascade transformations through the decoder without further training, turning an autoencoder into a generative model. Training a GAN in this setting could exclusively utilize the transformed neuron activations for inference. Neuron editing can model variation in X unsupervised, providing more information than GANs. GANs are difficult to train due to oscillating dynamics, uninterpretable losses, and mode collapse. Mode collapse in GANs refers to the generator producing the same output for different inputs, even without the discriminator detecting differences. This results in unrealistic outputs and struggles in capturing the natural variability of real data. Neuron editing offers a solution to the limitations of GANs by using an unsupervised model with an autoencoder to isolate variations in neuron activations. This approach is similar to word2vec embeddings in natural language processing. Neuron editing is a method that uses an unsupervised model with an autoencoder to isolate variations in neuron activations, similar to word2vec embeddings in natural language processing. It involves transforming an entire distribution into another distribution, comparing it to generating methods like regularized autoencoder, standard GAN, ResnetGAN, and CycleGAN. The regularized autoencoder penalized differences in distributions of source and target using maximal mean discrepancy. Image experiment used convolutional layers with specific filters. All models had fully connected layers with leaky ReLU activation. Training was done with minibatches, adam optimizer, and a learning rate. Motivational experiment was conducted on CelebA dataset. When training a generative model on the CelebA dataset, mapping between images with different hair colors can be challenging. Simply collecting images of people with black and blond hair may limit the model's ability to generalize beyond the dataset, as shown in FIG1. When training a generative model on the CelebA dataset, mapping between images with different hair colors can be challenging. The GAN models struggle to successfully model transformations on out-of-sample data, especially when changing hair color. This results in artifacts and difficulties in training these models, highlighting the importance of avoiding such complications. In FIG1, the NeuronEdit transformation is shown to be beneficial for editing neural networks, particularly in the neuron space for complex transformations like changing hair color. Neuron editing can also be applied to batch correction to address differences in data distributions. Batch effects are differences in observed data caused by technical artifacts, making it challenging to combine measurements or draw accurate conclusions in biological experimental data. Various models, including deep learning methods, aim to address batch effects to improve data quality. One method for addressing batch effects in biological experimental data is to repeatedly measure a control set of cells with each sample and correct based on the variation in the control. By choosing a source/target pair of Control1/Control2 and extrapolating to Sample1, the transformed Sample1 can be compared to raw Sample2 cells, removing variation induced by the measurement process. This approach can be seen as a natural application of neuron editing due to the complexity of data distributions and dissimilarity between the control population and samples. The dataset analyzed in this section is from a mass cytometry experiment measuring protein levels in cells from two individuals infected with dengue virus. The data includes 35 dimensions with varying numbers of observations in different samples. Batch effects were observed, including artificially low readings in a specific protein in Control1. The dataset from a mass cytometry experiment showed batch effects with artificially low readings in a specific protein in Control1. The GANs failed to capture true biological variation, mapping most cells to the same values of CCR6 and InfG. The GANs failed to capture true biological variation in a mass cytometry experiment dataset, mapping most cells to the same values of CCR6 and InfG. The CycleGAN further skewed the CCR6 values towards zero, leading to a loss of important information. The ResnetGAN also did not address this issue, as it only encourages output similar to the target distribution, which is not desired in this case. The regularized autoencoder undoes transformations to its latent space, producing unchanged data. Neuron editing removes batch effects, preserving real variation and separating populations in CCR6. Unlike other generative models, neuron editing achieves intended transformations. Neuron editing successfully produces accurate transformations for proteins InfG and CCR6, confirmed globally across all dimensions. The PCA embedding in FIG2 shows that the variation between controls mirrors the variation introduced by neuron editing in the sample, preserving intra-sample variation. The global assessments confirm that neuron editing accurately reflects transformations in proteins InfG and CCR6. A combinatorial drug experiment on cells from leukemia patients is analyzed, showing the need to correct a batch effect in IFNg. In a combinatorial drug experiment on leukemia cells, neuron editing corrects a batch effect in IFNg while preserving biological variation in CCR6. The experiment involves four treatments and mass cytometry on 41 dimensions, with varying numbers of observations in each dataset. Neuron editing accurately models the effects of applying Das to cells treated with Bez, showing a decrease in p4EBP1 without affecting pSTATS. The regularized autoencoder does not exhibit the same accuracy in this extrapolation dataset. The regularized autoencoder and three GAN models do not accurately predict the real combination in the extrapolation dataset. ResnetGAN, despite residual connections, still suffers from the same problems as the other models. Neuron editing outperforms GAN models in predicting transformations across all dimensions, as shown in the comparison of real and predicted means and variances. Neuron editing outperforms GAN models in predicting transformations across all dimensions, with better preservation of variation in real data. The paper addresses a data-transformation problem inspired by biological experimental settings, where transformed versions of data are generated based on observed pre-and post-transformation data subsets. This problem arises in clinical trials or experimental conditions where effects are only measured in a subset but expected to generalize. The novel approach introduced is called neuron editing. Neuron editing utilizes autoencoder latent layers to apply treatment effects to the entire dataset, mimicking transformations by editing internal layer encodings. It results in realistic transformations of image data and predicts synergistic effects of drug treatments in biological data. The approach outperforms GAN models in preserving variation in real data and is capable of learning complex data. The approach of neuron editing using autoencoder latent layers can mimic transformations by editing internal layer encodings, resulting in realistic transformations of image data and predicting synergistic effects of drug treatments in biological data. Learning edits in a hidden layer allows for interactions between the edit and other context information from the dataset during decoding. Future work could involve training parallel encoders with the same decoder or training to generate conditionally."
}