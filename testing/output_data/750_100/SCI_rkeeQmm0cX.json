{
    "title": "rkeeQmm0cX",
    "content": "Deep neural networks (DNNs) have emerged as a powerful solution this year for addressing longstanding issues in Artificial Intelligence. In this paper, DNNs are applied to three cyber security use cases: Android malware classification, incident detection, and fraud detection using real data sets from Cybersecurity Data Mining Competition (CDMC) 2017. Efficient network architectures for DNNs are chosen through experiments on network parameters and structures, running up to 1000 epochs with learning rates between 0.01-0.5. DNNs outperformed classical machine learning algorithms in cyber security experiments, extracting better features for improved accuracy. DNNs achieved highest accuracy in Android malware classification (0.940), incident detection (1.00), and fraud detection (0.972). Accuracy varied slightly from the top system in CDMC 2017 tasks. In the era of technical modernization, the top system in CDMC 2017 tasks highlighted the importance of cyber security in protecting systems, networks, and data from threats like hacking and malware. Malware remains a significant security threat on the Internet, indicating the need for efficient detection and prevention measures. Malware poses significant security threats on the Internet by causing harm to systems. Antivirus and blacklists are commonly used for protection, but they are not effective against new malware types. Machine learning algorithms have become crucial for real-time malware detection systems. This paper evaluates the effectiveness of deep neural networks (DNNs) for cyber security use cases such as Android malware classification, incident detection, and fraud detection. It discusses the related work, background knowledge of DNNs, and the proposed methodology. Section IV presents the proposed methodology for cyber security use cases, including Android malware classification, incident detection, and fraud detection. The methodology includes data set description. Results are displayed in Section V, and the related work for cyber security use cases is discussed in this section. Static and dynamic analysis are commonly used approaches in Android malware detection, with static analysis involving collecting android permissions by unpacking or disassembling the app, and dynamic analysis focusing on run-time execution characteristics. Commercial systems often use a combination of both static and dynamic analysis. In Android malware detection, static analysis is preferred for its advantages such as low computational cost and resource utilization. Dynamic analysis can detect metamorphic and polymorphic malwares. Traditional machine learning classifiers were evaluated using permission, API calls, and a combination of both as features on 2510 APK files, showing good performance. MalDozer, a system proposed by BID4, utilizes deep learning to detect and classify Android malware based on sequences of API calls. It has shown strong performance on both private and public datasets like Malgenome and Drebin. BID5 briefly discussed privacy and security issues in cloud computing, categorizing 28 issues into five major categories. BID6 proposed machine learning-based anomaly detection that operates on various layers such as network, service, or workflow. Anomaly detection on different layers like network, service, or workflow discussed. Hybrid system combining rule-based and machine learning systems shown. Security issues in cloud and incident detection system proposed. Comparative study of machine learning classifiers for financial fraud detection. Applicability of data mining for financial fraud detection discussed. Deep learning is a sub model of machine learning. The paper discusses deep learning as a sub model of machine learning used for various cyber security use cases. It proposes a unique DNN architecture for efficient use in cyber security. The section explains the concepts of deep neural networks (DNNs) architecture and techniques for training them. Artificial neural networks (ANNs) are described as a directed graph of artificial neurons connected by edges. A feed forward network (FFN) is a type of artificial neural network (ANN) consisting of units connected in a single direction without cycles. Multi-layer perceptron (MLP) is a subset of FFN with 3 or more layers - input, hidden, and output layers. Additional hidden layers can be added for complex data. The number of hidden layers in a multi-layer perceptron (MLP) can be increased for complex data. The hidden layers form an acyclic graph that passes information forward. The computation of each hidden layer is mathematically formulated. When the network consists of multiple hidden layers, the combined representation can be defined as Rectified Linear Units (ReLU), which accelerates the training process efficiently. Using ReLU is more time-effective for training large datasets compared to traditional activation functions like logistic sigmoid and hyperbolic tangent functions. Neurons with this nonlinearity are referred to as ReLU. TensorFlow is considered in conjunction with these advancements. Task 1 involves Android Malware Classification using a dataset of unique API information from APK files collected from the Opera Mobile Store in 2014. The deep learning architectures are trained using back propagation through time (BPTT) technique. When a user runs an application on Android, a set of APIs related to different permissions is called. The success of API execution depends on user-granted permissions, categorized as Normal, Dangerous, Signature, and Signature Or System. These permissions are explicitly mentioned in the AndroidManifest.xml file of APKs. Task 2 involves Incident Detection using operational log files from Unified Threat Management of UniteCloud BID25, a provider of e-learning and e-research services in New Zealand. Unified Threat Management system for UniteCloud server in New Zealand collects log file samples with nine operational features from sensors. The dataset for Fraud Detection task is anonymized and unified using HCRUD approach. Detailed statistics for Task 1, Task 2, and Task 3 datasets are available in TAB0. The highest 10-fold cross validation accuracy for Task 1, Task 2, and Task 3 datasets was achieved with a learning rate of 0.1, after experimenting with rates ranging from 0.01 to 0.5. Accuracy dropped at 0.2 but peaked at 0.35, 0.45, and 0.45. Running experiments for 1000 epochs could further enhance accuracy. Despite testing more complex architectures, 0.1 was chosen as the optimal learning rate for subsequent experiments. After selecting a learning rate of 0.1 for optimal results, various network topologies were tested, including DNNs with 1 to 5 layers. Each topology underwent 2 trials lasting 500 epochs. Most architectures learned normal data patterns within 600 epochs, while malicious data required more iterations, especially for complex networks. The best performing network topology for each use case was determined after multiple iterations. A 5 layer DNNs network showed good performance for Task 1 compared to a 4 layer DNNs network. This 5 layer DNNs network was chosen for further experiments. The architecture includes an input layer, 5 hidden layers, and an output layer with varying neuron counts for different tasks. The proposed deep neural network architecture includes an input layer with 4896 neurons for Task 1, 9 neurons for Task 2, and 12 neurons for Task 3. The output layer has 2 neurons for Task 1, 3 neurons for Task 2, and 2 neurons for Task 3. The network consists of fully-connected layers, batch normalization layers, and dropout layers, trained using backpropagation. The units in the input to hidden layer and hidden to output layer are fully connected. The fully-connected layer in the deep neural network architecture maps data into high dimensions for accurate output. ReLU is used as the activation function, with Batch Normalization and Dropout (0.01) to prevent overfitting and speed up model training. The final fully connected layer in the deep neural network architecture follows sigmoid activation function for Task 1 and Task 2, softmax for Task 3, absorbing non-linear kernel and providing output of 0 (benign) and 1 (malicious). Prediction loss is estimated using binary cross entropy for Task 1 and Task 2, and categorical cross entropy for Task 3. The prediction loss for Task 3 is estimated using categorical-cross entropy where ed is true probability distribution, pd is predicted probability distribution. The DNNs model is evaluated against classical machine learning classifiers on three cyber security use cases: identifying Android malware, incident detection on UniteCloud, and fraud detection in financial transactions. Training involves passing matrices of specific shapes for each task. XGBoost, short for Extreme Gradient Boosting, is used for supervised learning problems (Task1, Task2, and Task3) with training data to predict target variables. \"multi:softmax\" is used for classification. The input layer of DNNs receives matrices of specific shapes for each task, passing through hidden layers before outputting results. The XGBoost algorithm is used for supervised learning tasks to predict target variables. \"multi:softmax\" is used for classification, with a max depth of 20 for the tree. 10 fold cross validation is performed to observe training accuracy. Data is loaded using Pandas 1, with NaN values replaced by 0. In Task 1, data is represented as a term-document matrix using scikit-learn BID11 count vectorizer. The winner of CDMC 2017 achieved high accuracy on Task 1, Task 2, and Task 3. The proposed method using Random Forest achieved high accuracy on Task 1, Task 2, and Task 3 in 2017. It outperformed the winner of CDMC 2017 on Task 2 and showed comparable results with DNNs. The method can automatically select the best features and was evaluated for cyber security applications like Android malware classification and fraud detection. The performance of Deep Neural Networks (DNNs) is good compared to classical machine learning classifiers in Android malware classification, incident detection, and fraud detection. DNNs can be further improved by adding more layers to the existing architectures, which is a direction for future work."
}