{
    "title": "B1spAqUp-",
    "content": "Deconvolutional layers are commonly used in deep models for up-sampling, but they often face the checkerboard problem due to the lack of direct relationships among adjacent pixels. To address this issue, the PixelDCL method is proposed to establish direct relationships among adjacent pixels on the up-sampled feature map. The PixelDCL method proposes a solution to the checkerboard problem in deconvolutional layers by establishing direct relationships among adjacent pixels on up-sampled feature maps. It can replace deconvolutional layers without compromising model trainability and improves accuracy in tasks like semantic segmentation and image generation. Deep learning methods, including deconvolutional layers, are crucial in tasks like image classification, semantic segmentation, and image generation. Deconvolutional layers are used for up-sampling feature maps in deep models, addressing the checkerboard problem. In this work, a new method called PixelDCL is proposed to address the checkerboard artifacts issue in deconvolution operations, improving the generation of photo-realistic images and smooth outputs in semantic segmentation. Our method, PixelDCL, addresses the checkerboard artifacts in deconvolution operations by introducing pixel deconvolutional operations to sequentially generate intermediate feature maps, overcoming the issue of non-directly related adjacent pixels in the output feature map. PixelDCL introduces pixel deconvolutional operations to generate intermediate feature maps sequentially, establishing direct relationships among adjacent pixels on the output feature map. This approach overcomes checkerboard artifacts in deconvolution operations. The proposed PixelDCL introduces pixel deconvolutional operations to address checkerboard artifacts in deconvolution. Experimental results show improved performance in semantic segmentation and image generation tasks compared to existing models like PixelRNNs and PixelCNNs. PixelDCL introduces pixel deconvolutional layers to address checkerboard artifacts in deconvolution, improving efficiency compared to PixelRNNs and PixelCNNs. The training time is comparable to other generative models like GANs and VAEs, but the prediction time is slower due to generating images pixel by pixel. The implementation trick helps overcome efficiency issues. Deconvolutional layers are widely used in deep models for tasks like semantic segmentation and generative models. They involve periodical shuffling of intermediate feature maps obtained through convolutional operations. This operation is illustrated in Figures 2 and 3 for 1D and 2D deconvolution. Deconvolutional layers involve periodical shuffling of feature maps obtained through convolutional operations. Standard deconvolution can be decomposed into multiple convolutions based on the up-sampling factor. The up-sampled output is generated using a deconvolutional layer, with intermediate feature maps produced by convolutional kernels. The intermediate feature map i is generated by convolutional kernels, with no direct relationship among them. Due to shuffling, adjacent pixels on the output feature map can have significantly different values, leading to checkerboard artifacts. In this work, a pixel deconvolutional operation is proposed to address checkerboard artifacts in semantic segmentation. This operation adds direct dependencies among intermediate feature maps, making adjacent pixels' values closer to each other and effectively solving the problem. The pixel deconvolutional layers proposed in this work address the checkerboard artifact problem by adding direct dependencies among adjacent pixels' values, effectively solving the issue. The iPixelDCL layer adds direct dependencies among adjacent pixels in the input feature map and previously generated ones to address the checkerboard artifact problem. This allows for conditioning pixels on both input feature maps and adjacent pixels, improving the flexibility of relationships among intermediate feature maps. The iPixelDCL layer introduces dependencies among adjacent pixels in feature maps to address checkerboard artifacts, improving relationships among intermediate feature maps. The simplified pixel deconvolutional layer removes dependencies on the input feature map for most intermediate feature maps, improving computational efficiency and reducing trainable parameters. The purple feature map is generated from the input feature map, while the orange feature map depends on both the input feature map and the purple feature map. PixelDCL removes dependencies on the input feature map for most intermediate feature maps, improving efficiency and reducing trainable parameters. The green feature map relies on the input feature map, purple, and orange intermediate feature maps, while the red feature map is generated based on multiple intermediate feature maps. By allowing only the first intermediate feature map to depend on the input feature map, PixelDCL avoids repeated influence of the input, ensuring that only the first feature map is directly generated from the input. PixelDCL simplifies feature map dependencies, improving efficiency by reducing reliance on input. The orange feature map depends only on the purple map, while the green map relies on purple and orange. The red map is conditioned on purple, orange, and green. Checkerboard issue is solved with better computational efficiency. The experimental results show that models with simplified dependencies outperform those with complete connections, indicating that repeated dependencies on the input may not be necessary. Pixel deconvolutional layers can replace deconvolutional layers in various models like U-Net, VAEs, and GANs, transforming them into pixel deconvolutional networks (PixelDCN). In U-Net, these layers can upsample low-resolution feature maps, while in VAEs, they can be used in decoders. In experiments, pixel deconvolutional layers in U-Net and VAEs outperform traditional deconvolutional layers. Up-sampling operations increase feature map size, with pixels divided into groups. The pixel deconvolutional layer in U-Net and VAEs outperforms traditional deconvolutional layers by up-sampling a 4\u00d74 feature map to an 8\u00d78 feature map. The purple feature map is generated through a 3\u00d73 convolutional operation, followed by another convolutional operation to produce the orange feature map. The purple and orange feature maps are dilated and added together to form a larger feature map. The proposed pixel deconvolutional method improves performance in semantic segmentation and image generation tasks by reducing sequential dependencies and enhancing parallel computation efficiency. The method involves applying a masked 3\u00d73 convolutional operation to combine two large feature maps for the final output. The proposed pixel deconvolutional method enhances performance in semantic segmentation tasks by predicting labels for each pixel without post-processing. Evaluation is done on PASCAL 2012 and MSCOCO 2015 datasets, with images resized to 256\u00d7256\u00d73 for training. Two approaches are considered: training from scratch using U-Net architecture and fine-tuning from DeepLab-ResNet model. The U-Net architecture BID23 is used as the base model for image segmentation tasks, with four blocks in the encoder and decoder paths. The final output layer is adjusted based on the number of classes in the dataset, with the PASCAL 2012 dataset having 21 classes and the MSCOCO 2015 dataset having 81 classes. To accommodate the higher number of classes in the MSCOCO dataset, the number of feature maps in each layer is doubled. The U-Net model's decoder path uses deconvolutional layers to up-sample feature maps. These layers are replaced with proposed pixel deconvolutional layers (iPixelDCL and PixelDCL) while maintaining other variables. The kernel size in DCL is 6\u00d76, which has the same number of parameters as iPixelDCL with 4 sets of 3\u00d73 kernels, and more parameters than PixelDCL with 2 sets of 3\u00d73 and 1 set of 2\u00d72 kernels. This allows for evaluation of the new pixel deconvolutional layers against regular deconvolutional layers while controlling all other factors. Fine-tuning experiments are conducted based on the architecture of DeepLabResNet BID0, using external data for training and finetuning from classic ResNet101 to boost model performance. The output of DeepLab-ResNet is significantly smaller than the input image, requiring up-sampling blocks to recover the original dimensions. By replacing deconvolutional layers with PixelDCL and iPixelDCL, the model's performance is enhanced. The use of iPixelDCL and PixelDCL in U-Net models improves the capture of local image information compared to regular deconvolutional layers. These pixel deconvolutional layers consider spatial features like edges and shapes, leading to smoother semantic segmentation results. The models also produce better outputs with fewer training epochs. The U-Net models using iPixelDCL and PixelDCL show improved segmentation outputs compared to regular deconvolution. PixelDCL is more efficient with fewer parameters, outperforming iPixelDCL in most cases. Evaluation results in terms of pixel accuracy and mean IOU on two datasets are shown in TAB3. The model using PixelDCL outperforms the model using iPixelDCL in semantic segmentation. Mean IOU is a more accurate evaluation measure than pixel accuracy. The dataset used for image generation is CelebA, preprocessed to retain only facial information. The images have been preprocessed to retain only facial information for image generation. The size of images is 64 \u00d7 64 \u00d7 3. A standard VAE is used as the base model, with PixelDCL replacing deconvolutional layers in the decoder. The generated faces using VAEs with regular deconvolution and PixelDCL in decoders are compared. The proposed PixelDCL in VAEs eliminates checkerboard artifacts in generated images, establishing direct relationships among adjacent pixels for photo-realistic results. This approach considers local spatial information, producing high-quality face images without the checkerboard issue. The study compares face images generated by VAEs using different up-sampling techniques. PixelDCL is more efficient than iPixelDCL and DCL due to reduced dependencies and improved implementation. In this work, pixel deconvolutional layers are proposed to solve the checkerboard problem in deconvolutional layers by adding direct dependencies among intermediate feature maps. The increase in training and prediction time is not significant, making it not a major bottleneck for the proposed methods. PixelDCL establishes dependencies among intermediate feature maps to ensure adjacent pixels on output feature maps are directly related. It effectively overcomes checkerboard artifacts and improves segmentation results by considering local spatial features like edges and shapes. Future plans include integrating PixelDCL into a broader range of models, such as generative adversarial networks (GANs)."
}