{
    "title": "SylCrnCcFX",
    "content": "Deep networks aim to understand complex mappings through locally linear behavior. The challenge lies in the instability of derivatives, especially in networks with piecewise linear activation functions. This paper introduces a new learning problem to promote stable derivatives over larger regions, focusing on provably stable linear approximations around points. The paper introduces a new learning problem to promote stable derivatives over larger regions by identifying stable linear approximations around points. This method is illustrated with residual and recurrent networks on image and sequence datasets. The paper discusses the challenges of unstable derivatives in deep learning models, which are often over-parametrized, leading to instability in both function values and derivatives. The derivatives discussed are with respect to input coordinates, not parameters. The paper discusses the challenges of unstable derivatives in deep learning models, which are often over-parametrized, leading to instability in both function values and derivatives. Gradient stability is different from adversarial examples, with stable gradients remaining approximately invariant within a local region. Adversarial examples are small perturbations that change predicted outputs. Robust estimation techniques focus on protecting against adversarial examples. The paper focuses on deep networks with piecewise linear activations to ensure gradient stability by inferring lower bounds on the maximum radius of p-norm balls around a point where derivatives are stable. The paper investigates the stability of derivatives in deep networks with piecewise linear activations by analyzing the maximum radius of p-norm balls around a point. The special case of p = 2 is explored, leading to a regularization problem. A perturbation algorithm is proposed for evaluating gradients in piecewise linear networks. The paper proposes a novel perturbation algorithm for collecting exact gradients in D-dimensional data without back-propagation. It includes inference algorithms for identifying input regions of neural networks with piecewise linear activation functions. Empirical evaluation is done on fully-connected, residual, and recurrent networks using image and time-series datasets. The paper introduces algorithms for identifying stable regions in neural networks with piecewise linear activation functions, along with a novel learning criterion and perturbation algorithms for high-dimensional data. The focus is on networks with ReLU activation functions and their variants, emphasizing the importance of activation functions in defining neural network behavior. The proposed approach is based on a mixed integer linear representation of piecewise linear networks, encoding the active linear piece of the activation function for each neuron. This representation allows the network to degenerate into a linear model when the activation pattern is fixed. The feasible set corresponding to an activation pattern in the input space is a natural region where derivatives are provably stable. Neighboring regions may have the same end-to-end linear coefficients, leading to a linear region. Activation patterns have been studied in various contexts, such as visualizing neurons and reachability of specific output values. In contrast to quantifying the number of linear regions as a measure of complexity, this work focuses on local linear regions and aims to expand them through learning. The notion of stability is considered in relation to visualizing neurons, reachability of specific output values, vector quantization, counting linear regions of piecewise linear networks, and adversarial attacks or defense. The methods for expanding local linear regions differ from adversarial examples. Finding exact adversarial examples is NP-complete and not scalable. Layer-wise relaxations of ReLU activations are more scalable but yield bounds instead of exact solutions. Defense methods are still intractable on ImageNet scale images. In contrast, the inference algorithm certifies the exact 2 margin around a point subject to its activation pattern. The proposed learning algorithm certifies the exact 2 margin around a point by forwarding O(D) samples in parallel, using unbiased estimation through sub-sampling. It scales to ResNet on 299 \u00d7 299 \u00d7 3 dimensional images and maximizes the 2 margin of linear regions around each data point. Our approach maximizes the 2 margin of linear regions around each data point in an unsupervised manner, similar to transductive/semi-supervised SVM. We develop a smooth relaxation of the margin and perturbation algorithms for gradient stability, addressing interpretability and transparency issues. The problem addressed involves gradient stability and its implications for interpretability of complex models. Various explanation methods for deep models rely on gradients, such as gradient saliency maps and their variants, which attribute predictions to inputs with nonlinear post-processings. The focus is on establishing robust derivatives, with a specific interest in the instability of gradient-based explanations. The approaches are developed under the notation of FC. The approaches for establishing robust derivatives in deep models are developed under the notation of FC networks with ReLU activations. The neural network \u03b8 with M hidden layers and N i neurons in the i th layer is considered, along with the corresponding function f \u03b8 : R D \u2192 R L it represents. The vectors z i and a i are used to denote the raw neurons and activated neurons in the i th layer, respectively. The output of the network is a linear transformation of the last hidden layer, which can be further processed by a nonlinearity like softmax for classification. The focus is on the piecewise linear property of neural networks represented by f \u03b8 (x), using a generic loss function L(f \u03b8 (x), y) to handle such nonlinearity. The activation pattern BID20 used in this paper is defined as a set of indicators for neurons that specify functional constraints. Points on the boundary of a linear region can be feasible for multiple activation patterns. The activation pattern discussed in this paper is defined by a set of indicators for neurons that specify functional constraints. Points on the boundary of a linear region can be feasible for multiple activation patterns, with each linear region characterized by a set of linear constraints forming a convex polyhedron. The activation pattern is equipped with input space constraints, leading to the definition of the p margin of x subject to its activation pattern. The feasibility of a directional perturbation in a convex activation pattern can be determined by checking if a point x + \u00af\u2206x is within the set S(x). If x + \u00af\u2206x \u2208 S(x), then f \u03b8 is linear in the range {x + \u2206x : 0 \u2264 \u2264 \u00af}. The feasibility of a directional perturbation in a convex activation pattern can be determined by checking if x + \u00af\u2206x satisfies the activation pattern in set S(x). Proposition 5 states that this can be applied to 1-ball feasibility, with a generalization for \u221e-balls. However, in high dimensions, the exponential number of extreme points in an \u221e-ball makes it intractable, while the linear number of extreme points in a 1-ball allows for easier verification of feasibility. To verify feasibility, binary searches can be used to find certificates for directional perturbations in convex activation patterns. The feasibility of 1-balls is tractable due to the convexity of the activation pattern, and certification is efficient through a binary search. The minimum 2 distance between a point x and the union of hyperplanes can be computed analytically. The number of linear regions in a neural network can be efficiently computed using forward passes. Certifying the number of complete linear regions among data points is proposed to capture the structure of the data manifold. This certification method is more effective than counting linear regions on the whole space. The number of complete linear regions of f \u03b8 among the data points D x is efficiently computed under mild conditions. The focus is on maximizing the 2 margin\u02c6 x,2 through a regularization problem in the objective. The regularization problem aims to maximize the margin by introducing a hinge-based relaxation to the distance function, similar to SVM. This approach helps to address the rigidity of the objective function and optimize the loss surface for better convergence. The regularization problem introduces a relaxation to the distance function to maximize the margin, similar to SVM. This approach optimizes the loss surface for better convergence by addressing the rigidity of the objective function. The regularization problem introduces a relaxation to the distance function to maximize the margin, similar to SVM. This approach optimizes the loss surface for better convergence by addressing the rigidity of the objective function. To visualize the effect of the proposed methods, a toy 2D binary classification dataset is used, and a 4-layer fully connected network is trained with different loss functions. The resulting piecewise linear regions and prediction heatmaps are shown in FIG3. The distance regularization enlarges the linear regions around each training point, while the relaxed regularization generalizes the property to the whole space. The relaxed regularization in the context of distance regularization introduces a smoother prediction boundary with a special central region where gradients are 0. Generalizing the relaxed loss to include a set of neurons with high losses to a given point helps address scalability issues in large networks. The final generalized loss incorporates a set of neurons with top \u03b3 percent relaxed loss. The final objective for learning Robust Local Linearity (ROLL) is the generalized loss, which includes a set of neurons with top \u03b3 percent relaxed loss. When \u03b3 = 100, the nonlinear sorting step disappears, leading to a simple additive structure that stabilizes training, is easy to parallelize, and allows for an approximate learning algorithm. This choice can induce a strong synergy effect by highly correlating gradient norms between layers. The ROLL loss in Eq. (9) requires heavy computation on gradient norms, but a parallel algorithm is developed to avoid back-propagation. By exploiting the functional structure of f \u03b8, a linear network g \u03b8 is constructed to mimic f \u03b8 behavior in S(x) without calling back-propagation. This allows for the computation of derivatives of all neurons to an input axis by forwarding two samples. The proposed approach allows for the computation of derivatives of all neurons to an input axis by forwarding two samples, with a complexity analysis provided in Appendix C. Despite the parallelizable computation, computing the loss remains challenging. Despite the parallelizable computation of \u2207 x z i j, computing the loss for large networks in a high dimension setting is still challenging. An unbiased estimator of the ROLL loss in Eq. FORMULA17 is proposed when \u00ce(x, \u03b3) = I. The sum of gradient norms can be efficiently computed using a decoupling method, allowing for the computation to be stored within GPU memory. In practice, sampling D input axes can be done uniformly to aid in the computation process. The proposed algorithms provide an unbiased approximation for computing partial derivatives with respect to input axes in deep learning models with affine transformations and piecewise linear activation functions. They can be used by enumerating neurons with ReLU-like activation functions. The algorithms do not immediately generalize to nonlinearity of maxout/max-pooling, but initial steps are provided in the Appendix E. In this section, the 'ROLL' approach is compared with a baseline model ('vanilla') in various scenarios using accuracy, number of complete linear regions, and p margins of linear regions as evaluation measures on a testing set. Experiments were conducted on a single GPU with 12G memory. The proposed algorithms offer an unbiased approximation for computing partial derivatives in deep learning models with affine transformations and piecewise linear activation functions, specifically for neurons with ReLU-like activation functions. Parameter analysis was conducted on the MNIST dataset using a 4-layer FC model with ReLU activations. The testing data was evaluated at different percentiles, and models with the largest median were reported. Experiments were done with a 55,000/5,000/10,000 split of the dataset. The results are shown in TAB1. The tuned models with specific parameters showed improved accuracy compared to the baseline model. The ROLL loss achieved significantly larger margins for most percentiles compared to the vanilla loss, even with a slight decrease in accuracy. The Spearman's rank correlation between certain variables in the testing data was consistently high. The lower #CLR in our approach indicates the presence of larger linear regions across different testing points. The ROLL model shows larger linear regions with consistent labels for points within the same region. Parameter analysis in Figure 2 demonstrates how accuracy changes with different hyper-parameters. Higher gamma values indicate less sensitivity to C and lambda. Running time efficiency of the proposed method is validated. The efficiency of the proposed method is measured by comparing different loss computation methods. The approximate ROLL loss is found to be 9 times faster than the full loss, with comparable accuracy and margins. Overall, the approach is only twice slower than the vanilla loss. The perturbation algorithm achieves about 12 times empirical speed-up compared to back-propagation. The computational overhead of the method is minimal, achieved by the perturbation algorithm and the approximate loss. The dataset used for training/testing has variable sequence length with 12 channels and 9 classes. The network implemented is the scaled Cayley orthogonal RNN (scoRNN) with LeakyReLU activation. Results show our approach leads to larger margins on testing data compared to the vanilla loss. The Spearman's rank correlation between\u02c6 x,1 and\u02c6 x,2 among all cases is 0.98. Sensitivity analysis on derivatives identifies stability bounds at each timestamp and channel. ROLL regularization shows larger stability bounds compared to the vanilla model. Experiments on Caltech-256 BID18 dataset with 256 classes are conducted. The study conducted experiments on the Caltech-256 BID18 dataset with 256 classes, downsizing images and training a 18-layer ResNet. The ROLL loss was used with 120 random samples per channel, and evaluation measures were implemented due to high input dimensionality. The study used a sample-based approach to evaluate gradient stability in different linear regions for labeled data. Gradient distortion was measured in terms of expected and maximum distortion within an intersection of an \u221e-ball and image domain. The study evaluates gradient stability in different linear regions for labeled data by measuring gradient distortion using a genetic algorithm BID33 for black-box optimization. The study uses a genetic algorithm BID33 for black-box optimization to evaluate gradient stability in different linear regions for labeled data. Results show that the ROLL loss yields more stable gradients than the vanilla loss with slightly better precisions. Only 40 and 42 out of 1024 examined examples change prediction labels in the ROLL and vanilla model, respectively. This paper introduces a new learning problem to create locally transparent neural networks with stable gradients. The ROLL loss produces stable shapes and intensities of gradients compared to the vanilla loss. More examples with integrated gradient attributions are provided in the appendix. The proposed ROLL loss expands regions with stable derivatives and generalizes the stable gradient property across linear regions in piecewise linear networks. The feasible set of activation patterns is equivalent to satisfying linear constraints in each layer, ensuring stable gradients. The proof by induction shows that directional feasibility is satisfied when a point x, a feasible set S(x), and a unit vector \u2206x exist. Additionally, the 1-ball feasibility proposition states that any point x within a 1-ball B ,1 (x) with extreme points is a convex combination of x 1 , . . . , x 2D and thus belongs to the feasible set S(x). Proposition 6 states that the 2-ball Certificate guarantees the minimum distance between a point x and a union of hyperplanes in a convex polyhedron. The proof involves ensuring that the hyperplanes induced from linear constraints are at least a distance of 2 away from x. Additionally, a neural network feasible model is constructed to match the optimal model. The network g \u03b8 is constructed with the same weights and biases as f \u03b8 but with a linear activation function. Each layer in g \u03b8 is represented as a function of x, with a fixed activation function \u00f4. The new activation function applies linearity to the neurons, allowing for easy computation of derivatives with respect to input dimensions. This approach simplifies the process by using two forward passes to compute all gradients of z. The proposed approach simplifies gradient computation by using two forward passes to analyze complexity, assuming no overhead for parallel computation. This method requires 2M operations in total, compared to back-propagation which cannot be parallelized among neurons. The proposed approach simplifies gradient computation by using two forward passes to analyze complexity. Back-propagation cannot be parallelized among neurons, requiring sequential computation of gradients. Dynamic programming can be used with the chain-rule of Jacobian to compute all gradients efficiently. The proposed approach simplifies gradient computation using dynamic programming and chain-rule of Jacobian for efficient computation of gradients. It highlights the feasibility of deriving inference and learning methods for maxout/max-pooling nonlinearity. The text discusses deriving inference and learning methods for a piecewise linear network with max-pooling nonlinearity. It suggests avoiding max-pooling neurons due to inducing new linear constraints, recommending convolution with large strides or average-pooling instead. The target network is assumed to have a single nonlinearity mapping N neurons to 1 output. Once an activation pattern is fixed, the network reverts to a linear model. The text discusses how when an activation pattern is fixed, the network reverts to a linear model due to the disappearance of nonlinearity in max-pooling. This induces a feasible set in the input space with stable derivatives, but may lead to a degenerate case where two activation patterns result in the same linear coefficients. The feasible set can be represented as a convex polyhedron with linear constraints, allowing for the application of inference and learning algorithms. The text discusses how max-pooling induces linear constraints for inference and learning algorithms. The FC model has 4 hidden layers with 100 neurons each. The input dimension is 2, output dimension is 1, and the loss function is sigmoid cross entropy. The model is trained for 5000 epochs with Adam optimizer, tuning \u03bb for distance and relaxed regularization problems. The FC model consists of 4 hidden layers with 300 neurons each, using ReLU activation function. The loss function is cross-entropy with soft-max. The data is normalized with specific values. The margin and loss are computed during training without approximation. The model uses ReLU activation function, cross-entropy loss with soft-max, and stochastic gradient descent with Nesterov momentum. Parameters like learning rate, momentum, and batch size are specified. Grid search is done on \u03bb, C, \u03b3, and models with the largest validation accuracy are reported. Data normalization is not performed, and exact ROLL loss is computed during training. The representation is learned using a single layer scoRNN with LeakyReLU activation functions. The hidden neurons dimension is set to 512, and AMSGrad optimizer BID21 is used with a learning rate of 0.001. Grid search is done on \u03bb, C, and \u03b3 for tuning. We perform a grid search on \u03bb \u2208 {2 \u22126 , . . . , 2 3 }, C \u2208 {2 \u22125 , . . . , 2 7 }, with \u03b3 = 100. Models with the largest testing accuracy are compared to the baseline model. We use a pre-trained ResNet-18 model from PyTorch and modify the architecture by replacing max-pooling with average-pooling after the first convolutional layer. To optimize the model, max-pooling after the first convolutional layer is replaced with average-pooling to reduce linear constraints. The receptive field of the last pooling layer is enlarged to output 512 dimensions. The model is trained with stochastic gradient descent with Nesterov momentum for 20 epochs, starting with an initial learning rate of 0.005 adjusted to 0.0005 after the first 10 epochs. The model is trained for 20 epochs with an initial learning rate of 0.005, adjusted to 0.0005 after 10 epochs. The momentum is 0.5 and the batch size is 32. The best validation loss model is selected. Tuning involves fixing C = 8, using 18 samples for learning, and tuning \u03bb until a significantly inferior validation accuracy is reached. \u03bb is then fixed at 0.001 and C is found to be already at the highest plausible value of 8. Finally, a model is trained with 360 random samples for approximate learning. The model is trained with 360 random samples using a genetic algorithm (GA) BID33 with 4800 populations P and 30 epochs. Samples are evaluated based on distance from the target x, sorted, and updated through crossover and projection steps. The genetic algorithm (GA) used in training the model with 360 random samples involves a projection step to ensure feasibility. Mutation was not implemented due to computational reasons. The crossover operator in GA is compared to a gradient step, with direction determined by other samples and step size chosen randomly. Visualizations include the original image, original gradient, adversarial gradient, and image of the adversarial gradient. The text discusses the visualization of gradients and integrated gradients in the context of a genetic algorithm used for training a model. It explains the concepts of distorted gradient, image of adversarial gradient, original integrated gradient, and adversarial integrated gradient. The visualization process involves aggregating derivatives, taking absolute values, and normalizing the aggregated derivatives. The text discusses visualizing gradients and integrated gradients in a genetic algorithm for model training. It involves aggregating derivatives, normalizing them, and visualizing as gray-scaled images. The examples in Caltech-256 dataset highlight different gradient distortions. The text discusses visualizing gradient distortions in a genetic algorithm for model training using the Caltech-256 dataset. It shows the P25 and P50 percentiles of maximum 1 gradient distortions on the ROLL model. The values in Figure 5 and 6 differ slightly from Table 4 due to interpolation methods. The text visualizes gradient distortions in a genetic algorithm for model training using the Caltech-256 dataset. The maximum 1 gradient distortion values for the vanilla model and ROLL model are compared for different categories like 'Bear' and 'Rainbow'."
}