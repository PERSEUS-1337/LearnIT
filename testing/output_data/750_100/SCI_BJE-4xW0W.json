{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) that allow sampling from observational and interventional distributions using adversarial training. The generator architecture is structured based on a causal graph for conditional and interventional sampling of face images with binary feature labels. A two-stage procedure is devised for learning a CiGM over the labels and images using a Wasserstein GAN. The text discusses the use of causal implicit generative models (CiGMs) for sampling from observational and interventional image distributions using adversarial training. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed to generate images conditioned on binary labels. The optimal generator of CausalGAN samples from image distributions conditioned on labels, allowing for sampling from interventions not naturally occurring in the dataset. Generative adversarial networks (GANs) are neural models that can sample from high-dimensional distributions without explicit parameterization. The generator network uses a noise vector to produce outputs, refined through feedback from an adversary network. Generative adversarial networks (GANs) use a discriminator network to refine the output of the generator by distinguishing between generated and real samples. GANs have been successful in generating samples from distributions like images and videos. Extensions include sampling from class conditional data distributions by feeding class labels to the generator. Various neural network architectures have been proposed for this task. The architecture proposed in this paper aims to sample images from both joint and interventional distributions, capturing label dependencies that previous architectures lack. In this paper, the focus is on extending previous work on conditional image generation by capturing the dependence and causal effect between labels. Conditional image generation is viewed as a causal process where labels determine the image distribution. The generator maps labels to images non-deterministically, following the causal graph \"Labels cause the Image\". The model can also incorporate causal relationships between different labels, such as Gender and Mustache. The text discusses causal relationships between labels in conditional image generation. It explains how conditioning on different labels affects the sampling process and introduces the concept of interventions in causal graphs. Intervening in a causal graph fixes the value of a variable, impacting the distributions of its descendants but not its ancestors. This concept is illustrated with examples of conditional and interventional samples in the context of Bald and Mustache variables. The proposed causal implicit generative models (CiGM) can sample from the correct joint distribution. Implicit generative models (CiGM) can sample from correct joint, conditional, and interventional probability distributions. The true causal graph is assumed to be given. GANs can train causal implicit generative models when the generator structure inherits neural connections from the causal graph. Wasserstein GAN (WGAN) is used to train a CiGM for binary image labels, followed by the proposal of two novel conditional GANs called CausalGAN and CausalBEGAN for images and image labels. Our contributions include proposing two novel conditional GANs, CausalGAN and CausalBEGAN, which can sample from true conditional distributions. By combining CausalGAN with a CiGM on labels, we create a CiGM on both labels and images. Adversarial training can be used to train a CiGM by structuring the generator architecture based on the causal graph. Empirical results show that WGAN can learn a CiGM for binary labels, enabling conditional and interventional sampling of images. We propose a two-stage procedure to train a CiGM over binary labels and images using a novel conditional GAN architecture. Our model, CausalBEGAN, extends BEGAN to accept labels and produces high-quality images capturing the image labels. The model CausalBEGAN generates high-quality images based on image labels. It is evaluated on labeled CelebA data and can produce label-consistent images even for interventions not seen during training. Previous works have proposed conditional GANs like CGAN and ACGAN, which use image labels for generating images. In BID10, ACGAN proposes a new approach where the discriminator estimates the label instead of receiving it as input. BID15 introduces InfoGAN, aiming to maximize mutual information between inputs and generated images. Existing conditional GANs do not allow sampling from label combinations not in the dataset. BiGAN and ALI extend the standard GAN framework by learning a mapping from inputs. In CoGAN, SD-GAN extends the GAN framework by learning a mapping from image space to latent space and enforcing weight sharing between generators and discriminators. SD-GAN splits the latent space into \"Identity\" and \"Observation\" portions, allowing for the generation of faces of the same person by fixing the identity portion of the latent code. This extension of BEGAN to accept labels is the only one known to date. CausalBEGAN is an extension of BEGAN that accepts labels, a unique approach compared to CoGAN and SD-GAN. Authors in BID0 use CGAN with a one-hot encoded vector for age interval, allowing for age attribute changes in face images. Generative models have applications in compressed sensing, with guarantees for vector recovery. The use of causal principles in deep learning and deep learning techniques for causal inference is a growing area of interest. Recent attention has been given to using deep learning techniques for causal inference. In various studies, authors have explored the connection between GAN layers and structural equation models, proposed using neural networks to discover causal relations between variables and image class labels, and introduced causal regularization for training predictive models. In recent work, authors have explored the connection between GANs and causal generative models, using neural networks to learn causal graphs. They utilize Pearl's framework of structural causal models, representing causal models with structural equations and directed acyclic graphs between random variables. Within the structural causal model framework, X causing Y implies the existence of a function f and an unobserved variable E, independent from X, determining Y. The causal graph X \u2192 Y is a directed acyclic graph representing this relationship. The causal graph is constructed from structural equations, with the parents of a node X_i indicating its causes. In a structural causal model, the causal graph is constructed from structural equations, with parents of a variable representing its causes. The model includes functions, random variables, exogenous variables, and a probability distribution over the exogenous variables. The causal graph is a directed acyclic graph that illustrates the relationships between variables. In a structural causal model, the causal graph is constructed from structural equations, with parents of a variable representing its causes. The model includes functions, random variables, exogenous variables, and a probability distribution over the exogenous variables. The causal graph is a directed acyclic graph that illustrates the relationships between variables. An intervention changes the underlying causal mechanism and corresponding causal graph by removing connections of a node to its parents. In a structural causal model, the causal graph is constructed from structural equations, with parents of a variable representing its causes. An intervention changes the underlying causal mechanism and corresponding causal graph by removing connections of a node to its parents. The post-interventional distribution in a Bayesian network can be calculated by factorizing the observational distribution. The post-interventional distribution is determined by the assignment of variables, assuming a given causal graph. Learning the causal graph requires experiments or additional assumptions, as multiple graphs can produce the same joint probability distribution. This paper focuses on learning a causal model from a known causal graph and structural equations. In the context of learning causal graphs from known structural equations and exogenous variables, Bayesian networks can help sample from correct observational distributions. The proposed causal implicit generative models aim to sample from both observational and interventional distributions. Generative adversarial networks can be used to train causal implicit generative models by arranging the generator neural network connections to reflect the causal graph structure. This model represents functions f X , f Y , f Z using feedforward neural networks and independent noise terms (N X , N Y , N Z ). See FIG3 for the architecture. The feedforward neural network can represent causal models with a graph. Two causal models with the same observational distribution will have the same interventional distributions for any intervention, given the true causal graph. The feedforward neural network connects causal models with a graph. It defines causal implicit generative models using mutually independent random variables. Causal implicit generative models are defined as feedforward neural networks that generate outputs consistent with a causal graph. Adversarial training is used to ensure the generator network aligns with the causal graph. These models are trained using samples from a joint distribution based on the causal relationships between variables. However, in the context of image generation with binary labels, it is challenging to learn both the joint label and image distribution simultaneously. The focus is on the CausalGAN architecture for this application. The CausalGAN architecture divides the task of learning a CiGM into two subtasks: training a generative model over labels and then training a generative model for images conditioned on the labels. The architecture assumes the image node is always the sink node of the causal graph for image generation problems. The CausalGAN architecture introduces a new model called Causal Controller for binary labels, ensuring optimal generator outputs label-conditioned image distributions. This model controls the distribution from which images are sampled when intervened or conditioned on. The Causal Controller network in the CausalGAN architecture produces labels sequentially based on the causal graph, aiming to sample from a discrete label distribution using WGAN for better training results. In the CausalGAN architecture, a new conditional GAN is designed to generate images based on labels from the Causal Controller. Two separate labeler neural networks, Labeler and Anti-Labeler, are used to estimate labels. The CausalGAN architecture includes two separate labeler neural networks, Labeler and Anti-Labeler. The Labeler estimates image labels in the dataset, while the Anti-Labeler estimates labels of images sampled from the generator. The generator aims to produce realistic images by competing with the discriminator, ensuring consistency with labels by minimizing Labeler loss, and avoiding easy-to-label unrealistic image distributions by maximizing Anti-Labeler loss. CausalGAN stands out from other conditional GAN architectures by incorporating an Anti-Labeler network in addition to a Labeler. The CausalGAN architecture includes an Anti-Labeler network in addition to a Labeler network. The Anti-Labeler loss discourages label-conditioned mode collapse by preventing the generator from outputting only typical faces for a fixed label combination. Minibatch-features are commonly used to avoid mode-collapse, but may be ineffective for rare label combinations. The CausalGAN architecture includes an Anti-Labeler network to prevent mode collapse for rare label combinations. Results for a single binary label are presented, extendable to more labels. Pr(l, x) represents data distribution between image and labels, while Pg(l, x) denotes joint distribution between labels given to generator and generated images. Perfect Causal Controller assumption is made, with mappings by generator, discriminator, Labeler, and Anti-Labeler. The CausalGAN architecture includes a generator, discriminator, Labeler, and Anti-Labeler. The generator loss function contains label loss terms and a GAN loss, with an additional loss term from the discriminator. The optimal generator outputs the class conditional image distribution. The Anti-Labeler, Labeler, and discriminator each solve specific optimization problems. The CausalGAN generator, when operating optimally with the discriminator and labeler, samples from the class conditional image distribution. This result holds for a single binary label and can be extended to multiple binary variables. This architecture is the only one with this guarantee after CGAN. The CausalGAN architecture is the only one with a guarantee after CGAN. The optimal discriminator behaves the same as in GAN loss. The generator minimizes the loss by sampling from class conditional distributions. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. This two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. The causal graph D = (V, E) involves image labels and their joint distribution. A generator G can sample from the image distribution based on given labels. The objective is to extend the result to cases with multiple binary labels. If the Labeler and Anti-Labeler output scalars representing label probabilities, the minimizer of C(G) samples from the class conditional. To address the challenge of implementing the architecture for large d values, an alternative approach is proposed. This involves extending the single binary label setup by using cross entropy loss terms for each label. The goal is for the generator to capture the joint label posterior given the image, ensuring that it captures each label's posterior distribution. The posterior distribution, P r (l i |x) = P g (l i |x) (Proposition 3), does not always guarantee true class conditional distributions. However, for many practical joint distributions where labels are determined by the image, the joint label posterior will be true to the data distribution. Trained causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms. See Section 8.7 for formal results. In this section, counterfactual sampling is discussed, which involves conditioning on an event and sampling from the push-forward of posterior distributions of exogenous noise terms under an interventional causal graph. A simple extension of BEGAN is outlined where image labels are fed to the generator, with details provided in the Appendix. The Causal Controller is used to accommodate interventional sampling. In Section 8.8, the Causal Controller is utilized for interventional sampling. A Labeler network is modified to label real images well and generated images poorly, similar to the BEGAN discriminator. Margin modifications are motivated by the importance of a well-trained Labeler for meaningful gradients in label quality, with label gradients being most informative when image quality is high. In this section, CausalGAN and CausalBEGAN are trained on the CelebA Causal Graph. The Causal Controller is trained first, and observations suggest a margin term is necessary for comparing margins. The dataset used meets the conditions, with an example being Male \u2192 Mustache in the CelebA Causal Graph. The probability of Male = 1 is not affected by Mustache = 1. The top row of images shows males and females with mustaches, even though the generator never sees the label combination {Male = 0, Mustache = 1} during training. The bottom row displays only male images sampled from the conditional distribution P(.|Mustache = 1). Since Male \u2192 Mustache in CelebA Causal Graph, the probability of Male = 1 is not affected by Mustache = 1. The proposed generative model can create samples conditioned on labels and sample from interventional distributions. The theoretical analysis provides guarantees about correct sampling under interventions, such as intervening on the Narrow Eyes label in CelebA Causal Graph with CausalBEGAN. The generative model can produce samples conditioned on labels and intervene on distributions. Causality in generative models leads to creativity by generating diverse samples. This is illustrated with CausalGAN and its impact on Narrow Eyes in images. The research discusses training samples for models CausalGAN and CausalBEGAN, supported by various grants. A structural causal model includes functions, random variables, and exogenous variables with a probability distribution. The joint distribution of observable variables V is determined by the distributions of E and functional relations F. The causal graph D is a directed acyclic graph on nodes V, where a node Xj is a parent of node Xi if Xj is in the domain of fi. D is a Bayesian network for the joint probability distribution over V, assuming causal sufficiency. The joint distribution of observable variables V is determined by the distributions of E and functional relations F. A variable is a direct parent of at most one observable variable in a causal Bayesian network. Interventional distributions can be calculated directly from conditional probabilities and the causal graph. The joint data distribution over a single binary label l and the image x is denoted as P r (l, x), while the joint distribution over the binary label l fed to the generator and the image x produced by the generator is denoted as P g (l, x). Later, l is generalized to be a vector. The optimal discriminator D for a fixed generator G is given by a specific formula. The optimal Labeler and Anti-Labeler are identified through lemmas. The optimum Labeler has a certain relationship with D, while the optimum Anti-Labeler has a specific relationship with the generator. The optimum Anti-Labeler for a fixed generator is defined by D LG (x) = P g (l = 1|x), assuming causal sufficiency. Pearl's model assumes exogenous variables are mutually independent. The complete graph \"cG1\" is formed with added edges, and rcG1 is created by reversing the direction of every edge in cG1. The generator loss C(G) is defined for the discriminator, Labeler, and Anti-Labeler. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. DISPLAYFORM0 LG (x) = P g (l = 1|x), where KL is the Kullback-Leibler divergence, minimized if P g = P d jointly over labels and images. FORMULA8 due to P r (l = 1) = P g (l = 1) = \u03c1. Corollary 1 states that a causal implicit generative model for the causal graph D can sample from the image distribution conditioned on the given label combination. The concatenated generator neural network G(C(Z1), Z2) is consistent with the causal graph D, assuming perfect sampling from true label joint distribution and conditional image distribution. The joint distribution over generated labels and image is the true distribution, as per Proposition 1. The concatenated model is a causal implicit generative model for graph D, able to sample from observational and interventional distributions. Modifications are explained for extending the proof to cases with multiple binary labels, addressing the challenge of learning the correct joint distribution. The concatenated model is a causal implicit generative model for graph D, able to sample from observational and interventional distributions. Modifications are explained for extending the proof to cases with multiple binary labels, addressing the challenge of learning the correct joint distribution. Two solutions are presented: (1) Estimating the probability of label combinations and (2) Using labelers to estimate probabilities of individual labels to ensure equality at the minimizer of C(G). The Lemma presented in FORMULA12 DISPLAYFORM0 states that the optimum Labeler for loss in (12) has D * LR (x)[j] = P r (l = j|x). The proof shows that considering only label combinations with positive probability and functions D LR that are strictly positive on these combinations can achieve a finite loss. The optimum Labeler network for loss in (12) achieves a finite loss by satisfying P(Z x = j) = P r (l = j|x), as shown in the lemma. This unique optimum is reached when the two random variables have the same distribution. The optimum Labeler network provides the posterior probability of label combinations based on observed images. The Anti-Labeler network solves an optimization problem to determine the probability of labels given an image. The Anti-Labeler does not control the joint distribution between generated images and labels, unable to optimize label conditional entropy. The generator optimizes the conditional image distributions given specific label combinations, as shown in Theorem 2. The global minimum of the virtual training criterion C(G) is achieved when the generator, Labeler, and Anti-Labeler are at their optimum, with the condition that the joint label distribution is sampled accurately. This is proven by showing that the Kullback-Leibler divergence is minimized when the generated distribution equals the real distribution. The Kullback-Leibler divergence is minimized when the joint label distribution is accurate in the CausalGAN architecture with d labels, assuming a deterministic relationship between images and labels in the dataset. The global optimal generator samples from class conditional distributions by linking images to label vectors. The Anti-Labeler optimizes for fixed generators, while the generator optimizes for fixed discriminator, Labeler, and Anti-Labeler. The optimum generator is characterized for optimum Labeler, Anti-Labeler, and Discriminator. The global optimal generator achieves the global minimum of the virtual training criterion by ensuring equality between conditional image distributions and generated distributions. This guarantees correct conditional sampling. The assumption is that the image determines all labels, ensuring correct conditional sampling. In practice, this is relevant, as seen in the CelebA dataset where labels are a deterministic function of the image. The lemma states that any discrete joint distribution can be expressed as a product of conditional probabilities. Lemma 5 states that a discrete joint probability distribution with kronecker delta marginal probability functions is the product of these marginals. The proof involves showing that the joint distribution is zero everywhere except at specific points. The joint distribution can be marginalized to a kronecker delta function at specific points. Applying Bayes' rule shows that the image distributions and marginals are true to the data distribution. The text discusses the relationship between the joint distribution, marginal distributions, and product distributions. It concludes that the optimum generator samples from the class conditional image distributions. In this section, a new extension of BEGAN is proposed where image labels are fed to the generator. The central contribution of BEGAN is a boundary equilibrium approach that encourages generator training when the discriminator is near optimum. A new loss and set of margins are introduced to reflect the idea that label gradients are most informative when image quality is high. In this extension of BEGAN, image labels are incorporated into the generator. The loss functions are modified to include labels, but the use of margins is not addressed, which is crucial in BEGAN. The naive formulation of the BEGAN extension includes image labels in the generator but overlooks the use of margins, which are essential. A better trained Labeler is necessary for meaningful gradients, leading to the introduction of a margin-coefficient tuple (b2, c2). The generator aims to minimize two loss terms, but image quality may suffer as images exploiting the Labeler network may not be realistic. Label loss may not provide useful gradients for improving image quality. Based on the need for meaningful gradients, label loss should only be incorporated when the image quality margin is significantly larger than the label margin. A new margin of margins term, b3, is introduced to achieve this. The margin equations and update rules are adjusted accordingly, with learning rates \u03bb1, \u03bb2, \u03bb3 for the coefficients. BEGAN's advantage lies in its monotonically decreasing scalar for tracking gradient descent optimization convergence, which is preserved in our extension through the definition of DISPLAYFORM3 and the progressive decrease of M complete. In Section 4, a GAN was used to train a causal implicit generative model by incorporating the causal graph into the generator structure. The behavior and convergence of causal implicit generative models were investigated on synthetic data with three features {X, Y, Z} from different causal graphs: \"line\" X \u2192 Y \u2192 Z, \"collider\" X \u2192 Y \u2190 Z, and \"complete\" X \u2192 Y \u2192 Z, X \u2192 Z. Each node was randomly sampled once for a cubic polynomial in n + 1. For each causal model, a cubic polynomial in n + 1 variables computes the value of each node given its parents and an exogenous variable. A new synthetic dataset is created for each model, and the convergence of the joint distribution is compared to the true joint using total variation distance. Generators structured as line, collider, or complete graphs are included, as well as fully connected neural networks with no knowledge of causal structure. The fully connected neural networks {f c3, f c5, f c10} map random noise to 3 output variables using 3, 5, or 10 layers. Results are shown in FIG9 for data generated from different causal graphs. Convergence behavior of the generator distribution is observed based on the causal graph used to structure the generator. The correct Bayesian network should lead to convergence to the true joint distribution. The correct Bayesian network should lead to convergence to the true joint distribution. Complete graph can encode all joint distributions and is expected to work well with all data generation models. The convergence behavior of adversarial training across different causal generative models is being explored. In the line graph data X \u2192 Y \u2192 Z, the best convergence behavior is seen when the line graph is used in the generator architecture. The line graph is used in the generator architecture for good convergence. Fully connected networks with 3 layers perform well, but those with 5 and 10 layers perform worse. The number of layers in fully connected networks should be tuned for optimal performance in adversarial training. Using the wrong Bayesian network, like the collider, results in worse performance. Surprisingly, using a fully connected generator with 3 and 5 layers in the collider graph shows the best performance. Using 3 and 5 layers shows the best performance in fully connected networks, while 10 layers give the worst convergence behavior. Complete and collider graphs achieve decent performance, with line graphs performing the worst. Line and collider graphs do not show any convergence behavior. The effect of using the wrong causal graph on an artificially generated dataset is evaluated. The effect of using the wrong causal graph on an artificially generated dataset is demonstrated through scatter plots of a three-dimensional distribution. Different generator causal graphs are compared, showing that adding the edge Young \u2192 Male significantly improves the learned distribution. Both graphs include the edge Male \u2192 Mustache, correctly learning that women do not have mustaches. Using the correct causal graph improves the scatter plot distribution, while using the wrong graph results in a different distribution. A causal graph is used on a subset of image labels in the CelebA dataset, known as CelebA Causal Graph (G1), with a completed version cG1 showing the causal relationships between Young, Male, Eyeglasses, Bald, Mustache, Smiling, Wearing Lipstick, Mouth Slightly Open, and Narrow Eyes. The CelebA Causal Graph (G1) and its completed version cG1 show causal relationships between image labels like Young, Male, Eyeglasses, Bald, Mustache, Smiling, Wearing Lipstick, Mouth Slightly Open, and Narrow Eyes. The effect of using the incorrect Bayesian network for the data is examined, with G1 generating Male and Young independently, leading to inaccurate results. Despite this, both G1 and cG1 graphs produce Causal Controllers that never output certain label combinations. The CelebA Causal Graphs G1 and cG1 show causal relationships between image labels. Both graphs lead to Causal Controllers that never output the label combination {Female, Mustache}. A modified version of Wasserstein GAN assures convergence in distribution of the Causal Controller output to the discretely supported distribution of labels. The learned outputs have \"approximately discrete\" support, as demonstrated in FIG12. The CelebA Causal Graphs G1 and cG1 demonstrate causal relationships between image labels, leading to Causal Controllers that avoid outputting the label combination {Female, Mustache}. Both graphs allow training of reasonable marginal distributions for all labels, with minimal deviation. The Wasserstein Causal Controller performance is tested on a subset of binary labels from the CelebA dataset using a causal graph. The generator is trained to map continuous noise to a discrete distribution, with 96% of samples appearing near 0 or 1. The proposed Causal Controller outputs an almost discrete distribution. The text discusses the convergence of total variational distance (TVD) for different causal graphs in relation to the CelebA dataset. The completion and reversed versions of the causal graph show decreasing TVD to 0, while the original graph asymptotes to around 0.14, indicating incorrect conditional independence assumptions. This suggests that imperfect causal graphs can still lead to reasonable convergence in implicit causal generators. Additional CausalGAN results are presented in FIG3, 13, showing the impact of intervening vs conditioning on wearing lipstick in the CelebA dataset. The causal graph indicates that wearing lipstick does not affect the probability of being male. The top row displays both males and females wearing lipstick, while the bottom row only shows female images. The conditional distribution P(.|Wearing Lipstick = 1) in CelebA dataset shows only female images due to P(Male = 0|Wearing Lipstick = 1) \u2248 1. Intervening on Narrow Eyes does not affect Smiling, but conditioning on Narrow Eyes = 1 increases the proportion of smiling images in the dataset. In this section, CausalBEGAN is trained on CelebA dataset using CelebA Causal Graph. The Causal Controller is pretrained with a Wasserstein loss and used for training the CausalBEGAN. Empirical justification for the margin of margins introduced is shown by training the model with different settings. Image quality for rare labels deteriorates without the margin. The difference between interventional and conditional sampling for specific labels is illustrated. Intervening vs Conditioning on Bald label in CelebA Causal Graph. The top row shows both bald males and bald females, while the bottom row only displays male images due to the dataset distribution. In CelebA Causal Graph, the probability of Smiling = 1 is not affected by Mouth Slightly Open = 1. However, conditioning on Mouth Slightly Open = 1 increases the proportion of smiling images. Additional simulations for CausalGAN are provided, showing conditional image generation properties and examining mode collapse and image diversity. In this section, additional simulation results for CausalBEGAN are presented. The third margin term b3 introduces complications that cannot be ignored, as shown in FIG6. The setup allows for the definition of a scalar \"M\" that decreases monotonically during training, with an extension M complete that preserves these properties (defined in 28). FIG9 demonstrates M complete decreasing monotonically during training, along with conditional image generation properties. The CausalBEGAN architecture shows conditional image generation properties through label sweeps, revealing a discrete function with respect to label input parameters. Mode collapse and image diversity are examined through a random sampling of 256 images. The study explores training an implicit causal generative model for labels and images, treating the image as part of the causal graph. One approach involves encoding the label as a constant image in an additional channel. However, in the CelebA Causal Graph, the image generation was not effectively learned, possibly due to the discriminator focusing on labels rather than providing useful gradients for image generation. The implementation differs from the theoretical concept, highlighting various implementation details. The implementation details of the Wasserstein Causal Controller for generating face labels were explained, using the total variation distance (TVD) as a metric for model success. The gradient term as a penalty was estimated by evaluating the gradient at points interpolated between real and fake batches. The Wasserstein approach allowed training the Causal Controller to output discrete labels. The generator architecture in the Causal GAN framework uses uniform noise and neural networks to map parents to children. Training involves 25 Wasserstein discriminator updates per generator update with a learning rate of 0.0008. Stochastic gradient descent is used for training, and the DCGAN Radford et al. (2015) is extended into the framework by adding a Labeler. In the Causal GAN framework, the Labeler networks are added to extend the DCGAN architecture. The training process involves making 6 generator updates for each discriminator update on average. The loss functions are modified to accommodate d-dimensional label vectors, with the Labeler and Anti-Labeler loss terms being extended by averaging the loss terms for every label. The Labeler networks in the Causal GAN framework extend the DCGAN architecture by incorporating d-dimensional label vectors. The loss terms for each label are determined by the coordinates of the vectors provided by the labelers. This approach differs from the architecture in Section 8.6, where the discriminator estimates probabilities of all label combinations. While this method may not guarantee sampling from class conditional distributions if data distribution is not restricted, it is sufficient for labeled image datasets where labels are completely determined by the image. For more details, refer to Section 8.7 in the supplementary material. In the implementation of CausalBEGAN, the order of terms in cross entropy expressions for labeler losses was swapped to improve image sharpness. Parameter tunings were kept minimal, using the same learning rate for both generator and discriminator.\u03b3 values were set to 0.5, with little sensitivity expected to these values. The model's sensitivity to parameter values is low, achieving good performance without much tweaking. Customized margin learning rates are used, reflecting asymmetry in generator response speed. Best models have all margins active near 0 with occasional small positive values. Comparisons between CausalGAN behaviors are shown in this section. Using Anti-Labeler network in CausalGAN leads to faster convergence and more diverse images, especially for very rare labels. See FIG3, 25 for results comparison."
}