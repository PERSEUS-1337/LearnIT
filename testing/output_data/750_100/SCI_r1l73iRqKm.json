{
    "title": "r1l73iRqKm",
    "content": "In open-domain dialogue, intelligent agents struggle to incorporate knowledge into conversations. Most models rely on generating generic responses rather than using recalled knowledge as context. A new dataset grounded in knowledge from Wikipedia aims to address this challenge and improve dialogue architectures. Our dialogue models are designed to retrieve knowledge from Wikipedia, read and use it to generate natural responses. These models excel in conducting knowledgeable discussions on various topics, as evaluated by metrics and human feedback. The ultimate goal of natural language research is for humans to communicate effectively with machines, requiring machines to master skills like language comprehension and memory retention. Dialogue models aim to master skills like language comprehension, memory retention, reasoning, and generating captivating responses. Current state-of-the-art approaches, such as sequence to sequence models, struggle with bringing memory and knowledge into conversations effectively. In the context of dialogue models, the need for more direct knowledge memory mechanisms is emphasized for open-domain conversations where speakers exchange information and viewpoints on various topics. This task presents a challenge in effectively incorporating memory and knowledge into conversations. Incorporating memory and knowledge into open-domain conversations is a challenging task. The authors propose Transformer Memory Networks, combining Memory Network and Transformer architectures, to generate state-of-the-art text representations. They create a supervised dataset of human-human conversations to train the models. The authors propose Transformer Memory Networks to incorporate memory and knowledge into open-domain conversations. They use crowd-sourced workers to generate diverse discussion topics and conversations, linking them to Wikipedia for knowledge grounding. Their models are tested using automatic metrics and human evaluations. The authors introduce Transformer Memory Networks to enhance open-domain conversations with knowledge from Wikipedia. Their models are evaluated for engaging conversations compared to baselines, and a new benchmark in ParlAI aims to drive further research improvements in dialogue systems. Many existing dialogue tasks lack explicit knowledge utilization, focusing instead on sequence-to-sequence models attending to recent dialogue history. Our work explores unstructured knowledge from a wide range of topics, potentially covering all of Wikipedia, in contrast to models that focus on recent dialogue history. In contrast to models focusing on recent dialogue history, our work explores unstructured knowledge from various topics, including all of Wikipedia. This work does not address question answering but focuses on natural human dialogues with a diverse set of utterances. The work explores unstructured knowledge from various topics, including all of Wikipedia, focusing on natural human dialogues with a diverse set of utterances. Previous works have used Memory Networks for dialogue discussing movies and structured knowledge from Reddit, while others have used unstructured text for discussing news articles and local businesses. In contrast to previous works using Memory Networks for dialogue discussing movies and structured knowledge from Reddit, our task involves grounding crowdworkers dialogues in Wikipedia articles and sentences. Our model combines Memory Networks, Transformers, and RNN encoder-decoders to develop a new architecture. Our work BID13 introduced a dataset based on movie chats in a closed domain. The paper showcases models operating on full multi-turn dialogue in an open-domain setting, a novel approach. The dialogue setting involves two participants engaging in chitchat, with one as a knowledgeable expert (wizard) and the other as a curious learner (apprentice). The apprentice freely talks to the wizard, playing the role of a curious learner. In the conversation stage, the apprentice engages with the wizard as a curious learner, aiming to delve deeply into a chosen topic for an engaging and informative discussion. The wizard's role is to share information with their partner, emphasizing the use of knowledge in the conversation. The wizard in a conversation with an apprentice chooses a topic and has access to Wikipedia paragraphs to guide their replies. The wizard must use this knowledge creatively and engagingly in the conversation. The flow of the conversation involves either player selecting a topic and starting the discussion. The wizard in a conversation with an apprentice selects a topic and uses Wikipedia paragraphs to guide their responses creatively. The apprentice sends a message, and the wizard constructs a response based on relevant knowledge. The conversation continues until one participant ends it, with a minimum of 4 or 5 turns each. The goal is to replace the human wizard with a learned agent. The goal is to replace the human wizard with a learned agent in a conversation between humans. A set of 1365 natural dialogue topics linked to Wikipedia articles were crowd-sourced. The wizard has access to relevant knowledge passages during the dialogue. The text chunk discusses the use of a retriever for collecting dataset results in the context of a conversation between a human wizard and an apprentice. The retriever uses an inverted index lookup and term vector model scoring to retrieve top articles for dialogue turns and original topics. This system is used to build the dataset, but a better method may exist. During data collection, the wizard can select relevant article titles and sentences to generate responses for the apprentice. Only one article and sentence can be chosen per turn. The wizard's UI is shown in Appendix A.1. The Wizard's UI is displayed in Appendix A.1. Dialogue models are being developed to replace the wizard in learning tasks, with access to a knowledge source like Wikipedia. Extensions of Memory Network BID19 and Transformer BID21 models are created to retrieve relevant information from a large memory, read and attend to it, and generate dialogue responses. These models are used consecutively in each turn to form a complete dialogue with a user. The development of dialogue models involves retrieval and generative models that utilize knowledge from a large knowledge base. The models aim to produce responses based on the dialogue context provided at each turn. The dialogue models utilize a large knowledge base organized into documents for knowledge retrieval. Standard information retrieval techniques are used to return a smaller set of candidates for fine-grained selection. The dialogue models use a large knowledge base organized into documents for knowledge retrieval. They employ two turns for each query, retrieving the top 7 articles for each lookup and flattening the results into separate sentences. This approach allows the neural model to attend to candidates independently without hierarchical issues. Knowledge attention is performed using an attention mechanism for fine-grained selection. The dialogue models use knowledge attention with an attention mechanism for fine-grained selection of sentences. Utterance prediction is then used to predict the next dialogue turn based on the encoded memory and dialogue context. The model encodes knowledge sentences and dialogue context using a Transformer. It calculates the final input encoding by performing dot-product attention and adding the weighted sum to get the representation. Candidate responses are encoded separately. The model is trained to predict the next dialogue turn based on the encoded memory and context. The model is trained to minimize cross-entropy loss by selecting the most relevant knowledge and dialogue context for response generation. Beam search with BPE encoding is used to select the best response. The model uses BID16 to enable generators to copy rare words from Wikipedia sentences. It employs a shared Transformer encoder to encode candidates and dialogue history, followed by a Transformer decoder for response generation. Training aims to minimize negative cross-entropy loss. The End-to-end model is trained to minimize negative log-likelihood of response utterance and can add supervision for correct knowledge selection. In the Two-stage version, separate models are used for knowledge selection and utterance prediction to improve performance. Maximizing performance of the component is crucial. Employing knowledge dropout (K.D.) improves decoder performance by preventing model from attending to knowledge during training. This technique helps generator be more resilient to errors and speeds up training. Experimental setups and results are described, focusing on knowledge selection and dialogue with knowledge. K.D. is a novel technique proposed here, similar to other dropout methods like feature dropout in BID25. The study evaluates models' ability to predict human-selected knowledge in dialogue history, comparing Transformers with baselines like IR and Bag-of-Words Memory Network. Pretraining Transformers on Reddit data yields the best results. The study compares Transformers with baselines like IR and Bag-of-Words Memory Network in predicting human-selected knowledge in dialogue history. Pretraining Transformers on Reddit data is crucial for optimal performance. The best performing Transformer model is used for a two-stage generative Memory Network in the full dialogue task, evaluating models on dialogue generation given knowledge in two settings. The study evaluates Transformer Memory Networks with knowledge selection experiments, showing improved performance with the addition of knowledge. Generative experiments compare End-to-end and Two-stage Transformer Memory Network models. The study compares generative End-to-end and Two-stage Transformer Memory Network models with baselines, showing that both models utilize knowledge in their responses, outperforming a Transformer model without knowledge. The Two-stage model performs better with predicted knowledge, while the End-to-end model also shows improvements with gold knowledge. The End-to-end model outperforms the Two-stage model in gold knowledge experiments, showing stronger perplexity and F1 scores. Additional knowledge selection supervision in the End-to-end model improves performance on every metric, suggesting tight integration of tasks is beneficial. Knowledge dropout also proves to be helpful. The conversation revolves around a preference for physical books over e-books due to the tactile experience and ownership of a real book. The individuals find reading on a screen disorienting and feel that reading on a tablet is not the same as holding a physical book. They express a preference for owning physical copies of books and discuss their experiences with e-readers like Kindle and Nook. The study includes human evaluation of models using crowd-sourced workers who rate dialogue partners based on engagingness. The Wiki F1 score is calculated based on model utterances overlapping with the first 10 sentences of Wikipedia. The study evaluates models based on engagingness through crowd-sourced worker ratings. It compares retrieval models to generative models and finds retrieval models outperform in human engagingness. The study compares retriever models with and without knowledge, finding that both trend towards using knowledge due to candidate sentences retrieved. The knowledgeable version obtains significantly higher Wiki F1 scores in both seen and unseen test sets. Generative models show improved human engagingness ratings with the use of knowledge, conveying more knowledge than retrieval models on both seen and unseen sets. The study compares retriever models with and without knowledge, finding that both trend towards using knowledge due to candidate sentences retrieved. Generative models show improved human engagingness ratings with the use of knowledge, conveying more knowledge than retrieval models on both seen and unseen sets. The gap between retrieval and generative models is larger on unseen data, as retrieval models are limited to producing a response from the training set where the unseen topic did not appear. Our study focuses on developing Transformer Memory Network models that utilize encyclopedic knowledge for engaging open-domain conversations. We introduce the Wizard of Wikipedia dataset for training and evaluating these models, showing their effectiveness in both automatic and human experiments. This benchmark aims to inspire further exploration in this research area for significant advancements. Significant advances are expected in research using the Wizard of Wikipedia dataset. Future work includes bridging the gap between retrieval responses and generative models, learning to retrieve and reason simultaneously, and exploring the relationship between knowledge-grounded dialogue and existing QA tasks. The goal is to create an engaging and knowledgeable conversational agent. The Wizard of Wikipedia dataset contains conversations between a wizard and an apprentice, where the wizard has access to an information retrieval system over Wikipedia. The dataset shows that apprentices ask questions in 13.9% of training set utterances and answer questions 39.5% of the time. Knowledge retrieval is performed based on dialogue history, with wizards clicking on a sentence used 6.2% of the time. The Wizard of Wikipedia dataset shows that the wizard and apprentice engage in various dialogue acts, with the wizard answering questions 39.5% of the time and making new statements 49.3% of the time. The dataset used the Persona-Chat dataset to select natural topics for conversation, with each persona consisting of 4-5 sentences describing interests. The Wizard of Wikipedia dataset involves dialogue acts between a wizard and an apprentice, with the wizard answering questions and making new statements. Topics of interest were selected from the Persona-Chat dataset, resulting in 1,431 topics mapped to relevant Wikipedia pages. During data collection, 2-3 related topic choices were presented as conversation starters per dialogue. Additional experiments included testing the performance of models trained for the full dialogue task. The study tested the performance of models trained for full dialogue tasks on the knowledge selection task. Results showed potential for improvement in the retrieval system, with auxiliary loss benefiting generative models. Analysis of dialogues from human evaluation experiments revealed common errors and behaviors in different experimental settings. The study analyzed human-human and bot conversations in a single-blind setup, noting common errors and behaviors. Human conversations involve more small talk, while bot conversations aim to produce factual sentences. Humans sometimes treat bots as question-answer machines. The study analyzed human-bot conversations, noting that humans treat bots as question-answer machines. The retriever without knowledge tends to go off-topic, while the one with knowledge sticks to the chosen topic but struggles if the subject changes. The study tested a two-stage retrieval system using the best model for knowledge selection in dialogue retrieval, outperforming the best retrieval method in F1 but not Recall@1. Comparing this to a system optimized for seeing the gold knowledge sentence, results suggest improving performance on the knowledge selection subtask. The study evaluated a two-stage retrieval system for knowledge selection in dialogue retrieval, showing improved performance in F1 score but not Recall@1 compared to the best retrieval method. The wizard and apprentice's Wiki F1 scores were calculated for comparison to human evaluations, with the wizard having direct access to Wikipedia passages, leading to higher values. The model sometimes provides factually inaccurate answers but also offers inviting responses. The generator without knowledge in dialogue systems often exhibits typical issues like repetition and inconsistencies in personality, while the generator with knowledge shows fewer problems with repetition by copying large fragments. The generator with knowledge in dialogue systems can sometimes provide inaccurate information, but overall it is able to generalize to new topics using knowledge from Wikipedia. It may respond without inviting a reply and often gives formulaic responses. Selected conversations with this generator can be seen in Figure 5."
}