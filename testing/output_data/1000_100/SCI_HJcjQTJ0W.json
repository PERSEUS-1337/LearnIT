{
    "title": "HJcjQTJ0W",
    "content": "To enable cloud-based DNN training while protecting data privacy, the proposed method leverages intermediate representations of data by splitting DNNs and deploying them on local platforms and the cloud. The local NN generates feature representations from pre-trained NNs, avoiding local training to protect data privacy. The cloud NN is then trained using these intermediate representations for the target learning task. The idea of DNN splitting is validated by analyzing the relationship between privacy loss and classification accuracy based on the local NN topology. The dependency of privacy loss and classification accuracy on the local NN topology for a CNN image classification task is explored. PrivyNet is proposed to optimize accuracy under privacy loss, computation, and storage constraints, demonstrated with the CIFAR-10 dataset. Cloud-based services offer an alternative for deep model training but raise privacy concerns. To protect user data privacy in cloud-based training, various data pre-processing schemes are proposed to generate transformed representations locally. These representations must meet utility and privacy requirements, ensuring accurate learning tasks without leaking private information. The transformation scheme should be adaptable to different platforms and data types. The trade-off between privacy and utility is a key consideration in related works. Privacy and utility trade-off is a key consideration in privacy research. Various methods like k-anonymity, l-diversity, and t-closeness are proposed for anonymizing data. Differential privacy offers a formal privacy guarantee by adding noise. However, applying syntactic anonymization to high-dimensional continuous data is challenging. Existing works in privacy research propose various methods for data anonymization, including differential privacy which adds noise to protect privacy. However, these methods may not fully prevent information leakage. Linear and nonlinear transformations are also used for data anonymization, with linear transformations relying on covariance or linear discriminant analysis. Nonlinear transformations like minimax filter have been recently proposed for enhanced privacy protection. The proposed PrivyNet framework aims to achieve a fine-grained control of the trade-off between privacy and utility in DNN training. It divides the model into local and cloud parts, with the local NN generating intermediate representations and the cloud NN trained for the learning task. This allows for better privacy protection in the inference stage, addressing the challenge of privacy loss control during interactive training between cloud and local platforms. PrivyNet is a framework that splits DNN into local and cloud parts for privacy protection. The local NN generates intermediate representations using non-linear transformations, derived from pre-trained NNs to preserve utility. This approach controls specific features released for privacy while maintaining useful features in the representations. PrivyNet is a novel framework that splits DNN models for cloud-based training with fine-grained privacy control. It characterizes privacy loss and utility using CNN as the local NN, identifying key factors for the privacy-utility trade-off. A hierarchical strategy optimizes the local NN's topology considering computation, storage, and privacy constraints. PrivyNet is validated using CNN-based image classification, demonstrating efficiency and effectiveness in leveraging pre-trained NNs for intermediate representation generation. The overall characterization flow involves generating feature representations using a pre-trained NN, training an image classification network (ICN) based on these features, and training an image reconstruction network (IRN) to reconstruct original images. Utility is measured by target learning task accuracy and privacy by the distance between reconstructed and original images. The IRN is trained assuming knowledge of original images and feature representations, but not the transformation (FEN). This aligns with the adversarial model described in later sections. The text discusses the transformation induced by the FEN on image representations, parameterized by the number of FEN layers and filters selected. It evaluates the utility by learning a classifier with minimized empirical risk for the target learning task. The text evaluates the utility and privacy of transformed image representations by learning a classifier with minimized empirical risk for the target learning task and measuring privacy loss through peak signal-to-noise ratio (PSNR) of reconstructed images. The impact of FEN topology on privacy and utility of transformed representations is characterized by factors like number of layers, output depth, and selected channels. Evaluation of these factors forms the basis for the PrivyNet framework, with changes made to FEN's topology to assess their effects. The impact of FEN topology on privacy and utility is evaluated by changing the number of FEN layers and output depth. ICN and IRN are trained based on the generated representations to assess utility and privacy. Privacy loss is observed with smaller PSNR of reconstructed images, while accuracy shows different behaviors with changes in FEN layers and output depth. The trade-off between accuracy and PSNR in the PrivyNet framework is shown in FIG2 (c). Two key observations are made: FEN with different topologies have similar utility when privacy loss is high, and FEN with more layers provide better utility when privacy loss is low. The selected subset of output channels also impacts privacy and utility. Comparisons are made on the utility and privacy loss for transformed representations induced by each single channel. The utility and privacy loss for representations generated by each channel in the FEN with 4 VGG16 layers are compared in Figure 4 (a) and Table 4 (c). When m = 4, the best channel achieves 4X higher utility than the worst channel, with a privacy loss difference of 6 dB. Similar discrepancies are observed with 6 VGG16 layers in Figure 4 (b). The impact of output channel selection is compared with the number of FEN layers and output depth. The privacy and utility of representations generated by the FEN with varying numbers of layers and output channel depths are evaluated. The pre-trained CNN can be used to control the trade-off between utility and privacy by adjusting the FEN topology. The number of FEN layers, output channel depth, and output channel selection all impact the privacy and accuracy trade-off. Larger FEN layers and output channel depths show greater influence on privacy and utility compared to output channel selection. In the next section, the framework PrivyNet is proposed to optimize utility under privacy constraints, local computation capability, and storage. The FEN topology, derived from a pre-trained NN, impacts privacy, utility, computation, and storage on local platforms, especially for lightweight devices like mobile phones. Constraints on local computation and storage must be considered in FEN design to optimize utility. Our PrivyNet framework optimizes utility under privacy constraints, local computation, and storage. Privacy characterization is done using cloud-based services and NNs are profiled on local platforms. Channel pruning based on private data is conducted to optimize the FEN topology. The assumption of original image availability is stronger than previous works. The assumption of original image availability is crucial for evaluating privacy loss in releasing feature representations. It is necessary to consider attackers injecting images to obtain corresponding representations. The unknown transformation by the FEN in our adversarial model is vital to prevent sophisticated image reconstruction by attackers. The FEN, derived from pre-trained NNs, may expose architecture and weights to attackers, making it challenging to limit privacy loss. The pre-characterization stage involves performance and storage profiling of pre-trained NNs on local platforms and cloud-based privacy characterization. This is crucial to protect the anonymity of the FEN and prevent sophisticated image reconstruction by attackers. The reconstruction network is trained on publicly available data of the same dimension. The network is trained on publicly available data of the same dimension and distribution. Privacy characterization is done for different datasets like CIFAR-10 and CIFAR-100, comparing PSNR for FEN with different topologies. Experiments show less than 1000 samples are needed for accurate characterization with data augmentation. Detailed PSNR values can be less accurate, reducing the training sample requirement. Determining the FEN topology is the next step. In PrivyNet, the FEN's topology is crucial for privacy and accuracy. Factors like FEN layers and output channel depth impact the generated representations. The strategy involves selecting deeper layers for higher privacy requirements, considering computation and storage constraints. The relation between privacy, local computation, and storage on a mobile CPU is shown in Figure 8. The FEN's topology in PrivyNet is essential for privacy and accuracy. The output depth is determined by privacy constraints, with a shallow FEN selected for low privacy requirements to minimize local computation and storage consumption. Different FEN layers and output depths can achieve the privacy requirement, with deeper layers chosen for higher privacy needs. After determining the FEN topology for privacy and accuracy in PrivyNet, selecting output channels directly from the whole set may result in large variances in utility and privacy. Channel pruning is necessary to avoid poor utility with privacy leakage. Additionally, the utility and privacy loss of a single channel are not correlated, as shown in Figure 10. In channel pruning for optimizing utility and suppressing privacy loss, negligible correlation was observed between privacy loss and utility for different output channel depths and FEN layers. Fisher's linear discriminability analysis is used to identify channels with the worst utility, while privacy loss for each channel is determined from offline pre-characterization. This approach helps in pruning channels with the largest privacy loss while optimizing utility. In Fisher's LDA scheme, the distance between representations of images within the same class should be small, while the distance among different classes should be large. LDA is effective in identifying ineffective channels by measuring distance using the covariance matrix. The analysis involves evaluating Fisher's criterion for each channel based on the average representations of each class. In Fisher's LDA scheme, the distance between representations of images within the same class should be small, while the distance among different classes should be large. Fisher's linear discriminability for the j-th output channel is computed using between-class and within-class variances. The maximum value is achieved when p is the eigenvector corresponding to the largest eigenvalue of SwSb. By evaluating Fisher's discriminability for each channel, ineffective channels can be identified and pruned for better accuracy in the learning task. The effectiveness of the LDA-based supervised channel pruning algorithm is verified through experiments using the first 6 VGG16 layers to prune 32 output channels with the worst utility. In the LDA-based supervised pruning method, 69.7% of the worst 32 channels can be pruned on average, resulting in a 33.5% reduction in the probability of selecting a bad channel randomly. Similar results are seen when pruning the 64 channels with the worst utility. The number of samples required for pruning remains consistent across different mini-batch numbers. The experimental results show that the computation complexity of the LDA-based pruning process scales with the number of samples. The effectiveness of supervised channel pruning is demonstrated by setting the layer of FEN to 6 and the output depth to 8. Three settings for comparing privacy and utility are considered: random selection, channel pruning based on privacy and utility characterization, and channel pruning based on privacy characterization and LDA. In the pruning process, 64 channels with the worst utility are pruned. After characterizing channels for utility and privacy loss, 64 channels with the worst utility and 32 with the largest privacy loss are pruned. Results in FIG2 show that pruning improves utility and reduces privacy leakage. LDA-based pruning achieves 1.1% better accuracy and 1.25 dB smaller PSNR compared to random selection without pruning. Detailed statistics are provided in Table 13. Our supervised pruning strategy, compared to characterization-based pruning, achieves similar accuracy (around 0.5%) with slightly less privacy loss (around 0.45 dB). The adversarial model in the paper assumes the transformation induced by the FEN is unknown to attackers, enhancing privacy protection. The FEN, derived from pre-trained NNs, prevents more powerful attacks. In our framework, we propose strategies to protect the anonymity of the FEN derived from pre-trained NNs. Two methods are considered: building a pool of pre-trained NNs and applying channel selection procedures to make it harder for attackers to guess the FEN structure. In the framework, strategies are proposed to protect FEN anonymity by applying channel selection procedures to pre-trained NNs. Empirical verification shows that reducing channel depth in convolution layers minimally impacts privacy and utility while significantly reducing runtime. PrivyNet is a flexible framework designed to protect FEN anonymity by using channel selection procedures on pre-trained NNs. It enables cloud-based training with fine-grained privacy protection, addressing resource constraints and policy limitations. One application is in hospitals for training models on patient data for disease diagnosis and treatment. PrivyNet provides a framework for hospitals to release informative features instead of original patient data, enabling easy sharing of data while protecting privacy. It can also be used on mobile platforms to collect and upload data to the cloud while maintaining privacy. Overall, PrivyNet is simple, platform-aware, and flexible for different end-users and situations. The CIFAR-10 dataset contains 60000 32 \u00d7 32 color images in 10 classes, while the CIFAR-100 dataset has images of objects in 100 classes. VGG16, pre-trained on ImageNet, is used for privacy and accuracy characterization. CNN is used for image classification (h) and image reconstruction (g). The architecture for image reconstruction (g) utilizes a generative NN based on ResNet blocks. Each ResNet block cluster consists of 8 blocks. Gradient descent optimizer is used for training with a learning rate of 0.003 and a mini-batch size of 128 for 100 epochs. For image classification (h), the initial learning rate is 0.05 with a mini-batch size of 128, dropping by a factor of 0.1 at 100 and 200 epochs, training for a total of 250 epochs. Data augmentation includes normalization. The image reconstruction process involves determining the IRN topology for accurate privacy evaluation. The number of ResNet block clusters impacts the image recovery capability, with 2 clusters of 8 blocks each chosen for experiments. The PSNR of reconstructed images saturates with more ResNet block clusters, as shown in Figure 19. Performance and storage characterization of pre-trained NNs on local platforms is shown in FIG1. The increase in VGG16 layers leads to higher computation and storage requirements, with convolution layers dominating computation and fully connected layers requiring significant storage. Different platforms may face varying bottlenecks, with fully connected layers taking up more storage as input image size increases. The complexity of the computation in the second part is determined by the number of samples N LDA and the dimension of the output representations W \u00d7 H. The complexity is O((K + N LDA)W 2 H 2 + W 3 H 3), with N LDA being a key factor in the extra computation induced by the learning process. The learning process is usually small N LDA sufficient for good pruning results, leading to a small overall computation overhead."
}