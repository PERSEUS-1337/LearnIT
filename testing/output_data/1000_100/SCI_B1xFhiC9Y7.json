{
    "title": "B1xFhiC9Y7",
    "content": "Predicting structured outputs like semantic segmentation requires expensive per-pixel annotations for training convolutional neural networks. To address the challenge of generalizing to new domains without annotations, a domain adaptation method is proposed. This method involves learning discriminative feature representations of patches based on label histograms in the source domain and using an adversarial learning scheme to align feature distributions between source and target patches. The framework also includes a global alignment process and achieves state-of-the-art performance on semantic segmentation. Recent deep learning-based methods have shown significant progress in vision tasks like object recognition and semantic segmentation. Domain adaptation methods have been developed to bridge the gap between annotated training data and unlabeled target domains. Various techniques have been proposed for image classification, but there is still ongoing research on domain adaptation for pixel-level prediction tasks such as semantic segmentation. Domain adaptation is crucial for pixel-level predictions like semantic segmentation due to the high cost of annotating ground truth. Existing methods use feature-level or output space adaptation to align distributions between source and target domains using adversarial learning. However, global distribution alignment may not be sufficient as differences in camera pose or field of view can lead to significant discrepancies. The text discusses the importance of domain adaptation for semantic segmentation and the limitations of global alignment. It proposes a patch-level alignment approach using adversarial learning to match shared patches across domains, considering label histograms as a factor for discriminative representations. The text proposes a patch-level alignment approach using adversarial learning to match shared patches across domains, considering label histograms for discriminative representations. The text proposes a patch-level alignment approach using K-means clustering and adversarial learning to transfer discriminative representations across domains for image segmentation tasks. The proposed framework combines global and patch-level alignments for pixel-level road-scene image segmentation. Experiments include synthetic-to-real and cross-city scenarios, showing favorable performance compared to state-of-the-art methods. The framework is general and could be applied to other structured outputs like depth. Key contributions include a domain adaptation framework utilizing global and patch-level adversarial learning modules, and a method for learning discriminative representations guided by label histograms of patches. The proposed adaptation method utilizes label histogram guided discriminative representations for patch-level alignment and outperforms baselines on semantic segmentation tasks. Domain adaptation methods for image classification and pixel-level prediction tasks are discussed, focusing on aligning feature distributions between source and target domains using hand-crafted or deep features. Deep architectures BID8 BID32 are used for domain-invariant feature learning, with adversarial learning and Maximum Mean Discrepancy BID20 minimization. Various classifiers BID21 and loss functions BID33 are designed for this purpose. Recent work also focuses on enhancing feature representations through pixel-level transfer BID1 and domain separation BID0. Domain adaptation for structured pixel-level predictions, particularly in semantic segmentation for road-scene images, is introduced by BID14. They propose using adversarial networks to align global feature representations across domains and transfer category-specific priors from the source domain to the target distribution as a constraint. The CDA method BID36 uses SVM classifier to capture label distributions on superpixels for training the adapted model on the target domain. Class-wise domain adversarial alignment with pseudo labels is performed, and object priors from Google Street View aid in alignment for static objects. These domain adaptation methods focus on global distribution alignment and class-specific priors to match statistics between domains, but do not preserve structured information like patches. The proposed approach aims to learn discriminative representations for patches to maintain structured information. Our framework focuses on learning discriminative representations for patches to aid in patch-level alignment without requiring additional priors/annotations. Unlike the CDA method, which uses SVM classifiers for label distributions on superpixels, our algorithm learns patch-level representations for alignment. Additionally, we aim to learn disentangled representations for tasks such as facial recognition and image generation. Our proposed framework aims to learn discriminative representations for patches to assist in domain adaptation tasks. Unlike previous methods that focus on single-domain data, our approach leverages label distributions as disentangled factors without the need for pre-defined factors. Our proposed domain adaptation framework aims to align distributions across domains by predicting structured outputs and using discriminative representations for patches. The goal is to align the predicted output distribution of target data with the source distribution through supervised learning and adversarial loss. Additionally, a classification loss is incorporated to learn patch-level discriminative representations from the source output distribution. Another adversarial loss is used for target data to align patch-level distributions. The proposed domain adaptation framework aims to align distributions by predicting structured outputs and using discriminative representations for patches. An adversarial loss is employed to align patch-level distributions between source and target data, pushing the target distribution closer to the source distribution. The adaptation task is formulated with supervised loss functions for structured prediction and discriminative representation on source data, along with clustering on ground truth labels. Global and patch-level adversarial loss functions are utilized to align the target distribution. The method involves a baseline model with supervised cross-entropy loss and global alignment using an adversarial loss. A fully-convolutional network predicts structured outputs, and an adversarial loss is used to align distributions between source and target data. The min-max problem is optimized for the generator and discriminator in GAN training. The proposed method involves patch-level domain alignment for learning discriminative patch representations shared across source and target images. Clustering is performed on patches from the source domain to construct prototypical patch representations. The proposed method involves patch-level domain alignment by using ground truth segmentation labels to construct prototypical patch patterns. Patches from the target domain adapt to this disentangled space of source patch representations through adversarial guidance, selecting the closest cluster regardless of spatial location. The approach aims to learn discriminative representations without the need for class labels, utilizing per-pixel annotations in the source domain for semantic clustering. The method utilizes per-pixel annotations in the source domain to create a semantically disentangled space of patch representations. It involves sampling patches, extracting spatial label histograms, clustering them with K-means, and incorporating this clustered space into the network training. The learned representation F s is used for discriminative representation learning. The method involves creating a clustered space of patch representations using per-pixel annotations in the source domain. The learning process includes aligning target patches to the clustered space through an adversarial loss between F s and F t. The goal is to align patches regardless of their spatial location, achieved by reshaping F into U \u00b7 V independent data points. The method involves reshaping data into U \u00b7 V independent data points to align patches regardless of spatial location. The adversarial objective involves a discriminator to classify feature representations from the source or target domain. The network optimization process includes updating discriminators and the network alternately in a min-max problem. The method involves updating the Discriminator D to minimize binary cross-entropy loss and classify feature representations from the source or target domain. The goal is to align the target distribution with the source distribution using optimized D, while maintaining performance on main tasks with Networks G and H. The minimization problem combines supervised and adversarial loss functions, enhancing feature representations in G during testing phase. The method involves updating the Discriminator D to align target distribution with source distribution using optimized D, while maintaining performance on main tasks with Networks G and H. Feature representations are enhanced in G during testing phase. Generator G consists of network G with categorization module H, following DeepLab-v2 with ResNet-101 architecture pre-trained on ImageNet as baseline. The proposed architecture involves adding module H to the output prediction O by using an adaptive average pooling layer to generate a spatial map. This map is then fed into convolution layers to produce a feature map F with channel number K. The framework is implemented using PyTorch toolbox on a single Titan X GPU. Training details include using Adam optimizer for discriminators and Stochastic Gradient Descent solver for the generator. The proposed framework for domain adaptation involves an ablation study on GTA5-to-Cityscapes using the ResNet-101 network. The learning rates are decreased using polynomial decay, and specific loss functions are utilized. Hyper-parameters such as \u03bb d, \u03bb g adv, \u03bb l adv, and K are set for all experiments. The model is initially trained with L s loss for 10K iterations before incorporating all loss functions for 100K iterations. The framework is evaluated for semantic segmentation, showing favorable performance in the synthetic-to-real scenario. The method performs well in domain adaptation for semantic segmentation, including synthetic-to-real and cross-city scenarios. It adapts datasets like GTA5 and SYNTHIA to Cityscapes and Oxford RobotCar, showing favorable results against state-of-the-art approaches. In domain adaptation for semantic segmentation, the rainy tag randomly splits images into training and testing sets. 895 images are used for training, and 271 images are annotated for testing. The evaluation metric is intersection-over-union (IoU). An ablation study on GTA5-to-Cityscapes scenario shows the impact of different loss functions and design choices in the proposed framework. Adding disentanglement without alignments improves performance, demonstrating enhanced feature representation discrimination. Our method combining global and patch-level alignments achieves the highest IoU at 43.2%. Experiments show the necessity of losses Ld and Lladv for effective patch-level alignment, resulting in a 1.9% and 1.5% performance loss if removed. Reshaping features as independent data points in the clustered space is crucial for the alignment process. Without reshaping features as independent data points, the performance drops 2.4% in IoU, highlighting the importance of aligning patches with similar representations regardless of their locations. Visualization of feature representations using t-SNE shows that with adaptation in the clustered space, the features are embedded into groups and source/target representations overlap well. The proposed method is compared with state-of-the-art algorithms under various scenarios, including synthetic-to-real and cross-city cases. In experimental results, the proposed method shows favorable performance in adapting GTA5 to Cityscapes using VGG-16 and ResNet-101 architectures. Improvements in IoU and visual comparisons are presented for adapting SYNTHIA to Cityscapes. The method is compared with state-of-the-art algorithms in various scenarios, including synthetic-to-real and cross-city cases. The paper presents a domain adaptation method for structured output using global and patch-level alignments. Results show improved segmentation details compared to existing methods, with a mean IoU of 63.6% achieved. Further comparisons and results are available in the appendix. The proposed method focuses on global and patch-level alignments for domain adaptation in semantic segmentation. By constructing a clustered space of source patches and using adversarial learning, the model pushes target patch distributions closer to source ones. Extensive experiments validate the effectiveness of the approach under various challenges, showing superior performance compared to existing algorithms. Training is done in an end-to-end manner with a batch size of 1, following a specific optimization strategy outlined in the paper. The model utilizes an entropy loss as a regularization method to improve target feature representation. This approach achieves an IoU of 41.9%, slightly lower than the patch-level adversarial alignment method. The model learns discriminative representations by pushing target patches closer to the source distribution. The proposed method learns discriminative representations for target patches by aligning them with the source distribution in a clustered space guided by label histogram. Results comparing adaptation methods for Cityscapes to Oxford RobotCar are presented in tables and figures, showing the effectiveness of patch-level alignment. Additional visual comparisons for different scenarios are provided in figures 9 to 11. The proposed method improves segmentation outputs by adapting target images using a clustered space alignment approach. Results demonstrate better segmentation quality with fewer noisy regions compared to other adaptation methods. Visual examples in figures 9 to 11 showcase the effectiveness of the proposed method in adapting segmentation for the GTA5-to-Cityscapes setting. The proposed method enhances segmentation results by adapting target images through clustered space alignment. Results show improved segmentation quality with fewer noisy regions compared to other adaptation techniques. Visual examples in Figure 11 illustrate the effectiveness of the proposed method in adapting segmentation for the SYNTHIA-to-Cityscapes setting."
}