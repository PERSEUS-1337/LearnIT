{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The generator architecture is structured based on a causal graph for conditional and interventional sampling of face images with binary feature labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. The optimal generator of CausalGAN samples from image distributions conditioned on labels. The proposed architectures can sample from observational and interventional image distributions, even for interventions not in the dataset. GANs are successful in training implicit generative models. The generator network in GANs models the sampling process through feedforward computation with a noise vector. It is refined by a discriminator network that distinguishes between generated and real samples. GANs have been successful in generating samples from various distributions like images and videos. Extensions include sampling from class conditional data distributions by feeding class labels to the generator. Various neural network architectures have been proposed for this task. In this paper, the architecture aims to sample from both joint and interventional distributions, capturing label dependence and causal effects in conditional image generation. The generator in GANs uses noise vectors to generate samples, refined by a discriminator network. The generator in GANs maps labels to images non-deterministically, following causal graphs. Causal models allow sampling from conditional and interventional distributions. Causal models enable sampling from conditional and interventional distributions by fixing variable values in a causal graph. Intervening on a variable affects its descendants but not its ancestors in the graph. Causal implicit generative models (CiGM) can sample from correct joint, conditional, and interventional probability distributions. The objective is not to learn the causal graph but to assume it is given. When the generator structure inherits neural connections from the causal graph, GANs can train causal implicit generative models. Using WGAN, a CiGM is trained for binary image labels in a two-step procedure. CausalGAN and CausalBEGAN are proposed for the second step. The optimal generator of CausalGAN can sample from true conditional distributions. Combining CausalGAN with a CiGM on labels yields a CiGM on labels and images. Adversarial training can be used to train a CiGM after structuring the generator architecture based on the causal graph. The text discusses training a CiGM for binary image labels using WGAN and a two-stage procedure. A novel conditional GAN architecture and loss function are proposed, along with a model called CausalBEGAN. The framework is evaluated on labeled data. The CiGM training framework is evaluated on labeled CelebA data, showing that CausalGAN and CausalBEGAN can produce label-consistent images even for interventions not seen during training. Previous works include conditional GAN (CGAN), ACGAN, and InfoGAN architectures for generating images based on labels. InfoGAN introduces a new architecture that maximizes mutual information between inputs and generated images. Existing GAN variations like BiGAN, ALI, CoGAN, and SD-GAN also explore different ways to learn mappings and distributions in the image space. SD-GAN, in particular, splits the latent space into \"Identity\" and \"Observation\" portions, allowing for the generation of faces with fixed identity codes. SD-GAN is an extension of BEGAN that accepts labels, including a one-hot vector for changing age attributes in face images. Generative models are also used in compressed sensing, with recent attention on causal principles in deep learning and deep learning techniques for causal inference. The authors in BID3 observe a connection between GAN layers and structural equation models, using CGAN to learn. In recent works, various approaches have been proposed to learn causal relationships using neural networks, such as causal regularization and using neural connections to mimic structural equations for learning causal graphs. These methods aim to discover causal relations between variables and ensure predictive models in a causal sense. In this section, a brief introduction to causality is provided using Pearl's framework BID11, which involves structural causal models (SCMs) represented by directed acyclic graphs. Within the SCM framework, X causing Y implies the existence of a function f and an unobserved random variable E, where Y = f(X, E). The causal graph is represented as X \u2192 Y, with parents of a node X_i denoting its causes. The causal graph is constructed from structural equations, with parents of a variable determined by the structural equation. A structural causal model includes functions, random variables, exogenous variables, and a probability distribution. The causal graph is a directed acyclic graph on observable variables, where a node is a parent if it is in the domain of the function. An intervention changes the underlying causal structure. An intervention changes the underlying causal mechanism and corresponding causal graph. It removes connections of a node to its parents, altering the post-interventional distribution in a Bayesian network. After an intervention on a set of nodes in a causal graph, the post-interventional distribution is determined by the assignment of nodes. Identifying the true causal graph without experiments or assumptions is challenging due to multiple causal graphs producing the same joint probability distribution. This paper focuses on learning a causal model given a causal graph, with prior work available for learning causal graphs. Bayesian networks can be used to sample from correct observational distributions when the true causal graph is unknown. Causal implicit generative models allow sampling from both observational and interventional distributions, with generative adversarial networks being used for training. In the GAN training framework, generator neural network connections reflect the causal graph structure. Feedforward neural networks represent functions f X , f Y , f Z with independent noise terms (N X , N Y , N Z ). Gaussian distributed variables can be used for exogenous variables. The feedforward neural network represents causal models with a graph. Two causal models with the same observational distribution have the same interventional distributions for any intervention. A feedforward neural network G is linked to a causal graph in the context of causal implicit generative models. The network outputs a vector based on a set of mutually independent random variables Z. The generator neural network is trained adversarially to align with the causal graph structure. The generator neural network is trained to align with the causal graph structure in causal implicit generative models. To address difficulties in learning joint label and image distribution, the training is divided into two subtasks: training a generative model for labels and then for images conditioned on the labels. This approach ensures consistency with the causal structure. The new architecture and loss function (CausalGAN) ensure that the generator outputs label-conditioned image distributions. The Causal Controller is used for controlling image sampling based on labels in a generative model. The Causal Controller network structures the CausalGAN to generate images based on labels using a WGAN model. The architecture ensures label-conditioned image distributions in a generative model. Designing a new conditional GAN architecture for image generation based on Causal Controller labels. Utilizing a pretrained Causal Controller, two separate labeler neural networks (Labeler and Anti-Labeler) are employed. The generator aims to produce realistic images, consistent with labels, and avoid easy labeling by maximizing the Anti-Labeler loss. This distinguishes CausalGAN from existing conditional GANs. CausalGAN utilizes an Anti-Labeler network in addition to a Labeler network to prevent label-conditioned mode collapse in image generation. The Anti-Labeler loss discourages the generator from outputting only typical faces for a fixed label combination, leading to faster convergence and better results. The results for a single binary label in CausalGAN can be extended to more labels. The generator loss function contains label loss terms and additional loss terms from the discriminator, leading to the optimal generator outputting the class conditional image distribution. This result holds true for multiple binary labels as well. The CausalGAN architecture guarantees that the generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. This result holds for both single and multiple binary labels. The generative adversarial network architecture ensures the generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. This is achieved by finding the optimal discriminator for a fixed generator, with the generator minimizing the generator loss to achieve the global minimum of the virtual training criterion. The two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. Corollary 1 states that a causal implicit generative model can be trained for a causal graph with image labels and positive observational joint distribution. The generator can sample from the image distribution based on given label combinations. The objective is to extend this to cases with multiple binary labels by training the Labeler and Anti-Labeler to output posterior probabilities. The proposed alternative architecture extends the single binary label setup by using cross entropy loss terms for each label, requiring Labeler and Anti-Labeler to have only d outputs. This ensures that the generator captures each label's posterior distribution, but does not guarantee that the class conditional distributions will be true to the data distribution. The proposed alternative architecture extends the single binary label setup by using cross entropy loss terms for each label, ensuring the generator captures each label's posterior distribution. Trained causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms. In this section, a simple extension of BEGAN involves feeding image labels to the generator using a Labeler network for interventional sampling. The network is designed to label real images well and generated images poorly, similar to the CausalGAN Labeler and Anti-Labeler. Margin modifications are motivated by the need for better trained Labeler to provide meaningful gradients for label quality. The text discusses training CausalGAN and CausalBEGAN on the CelebA Causal Graph, focusing on label gradients and image quality. The dataset used satisfies certain conditions, with observations on male and mustache labels. The top row shows both genders with mustaches, while the bottom row only shows male images. The text discusses a novel generative model with label inputs that can sample from interventional distributions. It provides provable guarantees about correct sampling under interventions, such as intervening on Narrow Eyes=1 and conditioning on Narrow Eyes=1 in the CelebA Causal Graph. The text discusses the impact of intervening on Narrow Eyes=1 in the CelebA Causal Graph with CausalBEGAN. Conditioning on Narrow Eyes=1 increases the proportion of smiling images, showcasing the creativity of generative models like CausalGAN and CausalBEGAN. The research has been supported by various grants and organizations. A structural causal model consists of functions, random variables, exogenous variables, and a probability distribution. The causal graph is a directed acyclic graph based on the relationships between variables. The text discusses causal Bayesian networks and interventional distributions. It mentions the assumption of causal sufficiency and how interventional distributions can be calculated from conditional probabilities and the causal graph. The joint data distribution and joint distribution for binary labels and images are also discussed. The text discusses the optimal discriminator, Labeler, and Anti-Labeler in the context of causal Bayesian networks. It includes Proposition 2 from Goodfellow et al. (2014) and Lemmas 1 and 2 regarding the optimal Labeler and Anti-Labeler. The proof for Lemma 1 is outlined, and causal sufficiency is assumed in the definitions provided. The text discusses causal sufficiency in Pearl's model, where exogenous variables are mutually independent. It introduces the complete graph \"cG1\" and its reverse, rcG1. Theorem 1 defines the generator loss C(G) and states that the global minimum is achieved when the generator output matches the class conditional image distribution. The text discusses the optimization of Labeler D, Anti-Labeler D, and discriminator D in relation to the generator objective. It introduces a causal implicit generative model for a causal graph and a generator that can sample from the image distribution conditioned on labels. The text introduces a causal implicit generative model consistent with a causal graph D, where the concatenated generator neural network is aligned with D. If C and G are perfect, the model can sample from true observational and interventional distributions, making it a causal implicit generative model for graph D. The text discusses extending the proof to cases with multiple binary labels. The challenge lies in characterizing the joint distribution when each labeler can only learn about individual label posteriors. Two solutions are presented: (1) estimating probabilities of label combinations and (2) using labelers to estimate probabilities of individual labels, ensuring alignment between generator and true distribution. In this section, an extension of the proof is presented for cases with multiple binary labels. The Lemma states that the optimum Labeler minimizes loss by considering only label combinations with positive probability. The Labeler loss function is defined in terms of discrete random variables. The optimum Labeler network gives the posterior probability of a label combination based on the observed image. The constraint that coordinates sum to 1 can be satisfied using a softmax function. The Anti-Labeler network solves an optimization problem to determine the probability of generating an image given a label. The optimum Anti-Labeler determines the probability of generating an image given a label. The generator solves an optimization problem to sample from class conditional image distributions. The global minimum of the virtual training criterion is achieved when the discriminator, Labeler, and Anti-Labeler are at their optimum. The generator objective is minimized when the joint label and image distributions are equal. Relabeling binary labels to a larger label set may be challenging in practice. In this section, theoretical guarantees for the implemented CausalGAN architecture with d labels are provided under the assumption of deterministic relationships between images and labels. The global optimal generator samples from class conditional distributions based on this assumption. The optimization problems for the Anti-Labeler and generator are outlined, along with the conditions for achieving the global minimum of the virtual training criterion. The generator in the CausalGAN architecture aims to achieve the global minimum of the virtual training criterion by ensuring that the generated distribution matches the real distribution for all labels. This is done by introducing an assumption that the image determines all labels, leading to correct conditional sampling. The assumption that the image determines all labels is crucial in practice, as seen in the CelebA dataset. This allows for correct conditional sampling, where the joint probability distribution can be expressed as the product of marginal probabilities. The joint probability distribution is shown to be zero everywhere except at specific elements. By contradiction, it is proven that the distribution is 1 at these elements. Applying this lemma to the conditional distribution, it is shown that the image distributions and marginals are true to the data distribution. In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from class conditional image distributions, as shown by the joint probability distribution satisfying specific conditions. This extends the control theory-inspired boundary equilibrium approach of BEGAN. The proposed extension of BEGAN incorporates image labels into the generator training process. This new approach introduces a loss function and margins that prioritize label gradients when image quality is high. The proposed extension of BEGAN incorporates image labels into the generator training process by introducing a loss function and margins that prioritize label gradients for high-quality images. This approach includes a margin-coefficient tuple to improve the training of the Labeler network and generator. However, there is a challenge in maintaining image quality as the Labeler network may prioritize noisy or misshapen images, impacting the overall image quality. The extension of BEGAN incorporates image labels by introducing a margin-coefficient tuple to prioritize label gradients for high-quality images. This approach aims to improve the training of the Labeler network and generator while maintaining image quality. The extension also includes a monotonically decreasing scalar to track convergence during optimization. In this study, causal implicit generative models are analyzed for convergence on synthetic data from different causal graphs. The models are tested on three causal graphs: \"line\", \"collider\", and \"complete\". Results from 20 runs for each model are averaged and compared in terms of total variation distance. The study includes generators with varying knowledge of the causal structure. The study analyzes causal implicit generative models for convergence on synthetic data from different causal graphs: \"line\", \"collider\", and \"complete\". Results show the convergence behavior of the generator distribution based on each causal graph. The complete graph is expected to work well with all data generation models. The study explores the convergence behavior of different causal graphs in causal implicit generative models. Results show that the complete graph is expected to work well with all data generation models. In practice, fully connected networks with 3 layers perform well, while those with 5 and 10 layers perform much worse during adversarial training. Using the wrong Bayesian network, such as the collider graph, leads to worse performance in causal implicit generative models. Surprisingly, a fully connected generator with 3 and 5 layers shows the best performance for the collider graph. The number of layers is crucial, with 10 layers resulting in the worst convergence behavior. Complete and collider graphs perform similarly well, while the line graph performs the worst. Fully connected 3 layers perform the best for the complete graph, followed by fully connected 5 and 10 layers. Line and collider graphs show poor performance and lack convergence behavior. Using the wrong causal graph in causal implicit generative models leads to significant differences in the generated distribution. The correct graph produces the closest scatter plot to the original data, while the wrong Bayesian network results in a very different distribution. Adding the edge Young \u2192 Male improves the learned distribution significantly. The graphs also highlight that women do not have mustaches. The CelebA dataset experiments involve using a causal graph to analyze image labels. The CelebA Causal Graph (G1) is illustrated in FIG6, with cG1 being the completed version. The incorrect Bayesian network for the data leads to differences in the learned distribution, but a reasonable approximation is still achieved for {Male, Young} jointly. The CelebA dataset experiments involve using a causal graph to analyze image labels. Despite inaccuracies in the learned distribution, both graphs G1 and cG1 lead to Causal Controllers that never output the label combination {Female, Mustache}. Wasserstein GAN ensures convergence in distribution of the Causal Controller output to the discretely supported distribution of labels. A modified version of Wasserstein GAN with a penalized gradient is used to demonstrate good convergence for both graphs. The CelebA dataset experiments involve using a causal graph to analyze image labels. The Wasserstein Causal Controller is tested on a subset of binary labels, allowing the generator to learn a mapping from continuous noise to a discrete distribution. The CelebA dataset experiments involve using a causal graph to analyze image labels. The Wasserstein Causal Controller is tested on a subset of binary labels to learn a mapping from continuous noise to a discrete distribution. The proposed Causal Controller outputs an almost discrete distribution, with 96% of samples appearing near 0 or 1. Total variational distance (TVD) shows convergence with training for different causal graphs, indicating that any complete causal graph can lead to a nearly perfect implicit causal generator over labels. In this section, additional CausalGAN results are presented, showing interventions and conditioning on specific labels in the CelebA dataset causal graph. The results demonstrate the impact of interventions and conditioning on labels like \"Wearing Lipstick\" and \"Narrow Eyes\" in generating images. In this section, interventions and conditioning on \"Narrow Eyes\" in the CelebA dataset causal graph are explored. Intervening/conditioning on Narrow Eyes label in CelebA Causal Graph shows an increase in the proportion of smiling images. CausalBEGAN is trained on CelebA dataset using CelebA Causal Graph, with the Causal Controller pretrained with a Wasserstein loss. The need for the margin of margins introduced in the model is empirically justified. The image quality for rare labels deteriorates when setting c 3 = 1. Intervening vs Conditioning on Bald and Mouth Slightly Open labels in CelebA Causal Graph is illustrated. The top row shows both bald males and females, while the bottom row shows only male images due to the conditional distribution. In this section, additional simulations for CausalGAN and CausalBEGAN are provided. CausalGAN's conditional image generation properties are shown in Figures 16a-16d, while Figure 17 displays 256 randomly sampled images to examine mode collapse and image diversity. CausalBEGAN's simulation results demonstrate the importance of the third margin term b3 on image quality. The importance of the third margin term b3 on image quality is highlighted in the simulation results for CausalBEGAN. The architecture learns a discrete function with respect to its label input parameters, as shown in FIG9. The generator in CausalBEGAN exhibits label interpolation initially, which later becomes more step function-like during optimization. In this section, the results of training an implicit causal generative model for labels and images are presented. The approach treats the image as part of the causal graph, with attempts made to jointly train them. Implementation details for CausalGAN and CausalBEGAN are explained, along with observations on image generation and discriminator behavior. The implementation details of the Wasserstein Causal Controller for generating face labels are explained. The total variation distance is used as a metric to evaluate the success of the models. The generator architecture is based on a causal graph, using uniform noise as exogenous variables and neural networks for mapping parents to children. Training involves 25 Wasserstein discriminator updates per generator update. In practice, we use stochastic gradient descent to train our Causal GAN model, which is an extension of DCGAN. We make 6 generator updates for each discriminator update on average and update the discriminator and labeler networks concurrently. The loss terms are modified to accommodate a d-dimensional label vector, and the Labeler and Anti-Labeler loss terms are extended by averaging the loss terms for every label. The approach in training the Causal GAN model involves modifying loss terms to accommodate a d-dimensional label vector. The architecture differs from previous methods, but for labeled image datasets, it provides sufficient guarantees. Swapping the order of terms in cross entropy expressions for labeler losses has resulted in sharper images. The labels input to CausalBEGAN are taken from the Causal Controller, with minimal parameter tuning. The learning rate is set at 0.00008 for both the generator and discriminator, with \u03b3 values at 0.5. Customized margin learning rates are used to reflect the generator's response speed. The model achieves good performance without extensive hyperparameter tweaking. The best performing models in the parameter space have all three margins \"active\". Comparing CausalGAN behavior with and without Anti-Labeler network shows that using Anti-Labeler allows for faster convergence and provides more diverse images for very rare labels."
}