{
    "title": "rygZJ2RcF7",
    "content": "Neural networks struggle to generalize transformations outside of their training data. A new technique called neuron editing aims to address this issue by learning how neurons encode edits for specific transformations in a latent space. This approach uses an autoencoder to decompose dataset variations into neuron activations and generate transformed data by defining editing transformations on those neurons. The technique of neuron editing aims to generate transformed data by defining editing transformations on neurons in a latent space. This allows for complex transformations to be encoded with simpler distribution shifts in neuron activations. The technique is showcased in image domain/style transfer and biological applications such as removing batch artifacts and modeling drug treatment effects. Experiments in biology often study the effects of treatments on samples, like cells and drugs, with the assumption that effects generalize context-independently. Neural networks offer a powerful tool for learning a general edit function corresponding to treatment in a biological setting. While they can learn complex ways of transforming data distributions, they often overfit to the training dataset. By reframing the problem as learning a general edit function rather than generating post-treatment data distributions from pre-treatment data, we aim to address this limitation. Neural networks can learn an edit function for transforming data distributions in a biological setting. This approach, called neuron editing, involves training an autoencoder on the entire dataset to extract differences between pre-and post-treatment data distributions. The edit function is learned in the latent space of the autoencoder neural network with non-linear activations. Neuron editing involves applying pre-and post-treatment activation distributions to generate post-treatment data in the latent space of an autoencoder neural network. This technique allows for complex distribution-to-distribution transformations in high-dimensional space, leveraging the autoencoder's advantages. Research has shown that working in a lower-dimensional manifold with autoencoders can simplify complex effects into computationally efficient shifts in distribution. Editing neural network internal layers allows for modeling context dependence, with some neurons showing drastic changes post-treatment while others encoding background context information remain less affected. Neuron editing in a low-dimensional internal layer allows for editing on a denoised version of the data, avoiding noise and focusing on significant dimensions. The assumption is that internal neurons have semantic consistency across the data, encoding the same types of features for every data manifold. Neuron editing in a low-dimensional internal layer allows for editing on a denoised version of the data, focusing on significant dimensions. The autoencoder learns a joint manifold of all given data, including pre-and post-treatment samples. Neural networks prefer learning patterns over memorizing inputs. Neuron editing extrapolates better than generative models, producing more complex variation by preserving existing data variation. Comparisons show neuron editing predictions are more accurate than generation-based methods. Neuron editing is compared to generation-based approaches like traditional GANs and CycleGAN. While GANs struggle with generating plausible points, neuron editing excels in extrapolation. The method is detailed, and its effectiveness is demonstrated in natural image domain transfer and biological applications. The CelebA dataset is used for biological applications involving extrapolation, such as correcting batch effects and predicting combinatorial drug effects. GANs learn transformations with specific properties, but may not behave consistently on different sets. Instead of learning such a transformation, a new approach is defined. The approach defines a transformation on a learned space using an encoder/decoder pair to map data into an abstract neuron space. A piecewise linear transformation called NeuronEdit is applied to distributions of activations from different inputs, S and T, without further training. The NeuronEdit function operates on distributions of activations from different inputs, transforming them based on the difference between source and target distributions. It exhibits properties of a GAN generator and guarantees the same editing result for a given source distribution. The NeuronEdit function guarantees consistent editing results between source and extrapolation distributions by applying learned transformations without further training. This turns an autoencoder into a generative model that does not strictly adhere to the identity function. Training a GAN in this setting could exclusively utilize the data in S and T, while neuron editing can model the intrinsic variation in X unsupervised. GANs are difficult to train due to oscillating dynamics, uninterpretable losses, and mode collapse where the discriminator fails to detect differences in variability between real and fake examples. Neuron editing avoids the struggles of GANs in detecting differences in real and fake distributions, focusing on learning an unsupervised model of data space with an autoencoder. It isolates the variation in neuron activations to generate convincing entire distributions of post-transformation output. Neuron editing is compared to various generating methods like a regularized autoencoder, a standard GAN, a ResnetGAN, and a CycleGAN. Neuron editing transforms an entire distribution into another distribution, extending word2vec's vector arithmetic. The regularization penalized differences in distributions of source and target using maximal mean discrepancy. The image experiment utilized convolutional layers with specific filters and fully connected layers for other models. Training involved minibatches, the adam optimizer, and a learning rate. A motivational experiment on the CelebA dataset explored transforming images of people with different hair colors. The GAN models struggle to successfully transform images with different hair colors, especially when applied to out-of-sample data. They often generate artifacts and have difficulty recreating the input accurately, particularly in changing hair color. This highlights the limitations of training these models and their inability to generalize beyond the training data. Neuron editing provides a solution to the limitations of GAN models in transforming images with different hair colors. It demonstrates the ability to transform distributions for batch correction by addressing technical artifacts in the data measurement process. Batch effects are a common issue in biological experimental data, causing variations in measurements that can lead to incorrect conclusions. One method to address this is by repeatedly measuring a control set of cells with each sample and correcting based on the control's variation. This approach helps remove measurement-induced variations, allowing for more accurate comparisons between samples. The dataset investigated in this section involves mass cytometry BID5 experiment measuring protein levels in cells from two individuals infected with dengue virus. Control1, Control2, Sample1, and Sample2 have different numbers of observations. Technical artifacts and biological differences create variation between the two samples. The dataset involves mass cytometry BID5 experiment measuring protein levels in cells from individuals infected with dengue virus. Control1, Control2, Sample1, and Sample2 show variation due to technical artifacts and biological differences. The GANs fail to capture true biological variation, mapping cells to similar values and losing important information, such as high CCR6 levels in Sample1. ResnetGAN does not address this issue. The ResnetGAN fails to address the issue of capturing true biological variation in the dataset involving mass cytometry BID5 experiment. Neuron editing, on the other hand, successfully removes batch effects while preserving real variation. Neuron editing successfully preserves real variation and removes batch effects in mass cytometry BID5 experiment. Global assessments confirm accurate transformations across all dimensions. The study provides additional corroboration that neuron editing corrects batch effects while preserving true biological variation in a combinatorial drug experiment on cells from patients with acute lymphoblastic leukemia. The results show that GANs attempt to remove all sources of variation partially, while the autoencoder does not move the data at all. The study demonstrates that neuron editing effectively corrects batch effects in a combinatorial drug experiment on cells from patients with acute lymphoblastic leukemia. The experiment involves four treatments and measurements from mass cytometry on 41 dimensions. The effects of applying Dasatinib (Das) include a decrease in p4EBP1 without affecting pSTATS. Neuron editing accurately models this change without introducing additional variation. The study shows that GAN models struggle to accurately predict variations in datasets, even with residual connections. Despite attempts to mimic target data, GANs fail to replicate two-dimensional slices effectively. Neuron editing better predicts transformation globally by comparing real and predicted means and variances across all dimensions. GANs struggle to replicate data variance accurately, especially in clinical trial settings. Neuron editing is a novel approach that utilizes autoencoder latent layers to apply treatment effects to the entire dataset. By editing neurons in internal layers, more realistic transformations of data are achieved, leading to successful prediction of synergistic drug effects in biological data. This method can learn complex data transformations in a non-linear reduced space. Learning edits in a hidden layer allows for interactions between the edit and other context information from the dataset during decoding, making it feasible to learn complex data transformations in a non-linear reduced space. Future work could involve training parallel encoders with the same decoder or training to generate conditionally."
}