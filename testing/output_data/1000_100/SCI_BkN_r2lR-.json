{
    "title": "BkN_r2lR-",
    "content": "Identifying analogies across domains is a key task for artificial intelligence. Recent advances in cross domain image mapping focus on translating images, but visual fidelity often falls short. This paper introduces AN-GAN, a matching-by-synthesis approach that outperforms current techniques in finding exact analogies between datasets. The cross-domain mapping task involves domain alignment and learning the mapping function, which can be iteratively solved to improve unsupervised translation quality. Analogies between different domains are crucial for Artificial Intelligence, allowing for the use of prior knowledge to identify similarities. While most AI success has been in supervised problems, analogy identification presents a challenge as no explicit examples are given in advance. Recent approaches focus on unsupervised mapping between domains using sets of images without explicit correspondences. Recent approaches in Artificial Intelligence focus on unsupervised mapping between different domains using sets of images without explicit correspondences. The methods aim to learn a mapping function that can translate images from one domain to another by ensuring that the distributions of mapped images are indistinguishable from the target domain and that the cycle constraint is satisfied. However, while these constraints are effective for training the mapping function, the translated images may not always have high enough visual fidelity for exact matching. In this work, the focus is on improving visual analogy identification by adding exemplar-based constraints. The method is effective even when only some sample images have exact analogies. It can find correspondences between sets without exact matches, yielding better visual quality than mapping functions. The approach allows for domain alignment, enabling better performance in visual analogy identification. This paper introduces a two-step approach for training a domain mapping function that is more accurate than previous unsupervised methods. It focuses on identifying analogies between datasets without supervision, related to image matching methods and unsupervised style-transfer. Image matching is a long-standing computer vision task with various approaches proposed, including supervised deep neural networks and generic visual feature matching. However, in unsupervised scenarios, standard visual features may not achieve good analogies between domains. Generative Adversarial Networks (GAN) technology has shown breakthroughs in image synthesis, particularly in generating random images within a given set. Image to image translation work often utilizes GANs to create realistic images by training a generator network to synthesize samples from a target distribution. The generative architecture used is based on BID12, focusing on mapping input images rather than random noise. Unsupervised mapping for image translation has been recently explored, with a focus on generating mapped versions of images without supervision apart from sample images from the two domains. Supervised mapping methods focus on generating a mapped version of the sample in a new domain by training with matching pairs of input and output images. The discriminator in GANs receives pairs of images to strengthen the link between source and target images. Successful completion of the algorithm generates correspondences between domains, allowing for the use of supervised mapping methods on the inferred matches. BID2 improved mapping results in supervised settings without using GANs. The method for analogy identification involves finding matching indexes between two sets of images in different domains A and B. An iterative approach is used to map images from the source domain to the target domain and search for matches. A mapping function T AB is trained to transform images from domain A to appear as if they came from domain B. The distributional alignment is enforced by training a discriminator D to distinguish between the transformed images and real images from domain B. Additional constraints, such as circularity, have been added to improve results. The popular cycle approach in GANs enforces circularity and distance invariance constraints. It involves training one-sided GANs in both A \u2192 B and B \u2192 A directions, ensuring that an image translated from A to B and back to A recovers the original image. The two-sided cycle loss function is used to provide mapping functions between domains A and B, but it does not guarantee exact correspondences between images. A distributional approach is described for mapping images from domain A to appear as if they came from domain B. In this section, a method is provided for exact matches between domains A and B. The task is to find the set of indices that match A domain image x to B domain image y. A fully supervised mapping function T AB can be trained once exact matching is recovered. The proposed match matrix \u03b1 i,j between B domain image y and A domain image x is defined, aiming for a binary matrix with 1 for proposed matches and 0 for the rest. The task involves a \"perceptual loss\" L p based on predefined image representations. The optimization process involves a relaxed binary constraint on \u03b1, with an entropy constraint to encourage sparse solutions. The final objective includes enforcing positivity and sum constraints using an auxiliary variable. The relaxed formulation can be optimized using SGD, with the entropy term significance affecting convergence to the original correspondence problem. AN-GAN is a cross domain matching method that utilizes exemplar and distribution based constraints. The training scheme involves updating T AB for N epochs and then updating \u03b2 for N epochs, achieving good results with a full mapping performed only once at the beginning of the \u03b1 iteration. The AN-GAN loss function includes distributional loss and cycle loss constraints. The AN-GAN optimization problem involves cycle loss, exemplar loss, and adversarial training of discriminators D A and D B. The training process includes a burn-in period, optimization of losses for specific iterations, and decay of learning rate for exemplar loss. The exemplar loss rate is decayed after 20 epochs by a factor of 2. Shared \u03b2 parameters inform each other for likelihood of matches. Euclidean or L1 loss functions were not perceptual enough, but Laplacian pyramid loss and perceptual loss function provided improvement. Our loss function utilizes VGG features extracted from images, with varying numbers of feature maps based on resolution. L1 loss on pixels is also used for color consideration. The perceptual loss function compares feature maps of images I1 and I2, ensuring unsupervised matching. This method is evaluated through matching experiments. To evaluate our approach, matching experiments were conducted on public datasets. Various scenarios were evaluated, including exact matches. Our method was compared against other methods such as finding nearest neighbors using L1 loss on raw pixels or VGG feature loss. CycleGAN was also used for cross-domain matching. The authors used CycleGAN and VGG loss to compute nearest neighbors in the target set. They trained AN-GAN with different iterations and evaluated their method on public datasets including Facades, Maps, and Zappos50K dataset. Edge images were detected using HED. The authors used CycleGAN and VGG loss to compute nearest neighbors in the target set, training AN-GAN with different iterations and evaluating on public datasets. Edge images were detected using HED. The original dataset contains around 137k images of Amazon handbags. The datasets were down-sampled to 2k images each for memory complexity. The method was compared with five others on exact correspondence identification, with shuffled A and B images for training. Results showed successful matching between domains. The authors used CycleGAN and VGG loss to improve matching performance between different domains. They found that perceptual features outperformed pixel matching, with VGG features used as perceptual features. Exhaustive search was deemed too computationally expensive, requiring subsampling of features. Overall, there is room for improvement in CycleGAN performance for matching tasks. The method of using perceptual features outperformed pixel matching in improving matching performance between different domains. By running iterations on mapped source domain images and target images, linear combinations of mapped images were matched instead of a single image. This approach, less sensitive to outliers, utilized the same parameters for both sides of the match to enhance identification. The addition of distributional auxiliary loss aided in optimization, allowing the exemplar loss to converge successfully. The distribution and cycle auxiliary losses were crucial for successful analogy finding. Our full-method AN-GAN utilizes the full exemplar-based loss to optimize the mapping function for better performance in finding analogies. In experiments with a percentage of unavailable matches, the task is to identify correct matches for samples without matches in the other domain. The evaluation metric is the percentage of images with exact matches found. Our method AN-GAN achieves high match rates even when a large percentage of samples do not have matches, showing its ability to handle scenarios with missing matches. The quality of the mapping function is not significantly affected, with results comparable to the clean case even when 25% of samples do not have exact matches. Notably, for the Facades dataset, AN-GAN achieved a 90% match rate with up to 75% of samples not having matches. In an experiment evaluating the method on scenarios without exact matches, the DiscoGAN architecture was used for mapping in the Shoes2Handbags scenario. Results showed varying quality of matches, with some examples showing poor matches even with iterations. DiscoGAN + \u03b1 iterations and AN \u2212 GAN also presented challenges in achieving accurate matches. Our method, AN \u2212 GAN, improves the relevance of matches for better analogies. We propose a two-step approach for aligning datasets: (i) Find analogies using AN \u2212 GAN, and (ii) Train a mapping function using self-supervision. Achieving 97% alignment accuracy on the Facades dataset, we trained a fully self-supervised mapping function using Pix2Pix. The supervised mapping outperformed unsupervised mapping in accuracy. Our method, AN \u2212 GAN, improves analogies relevance for better matches. It aligns datasets by finding analogies with AN \u2212 GAN and training a mapping function using self-supervision. The supervised mapping is more accurate than unsupervised mapping, making the unsupervised problem effectively supervised. Our self-supervised method performs similarly to fully supervised methods and outperforms CycleGAN. The use of L1 loss in the Pix2Pix architecture works better for tasks like edges2shoes and edges2handbags datasets. The use of an appropriate loss and larger architecture enabled by ANGAN-supervision improves performance over CycleGAN and is competitive with full-supervision. The method was also evaluated on point cloud matching, showing success in achieving alignment for various ranges of rotation angles using the Bunny benchmark. The architecture used for the method includes a fully connected network with 2 hidden layers and BatchNorm. The mapping function is a linear affine matrix for rotation. Results show significant improvement over baseline at large angles, outperforming previous methods. Our method for cross domain matching with exemplar constraint significantly outperformed baseline methods, even in cases where exact matches are not available. The approach aligns domains and trains a fully supervised model, showing effectiveness for both large and low dimensional transformations. To achieve full operation end-to-end, aligning domains and training a fully supervised mapping function is possible. Future work should explore matching different modalities like images, speech, and text, as current distribution matching algorithms are inadequate for this task. New algorithms need to be developed to address this challenge."
}