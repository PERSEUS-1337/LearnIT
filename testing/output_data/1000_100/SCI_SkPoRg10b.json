{
    "title": "SkPoRg10b",
    "content": "We present an approach to understand the generalization properties of deep neural networks by revisiting ideas from statistical mechanics. A Very Simple Deep Learning (VSDL) model with two control parameters is introduced to explain the network's behavior. This model provides insights into the inability of deep neural networks to avoid overfitting training data. Empirical results show deep neural networks struggle with overfitting, discontinuous learning, and sharp transitions in generalization properties. Neural networks, including deep neural networks in deep learning, exhibit complex properties leading to varied conclusions about their behavior. Some studies suggest robustness to noise, while others highlight sensitivity even to small amounts. The PAC theory and VC theory do not accurately describe NN learning properties, leading to conflicting views on optimization problems and convergence to minima. Recent attention has been drawn to overtraining in state-of-the-art DNNs with noisy data, highlighting the complexities and challenges in understanding neural networks. State-of-the-art DNNs easily overtrain with noisy data, despite attempts at regularization methods not being effective in preventing this issue. State-of-the-art DNNs easily overtrain with noisy data, despite regularization methods not being effective. The only control parameter with a substantial regularization effect is early stopping, which is peculiar compared to SVMs. SVMs show bounded generalization accuracy when trained with a good dataset, unlike DNNs. Tuning regularization parameters in DNNs may not always prevent overtraining, leading to unexpected training accuracy results. The text discusses how deep neural networks (DNNs) behave differently from traditional models, leading to a need to rethink generalization. The authors suggest revisiting old ideas from statistical mechanics to understand DNN generalization better. They propose using statistical mechanics theory to explain empirical properties that PAC/VC theory struggles to clarify. The SM approach in ML can be formulated rigorously or non-rigorously, providing precise quantitative agreement with empirical results for models like DNNs. It offers a theory of generalization that naturally explains complex learning behaviors and phenomena like phases and transitions. Relevant parameters include load-like and temperature-like factors. The SM approach in ML explains generalization in DNNs with load-like and temperature-like parameters. These parameters control the learning process and are analogous to those in the traditional SM approach. The SM approach in machine learning explains generalization in deep neural networks using load-like and temperature-like parameters. These parameters control the learning process and are analogous to those in the traditional SM approach. The generalization error behavior is illustrated in a one-dimensional phase diagram, showing a critical value where properties change dramatically. The generalization properties of deep neural networks change dramatically with different values of \u03b1 and \u03c4 parameters. A two-dimensional phase diagram illustrates sharp transitions between phases, where adding noise and adjusting parameters can affect generalization behavior. Starting from a point with good generalization, noise can decrease \u03b1, but adjusting the number of iterations can improve generalization again. Starting from point A, adding noise decreases \u03b1, leading to point B with poor generalization. Adjusting the number of iterations can modify the \u03c4 parameter to obtain point C. The VSDL model and its consequences are discussed in more detail in Sections 3.1 and 3.2. The paper does not focus on technical complexities but instead on basic ideas and qualitative results. The text discusses the complexity of realistic DNN systems and the various control parameters that can affect generalization. It emphasizes the importance of considering the details of the model, learning algorithm, data properties, and noise when analyzing generalization in machine learning processes. In Section 2, the text reviews relevant background information, while Section 3 presents the main contributions connecting DNN control parameters with load-like, temperature-like parameters, and generalization behavior in a VSDL model. Section A provides a detailed discussion of the main result, and Section 4 offers a brief conclusion. The historical background discusses the equivalence between NNs with symmetric connections and the equilibrium behavior of magnetic systems like spin glasses in the Hopfield model. The SM approach and PAC/VC theory were popular in the 80s/90s for controlling generalization properties of NNs. However, the ML community shifted towards methods like SVMs, ignoring the SM approach. Recent theoretical work in ML has focused on PAC/VC approach to generalization, overlooking the SM approach. The SM approach to NNs provides a qualitative description of generalization phenomenon, highlighting diverse properties in learning curves. Unlike the gradual improvement suggested by PAC/VC theory, generalization in NN systems can exhibit various qualitative behaviors. The SM approach explains why generalization in neural networks can be more complex than predicted by PAC/VC theory. It highlights discontinuities in performance based on control parameters, model details, algorithm properties, regularization effects, data characteristics, and noise. This complexity, observed in modern deep learning systems, deviates from historical gradual improvement theories. The separation between algorithmic optimization and statistical inference questions can be limiting due to strong distribution assumptions and technical complexity. PAC/VC theory provides upper bounds on generalization accuracy, but it may not always imply smooth outcomes. The Smooth Upper Bound on Generalization Accuracy does not guarantee smooth outcomes. The SM approach suggests Neural Networks can have different phases and phase transitions based on control parameters, leading to non-trivial phase diagrams. Phases represent regions in parameter space where system properties change smoothly, while phase transitions indicate abrupt changes in system properties. In the Hopfield model of associative memory, the system can exhibit different phases depending on control parameters like load parameter \u03b1 and temperature parameter \u03c4. These phases include high-temperature ergodic phase, spin glass phase, and low-\u03c4 low-\u03b1 memory phase, each with distinct retrieval properties that can change dramatically as the control parameters are adjusted. In the context of associative memory models like Hopfield and Restricted Boltzmann machines, the study focuses on the generalization properties of neural networks. A simplified model is presented to explain the performance of deep learning systems, highlighting the impact of control parameters on NNs. The VSDL model is introduced as a practical representation of these parameters, shedding light on the behavior of modern DNNs. The VSDL model is a simplified representation of deep learning systems, focusing on the function mapping input images to output labels. It argues for the thermodynamic limit as an appropriate analysis framework and highlights non-trivial phases of learning in this limit. The VSDL model simplifies deep learning systems by focusing on the function mapping input to output. It introduces control parameters \u03b1 and \u03c4 that can be adjusted during training, similar to how temperature and pressure control states of water. In physical applications, transitions between regions are determined by these parameters. In physical applications, transitions between regions are determined by control parameters \u03b1 and \u03c4. Adding noise to training data decreases an effective load \u03b1, impacting the macroscopic properties of DNN learning systems. This noise can be introduced by randomizing labels or adding extra noisy data to the training set. Adding noise to training data, such as randomizing labels or adding extra noisy data, decreases the effective load parameter \u03b1 in DNN learning systems. This results in a decrease in the effective number of training examples, while the model capacity remains similar or unchanged. Adding noise to training data decreases the load parameter \u03b1 in DNN learning systems, resulting in a decrease in the effective number of training examples while the model capacity remains similar or unchanged. The model capacity of realistic DNNs scales with the number of data points, not the effective number of data points. Adding noise to training data decreases the load parameter \u03b1 in DNN learning systems, resulting in a decrease in the effective number of training examples while the model capacity remains similar or unchanged. According to some related SGD schedule, after randomizing labels, we essentially have new binary problems of different sizes, many of which are not satisfiable. Overtraining can occur due to the model having more capacity than needed for the labels. Early stopping increases an effective temperature \u03c4 in the training algorithm, acting as a control parameter similar to temperature. The temperature \u03c4 in a stochastic learning algorithm corresponds to the learning rate and annealing rate schedule of the SGD algorithm. It decreases the variability of neural network weights and depends on the number of steps taken by the algorithm. This parameter is denoted by \u03c4 and affects the learning process. The parameter \u03c4 in a stochastic learning algorithm, like the learning rate and annealing rate schedule of SGD, controls the variability of neural network weights. It can be adjusted by the practitioner to influence the learning process, along with other control knobs like \u03b1. Other associated quantities like VC dimension and growth function are not practical for controlling the learning process in NN/DNNs. When training modern DNNs, the model complexity grows with the number of parameters. In the VSDL model, a thermodynamic limit is considered where the hypothesis space and data points both diverge. This is different from the PAC/VC approach to generalization. Technical complexities in the SM approach to generalization are associated with subtleties in this limit. The phases of learning and transitions between them are influenced by general considerations from the SM theory of generalization. Considerations from the SM theory of generalization imply that the VSDL model in the thermodynamic limit exhibits a one-dimensional phase diagram based on the parameter \u03b1 and a two-dimensional phase diagram when varying the parameter \u03c4. These diagrams show the relationship between generalization and training errors. The VSDL model exhibits a one-dimensional phase diagram based on \u03b1 and a two-dimensional phase diagram based on \u03c4. The transition from \u03b1 > \u03b1 c to \u03b1 < \u03b1 c results in a dramatic increase in generalization error, where fitting training data well leads to poor test data fitting. This is illustrated in FIG1. The VSDL model shows a transition in learning behavior based on \u03b1 and \u03c4 values. Adding noise to data and adjusting algorithm parameters can lead to changes in generalization behavior, as illustrated in FIG1. The VSDL model demonstrates a transition in learning behavior based on parameter values \u03b1 and \u03c4. Adjusting parameters can affect generalization properties on new noisy data, with consequences for NN/DNN learning. Conclusion 1 states that neural networks can easily overtrain due to a lack of global control parameters for generalization. Conclusion 2 discusses how popular regularization methods may or may not help prevent overfitting in realistic NNs and DNNs. In an idealized model of realistic DNNs, the control parameter \u03c4 can prevent overfitting by decreasing the number of iterations. This approach provides a powerful way to rethink generalization properties and understand modern DNNs, different from the PAC/VC approach popular in ML. The VSDL model offers a different approach to understanding generalization in deep neural networks compared to the PAC/VC approach. It simplifies complex DNNs by using two control parameters to describe the network's behavior under different conditions. The model aims to reproduce key properties of realistic DNNs by considering the impact of data load and noise on the network's performance. The VSDL model simplifies complex DNNs using two control parameters to explain network behavior under different conditions. It explains the impact of data load and noise on network performance, providing a qualitative description of empirical results on DNNs' inability to avoid overfitting, discontinuous learning, and sharp transitions in generalization properties. Recent related work includes a refined scale-sensitive analysis in BID44 and Information Bottleneck ideas in BID45. The text discusses how DNNs are compressed early or late in optimization algorithms, with a focus on generalization properties and the impact of algorithm adjustments on network behavior. It suggests that revisiting old ideas can be beneficial and mentions the existence of a generalization phase diagram for every DNN. The VSDL model and SM approach provide an explanation for various empirical phenomena, including discontinuities in generalization performance and sensitivity to model details and algorithm properties. The conjecture of a \"low temperature\" spin glass phase affecting learning and generalization is difficult to evaluate due to methodological issues and non-reproducible results. In this section, simple models are discussed that capture aspects of realistic large DNNs and their generalization behavior, which can decay in the asymptotic regime with different exponents or functional forms. These models align with observations from the SM theory of generalization and provide insights into the behavior of multilayer networks. In this section, the text discusses various network architectures and their generalization properties, including discontinuous generalization properties shown in FIG1. The PAC/VC versus SM approach to generalization is overviewed, along with evidence in larger DNNs and mechanisms for regularization implementation. The \"general considerations from the SM theory of generalization\" are explored, starting with simple network architectures like the fully-connected committee machine. The fully-connected committee machine, tree-based parity machine, and one-layer reversed-wedge Ising perceptron are simple network architectures that capture multilayer and non-trivial representation capabilities essential for modern DNNs. Multilayer networks have stronger representational power than single layer networks. The fully-connected committee machine and tree-based parity machine represent extreme cases of connectivity, while the one-layer reversed-wedge Ising perceptron has a non-trivial activation function. The fully-connected committee machine is a multi-layer network with one hidden layer containing K elements, specified by K vectors connecting the inputs to the hidden units. The output is determined by the majority vote of the hidden layer. The tree-based parity machine is also a multi-layer network represented by K vectors connecting the inputs. The models capture multilayer and non-trivial representation capabilities essential for modern DNNs. The one-layer reversed-wedge Ising perceptron is a single layer network with a non-trivial activation function. It defines the output based on the majority vote of hidden units, showing discontinuous behavior in generalization error. The activation function in the one-layer reversed-wedge Ising perceptron model is non-monotonic, with classification outcomes depending on the values of \u03bb and \u03b3. The learning curve, as shown in FIG3, demonstrates abrupt changes in generalization error \u03b5 with respect to the control parameter \u03b1. This behavior is observed across different values of \u03b3, indicating a simple model of representation ability. The text discusses the generalization behavior in simple models of machine learning, focusing on the classification of elements into two classes. It explains the target rule, hypothesis space, and the problem of learning from examples. The activation function in the one-layer reversed-wedge Ising perceptron model is non-monotonic, with classification outcomes depending on specific parameters. The problem of learning from examples involves approximating a target rule T on a subset X using a mapping f. The generalization error \u03b5 measures the disagreement between the student's hypothesis and the teacher's target. The student iterates the process of constructing a new mapping f based on the teacher's label T(x) and the previous mapping f. In the iterative learning algorithm, the student constructs a new mapping f based on the teacher's label T(x) and the previous mapping f. The version space V(S) is the subset of X compatible with the data seen so far, and the training error \u03b5t quantifies the performance on the training set. The zero-temperature Gibbs learning rule is sometimes considered for generalization error evaluation. The learning curve characterizes the difference between training error and generalization error. The PAC/VC approach views training set size as a control parameter to analyze how the error varies. This framework uses accuracy parameters \u03b4 and \u03b3 to decide which hypothesis will perform well on a small training set. The statistical problem of convergence of frequencies to probabilities is closely related to deciding which hypothesis will perform well on a small training set. One approach is to fix the hypothesis space and focus on the worst-case scenario to derive bounds. Sauer and Vapnik and Chervonenkis showed that similar results could be obtained in this manner. The PAC/VC approach, based on the growth function and VC dimension of a function class F, minimizes empirical error on a random sample to bound generalization error. The bounds are universal and only depend on the VC dimension, measuring the complexity of F. The thermodynamic limit in information theory allows for easy computation of generalization error, forming the basis for the SM approach to generalization. This approach diverges m and the cardinality of F N in a well-defined manner, providing a theoretical framework for understanding generalization error. The SM approach to generalization error, proposed in (76; 25), involves describing the learning curve of a parametric class of functions for classification tasks. It utilizes a sequence of target functions f 1 , f 2 , . . . , f N to model the learning process with increasing data sets and NNs. The SM approach involves using a sequence of target functions to model the learning process. If a limiting behavior exists, the number of functions at a given error value may have an asymptotic behavior. This can be described as a \"competition\" between the error value and the logarithm of the number of functions. If sample size or number of functions approaches infinity, non-trivial results should not be expected. The sample size and function class sizes are fixed, with m and N approaching infinity such that \u03b1 = m/N is constant. This \u03b1 represents the load on the network in associative memory models and is a control parameter for investigating generalization error. Two approaches to the SM theory of generalization will be described, with a focus on understanding the behavior observed in various models. The basic single-layer perceptron model is discussed in detail, comparing continuous and discrete variants. The classification rule is based on the angle between input vector S and weight vector J. The analysis includes rigorous mathematical analysis, numerical simulations, and replica-based calculations from statistical physics. The focus is on understanding generalization error in models with fixed sample and function class sizes. The lengths of S and J do not affect classification in the perceptron model. The generalization error depends on the overlap between J and T, with specific values for different levels of overlap. The continuous perceptron model involves J in R N with constraints. The continuous perceptron model involves weights that are continuous and lie on an N-dimensional sphere with radius \u221aN. The Ising perceptron model has weights that lie on the corners of an N-dimensional hypercube, leading to a stronger discreteness condition with important consequences. The generalization error decreases as the training set size increases in the Ising perceptron model. In the Ising perceptron model, the generalization error \u03b5 decreases as the training set size increases. Vectors J are grouped into classes based on their overlap R with T, with a chance of producing the same output as T on a randomly chosen input of 1 \u2212 \u03b5. The volume of compatible students with generalization error \u03b5 after m training examples is reduced by a factor of 1\u2212\u03b5 on average. The volume of compatible students with generalization error \u03b5 after m training examples is controlled by the balance between energy and entropy in the traditional SM approach. The entropy density s(\u03b5) is the logarithm of the volume, while the energy e(\u03b5) is the penalty for incorrect predictions. The extremum condition for a combination of energy and entropy terms mathematically describes this relationship. The entropy behavior is ln(\u03b5) for small \u03b5 or large \u03b1, slowly diverging to -\u221e as \u03b5 approaches 0 or R approaches 1. In the context of the traditional SM approach, the energy behavior is described by e(\u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1. The maximum value of the expression in the square brackets of Eqn. BID5 dominates in the thermodynamic limit. Optimizing the difference s(\u03b5) \u2212 e(\u03b5) yields the scaling DISPLAYFORM12, showing a smooth decrease in generalization error with more examples. This contrasts with the behavior of the discrete Ising perceptron. The discrete Ising perceptron behaves differently from the traditional SM approach. The entropy approaches zero as \u03b5 \u2192 0 or as R \u2192 1, indicating one state with R = 1. The energy behavior is e(\u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1. For small-to-moderate values of \u03b1, there is a solution, but for large values of \u03b1, there is no solution. The discrete Ising perceptron shows a complex generalization behavior with a one-dimensional phase diagram depending on the control parameter \u03b1. The optimal value is at the boundary \u03b5 = 0 (or R = 1), leading to discontinuous changes in generalization error with increasing data. This behavior is not described by PAC/VC theory and is illustrated in FIG5 (c). The one-dimensional phase diagram of the learning system depends on the value of \u03b1, with two phases where generalization error changes discontinuously. In more complex cases, additional control parameters like temperature \u03c4 can affect the behavior, leading to a two-dimensional phase diagram with non-trivial behavior. The discrete Ising perceptron exhibits non-trivial behavior in a two-dimensional phase diagram, showing phases of perfect generalization, poor generalization, spin glass phase, and metastable regimes. The continuous perceptron, on the other hand, has a trivial phase diagram with generalization varying continuously. The SM approach to learning theory characterizes generalization as a competition between entropy and energy terms, providing rigorous results and intuitive explanations for observed phenomena. The version space V(S) and the -ball around the target function contain the target function f, providing bounds on the generalization error of any consistent learning algorithm. Lower bounds on \u03b4 = Pr[V(S) \u2286 B()] give insights into the generalization error \u03b5 = \u03b5(h) of the learning algorithm. The probability that a function h with generalization error \u03b5(h) remains in the version space V(S) is given by a sum of quantities over functions in F with generalization error greater than \u03b5. By fixing the failure probability \u03b4, it can be shown that any consistent function h satisfies \u03b5(h) \u2264 1/m ln(|F|/\u03b4) with probability at least 1 - \u03b4, regardless of the distribution or target function. This bound, independent of the distribution and target function, can be weak but provides insights into the generalization error of the learning algorithm. The PAC bound holds for all hypotheses in F, but does not guarantee finding the best one. The number of functions in F with generalization error exactly j is denoted by Q j, and in general, Q j |F|. Refined upper bounds can be obtained by tracking errors j and the number of hypotheses achieving that error Q j. If considering a parametric class of functions, the expression can be rewritten. In Eqn. FORMULA20, log Q (11) states that summing terms in Eqn. BID17 where > * + \u03c4 equals 0 in the thermodynamic limit. This allows bounding generalization error by * + \u03c4. The trade-off between entropy and energy is illustrated by non-negative functions s( ) and \u2212\u03b1 log(1 \u2212 ). * represents the error value where energy always dominates entropy. For the continuous perceptron, an entropy upper bound of s( ) = 1 is used. The Ising perceptron shows a gradual decrease of \u03b5 with increasing \u03b1, consistent with PAC/VC theory. An entropy upper bound for the Ising perceptron is s( ) = H(sin 2 (\u03c0 /2)), with very few configurations having energy slightly greater than the minimum value. The entropy density s( ) is very small for certain energy values. The rightmost intersection points plotted as a function of \u03b1 show a learning curve related to energy-entropy competition. As \u03b1 increases, the rightmost crossover point decreases gradually until a critical value is reached, where the plot suddenly drops to 0. This behavior is not described by PAC/VC theory but is consistent with other results. Theoretical and empirical work has focused on loss surfaces of NNs/DNNs, with a connection to spin glasses. Results suggest a link between NNs/DNNs and spin glasses, supported by the random energy model. The random energy model (REM) is the infinite limit of the p-spin spherical spin glass, exhibiting a transition in entropy density at a non-zero temperature parameter \u03c4. Above a critical value \u03c4 c, there are many configurations, while below \u03c4 c, there is a single configuration. This phenomenon of low entropy for configurations with loss slightly above the minimum value is crucial for complex learning behavior. The discussion in the curr_chunk delves into the Tikhonov-Phillips method and TSVD method for solving ill-posed LS problems, highlighting the challenges and alternatives in finding a vector x given a matrix A and vector b. The connection between early stopping as a regularization mechanism in the VSDL model and other popular regularization methods is also explored. The Tikhonov-Phillips method and TSVD method are discussed for solving ill-posed LS problems. The solution involves finding a vector x using matrix A and vector b. The control parameter \u03bb plays a crucial role in the convergence radius. The control parameter \u03bb influences the convergence radius of the estimator in the Tikhonov-Phillips approach. Similarly, the control parameter k affects the domain and range of the estimator in the TSVD approach. Adjusting \u03bb or k can prevent overfitting but may lead to underfitting, as the linear structure of the operators allows for this flexibility. In the 80s/90s, linear regularization approaches did not work well on NNs. Early stopping of iterative algorithms was more effective. Generalizing to a wide range of problems is possible by adjusting control parameters to prevent overfitting, even if it leads to underfitting. The main approach that worked well for training neural networks was early stopping of iterative algorithms, which is considered implicit regularization. This approach adjusts control parameters to prevent overfitting, even if it may result in underfitting. The dynamics leading to the SM approach to generalization do not optimize linear or convex objectives but follow a stochastic Langevin type dynamics, connected to Gibbs probability distribution. These dynamics, similar to SGD used in training DNNs, suggest broader application of the SM approach. More general dynamical systems exhibit phases, phase transitions, and phase diagrams. General dynamical systems exhibit phases, phase transitions, and phase diagrams, where a phase is defined as the set of inputs mapped to a fixed point under iterated dynamics. Phase transitions occur at points in parameter space where nearby points map to different fixed points. Unlike systems with a thermodynamic limit, general dynamical systems lack structure for obtaining generalization bounds or using control parameters as regularization parameters. Adding noise to a system, such as randomizing labels or shuffling pixel values, may not always lead to a regularization parameter that prevents overfitting. The hope is to find a regularization parameter that prevents overfitting, even if it leads to underfitting, with the quality of generalization varying smoothly. This can be achieved by increasing the regularization parameter \u03bb in an optimization problem. The PAC/VC approach provides smooth upper bounds, making it easier to reason about the limit of one quantity diverging. The results in Section 3 support this idea, showing that the SM approach to generalization emphasizes the importance of finding the right regularization parameter. The SM approach to generalization challenges the common practice of extending results from linear to nonlinear systems by assuming large data points or regularity conditions. Empirical results for NNs and DNNs suggest that these conditions often do not hold, leading to unexplored consequences."
}