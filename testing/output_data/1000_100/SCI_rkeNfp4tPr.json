{
    "title": "rkeNfp4tPr",
    "content": "Stochastic gradient descent with stochastic momentum is popular for training deep neural networks. The addition of a momentum term biases the update in the direction of the previous change in parameters, improving convergence time. Empirical evidence shows that stochastic momentum significantly improves convergence time in training deep networks. Stochastic momentum improves deep network training by helping SGD escape saddle points faster and find second order stationary points more quickly. The ideal momentum parameter should be large (close to 1), as supported by theoretical and empirical findings. Experimental results further validate the effectiveness of SGD with stochastic momentum in nonconvex optimization and deep learning applications. Stochastic momentum is widely used in various fields like speech recognition, natural language processing, and reinforcement learning to train models. It has been observed to help achieve faster convergence compared to standard SGD. Momentum is considered a necessary tool for designing new optimization algorithms in deep learning, with popular variants like Adam and AMSGrad incorporating its use. Despite its widespread use, empirical justification for stochastic momentum remains clear. In this paper, a theoretical analysis is provided for stochastic momentum in SGD, with guidelines for setting momentum parameters. The study shows that SGD with stochastic momentum can escape saddle points faster than standard SGD, offering clear benefits for optimization. In this paper, the focus is on finding second-order stationary points for smooth non-convex optimization using SGD with stochastic heavy ball momentum. The goal is to obtain a guarantee for second-order optimality in nonconvex problems. The paper aims to achieve a second-order guarantee in nonconvex optimization by utilizing momentum to reach an approximate second-order stationary point. The dynamic procedure in Algorithm 2 is introduced with a required condition to ensure suitable correlation with negative curvature directions of the function f. The paper introduces a dynamic procedure in Algorithm 2 to achieve a second-order guarantee in nonconvex optimization by utilizing momentum to reach an approximate second-order stationary point. It focuses on the correlation with negative curvature directions of the function f, showing that SGD with heavy ball momentum can escape saddle points faster under certain conditions. The paper introduces a dynamic procedure in Algorithm 2 to achieve a second-order guarantee in nonconvex optimization using momentum to reach an approximate second-order stationary point. A larger momentum parameter \u03b2 can help escape saddle points faster, shedding light on why SGD with momentum enables faster training in optimization and deep learning. In an iterative update scheme, parameters can enter a saddle point region where gradient updates may drift slowly. Moving along the direction of the smallest eigenvector guarantees a fast escape under certain constraints on the step size. Daneshmand et al. (2018) study non-momentum SGD and make an assumption akin to the proposed method. In the study of stochastic momentum, the CNC property requires that the update direction is strongly non-orthogonal to the direction of large negative curvature. Updates escape saddle point regions due to this property, especially when \u03b2 is close to 1. If the update direction has significant correlation with the negative curvature direction, successive iterations are amplified through the momentum update. The study shows that momentum can accelerate the escape process from saddle points by a factor of 1 - \u03b2. However, the choice of \u03b2 is constrained and cannot be arbitrarily close to 1. Empirical evidence demonstrates the benefits of stochastic momentum in solving optimization tasks with significant saddle points. The study discusses the acceleration of escape from saddle points using momentum, with empirical evidence supporting the benefits of stochastic momentum in optimization tasks. The optimization challenge involves a non-convex problem with stochastic gaussian perturbations and algorithms initialized at the same point. The algorithms are initialized at the same point with a specific step size. The second objective involves phase retrieval with real applications in physical sciences. Empirical findings show that larger choices of beta significantly accelerate convergence for both objectives. Large-momentum trajectories escape saddle points more quickly. The heavy ball method, proposed by Polyak in 1964, shows no convergence speedup over standard gradient descent in most cases. However, it can provide an accelerated rate in certain scenarios like convex quadratic objectives. Empirical findings suggest that larger momentum trajectories escape saddle points faster, leading to a dramatic speedup in stochastic momentum for finding optimal solutions in phase retrieval. Our work belongs to the category of specialized algorithms designed to exploit negative curvature and escape saddle points faster. Previous works in this category include Ge et al. (2015) and Jin et al. (2017), who showed that adding isotropic noise guarantees gradient descent escapes saddle points and finds second order stationary points. Phase retrieval is known to be nonconvex with strict saddle properties, where each saddle exhibits negative curvature. Daneshmand et al. (2018) assume that stochastic gradient inherently has a role in this process. Our work assumes Correlated Negative Curvature (CNC) for stochastic momentum instead of stochastic gradient, comparing results with related works in Appendix A. We assume L-Lipschitz gradient and \u03c1-Lipschitz Hessian, ensuring convergence. Stochastic gradient has bounded noise and momentum norm is limited. The analysis of stochastic momentum relies on three key properties: Almost Positively Aligned with Gradient (APAG), Almost Positively Correlated with Gradient (APCG), and Gradient Alignment or Curvature Exploitation (GrACE). These properties aim to demonstrate the behavior of stochastic momentum in natural settings and standard problems. The Gradient Alignment or Curvature Exploitation (GrACE) condition in stochastic momentum ensures that the momentum term aligns well with the gradient, allowing for algorithm progress. Another related property, Almost Positively Correlated with Gradient (APCG), measures the correlation between the current momentum term and the gradient in terms of local curvature. These properties help analyze the behavior of stochastic momentum in various scenarios. The text discusses the empirical validation of the Gradient Alignment and Curvature Exploitation (GrACE) condition in stochastic momentum. It shows that the properties of Almost Positively Correlated with Gradient (APCG) and Almost Positively Aligned with Gradient (APAG) hold in experiments, particularly in the context of the phase retrieval problem. The text discusses the GrACE condition in stochastic momentum for the phase retrieval problem. It shows that APCG and APAG properties hold in experiments, indicating alignment between stochastic momentum and gradient, as well as curvature exploitation. The analysis follows a similar template to previous works and is structured into three cases to determine convergence to a second-order stationary region. The algorithm analyzed is similar to the previous one but with a larger step size. The algorithm analyzed has step size parameters r and \u03b7, momentum parameter \u03b2, and period parameter T thred. It shows progress in cases (a) and (b), weakly hurting progress in case (c) when the goal is met. A second-order stationary point is reached with high probability. The proof borrows tools from previous works but the momentum analysis is novel. If SGD with momentum has APAG property when gradient is large, APCG T thred property in saddle points with negative curvature, and GrACE property, it reaches a second order stationary point in iterations with high probability. Higher \u03b2 leads to faster convergence due to escaping saddle points faster. Constraints on \u03b2 are needed to prevent it from being too close to 1. In the high momentum regime, Algorithm 2 outperforms CNC-SGD, showing that higher momentum helps find second order stationary points faster. Empirical findings suggest conditions are easily met for a wide range of \u03b2 values. The analysis focuses on escaping saddle points by SGD with momentum, with specific time considerations. In the high momentum regime, Algorithm 2 outperforms CNC-SGD in finding second order stationary points faster. The analysis focuses on escaping saddle points by SGD with momentum, showing that it takes at most T thred iterations to escape a region with a large negative eigenvalue of the Hessian. The technique used is proving by contradiction, demonstrating that the function value decreases by at least F thred on expectation when escaping. The text discusses the use of momentum in SGD to escape saddle points faster. It introduces Lemmas 1 and 2 to provide upper and lower bounds on the expected distance. Lemma 1 shows that larger momentum leads to faster escape, while Lemma 2 utilizes recursive dynamics to derive a lower bound. The text introduces Lemmas 1 and 2 to provide bounds on expected distance in SGD with momentum. Lemma 2 uses recursive dynamics to derive a lower bound that grows exponentially with time and momentum parameter \u03b2. The text discusses the exponential growth of a lower bound in SGD with momentum, emphasizing the importance of a higher momentum parameter \u03b2 for reaching a second-order stationary point faster. It introduces Lemmas 1 and 3 to support this claim and highlights the significance of three properties that ensure the effectiveness of SGD with momentum in escaping strict saddle points. The heavy ball method, proposed by Polyak in 1964, does not provide a convergence speedup over standard gradient descent in most cases. Recent research has focused on analyzing this method for various optimization problems beyond quadratic functions. Recent research has focused on analyzing optimization problems beyond quadratic functions, including stochastic heavy ball momentum and Nesterov's momentum for smooth non-convex objective functions. The expected gradient norm converges at a rate O(1/ \u221a t), which is not better than standard SGD. Some variants of stochastic accelerated algorithms with first order stationary point guarantees have been proposed, but they do not capture the stochastic heavy ball momentum used in practice. Kidambi et al. (2018) found that SGD with heavy ball momentum fails to achieve the best convergence rate for specific strongly convex and strongly smooth problems. Recent research has focused on analyzing optimization problems beyond quadratic functions, including stochastic heavy ball momentum and Nesterov's momentum for smooth non-convex objective functions. Specialized algorithms and simple GD/SGD variants aim to reach a second order stationary point by exploiting negative curvature explicitly. Fang et al. (2019) propose average-SGD with a suffix averaging scheme for updates, assuming an inherent property of stochastic gradients to escape saddle points. The algorithm can help escape saddle points faster compared to standard SGD under certain conditions. The text discusses the effectiveness of stochastic heavy ball momentum in optimization algorithms compared to other methods. It highlights the advantages of using this approach and references previous works to support its analysis. Lemma 6, 7, and 8 discuss the properties of SGD with momentum in optimization algorithms. Lemma 7 states that under the APAG property, SGD with momentum decreases the function value by a constant when the gradient norm is large. Lemma 8 bounds the increase of function value of the next iterate using the GrACE property. Lemma 8 bounds the increase of function value of the next iterate using the GrACE property. Consider the update rule w t+1 = w t \u2212 \u03b7m t, where m t represents the stochastic momentum and \u03b7 is the step size. By \u03c1-Lipschitzness of Hessian, we have that the update step satisfies certain conditions. Lemma 2 and Lemma 3 provide bounds on the function value increase of the next iterate using the GrACE property. The update rule w t+1 = w t \u2212 \u03b7m t satisfies certain conditions due to the \u03c1-Lipschitzness of Hessian. The quadratic approximation at w t0 is defined, and the proof involves rewriting m t0+j for any j \u2265 1. The proof involves rewriting m t0+j for any j \u2265 1 by using various notations and update rules. Lemma 5 provides bounds on the function value increase of the next iterate using the GrACE property, concluding that if SGD with momentum has the APCG property, certain inequalities hold. Lemma 5 provides bounds on function value increase of the next iterate using the GrACE property. If SGD with momentum has the APCG property, certain inequalities hold, constraining parameter \u03b2. The constraints upper-bound the value of \u03b2, which cannot be too close to 1. The dependence on L, \u03c3, and c are artificial and can be adjusted in the analysis. Lemma 5 provides bounds on function value increase of the next iterate using the GrACE property. The upper bounding of E t0 [ q q,t\u22121 ] is discussed in Lemmas 9, 1, and 2. The analysis involves the triangle inequality and the Lipschitz gradient assumption. The derivation of an upper bound for E t0 [ \u2207f (w t0+s ) \u2212 \u2207Q(w t0+s ) ] is also presented. Further analysis on \u03a0 t\u22121 j=s+1 G j 2 is conducted, introducing the notation \u03b8 j := j k=1 \u03b2 j\u2212k and \u03bb := \u2212\u03bb min. Lemma 5 provides bounds on function value increase of the next iterate using the GrACE property. The upper bounding of E t0 [ q q,t\u22121 ] is discussed in Lemmas 9, 1, and 2. The analysis involves the triangle inequality and the Lipschitz gradient assumption. The derivation of an upper bound for E t0 [ \u2207f (w t0+s ) \u2212 \u2207Q(w t0+s ) ] is also presented. Further analysis on \u03a0 t\u22121 j=s+1 G j 2 is conducted, introducing the notation \u03b8 j := j k=1 \u03b2 j\u2212k and \u03bb := \u2212\u03bb min. The proof involves bounding terms using various conditions and inequalities. Lemma 12 and Lemma 13 provide lower bounds for certain expectations based on defined conditions and properties. The proof involves the use of coefficients, matrix properties, and the assumption of zero mean for certain variables. The symmetric positive semidefinite nature of a matrix is also discussed in relation to the bounds. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation, using the APCG property and leveraging negative curvature. The function value must decrease by at least F thred in T thred iterations on expectation, proven by using Lemmas 1, 3, 12, and 13. By choosing T thred large enough, the inequality holds, as guaranteed by the constraint of \u03b7. The function value must decrease by at least F thred in T thred iterations on expectation, proven by Lemmas 1, 3, 12, and 13. By choosing T thred large enough, the inequality holds, as guaranteed by the constraint of \u03b7. T = 2T thred f (w 0 ) \u2212 min w f (w) /(\u03b4\u2206). We return w uniformly randomly from w 0 , w T thred , w 2T thred , . . . , w kT thred , . . . , w KT thred , where K := T /T thred. With probability at least 1 \u2212 \u03b4, we choose a w k where \u03a5 k did not occur. If SGD with momentum has APAG property when gradient is large, APCG T thred property in saddle points with negative curvature, and GrACE property throughout, it reaches a second order stationary point in T = O((1 \u2212 \u03b2) log( Lcm\u03c3 2 \u03c1c c h (1\u2212\u03b2)\u03b4\u03b3 ) \u221210 ) iterations with high probability 1 \u2212 \u03b4. Lemma 15 guarantees that uniformly sampling a w from a specific set gives a second-order stationary point with high probability. The proof of Lemma 15 is replicated in the appendix. By satisfying certain conditions, we can ensure the expected decrease in function value over iterations. Lemma 15 ensures that sampling a w from a specific set yields a second-order stationary point with high probability. The proof is detailed in the appendix. By meeting specific conditions, we can limit the expected increase in function value over iterations. The proof of the theorem relies on Lemma 15, where the expected increase in function value is bounded by \u03b4 when w kT thred is a second-order stationary point. By satisfying these conditions, we can apply Lemma 15 and conclude the proof. Algorithm 2 is proven to be better than the previous method by Daneshmand et al. (2018) as it can find a second-order stationary point faster with a higher momentum."
}