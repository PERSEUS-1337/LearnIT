{
    "title": "rygDeZqap7",
    "content": "Natural language understanding research has shifted towards complex Machine Learning and Deep Learning algorithms, which often outperform simpler models. To address the challenge of limited labeled data availability, a methodology for extending training datasets and training data-hungry models using weak supervision is proposed. This approach is applied to biomedical relation extraction, a task crucial for drug discovery. Small-scale experiments show consistent performance enhancements of an LSTM network, comparable to hand-labeled data. Optimal settings for applying weak supervision are discussed. The biomedical field has a growing number of scientific papers with important information encoded in unstructured text. Extracting and storing this information in a structured format can benefit tasks like drug design and adverse drug effect detection. Efforts have been made to automate Information Extraction due to the labor-intensive nature of manual annotation. This work focuses on automating semantic triple extraction from biomedical abstracts, specifically on regulations related to chemical effects. Semantic triple extraction from biomedical abstracts focuses on regulations related to chemical effects. This process involves identifying entities of interest and building classifiers to recognize target relationships, particularly in the subtask of relation extraction. This automated approach is crucial for drug design and safety, enabling researchers to filter and select chemical substances with specific properties efficiently. The main focus is on relation extraction, a complex task that requires increasing algorithm capacity along with training dataset size. Annotating training datasets for this task is labor-intensive, so a new methodology based on weak supervision is proposed. This methodology involves training base learners on a small labeled dataset, using them to predict labels for a larger unlabeled dataset, deriving weak labels using a denoiser, and training a meta-learner using weak supervision. This approach aims to improve relation extraction efficiency in biomedical abstracts. The main contributions of the study include proposing a methodology for relation extraction, demonstrating its effectiveness in a small-scale experiment, and investigating denoising methods. The study also discusses literature on information extraction, relation extraction from biomedical text, and semi-supervised and ensemble learning methods. The methodology is released on GitHub for reproducibility and further experimentation. Extraction BID4 focuses on unstructured Information Extraction without using training data. Fully-supervised methods require manual annotation, while semi-supervised methods like bootstrapping leverage both labeled and unlabeled data. Various algorithms like DIRPE, Snowball, KnowItAll, and TextRunner have been developed for bootstrapping. Recent approaches include contextual data augmentation for paraphrasing training samples. Distant supervision is also mentioned as a method to avoid excessive manual annotation. Our work complements distant supervision by using learning algorithms to generate weak labels for relation extraction without the need for human annotation. This approach has been beneficial for large-scale datasets, particularly in biomedical relation extraction tasks like BioCreative V's Chemically-induced Diseases extraction. The best performing team in a competition focused on identifying relations between Chemicals and Proteins (or Genes) on a sentence level implemented an ensemble of LSTM, CNN, and SVMs. The results highlighted the importance of the lack of training data in this domain and the suitability of ensemble methods for improving generalization, especially when using Deep Neural Networks. Our work aims to combine the advantages of ensemble learning and semi-supervised learning techniques to improve the performance of Machine Learning models, especially when using Deep Neural Networks. This combination has not been thoroughly studied but has the potential to enhance generalization by providing multiple views. Semi-supervised learning enhances system performance by utilizing multiple views and unlabeled data to increase diversity among learners. Co-training, initially proposed as a system with two independent learning algorithms, has evolved to incorporate expert-defined lexicons and natural language processing for noisy annotations. This approach has shown success in functional genomics without the need for manually labeled data. The system utilizes semi-supervised learning to annotate data samples in functional genomics, outperforming state-of-the-art methods. Tri-training extends co-training to three learners, where two learners agreeing on a label teach the third. Co-forest involves multiple learners making decisions on re-training using an ensemble system. Learners in the ensemble system are not used for final predictions, allowing for the use of all unlabeled data. Weak supervision and data programming have heavily influenced the development of the methodology described. Weak supervision involves training models using labels of questionable quality, while data programming focuses on creating training sets programmatically when no ground-truth labels are available. This approach allows for the use of all unlabeled data, unlike other paradigms that only incorporate a few examples with high confidence annotations for re-training. Weak supervision involves utilizing various weak sources to provide labels or abstain from voting for unlabeled data points. The process includes encoding sources into Labeling Functions (LF) and deriving a vote matrix \u039b. Denoising is then performed using a probabilistic graphical Generative Model (GM) to derive weak labels close to the true labels. This approach allows for the incorporation of all unlabeled data in training models. The methodology for semi-supervised learning involves using Labeling Functions to label data points and ensuring accuracy. The Generative Model structure is a hyperparameter that can be estimated automatically. Data programming maximizes the likelihood of observed votes occurring under the Generative Model. Weak labels are generated using predicted label distributions. A noise-aware discriminative model is trained using the generated labels for prediction. This methodology aims to leverage the benefits of multiple learners through weak supervision and data programming. In semi-supervised learning, a gold-labeled training set is assumed to be available but insufficient in size for training a complex model. To address this, additional lower quality training data is augmented using machine learning models of lower complexity as weak supervision sources. This approach allows for scaling the dataset size without relying on heuristics or crowd-sourced labels. In semi-supervised learning, additional lower quality training data is augmented using machine learning models of lower complexity as weak supervision sources to scale the dataset size without relying on heuristics or crowd-sourced labels. For relation extraction, a dataset D U of size M m is drawn from the same distribution as D B, with a validation set D V for hyperparameter tuning and a held-out test set D T for evaluation. 162 base learners are trained on solving T by maximizing individual performance and capturing different views of the data through varying hyperparameters and design choices, including sentence pruning to focus on relevant words between entities of interest. In this work, the focus is on different approaches for text analysis: (a) Whole sentences, (b) window of 0, (c) window of 5, and (d) Shortest Dependency Path. Sequential features like tri-grams are used, and text representation is done through token occurrences or TF-IDF weights. Various machine learning algorithms such as Logistic Regression, Support Vector Machines, Random Forest Classifiers, and Long-Short Term Memory Networks are employed on the feature matrix. After employing various machine learning algorithms on text features like tri-grams and TF-IDF weights, including Logistic Regression, Support Vector Machines, Random Forest Classifiers, Long-Short Term Memory Networks, and Convolutional Neural Networks, a subset of base learners is selected to maximize performance and diversity. Classifiers with lower performance than a set threshold are discarded to enhance diversity and account for limited hyperparameter tuning during their creation. To select diverse classifiers, a similarity-based clustering method is used on predictions of base learners. A KxK similarity matrix is constructed based on inter-annotator agreement rates. K-means clustering is performed to pick representative base learners. The silhouette score coefficient helps determine the appropriate number of clusters. Labels of D U are predicted using selected base learners to obtain a binary prediction matrix. In the final steps, a denoiser is used to reduce the vote matrix into weak labels. Different denoisers are considered, including a Majority Vote denoiser and an Average Vote denoiser. A discriminative model is then used as a meta-learner, trained with weak supervision to trade label quality for quantity, which can be beneficial when the meta-learner's performance is limited by the training set size. By using high-capacity models like Deep Neural Networks as meta-learners, we aim to improve performance even when limited by training set size. Experiments are conducted using Snorkel framework with BioCreative CHEMPROT and CDR datasets, utilizing annotated PubMed abstracts. The methodology requires three gold-labeled datasets and a held-out test set, with original test sets used for final evaluation. Using high-capacity models like Deep Neural Networks as meta-learners, the methodology involves merging and shuffling training and development sets to create three datasets: one for training base learners, one for validation, and one as unlabeled data. This ensures no bias in document selection and consistent pre-processing steps. The restructured dataset statistics are available for reference. This setup aims to control the impact of choices on algorithm results. The text discusses the controlled approach used to compare the performance of a meta-learner trained with weak supervision to optimal performance. SpaCy is utilized for text pre-processing tasks, including sentence splitting, tokenization, and dependency parsing. Snorkel is used for candidate extraction and mapping relationships within the text. Cross-sentence relations are not considered, and only candidates within the same sentence are processed. In experiments, Snorkel is used for candidate extraction and mapping relationships in Natural Language. Entities of interest are replaced with tokens like 'ENTITY1' and 'ENTITY2', and additional entities are replaced with 'CHEMICAL', 'GENE', or 'DISEASE'. A bi-directional Long-Short Term Memory network is employed with randomly initialized word embeddings and random under-sampling for class balance. Different hyperparameters are tested, including dropout values and training epochs. In this section, the research questions aim to enhance biomedical relation extraction using Machine Learning classifiers as weak supervision sources. The optimal setting for weak supervision on this task is explored, with theoretical warranties suggesting that adding weakly labeled data can improve the performance of the meta-learner. As the amount of weakly labeled data increases, the performance of the meta-learner is expected to improve quasi-linearly compared to scenarios with ground-truth labels. The study explores using Machine Learning classifiers as weak supervision sources for biomedical relation extraction. It aims to determine if a diverse set of base learners can produce meaningful weak labels. Experiments are conducted to evaluate the effectiveness of weak supervision in improving performance. In the study, weak supervision is utilized to train a meta-learner using different setups and modes. The number of base learners is crucial, as adding more can impact performance. The denoising component plays a key role in determining the quality of weak labels. The denoising component is crucial for determining the quality of weak labels used to train the final learner. Different denoising methods are assessed, producing binary or marginal weak labels with varying distributions. An error analysis is conducted to understand their impact on training and final performance. The study explores using supervised machine learning classifiers as weak classifiers and identifies the optimal settings for applying weak supervision. The selection of base learners is based on a specific strategy, with experiments conducted using different numbers of base learners and benchmarking results at intervals of 5. The study explores the impact of weak supervision on training performance, comparing results with full supervision. Training the meta-learner with weak labels shows improved performance, especially when combined with ground-truth labels. Weak supervision can achieve comparable performance to full supervision when drawn from the same distribution. Weak supervision can achieve performance comparable to full supervision, sometimes even slightly better. Differences are minor and not statistically significant due to high variance in meta-learners' performance. Under-sampled training sets in weak supervision are larger, based on weak labels. Majority Vote often outperforms meta-learner, but LSTM model struggles with small training datasets even with gold quality labels. Learning curves are visualized. The meta-learner's learning curves show an upward trend with statistically significant results. However, the F1 score on the training set is much higher than the test score, indicating overfitting. Additional training data is needed to improve performance. The small dataset size and problem complexity limit definitive conclusions, but analysis based on experimental results will be discussed. The experimental results show that the meta-learner's performance improves with more base learners. The F1 score is lowest for weak Majority Vote labels with 5 learners. The Generative model weak marginals show inconsistent patterns. The meta-learner performs better with Average Vote marginals, especially with more than 10 base learners. Performance slightly improves with more base learners using Generative model marginals, except for two cases. Overall, the meta-learner achieves the best performance with Average Marginals. Generative Model marginals also improve performance compared to Majority Vote weak labels, with one exception. The GM marginals depend on hyperparameters chosen based on F1 score on a validation dataset. Denoisers can produce binary or non-binary weak labels, with marginals improving meta-learner performance compared to binary labels. Generative Model tends to create U-shaped marginals, while average marginals are more uniformly spread. The error analysis on the validation set shows that Average Vote labels have higher quality compared to weak labels, with most misclassifications closer to 0.5. The F1 score is not suitable for evaluating marginal weak labels. Training with marginal labels results in higher error, especially with Average weak marginals, while LSTM quickly predicts binary labels accurately after a few epochs. In practice, training a classifier with marginal labels is akin to a regression problem. The predicted logits become more spread as the training marginals distributions become more uniform, resembling regression rather than classification. Efforts are made to apply this methodology to the CPR task by expanding datasets with CHEMPROT documents and BID19 data. The meta-learner's performance decreases with the addition of weakly labeled data. The meta-learner's performance decreases with the addition of weakly labeled data, indicating issues with data quality. A class imbalance is observed in the outgoing citations dataset compared to the original dataset. Visualization using t-SNE algorithm confirms unsuitability of the new dataset for the task. Further investigation into constructing appropriate unlabeled datasets is necessary. Weak supervision can enhance the performance of complex models like deep neural networks. The proposed methodology enhances complex model performance by utilizing unlabeled data and multiple base learners. It shifts human effort from hand-labeling to feature engineering and diverse learner construction. The method scales training datasets and consistently improves performance in supervised learning. The proposed methodology improves model performance by using unlabeled data and multiple base learners, reducing the need for hand-labeling large datasets. Further exploration is needed to construct a larger unlabeled dataset to enhance metalearner performance and draw stronger conclusions on research questions. The study highlights the challenges of collecting an appropriate unlabeled dataset for semi-supervised algorithms and emphasizes the need for a more suitable metric than the F1 score for evaluating weak labels. Additionally, optimizing hyperparameters of the Generative Model and experimenting with the meta-learner are suggested for further investigation. Areas for further investigation include experimenting with the meta-learner and defining a more appropriate selection method for the Base Learners. It would also be interesting to examine how the system would behave if the Base Learners abstained from voting on uncertain examples. This could provide the Generative Model with a modeling advantage compared to unweighted methods."
}