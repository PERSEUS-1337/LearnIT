{
    "title": "rkeeQmm0cX",
    "content": "Deep neural networks (DNNs) have emerged as a powerful solution this year for addressing longstanding issues in Artificial Intelligence. Deep neural networks (DNNs) are applied to three cyber security use cases: Android malware classification, incident detection, and fraud detection. The experiments show that DNNs outperform classical machine learning algorithms due to their ability to extract and build better features. In the era of technical modernization, DNNs show superior accuracy in Android malware classification, incident detection, and fraud detection compared to XGBoost. DNNs perform slightly below the top system in CDMC 2017 tasks. Cyber security is crucial in protecting systems, networks, and data from fraudulent activities like hacking. Cyber security focuses on protecting systems, networks, and data from fraudulent activities, including malware threats. Antivirus and blacklists are commonly used but are not always effective against new, polymorphic malware. Machine learning algorithms, particularly deep learning approaches, have shown promise in enhancing cyber security measures. Deep learning approaches are effective in cyber security for Android malware classification, incident detection, and fraud detection. The paper evaluates the use of deep neural networks (DNNs) in these areas, with sections on related work, background knowledge of DNNs, methodology, data set description, results, and conclusion. Static and dynamic analysis are commonly used in Android malware detection. Dynamic analysis is a commonly used approach in Android malware detection, focusing on run-time execution characteristics like system calls, network connections, and memory utilization. Commercial systems often combine static and dynamic analysis. While static analysis is preferred for its low computational cost and resource utilization, dynamic analysis is crucial for detecting metamorphic and polymorphic malwares. In a study, traditional machine learning classifiers were evaluated for android malware detection using features like permissions, API calls, and a combination of both. In a study, traditional machine learning classifiers performed well using a combination of API calls and permission features for Android malware detection. MalDozer, proposed by BID4, utilizes deep learning to detect and classify Android malware. BID5 briefly discussed privacy and security issues in cloud computing, while BID6 proposed machine learning-based anomaly detection on different layers. BID7 discussed creating intrusion detection for cloud infrastructure using rule-based and machine learning systems. In BID8, security problems in cloud were discussed, proposing an incident detection system that outperforms intrusion detection. BID9 conducted a comparative study of traditional machine learning classifiers for financial fraud identification. BID10 explored data mining approaches for financial fraud detection. Deep learning, a sub model of machine learning, is widely used in cyber security, with a unique DNN architecture proposed for various cyber security use cases. The discussion focuses on deep neural networks (DNNs) architecture and techniques for training them. Artificial neural networks (ANNs) are represented as directed graphs with artificial neurons connected by edges, inspired by biological neural networks. Feed forward networks (FFNs) are a type of ANNs with units connected in a single direction. Multi-layer perceptron (MLP) is a subset of FFNs with input, hidden, and output layers, allowing for increased complexity with more hidden layers. Multi-layer perceptron (MLP) allows for increasing hidden layers based on data complexity. The network consists of acyclic graph units passing signals forward. MLP is represented as O: Rp \u00d7 Rq, with input vector x and output vector O(x). Computation of hidden layers can be mathematically formulated. Rectified linear units (ReLU) are efficient for training acceleration. Selecting ReLU reduces training time significantly. When training vast amounts of data, using ReLU is more efficient due to its speed and advantages over traditional activation functions. TensorFlow with Keras is used as the software framework, along with GPU-enabled TensorFlow for faster computations. Deep learning architectures are trained using back propagation through time (BPTT) technique. Task 1 involves classifying Android malware using a dataset of unique API information from APK files collected from the Opera Mobile Store. Task 2 involves analyzing operational log files from Unified Threat Management (UTM) of UniteCloud BID25, a private cloud infrastructure providing e-learning and e-research services in New Zealand. The log files contain information on the real-time running system for UniteCloud server. The log files for UniteCloud server contain operational measurements of 9 sensors in the UTM system. The dataset for Fraud Detection task was anonymized using HCRUD approach. Experimentation showed that a learning rate of 0.1 achieved the highest accuracy in 10-fold cross validation. The experiments showed that higher accuracy was achieved with learning rates of 0.35, 0.45, and 0.45 compared to 0.1. Running experiments for 1000 epochs enhanced accuracy. More complex architectures performed poorly within 500 epochs, so a learning rate of 0.1 was used for subsequent experiments. Various network topologies were tested, including DNNs with 1 to 5 layers, each run for 2 trials up to 500 epochs. Most architectures learned normal category patterns within 600 epochs, while learning malicious category data varied. The experiments showed that more complex architectures required a large number of iterations to achieve best accuracy. The best performing network topology for each use case included 4 layer DNNs for Task 2 and Task 3, and 5 layer DNNs for Task 1. The 10-fold cross validation accuracy of each DNNs network topology is shown in TAB0. The proposed DNNs architecture, Deep-Net, consists of an input layer with varying neuron counts for each task, 5 hidden layers, and an output layer with different neuron counts for each task. The proposed DNN architecture includes fully-connected layers, batch normalization, and dropout layers to prevent overfitting and speed up training. Fully-connected layers map data into high dimensions for accurate output determination, using ReLU as the activation function. Dropout (0.01) and Batch Normalization are used between fully-connected layers. In alternative architectures for Task 1, deep networks risk overfitting without regularization. Classification involves final fully connected layers with different activation functions for each task. Prediction loss is estimated using binary cross entropy for Task 1 and Task 2, and categorical cross entropy for Task 3. The study evaluates DNN models using categorical-cross entropy and sgd optimizer on three cyber security use cases: Android malware identification, incident detection on UniteCloud, and fraud detection in financial transactions. Input matrices of different shapes are passed to multiple hidden layers, with varying output neuron configurations for each task. XGBoost is explained as Extreme Gradient Boosting. XGBoost, short for Extreme Gradient Boosting, is based on the Gradient Boosting model. It is used for supervised learning tasks like classification, with a max depth of 20 for the tree. Data is loaded using Pandas, with NaN values replaced by 0. In Task 1, data is represented as a term-document matrix using scikit-learn's count vectorizer. The data is then fed to XG Booster for prediction. The winner of CDMC 2017 achieved high accuracy on Task 1, Task 2, and Task 3 using Random Forest classifier with Python scikit-learn BID11. The proposed method outperformed the winner on Task 2 and DNNs showed good performance in cyber security use cases. DNNs outperform classical machine learning classifiers in all use cases and can be further improved by adding more layers. This direction will be pursued in future work."
}