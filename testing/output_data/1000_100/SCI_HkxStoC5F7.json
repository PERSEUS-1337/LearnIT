{
    "title": "HkxStoC5F7",
    "content": "The paper introduces a new framework called ML-PIP for data efficient and versatile learning. It extends existing probabilistic interpretations of meta-learning and introduces \\Versa{}, which uses a flexible amortization network for few-shot learning. This framework substitutes optimization at test time with forward passes through inference networks, reducing the need for second derivatives during training. The paper introduces \\Versa{}, a new framework for few-shot learning that achieves state-of-the-art results on benchmark datasets. It demonstrates the ability to handle arbitrary numbers of shots and classes at train and test time, and showcases its power through a challenging few-shot ShapeNet view reconstruction task. The framework aims to address the need for flexible, data-efficient learning in various applications requiring predictions on small, related datasets. In this paper, a new framework called ML-PIP is developed for meta-learning approximate probabilistic inference for prediction. The framework extends existing point-estimate probabilistic interpretations of meta-learning to cover a broader class of methods, incorporating shared statistical structure between tasks and sharing information between tasks for learning and inference. The framework ML-PIP is developed for meta-learning approximate probabilistic inference for prediction. A new method called VERSA is proposed, which substitutes optimization procedures at test time with forward passes through inference networks, resulting in faster test-time performance. VERSA employs a flexible amortization network that can handle arbitrary numbers of shots and classes at train and test time. The framework ML-PIP introduces VERSA, a method for meta-learning probabilistic inference. VERSA utilizes a multi-task probabilistic model with shared parameters to maximize predictive performance on various tasks. The framework ML-PIP introduces VERSA, a method for meta-learning probabilistic inference. It focuses on meta-learning fast and accurate approximations to the posterior predictive distribution for unseen tasks. The approach involves using point estimates for shared parameters and distributional estimates for task-specific parameters in few-shot learning scenarios. The framework ML-PIP introduces VERSA, a method for meta-learning probabilistic inference. It focuses on quickly approximating the posterior predictive distribution for new tasks by using point estimates for shared parameters and distributional estimates for task-specific parameters in few-shot learning scenarios. The approach involves learning an amortized distribution through an inference network to efficiently predict test outputs. The method VERSA introduces meta-learning for probabilistic inference, focusing on approximating posterior predictive distributions for new tasks efficiently. It involves learning an amortized distribution through an inference network to predict test outputs quickly. The approximate posterior predictive distribution is meta-learned by minimizing the KL-divergence between true and approximate distributions. Training aims to minimize the KL divergence over tasks by finding parameters that approximate the posterior predictive distribution. The process involves selecting a task, sampling training data, forming the posterior predictive, and computing the log-density. This meta-learning approach supports accurate prediction through approximate inference. The training procedure focuses on optimizing the posterior predictive distribution by minimizing KL divergence. It involves end-to-end stochastic training with shared parameters to maximize predictive performance. The objective function directly targets the posterior predictive distribution, different from standard variational inference methods. The training procedure involves end-to-end stochastic training with shared parameters to maximize predictive performance. The approach developed is for Meta-Learning Probabilistic Inference for Prediction (ML-PIP), utilizing episodic train/test splits at meta-train time and approximating the integral over \u03c8 using Monte Carlo samples. The learning objective does not require an explicit specification of the prior distribution over parameters, learning it implicitly through q \u03c6 (\u03c8|D, \u03b8) instead. The training procedure involves end-to-end stochastic training with shared parameters to maximize predictive performance for Meta-Learning Probabilistic Inference for Prediction (ML-PIP). Section 5.1 provides a simple investigation of the inference method with synthetic data. The ML-PIP framework supports versatile learning, enabling rapid and flexible inferences using deep neural networks. Rapid inference involves simple computation at test time, while flexibility allows for various tasks without retraining. The amortization network processes sets of variable size with permutation-invariant instance-pooling operations. For few-shot image classification, a shared feature extractor feeds into task-specific linear classifiers. The amortization network processes sets of variable size with permutation-invariant instance-pooling operations for few-shot image classification. It specifies the approximate posterior distribution over weight matrices in a context-independent manner, allowing for metalearning without pre-specifying the number of few-shot classes. The amortization network operates on extracted features to reduce learned parameters and construct a classification matrix for few-shot image classification. Context-independent inference is used as an approximation, supported by theoretical and empirical justification. The context-independent approximation in Density Ratio Estimation BID36 BID49 allows for a more efficient inference network with fewer parameters. This approach addresses the limitations of naive amortization and can handle varying numbers of classes at test-time. VERSA is applied to few-shot image reconstruction tasks involving complex output spaces. Our generative model involves a multi-output regression task using a latent vector and angle representation to produce images at specified orientations. The generator network's parameters are considered global, while the latent inputs are task-specific. Gaussian likelihood is used for the generator outputs, with a sigmoid activation to ensure output means are between zero and one. An amortization network processes image representations of an object. The text discusses an amortization network that processes image representations of an object and concatenates them with view orientations before instance-pooling. It shows how ML-PIP unifies various meta-learning approaches and compares them to VERSA. Meta-Learning involves task-specific parameters in a neural network, with a point estimate formed by gradient ascent of the training loss. This is an example of semi-amortized inference, where optimization is required for each task. The perspective of semi-amortized ML-PIP complements Model-agnostic meta-learning, providing insight into the update choice and amortization process. VERSATILE (VERSA) is a method that is distributional over \u03c8 and simplifies inference by treating both local and global parameters. It avoids back-propagation through gradient-based updates during training and enables the computation of gradients at test time. This approach involves task-specific parameters in a neural network, with a point estimate formed by averaging top-layer activations for each class. The predictive distribution recovers prototypical networks using a Euclidean distance function. BID43 proposed a method for predicting weights of classes from activations of a pre-trained network to support online learning on a single task with new few-shot classes and transfer to low-shot classification tasks. This utilizes hyper-networks BID17 and can be recovered by the ML-PIP framework through pre-training \u03b8 and performing MAP inference for \u03c8. The text discusses end-to-end training and full multi-task learning by sharing information between tasks. Conditional models are trained via maximum likelihood, with an amortization network used for task-specific parameters. A comparison is made to Variational Inference, highlighting differences in optimization methods. In contrast to ML-PIP, VERSA does not use meta train/test splits and incorporates KL for regularization. It outperforms standard VI in few-shot classification and is evaluated on various tasks including toy experiments, Omniglot, miniImageNet datasets, and ShapeNet objects. An experiment is conducted to analyze the amortized posterior inference achieved by VERSA. In an experiment conducted by our training procedure, data is generated from a Gaussian distribution with varying means across tasks. T = 250 tasks are generated with N \u2208 {5, 10} train observations and M = 15 test observations. An inference network q \u03c6 (\u03c8|D) is introduced for amortized inference. The learnable parameters \u03c6 = {w \u00b5 , b \u00b5 , w \u03c3 , b \u03c3 } are trained using Adam BID25 with mini-batches of tasks. The model is trained to convergence, and posterior distributions are inferred for unseen test sets using the learned amortization parameters. The true posterior over \u03c8 is Gaussian with a task-dependent mean. The evaluation of VERSA on few-shot classification tasks shows accurate recovery of posterior distributions over \u03c8. VERSA is compared to previous work on Omniglot and miniImageNet datasets, following established experimental protocols. The approximate posterior closely resembles the true posterior for both five and ten shot scenarios. The study evaluates VERSA on few-shot classification tasks, showing accurate recovery of posterior distributions over \u03c8. Training is done episodically, with k c examples used for training inputs. Results for VERSA and competitive approaches are detailed in TAB1, excluding those using pre-training or residual networks. Details on data preparation and network architectures are provided in Appendix D. VERS achieves state-of-the-art results on 5-way -5-shot miniImageNet and 20-way -1 shot Omniglot benchmarks using a convolution-based network architecture. It also performs competitively on other benchmarks. VERSA adapts only the weights of the top-level classifier for new tasks, outperforming methods that adapt all learned parameters. Our inference procedure, VERSA, outperforms amortized VI and non-amortized VI in terms of log-likelihood and accuracy. VERSA substantially improves over amortized VI due to VI's tendency to under-fit, especially for small datasets. Non-amortized VI improves performance but is slower in forming the posterior. VERSATILITY: VERSA significantly reduces the number of iterations needed for initialization compared to VERSA. It allows flexibility in varying the number of classes and shots during training and testing. VERSA shows high accuracy across different conditions, demonstrating robustness and efficiency. For example, a model trained for 20-way, 5-shot can handle 100-way conditions with 94% accuracy. VERSA only requires forward passes through the network, making it efficient. The 5-shot miniImageNet trained model using MAML took 302.9 seconds, while VERSA only took 53.5 seconds on a NVIDIA Tesla P100-PCIE-16GB GPU, showing a more than 5\u00d7 speed advantage for VERSA. VERSA also outperformed MAML in accuracy by 4.26%. The dataset used for experiments consisted of 37,108 objects from 12 object categories in ShapeNetCore v2 BID5. VERSA was evaluated against a conditional variational autoencoder (C-VAE) with similar architectures. VERSATILE (VERSA) is trained episodically on 12 object classes, generating detailed and sharp images compared to C-VAE. VERSA can accurately impute missing information from occluded views, outperforming C-VAE in quantitative metrics. VERSA outperforms C-VAE in quantitative metrics, showing superiority with varying shot numbers. ML-PIP is introduced as a meta-learning framework, leading to the development of VERSA, a few-shot learning algorithm with state-of-the-art performance. The Prototypical Networks demonstrate state-of-the-art performance on a challenging 1-shot view reconstruction task. When trained on 20-way classification and tested on 5-way, the model achieves 68.20 \u00b1 0.66%. The new inference framework presented is based on Bayesian decision theory, providing a recipe for making predictions for unknown test variables by combining information from observed training data and a loss function. The text discusses Bayesian decision theory (BDT) and its application in meta-learning probabilistic inference. It introduces a derivation of a stochastic variational objective for meta-learning that focuses on returning a full predictive distribution over unknown test variables. This approach aims to quantify the quality of the predictive distribution through a distributional loss function. The optimal predictive distribution q* is determined by minimizing expected distributional loss within a distributional family Q. Amortized variational training involves forming quick predictions at test time using shared variational parameters \u03c6. The variational parameters are optimized by minimizing expected distributional loss across tasks. The procedure involves stochastically approximating Eq. (A.3) by sampling tasks and partitioning data, without computing the true predictive distribution. It focuses on meta-learning and inferring predictive distributions from training tasks using log-loss. Eq. (A.4) shows that the optimal q \u03c6 is the closest to the true predictive p(\u1ef9|D) in a KL sense, similar to the wake-sleep algorithm's sleep phase. The approximate predictive distribution q \u03c6 is derived in this section through density ratio estimation, showing the optimal softmax classifier's construction of estimators for class conditional densities. The optimal classifier constructs estimators for conditional densities for each class independently, similar to training a naive Bayes classifier. The context-independent assumption is evaluated through a simple experiment to examine if weights may be context-independent without imposing the assumption on the amortization network. In an experiment, free-form variational inference is performed on weights for different tasks using a Gaussian distribution. The model achieves 99% accuracy on test examples and t-SNE plot shows similarity in weights distribution for different classes. The t-SNE plot illustrates how class weights cluster in 2-dimensional space, with some overlap between classes. For tasks containing both class '1' and '2', the weights for class '2' are located away from their cluster. This suggests that class weights are typically independent of the task, but the model may struggle to assign them properly in cases where classes overlap. A VI-based objective is derived for the probabilistic model using \"amortized\" VI. The VI-based objective for the probabilistic model is derived using \"amortized\" VI, where q \u03c6 (\u03c8|D (t) , \u03b8) is parameterized by a neural network with fixed-sized \u03c6. The objective function remains the same for \"non-amortized\" VI, which optimizes local parameters \u03c6 (t) independently for each new task. An evidence lower bound (ELBO) for a single task t can be expressed, and a stochastic estimator is derived to optimize it by sampling D (t) \u223c p(D) and performing Monte Carlo integration over \u03c8. The objective function in Eq. (4) differs from Eq. (C.2) in that it does not contain a KL term for q \u03c6 (\u03c8|D (t) , \u03b8) and does not distinguish between training and test data. In this section, details on few-shot classification experiments are provided using the Omniglot dataset. The dataset consists of 1623 handwritten characters from 50 alphabets, with training, validation, and test sets split accordingly. Training involves episodic C-way, k c -shot classification with augmented character classes. During training, episodic C-way, k c-shot classification is conducted with random selection of classes. Validation set is used for monitoring progress and model selection. Final evaluation is done on 600 randomly selected tasks. Adam BID25 optimizer with a constant learning rate of 0.0001 is used. Different models are trained for varying iterations based on shot and way configurations. The miniImageNet dataset consists of 60,000 color images divided into 100 classes. Training is done episodically with Adam optimizer and Gaussian form for q. Different models are trained for varying iterations based on shot and way configurations. The feature extraction network \u03b8 is similar to BID54, while the amortization network \u03c6 provides Gaussian parameters for the linear classifier \u03c8. The local-reparameterization trick is used for sampling weight distributions, and the feature extraction network is shared with the amortization network to reduce parameters. The feature extraction network used for miniImageNet few-shot learning consists of multiple convolutional layers with dropout and pooling. Batch Normalization is applied with a keep probability of 0.5 throughout the network. The network architecture includes convolutional layers with different sizes and strides, followed by dropout and pooling layers. The output size of the network is 256. For ShapeNet experimentation, a dataset of 37,108 objects from 12 categories is used. Objects are represented by 128x128 pixel views converted to grayscale and resized to 32x32 pixels. The model is trained episodically with 70% for training, 10% for validation, and 20% for testing. The model is trained episodically on a dataset of 37,108 objects from 12 categories represented by 32x32 pixel views. Training iterations consist of batches of tasks, with objects randomly selected for each task. Views are generated using an amortization network, and quantitative metrics are computed over the test set. The network architectures for the encoder, amortization, and generator networks are described in Tables E.2 to E.4. Training is done with the Adam optimizer using a constant learning rate of 0.0001 for 500,000 iterations. The ShapeNet Encoder Network (\u03c6) has specific layer sizes and operations, with parameters set to d \u03c6 = 256, d \u03c8 = 256, and 1 sample for \u03c8. The network consists of multiple convolutional and pooling layers, followed by fully connected layers with RELU activation."
}