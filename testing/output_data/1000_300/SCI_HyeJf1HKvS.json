{
    "title": "HyeJf1HKvS",
    "content": "This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs. It uses localized node embeddings computed by a graph neural network to rank soft correspondences between nodes initially. Synchronous message passing networks are then employed to iteratively re-rank the soft correspondences and reach a matching consensus in local neighborhoods between graphs. The message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, guiding the re-ranking process. The architecture scales well to large inputs and consistently recovers global correspondences. The method is effective in tasks such as computer vision and entity alignment between knowledge graphs. Graph matching involves establishing structural correspondences between nodes in graphs by considering node and edge similarities. This is crucial for various real-world applications like comparing molecules, matching protein networks, linking user accounts, and tracking objects. The proposed neural architecture effectively learns and refines these correspondences, demonstrating practical effectiveness in tasks such as computer vision and entity alignment between knowledge graphs. Graph matching is essential for various applications like comparing molecules, matching protein networks, linking user accounts, and tracking objects. The problem has been extensively studied in theory and practice, often related to distances like graph edit distance and maximum common subgraph problem. However, solving graph matching optimally is challenging for large-scale instances due to its NP-hard nature. Combinatorial approaches may not adapt well to data distribution. Various neural architectures have been proposed to tackle graph matching or graph similarity in a data-dependent fashion. However, existing approaches have limitations such as only computing similarity scores between whole graphs, relying on inefficient global matching procedures, or not generalizing to unseen graphs. Existing approaches to graph matching have limitations such as only computing similarity scores between whole graphs, relying on inefficient global matching procedures, or not generalizing to unseen graphs. Graph matching is typically formulated as an edge-preserving, quadratic assignment problem based on finding correspondences through neighborhood consensus to prevent adjacent nodes from being mapped to different regions in the target graph. Neighborhood consensus is used to prevent adjacent nodes in the source graph from being mapped to different regions in the target graph. The problem of supervised and semi-supervised graph matching is addressed by incorporating this concept as an inductive bias into the model. In the supervised setting, pair-wise ground-truth correspondences are given for a set of graphs to generalize to unseen pairs. In the semi-supervised setting, ground-truth correspondences are only provided for a small subset of nodes, but complete graph structures can be utilized. The proposed approach is an end-to-end, deep graph matching model. The proposed deep graph matching architecture consists of two stages: a local feature matching procedure and an iterative refinement strategy using synchronous message passing networks. The feature matching step computes initial correspondence scores based on the similarity of local node embeddings, while the iterative refinement strategy aims to reach neighborhood consensus for correspondences using a differentiable validator for graph isomorphism. The method is scalable to large, real-world inputs. The deep graph matching architecture includes a two-stage process: local feature matching and iterative refinement using synchronous message passing networks. The refinement strategy aims to achieve neighborhood consensus for correspondences by utilizing a differentiable validator for graph isomorphism. The method is scalable to handle large, real-world inputs. The deep graph matching architecture involves local feature matching based on pair-wise color differences. Similarities between nodes in the source and target graphs are computed using node embeddings. Sinkhorn normalization is applied to obtain initial soft correspondences, interpreted as discrete distributions over potential correspondences. The neural network is trained in a supervised manner against ground truth correspondences. The deep graph matching architecture involves training a Graph Neural Network (GNN) to obtain localized node representations for potential correspondences in the source and target graphs. The GNN follows a neural message passing scheme to update node features in each layer, utilizing operators from geometric deep learning and relational representation learning. The recent work in geometric deep learning and relational representation provides various operators for updating node features in a Graph Neural Network. The feature matching procedure is susceptible to false correspondences due to the local nature of node embeddings, leading to violations of neighborhood consensus criteria. To address this, violations are detected in local neighborhoods using graph neural networks and resolved iteratively. The proposed algorithm aims to detect violations of neighborhood consensus criteria in local neighborhoods using graph neural networks. It iteratively refines correspondences starting from an initial matrix S (0). The soft correspondence matrix S is used to pass node functions between domains, allowing for the mapping of node indicator functions from one graph to another. The consensus method involves mapping node indicator functions between graphs using a shared graph neural network. Synchronous message passing is performed to measure neighborhood consensus between nodes, allowing for trainable updates of correspondence scores. This iterative process aims to improve consensus in local neighborhoods by combining feature matching error and neighborhood consensus error. The objective is fully differentiable and can be optimized using stochastic gradient descent. The consensus stage in the process involves iteratively improving consensus in local neighborhoods by combining feature matching error and neighborhood consensus error. This objective is fully differentiable and can be optimized using stochastic gradient descent. The method distributes global node colorings to resolve ambiguities and false matchings using purely local operators. The importance of the two-stage approach is highlighted as an initial matching is needed to test for neighborhood consensus. The method involves improving consensus in local neighborhoods by combining feature matching error and neighborhood consensus error. The GNN \u03a8 \u03b82 provides equal node embeddings for isomorphic graphs and satisfies permutation equivariance and injectivity criteria. Common GNN architectures are equivariant due to permutation invariant neighborhood aggregators. The method combines feature matching error and neighborhood consensus error to improve consensus in local neighborhoods. GNN architectures fulfill permutation equivariance and injectivity criteria, with the use of sum aggregation and MLPs on neighboring node features. The approach is related to classical graph matching techniques, such as the graduated assignment algorithm. Our proposed approach relates to classical graph matching techniques like the graduated assignment algorithm. It involves iteratively computing new solutions by solving a linear assignment problem and implementing the softassign operator with sinkhorn normalization. The gradient Q is closely linked to a neighborhood consensus scheme in a simple, non-trainable GNN instantiation. Our approach involves using trainable neural networks to update correspondence scores in graph matching, allowing for the interpretation of our model as a deep parameterized generalization of the graduated assignment algorithm. Additionally, our method supports continuous node and edge features through established GNN models, providing benefits over traditional approaches that struggle with specifying attribute similarities. Our approach involves using trainable neural networks to update correspondence scores in graph matching, supporting continuous node and edge features through established GNN models. We propose sparsifying initial correspondences before neighborhood consensus, reducing memory footprint and refining time complexity. The approach involves using the KEOPS library to reduce memory footprint and refine time complexity in graph matching. This includes sparsifying initial correspondences and optimizing feature matching loss. Additionally, node indicator functions are replaced with randomly drawn node functions for computational efficiency. In graph matching, node indicator functions are replaced with randomly drawn node functions for computational efficiency. Softmax normalization is used to fulfill the requirements of doubly-stochastic solutions. In graph matching, softmax normalization is used to achieve doubly-stochastic solutions. The proposed approach relaxes constraints by applying row-wise softmax normalization, allowing for natural resolution of violations and convergence to the correct solution. The number of refinement iterations can vary to improve efficiency. The proposed approach relaxes constraints in graph matching by using row-wise normalization for convergence. Varying the number of refinement iterations improves efficiency during training and testing. The method is validated on synthetic and real-world tasks, demonstrating its benefits in keypoint matching in natural images. Our method is validated on synthetic and real-world tasks, including supervised keypoint matching in natural images and semi-supervised cross-lingual knowledge graph alignment. Implementation is in PYTORCH using PYTORCH GEOMETRIC and KEOPS libraries for efficient processing with GPU acceleration. Optimization is done via ADAM with a fixed learning rate. Hits@k is used to evaluate and compare the model performance. In experiments, optimization is done via ADAM with a fixed learning rate. Hits@k is used to evaluate model performance on synthetic graphs with different configurations. The target graph G t is constructed from G s by removing edges with probability p s without disconnecting any nodes. Training and evaluation are done on 1,000 graphs for different p s values. Additional experiments in Appendix E test the approach's robustness towards node addition or removal. The graph neural network operators \u03a8 \u03b81 and \u03a8 \u03b82 are implemented with three layers of the GIN operator. Input features are initialized with one-hot encodings of node degrees, and final node representations are computed using Jumping Knowledge style concatenation. Training and testing are done using ADAM optimization with fixed learning rate, and model performance is evaluated using Hits@k on synthetic graphs. The target graph G t is constructed from G s by removing edges with probability p s without disconnecting any nodes. Training and evaluation are done on 1,000 graphs for different p s values. The graph neural network operators \u03a8 \u03b81 and \u03a8 \u03b82 are implemented with three layers of the GIN operator. Input features are initialized with one-hot encodings of node degrees, and final node representations are computed using Jumping Knowledge style concatenation. Training and testing are done using ADAM optimization with fixed learning rate, and model performance is evaluated using Hits@k on synthetic graphs. The proposed two-stage architecture can recover all correspondences, independent of the applied structural noise p s. The architecture can recover all correspondences, regardless of structural noise. It includes an initial formulation and an optimized version using random node indicator sampling and row-wise normalization. The enhancements made towards scalability justify the benefits of matching consensus. The refinement strategy performs well on sparsified correspondences, converging even when training does not. The refinement strategy performs well on sparsified correspondences, converging to the perfect solution with increasing k. Experiments were conducted on PASCALVOC and WILLOW-OBJECTCLASS datasets, demonstrating the scalability of the algorithm. The PASCALVOC dataset contains annotated images with keypoint locations, filtered to exclude difficult objects. The WILLOW-OBJECTCLASS dataset has images with consistent orientations and 10 keypoints each. The model is pre-trained on PASCALVOC and fine-tuned on 20 random splits for 20 per-class images. The model is pre-trained on PASCALVOC and fine-tuned on 20 random splits with 20 per-class images used for training. Graphs are constructed via Delaunay triangulation of keypoints, and input features are obtained from a pre-trained VGG16 model. The architecture includes a SPLINECNN graph neural network operator with trainable B-spline based kernel function. Isotropic and anisotropic evaluations are conducted to align results with related work. The SPLINECNN model includes a graph neural network operator with a trainable B-spline based kernel function conditioned on edge features. Isotropic and anisotropic evaluations are conducted using normalized relative distances and 2D Cartesian coordinates for edge features. The SPLINECNN model utilizes edge features as normalized relative distances and 2D Cartesian coordinates. It employs a kernel size of 5, a hidden dimensionality of 256, ReLU as the non-linearity function, and consists of two convolutional layers followed by dropout. Training involves forming pairs between examples of the same category and evaluating the model with test graph pairs. The model is trained using negative log-likelihood for superior performance. The study evaluates the performance of their model using isotropic and anisotropic GNNs for different values of L, and includes ablation results using MLP for local node matching. Results show significant improvement over competing methods and non-refined baselines, with the refinement stage reducing errors by half on the WILLOW-OBJECTCLASS dataset. Our refinement stage significantly improves model performance on various datasets, reducing errors by half on the WILLOW-OBJECTCLASS dataset and up to 14 percentage points on PASCALVOC. Initial good matchings enhance consensus stage performance, utilizing task-specific isotropic or anisotropic GNNs. The model's generalization capabilities are tested on the PASCALPF dataset, demonstrating effectiveness in geometric feature matching without additional visual features. The experimental training setup follows Zhang & Lee (2019) and tests model generalization on the PASCALPF dataset. Synthetic graph pairs are generated for training with added noise and outliers. The unmodified anisotropic keypoint architecture is trained until 32,000 examples are seen. Evaluation on the PASCALPF dataset shows Hits@1 results in Table 3. Our trained model is evaluated on the PASCALPF dataset, consisting of 1,351 image pairs across 20 classes with varying numbers of keypoints. Results show improvement over previous state-of-the-art results in almost all categories. Additionally, our method performs well even without visual information. The model is also tested on the DBP15K datasets, linking entities from Chinese, Japanese, and French knowledge graphs to the English version. The DBP15K datasets link entities from Chinese, Japanese, and French knowledge graphs to the English version. Each dataset contains 15,000 links split into training and testing sets. Entity input features are obtained using monolingual FASTTEXT embeddings, aligned into the same vector space. The graph neural network operator architecture mostly matches previous works, using ReLU followed by dropout with probability 0.5. The graph neural network operator architecture matches previous works, using ReLU followed by dropout with probability 0.5. Training is performed using negative log likelihood in a semi-supervised fashion, with a three-layer GNN for obtaining initial similarities and refining alignments. Hits@1 and Hits@10 are reported as results. In the refinement phase, the sparse correspondence matrix is updated 10 times for efficiency. Results show that the model outperforms previous works, with improvements of up to 9.38 percentage points. Hits@1 significantly improves with the refinement strategy, while Hits@10 results are mixed due to operating on top 10 initial correspondences. The approach is scalable and shows promising results. Our refinement strategy significantly improves Hits@1 results by a large margin, while Hits@10 results are affected by operating on only the top 10 initial correspondences. The scalability of our approach allows for multiple refinement iterations with large hidden feature dimensionalities. Experimental results demonstrate the effectiveness of our approach in solving real-world problems. However, our method inherits limitations related to the expressive power of GNNs and the WL heuristic for graph isomorphism testing. One limitation is the potential failure to converge when two nodes are assigned the same color by WL. Identifying correspondences between nodes in graphs has been extensively studied in various domains. One limitation of current methods is the potential failure to converge when two nodes are assigned the same color by WL, leading to non-convergence. Resolving these ambiguities by adding noise to the initial correspondence distributions is theoretically possible but unlikely to occur due to the presence of feature noise in real-world datasets. Related problems include maximum common subgraph and network alignment. Identifying correspondences between nodes in graphs has been extensively studied in various domains. Related problems include maximum common subgraph and network alignment. Graph neural networks have become a focus of research, leading to proposed deep graph matching techniques. Our proposed graph matching consensus procedure utilizes a two-stage neural architecture to learn node correspondences between graphs in a supervised or semi-supervised manner. The approach aims to achieve a neighborhood consensus between matchings and can handle violations of this criteria iteratively. Enhancements have been made to scale the algorithm to large input domains, with evaluations on real-world datasets showing consistent improvements over existing methods. The final optimized algorithm is detailed in Algorithm 1. The proposed graph matching consensus procedure utilizes a two-stage neural architecture to learn node correspondences between graphs. The algorithm aims to achieve a neighborhood consensus between matchings and can handle violations of this criteria iteratively. It has been enhanced to scale to large input domains and has shown consistent improvements over existing methods on real-world datasets. The algorithm proposed for graph matching consensus utilizes a two-stage neural architecture to learn node correspondences between graphs. It extends the graduated assignment algorithm by introducing trainable parameters. The algorithm aims to achieve a neighborhood consensus between matchings and can handle violations of this criteria iteratively. The algorithm proposed for graph matching consensus extends the graduated assignment algorithm with trainable parameters. Using trainable neural networks consistently improves results compared to fixed-function message passing schemes. This approach can learn to utilize node and edge features for refining the matching procedure. Our approach for graph matching consensus extends the graduated assignment algorithm with trainable neural networks, allowing for the utilization of node and edge features to guide the refinement procedure. Experimental validation was conducted using synthetic experiments similar to previous work, demonstrating robustness towards node addition or removal. Our approach for graph matching consensus extends the graduated assignment algorithm with trainable neural networks, allowing for the utilization of node and edge features to guide the refinement procedure. The consensus stage is robust to node addition or removal, while the first stage struggles with finding the right matching due to unmatched nodes not influencing the neighborhood consensus error. The neural architecture detects and decreases false positive influence of these nodes in the refinement stage. The problem of identifying correspondences between nodes of two graphs is studied in graph theory, specifically the maximum common subgraph isomorphism problem. This problem is NP-hard and difficult to approximate with guarantees. Various variants of the problem have been explored, with exact polynomial-time algorithms available for specific instances. The problem of identifying correspondences between nodes of two graphs is studied in graph theory. Most variants of the problem are difficult to approximate with guarantees. Different techniques have been developed in bioinformatics and computer vision for network alignment or graph matching. In graph matching, the goal is to minimize a function for two graphs with adjacency matrices. In graph matching, the goal is to minimize a function for two graphs with adjacency matrices. The problem involves minimizing Equation (12) using a Frank-Wolfe type algorithm and projecting the fractional solution to P. The applicability of relaxation and projection is still poorly understood with few theoretical results available. The WL heuristic distinguishes graphs using relaxation and projection to obtain the WL partition. Various studies have explored the applicability of relaxation and projection in graph matching, with different approaches based on spectral properties and complexity. The problem of graph matching is closely related to the quadratic assignment problem (QAP), which has been studied for decades. Recent literature considers a weighted version, incorporating node and edge similarities, leading to Lawler's QAP formulation. Zhou & De la Torre (2016) proposed factorizing the affinity matrix for computational efficiency. In Lawler's QAP formulation, the affinity matrix is factorized for computational efficiency. Zhang et al. (2019c) explored kernelized graph matching using node and edge similarities as kernels. Swoboda et al. (2017) investigated Lagrangean decompositions of the graph matching problem solved by dual ascent algorithms for improved performance. Recently, Lagrangean decompositions of the graph matching problem solved by dual ascent algorithms have shown state-of-the-art performance. Functional representation for graph matching aims to avoid constructing the affinity matrix. The graph edit distance concept measures the cost to transform one graph into another by adding, deleting, and substituting vertices and edges, but its computation is NP-hard. The graph edit distance concept measures the cost to transform one graph into another by adding, deleting, and substituting vertices and edges. It is closely related to the maximum common subgraph problem and the quadratic assignment problem. Various algorithms have been proposed for computing the graph edit distance, with heuristics based on the assignment problem being widely used in practice. The original approach requires cubic running time, but this can be reduced to quadratic or even linear time with different strategies. Network alignment is a problem that involves computing an alignment between two graphs based on a similarity function. Algorithms typically involve computing a similarity matrix and then solving the assignment problem. ISORANK, proposed by Singh et al. (2008), uses the adjacency matrix of the product graph and applies PAGERANK to compute the alignment. Kollias et al. (2012) also contributed to this area. The matrix M is obtained by applying PAGERANK using a normalized version of the product graph K as the GOOGLE matrix and node similarities as the personalization vector. Various techniques have been proposed for network alignment, including an efficient approximation of ISORANK by decomposition techniques, an extension supporting vertex and edge similarities, and a message passing algorithm for sparse network alignment. These techniques aim to find an optimal alignment between two graphs. In network alignment, message passing algorithms like the one by Bayati et al. (2013) aim to find optimal correspondences between graphs. Recent approaches involve learning node and edge similarity functions for specific tasks, such as graph edit distance cost models (Cort\u00e9s et al., 2019). Caetano et al. (2009) proposed a method to learn correspondences in a more principled manner. Deep graph matching procedures explore various perspectives, including local node feature matchings and cross-graph embeddings. The method presented in this work explores deep graph matching procedures, refining local feature matchings by enforcing neighborhood consistency. Recent research has heavily investigated graph matching in a deep fashion, with supervised deep graph matching networks developed based on displacement and combinatorial objectives. In contrast to existing approaches, our fully-learnable method refines local feature matchings by enforcing neighborhood consistency in deep graph matching procedures. Wang et al. (2019b) and Zhang & Lee (2019) utilize different strategies such as node-wise features with dense node-to-node affinities and compositional message passing, respectively, but fail to address inconsistent neighborhood assignments like our approach does. Our approach refines local feature matchings by enforcing neighborhood consistency in deep graph matching procedures, unlike existing methods. Xu et al. (2019b) relate graph matching to Gromov-Wasserstein discrepancy and enhance the optimal transport objective by learning node embeddings. They extend this concept to multi-graph partitioning and matching. Our supervised approach generalizes to unseen graph instances and resembles optimal transport between nodes. Network alignment has also been explored from various perspectives, such as by Derr et al. (2019). The task of network alignment has been investigated from multiple perspectives. Different methods have been used, such as leveraging CYCLEGANs to align NODE2VEC embeddings and utilizing graph neural networks to approximate the graph edit distance between two graphs. Bai et al. proposed various approaches, including a deep graph model based on global and local network topology preservation and a fast, local, and greedy matching procedure based on node embedding similarity. Bai et al. (2019) utilize shared graph neural networks to approximate graph edit distance between graphs. They use a histogram of correspondence scores to fine-tune the network output. In a follow-up work, they propose ordering the correspondence matrix in a breadth-first-search manner and processing it with traditional CNNs. Wang et al. (2019b) and Xu et al. (2019d) enhance GNN operators by aggregating information from local neighbors and similar embeddings in the other graph through cross-graph matching. In their work, Wang et al. (2019b) and Xu et al. (2019d) improve GNN operators by aggregating information from local neighbors and similar embeddings in the other graph through cross-graph matching. Wang & Solomon (2019) address the unknown rigid motion problem by relating it to a point cloud matching issue and using a differentiable SVD module. They pass intra-graph node embeddings through a Transformer module before conducting feature matching based on inner product similarity scores. These methods can enhance the initial feature matching process. Neighborhood consensus methods in computer vision have a history of improving local feature matching results efficiently. A recent approach using 4D convolution for neighborhood consensus was proposed, but it cannot be directly applied to the graph domain. The 4D convolution method for neighborhood consensus in computer vision cannot be efficiently transferred to the graph domain due to computational complexity. Our algorithm infers errors on the product graph but performs computations on the original graphs, utilizing the functional maps framework for continuous maps between function spaces on manifolds."
}