{
    "title": "HJcjQTJ0W",
    "content": "To enable cloud-based DNN training while protecting data privacy, the proposed method leverages intermediate representations of data by splitting DNNs between local platforms and the cloud. The local NN generates feature representations from pre-trained NNs, avoiding local training to protect data privacy. The cloud NN is then trained using these intermediate representations for the target learning task. The idea of DNN splitting is validated by analyzing the relationship between privacy loss and classification accuracy based on the local NN topology. PrivyNet optimizes local NN topology for target learning tasks with constraints on privacy loss, computation, and storage. It is demonstrated with CIFAR-10 dataset, addressing the challenge of computationally intensive training on local platforms by leveraging cloud-based services. Cloud-based services offer an alternative for deep model training due to the computational intensity on local platforms, but they rely on excessive user data collection, posing privacy risks. To address this, different data pre-processing schemes are proposed where transformed representations are generated locally and uploaded for learning tasks, ensuring both utility and privacy requirements are met. The intermediate representations for target learning tasks must meet utility and privacy requirements. The transformation scheme should be flexible for different platforms and data types. Privacy and utility trade-off is a key focus in privacy research, with various measures proposed. In privacy research, different measures of privacy and utility are proposed based on rate-distortion theory, statistical estimation, and learnability. Various transformations have been suggested to explore the trade-off between privacy and utility, including syntactic anonymization methods like k-anonymity, l-diversity, and t-closeness. Differential privacy offers a formal privacy guarantee by adding noise to prevent adversaries from gaining additional knowledge. Differential privacy provides a formal privacy guarantee by adding noise to prevent adversaries from gaining additional knowledge. Existing methods for achieving differential privacy often involve local platforms in the process, making deployment on lightweight platforms challenging. Linear and non-linear transformations are also used for data anonymization, with linear transformations relying on covariance or linear discriminant analysis for filtering training data. However, linear transformations may offer limited privacy protection. PrivyNet is a DNN training framework that offers better privacy protection than existing linear transformations. It utilizes nonlinear transformations like minimax filter or Siamese networks, but can only be applied in the inference stage due to the need for an iterative training scheme. The framework consists of a local NN for feature extraction and a cloud NN for the learning task, with privacy and utility trade-off controlled by the local NN's topology. PrivyNet is a DNN training framework that divides a model into local and cloud parts for privacy protection. The local NN generates intermediate representations using non-linear transformations like convolution and pooling, while the cloud NN is trained based on these representations. The framework allows fine-grained control of the trade-off between privacy and utility. The local NN in PrivyNet utilizes non-linear transformations like convolution and pooling to extract general features from pre-trained NNs, enabling fine-grained control over privacy loss. The framework splits the DNN model for cloud-based training, balancing privacy and utility effectively. PrivyNet is a novel framework that splits DNN models for cloud-based training, balancing privacy and utility. It characterizes privacy loss and utility using CNN as the local NN, identifying key factors for the trade-off. A hierarchical strategy optimizes the local NN's topology considering computation, storage, and privacy constraints. The framework is validated using CNN-based image classification, demonstrating efficiency and effectiveness in leveraging pre-trained NNs for feature representation generation. The idea of using pre-trained neural networks for generating intermediate representations is validated through a detailed utility and privacy characterization. The process involves using a feature extraction network (FEN) from a pre-trained NN to generate feature representations, training an image classification network (ICN) based on these features, and training an image reconstruction network (IRN) to reconstruct original images. Utility is measured by the accuracy of the learning task, while privacy is assessed by the distance between reconstructed and original images. The IRN is trained assuming knowledge of original images and feature representations, but not the transformation (FEN). The IRN is trained with knowledge of original images and feature representations, but not the transformation (FEN). The transformation induced by the FEN is parameterized by the number of layers and filters selected for each layer. The transformation induced by the FEN is parameterized by the number of layers and filters selected for each layer. The output feature representations have a depth of D and a dimension of W \u00d7 H. Evaluating the utility involves learning a classifier with minimized empirical risk for the target learning task. Privacy considerations are also taken into account. The utility of the transformed representations is evaluated based on accuracy achieved by the classifier, while privacy is assessed using the peak signal-to-noise ratio (PSNR) of reconstructed images compared to the original ones. Larger PSNR indicates higher privacy loss. The impact of FEN topology on privacy and utility of transformed representations is characterized. FEN is derived from VGG16 and determined by factors like number of layers and output channels. Evaluation of these factors forms the basis for the PrivyNet framework. Architecture details of VGG16, ICN, and IRN are provided in the appendix. The FEN topology, influenced by the number of layers and output depth, is evaluated for its impact on privacy and utility in the PrivyNet framework. Changes in FEN layers and output depth affect privacy loss and accuracy differently, as shown in the plotted results. Smaller PSNR indicates less privacy loss with reduced output depth or increased FEN layers. In the PrivyNet framework, the FEN topology's impact on privacy and utility is evaluated. Changes in FEN layers and output depth affect privacy loss and accuracy differently. Smaller PSNR indicates less privacy loss with reduced output depth or increased FEN layers. Trade-off between accuracy and PSNR is shown in FIG2 (c), guiding the PrivyNet framework. In the PrivyNet framework, the impact of FEN topology on privacy and utility is assessed. Different FEN topologies show similar utility with high privacy loss and better utility with more layers and lower privacy loss. Channel selection also affects privacy and utility. Characterization of utility and privacy loss for each channel in a 4-layer FEN is shown in Figure 4 (a) and detailed statistics are provided in Table 4 (c). When evaluating the impact of FEN topology on privacy and utility in PrivyNet, different FEN topologies exhibit varying levels of utility and privacy loss. The characterization results for each channel in a 4-layer FEN are depicted in Figure 4 (a), with detailed statistics in Table 4 (c). The best channel achieves significantly higher utility and lower privacy loss compared to the worst channel, showing a large discrepancy. Similar trends are observed with 6 VGG16 layers in Figure 4 (b). Additionally, the impact of output channel selection is compared to the number of FEN layers and output depth, revealing varying effects on privacy and utility. The impact of output channel selection is compared with the number of FEN layers and output depth in PrivyNet. Privacy and utility depend more on the number of FEN layers and output channel depth than on output channel selection. Leveraging pre-trained CNN for FEN construction allows for exploring the trade-off between utility and privacy. In the context of leveraging pre-trained CNN for FEN construction and exploring the trade-off between utility and privacy, the key observations include controlling the FEN topology to optimize utility while considering privacy constraints, local computation capability, and storage. The trade-off between privacy and accuracy can be managed by adjusting the number of FEN layers and output channel depth in PrivyNet. Our framework, PrivyNet, optimizes utility under privacy, local computation, and storage constraints. Privacy characterization is done using cloud-based services, and NN performance profiling is conducted on local platforms. Our PrivyNet framework optimizes utility under privacy, local computation, and storage constraints. Privacy characterization is done using cloud-based services, and NN performance profiling is conducted on local platforms. The FEN topology is determined through supervised channel pruning based on private data. The assumption of availability of original images is necessary for worst-case scenarios. The output channels are randomly selected, and the FEN topology is determined. The assumption on the availability of original images is crucial for evaluating privacy loss. The attackers are assumed to be unaware of the FEN transformation to limit privacy loss. The FEN must remain unknown to attackers to prevent sophisticated image reconstruction mechanisms. Protecting the anonymity of the FEN, derived from pre-trained NNs, is crucial. The pre-characterization stage involves performance and storage profiling on local platforms and cloud-based privacy characterization for pre-trained NNs. Different platforms have varying computation capability and storage configurations, which impact the profiling process. Performance and storage characterization is conducted by profiling pre-trained NNs on local platforms, which is crucial due to the varying computation capability and storage configurations of different platforms. Privacy characterization for the NNs is achieved through cloud-based services, and the reconstruction network is trained on publicly available data of the same dimension and distribution. Experiments comparing PSNR for FEN with different topologies on datasets like CIFAR-10 and CIFAR-100 show similar results. In the study, privacy characterization for different datasets like CIFAR-10 and CIFAR-100 is compared by analyzing the PSNR for FEN with various topologies. Experiments show that less than 1000 samples are needed for an accurate characterization with data augmentation. The number of FEN layers and output channel depth have significant impacts on privacy and accuracy, leading to the determination of the topology for the FEN in PrivyNet. In PrivyNet, the topology for the FEN is determined based on the number of layers and output channel depth, considering constraints on local computation, storage, and privacy loss. When privacy requirements are high, a FEN with more layers is selected for better utility, following constraints on computation and storage. When privacy requirements are low, a shallow FEN is selected to achieve the required privacy level with less local computation and storage consumption. For example, choosing a shadow FEN with m = 1 and D = 4 can minimize local computation while still meeting the privacy loss requirement of 28 dB. After determining the number of layers and output depth for privacy requirements, the next step is to select output channels. Large discrepancies in utility and privacy are observed for a single channel, leading to variance in utility when changing layers or increasing output channel depth. Directly selecting output channels from the whole set can result in significant utility and privacy differences. When selecting output channels, there are significant differences in utility and privacy for a single channel. This variance can lead to poor utility with large privacy leakage, highlighting the need for channel pruning. The correlation between utility and privacy loss for a single channel is negligible, even when considering different output channel depths and FEN layers. This observation is crucial for decision-making. In channel pruning, the correlation between utility and privacy loss is negligible. To optimize utility while suppressing privacy loss, channels with the largest privacy loss are pruned using Fisher's LDA analysis. This analysis focuses on the effectiveness of output channels by considering the distance of representations generated for images within the same class. Fisher's LDA scheme measures the distance of representations for images within the same class and among different classes using the covariance matrix. It is effective in identifying ineffective channels in output representations. Fisher's LDA scheme evaluates the discriminability of output channels by computing between-class and within-class variances. By identifying channels with poor utility, they can be pruned to improve accuracy in the learning task. This method is effective in determining ineffective channels in output representations. The Fisher's discriminability is used to identify and prune channels with poor utility, improving accuracy in the learning task. The LDA-based supervised channel pruning algorithm effectively prunes 69.7% of the worst 32 channels, compared to only 50.3% with random pruning, resulting in a 33.5% reduction in the probability of obtaining a bad outcome. The LDA-based supervised pruning method effectively prunes 69.7% of the worst 32 channels, reducing the probability of selecting a bad channel by 33.5%. Varying the number of samples for pruning shows consistent results in channel selection. The computation complexity of the LDA-based pruning process scales proportionally. The experimental results show that the LDA-based supervised pruning method effectively prunes channels with similar average values and standard deviations. The computation complexity scales with the number of samples, but the extra computation introduced by pruning is minimal. The effectiveness of supervised channel pruning is demonstrated by comparing different settings for channel selection. The experimental results demonstrate the effectiveness of channel pruning based on privacy and utility characterization, followed by random selection. Pruning the channels with the worst utility and largest privacy loss results in improved utility and reduced privacy leakage simultaneously. The detailed statistics are provided in Table 13. The experimental results show that after pruning, better utility and less privacy leakage can be achieved simultaneously. Comparing different pruning strategies, the LDA-based pruning method outperforms others in terms of accuracy and PSNR. The supervised pruning strategy is proven effective in maintaining similar accuracy with less privacy loss. In this section, the supervised pruning strategy is verified for utility and privacy comparison in three settings: random selection without pruning, random selection after pure characterization-based pruning, and random selection after LDA-based pruning. The adversarial model adopted in the paper assumes the transformation induced by the FEN is unknown to attackers to prevent powerful attacks and enhance privacy protection. Strategies are provided to protect the anonymity of the FEN, including building a pool of pre-trained NNs for FEN derivation. In the framework, strategies are proposed to protect the anonymity of the FEN by building a pool of pre-trained NNs and applying channel selection procedures to make it harder for attackers to guess how the FEN is derived. In the framework, strategies are proposed to protect the anonymity of the FEN by building a pool of pre-trained NNs and applying channel selection procedures to make it harder for attackers to guess how the FEN is derived. The privacy and utility of the intermediate channel selection are empirically verified using the first 6 layers of VGG16 with a depth of output channel set to 8. The impact of reducing the channel depth of the convolution layers on privacy, utility, and runtime is analyzed, showing minimal impact on privacy and utility with a significant reduction in runtime. PrivyNet is a flexible framework designed to protect the anonymity of the FEN by reducing channel depth for each convolution layer, maintaining privacy and utility while significantly reducing runtime. By selecting channels for intermediate layers, it becomes difficult for attackers to determine the structure of the FEN. This framework enables cloud-based training and addresses resource constraints and lack of expertise. PrivyNet is a flexible framework that protects the anonymity of the FEN by reducing channel depth in convolution layers. It enables cloud-based training and addresses resource constraints and lack of expertise. One use case is for hospitals to release informative features instead of original patient data for disease diagnosis and treatment. Another application is for mobile platforms to collect useful information for individuals. PrivyNet is a platform-aware framework that enables mobile platforms to collect and upload data to the cloud while protecting privacy. It is simple, flexible, and applicable for different end-users in various situations. The framework uses CIFAR-10 and CIFAR-100 datasets for characterization. The CIFAR-10 dataset contains 60000 32 \u00d7 32 color images in 10 classes, with 50000 training images and 10000 test images. The CIFAR-100 dataset has images of objects in 100 classes, with 600 images per class. VGG16, pre-trained on ImageNet, is used for privacy and accuracy characterization. CNN is used to construct networks for image classification and reconstruction tasks. The architecture of VGG16 is used for image classification and reconstruction tasks. A CNN is used to construct networks h and g, with g based on ResNet blocks. The image reconstruction network (IRN) follows a similar structure with 8 ResNet blocks per cluster. Gradient descent optimizer is used for training, with specific parameters for each task. For image reconstruction and classification tasks, specific parameters are set such as learning rates and mini-batch sizes. Data augmentation includes normalization, brightness, and contrast modifications. The topology of the IRN is determined before characterization to ensure image recovery capability. Quality changes are recorded during image reconstruction experiments with different FEN topologies. In image reconstruction experiments, the image recovery capability of IRN is determined by the number of ResNet block clusters. The PSNR of reconstructed images saturates with an increase in ResNet block clusters. Performance and storage characterization of pre-trained NNs on local platforms are shown in figures. Characterization of pre-trained NNs on local platforms shows that as the number of VGG16 layers increases, requirements for computation and storage also increase rapidly. Computation mainly comes from convolution layers, while storage is dominated by fully connected layers, especially with larger input image sizes. Different platforms may have varying bottlenecks, and significant runtime differences exist. This highlights the need for a flexible framework to address these variations. The complexity of the second part of the computation is determined by the number of samples N LDA and the dimension of the output representations W \u00d7 H. The complexity for different computations varies, with O(KW 2 H 2 ) for S b, O(N LDA W 2 H 2 ) for S w, and O(W 3 H 3 ) for W \u22121 and the largest eigenvalue of W \u22121 B. The overall complexity is O((K + N LDA )W 2 H 2 + W 3 H 3 ), where N LDA plays a key role in determining the extra computation needed. The complexity of the second part of the computation is O((K + N LDA)W 2 H 2 + W 3 H 3). N LDA is a key factor determining the extra computation induced by the learning process, but usually a small N LDA is sufficient for good pruning results, resulting in a small overall computation overhead."
}