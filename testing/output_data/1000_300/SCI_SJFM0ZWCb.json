{
    "title": "SJFM0ZWCb",
    "content": "Unsupervised learning of timeseries data is a challenging problem in machine learning. The proposed algorithm, Deep Temporal Clustering (DTC), integrates dimensionality reduction and temporal clustering in an unsupervised learning framework. It utilizes an autoencoder for dimensionality reduction and a novel temporal clustering layer for cluster assignment. The algorithm optimizes clustering and dimensionality reduction objectives simultaneously and can be customized with various temporal similarity metrics. A visualization method is used to analyze learned features, and the algorithm is validated with timeseries data from different domains. The algorithm Deep Temporal Clustering (DTC) combines dimensionality reduction and temporal clustering in unsupervised learning. It outperforms traditional methods in various domains using timeseries data, showcasing integrated temporal dimensionality reduction and clustering criteria. While deep learning is prevalent in supervised learning, DTC focuses on unsupervised learning for complex, high-level structures and features in unlabeled data. The progress in learning complex structures from unlabeled data has been limited to labeled datasets. Unsupervised techniques like clustering organize similar objects into clusters, but their application to time series data remains a challenge. This gap in technology hinders accurate unsupervised learning of time series data in various fields like finance, medicine, and event detection. The novel algorithm called deep temporal clustering (DTC) addresses the challenges of unsupervised time series clustering by transforming the data into a low dimensional latent space using a deep autoencoder network. This approach overcomes the limitations of standard clustering techniques on time series data with variations in properties, temporal scales, and dimensionality. The DTC algorithm transforms time series data into a low dimensional latent space using a deep autoencoder network integrated with a temporal clustering layer. The method disentangles data manifolds by identifying latent dimensions for clustering unlabeled data into classes. The algorithm includes a CNN for reducing data dimensionality and learning short-time-scale waveforms, and a BI-LSTM for further data reduction. The proposed three-level approach involves a CNN to reduce data dimensionality and learn short-time-scale waveforms, a BI-LSTM to learn temporal connections between waveforms, and non-parametric clustering to split data into classes based on spatio-temporal dimensions. This approach untangles data manifolds without discarding time course information, achieving high performance on various datasets without parameter adjustment. The DTC algorithm also includes a feature to visualize cluster-assignment activations over time. The proposed deep learning algorithm, DTC, achieves high performance on real-life and benchmark datasets without parameter adjustment. It includes a unique feature to visualize cluster-assignment activations over time, providing explanations for class assignment. This is the first work on applying deep learning to temporal clustering, with a focus on achieving meaningful clustering through effective latent representation and objective formulation. The study presents an end-to-end deep learning algorithm for temporal clustering, focusing on effective latent representation and a similarity metric. The algorithm outperforms existing methods on real-world time series datasets. Existing research has mainly addressed dimensionality reduction and similarity metric selection in temporal clustering methods. The existing research in temporal clustering methods has focused on dimensionality reduction and similarity metric selection. One class of solutions uses application-dependent dimensionality reduction to filter out noise, while another class focuses on creating a suitable similarity measure. These approaches have limitations such as potential loss of long-range correlations and hand-crafted transformations. The existing research in temporal clustering methods has focused on dimensionality reduction and similarity metric selection. One class of solutions uses application-dependent dimensionality reduction to filter out noise, while another class focuses on creating a suitable similarity measure between time series data. These similarity measures consider features like complexity, correlation, and time warping, and are incorporated into traditional clustering algorithms. The choice of similarity measure has a significant impact on clustering results, but proper dimensionality reduction is also crucial for optimal results due to the high dimensional nature of time series data. Recent research in temporal clustering methods has highlighted the importance of proper dimensionality reduction and selecting a suitable similarity metric for time series data clustering. While some approaches focus on filtering out noise through application-dependent dimensionality reduction, others emphasize creating effective similarity measures based on complexity, correlation, and time warping. However, achieving optimal clustering results in high-dimensional time series data requires a balance between dimensionality reduction and similarity metric selection. The proposed DTC method combines a stacked autoencoder and k-means for clustering, specifically designed for time series data. It involves encoding the input signal into a latent space using a convolutional autoencoder and BI-LSTM, followed by a temporal clustering layer to generate cluster assignments. Effective latent representation is crucial for optimal clustering results in high-dimensional time series data. The proposed DTC method combines a stacked autoencoder and k-means for clustering time series data. It involves encoding the input signal into a latent space using a convolutional autoencoder and BI-LSTM, followed by a temporal clustering layer to generate cluster assignments. The BI-LSTM is part of a temporal autoencoder (TAE) that extracts key short-term features and reduces dimensionality for better processing. The proposed DTC method combines a stacked autoencoder and k-means for clustering time series data by encoding the input signal into a latent space using a convolutional autoencoder and BI-LSTM. The BI-LSTM learns temporal changes in both directions to collapse input sequences into a smaller latent space, and a clustering layer assigns sequences to clusters based on the BI-LSTM latent representation. Learning is driven by minimizing two cost functions, including mean square error for input sequence reconstruction to ensure representation quality after dimensionality reduction. The DTC method combines a stacked autoencoder and k-means for clustering time series data by encoding the input signal into a latent space using a convolutional autoencoder and BI-LSTM. The BI-LSTM learns temporal changes in both directions to collapse input sequences into a smaller latent space, and a clustering layer assigns sequences to clusters based on the BI-LSTM representation. Two cost functions are minimized: mean square error for input sequence reconstruction and clustering metric for separating sequences into distinct clusters based on high-level features. The clustering metric optimization in the BI-LSTM and CNN modifies weights to separate sequences into clusters, disentangling spatio-temporal manifolds of dynamics. The end-to-end optimization efficiently extracts features best suited for categorizing input sequences, unlike traditional approaches that only optimize for reconstruction or clustering separately. The traditional approaches optimize reconstruction or clustering separately, leading to suboptimal separation in the latent feature space. End-to-end optimization in unsupervised categorization shows significant improvement compared to disjointly optimized methods. Directly applying clustering algorithms to spatio-temporal data without initial dimensionality reduction often results in overfitting and poor performance. Our approach utilizes temporal continuity to extract informative features at all time scales in the latent representation of the BI-LSTM. Our approach emphasizes end-to-end optimization and utilizes temporal continuity to extract informative features in the latent representation of the BI-LSTM. The temporal clustering layer consists of centroids initialized using latent signals and hierarchical clustering. Unsupervised training alternates between computing probabilities and updating cluster centroids. The temporal clustering layer in our approach utilizes centroids initialized with latent signals and hierarchical clustering. Unsupervised training involves computing probabilities for input assignment to clusters and updating centroids based on a loss function maximizing high confidence assignments. Distance computations from centroids are normalized into probability assignments using a Student's t distribution kernel. The clustering layer computes distances from centroids using a similarity metric and normalizes them into probability assignments. The probability of input belonging to a cluster is determined using a Student's t distribution. The parameter \u03b1 can be set to 1 in an unsupervised setting. The temporal similarity metric siml() is used to compute distances between the encoded signal and centroids. The CID similarity metric computes distance between encoded signal and centroids using complexity estimation. It corrects euclidean distance based on complexity factors of input sequences. The CID similarity metric calculates distance between encoded signal and centroids based on complexity estimates, while COR computes similarities using pearson's correlation and ACF uses autocorrelation coefficients. The Auto Correlation based Similarity (ACF) in BID7 calculates similarity between latent representation z i and centroids w j using autocorrelation coefficients, followed by weighted euclidean distance. Training the temporal clustering layer involves minimizing KL divergence loss between q ij and target distribution p ij to maintain high confidence predictions and normalize losses. This is achieved through DISPLAYFORM0 where f j = n i=1 q ij, with further details discussed in BID9 and BID19. The text discusses the use of KL divergence loss in optimizing clustering and autoencoder jointly. It emphasizes the importance of effective initialization of cluster centroids to reflect the latent representation of the data. Pretraining the autoencoder parameters is crucial for meaningful latent representation before initializing cluster centers through hierarchical clustering. The text emphasizes the importance of effective initialization of cluster centroids to reflect the latent representation of the data. Pretraining the autoencoder parameters is crucial for meaningful latent representation before initializing cluster centers through hierarchical clustering. Later, the autoencoder weights and cluster centers are updated using backpropagation mini-batch SGD to minimize clustering and MSE loss. The text discusses the convergence of latent representation to minimize clustering and MSE loss for signal reconstruction. A heatmap-generating network is used to identify main data features, with an example shown for NASA data. The networks were implemented using Python, TensorFlow 1.3, and Keras 2.0. The network generates heatmaps to highlight relevant parts of spatio-temporal inputs for clustering. Heatmap example for NASA data is shown in FIG1. Implemented using Python, TensorFlow, and Keras on Nvidia GTX 1080Ti. DTC algorithm performance evaluated on various real-world datasets from UCR Time series Classification Archive. The DTC algorithm performance is evaluated on real-world datasets including UCR Time series Classification Archive datasets and spacecraft magnetometer data from NASA's MMS Mission for automated detection of flux transfer events. Automated detection of spacecraft crossings of flux transfer events (FTEs) using the DTC algorithm is compared against hierarchical clustering and k-Shape algorithm. Four similarity metrics are considered: CID, COR, ACF, and EUCL. Expert labels are available for the datasets used in the experiments. In experiments, four similarity metrics were considered: CID, COR, ACF, and EUCL. Expert labels were used for dataset evaluation, but the training pipeline was unsupervised. Evaluation metrics included ROC, AUC, and bootstrap sampling over 5 trials. Parameter optimization was limited due to unsupervised clustering. Specific parameters for DTC were used, with a convolution layer of 50 filters and Bi-LSTM filters of 50 and 1. Pooling size was chosen to keep latent representation size < 100. The deep architecture for clustering and autoencoder uses commonly used parameters, including 50 filters in the convolution layer, Bi-LSTM filters of 50 and 1, and a pooling size that keeps the latent representation size < 100. Weights are initialized with a zero-mean Gaussian distribution, and the network is pre-trained over 10 epochs using the Adam optimizer. Temporal clustering layer centroids are initialized using hierarchical clustering, and the entire architecture is jointly trained until a convergence criterion of 0.1% change in cluster assignment is met. The mini-batch size is set to 64 for both pretraining and end-to-end fine-tuning. The deep architecture is trained for clustering and autoencoder loss with a mini-batch size of 64 and a starting learning rate of 0.1. Results of DTC on three time series from the MMS dataset are shown in FIG1, where the activation map profiles correlate well with the location of events. The heatmap correctly identifies events, even when there are multiple events in a time series. The paper demonstrates that joint training of reconstruction and clustering objectives in the deep architecture outperforms disjoint training. Comparison on the MMS dataset shows an average AUC of 0.93 for joint training versus 0.88 for disjoint training. Training the temporal autoencoder on the MMS dataset resulted in an average AUC of 0.93 for joint training compared to 0.88 for disjointed training. DTC algorithm outperformed baseline clustering techniques across 13 datasets and various similarity metrics. ROC comparison in FIG2 shows DTC's robustness and superior performance. In this work, the DTC algorithm is shown to be robust and outperform existing techniques in unsupervised learning of patterns in temporal sequences and event detection. Post-hoc labeling of clusters reveals high agreement with human-labeled categories, indicating graceful dimensionality reduction. The unsupervised clustering results show graceful dimensionality reduction from inputs with complex temporal structure to a one or few-dimensional space spanned by cluster centroids. This approach is promising for real-world applications, especially with time-continuous and unlabeled natural stimuli. Generalization to multichannel spatio-temporal input is straightforward and has been explored in a separate paper."
}