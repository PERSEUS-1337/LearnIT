{
    "title": "r1l73iRqKm",
    "content": "In open-domain dialogue, intelligent agents struggle to incorporate knowledge effectively. Existing models often rely on generic responses rather than utilizing recalled knowledge as context. To address this, a new dataset grounded in Wikipedia knowledge was created. Architectures were developed to retrieve, read, and use this knowledge to generate natural responses. The best dialogue models were able to engage in knowledgeable discussions on various topics, as confirmed by both automatic metrics and human evaluations. Our dialogue models are designed to retrieve and use knowledge to generate natural responses, aiming to enable humans to communicate effectively with machines. Machines must master language comprehension, memory retention, reasoning, and response generation to achieve this goal. The current state-of-the-art models focus on sequence to sequence approaches. The current state-of-the-art models in dialogue generation focus on sequence to sequence approaches, but they lack the ability to bring memory and knowledge to bear. More direct knowledge memory mechanisms are needed for intelligent conversation on various topics. In this work, the focus is on employing more direct knowledge memory mechanisms for open-domain dialogue. The task involves two speakers engaging in chit-chat, broadening or focusing on related themes. The goal is to design architectures combining Memory Network and Transformer architectures to retrieve knowledge, provide text representations, and generate outputs, termed Transformer Memory Networks. The study focuses on creating Transformer Memory Networks by combining Memory Network and Transformer architectures to retrieve knowledge and generate text representations for open-domain dialogue. A supervised dataset of human-human conversations was built using crowd-sourced workers, with topics connected to Wikipedia for knowledge grounding. This approach allows for training a knowledgeable conversation agent and evaluating models based on their ability to locate and use existing text. Our study introduces Transformer Memory Networks for training a knowledgeable conversation agent and evaluating models based on their ability to use existing text. The architectures are tested using automatic metrics and human evaluations, showing their effectiveness in engaging conversations compared to baseline models. A new benchmark in ParlAI aims to drive further improvements in this research direction. Many existing dialogue tasks do not explicitly study knowledge use, highlighting the importance of our approach. Our work investigates unstructured knowledge across a diverse set of topics potentially spanning all of Wikipedia, aiming to encourage and measure improvements in dialogue tasks that do not explicitly study knowledge use. Our work focuses on natural human dialogues containing a diverse set of utterances, rather than question answering like other datasets such as SQuAD and QuAC. The QuAC dataset explores dialogues in question-answer format, while our work focuses on natural human dialogues with a variety of utterances. Previous works have used Memory Networks for dialogue on movies and Reddit discussions, linking them to structured knowledge. Other works have utilized unstructured text for discussing news articles and local businesses in dialogues. Our work compares Memory Networks and Transformers for multi-turn dialogue using external knowledge sources like Wikipedia summaries and Foursquare tips. We develop an architecture that combines these approaches and ground crowdworkers dialogues with known Wikipedia articles and sentences. This contrasts with previous works that focused on closed-domain movie chats. Our paper introduces a new architecture for multi-turn dialogue in an open-domain setting, where two participants engage in chitchat with one participant acting as a knowledgeable expert (wizard) and the other as a curious learner (apprentice). The goal is for the apprentice to delve deep into a chosen topic that interests them. The apprentice engages in conversation with the wizard, playing the role of a curious learner. The wizard's goal is to inform their partner about a chosen topic using an information retrieval system. The conversation aims to be engaging and informative, different from shallow chit-chat tasks. The wizard uses an information retrieval system to provide relevant knowledge during conversations with the apprentice. The wizard is instructed to craft engaging replies based on this knowledge, rather than simply repeating it. The flow of the conversation involves choosing a topic, sharing information, and constructing responses based on the retrieved knowledge. The apprentice selects a topic and initiates the conversation with the wizard. The wizard uses relevant knowledge to respond, and the dialogue continues until one participant ends it. The goal is to replace the human wizard with a learned agent in future interactions. Topics are sourced from natural dialogue topics linked to Wikipedia articles. The wizard in the dialogue uses knowledge to respond to topics selected by the apprentice. The wizard has access to relevant passages of knowledge during the conversation. The retrieval process involves comparing articles and queries using TF-IDF weighted bag-of-word and n-gram vectors. The wizard in the dialogue uses a retriever to select relevant articles for knowledge context. The retriever compares articles and queries using TF-IDF weighted bag-of-word and n-gram vectors. The wizard can click on article titles to expand and select relevant sentences for response generation. During data collection, the wizard can select relevant sentences from retrieved articles to generate responses. The dialogue model, acting as the knowledgeable speaker, can access a knowledge source like Wikipedia to enhance conversations. Extensions of Memory Network BID19 and Transformer BID21 models are developed to retrieve relevant information from a large memory based on dialogue history. The model developed can access Wikipedia to ground conversations, retrieve relevant information, read and attend to knowledge, and generate dialogue responses. Two classes of models are created: retrieval models that select from candidate responses and generative models that generate word-by-word. The input to both models is the current dialogue context at each turn. The model developed can access Wikipedia to ground conversations, retrieve relevant information, and generate dialogue responses. It uses retrieval models to select from candidate responses and generative models to generate responses word-by-word. The input to both models is the current dialogue context at each turn. Knowledge retrieval is done through a large knowledge base organized hierarchically into documents, with standard information retrieval techniques used to return a smaller set of candidates for fine-grained selection. The model accesses Wikipedia for information retrieval techniques to select candidates for dialogue responses. It uses the IR system on the topic and last two turns, retrieving top 7 articles and flattening results into sentences. This allows the neural model to attend to candidates independently. The model uses an attention mechanism to select knowledge sentences for dialogue responses independently. Each sentence is encoded with a Transformer encoder, and dot-product attention is performed between candidates and dialogue context. The final stage involves predicting the output utterance for the next dialogue turn. The model uses an attention mechanism to select knowledge sentences for dialogue responses independently. It encodes each knowledge sentence and dialogue context with a Transformer. The final stage involves predicting the output utterance for the next dialogue turn by performing dot-product attention and encoding candidate responses with a separate Transformer. The model utilizes a weighted sum of vectors to represent dialogue context and candidate responses. It is trained to minimize cross-entropy loss and considers two versions: Two-stage and End-to-end. Both versions find relevant knowledge and incorporate it into the response generation process. Beam search is used to select the best response, and BPE encoding is employed for generative models. In the End-to-end version, a shared Transformer encoder is utilized. The response generation model employs a beam search of 5 for selecting the best response. BPE encoding is used for generative models to copy rare words from Wikipedia sentences. In the End-to-end version, a shared Transformer encoder encodes all candidates and dialogue history. The model is trained to minimize the negative log-likelihood of the response utterance. Additional supervision can be added for correct knowledge selection. In the Two-stage version, two separately trained models are used for knowledge selection and utterance prediction. Knowledge dropout is employed to improve decoder performance by preventing the model from attending to knowledge during training. In the context of improving decoder performance, the use of knowledge dropout (K.D.) is proposed to enhance the generator's resilience to errors during knowledge selection. This technique, similar to other dropout methods, helps in faster training and better model performance. Experimental setups and results are described, focusing on knowledge selection and dialogue tasks before assessing models' ability to predict human-selected knowledge in the dataset. The study evaluates models' ability to predict human-selected knowledge in a dataset for a dialogue task. Transformers outperform baselines when pretrained on a large dataset like Reddit. The best Transformer model is used in a two-stage generative Memory Network for the full dialogue task. The study evaluates models' ability to predict human-selected knowledge in a dialogue task using Transformer models pretrained on a large dataset like Reddit. The best performing Transformer model is used in a two-stage generative Memory Network for the full dialogue task, with further analysis provided in Appendix B.1. The models are evaluated on dialogue generation given knowledge in two settings: with gold knowledge chosen by a human or predicting which knowledge to use. The addition of knowledge improves all models, as shown in TAB2. The study evaluates models' ability to predict human-selected knowledge in a dialogue task using Transformer models pretrained on a large dataset like Reddit. The addition of knowledge improves all models, with significant performance improvements when models are provided with gold knowledge. Generative experiments compare different models using perplexity and unigram F1 metrics, showing that both End-to-end and Two-stage models utilize knowledge in their response predictions. The study evaluates models' ability to predict human-selected knowledge in a dialogue task using Transformer models. Both End-to-end and Two-stage models utilize knowledge in their response predictions, with the Two-stage model showing stronger performance in perplexity and F1 scores using predicted knowledge. The End-to-end model outperforms in experiments with gold knowledge, benefiting from additional knowledge selection supervision. The study compares End-to-end and Two-stage models in predicting human-selected knowledge in dialogue tasks. End-to-end model performs better with additional knowledge selection supervision, while Two-stage model excels in perplexity and F1 scores using predicted knowledge. Knowledge dropout also proves beneficial. In a separate conversation, individuals express a preference for physical books over e-books due to the tactile experience and dislike for reading on screens. The study compares End-to-end and Two-stage models in predicting human-selected knowledge in dialogue tasks. Individuals express a preference for physical books over e-books due to the tactile experience and dislike for reading on screens. Additionally, human evaluation of the models is conducted using crowd-sourced workers to rate engagingness of conversations. The study compares End-to-end and Two-stage models in predicting human-selected knowledge in dialogue tasks. Human evaluation of the models is conducted using crowd-sourced workers to rate engagingness of conversations. Conversations are rated on a scale of 1-5 for engagingness, and a metric called Wiki F1 score is calculated to measure knowledge exhibited by the model. Retrieval models outperform generative models in engagingness ratings based on 546 conversations with ratings from 464 workers. The study compared End-to-end and Two-stage models in predicting human-selected knowledge in dialogue tasks. Retrieval models significantly outperformed generative models in human engagingness evaluation. Models with knowledge retrieval showed higher Wiki F1 scores in both seen and unseen test sets. Generative models also improved engagingness ratings with the use of knowledge. The use of knowledge significantly improved ratings (p < .01) and Wiki F1 scores, indicating that models with knowledge convey more knowledge than those without. Generative models outperformed retrieval models on unseen data, showcasing their ability to engage in open-domain conversations using large memory systems with encyclopedic knowledge. Additional analysis and examples can be found in the appendices. In this work, dialogue agents are developed with large memory systems containing encyclopedic knowledge for engaging open-domain conversations. Transformer Memory Network models are used to retrieve and output responses. The Wizard of Wikipedia dataset is collected to train and evaluate these models, showing effectiveness in experiments. A new benchmark is introduced to encourage further exploration in this research direction. Future work using this dataset is anticipated. The new benchmark introduced aims to encourage model exploration for engaging open-domain conversations using large memory systems with encyclopedic knowledge. Future work includes bridging the gap between retrieval responses and generative models, learning to retrieve and reason simultaneously, and investigating the relationship between knowledge-grounded dialogue and existing QA tasks. The goal is to develop an engaging and knowledgeable conversational agent. The dataset contains conversations between a wizard and an apprentice, where the wizard has access to an information retrieval system over Wikipedia. The wizard can ask and answer questions, and make relevant statements. The dataset shows that apprentices ask questions in 13.9% of training set utterances, answer questions 39.5% of the time, and make new or follow-on statements 49.3% of the time. This allows for a variety of dialogue acts between the wizard and apprentice. The dataset includes conversations between a wizard and an apprentice, where the apprentice asks questions 13.9% of the time, answers questions 39.5% of the time, and makes new or follow-on statements 49.3% of the time. To select natural topics, the Persona-Chat dataset was used, containing \u223c1000 personas with interests mapped to relevant Wikipedia pages. The dataset includes conversations between a wizard and an apprentice, where the apprentice asks questions 13.9% of the time, answers questions 39.5% of the time, and makes new or follow-on statements 49.3% of the time. To select natural topics, the Persona-Chat dataset was used, containing \u223c1000 personas with interests mapped to relevant Wikipedia pages. Interest mapping was done using annotators to connect sentences to Wikipedia pages, resulting in 1,431 topics for the task. Additional experiments were conducted to test the performance of models on knowledge selection tasks, showing that the retrieval system could be improved with the help of auxiliary loss. The retrieval system's performance on the knowledge selection task could be enhanced with the help of auxiliary loss. Analysis of human evaluation experiments reveals stark differences between human-human conversations and bot conversations, with humans engaging in more small talk and using topics as icebreakers. The human-human conversations in the Wizard dataset differ from bot conversations, with humans engaging in more small talk and using topics as icebreakers. Models attempt to produce more factual sentences, but the retriever without knowledge is prone to non sequiturs. The retriever with knowledge sticks to the chosen topic but struggles in unseen conversations. The retriever with knowledge tends to stick to the chosen topic strongly but struggles if the subject changes. A two-stage retrieval system outperformed the best retrieval method in terms of F1 but not in terms of Recall@1. The best retrieval method outperformed by a two-stage retrieval system in terms of F1 but not Recall@1. The system's performance on the gold knowledge task suggests improvement is needed in knowledge selection. Human experiments showed that knowledge produces similar but factually inaccurate answers to user queries. The retrieval system's performance on the gold knowledge task suggests improvement is needed in knowledge selection. Human experiments showed that knowledge produces similar but factually inaccurate answers to user queries. The generator without knowledge is prone to typical behaviors of seq2seq systems, including repetition and inconsistencies in personality. The generator with knowledge has fewer issues with repetition and can act as a selfish conversationalist. It sometimes produces inaccurate statements but can successfully generalize to unseen topics using Wikipedia knowledge. The generator with knowledge can successfully generalize to unseen topics using Wikipedia knowledge, despite sometimes producing inaccurate statements. Selected conversations with the generator can be found in Figure 5."
}