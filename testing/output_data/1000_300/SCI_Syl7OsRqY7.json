{
    "title": "Syl7OsRqY7",
    "content": "End-to-end neural models have advanced question answering, but recent studies suggest they assume answers and evidence are close in a single document. The Coarse-grain Fine-grain Coattention Network (CFC) is a new model that combines evidence from multiple documents. It includes a coarse-grain module for interpreting documents with respect to the query and finding relevant answers, and a fine-grain module that scores candidate answers by comparing their occurrences across all documents with the query. Using hierarchies of coattention and self-attention, the CFC achieves a state-of-the-art result of 70.6% accuracy on the Qangaroo WikiHop multi-evidence question answering task. The Coarse-grain Fine-grain Coattention Network (CFC) achieves a new state-of-the-art result of 70.6% accuracy on the Qangaroo WikiHop multi-evidence question answering task by combining evidence from multiple documents. Existing datasets focus on reasoning over localized sections of a single document, but the CFC model emphasizes reasoning over multiple documents to answer questions. The Coarse-grain Fine-grain Coattention Network (CFC) focuses on multi-evidence question answering by aggregating evidence from multiple documents. It combines coarse-grain reasoning to build a summary of support documents and fine-grain reasoning to match specific contexts with the query to gauge candidate relevance. The Coarse-grain Fine-grain Coattention Network (CFC) uses hierarchical attention to combine information from support documents based on the query and candidates. It achieves a new state-of-the-art result on the blind Qangaroo WikiHop test set and the TriviaQA multi-paragraph question answering task. The Coarse-grain Fine-grain Coattention Network (CFC) achieved a new state-of-the-art result on the blind Qangaroo WikiHop test set and the TriviaQA multi-paragraph question answering task, with a test set accuracy of 70.6%. It improved exact match accuracy by 3.1% and F1 by 3.0% without using pretrained contextual encoders. The attention hierarchies of the CFC modules focus on distinct parts of the input, enabling better representation of long documents. Common errors produced by CFC include difficulty in aggregating references, noise in distant supervision, and challenging relation types. The Coarse-grain Fine-grain Coattention Network (CFC) encounters errors due to challenges in aggregating references, noise in distant supervision, and complex relation types. The CFC consists of a coarse-grain module for summarizing support documents and a fine-grain module for retrieving specific contexts of candidates. These modules share low-level encodings but focus on different parts of the input, improving the model's performance. The Coarse-grain Fine-grain Coattention Network (CFC) uses modules that share low-level encodings but focus on different parts of the input to improve performance. It builds codependent representations between mentions and the query, allowing attention hierarchies to effectively represent a large number of support documents. The model encodes sequences using bidirectional GRUs, enhancing the understanding of queries, support documents, and candidate answers. The Coarse-grain Fine-grain Coattention Network (CFC) utilizes bidirectional GRUs to encode sequences and create codependent representations between support documents and queries. It employs coattention and self-attention mechanisms to compare support documents and queries with candidate answers, enhancing single-document question answering models. Coattention and similar techniques are essential for single-document question answering models. The affinity matrix between the document and query is computed, and the document context is obtained through coattention. The coattention context is a concatenation of the document context and summary vector. Hierarchical self-attention is then used to summarize the coattention context, creating a codependent encoding of the supporting document and query. The coattention context, a codependent encoding of the supporting document and query, is summarized using hierarchical self-attention. A fixed-length summary vector is created using self-attention, with scores computed for each position of the coattention context. These scores are normalized and used to compute a weighted sum over the context. The coattention context is summarized using hierarchical self-attention, with scores computed for each position. A fixed-length summary vector is created, which is then multiplied with the candidate answer summary to produce a coarse-grain score. This process involves encoding the candidate answer and support documents, and applying a projection layer to reduce the support documents summary dimension. The encoding and self-attention summary of the candidate are represented by E c and G c respectively. The support documents summary is reduced using a projection layer with parameters W coarse and b coarse. The fine-grain module utilizes coreference resolution to find specific context in supporting documents, summarizing mentions with self-attention. Coattention between mention representations and the query is computed to produce a fine-grain summary for scoring the candidate. The candidate's encoding and self-attention summary are represented by E c and G c. Mentions of the candidate in support documents are summarized using self-attention to produce a fine-grain score. Multiple pieces of evidence are required to answer questions, with coattention between mention representations and the query used to determine the fine-grain score. The model uses self-attention to extract mention representations and determine candidate scores. It combines coarse-grain and fine-grain scores to calculate the final score vector. The model is trained using cross-entropy loss and evaluated on multi-evidence question answering tasks. The CFC achieves state-of-the-art results in multi-evidence question answering tasks on the WikiHop dataset and TriviaQA. The WikiHop dataset links entities in a document corpus with a knowledge base, creating a bipartite graph. The model reranks outputs from a span-extraction model, leading to performance improvement. The WikiHop dataset connects entities in documents with a knowledge base, forming a bipartite graph. The Qangaroo WikiHop task involves selecting the correct candidate answer from a set of plausible options based on support documents. The unmasked version uses original text for candidate answers, while the masked version uses placeholders to reduce correlation between answers and support documents. The WikiHop dataset involves selecting the correct candidate answer from support documents. The unmasked version uses original text for answers, while the masked version uses placeholders to reduce correlation. The CFC model achieves state-of-the-art results on both versions of WikiHop, with detailed experiment setup and hyperparameters provided in the Appendix. The CFC model achieves state-of-the-art results on both masked and unmasked versions of WikiHop, outperforming previous results by 3% without using pretrained contextual encoders. The division of labor between coarse-grain and fine-grain modules allows for effective attention hierarchies, enabling better modeling of long documents in WikiHop. The CFC model achieves state-of-the-art results on WikiHop by utilizing attention hierarchies in coarse-grain and fine-grain modules. Experimentation on TriviaQA involves proposing candidate answers and reranking them. Ablation study on WikiHop dev set shows the impact of different model components. The CFC model improves performance by reranking candidate answers obtained from BiDAF++ using average pooling, unidirectional GRUs, and projection over word embeddings. This approach consistently outperforms using only the span extraction question answering model on the TriviaQA dev set. The CFC model enhances performance by reranking candidate answers from BiDAF++ using average pooling, unidirectional GRUs, and word embedding projection. It consistently outperforms the span extraction question answering model on the TriviaQA dev set, showing a 3.1% EM and 3.0% F1 gain. The coarse-grain and fine-grain modules significantly contribute to model performance, while replacing self-attention layers and bidirectional GRUs with simpler alternatives results in less performance degradation. Replacing self-attention layers with mean-pooling and bidirectional GRUs with unidirectional GRUs results in less performance degradation. However, replacing the encoder with a projection over word embeddings leads to a significant performance drop, highlighting the importance of contextual encodings for capturing positional information. The fine-grain-only model consistently under-performs the coarse-grain-only model due to difficulties in coreference resolution, but performs better on examples with a large number of support. The technique used for coreference resolution in support documents shows high precision but low recall. The fine-grain-only model performs better on examples with many support documents or long documents, capturing dependencies more precisely than hierarchical attention. Coattention layers focus on similar phrases between documents and queries, while self-attention layers capture entity characteristics. Attention maps are detailed in the Appendix. The coattention and self-attention scores align relation parts of the query to the context in the text. The mentions describe locations in Richmond upon Thames, with a focus on the country of origin being the United Kingdom. The third paragraph discusses the self-attention scores for the query \"country of origin the troll\" focusing on documents related to the literary work \"The Troll\" and its author Julia Donaldson. The self-attention tends to highlight information relevant to the query, while the coattention aligns relation parts of the query to the text context. The self-attention in the context of \"The Troll\" focuses on documents related to the literary work and its author Julia Donaldson. Fine-grain coattention, on the other hand, emphasizes the relationship part of the query. Errors in the CFC model on the WikiHop development set are categorized into four types, with the first type (42% of errors) attributed to the model aggregating the wrong reference. The errors in the CFC model on the WikiHop development set are categorized into three types. The first type (42% of errors) is due to the model aggregating the wrong reference. The second type (28% of errors) occurs when questions are not answerable. The third type (22% of errors) happens when queries have multiple correct answers. Ways to reduce errors include using more robust pretrained contextual encoders and coreference resolution. The errors in the CFC model on the WikiHop development set are categorized into different types. One type results from queries with multiple correct answers, such as predicting \"archaeological site\" instead of \"town\". Another type stems from complex relation types like parent taxon, which are challenging to interpret using pretrained word embeddings. To address these errors, embedding relations using tunable symbolic embeddings along with fixed word embeddings can be helpful for question answering and information aggregation tasks. The CFC model errors in WikiHop dataset are categorized into different types, including those from queries with multiple correct answers and complex relation types like parent taxon. To address these errors, embedding relations using tunable symbolic embeddings and fixed word embeddings can be helpful for question answering and information aggregation tasks. The Qangaroo WikiHop dataset encourages reasoning over multiple pieces of evidence across documents, unlike most QA tasks that seldom require reasoning over multiple pieces of evidence. The Qangaroo WikiHop dataset promotes reasoning over multiple pieces of evidence across documents. Query-focused multi-document summarization involves aggregating information from multiple documents. Various question answering models have been developed, including document attention models, multi-hop memory networks, and cross-sequence attention models. Recent advances include the use of match-LSTM, coattention, bidirectional attention, and query-context attention. Our work builds upon prior research on single-document QA and extends to multi-evidence QA across documents. Attention models like match-LSTM, coattention, bidirectional attention, and query-context attention have been used in recent advancements. Additionally, reinforcement learning is employed to explore close answers, convolutions and self-attention model interactions, and reranking models refine span-extraction output. Neural attention is effective for information aggregation in various tasks. Neural attention is utilized for information aggregation in various tasks such as machine translation, relation extraction, summarization, and semantic parsing. Coattention is used to encode codependent representations between inputs, while self-attention is effective for combining information in textual entailment, coreference resolution, dialogue state-tracking, and machine translation. In the CFC, a novel approach combines self-attention and coattention hierarchically to create effective representations of long documents. Hierarchical coarse-to-fine modeling gradually introduces complexity and is effective for modeling long documents. Neural coarse-to-fine modeling has been applied to question answering and semantic parsing. The CFC is a state-of-the-art model for multi-evidence question answering, achieving 70.6% test accuracy on the WikiHop task. It combines coarse-grain and fine-grain reasoning modules that focus on different aspects of the input, outperforming previous methods by 3% accuracy. In the WikiHop question answering task, the CFC achieves 70.6% test accuracy, surpassing previous methods by 3%. The model utilizes complementary coarse-grain and fine-grain modules to represent large document collections effectively. Simple lexical matching is used instead of full-scale coreference resolution systems, with potential integration for future work. Training the CFC model involves using Adam for up to 50 epochs with a batch size of 80 examples. The best-performing model trains the CFC using Adam for a maximum of 50 epochs with a batch size of 80 examples. It employs a cosine learning rate decay and outperforms other annealing heuristics. The model's accuracy is evaluated on the development set every epoch, with the best model evaluated on the test set. The embeddings used have a size of 400, with 300 from GloVe vectors and 100 from character ngram vectors. The model uses fixed embeddings with a size of 400, 300 from GloVe vectors and 100 from character ngram vectors. GRUs have a hidden size of 100 and dropout regularization is applied at various stages in the model. Attention maps from the CFC on the WikiHop development split are included, showing fine-grain mention self-attention and coattention, as well as coarse-grain summary self-attention. The section includes attention maps produced by the CFC on the development split of WikiHop, focusing on word dropout sensitivity. It also features identifiers and examples of unanswerable questions found during error analysis on the dev split. The CFC analyzed 100 errors on the dev split of WikiHop, focusing on Glasgow and Edinburgh in Scotland. Glasgow is the largest city in Scotland, while Edinburgh is the capital city with a population of 464,990. Edinburgh, Scotland's second most populous city and the UK's seventh most populous, has an official population estimate of 464,990. It is the capital of Scotland, home to the Scottish Parliament, and hosts national institutions like the National Museum of Scotland. Edinburgh is also a major financial center in the UK. The National Library of Scotland and the Scottish National Gallery are located in Edinburgh, the capital of Scotland. Carlisle is a city in Cumbria, and the River Clyde flows through Glasgow in Scotland. Scotland is a country that shares a border with England and is surrounded by the Atlantic Ocean. Scotland is a country located in the northern third of Great Britain, sharing a border with England to the south. It is surrounded by the Atlantic Ocean, with the North Sea to the east and the North Channel and Irish Sea to the south-west. The country consists of over 790 islands, including the Northern Isles and the Hebrides. Avon Water, also known as the River Avon, is a river in Scotland that is a tributary of the River Clyde. Lanarkshire, also known as the County of Lanark, is a historic county in the central Lowlands of Scotland. The North Sea is a marginal sea of the Atlantic Ocean located between Great Britain, Scandinavia, Germany, the Netherlands, Belgium, and France. It connects to the ocean through the English Channel in the south and the Norwegian Sea in the north. Worms is a city in Rhineland-Palatinate, Germany, situated on the Upper Rhine about southsouthwest of Frankfurt-am-Main. William George \"Will\" Barker was a British film producer, director, cinematographer, and entrepreneur. Ealing, a suburban district of west London, had approximately 85,000 inhabitants. William George \"Will\" Barker was a British film producer who elevated British filmmaking to Hollywood standards. Paris is the capital of France. The opening of the railway station in 1838 shifted Ealing's economy to market garden supply and suburban development. Paris is the capital and most populous city of France, while Bordeaux is a port city on the Garonne River in southwestern France. The Mediterranean Sea is surrounded by Southern Europe, Anatolia, North Africa, and the Levant. The Mediterranean Sea is a sea connected to the Atlantic Ocean, surrounded by land on all sides. Maurice Auguste Chevalier was a French actor and entertainer known for his songs and films. Nice is the fifth most populous city in France and the capital of the Alpes-Maritimes \"d\u00e9partement\". Nice is the fifth most populous city in France, located on the French Riviera. It is the second-largest city in the Provence-Alpes-C\u00f4te d'Azur region. Ealing Studios is a film production company in west London, established in 1902. Ealing Studios, established in 1902, is a film production company located in west London. It is the oldest continuously working studio facility for film production in the world, known for producing classic films post-WWII. Europe is a continent bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean Sea to the south. Europe is a continent bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean Sea to the south. It is separated from Asia by various geographical features. France, officially the French Republic, is a country in western Europe with overseas regions. France, a country in western Europe, has overland boundaries and overseas regions. The European area extends from the Mediterranean Sea to the English Channel and the North Sea. Overseas territories include French Guiana and island territories in the Atlantic, Pacific, and Indian oceans. With a population of nearly 67 million, France is a unitary semi-presidential republic with Paris as the capital. Other major cities include Marseille, Lyon, Lille, Nice, Toulouse, and Bordeaux. The British Broadcasting Corporation (BBC) is headquartered in London and is the world's oldest national broadcasting organization. The British Broadcasting Corporation (BBC) is a British public service broadcaster headquartered in London. It is the world's oldest national broadcasting organization and the largest broadcaster by number of employees. The Rhine is a European river that flows through several countries and empties into the North Sea in the Netherlands. Cologne, Germany, is the largest city on the river Rhine. The Rhine is a river in Europe that flows through the Franco-German border, the Rhineland, and empties into the North Sea in the Netherlands. The largest city on the river is Cologne, Germany. It is the second-longest river in Central and Western Europe. The Atlantic Ocean is the second largest ocean in the world, covering about 20% of the Earth's surface and separating the \"Old World\" from the \"New World\". The Atlantic Ocean is the second largest ocean in the world, covering about 20% of the Earth's surface and separating the \"Old World\" from the \"New World\". Claude Austin Trevor was a Northern Irish actor with a long career in film and television. The English Channel separates southern England from northern France and connects the North Sea to the Atlantic Ocean. North America is a continent bordered by the Arctic Ocean to the north, the Atlantic Ocean to the east, the Pacific Ocean to the west and south, and South America and the Caribbean Sea to the southeast. It is considered a northern subcontinent of the Americas. Inuit culture and language isolate are prominent in the region. Inuit, a group of indigenous peoples in the Arctic regions of Greenland, Canada, and Alaska, speak Inuit languages classified in the Eskimo-Aleut family. Inuit Sign Language is spoken in Nunavut. Qilakitsoq, an archaeological site in Greenland, is famous for the discovery of mummified bodies in 1972. Qilakitsoq, a settlement on the shore of Uummannaq Fjord in northwestern Greenland, is known for the discovery of eight mummified bodies in 1972. Four of the mummies are currently on display in the Greenland National Museum. Norway is a sovereign monarchy in Scandinavia, with territories including Jan Mayen, Svalbard, and Queen Maud Land in Antarctica. The Kingdom included Faroe Islands, Greenland, and Iceland until 1814. It also included Shetland and Orkney until 1468, as well as provinces now in Sweden. The Arctic is a polar region with Arctic Ocean, adjacent seas, and parts of various countries. It has seasonally varying snow and ice cover, with treeless tundra. Archaeology is the study of human activity through material culture analysis. Archaeology is the study of human activity through material culture analysis. It involves the recovery and analysis of artifacts, architecture, biofacts, and cultural landscapes. Archaeological sites preserve evidence of past activities and can range from barely visible remains to still-in-use structures. Nuussuaq Peninsula is a large peninsula in western Greenland. The Nuussuaq Peninsula in western Greenland is a large peninsula with fjords created by glacial erosion. Fjords are found in various locations such as Alaska, Chile, Iceland, Norway, and Scotland. The archaeological record is physical evidence of the past, essential in the field of archaeology. The archaeological record is crucial in archaeology, providing physical evidence of past human cultures. Human activities like agriculture and land development can damage or destroy archaeological sites. Archaeologists limit excavation to preserve the finite resources of the archaeological record. The archaeological record is essential for understanding human history and cultures. Archaeologists limit excavation to preserve these resources. Greenland is part of the Danish Realm, politically and culturally associated with Europe for over a millennium. Greenland, politically associated with Europe for over a millennium, is home to mostly Inuit residents. Uummannaq, a town in northwestern Greenland, has a population of 1,282 and is known for hunting, fishing, and a marble quarry. Iceland is a Nordic island country in the North Atlantic Ocean. Greenland's Uummannaq is known for hunting, fishing, and a marble quarry. Iceland is a Nordic island country with a sparse population, active volcanoes, and a temperate climate due to the Gulf Stream. Iceland has a temperate climate due to the Gulf Stream, despite its high latitude. The Canadian Arctic Archipelago is a group of islands north of the Canadian mainland. Uummannaq Fjord in Greenland is the second largest fjord in the country, emptying into Baffin Bay. A honey bee is a bee from the genus Apis known for producing honey and building colonial nests from wax. There are seven recognized species with 44 subspecies. The Western honey bee is the most well-known and is used for honey production and pollination. Honey bees are just a small fraction of the 20,000 known bee species. The study of bees, including honey bees, is called melittology. Honey bees, a small fraction of the 20,000 known bee species, produce honey from floral nectar or aphid honeydew through regurgitation and enzymatic activity. Honey bees belong to the genus \"Apis\" and are well-known for their worldwide commercial production and human consumption. Honey, produced by honey bees, is well-known for its sweetness from fructose and glucose. It has properties for baking and a unique flavor preferred by some over sugar. Sealed honey does not spoil due to the lack of microorganism growth, but may contain dangerous endospores of Clostridium botulinum. It is not recommended for babies or those with weakened immune systems due to the risk of infection. Honey, produced by honey bees, is known for its sweetness and unique flavor preferred by some over sugar. It does not spoil but may contain dangerous endospores of Clostridium botulinum, which can be harmful, especially to babies. People with weakened immune systems should avoid honey due to the risk of infection. While honey may have some medical benefits, its overall therapeutic use is inconclusive. Excessive consumption of honey can have adverse effects and interactions with existing health conditions or medications. Honey has a long history of use and production, dating back at least 8,000 years ago in Valencia, Spain. Honey production has a long history dating back at least 8,000 years ago in Valencia, Spain. Bees play a crucial role in pollination and honey production. Australia is a large country with diverse flora and fauna. Bees, closely related to wasps and ants, are known for pollination, honey production, and beeswax. There are nearly 20,000 species of bees found on every continent except Antarctica. Solomon Islands is a sovereign country in Oceania consisting of six major islands and over 900 smaller islands. The Solomon Islands, located east of Papua New Guinea and northwest of Vanuatu, consist of Melanesian islands including Guadalcanal. The country is named after this archipelago and excludes outlying islands like Rennell and Bellona. The Colletidae family of bees, known as plasterer bees, have unique nest-building methods using secretions to line their cells. The Colletidae family of bees, also known as plasterer bees, consist of five subfamilies, 54 genera, and over 2000 species. Two subfamilies, Euryglossinae and Hylaeinae, lack the external pollen-carrying apparatus and carry pollen in their crops. These bees have liquid or semiliquid pollen masses for larval development. Indonesia is a transcontinental country in Southeast Asia with over 17,000 islands, making it the world's largest island country. With a population of over 260 million, Indonesia is the world's fourth most populous country. Indonesia is a transcontinental country in Southeast Asia with over 17,000 islands and a population of over 260 million, making it the world's largest island country and the fourth most populous country. Ants, along with wasps and bees, belong to the order Hymenoptera and evolved from wasp-like ancestors about 99 million years ago. Ants, part of the order Hymenoptera, evolved from wasp-like ancestors 99 million years ago. Over 12,500 of 22,000 ant species have been classified, known for their elbowed antennae and slender waists. Tasmania is an island state of Australia, with a population of around 518,500. New Zealand is an island nation in the southwestern Pacific Ocean, comprising the North Island and the South Island. New Zealand is an island nation in the southwestern Pacific Ocean, comprising the North Island, or Te Ika-a-Mui, and the South Island, or Te Waipounamu. It is located east of Australia across the Tasman Sea and south of the Pacific island areas of New Caledonia, Fiji, and Tonga. New Zealand developed a unique biodiversity due to its isolation, with varied topography including sharp mountain peaks like the Southern Alps. Wellington is the capital city, and Auckland is the most populous city. New Zealand's unique biodiversity is attributed to its isolation and varied topography, including sharp mountain peaks like the Southern Alps. The capital city is Wellington, and the most populous city is Auckland. Angiosperms, the most diverse group of land plants, produce seeds within an enclosure, distinguishing them from gymnosperms. Pollination is the transfer of pollen for seed production. Angiosperms are fruiting plants with enclosed seeds. Pollination is crucial for fertilization and seed production in seed plants. Insects, the most diverse group of animals, play a key role in pollination. Invertebrates in the arthropod phylum, known as insects, are the most diverse group of animals on the planet, with over a million described species. The Stenotritidae family, the smallest bee family with 21 species in Australia, have unmodified mouthparts and are considered a sister taxon to the Colletidae family. The Stenotritidae family, with unmodified mouthparts, is considered a sister taxon to the Colletidae family. They are large, fast-flying bees that make burrows in the ground and provision masses in waterproof cells. Fossil brood cells of a stenotritid bee have been found in South Australia."
}