{
    "title": "HJlfAo09KX",
    "content": "We study model recovery for data classification using neural networks with sigmoid activations. Under Gaussian inputs, the empirical risk function exhibits strong convexity and smoothness, allowing gradient descent to converge linearly to a critical point close to the ground truth. This is the first global convergence guarantee for empirical risk minimization using cross entropy via gradient descent for learning one-hidden-layer neural networks. Neural networks have attracted research interest due to their success in practical domains like computer vision and artificial intelligence. Efforts have been made to understand the theoretical underpinnings behind their success, including model recovery to recover the underlying model parameter W for generalization. One model-recovery setup focuses on recovering the underlying model parameter W from training samples generated from a neural network model. Previous studies have looked at regression and classification problems using different types of data generations. The study focused on recovering neural network parameters in a two-layer feedforward network with ReLU activations. Previous research used gradient descent over squared loss for regression and classification problems. Statistical guarantees were provided for model recovery using squared loss, with considerations for sample complexity and convergence to the ground truth. The study aims to provide a statistical guarantee for recovering neural network parameters using the cross entropy loss function in a two-layer feedforward network with ReLU activations. Previous research focused on gradient descent with squared loss for regression and classification, showing guarantees for model recovery with considerations for sample complexity and convergence to the ground truth. This study presents the first performance guarantee for recovering one-hidden-layer neural networks using the cross entropy loss function. It shows that the empirical risk function based on cross entropy loss is uniformly strongly convex in a local neighborhood of the ground truth, with gradient descent converging linearly to a critical point. The sample complexity for convergence is near-optimal, and the recovery of parameters is up to a certain statistical accuracy. The study provides a performance guarantee for recovering one-hidden-layer neural networks using the cross-entropy loss function. It shows that the empirical risk function is uniformly strongly convex in a local neighborhood of the ground truth, with gradient descent converging linearly to a critical point. The sample complexity for convergence is near-optimal, and the recovery of parameters is up to a certain statistical accuracy. The convergence rate of W n to W is O(dK 9/2 log n/n) in the Frobenius norm, and a computational complexity of O(ndK 2 log(1/ ) is required for -accuracy. The tensor method proposed in BID38 provides an initialization near the ground truth, with new machineries developed to exploit statistical information of geometric curvatures. The proof focuses on analyzing the curvature of activation functions around W, developing new techniques to exploit statistical information of geometric curvatures. It also provides performance guarantees for classification using the squared loss function. The study emphasizes the relevance of parameter recovery in non-convex learning for signal processing problems. The relevance of viewpoint in non-convex learning for signal processing problems like matrix completion, phase retrieval, blind deconvolution, and tensor decomposition is crucial. Studies show that in large networks compared to data input, there are no spurious local minima, and all local minima are global. However, in cases with multiple neurons, spurious bad local minima can exist even at the population level. In the under-parameterized setting with multiple neurons, Tian studied the landscape of the population squared loss surface with ReLU activations, revealing spurious bad local minima. Zhong et al. provided characterizations for the local Hessian in regression with various activation functions. For a single neuron under Gaussian input, gradient descent converges linearly with ReLU activation and zero initialization. When the activation function has bounded derivatives, only the global minimum exists, and gradient descent converges linearly with any initialization. In a study on the landscape of the population squared loss surface with ReLU activations in the under-parameterized setting with multiple neurons, spurious bad local minima were revealed. Different characterizations for the local Hessian in regression with various activation functions were provided. For a single neuron under Gaussian input, gradient descent converges linearly with ReLU activation and zero initialization. BID21 demonstrated that with bounded derivatives, only the global minimum exists, and gradient descent converges linearly with any initialization. The study analyzed the cross entropy loss function with a unique form and focused on model recovery classification under the multi-neuron case, a topic not previously explored. Several papers on neural networks with different structures and loss functions were mentioned, but they are not directly comparable to the current study. The paper discusses various neural network structures and loss functions, such as non-overlapping convolutional networks, two-layer feedforward networks, and the Porcupine Neural Network. These results are not directly comparable to the current study. The paper is organized into sections describing problem formulation, local geometry, convergence of gradient descent, initialization methods, numerical examples, and conclusions. Notations for vectors, matrices, norms, and random variables are also defined. The paper introduces notation for matrices, norms, and random variables, and describes the generative model for training data and the gradient descent algorithm for learning network weights in a classification setting with sigmoid activation function. The paper introduces notation for matrices, norms, and random variables, and describes the generative model for training data and the gradient descent algorithm for learning network weights in a classification setting with sigmoid activation function. Given n training samples drawn i.i.d., the goal is to estimate W by minimizing the empirical risk function using the cross entropy loss. To avoid local minima, a well-designed initialization scheme is implemented in the gradient descent algorithm with a specific update rule. The gradient descent algorithm is implemented with a specific initialization scheme to avoid local minima. The update rule is defined as DISPLAYFORM0 with \u03b7 as the step size. The algorithm uses the same set of training samples throughout, unlike other methods that resample at each iteration. An important quantity regarding \u03c6(z) is introduced to capture the geometric properties of the loss function. The gradient descent algorithm uses a specific initialization scheme to avoid local minima and updates with a defined rule. It maintains the same training samples throughout. A key quantity related to \u03c6(z) is introduced to capture the loss function's geometric properties. The current chunk discusses the local strong convexity of the activation function and guarantees the positive definiteness of the Hessian of the empirical risk function in a local neighborhood with high probability. The Hessian of the empirical risk function in the local neighborhood of W is positive definite with high probability for the classification model with sigmoid activation function. Theorem 1 guarantees this property as long as certain conditions are met, ensuring the positive definiteness of the Hessian in a neighborhood of the ground truth W. Theorem 1 guarantees that the Hessian of the empirical risk function is positive definite in a local neighborhood of the ground truth W for the classification model with sigmoid activation. The sample complexity for this model is near-optimal in dimension up to polynomial factors of K and log d. Theorem 2 shows the existence of a critical point Wn close to W, where gradient descent converges linearly under certain conditions. Theorem 2 guarantees the existence of a critical point Wn close to W, where gradient descent converges linearly to Wn at a rate of O(K^(9/4) d log n/n). This critical point can be consistently recovered as n approaches infinity, with a computational complexity of O(ndK^2 log(1/\u03b5)) to achieve \u03b5-accuracy. The tensor method proposed in BID38 is used for initialization in gradient descent, converging linearly to Wn at a rate of O(K^(9/4) d log n/n). The computational complexity to achieve \u03b5-accuracy is O(ndK^2 log(1/\u03b5). The method involves defining product \u2297, estimating critical points, and initializing with Algorithm 2. The tensor method proposed in BID38 is used for initialization in gradient descent, converging linearly to Wn at a rate of O(K^(9/4) d log n/n). The method involves defining product \u2297, estimating critical points, and initializing with Algorithm 2. Let \u03b1 \u2208 R d denote a randomly picked vector. P 2 and P 3 are defined based on certain conditions. The initialization algorithm in Algorithm 2 includes estimating the direction of each column of W and approximating the magnitude and sign of w i. Assumptions are made regarding the activation function \u03c6(z) for the classification problem. The tensor method proposed in BID38 is used for initialization in gradient descent, converging linearly to Wn at a rate of O(K^(9/4) d log n/n). Assumptions are made regarding the activation function \u03c6(z) for the classification problem, including technical assumptions and conditions on the curvature of the activation function. The performance guarantee for the initialization algorithm is presented in Theorem 3, stating that under certain assumptions, the output W 0 \u2208 R d\u00d7K of Algorithm 2 satisfies certain conditions. The performance guarantee for the initialization algorithm in Theorem 3 ensures that the output W 0 of Algorithm 2 satisfies certain conditions. The proof involves accurate estimation of the direction and norm of W, with details provided in the supplementary materials. Gradient descent is implemented to verify strong convexity of the empirical risk function in the local region around W, leading to convergence to the same critical point W n with multiple initializations. In this section, gradient descent is used to verify the strong convexity of the empirical risk function around W. Multiple initializations in the local region lead to convergence to the same critical point Wn. The success rate of gradient descent is shown to be high with large enough sample complexity. The statistical accuracy of the local minimizer for gradient descent is analyzed when initialized close to the ground truth. Average estimation error decreases with increasing sample size, matching theoretical predictions. Gradient descent with cross entropy loss outperforms squared loss in terms of error rates. The study compares gradient descent performance with cross entropy and squared loss in a neural network classification problem. Cross entropy shows lower error rates, indicating its preference over squared loss. The sample complexity for local strong convexity is characterized, ensuring gradient descent convergence to the ground truth. Future analysis may extend to different activation functions and network structures. The study analyzes gradient descent convergence in neural networks, focusing on the population loss function and Hessian properties. The proof of Theorem 1 involves showing smoothness and strong convexity of the Hessian. Future work may explore different activation functions and network structures. The study focuses on analyzing gradient descent convergence in neural networks, specifically examining the Hessian properties of the population loss function. The Hessian of the empirical loss function is shown to be close to the Hessian of the population loss function in a uniform sense. Lemmas are used to establish local strong convexity and smoothness of the population loss function. The study analyzes gradient descent convergence in neural networks, focusing on the Hessian properties of the population loss function. Lemmas establish local strong convexity and smoothness of the population loss function. The proof of Theorem 1 combines Lemmas to show the gradient concentration around \u2207f (W) in B(W, r). Theorem 2 follows a similar proof structure. The proof of Theorem 2 shows the gradient concentration around \u2207f (W) in B(W, r) and guarantees the existence of a critical point W n in B(W, r). Gradient descent converges linearly to W n with a properly chosen step size. Lemmas 3 and 4 ensure the uniqueness of the critical point W n in B(W*, r). The proof guarantees the existence of a critical point W n in B(W, r) due to local strong convexity. Lemmas 3 and 4 ensure the uniqueness of W n. Gradient descent converges linearly to W n with a properly chosen step size. The proof establishes local linear convergence of gradient descent to the local minimizer W n. It consists of two parts: (a) ensuring accurate estimation of the direction of W, and (b) proving convergence based on a mild condition in Assumption 2. A tensor operation is defined for matrices A, B, and C. The proof details the tensor operation for matrices A, B, and C. It shows that for regression problems, estimation error is bounded using Bernstein inequality. The classification problem has similar results with slight differences in the proof. In the classification problem, Bernstein inequality is applied to all neurons together, with bounded labels y i. The regression model requires upper bounding of output y i via activation function conditions. A different proof for estimating w i is provided, not needing homogeneous activation function conditions. Quantity Q 1 is defined to estimate w i, with an optimization problem to solve. The text discusses the estimation of w i using Quantity Q 1 and an optimization problem. It involves substituting values and solving equations to obtain estimates. The text also mentions the existence of a constant \u03b4 and the conditions for Q 1 and Q 1 to be close. The text discusses the estimation of w i using Quantity Q 1 and an optimization problem. It involves substituting values and solving equations to obtain estimates. There is a constant \u03b4 such that the inverse function g(\u00b7) of m 3,1 (\u00b7) has an upper-bounded derivative in a specific interval. If the sample size is sufficient, Q 1 and Q 1 can be close. Definitions of sub-gaussian and sub-exponential norms are introduced, along with calculations of the gradient and Hessian of E [ (W ;. X, denoted as X \u03c81, is defined as a sub-gaussian random variable with calculations of the gradient and Hessian of E[(W; provided. The hessian block is written concisely, and the goal is to upper bound E T 2 j,l,k. The variable of g j,l(W) is in the form of w i x, and the scalar coefficient is upper bounded. The denominator is left after all upper bounds are considered, and a constant C is introduced. The text discusses upper bounding E T 2 j,l,k using Cauchy-Schwarz inequality and introduces a constant C. It also presents a lemma for sigmoid activation function and provides bounds for the Hessian of the population risk at ground truth. The text presents upper and lower bounds for the Hessian of the population risk at ground truth, and applies Lemma 1 to obtain a uniform bound in the neighborhood of W. It further discusses bounding strategies and provides proofs for the presented lemmas. The text discusses bounding strategies and provides proofs for lemmas related to the Hessian of the population risk at ground truth. It adapts analysis from a previous setting and introduces events A t, B t, and C t for further analysis."
}