{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The models are structured based on a causal graph and applied to conditional and interventional sampling of face images with binary feature labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. The optimal generator of CausalGAN samples from image distributions conditioned on labels, demonstrating the effectiveness of the proposed architectures. The proposed architectures, CausalGAN and CausalBEGAN, can sample from observational and interventional image distributions using adversarial training. Generative adversarial networks (GANs) are effective in training implicit generative models to sample from high-dimensional distributions. The generator network generates samples based on a noise vector, refined by a discriminator network. Generative adversarial networks (GANs) use backpropagation to train models for sampling from high-dimensional distributions. The generator network produces samples from noise vectors, refined by a discriminator network. GANs have been successful in generating samples like images and videos. Extensions include sampling from class conditional data distributions by providing class labels to the generator. Various neural network architectures have been proposed for this task. In this paper, the focus is on extending previous work on conditional image generation by capturing the dependence between labels and the causal effect between labels. Conditional image generation is viewed as a causal process where labels determine the image distribution. The generator maps labels to images non-deterministically, following the causal graph \"Labels cause the Image\". Conditional image generation involves capturing the dependence and causal effect between labels. The generator maps labels to images non-deterministically, following the causal graph \"Labels cause the Image\". Causal models allow sampling from conditional and interventional distributions in the context of different variables. Causal models enable sampling from conditional and interventional distributions. Interventions fix variable values in a causal graph, affecting descendant distributions but not ancestors. Causal implicit generative models (CiGM) can sample from correct joint, conditional, and interventional probability distributions. The objective is not to learn the causal graph but to capture causal relationships in sampling. In this work, causal implicit generative models (CiGM) are proposed to sample from correct joint, conditional, and interventional probability distributions. The true causal graph is assumed to be given, and GANs are used to train CiGM when the generator structure inherits neural connections from the causal graph. Wasserstein GAN is used to train a CiGM for binary image labels, followed by the proposal of conditional GANs called CausalGAN and CausalBEGAN. The optimal generator of CausalGAN can sample from true conditional distributions, and combining it with a CiGM on labels yields a CiGM on both labels and images. Our contributions include demonstrating that CausalGAN's optimal generator can sample from true conditional distributions and combining it with a CiGM on labels results in a CiGM on both labels and images. We also propose a two-stage procedure for training a CiGM over binary labels and images, introducing a novel conditional GAN architecture and loss function. Additionally, we extend BEGAN to accept labels, creating CausalBEGAN with a \"margin of margins\" term for improved performance. We propose CausalBEGAN, an extension of BEGAN that accepts labels and introduces a \"margin of margins\" term for improved image quality. Empirical results show that CausalBEGAN can produce high-quality, label-consistent images even for label combinations not seen during training. This model, along with CausalGAN, demonstrates the ability to sample from true conditional distributions and generate images based on both labels and images. In extending generative adversarial networks, ACGAN and InfoGAN propose new architectures to incorporate extra information like labels. Other models like BiGAN, ALI, CoGAN, and SD-GAN also enhance the standard GAN framework by learning mappings between image and latent spaces. These advancements allow for sampling from label combinations not present in the dataset. In extending generative adversarial networks, models like CoGAN and SD-GAN enhance the standard GAN framework by learning mappings between image and latent spaces. SD-GAN splits the latent space into \"Identity\" and \"Observation\" portions, allowing for the generation of faces with fixed identity portions. BID0 uses CGAN with a one-hot encoded vector to change the age attribute of a face image. Additionally, generative models can be applied in compressed sensing, providing guarantees for recovering a vector close to the output of a trained generative model. Generative models can be used for changing attributes of face images, such as age, by conditioning on a one-hot vector. They can also be applied in compressed sensing to recover a vector close to the output of a trained generative model. Recent research has focused on using causal principles in deep learning, with connections observed between GAN layers and structural equation models. Various approaches have been proposed to learn causal relations between variables and image class labels using neural networks and causal regularization techniques. In recent research, causal principles have been applied in deep learning, with connections between GAN layers and structural equation models. Various approaches, such as causal regularization, have been proposed to learn causal relations between variables and image class labels using neural networks. Pearl's framework of structural causal models (SCMs) is used to represent causal models with directed acyclic graphs and structural equations. Within the SCM framework, causal models are represented by variables X and Y, where X causes Y through a function f and an unobserved variable E. The causal graph is depicted as X \u2192 Y in a directed acyclic graph. A structural causal model consists of functions, random variables, exogenous variables, and a probability distribution over the exogenous variables. A structural causal model (SCM) is defined by a tuple containing functions, random variables, exogenous variables, and a probability distribution. The causal graph in SCM is a directed acyclic graph where nodes represent variables and their relationships. Interventions in SCM change the causal mechanism and corresponding causal graph by disconnecting nodes from their parents. Interventions in a structural causal model (SCM) disconnect nodes from their parents, changing the causal graph. The post-interventional distribution can be calculated for a set of nodes by factorizing the observational distribution. Identifying the true causal graph without experiments or additional assumptions is generally not possible due to multiple causal graphs. The post-interventional distribution for a set of nodes in a causal graph is determined by factorizing the observational distribution. Identifying the true causal graph without experiments is challenging due to multiple possible causal graphs. This paper focuses on learning a causal model assuming the causal graph is known, with prior work available for learning causal graphs. Using a Bayesian network that respects conditional independences allows sampling from correct observational distributions. The impact of the Bayesian network is explored in later sections. Implicit generative models can sample from data distribution but not interventional distributions. Causal implicit generative models allow sampling from both types. Generative adversarial networks can train causal implicit generative models by arranging connections to reflect causal graph structures. In the GAN training framework, generator neural network connections reflect the causal graph structure. Feedforward neural networks represent functions f X , f Y , f Z with independent noise terms (N X , N Y , N Z ). Gaussian distributed variables can be used for rich function classes. The feedforward neural network represents causal models with a graph. Two causal models with the same observational distribution have the same interventional distributions for any intervention. Definition ties a feedforward neural network with a causal graph. In the context of GAN training, the generator neural network connections mirror the causal graph structure. A feedforward neural network is linked to a causal graph, defining causal implicit generative models. These models, known as CiGMs, are trained using adversarial training to align with the causal graph, allowing for image generation applications. The proposed approach involves training a causal implicit generative model (CiGM) using adversarial training to align with the causal graph structure. The training process is divided into two subtasks: first, training a generative model for labels, and then training a generative model for images conditioned on the labels. This architecture ensures consistency with the causal structure, with the image node always considered as the sink node in image generation problems. The proposed approach involves training a causal implicit generative model (CiGM) by first training a generative model for labels and then training a generative model for images conditioned on the labels. The new architecture and loss function (CausalGAN) ensure that the optimum generator outputs label-conditioned image distributions, assuming a strictly positive joint distribution over the labels. The Causal Controller, a generative model for binary labels, is used to control the distribution from which images are sampled based on a set of labels. The Causal Controller, a generative model for binary labels, is used to control the distribution from which images are sampled based on a set of labels. To sample from a discrete distribution, a WGAN is employed, replacing the Lipschitz constraint with a penalty term in the loss function. This new architecture and loss function are part of the two-step process for learning a CiGM over labels and image variables. The Causal Controller is utilized to control image sampling based on labels, using a penalty term in the loss function instead of a Lipschitz constraint. A new conditional GAN architecture is designed to generate images based on labels, ensuring realistic outputs and label consistency. Two separate labeler neural networks are employed, along with a generator with the objective of producing realistic images, consistent with labels, and avoiding easy-to-label distributions. CausalGAN stands out from other conditional GAN architectures in its approach. The Causal Controller is used to control image sampling based on labels, with a penalty term in the loss function. CausalGAN's generator aims to produce realistic images, consistent with labels, and avoid easy-to-label distributions by utilizing an Anti-Labeler network. This helps prevent label-conditioned mode collapse and promotes faster convergence. The Anti-Labeler network helps prevent label-conditioned mode collapse and promotes faster convergence in CausalGAN by controlling image sampling based on labels. The generator loss function includes label loss terms and additional terms to ensure optimal outputs of class conditional image distribution. The generator loss function of CausalGAN includes label loss terms and GAN loss, with an added term from the discriminator. The optimal generator outputs the class conditional image distribution, proven true for multiple binary labels. The Labeler and Anti-Labeler networks solve optimization problems, while the discriminator and generator also have their own optimization tasks. The best CausalGAN generator samples from the class conditional image distribution when all networks operate optimally. The optimal generator for CausalGAN samples from the class conditional image distribution when all networks operate optimally. This architecture is the only one with this guarantee after CGAN. The generator minimizes the loss function by sampling from the class conditional distributions. The generator minimizes the loss function by sampling from the class conditional distributions, achieving the global minimum of the virtual training criterion. This two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The generator samples from class conditional distributions to minimize the loss function and achieve the global minimum of the virtual training criterion. The model aims to extend results to cases with multiple binary labels, proposing an alternative architecture using cross entropy loss terms for each label to simplify implementation. The proposed alternative architecture extends the single binary label setup by using cross entropy loss terms for each label. This ensures that the generator captures the joint label posterior given the image, leading to sampling from class conditional distributions. The model also discusses the use of causal implicit generative models for counterfactual sampling when exogenous noise terms are known. The text discusses using causal implicit generative models for counterfactual sampling by conditioning on events and sampling from posterior distributions. It also introduces an extension of BEGAN where image labels are fed to the generator, with details provided in the Appendix. The architecture includes a Labeler network for labeling real images well and generated images poorly. The text discusses using causal implicit generative models for counterfactual sampling by conditioning on events and sampling from posterior distributions. The architecture includes a Labeler network for labeling real images well and generated images poorly, with details provided in the Appendix. The CausalGAN and CausalBEGAN models are trained on the CelebA Causal Graph dataset. The final observation suggests a margin of margins term comparing the first two margins. CausalGAN and CausalBEGAN are trained on the CelebA Causal Graph dataset. The top row shows both males and females with mustaches, while the bottom row shows only male images sampled from the conditional distribution P(.|Mustache = 1). In CelebA Causal Graph, the generative model can create samples conditioned on labels and sample from interventional distributions. Intervening on Narrow Eyes=1 does not affect the probability of Smiling=1, but conditioning on Narrow Eyes=1 increases the proportion of smiling images in the dataset. Causal models like CausalBEGAN in CelebA Causal Graph show that intervening on Narrow Eyes=1 does not affect the probability of Smiling=1, but conditioning on Narrow Eyes=1 increases the proportion of smiling images in the dataset. This leads to more creative generative models that can produce diverse samples. The research acknowledges support from various grants and organizations. A structural causal model consists of functions, random variables, exogenous variables, and a probability distribution. The causal graph is a directed acyclic graph representing the relationships between variables. Causal sufficiency is assumed, where each exogenous variable is a direct parent of at most one observable variable. The text discusses Bayesian networks and causal sufficiency assumptions in the context of a structural causal model. It mentions the calculation of interventional distributions and introduces joint data distributions for binary labels and images. The optimal discriminator D is defined for a fixed G according to Proposition 2 from Goodfellow et al. (2014). The text discusses Bayesian networks, causal sufficiency assumptions, and optimal Labeler and Anti-Labeler in the context of a structural causal model. It introduces joint data distributions for binary labels and images, and defines the optimal discriminator D for a fixed G based on Proposition 2 from Goodfellow et al. (2014). The text discusses the optimum Anti-Labeler in a structural causal model under causal sufficiency assumptions. It defines the generator loss and the conditions for achieving the global minimum of the virtual training criterion. The text discusses the conditions for achieving the global minimum of the virtual training criterion in a causal implicit generative model for the causal graph D. It involves the relationship between the generator output and the class conditional image distribution. The text discusses the conditions for achieving the global minimum of the virtual training criterion in a causal implicit generative model for the causal graph D. It involves the relationship between the generator output and the class conditional image distribution. The observational joint distribution over labels is strictly positive. Generator G can sample from the image distribution conditioned on the given label combination. The concatenated generator neural network is consistent with the causal graph D. The concatenated model can sample from the true observational and interventional distributions. Modifications are explained for extending the proof to the case with multiple binary labels. The concatenated model is a causal implicit generative model for graph D, able to sample from true observational and interventional distributions. Modifications are discussed for extending the proof to cases with multiple binary labels, addressing the challenge of characterizing the joint distribution. Two solutions are proposed, including estimating probabilities of label combinations or using Labelers to estimate probabilities of individual labels to ensure consistency at the minimizer of C(G). The extension presented in this section discusses using Labelers to estimate probabilities of individual labels to ensure consistency at the minimizer of C(G). The optimum Labeler with respect to the loss has D * LR (x)[j] = P r (l = j|x). The Labeler loss can be expressed as DISPLAYFORM3. The optimum Labeler network provides the posterior probability of a label combination given an observed image. The constraint that the coordinates sum to 1 can be satisfied using a softmax function in the implementation. The optimum Labeler network gives the posterior probability of a label combination based on an observed image. The Anti-Labeler network solves a different optimization problem and has a corresponding loss function. The generator also has its optimization problem, with a theorem showing the optimal generator samples from class conditional image distributions given a specific label. The generator aims to optimize the conditional entropy of labels given the image. The optimal generator samples from class conditional image distributions based on specific label combinations. The global minimum of the virtual training criterion is achieved when the generator's distribution matches the true joint label distribution. Theoretical guarantees for the implemented CausalGAN architecture with d labels are provided under the assumption of deterministic relationship between images and labels. This ensures the global optimal generator samples from class conditional distributions. The implemented CausalGAN architecture with d labels assumes a deterministic relationship between images and labels, guaranteeing the global optimal generator samples from class conditional distributions. The optimization problems for the Anti-Labeler, Labeler, and generator are defined, with a proposition characterizing the optimum generator. The global minimum of the virtual training criterion is achieved when certain conditions are met. The global minimum of the virtual training criterion is achieved when certain conditions are met, including the assumption that the image determines all labels. This assumption is relevant in practice, ensuring correct conditional sampling given all labels. The Kronecker delta function is used in a lemma to further explain this concept. The Kronecker delta function is used in a lemma to show that a discrete joint probability distribution with all marginal probability distributions being Kronecker delta functions is the product of these marginals. The lemma demonstrates that the joint probability distribution is zero everywhere except at specific points. The Kronecker delta function is utilized in a lemma to prove that a discrete joint probability distribution, where all marginal distributions are Kronecker delta functions, is the product of these marginals. This implies that the joint distribution is only non-zero at specific points. In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The approach is inspired by control theory and encourages generator training when the discriminator is near optimum. The introduction of a new loss and margins reflects the idea that label gradients are most informative when image quality is high. The proposed extension of BEGAN involves feeding image labels to the generator, inspired by control theory. A new loss and margins are introduced to emphasize that label gradients are most informative when image quality is high. The formulation includes the generator function G and loss functions, but lacks consideration of margins critical in the BEGAN framework. The proposed extension of BEGAN involves incorporating image labels into the generator to improve image quality. A new loss function and margins are introduced to emphasize the importance of label gradients when generating high-quality images. The formulation includes the generator function G and loss functions, but lacks consideration of margins critical in the BEGAN framework. The extension of BEGAN involves incorporating image labels to improve image quality by introducing a new margin of margins term. This allows for the tracking of convergence during optimization and explores the behavior of causal implicit generative models on synthetic data with different causal graphs. In this study, the behavior and convergence of causal implicit generative models are investigated on synthetic data with different causal graphs. Three causal graphs are considered: \"line\" X \u2192 Y \u2192 Z, \"collider\" X \u2192 Y \u2190 Z, and \"complete\" X \u2192 Y \u2192 Z, X \u2192 Z. The convergence of the joint distribution to the true joint is compared for different generator structures, including fully connected neural networks with no knowledge of causal structure. The study investigates the convergence of causal implicit generative models on synthetic data with different causal graphs: \"line\", \"collider\", and \"complete\". Results show the behavior of generators structured based on these causal graphs, with expectations of convergence when the generator aligns with the true causal graph. The study explores the convergence of causal implicit generative models on synthetic data with different causal graphs: \"line\", \"collider\", and \"complete\". Results indicate that the generator's structure should align with the true causal graph for optimal convergence behavior. The performance of different generator architectures, such as complete graph and fully connected layers with varying depths, is analyzed, showing that the number of layers in fully connected networks needs to be tuned for effective performance in adversarial training. Using the wrong Bayesian network, like the collider, leads to inferior results. The study explores the convergence of causal implicit generative models on synthetic data with different causal graphs. Results show that the generator's structure should align with the true causal graph for optimal performance. Different generator architectures, such as fully connected layers with varying depths, need to be tuned for effective performance in adversarial training. Using the wrong Bayesian network, like the collider, leads to inferior results. The study evaluates the impact of using different causal graphs on an artificially generated dataset. The correct causal graph produces the closest scatter plot to the original data, while using the wrong graph results in a significantly different distribution. The generator's structure should align with the true causal graph for optimal performance in causal implicit generative models. The study compares the impact of using different causal graphs on an artificially generated dataset. The correct graph produces a scatter plot closest to the original data, while the wrong graph results in a different distribution. The causal graph used for experiments on the CelebA dataset is discussed, including the CelebA Causal Graph (G1) and its variations. The effect of using the incorrect Bayesian network for the data is also examined. The study analyzes the impact of using different causal graphs on an artificial dataset. The incorrect Bayesian network generates Male and Young independently, leading to inaccurate distributions. Despite this, both graphs G1 and cG1 result in Causal Controllers that never output {Female, Mustache}. Wasserstein GAN with a modified version ensures convergence in distribution of the Causal Controller output. The outputs have \"approximately discrete\" support, as shown in FIG12. The study demonstrates the convergence in distribution of the Causal Controller output using a modified version of Wasserstein GAN. The outputs have \"approximately discrete\" support, as evidenced in FIG12. Additionally, the CelebA Causal Graph (G1) and its completion (cG1) allow training of reasonable marginal distributions for all labels. The Wasserstein Causal Controller is tested on a subset of binary labels from the CelebA dataset using a causal graph. The generator learns to map continuous noise to a discrete distribution, with 96% of samples appearing near 0 or 1. Total variational distance (TVD) shows convergence for different graph variations, with TVD decreasing to 0.14 for the original graph. The total variational distance (TVD) measures convergence for different CelebA Causal Graph variations, showing TVD decreasing to 0.14 for the original graph. Additional CausalGAN results are presented, including interventions and conditioning on wearing lipstick. The CelebA Causal Graph includes interventions and conditioning on wearing lipstick and narrow eyes. Intervening on wearing lipstick does not affect the probability of male gender, while conditioning on narrow eyes increases the proportion of smiling images. CausalBEGAN is trained on the CelebA dataset using the CelebA Causal Graph. The CelebA Causal Graph includes interventions and conditioning on various attributes. CausalBEGAN is trained on the CelebA dataset using this graph. Training the model without a specific margin affects image quality for rare labels. Intervening and conditioning on specific labels like Bald show differences in image sampling. The CelebA Causal Graph is used for interventions and conditioning in CausalBEGAN training on the CelebA dataset. Intervening and conditioning on attributes like Bald result in differences in image sampling, showcasing the conditional image generation properties of CausalGAN. In this section, additional simulations for CausalGAN and CausalBEGAN are provided. CausalGAN shows increased smiling images with Open = 1, while CausalBEGAN explores image diversity and the impact of a third margin term on image quality. The conditional image generation properties of both models are demonstrated through label sweeps. The text discusses the properties of CausalBEGAN, showing monotonically decreasing scalar \"M\" during training and image generation using label sweeps. It highlights the discrete function learning of the generator and presents image diversity through random sampling. The approach involves jointly training a causal generative model for labels and images, treating the image as part of the causal graph. In this section, the text explains the challenges faced in jointly training an implicit causal generative model for labels and images. The approach involves encoding labels as a constant image in an additional channel, but the image generation is not effectively learned. The implementation details of CausalGAN, CausalBEGAN, and the Wasserstein Causal Controller for generating face labels are discussed, with the success of the models evaluated using the total variation distance metric. The Wasserstein approach involves estimating the gradient term as a penalty by evaluating gradients between real and fake batches. The Wasserstein Causal Controller is used to generate face labels, with the success of the models evaluated using the total variation distance metric. The generator architecture is based on a causal graph, using uniform noise as exogenous variables and neural networks. The training involves Wasserstein discriminator updates and stochastic gradient descent. The DCGAN implementation is extended into the Causal GAN framework with Labeler networks added. In the Causal GAN framework, the discriminator and labeler networks are updated concurrently, with 6 generator updates for each discriminator update on average. The loss terms are modified to accommodate a d-dimensional label vector, where the Labeler and Anti-Labeler loss terms are extended by averaging the loss terms for every label. This differs from the architecture where the discriminator outputs a length-2d vector to estimate probabilities of all label combinations given the image. The labeler and anti-labeler loss terms are averaged for every label in the Causal GAN framework. The architecture differs from Section 8.6 as it does not guarantee sampling from class conditional distributions. Swapping the order of terms in the cross entropy expressions for labeler losses has improved image sharpness. Labels input to CausalBEGAN are from the Causal Controller with minimal parameter tuning and a shared learning rate of 0.00008 for the generator and discriminator. The implementation involves swapping the order of terms in cross entropy expressions for labeler losses, resulting in sharper images. Labels for CausalBEGAN are from the Causal Controller with minimal parameter tuning. A shared learning rate of 0.00008 is used for both the generator and discriminator. Customized margin learning rates are also utilized for asymmetry in generator response. The best models exhibit active margins near 0 while occasionally taking small positive values. In comparing CausalGAN behavior with and without Anti-Labeler network, using Anti-Labeler allows for faster convergence and provides more diverse images for very rare labels. The best performing models have active margins near 0 while occasionally taking small positive values."
}