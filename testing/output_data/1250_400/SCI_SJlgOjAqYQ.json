{
    "title": "SJlgOjAqYQ",
    "content": "We conducted experiments to test global translation-invariance in deep learning models trained on the MNIST dataset. Both convolutional and capsules neural networks showed poor performance in this aspect, but data augmentation improved their performance. While the capsule network performed better on the MNIST testing dataset, the convolutional neural network generally had better translation-invariance performance. CNNs have achieved state-of-the-art performance in computer vision tasks due to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. CNNs need to learn different models for different viewpoints, requiring big data and high costs. Capsule networks aim for 'rate-coded' equivariance by encoding viewpoint-invariant knowledge in weights, not neural activities. They handle different viewpoints robustly by representing visual entities with capsules containing pose, color, lighting, and deformation information. However, it remains unclear if capsule networks can generalize for global translation invariance. Understanding translation-invariance in deep learning models is crucial for developing generalization models that are invariant to viewpoint changes. In this study, a method is introduced to test global translation-invariance in convolutional and capsule neural network models trained on the MNIST dataset. A testing dataset is created by shifting the centre of mass of a Helvetica font digit one pixel at a time. This dataset consists of 2520 testing images, covering all possible locations of the centre of mass for each digit. The GTI testing dataset consists of 2520 images with the centre of mass of a Helvetica font digit shifted pixel by pixel. It is used to test deep learning models trained on the MNIST dataset for global translation-invariance. The GTI dataset covers all possible translations and is robust to random noise, unlike the MNIST dataset. The advantage of the GTI training dataset is its ability to capture subtle differences between models. The CNN model used in the study has nine layers, including convolutional and fully connected layers with specific filter sizes and channel numbers. Dropout is applied to certain layers, and the total number of parameters is significantly smaller compared to Capsule networks. The model uses ReLU activation function for most layers and Adam optimizer. The CNN model consists of 9 layers with specific sizes for fully connected layers. Dropout with a rate of 0.5 is applied to certain layers. The total number of parameters is 361578, much smaller than Capsule networks. ReLU is used for most layers except the last layer, which uses softmax. The optimizer is Adam with default parameters. The model achieves high accuracy on the MNIST testing set but struggles with global translational invariance. Images with the digit's center predicted correctly, while those at the corner are often misclassified. The CNN model achieves high accuracy on the MNIST testing set but struggles with global translational invariance. Images with the digit's center predicted correctly, while those at the corner are often misclassified. To improve performance on the GTI dataset, data augmentation by shifting images from the center in x and y-direction was implemented. This increased accuracy on the GTI testing dataset to 98.05%. Data augmentation implies 'place-code' equivariance in CNN. The CapsNet model, with 8.2M parameters, was tested on the GTI dataset using data augmentation. The model showed improved accuracy of 98.05% by randomly shifting images during training. Capsule network demonstrates robustness in viewpoint invariance but struggles with global invariance. Data augmentation in training dataset helps CapsNet performance. The experiment showed that Capsule Network's performance on global invariance needs improvement. Data augmentation in the MNIST training dataset helped improve CapsNet accuracy on the GTI dataset. However, CNN generally outperformed CapsNet on the GTI dataset, even with wider receptive fields in CapsNet's convolutional layers. The removal of max-pooling layers in CapsNet may be a reason for its lower performance on the GTI dataset, indicating room for improvement in handling translational invariance. The Capsule Network's performance on global translational invariance needs improvement, as shown in the experiment. Despite data augmentation in the MNIST training dataset, CNN generally outperformed CapsNet on the GTI dataset. The removal of max-pooling layers in CapsNet may contribute to its lower performance, indicating room for improvement in handling translational invariance. CapsNet architecture has potential advantages over CNN in dealing with global translational invariance due to capsules' ability to learn viewpoints regardless of information source. The Capsule Network's performance on global translational invariance needs improvement, as shown in the experiment. Testing method involves GTI dataset accuracy of models trained on CNN and CapsNet with different random shifting in MNIST training dataset. It is quantifiable and easy to implement for other computer vision tasks by applying translational shifting to cover all possible cases."
}