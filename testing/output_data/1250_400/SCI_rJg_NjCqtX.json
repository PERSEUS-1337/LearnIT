{
    "title": "rJg_NjCqtX",
    "content": "Chemical information extraction involves converting chemical knowledge in text into a chemical database by identifying and standardizing compound names. A framework using spelling error correction, tokenization, and neural models was proposed to standardize non-systematic names to systematic names, achieving 54.04% accuracy on the test dataset. Systematic names are essential to uniquely identify the over 100 million named chemical substances worldwide. The International Union of Pure and Applied Chemistry (IUPAC) defines rules for assigning systematic names to chemical substances. However, besides systematic names, there are also common names and new names generated by producers in the pharmaceutical industry to distinguish their products. Chemical information extraction involves extracting useful chemical knowledge from text and converting it into databases, relying on unique standard chemical names. Various databases like PubChem and SciFinder store chemical information including names, structures, and formulas. Updating these databases involves extracting information from chemical papers. If all substances were expressed by systematic names, it would simplify database updates. Chemical databases like PubChem and SciFinder store chemical information such as names, structures, and formulas. Extracting chemical information from papers to update these databases is ongoing work. Converting systematic names to SMILES and InCHI can generate structural formulas. OPSIN is a system that can convert systematic names to SMILES with high precision. Non-systematic names can lead to errors like spelling mistakes. In natural language processing, errors in non-systematic chemical names can be categorized into four types: spelling error, ordering error, common name error, and synonym error. These errors can occur simultaneously in a single non-systematic name, especially ordering and synonym errors. For example, 2-(Acetyloxy)benzoic Acid has synonyms Acetylsalicylic Acid and Acetysal, all sharing the root word \"Acety\". Based on the errors in non-systematic chemical names, a framework is proposed to automatically convert them to systematic names. The framework includes spelling error correction, BPE tokenization, and a sequence to sequence model to fix ordering and synonym errors. Limited work has been done in chemical name standardization, with BID2 being a notable citation for developing an online system called ChemHits. The framework proposed aims to automatically convert non-systematic chemical names to systematic names by utilizing a sequence to sequence model. Unlike previous work like BID2, this approach is fully data-driven and does not rely on external chemical knowledge. The model achieves an accuracy of 54.04% on the test dataset. Our framework aims to convert non-systematic chemical names to systematic names using a fully data-driven approach. The corpus contains 384,816 data pairs of chemical substances. The Levenshtein distance distribution between non-systematic and systematic names is shown in FIG1. The experiment uses 80% training data, 19% test data, and 1% development data. The goal is to correct spelling errors in chemical substance names. In the experiment, the Levenshtein distance distribution between non-systematic and systematic chemical names is analyzed using 80% training data, 19% test data, and 1% development data. The goal is to correct spelling errors by separating chemical names into elemental words and building vocabularies of systematic and non-systematic elemental words. The experiment analyzes the Levenshtein distance distribution between non-systematic and systematic chemical names to correct spelling errors. Elemental vocabularies are built by separating chemical names into systematic and non-systematic words, combining them to create a final elemental vocabulary. The BK-Tree structure is used for efficient correction searches based on Levenshtein distance. The BK-Tree is used to efficiently correct spelling errors in chemical names by finding the closest match based on Levenshtein distance. It allows for easy insertion of new training data, making it scalable. By inputting elemental words one by one, the BK-Tree can correct non-systematic names, reducing noise in training data for sequence to sequence models. After correcting non-systematic names using the BK-Tree, the elemental words are combined to form the full chemical name. This process helps reduce noise in training data for sequence to sequence models. Tokenization of chemical names is done using Byte Pair Encoding (BPE) BID11 to prepare for the sequence-to-sequence model application. The text discusses the tokenization of chemical names using Byte Pair Encoding (BPE) BID11 for sequence-to-sequence model application. BPE helps in dealing with out-of-vocabulary problems and separates names into meaningful subwords by finding frequently appearing small molecules in the corpus. The text discusses the application of Byte Pair Encoding (BPE) for tokenizing chemical names to train a sequence-to-sequence model. The model consists of an encoder using a multilayer bidirectional LSTM to generate context vectors and a decoder to produce systematic names from non-systematic ones. The text describes the use of a multilayer bidirectional LSTM for encoding sequences and a decoder for generating output sequences in a sequence-to-sequence model. Parameters such as threshold values for BK-Tree and merge operations for BPE are experimented with. The model uses 500 dimensions for word embeddings and hidden states, with various values tested for the vocabulary size. In experiments, various threshold values and merge operation numbers were tested. The sequence-to-sequence model used 500 dimensions for word embeddings and hidden states, with encoder and decoder both having 2 layers. Parameters were trained jointly using SGD with a cross-entropy loss function. The model was trained for 15 epochs with a dropout rate of 0.3 and a beam search was applied. The model is trained for 15 epochs with a dropout rate of 0.3 and a beam size of 5 for decoding. A comparison experiment is done with a Statistical Machine Translation model using Moses system and KenLM for language modeling. Data augmentation is used to handle noisy data, specifically spelling errors, by inserting errors with a probability of 0.025. Data augmentation is utilized to handle noisy data, such as spelling errors, by inserting errors with a probability of 0.025. Four types of error insertion methods are applied equally: inserting a random character, deleting a random character, exchanging two characters, and replacing a character with another random character. The experiment measures standardization quality using accuracy and BLEU score BID10, with the best performance achieved by combining spelling error correction, BPE tokenization, and a sequence to sequence model. The experiment results for different models on a test dataset are shown in TAB3, with the combination of spelling error correction, BPE tokenization, and sequence to sequence model achieving the best performance. The framework shows improvement compared to the SMT model and the ChemHits system. Results for different numbers of BPE merge operations are shown in TAB4, with 5000 being the best value. Different Levenshtein distance thresholds for spelling error correction and the impact of data augmentation are shown in TAB5, highlighting the helpfulness of spelling error correction and the limited performance of data augmentation. The experiment results in TAB5 show the impact of error correction and data augmentation. Spelling error correction improves the framework, while data augmentation has limited performance. Overcorrection can reduce standardization quality. Examples in Table 6 demonstrate the capabilities of the sequence to sequence model in correcting non-systematic names. The sequence to sequence model successfully corrects non-systematic chemical names, such as ethane,1,2-dichloro to 1,2-dichloroethane and adenine,9-methyl-(7ci,8ci) to 9-methyl-9H-purin-6-amine. The model can find relations between different chemical names and standardize them effectively. The system successfully standardizes non-systematic chemical names, with examples provided in Table 6. However, there are challenges in standardizing common names, with synonym errors being the most common issue. Out of 100 samples of failed attempts, some are nearly correct while others are completely incorrect. The system struggles with finding a rule between unseen common names and their systematic counterparts. Our system struggles with standardizing non-systematic chemical names, especially for names longer than 60 characters. The model does not consider chemical rules, leading to errors in generated names. Examples of failed attempts are shown in Table 8. Our model struggles with standardizing non-systematic chemical names due to the lack of consideration for chemical rules. Examples of failed attempts are provided, showcasing errors in the generated names. Our proposed framework utilizes spelling error correction, byte pair encoding tokenization, and a sequence to sequence model to convert non-systematic names to systematic names, achieving an accuracy of 54.04% on our dataset. This approach significantly outperforms previous rule-based systems, enabling improved chemical information extraction. Our framework, utilizing spelling error correction, byte pair encoding tokenization, and a sequence to sequence model, achieves an accuracy of 54.04% on our dataset. It outperforms previous rule-based systems and enables improved chemical information extraction. The framework is trained end to end, fully data-driven, and independent of external chemical knowledge, starting a new research line in chemical information extraction."
}