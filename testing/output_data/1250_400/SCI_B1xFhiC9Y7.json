{
    "title": "B1xFhiC9Y7",
    "content": "Predicting structured outputs like semantic segmentation requires expensive per-pixel annotations for training convolutional neural networks. To address the challenge of generalizing to new domains without annotations, a domain adaptation method is proposed. This method involves learning discriminative feature representations of patches based on label histograms in the source domain and using an adversarial learning scheme to align feature distributions between source and target patches. The framework also includes a global alignment process and achieves state-of-the-art performance on semantic segmentation tasks. Extensive experiments on benchmark datasets demonstrate the effectiveness of the approach. The framework integrates global alignment with patch-level alignment for semantic segmentation, achieving state-of-the-art performance. Extensive experiments on various datasets show the effectiveness of domain adaptation methods for pixel-level predictions. Existing methods for image classification have been developed, but there is still room for improvement in domain adaptation for pixel-level prediction tasks like semantic segmentation. Domain adaptation is crucial for pixel-level predictions due to the high cost of annotating ground truth. State-of-the-art methods use feature-level or output space adaptation to align distributions between source and target domains using adversarial learning. However, global statistics may differ significantly between domains, leading to misalignment and potential bias during adaptation. Matching patches that are more likely to be shared across domains is considered as a solution. Global statistics may differ significantly between domains, leading to misalignment and bias during adaptation. To address this, matching patches shared across domains is considered. Adversarial learning is used to align patch distributions, guided by recent advances in learning disentangled representations. This approach aims to learn discriminative representations for source patches and push target representations close to the distribution of source ones. The proposed method aims to align patch distributions between source and target domains by learning discriminative representations for patches and utilizing adversarial modules. Pixel-level annotations are used to extract label histograms as patch-level representations, which are then clustered to guide the learning process. The proposed method aligns patch distributions between source and target domains by learning discriminative representations and utilizing adversarial modules. Pixel-level annotations are used to extract label histograms as patch-level representations, which are clustered to guide the learning process and transfer discriminative representations from the source to the target domain. An adversarial loss is used to align feature representations of target patches with the distribution of source patches in a clustered space. The proposed framework utilizes global and patch-level adversarial learning modules for domain adaptation in structured output prediction. Experiments include synthetic-to-real and cross-city scenarios, showing favorable performance compared to state-of-the-art methods in terms of accuracy and visual quality. The framework is general and could be applied to other structured outputs such as depth. The proposed framework for domain adaptation in structured output prediction utilizes global and patch-level adversarial learning modules. It includes a method to learn discriminative representations guided by label histograms of patches through clustering. The adaptation method outperforms various baselines and state-of-the-art methods on semantic segmentation tasks. Domain adaptation approaches for image classification and pixel-level prediction tasks are discussed, along with algorithms for learning disentangled representations. Algorithms for learning disentangled representations in domain adaptation for image classification tasks involve aligning feature distributions between source and target domains. Conventional methods minimize domain discrepancy using hand-crafted features, while recent approaches utilize deep architectures to learn domain-invariant features. Adversarial learning schemes and Maximum Mean Discrepancy are commonly used, with variations in classifiers and loss functions. Recent work focuses on enhancing feature representations through pixel-level transfer and domain separation. Domain adaptation for structured pixel-level predictions, such as semantic segmentation, is less studied but shows promise in addressing the synthetic-to-real image domain adaptation problem. Domain adaptation for structured pixel-level predictions, like semantic segmentation, is a less explored area compared to image classification tasks. Methods like BID14 and CDA (BID36) use adversarial networks and SVM classifiers to align feature representations and label distributions across different domains. These approaches also incorporate class-specific priors and object priors to aid in the alignment process. Overall, these domain adaptation methods focus on global distribution alignment and class-specific priors to match statistics between source and target domains. In contrast to existing domain adaptation methods focusing on global distribution alignment and class-specific priors for structured output, our proposed approach learns discriminative representations for patches to aid in patch-level alignment. This framework does not require additional priors/annotations and enables end-to-end training. Additionally, our algorithm focuses on learning patch-level representations to improve the alignment process, unlike other methods that focus on class-wise alignment. Our algorithm focuses on learning patch-level representations to aid in the alignment process, inspired by the benefits of learning a latent disentangled space for tasks like facial recognition and image generation. This approach aims to improve alignment without the need for additional priors or annotations, enabling end-to-end training. Our proposed domain adaptation framework leverages discriminative representations for patches to align distributions across domains, without the need for pre-defined factors. The goal is to predict structured outputs by aligning the predicted output distribution of target data with the source distribution using supervised learning and adversarial loss. The proposed domain adaptation framework aims to align distributions across domains by leveraging discriminative representations for patches. It involves using supervised learning and adversarial loss to predict structured outputs and align the predicted output distribution of target data with the source distribution. Additionally, a classification loss in a clustered space is incorporated to learn patch-level discriminative representations from the source output distribution. An adversarial loss is also employed to align patch-level distributions between the source and target data. The adaptation task involves loss functions for structured prediction and discriminative representation on source data, with clustering for ground truth label distribution. Global and patch-level adversarial loss functions are used to align the target distribution. The baseline model includes a supervised cross-entropy loss and an output space adaptation module for global alignment. The structured output is predicted by a fully-convolutional network, with the loss optimized over spatial map indices and categories. The text discusses using a fully-convolutional network for global alignment and optimizing loss functions for structured prediction. It also introduces patch-level alignment for transferable structured output representations shared across source and target images. The text introduces patch-level alignment for transferable structured output representations shared across source and target images. It proposes clustering patches from the source domain to construct prototypical patch patterns, guiding patches from the target domain to adapt to this space via adversarial objective. The proposed method involves clustering patches from the source domain to create prototypical patch patterns. Patches from the target domain then adapt to this space by selecting the closest cluster, guided by an adversarial objective. The goal is to achieve patch-level alignment for transferable structured output representations. The method involves constructing a semantically disentangled space of patch representations by using label histograms for patches in the source domain. This is achieved by sampling patches, extracting spatial label histograms, clustering them with K-means, and incorporating this clustered space during training. The goal is to learn a discriminative representation for patch-level alignment in transferable structured output representations. The method involves constructing a semantically disentangled space of patch representations through clustering label histograms in the source domain. The learning process includes aligning target patches to the clustered space using adversarial loss, reshaping data for alignment regardless of spatial location, and utilizing a discriminator for feature classification. The method involves reshaping data by concatenating K-dimensional vectors to create independent data points, achieving a similar effect as using a convolution layer. An adversarial objective is formulated with a discriminator Dl classifying feature representations from the source or target domain. The optimization process alternates between updating discriminators Dg and Dl, and updating networks G and H while fixing the discriminators. The discriminators are trained to distinguish between source and target distributions, with binary cross-entropy loss minimized. The method involves training discriminators Dg and Dl to distinguish between source and target distributions, minimizing binary cross-entropy loss. The goal is to align the target distribution with the source distribution while maintaining good performance on main tasks using networks G and H. Updating H also enhances G through back-propagation, with G only required during testing for unaffected runtime compared to the baseline approach. The method involves training discriminators Dg and Dl to align target distribution with source distribution using cross-entropy loss. Discriminator Dg uses a spatial map O with fully-convolutional layers, while Dl utilizes fully-connected layers. The generator consists of network G with a categorization module H, enhancing feature representations in G through back-propagation. Only G is required during testing for unaffected runtime compared to the baseline approach. The generator in the proposed architecture consists of network G with a categorization module H, which enhances feature representations. The implementation details include the use of PyTorch toolbox on a single Titan X GPU for training discriminators and the generator. The GPU has 12 GB memory. Adam optimizer BID16 is used for training discriminators with initial learning rate of 10 \u22124. Stochastic Gradient Descent (SGD) solver is used for training the generator with momentum of 0.9, weight decay of 5 \u00d7 10 \u22124, and initial learning rate of 2.5 \u00d7 10 \u22124. Ablation study on GTA5-to-Cityscapes using ResNet-101 network is conducted with corresponding loss functions. Learning rates are decreased using polynomial decay with a power of 0.9. Hyper-parameters such as image and patch sizes are provided in the appendix. The proposed framework for domain adaptation on semantic segmentation is evaluated through an ablation study on GTA5-to-Cityscapes scenario. The proposed framework for domain adaptation on semantic segmentation is evaluated through an extensive ablation study on GTA5-toCityscapes scenario. The method performs well against state-of-the-art approaches on various benchmark datasets and settings, including synthetic-to-real and cross-city scenarios. The adaptation experiments involve datasets like GTA5, Cityscapes, SYNTHIA, and Oxford RobotCar under different weather conditions. The study evaluates domain adaptation for semantic segmentation on GTA5-to-Cityscapes scenario. It includes adapting Cityscapes with sunny images to the rainy scenes in the Oxford RobotCar dataset. A total of 895 training images and 271 annotated test images are used, with IoU ratio as the evaluation metric. An ablation study on different loss functions and design choices is conducted, showing the impact of disentanglement, global alignment, and patch-level alignment. The ablation study on GTA5-to-Cityscapes scenario evaluates the impact of different loss functions and design choices in the proposed framework. Adding disentanglement without alignments improves performance, and combining global and patch-level alignments achieves the highest IoU. Both losses, Ld and Lladv, are necessary for effective patch-level alignment. The study evaluates the impact of different loss functions and design choices in the proposed framework for GTA5-to-Cityscapes scenario. Both losses, Ld and Lladv, are necessary for effective patch-level alignment, with a performance drop if either is removed. Reshaping the features in the clustered space is crucial for alignment, as shown by a 2.4% drop in IoU without it. Visualization of feature representations demonstrates successful adaptation in the clustered space. In the clustered space, t-SNE visualization shows successful adaptation of patch-level features with overlapping representations. Experimental results compare the proposed method favorably against state-of-the-art algorithms in various scenarios, including synthetic-to-real and cross-city cases. The method improves IoU by 1.8% and achieves the best IoU on 14 out of 19 cases when utilizing the ResNet-101 base network. The proposed method improves IoU by 1.8% and achieves the best IoU on 14 out of 19 categories by utilizing ResNet-101 base network. Results for adapting SYNTHIA to Cityscapes show similar improvements compared to state-of-the-art methods. Visual comparisons are shown in Figure 5, with more results in the appendix. Adapting between real images across different cities and conditions is demonstrated by adapting Cityscapes to Oxford RobotCar. The proposed method presents a domain adaptation approach for structured output, combining global and patch-level alignments to improve semantic segmentation. Results show higher segmentation detail and less noise compared to existing methods, with a mean IoU of 63.6%. Extensive experiments validate the effectiveness of the approach under various challenges, including synthetic-to-real and cross-city adaptation. The proposed method utilizes a clustered space of source patches and adversarial learning to align target patch distributions with source ones for semantic segmentation. Extensive experiments validate its effectiveness under various challenges, showing favorable performance compared to existing algorithms. Training involves randomly sampling one image from each domain in each iteration and optimizing according to a specified strategy. TAB3 displays image and patch sizes during training and testing, maintaining the image aspect ratio without cropping. BID12 is used as a loss to push target feature representation to source clusters, replacing adversarial loss with entropy loss for regularization. The proposed method uses clustered space and adversarial learning to align target patch distributions with source ones for semantic segmentation. By adding entropy regularization, the model achieves an IoU of 41.9%, lower than patch-level adversarial alignment at 43.2%. The model learns discriminative representations by pushing target patches closer to the source distribution in the clustered space guided by label histogram. Example patches from source and target domains show high similarity in t-SNE visualization, demonstrating the effectiveness of patch-level alignment. The proposed method utilizes clustered space and adversarial learning to align target patch distributions with source ones for semantic segmentation. Example patches from the source and target domains demonstrate high similarity in the t-SNE visualization, showcasing the effectiveness of patch-level alignment. Results for adapting Cityscapes to Oxford RobotCar are presented, showing that the proposed method often yields better segmentation outputs with more details and less noisy regions. Additional visual comparisons for different scenarios are provided in figures 9 to 11. The proposed method demonstrates better segmentation outputs with more details and less noise in adapted segmentations for different scenarios, as shown in figures 9 to 11."
}