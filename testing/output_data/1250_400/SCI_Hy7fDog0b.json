{
    "title": "Hy7fDog0b",
    "content": "Generative models, like AmbientGAN, aim to model complex distributions using partial, noisy observations instead of fully-observed samples. This approach allows for the recovery of the true underlying distribution even with information loss. AmbientGAN shows significant improvements in training Generative Adversarial Networks (GANs), achieving higher inception scores on benchmark datasets. The method involves passing the generator's output through a simulated random measurement function for the discriminator to distinguish between real and generated measurements. Generative models trained with a new method show substantial improvements in qualitative and quantitative performance, achieving 2-4 times higher inception scores than baseline models. The approach involves training a generative model directly from noisy or incomplete samples, allowing for the recovery of the underlying distribution. Various measurement processes are presented to learn a generative model from measured samples, both theoretically and practically. The key assumption is that the measurement process is known and meets specific technical conditions. Our approach, AmbientGAN, trains GANs by distinguishing real measurements from simulated ones of generated images. It can construct good generative models from noisy observations and low-dimensional projections. The method shows qualitative and quantitative improvements in image generation compared to baseline methods. The curr_chunk discusses low-dimensional projections with significant information loss, showcasing qualitative and quantitative comparisons to baseline methods. Theoretical results demonstrate the uniqueness of measured images determining original image distribution, leading to the necessity of a generative model matching the true distribution in a GAN game. Empirical work explores various measurement models without guarantees, presenting results on different models. The empirical work explores measurement models without guarantees, presenting results on different models. In the celebA dataset, random occlusions and noisy, blurred images are used to train a GAN model for better sample quality. In FIG2, learning a generative model on 2D images from the MNIST dataset involves projecting images onto random lines. Two variants are considered, with AmbientGAN recovering underlying structure well. Different approaches to neural network-based generative models include autoregressive and adversarial methods, with some successful combination approaches. The adversarial framework is powerful for modeling complex data distributions like images, video, and 3D models. Generative models have various applications, including solving inverse problems and translating images between domains using GANs. Training stability is explored by operating generators and discriminators on different spaces. Our work involves translating images between domains using GANs. BID22 explores training stability with low dimensional projections of samples, while BID10 creates 3D object shapes from 2D projections. We use 'r' for real distribution, 'g' for generated distributions, 'x' for underlying space, and 'y' for measurements. Measurements are outputs of a stochastic measurement function f \u03b8 : R n \u2192 R m. Our task involves creating an implicit generative model of a real distribution using lossy measurements from a known distribution. By combining the measurement process with adversarial training, we aim to sample from the real distribution. The goal is to create an implicit generative model of a real distribution using lossy measurements. This involves combining the measurement process with adversarial training to sample from the real distribution. The approach involves simulating random measurements on generated objects and using a discriminator to distinguish real from fake measurements. The approach involves simulating random measurements on generated objects and using a discriminator to distinguish real from fake measurements. The AmbientGAN objective is defined based on the discriminator output, with the model being end-to-end differentiable and trainable using a gradient-based GAN training procedure. The model is end-to-end differentiable and can be trained using a gradient-based GAN training procedure. Stochastic gradients are computed for the generator and discriminator in each iteration. The approach is compatible with various GAN improvements and can incorporate additional information such as per sample labels. Different measurement models are used for theoretical and empirical results, focusing on 2D images. In our experiments, we use different versions of GANs for image generation. The measurement models used are tailored for 2D images, including Block-Pixels, Convolve+Noise, Block-Patch, Keep-Patch, and Extract-Patch. These models can be applied to other data formats as well. The measurement models used for image generation in our experiments include Block-Pixels, Convolve+Noise, Block-Patch, Keep-Patch, Extract-Patch, Pad-Rotate-Project, PadRotate-Project-\u03b8, and Gaussian-Projection. These models aim to recover the true underlying distribution of the data. The chosen angle is included in the measurements for Gaussian-Projection. The goal is to recover the true underlying distribution of the data by showing a unique distribution consistent with the observed measurement distribution. This uniqueness allows for a consistency guarantee with the AmbientGAN training procedure. The lemma states that for a given data distribution and measurement function parameters, there is a unique probability distribution that induces the given measurement distribution. All proofs are deferred to Appendix A. The lemma assumes uniqueness of the true underlying distribution given the measurement distribution, which is satisfied under various measurement models like Gaussian-Projection and Convolve+Noise. This allows for recovery of the true distribution with the AmbientGAN framework, especially in scenarios with finite discrete pixel values. Theorem 5.4 discusses learning distributions in the AmbientGAN framework with a finite set of pixel values. It states that under certain conditions, a unique distribution can induce a measurement distribution, and provides a sample complexity result for learning. The experiment used three datasets including MNIST and CelebA. The experiment used three datasets: MNIST for handwritten digits, CelebA for face images of celebrities, and CIFAR-10 for images from 10 different classes. Different generative models were used for each dataset, with details on architectures and hyperparameters provided in the appendix. The experiment utilized various generative models tailored to different datasets, such as DCGAN for celebA and ACWGANGP for CIFAR-10. Different discriminator architectures were employed based on the output dimensions, with fully connected discriminators for 1D projections. Baseline approaches were implemented to assess the AmbientGAN framework's performance, aiming to create an implicit generative model for the dataset. The baseline approaches implemented to evaluate the AmbientGAN framework involve creating a generative model for the dataset by considering different scenarios, such as ignoring measurements or attempting to invert measurement functions, despite violations of assumptions in the AmbientGAN setting. In the AmbientGAN setting, we aim to approximate inverse functions for measurement models that violate key assumptions. For Block-Pixels measurements, we use blurring or total variation inpainting as approximate inverse functions. For Convolve+Noise measurements, we employ Wiener deconvolution as an approximation. In the AmbientGAN setting, approximate inverse functions are used for measurement models that violate key assumptions. Blurring or total variation inpainting is used for Block-Pixels measurements, while Wiener deconvolution is employed for Convolve+Noise measurements. Other measurement models present challenges in obtaining an approximate inverse function. In the AmbientGAN setting, approximate inverse functions are used for measurement models that violate key assumptions. Inverting Pad-Rotate-Project measurements is challenging due to lack of information about \u03b8. Results with AmbientGAN models are reported on a subset of experiments, showing samples generated by baselines and our models. Samples are heavily degraded in the measurement process, making it difficult for baselines to produce good samples. Our models can generate images with good visual quality. Block-Pixels: Results on celebA with DCGAN and CIFAR-10 with ACW-GANGP show degraded samples in the measurement process. Baselines struggle to invert the process, while our models produce high-quality images. Convolve+Noise: Gaussian kernel and IID Gaussian noise are used, with results on celebA showing drowned measurements in noise. Block-Patch and Keep-Patch: Results on celebA with DCGAN show coherent faces with our models observing parts of one image at a time. 1D projections: Pad-Rotate-Project and Pad-Rotate-Project-\u03b8 models exhibit signal degradation, with experiments using two measurements at a time on MNIST with DCGAN. The Pad-Rotate-Project and Pad-Rotate-Project-\u03b8 measurement models show signal degradation, with the second model producing upright digits. While the generated images are of lesser quality, the method demonstrates the ability to produce digit images from 1D projections. However, the model trained on celebA dataset struggles to capture details, emphasizing the challenge of learning complex distributions with only 1D projections. The model trained on celebA dataset with Pad-Rotate-Project-\u03b8 measurements shows a crude outline of a face but lacks details, highlighting the difficulty of learning complex distributions with 1D projections. Inception scores are used to quantify the quality of generative models learned in the AmbientGAN framework, with different models trained on CIFAR-10 and MNIST datasets. The inception scores for MNIST models with Block-Pixels measurements are plotted against the probability of blocking pixels. The final test set accuracy of the model trained with Block-Pixels measurements on MNIST was 99.2%. Different models were trained with varying probabilities of blocking pixels, and the inception scores were computed after convergence. The performance of AmbientGAN models remained relatively high compared to baseline models as the probability of blocking pixels increased. Additionally, models trained on MNIST with Convolve+Noise measurements showed that AmbientGAN models maintained a high inception score even with increased levels of noise. In Fig. 7 (right), the plot shows the Inception score vs. \u03c3. Wiener deconvolution and \"ignore\" baseline perform well with low noise levels but deteriorate as noise increases. AmbientGAN models maintain high scores. For 1D projection measurements, Pad-Rotate-Project model scores poorly at 4.18, while Pad-Rotate-Project-\u03b8 scores 8.12. Vanilla GAN model scores 8.99. In Fig. 8 (left), Inception score vs. probability of blocking pixels p is shown for CIFAR-10. Total variation inpainting method is slow. The second model achieves an inception score of 8.99, coming close to the fully-observed case while trained on 1D projections. In Fig. 8 (left), a plot of inception score vs the probability of blocking pixels p on CIFAR-10 is shown. The total variation inpainting method is slow, and performance on MNIST was similar to the unmeasured-blur baseline. In Fig. 8 (right), the inception score is shown as a function of training iteration. Generative models require high-quality datasets, but this study demonstrates learning from incomplete, noisy measurements to construct new generative models. The text discusses learning a distribution from incomplete, noisy measurements to construct new generative models when high-quality datasets are not available. It introduces a lemma and discusses the unique probability distribution that induces a given measurement distribution. The text also mentions the importance of matching 1D marginals in the underlying distribution for projections. The text discusses the unique probability distribution that can match all 1D marginals obtained with Gaussian projection measurements. It also introduces a theorem stating that there is a unique distribution that can induce a given measurement distribution in Convolve+Noise models. The text discusses the unique probability distribution that can match all 1D marginals obtained with Gaussian projection measurements. It introduces a theorem stating that there is a unique distribution that can induce a given measurement distribution in Convolve+Noise models, showing a bijective map between X and Z with continuous transformations. The text discusses the reverse map from the measurement distribution to the sample distribution in Convolve+Noise models, proving the uniqueness of the true underlying distribution. It introduces a theorem for the discrete setting and defines the empirical version of the vanilla GAN objective. The optimal discriminator and generator conditions are also discussed in the context of Empirical Risk Minimization (ERM). The optimal discriminator for the empirical objective is determined by the empirical distribution of samples. If the discriminator is fixed to be optimal, then any optimal generator must match the real data distribution. The proof involves replacing the real data distribution with the empirical version. Additionally, in the Block-Pixels measurement model, if the probability of blocking a pixel is less than 1, there exists a unique distribution. In the Block-Pixels model, if the probability of blocking a pixel is less than 1, there exists a unique distribution p. By applying random measurement functions to samples from p x, measurements can be obtained. The distribution over measurements p y can be written in terms of p x and a transition matrix A. If A is invertible, p x can be recovered from p y. The sample complexity is determined by the minimum eigenvalue of A, with the dataset of measurements needing to satisfy a certain condition for recovery. In the Block-Pixels model, images are divided into classes based on the number of zero pixels. The transition matrix A is lower triangular due to pixel blocking probabilities. Each image has a (1 - p) n chance of being unaffected by measurements. The DCGAN model on MNIST follows a specific architecture with a noise input to the generator having 100 dimensions. The generator and discriminator both have specific layers and operations in their structure. The DCGAN model on MNIST and WGANGP model on MNIST have specific architectures with different input dimensions and layer structures. The unconditional DCGAN model on celebA also has a unique architecture with specific layer configurations and the use of batch-norm in both generator and discriminator. The ACWGANGP model on CIFAR-10 follows a residual architecture with a latent vector of 128 dimensions sampled from a standard Gaussian distribution. The generator includes a linear layer and three residual blocks, each consisting of conditional batch normalization, nonlinearity, and upconvolution layers. The discriminator features one residual block and three additional residual blocks before a final linear layer. The discriminator in the ACWGANGP model on CIFAR-10 consists of one residual block with two convolutional layers followed by three residual blocks and a final linear layer. The current analysis explores the robustness of the AmbientGAN approach to systematic mismatches in the parameter distribution of the measurement function, specifically using the Block-Pixels measurement model on the MNIST dataset with varying blocking probabilities. In an experiment, the AmbientGAN approach is shown to be robust to parameter distribution mismatches in the Block-Pixels measurement model on the MNIST dataset. The generator learned through AmbientGAN captures the data distribution well, and it shows promise for compressed sensing applications. Using the AmbientGAN approach with Block-Pixels measurement model on MNIST dataset, the generator captures data distribution well. Comparing Lasso with AmbientGAN, a reduction in the number of measurements is observed when using AmbientGAN trained with corrupted samples."
}