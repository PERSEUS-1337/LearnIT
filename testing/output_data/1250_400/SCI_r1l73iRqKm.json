{
    "title": "r1l73iRqKm",
    "content": "In open-domain dialogue, intelligent agents struggle to incorporate knowledge into conversations. Existing models often rely on generic responses rather than recalled knowledge from sources like Wikipedia. To address this, a new dataset grounded in knowledge has been created to train models that can retrieve, read, and generate responses based on this knowledge. These models have shown promising results in conducting knowledgeable discussions on various topics, marking a significant step towards the goal of enabling humans to communicate effectively with machines. Dialogue models are advancing in conducting knowledgeable discussions on open-domain topics, aiming to enable effective communication between humans and machines. State-of-the-art approaches like sequence to sequence models are addressing language comprehension and reasoning skills but struggle with incorporating memory and knowledge into conversations. In this work, the focus is on improving dialogue models by incorporating direct knowledge memory mechanisms. The task at hand is open-domain dialogue where speakers engage in open-ended conversations, exchanging information and viewpoints. To achieve this, new architectures combining Memory Network and Transformer elements are designed to retrieve and condition on knowledge effectively. The study focuses on enhancing dialogue models by integrating direct knowledge memory mechanisms. They introduce Transformer Memory Networks, a combination of Memory Network and Transformer architectures, to improve text representations and sequence models for generating outputs. A dataset of human-human conversations was created using crowd-sourced workers, linking topics to Wikipedia for training and evaluating conversation agents. The study introduces Transformer Memory Networks to improve dialogue models by integrating direct knowledge memory mechanisms. They use a dataset of human-human conversations linked to Wikipedia for training and evaluating conversation agents. Their new benchmark in ParlAI aims to encourage further improvements in this research direction. The study explores the use of knowledge in dialogue tasks, focusing on unstructured knowledge from a wide range of topics like Wikipedia. Unlike existing dialogue tasks, which mainly rely on sequence-to-sequence models, this work emphasizes the importance of retrieving and conditioning knowledge for question answering. In question answering, retrieving and conditioning knowledge is crucial. Neural models have been developed for tasks like SQuAD and Open-SQuAD, which involve answering questions based on Wikipedia. The QuAC dataset focuses on dialogues in question-answer format. This work differs by focusing on natural human dialogues with a diverse set of utterances. Previous work has used Memory Networks for non-goal directed dialogue incorporating knowledge from sources like Reddit. The work of BID5 used Memory Networks for dialogue discussing movies and Reddit knowledge. BID14 and BID8 also incorporated knowledge from Wikipedia and Foursquare, respectively. Our work compares Memory Networks and Transformers for dialogue tasks. Our work compares Memory Networks BID19 and Transformers for dialogue tasks in an open-domain setting where two participants engage in chitchat, with one playing the role of a knowledgeable expert (wizard) and the other as a curious learner (apprentice). The apprentice talks freely to the wizard, eager to chat and delve into a chosen topic of interest. The task involves two participants engaging in dialogue, with one as a knowledgeable expert (wizard) and the other as a curious learner (apprentice). The wizard informs the apprentice about a chosen topic using information from Wikipedia, while the apprentice aims to delve deeply into the topic during the conversation. The focus is on using knowledge and making the conversation engaging and fun. The wizard in this dialogue task has access to relevant information from Wikipedia to craft engaging responses to the apprentice. The conversation flow involves choosing a topic, exchanging messages, and responding based on the observed knowledge. The chat continues until one participant ends it, with a minimum number of turns required. The wizard in this dialogue task uses relevant information from Wikipedia to respond to the apprentice. The conversation involves selecting a sentence to respond to, with the wizard basing their response on that sentence. The chat continues until one participant ends it, with a minimum number of turns required. The goal is to replace the human wizard with a learned agent in future conversations. The wizard in the dialogue task uses passages of knowledge from Wikipedia to respond to the apprentice. The retriever used for this task is fixed and retrieves relevant articles for the dialogue context. The wizard can click on retrieved article titles to expand them and select a relevant sentence to respond with. This system is used to build the dataset, but a model can potentially learn a better method for test time. The wizard in the dialogue task uses Wikipedia knowledge to respond to the apprentice. The system allows the wizard to select a relevant sentence from retrieved articles. Models can potentially learn a better method for test time. The system uses Wikipedia knowledge to ground the conversation. Models are developed to retrieve relevant information from a large memory and generate dialogue utterances. Two classes of models are created: retrieval models and generative models. The input to the models is the dialogue context, and the goal is to output the next utterance. Knowledge retrieval is based on a large hierarchically organized memory base. The system uses a large knowledge base for dialogue generation, utilizing information retrieval techniques to select relevant candidates for response generation. The system retrieves the top 7 articles for each lookup and flattens the results for better performance. The system operates on the topic and the last two turns, calling the IR system three times with different queries. It retrieves top 7 articles for each lookup, flattens the results, and uses an attention mechanism for fine-grained selection of knowledge sentences. The hidden state derived from memory attention is used for utterance prediction. The system uses a Transformer encoder to encode memory sentences and dialogue context for attention. It predicts the next dialogue turn based on the hidden state from memory attention. Different variants are considered for knowledge attention and utterance prediction in retrieval and generative models. The model encodes knowledge sentences and dialogue context with a Transformer, calculates input encoding with dot-product attention, and encodes candidate responses separately. The model is trained to minimize loss. The model uses a Transformer encoder to encode knowledge sentences and dialogue context, predicting the next dialogue turn based on memory attention. It considers different variants for knowledge attention and utterance prediction in retrieval and generative models. The model is trained to minimize loss by encoding candidate responses separately and using dot-product attention for input encoding. The model employs a beam search of 5 for response selection, utilizing BPE encoding BID16 to copy rare words from Wikipedia sentences. In the End-to-end version, a shared Transformer encoder encodes candidates and dialogue history, with attention prediction over memory. The model is trained to minimize negative log-likelihood of response utterance and can add supervision for knowledge selection. In the Two-stage version, two separately trained models are used for knowledge tasks. In the Two-stage version, two separately trained models are used for knowledge selection and utterance prediction. Additional supervision can be added for knowledge selection to improve performance. Knowledge dropout is employed to make the generator more resilient to errors and speed up training. Experimental setups and results are described, focusing on the ability of models to select knowledge appropriately in dialogue tasks. The novel technique proposed, Knowledge Dropout (K.D.), aims to improve training efficiency by reducing errors in knowledge selection. Experimental setups compare Transformers with various baselines, showing that pretraining on a large dataset like Reddit yields the best results. Further analysis using different models is provided in the appendix. The Bag-of-Words Memory Network BID19 is evaluated in the full dialogue task, using a Transformer pretrained on Reddit data. Results show that Transformers perform best when pretrained on a large dataset like Reddit. Knowledge improves all models, with Bow MemNet improving from 56 to 71 Recall@1. The addition of knowledge improves all models, with Bow MemNet improving from 56 to 71 Recall@1 and Transformer MemNet from 79 to 87 Recall@1. Generative experiments show that End-to-end and Two-stage models outperform Transformer without knowledge, demonstrating substantial improvements when provided with gold knowledge. The End-to-end and Two-stage models outperform the Transformer without knowledge, showing improvements with gold knowledge. The Two-stage model excels in using predicted knowledge, while the End-to-end model performs better with gold knowledge. Integrating knowledge selection supervision in the End-to-end model enhances performance on all metrics. Knowledge dropout also proves beneficial. The End-to-end and Two-stage models outperform the Transformer without knowledge, showing improvements with gold knowledge. Integrating knowledge selection supervision in the End-to-end model enhances performance on all metrics. Knowledge dropout (K. D.) also proves beneficial. Additionally, human evaluation of the models using crowd-sourced workers shows that Two-stage models give higher F1 scores than retrieval models. The Two-stage models outperform retrieval models in terms of F1 scores. Human evaluation is conducted using crowd-sourced workers, where conversations are rated for engagingness. A metric called Wiki F1 score is calculated to measure the model's knowledge. Results show that retrieval models significantly outperform. The study collected 546 conversations with ratings from 464 workers. Retrieval models outperformed generative models in human engagingness evaluation. Models with knowledge retrieval had higher Wiki F1 scores in seen and unseen test sets. Generative models improved engagingness ratings with knowledge use and conveyed more knowledge than retrieval models. The study found that ratings significantly improved with the use of knowledge. Models with knowledge retrieval had higher Wiki F1 scores on seen and unseen test sets, indicating they conveyed more knowledge than models without knowledge conditioning. Retrieval models were limited in producing responses for unseen topics, resulting in a gap compared to generative models. The dialogue agents developed in the study utilized large memory systems containing encyclopedic knowledge to engage in open-domain conversations. The study developed Transformer Memory Network models capable of engaging in open-domain conversations using large memory systems with encyclopedic knowledge. They collected the Wizard of Wikipedia dataset to train and evaluate these models, showing their effectiveness in both automatic and human experiments. Future work includes bridging the gap between retrieval and generative models, learning to retrieve and reason simultaneously, and exploring the relationship between knowledge-grounded dialogue and existing QA tasks. The study developed Transformer Memory Network models for open-domain conversations using encyclopedic knowledge. The Wizard of Wikipedia dataset was collected to train these models, focusing on bridging retrieval and generative models, learning to retrieve and reason simultaneously, and exploring knowledge-grounded dialogue in QA tasks. The dataset includes conversations where wizards have access to an information retrieval system over Wikipedia to ask and answer questions. The Wizard of Wikipedia dataset was collected to train Transformer Memory Network models for open-domain conversations using encyclopedic knowledge. The dataset includes conversations where wizards have access to an information retrieval system over Wikipedia to ask and answer questions. Apprentices ask questions in 13.9% of training set utterances, answer questions 39.5% of the time, and engage in new or follow-on statements 49.3% of the time. The dataset also includes \u223c1000 personas with 4-5 sentences describing interests, which are mapped to relevant Wikipedia pages. The dataset for training Transformer Memory Network models includes conversations where wizards have access to an information retrieval system over Wikipedia. Conversations involve asking and answering questions, with personas mapped to relevant Wikipedia pages. An analysis of dialogues shows that the retrieval system performance could be improved, and auxiliary loss helps generative models. The retrieval system performance could be improved with the help of auxiliary loss, as shown in the analysis of dialogues from human evaluation experiments. Human-human conversations differ from bot conversations, with humans engaging in more small talk and factual discussions, while bots attempt to play the role of a wizard. The retrieval system performance in human-bot conversations could be enhanced by incorporating SQuAD-like training data. The retriever without knowledge tends to go off-topic, while the retriever with knowledge sticks to the chosen topic but struggles when the subject changes. Additionally, a two-stage retrieval system outperformed other models in terms of F1 score on the full Wizard task. The two-stage retrieval system outperformed other models in terms of F1 score on the full Wizard task. The system could be improved by increasing performance on the knowledge selection subtask. Human experiments were conducted to calculate the Wiki F1 score for the wizard and apprentice for comparison to human evaluations. The generator without knowledge exhibits typical seq2seq system behaviors like repetition and inconsistencies in personality. The generator with knowledge has fewer issues and produces more accurate responses. The generator with knowledge exhibits fewer issues with repetition and produces more accurate responses compared to the generator without knowledge. It can act as a selfish conversationalist and sometimes produces formulaic responses, but is able to successfully generalize to unseen topics using knowledge from Wikipedia."
}