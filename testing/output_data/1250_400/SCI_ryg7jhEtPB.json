{
    "title": "ryg7jhEtPB",
    "content": "The importance weighted autoencoder (IWAE) is a variational-inference method that achieves a tighter evidence bound than standard variational autoencoders by optimizing a multi-sample objective. However, IWAE faces challenges with increasing Monte Carlo samples, leading to breakdowns in inference-network gradients. Alternative approaches like IWAE-STL and IWAE-DREG have been proposed to address these issues. The authors argue for directly optimizing the proposal distribution in importance sampling, as in the reweighted wake-sleep (RWS) algorithm, over IWAE-type multi-sample objectives. In this work, the authors introduce an adaptive importance sampling framework called AISLE, which generalizes the RWS algorithm. They argue for optimizing the proposal distribution in importance sampling over IWAE-type multi-sample objectives. The goal is to learn the generative model and construct a variational approximation of the model parameters. In this work, algorithms for variational inference are analyzed, focusing on learning the generative model and constructing a tractable variational approximation. The setting includes a single latent representation-observation pair and assumes no shared parameters between the generative model and the variational approximation. Stochastic gradient-ascent algorithms for optimizing parameters using Monte Carlo samples are discussed. The text discusses stochastic gradient-ascent algorithms for optimizing parameters using Monte Carlo samples in variational inference. Two main classes of algorithms, IWAE-DREG and RWS, are proposed to reduce errors and biases in the optimization process. The text discusses the RWS method for optimizing proposal distribution in variational inference, highlighting its advantages over the IWAE multi-sample objective approach. RWS avoids \u03c6-gradient breakdown and exhibits superior empirical performance compared to IWAE. In this work, it is shown that directly optimizing the proposal distribution, such as with RWS, is preferable to the IWAE multi-sample objective approach due to the \u03c6-gradient breakdown issue. The study introduces a generic adaptive importance-sampling framework called AISLE, which encompasses RWS, IWAE-DREG, and IWAE-STL gradients as special cases. Our work introduces the AISLE framework, a generic adaptive importance-sampling approach for variational inference. It encompasses RWS, IWAE-DREG, and IWAE-STL gradients as special cases, providing a theoretical foundation for IWAE-STL. The derived gradient estimators are guaranteed not to degenerate as K \u2192 \u221e, with connections established to recover the IWAE-STL gradient as a special case of AISLE. Our work provides a theoretical foundation for IWAE-STL and introduces the AISLE framework, which includes RWS, IWAE-DREG, and IWAE-STL gradients as special cases. The learning rate scaling for IWAE \u03c6-gradient is discussed, and AISLE leads to a new family of gradient estimators for \u03b1-divergences. Insights on the impact of self-normalization bias on importance-sampling based gradient approximations are also provided in the supplementary materials. The AISLE framework introduces a new family of gradient estimators for \u03b1-divergences, generalizing some previously derived in the literature. The focus is not on deriving new algorithms but on comparing existing ones empirically. The notation is simplified for concise representation. The importance weighted autoencoder (IWAE) aims to maximize a lower bound on the log-marginal likelihood by finding the generative-model parameters that optimize it. The estimator used in IWAE is not unbiased but its bias vanishes under certain assumptions. The notation used in the estimation process is simplified for readability. The IWAE, introduced by Burda et al. (2016), maximizes a lower bound on the log-marginal likelihood by optimizing generative-model parameters. The estimator used is not unbiased, but its bias vanishes under certain assumptions. The objective depends on inference-network parameters and the number of samples, K \u2265 1. For K > 1, IWAE extends VAE on an auxiliary-variable construction. The gradient of the IWAE objective can be approximated using a vanilla Monte Carlo approach. The IWAE, an extension of VAE, uses a Monte Carlo approach to approximate the gradient of its objective. To reduce high variance, the reparametrisation trick is employed, requiring a specific distribution and differentiable mappings. The IWAE then estimates the objective using a vanilla Monte Carlo approach. The IWAE utilizes a Monte Carlo estimate to approximate the gradient of its objective, with a focus on the \u03c6-portion. However, drawbacks of the IWAE \u03c6-gradient include reliance on reparametrisations and a vanishing signal-to-noise ratio. The IWAE \u03c6-gradient faces challenges such as vanishing signal-to-noise ratio and inability to achieve zero variance. Modifications have been proposed to address these issues, including IWAE-STL and IWAE-DREG gradients. The 'sticking-the-landing' IWAE (IWAE-STL) gradient ignores score function terms, introducing bias when K > 1. The 'doubly-reparametrised' IWAE (IWAE-DREG) gradient removes score-function terms through Lemma 1. The reweighted wake-sleep (RWS) algorithm optimizes both \u03b8 and \u03c6 simultaneously, sharing particles and weights, but lacks a joint objective. The bias of the RWS algorithm relative to (6) is of order O(1/K). Appendix A discusses this bias's impact on the \u03c6-gradient in more detail. Optimizing both \u03b8 and \u03c6 simultaneously allows sharing particles and weights. However, the lack of a joint objective for both \u03b8 and \u03c6 is seen as a drawback. Adapting the proposal distribution q \u03c6 in importance-sampling schemes does not always require minimizing the KL-divergence. Numerous techniques exist in the literature for this purpose. Adapting the proposal distribution q \u03c6 in importance-sampling schemes may not always require minimizing the KL-divergence. Alternative techniques, such as minimizing the \u03c7 2 -divergence, exist in the literature. The RWS-objective can be slightly generalized to optimize both \u03b8 and \u03c6, resulting in the algorithm adaptive importance sampling for learning (AISLE). This unified framework allows for a principled derivation of robust \u03c6-gradient. The algorithm adaptive importance sampling for learning (AISLE) provides a unified framework for deriving robust \u03c6-gradient estimators that do not degenerate as K \u2192 \u221e. Optimization is done via stochastic gradient ascent, with the \u03b8-gradient being the same for all algorithms discussed. The \u03b8-gradient is interpreted differently by IWAE and AISLE, with AISLE viewing it as a self-normalized importance-sampling approximation of the gradient \u2207 \u03b8 log Z \u03b8. Integrals involving \u03c0 \u03b8 ([F \u2022 w \u03c8 ]\u2207 \u03c6 log q \u03c6 ) can be approximated using the vanilla Monte Carlo method with a bias of order O(K \u22121 ) and a standard deviation of order O(K \u22121/2 ). The derivations involve integrals of the form \u03c0 \u03b8 ([F \u2022 w \u03c8 ]\u2207 \u03c6 log q \u03c6 ), which can be approximated using the vanilla Monte Carlo method. Most \u0192-divergences used in variational inference allow for optimization without knowing Z \u03b8. Self-importance sampling can be used to approximate the integral in Equation (11), leading to a reparametrised estimator. The text discusses the approximation of \u03c0 \u03b8 using self-importance sampling and the reparametrised estimator. It also mentions specific cases like AISLE-KL-NOREP/RWS and AISLE-KL, showing how IWAE-STL can be derived from AISLE without the need for a multi-sample objective. This provides a theoretical basis for IWAE-STL. Proposition 1 shows that IWAE-STL can be derived from AISLE without relying on a multi-sample objective, providing a theoretical basis for IWAE-STL. This approach avoids bias and variance issues highlighted in previous studies and has shown good empirical performance. The AISLE-KL method is derived by first applying Lemma 1 to the exact \u03c6-gradient and then approximating the expression, potentially reducing bias and variance. The \u03b1-divergence between two distributions p and q can be expressed in terms of \u03ba and f(y), with the case \u03b1 = 2 equivalent to a standard \u03c7 2 -divergence. AISLE-\u03b1-NOREP and AISLE-\u03b1 are special cases related to importance sampling and reparametrisation. The AISLE-KL method involves deriving the AISLE-\u03b1-NOREP and AISLE-\u03b1 special cases, which are related to importance sampling and reparametrisation. The method utilizes the \u03b1-divergence between distributions p and q, with \u03b1 = 2 corresponding to a standard \u03c7 2 -divergence. The variance of importance weights is crucial in sampling, and the IWAE-DREG can be derived from AISLE in a principled manner. The learning rate adjustment for IWAE or IWAE-DREG \u03c6-gradients is necessary in certain implementations. The 'exclusive' KL-divergence, denoted as KL(q \u03c6 \u03c0 \u03b8 ), can be approximated as a simple average over K independent replicates of the 'sticking-the-landing' estimator for VAEs. Optimizing this divergence may lead to faster convergence of \u03c6 compared to optimizing the 'inclusive' KL-divergence KL(\u03c0 \u03b8 q \u03c6 ). However, minimizing the exclusive divergence may negatively impact learning of \u03b8 due to potential issues with importance weights. The adaptive-importance sampling paradigm of reweighted wake-sleep (RWS) is preferred over the multi-sample objective paradigm of importance weighted autoencoders (IWAEs). The adaptive-importance sampling paradigm of the reweighted wake-sleep (RWS) is preferred over the multi-sample objective paradigm of importance weighted autoencoders (IWAEs) due to achieving the same goals while avoiding drawbacks. The self-normalised importance-sampling approximation adjusts the number of particles to provide accurate approximations, with insights on estimators as the number of particles increases. The estimators \u2207 aisle-kl \u03c6 \u03b8, z and \u2207 aisle-\u03c7 2 \u03c6 \u03b8, z become more accurate as K \u2191 \u221e. For K = 1, they reduce to vanilla Monte Carlo approximations. The small-K self-normalisation bias of AISLE \u03c6 gradients is challenging to characterize, but it may favor minimizing the exclusive KL-divergence. IWAEs use self-normalised importance-sampling with K > 1 particles to reduce bias in the \u03b8-gradient relative to \u2207 \u03b8 log Z \u03b8. IWAEs aim to minimize the exclusive KL-divergence by using self-normalised importance-sampling with K > 1 particles to reduce bias in the \u03b8-gradient. The error of importance-sampling can be controlled by ensuring q \u03c6 is close to \u03c0 \u03b8 in parts of the space Z with positive probability mass. The family of proposal distributions Q distinguishes between scenarios with sufficiently expressive Q. The family of proposal distributions Q distinguishes between scenarios with sufficiently expressive Q. If Q is flexible enough to contain a distribution close to \u03c0 \u03b8, minimizing the exclusive KL-divergence can yield well-behaved importance weights. However, if Q is not flexible enough and all members are far from \u03c0 \u03b8, minimizing the exclusive KL-divergence could lead to poorly-behaved importance weights. In such cases, optimizing \u03c6 to minimize KL(\u03c0 \u03b8 q \u03c6 ) is recommended. In Scenario 1, for a flexible Q, using a gradient-descent algorithm to minimize exclusive divergence may be preferable for faster convergence. A smaller number of particles, K, could be better for some \u03c6-gradients due to self-normalization bias. Increasing K is still desirable to reduce gradient approximation variance. The bias towards faster convergence may favor setting K = 1 for the approximation of the \u03c6-gradients. However, increasing K is still desirable to reduce gradient approximation variance. Using all K particles and weights for the \u03b8-gradient approximation is important. Different \u03c6-gradient estimators are compared, including AISLE-KL-NOREP. In the supplementary materials, various \u03c6-gradient estimators for AISLE are compared, including AISLE-KL-NOREP, AISLE-KL, AISLE-\u03c7 2 -NOREP, and AISLE-\u03c7 2. These estimators are based on different divergences and reparametrizations, with varying levels of variance reduction. The gradient estimators for AISLE include AISLE-\u03c7 2, which is proportional to IWAE-DREG and RWS-DREG, and does not require R1 but does not achieve zero variance. The gradient for IWAE-DREG is based on the reparametrisation trick from Kingma & Welling (2014) and is also proportional to AISLE-\u03c7 2. The text discusses gradient estimators for AISLE, including AISLE-\u03c7 2, IWAE-DREG, and RWS-DREG, which are all based on reparametrisation tricks. The joint law of observations and latent variables is factorised, with proposal distributions modelled as fully-factored Gaussians. The parameters to optimise are determined, and the mean of the proposal coincides with the mean of the posterior under certain conditions. The text discusses gradient estimators for AISLE, including AISLE-\u03c7 2, IWAE-DREG, and RWS-DREG, based on reparametrisation tricks. The proposal distributions are modelled as fully-factored Gaussians, with parameters to optimise and conditions where the mean of the proposal coincides with the mean of the posterior. The model allows for correlated latent variables under the generative model, while the variational approximation remains fully factored. The text discusses gradient estimators for AISLE, including AISLE-\u03c7 2, IWAE-DREG, and RWS-DREG, based on reparametrisation tricks. The proposal distributions are modelled as fully-factored Gaussians, with parameters to optimise. The latent vectors can be correlated under the generative model, but the variational approximation may not fully capture the uncertainty. The 'score-function free' \u03c6-gradients achieve near-zero variance for proposal mean parameters. Empirical comparisons of algorithms are conducted for varying numbers of particles. The text discusses the benefits of reparametrisation-trick gradients in Gaussian settings and compares algorithms empirically. Different model settings are explored, including scenarios with varying numbers of particles and model dimensions. The generative model specifications are detailed, showing how the fully-factored variational approximation may not fully capture the dependence structure. The generative model is specified in two scenarios, with different covariance matrices. The fully-factored variational approximation may not capture the dependence structure fully. Gradient-ascent algorithms are used with different parameter settings for optimization."
}