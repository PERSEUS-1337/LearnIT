{
    "title": "HJlfAo09KX",
    "content": "We study model recovery for data classification using a one-hidden-layer fully-connected neural network with sigmoid activations. Under Gaussian inputs, the empirical risk function exhibits strong convexity and smoothness, allowing gradient descent to converge linearly to a critical point close to the ground truth. This can be achieved via the tensor method without needing fresh samples at each iteration. Gradient descent converges linearly to a critical point close to the ground truth using the tensor method for empirical risk minimization in one-hidden-layer neural networks. This is the first global convergence guarantee for cross entropy via gradient descent, achieving near-optimal sample and computational complexity. Neural networks have gained research interest for their success in practical domains like computer vision and artificial intelligence. Recent research interest has focused on the success of deep neural networks in practical domains like computer vision and artificial intelligence. The theoretical underpinnings behind this success remain largely mysterious. Efforts have been made to understand the classes of functions that can be represented by deep neural networks, the effectiveness of gradient descent for optimizing non-convex loss functions, and why these networks generalize well. Model-recovery setups, where training samples are generated i.i.d., have attracted extensive attention. One important line of research focuses on model-recovery setups in deep neural networks to recover the underlying model parameter W for generalization. Previous studies have looked at two types of data generations, including a regression problem where samples are generated based on weight vectors and Gaussian inputs. In regression problems, samples are generated using weight vectors and Gaussian inputs. Different studies have examined single-neuron models, one-hidden-layer multi-neuron networks, and two-layer feedforward networks with ReLU activations. For classification, labels are drawn under a conditional distribution where each label is determined by the sum of neuron activations. The conditional distribution P(y = 1|x) = 1 K K k=1 \u03c6(w k x) is studied in the case with a single neuron. Previous studies used gradient descent over squared loss for neural network parameter recovery in regression and classification settings. Statistical guarantees for model recovery using squared loss were provided, showing positive definiteness of the Hessian in the local neighborhood of the ground truth. The Hessian of the empirical loss function is positive definite in the local neighborhood of the ground truth, requiring fresh samples at each iteration for gradient descent to converge. Studies have shown that certain types of uniform geometry, like strong convexity, eliminate the need for resampling per iteration, ensuring guaranteed linear convergence for gradient descent. In this paper, the aim is to develop a strong statistical guarantee for the loss function in eq. (2) for classification problems, specifically focusing on the recovery of one-hidden-layer neural networks using the cross entropy loss function. This study provides the first performance guarantee for this scenario, without the need for per-iteration resampling, ensuring guaranteed linear convergence for gradient descent. The study provides a performance guarantee for the recovery of one-hidden-layer neural networks using the cross entropy loss function. For a multi-neuron classification problem with sigmoid activations and Gaussian input, the empirical risk function is uniformly strongly convex in a local neighborhood of the ground truth. Gradient descent converges linearly to a critical point when initialized in this neighborhood. The study shows that gradient descent converges linearly to a critical point Wn with a sample complexity of O(dK5 log2d) for one-hidden-layer neural networks. The recovery of W is up to statistical accuracy, and Wn converges to W at a rate of O(dK9/2 logn/n) in the Frobenius norm. The convergence guarantee does not require a fresh set of samples at each iteration due to uniform strong convexity in the local neighborhood. The study demonstrates that gradient descent converges linearly to a critical point Wn with a sample complexity of O(dK5 log2d) for one-hidden-layer neural networks. It does not require fresh samples at each iteration due to uniform strong convexity in the local neighborhood. The tensor method proposed in BID38 provides an initialization near the ground truth, with a proof that replaces the homogeneous assumption on activation functions with a condition on the curvature, applicable to a wider range of activation functions. The proof develops new techniques to analyze the cross-entropy loss function, utilizing statistical information of geometric curvatures. It also provides performance guarantees for classification using the squared loss. The focus is on theoretical and algorithmic aspects of learning shallow neural networks via nonconvex optimization. The focus is on theoretical and algorithmic aspects of learning shallow neural networks via nonconvex optimization, with relevance to signal processing problems such as matrix completion, phase retrieval, blind deconvolution, dictionary learning, and tensor decomposition. The statistical model for data generation removes worst-case instances, allowing for a focus on average-case performance and enabling global convergence of simple local search algorithms. The studies focus on the landscape analysis and model recovery of one-hidden-layer network models. It is known that in the optimization landscape, there are no spurious local minima if the network size is large enough compared to the data input. In the under-parameterized setting with multiple neurons, the landscape of the population squared loss surface with ReLU activations has been studied. In the under-parameterized setting, Tian BID33 studied the population squared loss surface landscape with ReLU activations, revealing spurious bad local minima. Zhong et. al. BID38 characterized the local Hessian for regression with various activation functions. For a single neuron (K = 1) and Gaussian input, BID28 demonstrated linear convergence of gradient descent with ReLU activation and zero initialization. BID28 showed linear convergence of gradient descent with ReLU activation and zero initialization for a single neuron under Gaussian input, with sample complexity O(d) for regression. BID21 demonstrated linear convergence with bounded derivatives of the activation function and O(d log 2 d) sample complexity for classification with sub-Gaussian inputs. BID38 discussed the ground truth in technical terms. Our study analyzes the cross entropy loss function for the classification problem with sub-Gaussian inputs, showing a sample complexity of O(d log 2 d). We focus on model recovery in the multi-neuron case, a novel approach not previously studied. This differs from existing work on one-hidden-layer or two-layer neural networks under Gaussian input. The paper discusses various neural network structures and loss functions, highlighting differences from previous studies. It is organized into sections covering problem formulation, local geometry, gradient descent convergence, initialization methods, numerical examples, and conclusions. Section 4 discusses the initialization method, numerical examples are demonstrated in Section 5, and conclusions are drawn in Section 6. Boldface letters denote vectors and matrices, with various notations for norms and matrices used throughout the paper. The text describes the generative model for training data and the gradient descent algorithm for learning network weights. Training samples are drawn i.i.d. from a normal distribution, with an activation function assumed. Various constants and norms are used throughout the paper. The text discusses the descent algorithm for learning network weights using training samples drawn i.i.d. from a normal distribution. It focuses on estimating W through minimizing the empirical risk function, which is the cross entropy loss. The text discusses the gradient descent algorithm for estimating W by minimizing the cross entropy loss function. The algorithm includes a well-designed initialization scheme to avoid local minima and uses a specific update rule with a step size parameter. The update rule for gradient descent is given as DISPLAYFORM0 with step size \u03b7. The algorithm uses the same set of training samples throughout, unlike BID38 which resamples at every iteration. An important quantity regarding \u03c6(z) is introduced to capture geometric properties of the loss function. The update rule for gradient descent with a step size \u03b7 is used consistently with the same training samples. A key quantity, \u03c6(z), captures geometric properties of the loss function, as shown in Figure 1 for sigmoid activation. The local strong convexity of f n (W) near the ground truth W is characterized. The local strong convexity of the empirical risk function f n (W) near the ground truth W is characterized by the condition number \u03ba and \u03bb. The Hessian of f n (W) in a neighborhood of W is guaranteed to be positive definite with high probability for the classification model with sigmoid activation function. The classification model with sigmoid activation function ensures the Hessian of the empirical cross-entropy loss function is positive definite near the ground truth W, as long as W is full-column rank and the sample size is sufficiently large. All column permutations of W are equivalent global minima of the loss function. The Hessian of the empirical cross-entropy loss function is positive definite near the ground truth W for the classification model with sigmoid activation, as long as W is full-column rank and sample size is sufficiently large. The bounds in Theorem 1 depend on network dimension parameters, activation function, and ground truth. For orthonormal columns in W with specific parameters, Theorem 1 guarantees a certain result with optimal sample complexity. The sample complexity is near-optimal in d up to polynomial factors of K and log d. For the classification problem with quantized labels, the empirical risk function is strongly convex in the local neighborhood of W. There exists a critical point Wn close to the ground truth W, and gradient descent converges linearly to Wn for the classification model with sigmoid activation function. The sample complexity is near-optimal in d up to polynomial factors of K and log d. For the classification model with sigmoid activation function, there exists a critical point Wn close to the ground truth W, and gradient descent converges linearly to Wn. Theorem 2 guarantees the existence of a unique critical point Wn in a local neighborhood of W with high probability. Theorem 2 guarantees the existence of a critical point Wn in a local neighborhood of W, converging at a rate of O(K 9/4 d log n/n). Gradient descent converges linearly to Wn with proper initialization, requiring a computational complexity of O(ndK 2 log(1/\u03b5)). Initialization method follows the tensor method proposed in BID38. The initialization method for gradient descent follows the tensor method proposed in BID38, with a computational complexity of O(ndK 2 log(1/\u03b5)). It guarantees the existence of a critical point Wn converging at a rate of O(K 9/4 d log n/n). The initialization algorithm based on the tensor method, as proposed in BID38, involves estimating the direction of each column of W and reducing a third-order tensor to a lower-dimension tensor for non-orthogonal decomposition. The initialization algorithm involves estimating the direction of each column of W and reducing a third-order tensor to a lower-dimension tensor for non-orthogonal decomposition. The algorithm applies non-orthogonal tensor decomposition to output the estimate s i V w i, where s i is a random sign, and approximates the magnitude of w i and the sign s i by solving a linear system of equations. Technical assumptions are made for the classification problem, including conditions on the activation function and the non-zero values of M 3 and M 4. The homogeneous assumption is not required. The initialization algorithm estimates the direction of each column of W and reduces a third-order tensor for non-orthogonal decomposition. Assumption 2 states that the activation function must have a certain curvature around the ground truth, allowing for a larger class of activation functions. The algorithm does not require the homogeneous assumption and guarantees performance based on the curvature of the activation function. The initialization algorithm estimates the direction of each column of W and reduces a third-order tensor for non-orthogonal decomposition. The algorithm guarantees performance based on the curvature of the activation function. The performance guarantee for the initialization algorithm is presented in Theorem 3, showing accurate estimation of the direction of W and the norm of W. In this section, the proof of the accuracy of the norm of W is discussed, with a different argument for relaxing the homogeneous assumption on activation functions. Gradient descent is implemented to verify the strong convexity of the empirical risk function around W, ensuring convergence to the same critical point Wn with multiple initializations in the local region. Multiple random initializations are performed to calculate the critical point with the same training samples. The successful rate of gradient descent is determined by calculating the variance of the output of multiple random initializations with the same training samples. The experiment is considered successful if the standard deviation is less than 10^-2. Averaging over 50 sets of training samples shows the successful rate for different pairs of n and d values. The successful rate of gradient descent is determined by averaging over 50 sets of training samples for different pairs of n and d values. If initialized close enough to the ground truth, gradient descent converges to the same local minima with high probability. The average estimation error decreases as sample size increases in Monte Carlo simulations with random initializations. Gradient descent with cross entropy loss achieves lower error than squared loss when K = 3 and d = 20. The study compares cross entropy loss and squared loss in a classification problem, showing that cross entropy loss achieves lower error. The research focuses on model recovery of a neural network using cross entropy loss in a multi-neuron classification problem, characterizing sample complexity for local strong convexity near the ground truth. The study focuses on model recovery of a neural network using cross entropy loss in a classification problem. It aims to extend the analysis to different activation functions and network structures in the future. The population loss function is denoted as DISPLAYFORM0, and the proof of Theorem 1 involves showing convergence of gradient descent to the ground truth. The proof of Theorem 1 involves demonstrating the smoothness and convexity properties of the Hessian of the population loss function. This is done by showing that the Hessian is smooth with respect to itself, satisfies local strong convexity and smoothness in a neighborhood of W, and that the Hessian of the empirical loss function is close to the population loss function uniformly in a certain region. The Hessian of the population loss function is smooth and satisfies local strong convexity and smoothness in a neighborhood of W. For sigmoid activations, when W \u2212 W F \u2264 0.7, the Hessian is bounded in a neighborhood around the ground truth. The Hessian of the population loss function exhibits local strong convexity and smoothness in a neighborhood of W for sigmoid activations. There exists a constant C such that the Hessian of the empirical loss function is close to the Hessian of the population loss function in a uniform sense under certain conditions. Lemma 3 states that for sigmoid activations, there exists a constant C such that under certain conditions, a specific inequality holds with high probability. The proof can be found in Appendix D.4. Combining Lemma 3 and Lemma 1 leads to the establishment of Theorem 1, which shows the strong convexity of a function in a certain region. This implies the existence of at most one critical point in that region. The proof of Theorem 2 follows similar steps. The proof of Theorem 2 involves showing the gradient concentrates around a specific point in a given region, guaranteeing the existence of a critical point. Additionally, it demonstrates the convergence of gradient descent to this critical point with a properly chosen step size. The proof involves showing gradient concentration around a specific point, guaranteeing a critical point's existence. Lemma 4 states conditions for sigmoid activation function, ensuring a unique critical point in a given region. Corollary 1 confirms the existence of a critical point satisfying certain conditions. The proof establishes the existence of a critical point in a specific region, ensuring gradient concentration. Local linear convergence of gradient descent is then demonstrated through an update rule for the estimate at each iteration. The proof demonstrates the convergence of gradient descent to the local minimizer Wn by showing the accuracy of estimating the direction of W and setting the learning rate \u03b7 < a certain value. The direction of W is accurately estimated without requiring a homogeneous condition for the activation function. The proof is based on a mild condition in Assumption 2 and involves defining a tensor operation. BID38 shows that for the regression problem, if the sample size meets a certain condition, a specific result holds with high probability. The direction of each w i for i = 1, . . . , K is estimated accurately for regression and classification problems by applying Bernstein inequality to terms associated with neurons individually or all together. For regression and classification problems, the bounds for estimating w i are determined differently. In regression, the output y i needs to be upper bounded, while in classification, the label y i is naturally bounded. The proof for this can be found in BID38. Additionally, a different proof for estimating w i is provided in this study, which does not require homogeneous conditions on the activation function. The study provides a proof for estimating w i that does not require homogeneous conditions on the activation function. It defines a quantity Q 1 and solves an optimization problem to estimate w i. The study proposes a method to estimate w i without requiring homogeneous conditions on the activation function. It involves substituting Q 1 and V u i into formulas to estimate \u03b2 and a i. The sign of \u03b2 i can correctly estimate s i. The study introduces a method to estimate w i without needing homogeneous conditions on the activation function. By utilizing Q 1 and V u i in formulas to estimate \u03b2 and a i, the sign of \u03b2 i can accurately estimate s i. Additionally, the study establishes the existence of a constant \u03b4 > 0 for the inverse function g(\u00b7) of m 3,1 (\u00b7) with an upper-bounded derivative in a specific interval. If the sample size meets certain criteria, Q 1 and Q 1 , V u i and s i w i can be closely approximated, leading to the desired result. The study introduces a method to estimate w i without needing homogeneous conditions on the activation function. By utilizing Q 1 and V u i in formulas to estimate \u03b2 and a i, the sign of \u03b2 i can accurately estimate s i. The study establishes the existence of a constant \u03b4 > 0 for the inverse function g(\u00b7) of m 3,1 (\u00b7) with an upper-bounded derivative in a specific interval. If the sample size meets certain criteria, Q 1 and Q 1 , V u i and s i w i can be closely approximated, leading to the desired result. Definitions and results related to sub-gaussian and sub-exponential norms of random variables are introduced, along with calculations of the gradient and Hessian of E [ (W ;. The study introduces a method to estimate w i without needing homogeneous conditions on the activation function. By utilizing Q 1 and V u i in formulas to estimate \u03b2 and a i, the sign of \u03b2 i can accurately estimate s i. The study establishes the existence of a constant \u03b4 > 0 for the inverse function g(\u00b7) of m 3,1 (\u00b7) with an upper-bounded derivative in a specific interval. If the sample size meets certain criteria, Q 1 and Q 1 , V u i and s i w i can be closely approximated, leading to the desired result. Definitions and results related to sub-gaussian and sub-exponential norms of random variables are introduced, along with calculations of the gradient and Hessian of E [ (W ;. The gradient and Hessian calculations involve formulas for \u2206 j,l and hessian blocks, with detailed steps on how to calculate them. The study utilizes Cauchy-Schwarz inequality to upper bound E T 2 j,l,k, with Lemma 5 providing a bound for x \u223c N (0, I) and sigmoid activation function \u03c6 (x). The study introduces a method to estimate w i without homogeneous conditions on the activation function, establishing the existence of a constant \u03b4 > 0 for the inverse function g(\u00b7) of m 3,1 (\u00b7) with an upper-bounded derivative. The study introduces a method to estimate w i without homogeneous conditions on the activation function, establishing the existence of a constant \u03b4 > 0 for the inverse function g(\u00b7) of m 3,1 (\u00b7) with an upper-bounded derivative. For a large enough constant C, the study derives bounds for the Hessian of the population risk at ground truth, applying Lemma 1 to obtain a uniform bound in the neighborhood of W. The study establishes bounds for the Hessian of the population risk at ground truth by deriving a uniform bound in the neighborhood of W using Lemma 1. The upper bound for \u2207 2 f (W) is obtained, leading to the conclusion that when W - W_F \u2264 0.7, certain conditions hold. The study establishes bounds for the Hessian of the population risk at ground truth by deriving a uniform bound in the neighborhood of W using Lemma 1. Within the same neighborhood, by the triangle inequality, certain conditions hold for W - W_F \u2264 0.7. The -covering number of the Euclidean ball B (W , r) is analyzed in the proof of Lemma 3. The study establishes bounds for the Hessian of the population risk at ground truth by deriving a uniform bound in the neighborhood of W using Lemma 1. Within the same neighborhood, certain conditions hold for W - W_F \u2264 0.7. The -covering number of the Euclidean ball B (W , r) is analyzed in the proof of Lemma 3. For any W \u2208 B (W , r), let j (W ) = argmin j\u2208[N ] W \u2212 W j(W ) F \u2264 for all W \u2208 B (W , r).DISPLAYFORM11 and DISPLAYFORM12 are derived based on this. The events A t , B t and C t are defined as DISPLAYFORM13 DISPLAYFORM14 DISPLAYFORM15. The terms P (A t ), P (B t ), and P (C t ) are bounded separately. Upper bounding P (B t ) involves a technical lemma summarized in Lemma 7."
}