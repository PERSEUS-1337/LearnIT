{
    "title": "r1l73iRqKm",
    "content": "In open-domain dialogue, intelligent agents struggle to incorporate knowledge into conversations. Existing models often rely on generic responses rather than utilizing recalled knowledge as context. To address this, a new dataset grounded in knowledge from Wikipedia has been created to improve dialogue systems. Our research focuses on developing dialogue models that can incorporate knowledge from Wikipedia into conversations, leading to more informed and engaging discussions. By creating a dataset grounded in factual information, our models can generate natural responses based on retrieved knowledge. This advancement in dialogue systems aims to bring us closer to the ultimate goal of enabling humans to effectively communicate with machines. One of the key goals of AI and natural language research is for humans to communicate with machines. Machines need to comprehend language, employ memory, reason about concepts, and output responses that fulfill functional goals and engage human partners. Current state-of-the-art approaches, like sequence to sequence models, attempt to address these skills but struggle to bring memory and knowledge into conversations. Sequence models like BID20, BID23, BID17, and BID21 aim to address skills like memory and knowledge in conversations. However, they struggle to bring direct knowledge memory mechanisms into play. This work focuses on open-domain dialogue where speakers engage in chit-chat, emphasizing the need for more direct knowledge memory mechanisms. In this work, the focus is on open-domain dialogue where speakers engage in chit-chat, aiming to incorporate direct knowledge memory mechanisms. The design includes architectures combining Memory Network and Transformer elements to retrieve and condition on knowledge for the challenging task of open-ended conversations. We introduce Transformer Memory Networks, a novel architecture combining Memory Network and Transformer elements for open-domain dialogue. A supervised dataset of human-human conversations was created using crowd-sourced workers, with 1365 discussion topics and 201,999 utterances. Each topic is linked to Wikipedia for knowledge retrieval. The Transformer Memory Networks combine Memory Network and Transformer elements for open-domain dialogue. A dataset of human-human conversations with 1365 topics and 201,999 utterances linked to Wikipedia is used to train and evaluate models. The architectures are tested using automatic metrics and human evaluations, showing their ability to engage in knowledgeable conversations. Network architectures, in both retrieval and generative versions, are tested in this setup using automatic metrics and human evaluations to demonstrate their ability to engage in knowledgeable conversations with humans. A new benchmark in ParlAI aims to encourage and measure improvements in this research direction, focusing on the explicit use of knowledge in dialogue tasks. Popular chit-chat datasets have tested sequence-to-sequence models' abilities without explicitly incorporating knowledge. Our work investigates unstructured knowledge across a large, diverse set of topics potentially spanning all of Wikipedia, in contrast to existing dialogue models that do not attempt to recall long-term knowledge beyond encoding it directly into the network weights. Our work focuses on unstructured knowledge from a wide range of topics in Wikipedia, unlike dialogue models that do not incorporate long-term knowledge. This is crucial for question answering tasks, where factual answers are derived from retrieved and conditioned knowledge. Various neural models have been developed to answer questions by attending to Wikipedia paragraphs, such as in SQuAD and Open-SQuAD. The QuAC dataset explores similar themes in a sequential manner. The work focuses on natural human dialogues with a diverse set of utterances, not just questions and answers. Previous work used Memory Networks for dialogue discussing movies and open-ended discussion from Reddit. In contrast to previous work using Memory Networks for dialogue discussing movies and open-ended discussion from Reddit, Zhou et al. (2018) link Reddit to structured knowledge. BID14 and BID8 use unstructured text to discuss news articles and local businesses, respectively, with external knowledge. Our task involves dialogue authored with given knowledge, highlighting the usefulness of knowledge in dialogue. In contrast to previous work, our task involves dialogues grounded in Wikipedia articles and sentences. Model-wise, BID14 uses a Bag-of-Words Memory Network fact encoder and an RNN decoder. Our paper compares Memory Networks BID19 and Transformers, developing an architecture that combines these approaches for multi-turn dialogue in an open-domain setting. Our paper introduces models for full multi-turn dialogue in an open-domain setting, where two participants engage in chitchat with one being a knowledgeable expert (wizard) and the other a curious learner (apprentice). The apprentice freely talks to the wizard at each stage of the conversation. The apprentice engages in deep conversations with the wizard, playing the role of a curious learner. The wizard's goal is to discuss a topic with the apprentice, emphasizing the use of knowledge. The wizard is instructed to engage in conversations with the apprentice, using knowledge from Wikipedia to craft relevant replies. The wizard engages in conversations with the apprentice, using Wikipedia knowledge to craft relevant and engaging replies. The flow of the conversation involves choosing a topic, sharing relevant information, and responding creatively. The wizard engages in conversations with the apprentice, using Wikipedia knowledge to craft relevant and engaging replies. The conversation involves choosing a topic, sharing information, and responding creatively. The goal is to replace the human wizard with a learned agent in future interactions. In Wizard of Oz experiments, a set of 1365 natural dialogue topics linked to Wikipedia articles were crowd-sourced. The wizard has access to relevant knowledge passages during the dialogue, using a fixed retriever similar to Open-SQuAD dataset. The dataset collection process involves presenting retrieved articles to the annotator using a standard retriever similar to Open-SQuAD dataset. The retriever uses TF-IDF weighted bag-of-word and n-gram vectors for comparison, retrieving top articles for dialogue turns and original topics. This system is used to build the dataset, but a model can potentially learn and use a superior method. During data collection, the wizard selects relevant articles and sentences for response generation. The wizard's UI allows them to choose one article and one sentence per turn, or none if no relevant information is found. The wizard selects relevant articles and sentences for response generation. The dialogue model learns to replace the wizard in learning tasks by accessing a knowledge source like Wikipedia. Extensions of Memory Network BID19 and Transformer BID21 models are developed to retrieve relevant information, read and attend over the knowledge, and generate the next response. The model can retrieve relevant information from a large memory based on dialogue history, read and attend to the retrieved knowledge, and generate the next dialogue utterance. It is used consecutively on each turn to form a complete dialogue with a user. There are two classes of models: retrieval models that select a response from a set of candidates and generative models that produce responses word-by-word. The input for both models is the current dialogue context at each turn. The model can retrieve information from a large memory based on dialogue history and generate the next dialogue utterance. It uses retrieval or generative models to select or produce responses. The input for both models is the current dialogue context at each turn. The knowledge base is hierarchically organized into documents, and standard information retrieval techniques are used to return relevant information. The model uses standard information retrieval techniques to return a smaller set of candidates for fine-grained selection. The retriever operates on the topic and the last two turns, calling the IR system three times with different queries. Top 7 articles are retrieved for further processing. The model uses information retrieval techniques to select candidates for fine-grained selection. It retrieves the top 7 articles for each lookup and flattens the results into separate sentences. This allows the neural model to attend to candidates independently without hierarchical issues. An attention mechanism is used for fine-grained selection of knowledge sentences for the next turn of dialogue. The model utilizes an attention mechanism to select knowledge sentences for the next dialogue turn. It encodes memory sentences and dialogue context with a Transformer encoder, then uses dot-product attention to select relevant information. The final stage involves predicting the output utterance for the next turn of dialogue. Different variants are considered for knowledge attention and utterance prediction in retrieval scenarios. The model encodes knowledge sentences and dialogue context using a Transformer encoder and dot-product attention. It predicts the output utterance for the next dialogue turn by considering different variants for knowledge attention and utterance prediction. The model encodes knowledge sentences and dialogue context using a Transformer encoder and dot-product attention to predict the output utterance for the next dialogue turn. Two versions are considered: a Two-stage and an End-to-end version, both finding the most relevant piece of knowledge and incorporating it with the dialogue context for response generation. Beam search with a size of 5 is employed for decoding. The model uses an encoding step to concatenate knowledge sentences with dialogue context for response generation. Beam search with a size of 5 is used for selecting the best response. Generative models employ BPE encoding BID16 to enable copying rare words from Wikipedia sentences. In the End-to-end version, a shared Transformer encoder encodes all candidates and dialogue history, producing an attention prediction over the memory. The model utilizes BID2 normalization for attention prediction over memory, concatenating knowledge encoding with dialogue for response generation. Training minimizes negative log-likelihood of response utterance and can add supervision for correct knowledge selection. Illustration of the End-to-end model is shown in FIG0. The model employs BID2 normalization for attention prediction over memory and concatenates knowledge encoding with dialogue for response generation. Training focuses on minimizing negative log-likelihood of response utterance and can include supervision for correct knowledge selection. Additionally, the Two-stage version utilizes separately trained models for knowledge selection and utterance prediction, with techniques such as knowledge dropout to enhance decoder performance. The decoder's performance is improved by using knowledge dropout (K.D.), which prevents the model from attending to knowledge during training. This technique helps the generator be more resilient to errors and speeds up training. It is similar to other dropout techniques like feature dropout. Experimental setups and results are described, focusing on the model's ability to select knowledge and perform dialogue tasks. Before analyzing the full Wizard dialogue task, the models' ability to predict selected knowledge is assessed. The study evaluates models' ability to predict selected knowledge in a dialogue task. Transformers outperform baselines when pretrained on Reddit data. The study evaluates models' ability to predict selected knowledge in a dialogue task. Transformers pretrained on Reddit data outperform baselines, with marginal impact from multi-tasking on SQuAD. The best performing Transformer model is used for a two-stage generative Memory Network in the full dialogue task. Experiments are conducted for retrieval and dialogue generation given knowledge in two settings. The study evaluates models' ability to predict selected knowledge in a dialogue task. Experiments are conducted for retrieval and dialogue generation in two settings, using Transformer Memory Networks to attend over knowledge. The addition of knowledge improves all models, with significant performance gains for predicted knowledge. The addition of knowledge improves all models for predicted knowledge, with significant performance gains. Generative experiments compare End-to-end and Two-stage Transformer Memory Network models to baselines, showing improvements in perplexity and unigram F1. The End-to-end and Two-stage models outperform the Transformer without knowledge, showing improvements in perplexity and F1 scores. The Two-stage model excels in using predicted knowledge, while the End-to-end model performs better with gold knowledge. This indicates the Two-stage model benefits from a strong knowledge selection module, while the End-to-end model is better at utilizing selected knowledge. The Two-stage model benefits from a strong knowledge selection module, while the End-to-end model is better at utilizing selected knowledge. Additional knowledge selection supervision in the End-to-end model improves performance on every metric. Knowledge dropout also proves to be helpful. The conversation revolves around a preference for physical books over e-books due to the tactile experience and ownership of a real book. The models discussed show that Two-stage models outperform retrieval models in terms of F1 scores. The Two-stage models outperform retrieval models in terms of F1 scores. Human evaluation of the models is done using crowd-sourced workers who rate the dialogue partner's engagingness on a scale of 1-5. The Wiki F1 score is calculated based on the conversations collected. The study collected conversations to measure engagingness and knowledge exhibited by models. A metric called Wiki F1 score was used to assess the model's knowledge level. Results from 546 conversations with ratings from 464 workers were analyzed. The study analyzed 546 conversations with ratings from 464 workers, showing that retrieval models outperform generative models in human engagingness evaluation. Retrieval models with knowledge retrieval trend towards higher Wiki F1 scores. Generative models benefit significantly from the use of knowledge in improving human engagingness ratings. The study found that generative models with knowledge conditioning had significantly higher Wiki F1 scores and improved human engagingness ratings. These models conveyed more knowledge than their counterparts without knowledge conditioning, especially on unseen data where the gap between retrieval and generative models was larger. In this work, dialogue agents are developed with large memory systems containing encyclopedic knowledge to engage in open-domain conversations. Transformer Memory Network models are used to retrieve and output responses. Additional analysis and examples can be found in the appendices. The study introduces Transformer Memory Network models for open-domain conversations grounded in Wikipedia knowledge. The effectiveness of these models is demonstrated using the Wizard of Wikipedia dataset, with potential for further research and advancements in this area. The study introduces Transformer Memory Network models for open-domain conversations grounded in Wikipedia knowledge, showing their effectiveness using the Wizard of Wikipedia dataset. Future work includes bridging the gap between retrieval responses and generative models, learning to retrieve and reason simultaneously, and exploring the relationship between knowledge-grounded dialogue and existing QA tasks. The goal is to create an engaging and knowledgeable conversational agent. The aim is to create an engaging conversational agent by using Transformer Memory Network models with access to Wikipedia knowledge. The dataset includes conversations between a wizard and apprentice, where the wizard can retrieve information from Wikipedia. The apprentices ask questions in 13.9% of training set utterances. In the dataset, apprentices ask questions in 13.9% of training set utterances, while the wizard answers questions 39.5% of the time. They also engage in new or follow-on statements 49.3% of the time. To select natural topics, the Persona-Chat dataset BID26 was used, containing \u223c1000 personas with 4-5 sentences describing their interests. The dataset BID26 contains \u223c1000 personas with 4-5 sentences describing interests, mapped to relevant Wikipedia pages. 1,431 topics were obtained for the task using these personas. The dataset BID26 contains \u223c1000 personas with interests mapped to Wikipedia pages, resulting in 1,431 topics for the task. The persona topic sets are used as conversation starters during data collection. Additional experiments were conducted on knowledge selection tasks, showing that the retrieval system could be improved with auxiliary loss for generative models. The retrieval system performance could be enhanced with auxiliary loss for generative models. Analysis of dialogues from human evaluation experiments revealed stark differences between human-human and bot conversations. The human-human conversations are different from bot conversations, with humans engaging in small talk and using discussion topics as icebreakers. In contrast, human-human conversations from the Wizard dataset involve one human with access to Wikipedia, leading to more factual discussions. Models attempt to mimic the role of a wizard by producing factual sentences, but could benefit from additional training data like SQuAD. The retriever models in bot conversations struggle with non sequiturs and changing topics. The retriever with knowledge sticks to the chosen topic but faces challenges when the human changes the subject. The two-stage retrieval system was also tested on the full Wizard task. The two-stage retrieval system was tested on the full Wizard task, outperforming the best retrieval method in terms of F1 but not Recall@1. The system could be improved by optimizing the dialogue retrieval module for the gold chosen knowledge sentence. The system's performance on the gold knowledge task suggests improving the retrieval system by enhancing performance on the knowledge selection subtask. Human experiments were conducted to calculate the Wiki F1 score for the wizard and apprentice, showing higher values due to the wizard's direct access to Wikipedia passages. The UI explains the higher Wiki F1 values for the wizard and apprentice. The model produces factually inaccurate answers but includes inviting responses for a natural conversational flow. The generator without knowledge exhibits typical seq2seq system behaviors. The generator without knowledge exhibits typical seq2seq system behaviors, such as local and global repetition and inconsistencies in personality. In contrast, the generator with knowledge copies large fragments from Wikipedia, resulting in fewer repetition issues and the ability to act as a selfish conversationalist. The generator with knowledge can act as a conversationalist, providing accurate information from Wikipedia but sometimes with errors. It can generalize to new topics and often gives formulaic responses."
}