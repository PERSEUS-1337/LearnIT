{
    "title": "SkPoRg10b",
    "content": "We present an approach to understand the generalization properties of deep neural networks by revisiting old ideas in the statistical mechanics of neural networks. A prototypical Very Simple Deep Learning (VSDL) model is introduced, controlled by two parameters: one representing the amount of data on the network and another with an effective temperature interpretation. This model helps explain how the network behaves under different conditions. The VSDL model introduced in the study explores the generalization properties of deep neural networks by incorporating ideas from statistical mechanics theory. It describes the behavior of neural networks under various conditions, including overfitting, discontinuous learning, and sharp transitions in generalization properties. Neural networks, particularly deep neural networks used in deep learning, have shown impressive performance in machine learning tasks. Researchers have conflicting views on their behavior, with some claiming robustness to noise while others highlighting sensitivity to even small amounts of noise. Some papers express surprise that popular theories like PAC and VC do not describe neural network properties well, while others believe these theories are not suitable for understanding NN learning. Many papers mention the non-convex nature of optimization problems leading to issues like local minima, while some argue that non-convexity and local minima are not a concern. Some advocate for convergence to flat minimizers. Some argue that non-convexity and local minima are not a concern in neural networks, while others advocate for convergence to flat minimizers. Recent attention has been drawn to these tensions due to a study on DNNs overtraining with noisy data. Observation 1 highlights that neural networks easily overtrain when presented with noisy data, fitting to noise even with state-of-the-art systems. Observation 2 suggests that popular regularization methods may not prevent overtraining in deep learning systems. Regularization methods in deep learning, such as adding capacity control functions or performing dropout, do not effectively prevent overtraining. The only control parameter that significantly helps is early stopping. This contrasts with SVMs, where overtraining is not as prominent even with high training accuracy. In statistical data analysis, SVMs may overtrain if labels are randomized, leading to spuriously high training accuracy. Textbook discussions suggest tuning regularization parameters to prevent overtraining and improve generalization error. Tuned accuracies are expected to be around 80% after label randomization. Observation 1 and Observation 2 suggest that DNNs behave differently, leading to a need for rethinking generalization in DNN-based learning. This requires revisiting old ideas on generalization and capacity control beyond current ML methods. Rethinking generalization in DNN-based learning involves revisiting old ideas on generalization and capacity control beyond current ML methods, specifically through the statistical mechanics theory applied to NNs and DNNs. This approach can explain empirical properties not easily understood by traditional generalization theories like PAC/VC theory. The SM approach can be formulated rigorously or non-rigorously. The statistical mechanics (SM) approach in machine learning can be formulated rigorously or non-rigorously. The non-rigorous approach, more common in DNN models, provides precise quantitative agreement with observed results along the learning curve. It offers a theory of generalization that explains complex learning behaviors like phases and phase transitions. The statistical mechanics approach in machine learning explains complex learning behaviors like phases and phase transitions, with load-like and temperature-like parameters influencing the process. While not inconsistent with the PAC/VC approach, the SM approach offers a more detailed understanding of phenomena that are not typically observed in the latter. The VSDL model of classification in DNN learning models involves error plots, phase diagrams, and adjusting algorithm knobs. Two parameters in the model are compared to load-like and temperature-like parameters in traditional statistical mechanics for generalization. The VSDL model of classification in DNN learning involves error plots, phase diagrams, and adjusting algorithm knobs. Two parameters in the model are compared to load-like and temperature-like parameters in traditional statistical mechanics for generalization. The existence of two or more such parameters holds more generally, leading to complex generalization properties. Observations 1 and 2 are explained through a one-dimensional phase diagram. The generalization error behavior is illustrated in one-dimensional and two-dimensional phase diagrams based on the load parameter \u03b1 and \u03c4. A critical value \u03b1 c leads to dramatic changes in generalization properties, while other values result in smooth transitions. The two-dimensional phase diagram shows sharp transitions in generalization properties in the \u03b1 and \u03c4 parameter space. The phase diagram in a two-dimensional space is defined by the \u03b1 and \u03c4 parameters, showing sharp transitions in generalization properties. Adding noise and adjusting parameters can affect generalization behavior, with adjustments needed to maintain good generalization. Adjusting the number of iterations to modify the \u03c4 parameter can offset poor generalization in the VSDL model. Adding noise can decrease \u03b1, leading to poor generalization at point B, which can be improved by increasing the number of iterations to obtain point C. The SM approach to generalization can yield quantitative results but may require technical expertise. The SM approach to generalization can lead to quantitative results but can be technically complex. The paper focuses on basic ideas and qualitative results, leaving technical complexities for future work. Caution is advised when interpreting results for realistic DNN systems. The paper focuses on basic ideas and qualitative results, cautioning against interpreting results for realistic DNN systems due to the complexity of control parameters and interactions between them. In the next section, the paper will review relevant background and present main contributions on connecting practical DNN control parameters with load-like parameters, temperature-like parameters, and non-trivial generalization behavior in a VSDL model. Section A will provide a more detailed discussion and explanation. In Section A, the paper discusses the historical background of the SM approach to NNs, highlighting the equivalence between NNs with symmetric connections and the equilibrium SM behavior in models like the Hopfield model. In the Hopfield model, there is an equivalence between neural networks with symmetric connections and the behavior of magnetic systems like spin glasses. This allows for the design of neural networks for tasks such as associative memory. The SM approach and PAC/VC theory were popular in the 80s/90s for controlling generalization properties of NNs before the rise of Support Vector Machines and related methods. The ML community shifted from neural networks to Support Vector Machines and PAC/VC-based methods before the renewed interest in DNNs. Theoretical work in ML has focused on PAC/VC generalization, ignoring the SM approach. The SM approach to NNs can offer insights into recent observations. The SM approach to NNs provides a qualitative description of recent phenomena in learning and generalization, highlighting a wide variety of observable properties in both simple and complex neural network systems. The focus is on qualitative rather than quantitative descriptions, raising questions of interest in contrast to the PAC/VC approach. The SM approach to NNs explains the complex nature of generalization in neural network systems, highlighting discontinuities and sensitivity to control parameters and model details. The generalization performance of neural network systems can exhibit strong discontinuities and sensitivity to control parameters, model details, algorithms for approximate computation, implicit regularization properties, data properties, and noise. This complexity in generalization has been historically recognized and is a modern phenomenon observed in complex deep learning systems. In recent years, researchers have observed complex properties in deep learning systems, leading to challenges in algorithmic optimization and statistical inference. This complexity in generalization is influenced by various factors such as control parameters, model details, and data properties. The complexity of deep learning systems poses challenges in algorithmic optimization and statistical inference. BID3 involves strong distribution assumptions and complex technical applications, with limits different from traditional computer science and statistics. PAC/VC theory provides smooth upper bounds on generalization accuracy, but lacks sufficient detail in publications for reproducibility. The upper bound on a quantity does not imply smoothness. Details in publications are often insufficient for result reproduction. Neural networks can have different phases and non-trivial phase diagrams based on control parameters. Phases represent regions in parameter space where system properties change smoothly. In the context of neural networks, phase transitions refer to points of discontinuity in system properties under parameter scaling, leading to qualitatively different behavior in phase diagrams. For example, in the Hopfield model of associative memory, changes in the load parameter can result in dramatic improvements or deteriorations in retrieval capabilities. In the Hopfield model of associative memory, changes in the load parameter \u03b1 and temperature parameter \u03c4 can lead to different system phases with varying retrieval properties. The system can transition between high-temperature ergodic phase, spin glass phase, and low-\u03c4 low-\u03b1 memory phase, affecting its retrieval capabilities dramatically. The retrieval properties of neural networks can change significantly based on control parameters. Different types of neural networks, such as unsupervised holographic associative memories, restricted Boltzmann machines, and multilayer perceptrons, exhibit unique phase behavior. Understanding how these properties generalize is crucial in deep learning computations. This idealized model sheds light on various aspects of generalization through the SM theory. The VSDL model, based on the SM theory of generalization, explains aspects of large modern DNN performance. Three main claims are presented: the VSDL model captures practical control parameters, the thermodynamic limit is suitable for analysis, and the model exhibits non-trivial phases in this limit. The VSDL model, based on the SM theory of generalization, explains aspects of large modern DNN performance. Claim 1 describes a Very Simple Deep Learning (VSDL) model that can model practical DNN training. The model implements a function f that maps input images to output labels. The VSDL model implements a function f that maps input images to output labels, where f depends on parameters \u03b1 and \u03c4. These parameters can be controlled during DNN training. The VSDL model implements a function f that maps input images to output labels using parameters \u03b1 and \u03c4 that can be controlled during DNN training. Control parameters like temperature and pressure can determine the state of water or the presence of a giant component in a random graph model. In statistical learning applications, the focus is on macroscopic properties and transitions between regions of control parameter space. The interest lies in understanding the macroscopic properties of DNN learning systems rather than microscopic improvements. Adding noise can help improve prediction quality. In rethinking generalization and understanding deep learning, the focus is on macroscopic properties of DNN learning systems. Adding noise to the training data decreases an effective load \u03b1, which corresponds to a control parameter. This can be achieved by randomizing labels or adding noisy data to the training set. The goal is to improve prediction quality and understand the effective capacity of the model. Adding noise to the training data decreases the effective load parameter \u03b1, which can be achieved by randomizing labels. This helps improve prediction quality and understand the model's effective capacity. By adding noise to the training data, the effective load parameter \u03b1 is decreased, improving prediction quality and understanding the model's capacity. The Rademacher complexity measures how well a model can fit random data, with a value between 0 and 1. The Rademacher complexity measures the model's capacity to fit random data, with a value between 0 and 1. Empirical results show that for realistic DNNs, the model capacity scales with the number of data points. If a new DNN model is trained on a set of data points with noisy labels, the model capacity remains approximately the same. After training a DNN model on data with noisy labels, the model's capacity remains the same. Overtraining occurs when the model has more capacity than needed for the labels. Early stopping increases an effective temperature in the training algorithm. The iterative training algorithm uses an effective temperature-like control parameter, with early stopping increasing this parameter. This is justified by the interpretation of DNN training as a stochastic learning algorithm with weights evolving according to a Langevin equation. The temperature \u03c4 corresponds to the learning rate, and is related to the annealing rate schedule of the SGD algorithm. The temperature \u03c4 in the stochastic dynamics corresponds to the learning rate and annealing rate schedule of the SGD algorithm. It decreases the variability of NN weights with t * as the number of steps taken by the iterative algorithm. The parameters \u03b1 and \u03c4 can be used to control the learning process by adjusting input data noise or early-stopping. Other associated quantities like VC dimension or growth function are not practical for control. When controlling the learning process, parameters like \u03b1 and \u03c4 can be adjusted for input data noise or early-stopping. Other quantities like VC dimension or growth function are not practical for control. When analyzing modern DNNs, it is important to consider appropriate limits, allowing model complexity to grow with the number of parameters. When analyzing modern DNNs, it is crucial to consider appropriate limits that allow model complexity to increase with the number of parameters. The VSDL model requires a thermodynamic limit where the hypothesis space and data points diverge, unlike the PAC/VC approach. Technical complexities in generalization arise from subtleties in this limit. The VSDL model in the thermodynamic limit has error plots that resemble those in FIG1, with generalization and training errors plotted against the load-like parameter \u03b1. The SM approach to generalization has subtleties associated with this limit, as described in the references cited in Section A. The VSDL model's error plots resemble those in FIG1, with generalization and training errors plotted against the load-like parameter \u03b1. When \u03c4 is varied, the phase diagram of the VSDL model is shown in FIG1 (b), with lines indicating different phases of learning. The transition between different phases of learning in the VSDL model is illustrated in FIG1 (a) by varying the load-like parameter \u03b1. As \u03b1 changes, the generalization error either decreases gradually or increases dramatically, depending on whether \u03b1 is increased or decreased from a critical value \u03b1 c. This transition signifies a significant change in generalization error. The transition in learning phases in the VSDL model is depicted by varying the parameter \u03b1 in FIG1. As \u03b1 changes from \u03b1 > \u03b1 c to \u03b1 < \u03b1 c, there is a sharp increase in generalization error, where fitting training data well does not translate to fitting test data well. This is shown in FIG1 (b) along the \u03c4 = 0 axis. The system may exhibit only one phase of learning for \u03c4 > \u03c4 c. The transition in learning phases in the VSDL model is depicted by varying the parameter \u03b1. For \u03c4 > \u03c4 c, the sharp transition in learning as a function of \u03b1 may disappear, resulting in only one phase of learning. Adding noise to data and adjusting algorithm knobs is illustrated in FIG1 (c) in the (\u03b1, \u03c4) plane. The system transitions from point A to point B with parameter values (\u03b1 A , \u03c4 A ) to (\u03b1 B , \u03c4 B ) when data labels are randomly changed. Adjusting the temperature parameter \u03c4 can compensate for the decrease in generalization properties on new noisy data. The system transitions from point A to point B with parameter values (\u03b1 A , \u03c4 A ) to (\u03b1 B , \u03c4 B) when data labels are randomly changed. Adjusting the temperature parameter \u03c4 can compensate for the decrease in generalization properties on new noisy data. If the iterative algorithm is stopped properly at point C with parameter values (\u03b1 C , \u03c4 C), where \u03b1 C = \u03b1 B, then the generalization properties are much better. The VSDL model has consequences for NN/DNN learning, focusing on Observations 1 and 2. Many technical complexities are left for future work. Neural networks can easily overtrain due to the lack of a global control parameter for generalization in realistic NNs and DNNs, as discussed in more detail in Section A.5. Certain parameter values can lead to a phase where overfitting is unavoidable. In certain scenarios, neural networks can enter a phase of unavoidable overfitting due to specific parameter values. Regularization techniques may or may not help in preventing this issue. The number of iterations and the parameters \u03c4 and \u03b1 play a crucial role in controlling overfitting in realistic neural networks and deep neural networks. In this context, \u03c4 is identified as the primary control parameter for preventing overfitting in an idealized model of realistic deep neural networks. In an idealized model of realistic deep neural networks, the primary control parameter to prevent overfitting is \u03c4. The number of iterations must be decreased to avoid overfitting, as observed in the SM theory of generalization. This approach provides a powerful way to understand the properties of modern DNNs. The VSDL model and SM theory of generalization offer a new way to understand modern DNNs, different from the PAC/VC approach. Revisiting these old ideas can be valuable, despite technical complexity. Relevant highlights will be provided in Section A for better understanding. In Section A, highlights of the VSDL model are provided to explain the simplest model for understanding realistic DNNs. The model simplifies complex DNNs into two control parameters, describing data load and temperature interpretation. The VSDL model simplifies complex DNNs into two control parameters: one related to data load and the other to temperature interpretation. This model helps explain empirical results on DNNs' inability to avoid overfitting, discontinuous learning, and sharp transitions in generalization properties. Recent work has also explored similar ideas with a scale-sensitive analysis involving the Lipshitz constant of the network. Recent work has explored scale-sensitive analysis involving the Lipshitz constant of the network, making connections with margin-based boosting methods and Information Bottleneck ideas to analyze information compression in stochastic optimization algorithms. These lines of work complement the VSDL model's explanation of DNN behaviors like overfitting and discontinuous learning. Recent work has explored connections with margin-based boosting methods and Information Bottleneck ideas to analyze information compression in stochastic optimization algorithms. The results suggest that every DNN has a generalization phase diagram based on its control parameters, with algorithm adjustments affecting parameter space. This phase includes a gradual change in generalization, consistent with PAC/VC-based intuition. In DNNs, there is a phase diagram based on control parameters, with a gradual change in generalization. The conjecture is hard to evaluate due to conflating optimization and regularization issues, and non-reproducible empirical results. The VSDL model and SM approach explain various phenomena observed empirically, such as discontinuities in generalization performance and sensitivity to model details, algorithms, regularization, data properties, and noise. The VSDL model and SM approach explain phenomena like discontinuities in generalization performance and sensitivity to model details, algorithms, regularization, data properties, and noise. Implicit regularization properties of approximate computations and generalization decay in asymptotic regime are discussed in detail with simple models in this section. The VSDL model and SM approach explain discontinuities in generalization performance and sensitivity to various factors. Simple models are used to illustrate these properties, with a focus on PAC/VC versus SM approaches and evidence for discontinuous generalization behavior. In Section A.3, the root of discontinuous generalization properties is explained in a simpler model for detailed analysis. Section A.4 discusses evidence in larger DNNs, while Section A.5 reviews popular regularization mechanisms and their limitations in certain situations. The \"general considerations from the SM theory of generalization\" suggest a qualitative generalization diagram similar to FIG1 and 1(b). Starting with simple network architectures like the fully-connected committee helps address this question. The fully-connected committee machine, tree-based parity machine, and one-layer reversedwedge Ising perceptron are simple network architectures that capture multilayer and non-trivial representation capabilities essential for modern DNNs. Multilayer networks have stronger representational power than single layer networks, with the former representing extreme cases. The fully-connected committee machine and tree-based parity machine represent extreme cases of connectivity in multilayer networks, with the former having K elements in one hidden layer. The one-layer reversed-wedge Ising perceptron serves as a prototype model for the representation ability of more realistic networks. The fully-connected committee machine and tree-based parity machine have different levels of connectivity in multilayer networks. The former has K elements in one hidden layer, specified by K vectors connecting inputs to hidden units. The activity of the hidden units and the output are determined by the majority vote of the hidden layer. The generalization error is shown in FIG3 (a) as a function of the control parameter \u03b1\u03b2, illustrating discontinuous behavior. The tree-based parity machine is a multi-layer network with a tree-like structure in the hidden units. The output is determined by the parity of the hidden units, and the generalization error is shown in FIG3 (b) as a function of the control parameter \u03b1\u03b2. The one-layer reversed-wedge Ising perceptron is a single layer network with a non-trivial activation function. It classifies inputs as +1 or -1 based on the non-monotonicity of the activation function. The model's representation ability is illustrated by the generalization error \u03b5 as a function of the control parameter \u03b1 in FIG3. The activation function of the one-layer reversed-wedge Ising perceptron is non-monotonic, with classification as +1 or -1 based on \u03bb compared to \u03b3. The learning curve in FIG3 demonstrates the abrupt change in generalization error \u03b5 with respect to the control parameter \u03b1. In all three cases (Figs. 2(a), 2(b), and 2(c)), there is an abrupt change in the learning curve based on a load-like parameter. Different parameters may affect the behavior, but there is a range where discontinuous generalization behavior is observed. Further explanation will be provided in Section A.3 with simpler models. In Section A.3, simpler models will be discussed to explain the mechanism behind the abrupt change in learning curve behavior based on a load-like parameter. The models will analyze the SM theory of generalization using two complementary approaches. The hypothesis space F consists of mappings used to approximate the target T in the input space. Learning from examples involves selecting an element from F to approximate T on the complete input space. The goal is to approximate the teacher (target rule) as well as possible, with the generalization error \u03b5 representing the probability of disagreement between the student/hypothesis. The student aims to approximate the teacher by minimizing the generalization error \u03b5, which is the probability of disagreement between them on a subset of X. The student iterates the process of updating their mapping f to match the teacher's label T(x) on each element x \u2208 X. If the target rule is in the hypothesis space F, the problem is realizable; otherwise, it is unrealizable. In the iterative learning algorithm, the student constructs a new mapping f at each time step t according to a learning rule. If the target rule is in the hypothesis space F, the problem is realizable; otherwise, it is unrealizable. The version space at time step t is the subset of X compatible with the data seen so far. The zero-temperature Gibbs learning rule is sometimes considered for generalization error evaluation. The zero-temperature Gibbs learning rule evaluates the generalization error of a vector drawn randomly from V(S). The training error \u03b5t quantifies the performance of the student on the training set. The difference between training error and generalization error is characterized as the learning curve. The learning curve is characterized by the difference between training error \u03b5t and generalization error |\u03b5 t \u2212 \u03b5|. The PAC/VC approach considers the training set size m as a control parameter to understand how the error varies as m increases. This framework uses accuracy parameters \u03b4 and \u03b3 to make decisions based on the generalization error. The PAC framework uses accuracy parameters \u03b4 and \u03b3 to make decisions based on the generalization error, closely related to the statistical problem of convergence of frequencies to probabilities. The approach provides bounds for learning with finite values of m, but is not suitable when the rule f* is not independent of the training data. When dealing with the generalization error in learning with finite values of m, a Hoeffding-type approach may be used. However, this approach is not suitable when the rule f* is dependent on the training data. To address this, fixing F and constructing a uniform bound over the hypothesis space F can be done by focusing on the worst-case scenario. This method can be derived from the Hoeffding inequality, even if |F| is infinite, as long as the classification diversity of F is not too large. Vapnik and Chervonenkis demonstrated that even with an infinite set of functions |F|, results can be achieved if the classification diversity is limited. The PAC/VC approach focuses on minimizing empirical error within function class F on a random sample of m examples, leading to a generalization error bounded by DISPLAYFORM3. This power law decay, dependent on an inverse power of m, is due to the need for uniform convergence. The only problem-specific quantity in these bounds is the VC dimension. The power law decay in generalization error, dependent on the VC dimension, arises from the demand for uniform convergence. The bounds are universal and hold for any function class F, input distribution, and target distribution. The thermodynamic limit, known in information theory, allows for easy computation of quantities related to generalization error in the context of function class F varying with training set size m. This limit forms the basis for the SM approach to generalization. The SM approach to generalization is based on the thermodynamic limit, allowing for easy computation of quantities related to generalization error in the context of a function class F varying with training set size m. This approach describes the learning curve of a parametric class of functions for tasks like classification in input space X. The SM approach to generalization is based on the thermodynamic limit, describing the learning curve of a parametric class of functions for tasks like classification in input space X. It involves choosing a fixed target function for each class of functions, leading to a sequence of target functions. The SM approach to generalization involves considering the behavior of the number of functions in a class at a given error value in the limit. This limit can be described as a \"competition\" between the error value and the logarithm of the number of functions, resembling an energy-entropy balance. If the limit exists, learning curves can be analyzed in this context. In the context of generalization error, the sample size and function class sizes play a crucial role. By considering the case where the sample size and function class sizes both approach infinity while maintaining a fixed ratio, denoted by \u03b1, one can analyze the generalization error. This ratio is similar to the load on a network in associative memory models and serves as a control parameter for investigating generalization error under different conditions. The mechanism for behavior observed in FIG3 for various machine models in the SM theory of generalization will be explored by considering simpler models in Section A.3. The text discusses simpler models to explore the behavior observed in machine models in the SM theory of generalization. The behavior is characterized through rigorous analysis, numerical simulations, and replica-based calculations from statistical physics. The two basic models involve a continuous versus a discrete variant of a simple one-layer perceptron. The basic single-layer perceptron model is described in Sections IV, V.B, and V.D of FORMULA22, Section 2 of (11), and Chapters 2 and 7 of (31). The model uses a set of weights represented by a vector J in R N to classify input vectors S in R N as +1 or -1 based on the angle between S and J. The lengths of S and J do not affect the classification, and normalization is commonly chosen so that both vectors lie on the surface of an N-dimensional sphere with radius \u221a N. The generalization error in the single-layer perceptron model depends on the overlap parameter R between input vectors and weights. The error is given by \u03b5 = \u03b8/\u03c0, where \u03b8 is the angle between the input and weight vectors.\u03b5 = 0 for R = +1, \u03b5 = 0.5 for R = 0, and \u03b5 = 1 for R = -1. The perceptron model's generalization error depends on the overlap R between input vectors and weights. There are two basic versions of the perceptron: continuous perceptron with continuous weights on an N-dimensional sphere, and Ising perceptron with binary weights. The Ising perceptron model, with binary weights J \u2208 {\u22121, +1}, exhibits a phase transition common to spin glass models of neural networks. The generalization error \u03b5 decreases as the training set size increases, due to more incompatible vectors J. This model is not well-described by PAC/VC theory. The generalization error \u03b5 decreases as the training set size increases, with more incompatible vectors J. The probability of a vector J remaining compatible with the teacher when a new example is presented can be quantified by grouping vectors J into classes based on their overlap R with T. The chance of producing the same output as T on a randomly chosen input is 1 \u2212 \u03b5 for all vectors J with overlap R. The volume of vectors J with overlap R before any data are presented is denoted by \u2126 0 (\u03b5). The volume of compatible students with generalization error \u03b5 after m training examples is controlled by the balance between energy and entropy in the traditional SM approach. In the SM approach, generalization is characterized by the volume \u2126 m (\u03b5) and controlled by the balance between energy and entropy. The entropy density s(\u03b5) is the logarithm of the volume, while the energy e(\u03b5) is the penalty for incorrect predictions. The continuous perceptron's entropy behaves as \u223c ln(\u03b5) for small \u03b5 or large \u03b1. The entropy of the continuous perceptron slowly diverges to -\u221e as \u03b5 approaches 0 or R approaches 1. The energy behaves as \u03b1\u03b5 for small \u03b5 or large \u03b1, and in the thermodynamic limit, it is dominated by the maximum value of the expression in the square brackets. When a student vector is randomly chosen from the version space, it is likely to be one for which the expression in the square bracket is a maximum. The maximum value of the expression in the square bracket determines the student vector chosen randomly from the version space. The generalization error decreases smoothly with more examples, following PAC/VC theory. In the case of the discrete Ising perceptron, a different behavior is observed. The discrete Ising perceptron shows different behavior, with entropy approaching zero as \u03b5 \u2192 0 or R \u2192 1. The energy behaves as e(\u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1, minimizing s(\u03b5) \u2212 e(\u03b5) by exploiting the first order condition. See Sec. V.D of FORMULA22 for a more complete discussion. For the continuous perceptron, minimizing s(\u03b5) \u2212 e(\u03b5) by exploiting the first order condition leads to a solution for small-to-moderate values of \u03b1. However, for large values of \u03b1, the optimal value is at the boundary \u03b5 = 0. This results in a discontinuous change in the generalization error with increasing training set size. The behavior of the continuous perceptron shows a smooth decrease in generalization error with increasing data, while the discrete Ising perceptron exhibits more complex behavior with a discontinuous change in error at a critical value \u03b1 c. The discrete Ising perceptron exhibits complex generalization behavior with a one-dimensional phase diagram dependent on the parameter \u03b1. There are two phases with different generalization levels, and a discontinuous change in error between them. The discussion focuses on realizable learning with the Gibbs learning rule, where the learning algorithm may not find a random point from the version space. The discrete Ising perceptron exhibits complex generalization behavior with a one-dimensional phase diagram dependent on the parameter \u03b1. In cases where the problem may not be realizable, additional control parameters like a temperature parameter \u03c4 are introduced to avoid reproducing training data exactly. The phase diagram becomes two-dimensional with non-trivial behavior as a function of both \u03b1 and \u03c4. The full two-dimensional phase diagram is shown in FIG5, depicting different phases depending on the values of \u03b1 and \u03c4. The discrete Ising perceptron exhibits complex generalization behavior with a two-dimensional phase diagram showing different phases depending on the values of \u03b1 and \u03c4. The continuous perceptron has a trivial phase diagram with only one phase. Generalization in the SM theory of learning is characterized by a competition between entropy-like and energy-like terms. Results from the rigorous SM approach show that generalization in the SM theory of learning involves a competition between entropy-like and energy-like terms. The version space V(S) is the set of functions consistent with the target function T on the sample S. The -ball around the target function consists of functions with generalization error not larger than a certain value. This approach offers intuitive pictorial explanations of observed results. The -ball around the target function is a sample-independent subclass of functions with generalization error not larger than a certain value. Lower bounds on the probability of the version space being within the -ball provide bounds on the generalization error of any consistent learning algorithm. The probability that a function with generalization error remains in a certain subset of functions can provide bounds on the generalization error of any consistent learning algorithm. If the failure probability is fixed, then with high probability, a function consistent with random examples of a target function will have a low generalization error. The goal is to minimize the generalization error by considering functions within a certain subset. The generalization error \u03b5(h) can be bounded by a sum of quantities over a subset of functions, aiming to minimize it for improved bounds. A PAC/VC-like bound states that any consistent h satisfies \u03b5(h) \u2264 1 m ln (|F|/\u03b4) with probability at least 1 \u2212 \u03b4, independent of the distribution or target function, depending only on |F|. This bound may be weak, leading to larger values of \u03b5(h) compared to the bound. The PAC bound holds for all hypotheses, but does not guarantee finding the best one. Values of \u03b5(h) can be much larger than expected. Refined upper bounds can be obtained by tracking errors and the number of hypotheses achieving those errors. In the context of PAC bounds for hypotheses, considering a parametric class of functions can lead to a trade-off between entropy and energy, allowing for a bound on generalization error. In the context of PAC bounds for hypotheses, a trade-off between entropy and energy can bound generalization error by * + \u03c4. The error value * is where the energy term dominates the entropy term. This concept is applied to the continuous perceptron and the Ising perceptron. For the continuous perceptron, an entropy upper bound of s( ) = 1 is used, as shown in FIG5 (e). The learning curve gradually decreases with increasing \u03b1. For the Ising perceptron, the entropy upper bound is s( ) = H(sin 2 (\u03c0 /2)), shown in FIG5. The Ising perceptron has an entropy upper bound of s( ) = H(sin 2 (\u03c0 /2)), as shown in FIG5 (g). The entropy density s( ) is very small for configurations with energy slightly greater than the minimum value, indicating a small number of such configurations. The learning curve corresponding to the energy-entropy competition is plotted in FIG5. The rightmost intersection points plotted as a function of \u03b1 in FIG5 show the learning curve for the energy-entropy competition. For smaller \u03b1 values, the crossover point is non-zero and decreases gradually with increasing \u03b1. A critical value of \u03b1 is reached where the plot suddenly decreases to 0, and for larger \u03b1 values, the minimum is at the boundary. This non-smooth decrease of \u03b5 with \u03b1 is not described previously. At a critical value of \u03b1, the plot in FIG5 suddenly decreases to 0; for larger \u03b1 values, the minimum is at the boundary. This non-smooth decrease of \u03b5 with \u03b1 is not described by PAC/VC theory but is consistent with results from Eqn. BID12. The reason to believe in idealized models for understanding large DNNs lies in the theoretical and empirical work on loss surfaces. Theoretical and empirical work has focused on loss surfaces of NNs/DNNs, with a connection between NNs/DNNs and spin glasses. Results suggest a connection to the random energy model. The random energy model (REM) is a weaker hypothesis compared to a spin glass. It shows a transition in entropy density at a non-zero temperature parameter \u03c4, where entropy vanishes. Above a critical value \u03c4c, there are many configurations, while below \u03c4c, there is only one configuration. This phenomenon is similar to the Ising perceptron, with a small entropy for configurations with loss \u03b5. The Ising perceptron exhibits a small entropy for configurations with loss \u03b5, which is responsible for its complex learning behavior. This phenomenon is illustrated analytically and pictorially, suggesting that every DNN may display similar behavior. The Ising perceptron shows low entropy for configurations with loss \u03b5, leading to complex learning behavior. DNNs exhibit similar behavior, with early stopping acting as a form of regularization in the VSDL model. The Tikhonov-Phillips and TSVD methods are used to solve ill-posed LS problems. The Tikhonov-Phillips and TSVD methods are utilized to address ill-posed least squares problems, dealing with issues such as rank deficiency and poor conditioning of matrices. These methods offer alternative solutions to the LS problem, aiming to prevent overfitting and improve generalization to new data. The TSVD method replaces Problem BID18 with DISPLAYFORM3, where A k is the best rank-k approximation to A. The solution to Problem (22) is given by DISPLAYFORM4, where A + k is the Moore-Penrose generalized inverse of A. The control parameter \u03bb controls the radius of convergence of the inverse of A T A + \u03bb 2 I. The control parameter \u03bb determines the convergence radius of the inverse of A T A + \u03bb 2 I for the estimator in the Tikhonov-Phillips approach. The parameter k restricts the domain and range of A k for the estimator in the TSVD approach. Choosing appropriate values of \u03bb or k can prevent overfitting but may lead to underfitting. Increasing \u03bb or decreasing k can help prevent large differences between training and test errors. The control parameter \u03bb or k can prevent overfitting by minimizing the difference between training and test errors. For non-linear systems like NNs or DNNs, this may not hold true. Different approaches generalize to various problems by considering different objectives. The closed-form solution of certain objectives may not be applicable for problems like NNs. Linear regularization approaches historically did not work well on NNs in the 80s/90s. In the 80s/90s, linear regularization approaches were known to be ineffective on neural networks. Early stopping of iterative algorithms was found to work well as an implicit form of regularization. This approach is considered more natural and fundamental in controlling the training process. Regularization in learning algorithms is viewed as the solution to iterative algorithms without a specific optimization objective. While a connection to Tikhonov-Phillips/TSVD can be made in linear problems, it is not generally expected. The main results highlight the importance of controlling parameters in the training process. The dynamics leading to the SM approach to generalization do not optimize linear or convex objectives but follow a stochastic Langevin type dynamics, connected to an underlying Gibbs probability distribution. These dynamics, resembling stochastic dynamics like SGD, are well-suited for obtaining simple generalization bounds. The dynamics of general dynamical systems involve phases, phase transitions, and phase diagrams, where a phase is the set of inputs mapped to a fixed point, and a phase transition is a point where nearby points map to different fixed points. In general dynamical systems, phase transitions occur when nearby points map to different fixed points. There is no structure like the thermodynamic limit to provide generalization bounds, and control parameters of the system may not serve as regularization parameters. Adding noise to a system, such as randomizing labels or shuffling pixel values, may not always lead to finding an optimal regularization parameter. Adding noise to a system, like randomizing labels or shuffling pixel values, may not always lead to finding an optimal regularization parameter that prevents overfitting. The hope is that a regularization parameter can be found to prevent overfitting, even if it means underfitting, and that the generalization quality will vary smoothly with changes in the parameter. Our results in Section 3 show that increasing the regularization parameter \u03bb may not always prevent overfitting as expected. The popular PAC/VC approach provides smooth upper bounds, but our findings suggest that this intuition is often incorrect. It is easier to reason about the divergence of one quantity rather than two quantities in a well-defined manner. The intuition in ML and mathematical statistics often assumes regularity conditions that may not hold for nonlinear systems like NNs and DNNs. The consequences of this realization need further exploration."
}