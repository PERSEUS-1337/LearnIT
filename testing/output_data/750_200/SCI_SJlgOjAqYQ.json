{
    "title": "SJlgOjAqYQ",
    "content": "We conducted experiments to test global translation-invariance in deep learning models trained on the MNIST dataset. Both convolutional and capsules neural networks showed poor performance in this aspect, but data augmentation improved their performance. While the capsule network performed better on the MNIST testing dataset, the convolutional neural network generally had better translation-invariance performance. The success of convolutional neural networks in computer vision tasks is attributed to two key features. The success of convolutional neural networks in computer vision tasks is attributed to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. Capsule networks are robust in dealing with different viewpoints and offer more generalization capabilities. Capsule networks aim for 'rate-coded' equivariance by encoding viewpoint-invariant knowledge in weights, not neural activities. Viewpoint changes in capsule networks have linear effects on pose matrices, but their ability to generalize for global translation invariance is still unclear. The study aims to analyze global translation invariance in convolutional and capsule neural network models trained on the MNIST dataset. In this paper, a method is introduced to test global translation-invariance in convolutional and capsule neural network models trained on the MNIST dataset. The testing dataset consists of images generated by shifting the centre of mass of a Helvetica font digit one pixel at a time. There are a total of 2520 testing images covering all possible cases of translational invariance. The study tested global translation-invariance in neural network models using images of shifted centre of mass of digits. The testing dataset had 2520 images covering all possible translations, compared to MNIST dataset with images mostly at the center. Our method for testing global translation-invariance in neural network models is robust to noise and uses a smaller GTI training dataset. The GTI dataset allows for capturing tiny differences in models and quantifying global invariance. The CNN model has nine layers. The CNN model for testing global translational invariance has nine layers with specific configurations for each layer, including convolutional and fully connected layers. The total number of parameters is 361578, and ReLU activation function is used in most layers except for the last layer which uses softmax. The CNN model has nine layers with ReLU activation function, except for the last layer which uses softmax. It is optimized with Adam in Keras and trained on MNIST data, achieving high accuracy. However, its performance on global translational invariance is poor, with only 42.16% accuracy on GTI testing dataset. The CNN model's poor performance on global translational invariance is evident in the GTI testing dataset. Images with the digit's center predicted correctly, while those at the corner were assigned to incorrect classes. The model, trained on MNIST data, struggled to predict images shifted towards the corner, suggesting 'place-code' equivariance. Training the CNN model on MNIST data revealed poor performance on global translational invariance in the GTI testing dataset. By augmenting the training data with image shifts from the center in x and y-direction, the accuracy on the GTI dataset increased to 98.05%. This data augmentation implies 'place-code' equivariance in CNN, as neurons at the corner of features are better predicted. The CapsNet model with 8.2M parameters was tested on the GTI dataset, showing robustness in viewpoint invariance. Training involved Adam optimizer with exponential decay of learning rate and margin loss with scaled-down reconstruction loss. CapsNet demonstrated improved performance compared to CNN in handling objects at the edge of feature maps. The CapsNet model, with 8.2M parameters, showed robustness in viewpoint invariance on the GTI dataset. Training included Adam optimizer with exponential decay of learning rate and margin loss with scaled-down reconstruction loss. However, the experiment revealed that Capsule network's performance on global invariance needs improvement. Data augmentation in the MNIST training dataset helped improve CapsNet accuracy on the GTI dataset. The CapsNet model, with 8.2M parameters, demonstrated robustness in viewpoint invariance on the GTI dataset. Data augmentation in the MNIST training dataset improved CapsNet accuracy on the GTI dataset, with CNN outperforming CapsNet on the GTI dataset. The CapsNet model struggles with global translational invariance, lacking performance on the GTI dataset compared to CNN. Data augmentation improved CapsNet accuracy, but it still falls short in handling translational invariance without augmentation. CapsNet architecture shows potential over CNN in addressing this issue. CapsNet struggles with global translational invariance, but its architecture shows potential over CNN in addressing this issue. Testing involved GTI dataset accuracy comparison between CNN and CapsNet with different random shifting amounts in the MNIST training dataset. The method is quantifiable and easily implementable for other computer vision tasks."
}