{
    "title": "rk1J969Xz",
    "content": "Estimating image location solely based on image contents is challenging due to the need for contextual information. Current models struggle to address all complexities. This work introduces a global meshing strategy and training procedures to improve image geolocation inferencing. This work introduces a novel global meshing strategy for image geolocation inference, demonstrating improved performance by incorporating additional information such as time of posting and user metadata. Delaunay triangles are shown to be effective for geolocation in low volume scenarios, outperforming state-of-the-art models using quad trees with less training data. Incorporating additional information can improve geolocation accuracy by up to 11% for country-level and 3% for city-level locality accuracy. Incorporating additional information like time of posting and user metadata can improve geolocation accuracy by up to 11% for country-level and 3% for city-level localities. Advancements in deep learning have expanded the capabilities of machine learning in computer vision, allowing for more in-depth analysis of contextual information in images. This progress enables researchers to ask complex questions, such as determining the geographic location of a ground-level image, which remains a challenging task. Incorporating additional data like posting time and user metadata can enhance geolocation accuracy for both country and city-level locations. Estimating the geographic origin of ground-level images is challenging due to uneven distribution of geo-tagged image data and potential conflicting information. The work focuses on content-based image geolocation, identifying the geographic origin of ground-level images amidst conflicting data and ambiguous geographic terms. With the rise of image-based social media platforms, inferring geographic context from images has become a significant challenge. The shift from text-based platforms to mixed-media poses challenges in inferring geographic context from images due to the lack of consistent geolocation information. Social textual data may have geolocation, but images often lack EXIF data or have incomplete information. Using geolocation from linked objects in mixed-media data can be unreliable. For example, a user may have geolocation enabled on Twitter but post an image from a different location. The paper discusses various approaches for geolocating images, building on previous work in global geolocation from ground-based imagery. One common method is performing instance-level scene retrieval to assign a geolabel based on the similarity of the image query. For more details, refer to Brejcha & \u010cad\u00edk (2017) for a comprehensive review. The text discusses geolocation of imagery through scene retrieval and geolabel assignment based on image similarity. Prior work includes data sampling strategies for large-scale classification problems in social media applications, such as weighted sampling of minority classes and biasing class selection during deep learning model training. Biasing class selection with random noising is a known method to allow deep learning models to see more examples of rare classes. However, there are concerns specific to social media applications, such as sampling images without respect to users, which may overlook the influence of latent variables and communities. The study focuses on geolocation in social media, considering models based on image content (M1), time information (M2), and user-album inputs (M3). The research highlights the use of alternative methods for geolocation and the importance of time and user information in improving accuracy. Data is collected from YFCC100M BID17 for training and validation. The study focuses on geolocation in social media, utilizing image content (M1) and user information to improve accuracy. Data is collected from YFCC100M BID17 for training and validation, with user-id and posted-time metadata playing a crucial role in the analysis. The YFCC100M dataset contains user-id and posted-time metadata for every image, crucial for geolocation analysis. The global-scale geolocation model utilizes a classification approach similar to PlaNet, subdividing the globe into a grid for image classification. The YFCC100M dataset includes user-id and posted-time metadata for images, essential for geolocation analysis. PlaNet BID19 subdivides the globe into a grid for image classification, with prior distribution for image longitude varying by the time of day an image is posted. For example, it is easier to predict a longitude near zero for an image posted at 01:00 UTC compared to 21:00 UTC due to observed priors. The classification structure is generated using a Delaunay triangle-based meshing architecture, different from PlaNet's quad-tree mesh approach. Mesh cells are created to conserve surface area, but the method is more complex than a quad-tree. The mesh assigns a probability distribution of geo-labels for input imagery based on ground truth GPS data in each cell. The PlaNet approach uses a triangular mesh instead of a quad-tree mesh to capture Earth's geometric features more adaptively. Triangular meshes are unstructured but can easily capture water/land interfaces without additional refinement. However, they lack refinement level information compared to quad-tree meshes, which offer more control over granularity. The structured quad-tree approach allows for controlled granularity by adaptively refining cells based on the number of examples they contain. Mesh cells are refined if they exceed a certain limit or dropped if they have too few samples. The three meshes in the study were generated using specific options listed in Table 1. Mesh initialization parameters were not explored, with each mesh starting as a 31 x 31 structured grid with equal surface area. The three meshes in this study were initialized with a 31 x 31 structured grid with equal surface area in each triangle. The geolocation classification mesh can be adjusted by modifying the refinement level to control the number of cells. The mesh parameters for the coarse and fine meshes are shown in Table 1 and FIG2.1.1, covering a range of structures. The fine mesh aimed to replicate PlaNet's parameters but is not directly comparable. The study utilized three meshes with different structures, including fine P mesh replicating PlaNet's parameters. The coarse mesh was generated with an early dataset, while the final training included all training data. The study used three meshes with different structures, including a fine mesh that better represents geographic regions. The Inception v4 convolutional neural network architecture was deployed to develop the mesh-based classification geolocation model. The study utilized the Inception v4 convolutional neural network architecture to develop a mesh-based classification geolocation model. A softmax classification approach was employed, with cells labeled based on the cell centroid in latitudelongitude. The geolocation for each cell was specified as the lat/lon centroid of the image population, leading to significant improvements for coarse meshes. The geolocation for each cell is computed using the lat/lon centroid of the image population. Coarse meshes show significant improvements, with models evaluated by calculating the distance between predicted and ground-truth GPS coordinates using great-circle distance. The error threshold is defined as the number of images classified within a certain distance, with thresholds of 1 km, 25 km, 200 km, 750 km, and 2500 km representing different localities. Each YFCC100M image has associated metadata. The YFCC100M images have metadata including user id and posting time. Model M2 uses posting time in FIG2. The one-hot encoding Zik represents image i belonging to geolocation class k. Output N Softmax 1 indicates evidence for P(Zik=1|ti) = P(Zik=1). Time may not affect image content, but evidence suggests a relationship. The operational research hypothesis for model M2 is that there is time dependence after conditioning on image content. Variables related to time are added to the geolocation model output to create a new input. The top 10 probabilities from the softmax layer are retained for each image, with the rest set to 0. Model M3 geolocates multiple images from a single user using an LSTM model. Model M3 filters top 10 maximum entries, setting the rest to 0. It geolocates multiple images from a single user using Bidirectional LSTMs to capitalize on correlations in the user's images. The research question is whether the success observed in previous studies extends to this less organized approach. In M3, images by a single user are organized sequentially in time with no specific further organization. The research question is whether the success observed by BID19 extends to this less informative image organization. Images are grouped into albums of size 24, padded with zeros if needed, and masking is used. During training, a user is limited to a random album per epoch. Album averaging, as proposed by Weyand et al. (2016), assigns images in an album to a mesh cell based on the highest average probability, increasing accuracy by leveraging information across related images. The method assigns images in an album to a mesh cell based on the highest average probability, increasing accuracy by borrowing information across related images. User images are located based on the maximum average probability across all images associated with the user. LSTM on a time-ordered sequence of images was considered but did not significantly improve performance. The study explored using LSTM on a time-ordered sequence of images but found no significant performance improvement. The output of M1 is filtered to show the top 10 mesh cell probabilities and re-normalized. Training of M2 and M3 was only done on the validation data of M1. Time inputs are concatenated to the filtered outputs, and a new training step is implied. M3 (Time-Albums) is described as M2 concatenated with M3. The study explored using LSTM on a time-ordered sequence of images but found no significant performance improvement. Meshing parameters are investigated to understand sensitivity to mesh adaptation, showing a trade-off between fine-grain and coarse-grain geolocation. Results for each mesh are shown in TAB1, with coarse mesh demonstrating improved large granularity geolocation and fine mesh performing better at finer-granularities. Impact of classifying on training data centroid is compared to utilizing cell centroid for class labels. The impact of classifying on the centroid of the training data is compared to using the cell centroid for class labels. A significant improvement is seen for the coarse mesh, with a slight improvement for the fine mesh. The BID20 model, combined with indoor-outdoor label deliminations, is used to filter geolocation inference on outdoor imagery without re-training the geolocation model. Results show a 4-8% increase in accuracy for region/country localities. The Im2GPS testing data is used to test the model on 237 images from BID6, showing a 4-8% improvement in accuracy for region/country localities. Results are tabulated for all meshes, demonstrating generality in approach. Performance of the M1 classification model is comparable to BID19 with less training data. The M1 classification model shows comparable performance to BID19 with less training data and fewer classification regions. The coarse mesh model outperforms PlaNet for large regions. Time usage improves geolocation accuracy, with a slight gain in accuracy across all error calculations. The coarse mesh model outperforms PlaNet for large regions, with a small persistent advantage in accuracy across error calculations. Time usage improves geolocation accuracy, showing a measurable difference between errors with and without time. The hypothesis is tested using a Wilcoxon-Signed-Test for paired observations, without assuming normality of errors. The Wilcoxon-Signed-Test for paired observations showed a highly significant difference (p-value < 10 \u221216) in favor of using time-inputs, indicating that the effect of M2 is not due to chance alone. The distribution of errors is mean shifted, with the median error for coarse mesh e1 at 1627 km and e2 at 1262 km. Time input models have lower-bias class probabilities and improved cross-entropy optimization during training. The median error for coarse mesh e1 is 1627 km and for e2 is 1262 km. Time input models have lower-bias class probabilities and improved cross-entropy optimization during training, aiming to minimize class biases. KL-Divergence is calculated for each model to compare model output class frequencies with true class frequencies. The KL-divergence of the model output class frequencies compared to the true class frequencies in validation are in TAB5. \"User-Averaging\" is incorporated into results as a simple method that appears more accurate than predicting individual images with M1 or M2, but biases cell count frequency. Using the average probability vector to predict a user's image may result in higher bias and improved accuracy, with no guarantee of similar class frequency distribution to the truth. Albums are a better approach to borrow information across users. Improved accuracy can come with higher bias when using albums to borrow information across users. LSTMs on user albums had the lowest class bias compared to other models. Table 6 shows percentage accuracy at different spatial resolutions, with coarse and fine mesh having different numbers of triangles. Time inputs are concatenated with M1 output for album creation, which contains 24 images. \"Time inputs are concatenated with M1 output for album creation, containing 24 images. Best observed accuracy is in bold. Coarse Mesh and Fine Mesh Best Possible are theoretical models. Using time of day universally in geolocation models improves accuracy and reduces bias.\" Using time of day in models improves accuracy and reduces bias, especially in geolocation. Time information statistically enhances both meshes (M2). Accounting for indoor/outdoor scenes in images impacts validation accuracy, with outdoor-only results outperforming all images. Future work could involve incorporating the probability of an image being outdoor into the model input. Future work could involve concatenating the probability of an image being outdoor to the input of M2. Increasing the granularity of a grid reduces accuracy at the country and regional level, while improving accuracy at street and city levels. Street level geoinferencing is not practical with a coarse mesh, as shown by the best possible accuracy in Table 6. A fine mesh may not be better for geolocation at resolutions larger than 25 km, and there is no explicit way to prove it should perform no worse than a coarse mesh. However, a coarse mesh is superior for 200 km resolutions. Using a Delunary triangle-based mesh allows for training accurate models with fewer examples. Using a Delunary triangle-based mesh, accurate models can be trained with fewer examples. Images were divided into training and validation sets, with no overlap between models M1, M2, and M3. Softmax classification performs poorly with a large number of output classes. The training procedure developed for large models involved pre-training on ImageNet with Adagrad, increasing training examples each epoch, and oversampling minority classes. The training procedure for large models involved increasing training examples each epoch by 6%, oversampling minority classes, and reducing class bias after each training cycle. The final model was trained with SGD, using a decreasing learning rate and without class biasing. The final model was trained with SGD using a linearly decreasing learning rate, without class biasing, and with the full dataset per epoch. The hyperparameters were empirically determined, and M2 is trained using He initializations and ADAM with specific learning rates. Early stopping is used to detect a sustained decrease in validation accuracy. The generality of the M1 classification model is demonstrated by performing a query-by-example on the 2K random Im2GPS dataset. The M1 classification model's generality is shown by querying a 2K random Im2GPS dataset. An image of the Church of the Savior on Spilled Blood is used as an example, not present in the training or random dataset. Each image has a categorical indicator variable, and a latent class distribution is assumed constant between training, testing, and application. An estimate of this distribution is calculated. The latent class distribution p i is assumed constant between training, testing, and application. An estimate of this distribution is calculated. The last layer output from networks is a softmax model. When comparing models, accuracy is preferred but unbiased models may also be considered. The KL-divergence between q and p should be low if training is done well. Entropy of p and q is also considered for completeness."
}