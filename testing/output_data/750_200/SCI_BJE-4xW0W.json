{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) that allow sampling from both observational and interventional distributions. Adversarial training can be used to learn a CiGM with a structured generator architecture based on a causal graph. The application involves conditional and interventional sampling of face images with binary feature labels like mustache and young, preserving the dependency structure with the causal graph. A two-stage procedure is devised for learning a CiGM over the labels and images using a Wasserstein GAN. We propose two new conditional GAN architectures, CausalGAN and CausalBEGAN, for learning a CiGM over binary labels. The optimal generator of CausalGAN samples from image distributions conditioned on labels, creating a CiGM over labels and generated images. These architectures enable sampling from observational and interventional distributions. Generative adversarial networks (GANs) combined with a trained CiGM for labels create a CiGM over labels and generated images. The proposed architectures allow sampling from observational and interventional image distributions, including interventions not present in the dataset. GANs are successful in training implicit generative models without explicit parameterization of likelihood. Generative adversarial networks (GANs) are neural models trained to sample from high-dimensional distributions. A generator network produces samples from noise input, refined by a discriminator network that distinguishes between real and generated samples. GANs aim to maximize the discriminator's loss to generate realistic samples. They have been successful in generating samples, particularly in image distributions. Generative adversarial networks (GANs) have been successful in generating samples from distributions like images and videos. An extension of GANs involves sampling from class conditional data distributions by providing class labels to the generator. Various neural network architectures have been proposed for this task. The architecture can sample from joint and interventional distributions. Our architecture extends previous work on conditional image generation by capturing the dependence between labels and the causal effect between labels. It can sample from joint and interventional distributions, allowing for the sampling of images given a subset of labels. In this paper, the focus is on extending previous work on conditional image generation by capturing the dependence and causal effect between labels. The generator maps labels to images in a non-deterministic way, following the causal graph \"Labels cause the Image\" denoted by L \u2192 I. Additionally, causal relations between different labels can be included in the model, such as the example of Gender (G) and Mustache (M) labels. The causal graph between Gender (G) and Mustache (M) labels shows that Gender causes Mustache (G \u2192 M). Conditioning on Gender = male results in males with or without mustaches. When conditioning on Mustache = 1, only males are sampled. Causal models allow sampling from interventional distributions. Causal models enable sampling from interventional distributions by fixing variable values in a causal graph, affecting descendant distributions but not ancestors. Intervening on Mustache = 1 does not change the distribution of Gender in the same causal graph. The label combination (Gender = female, Mustache = 1) would appear as often as Gender = female after the intervention. See Figure 1 for illustrations of conditional and interventional samples. In this work, causal implicit generative models (CiGM) are proposed to sample from joint, conditional, and interventional probability distributions. The true causal graph is assumed to be given, and GANs can be used to train these models when the generator structure inherits neural connections from the causal graph. The Wasserstein GAN (WGAN) is utilized for training. When the generator structure inherits neural connections from the causal graph, GANs can train causal implicit generative models. Wasserstein GAN (WGAN) is used to train a CiGM for binary image labels. Two novel conditional GANs, CausalGAN and CausalBEGAN, are proposed for the second step. CausalGAN's optimal generator can sample from true conditional distributions. Combining CausalGAN with a CiGM on labels yields a CiGM on labels and images. The combination of CausalGAN with a CiGM on labels results in a CiGM on both labels and images. Adversarial training is used to structure the generator architecture based on the causal graph, allowing for the training of a CiGM using WGAN. This approach enables the learning of a CiGM that outputs discrete 1 labels for binary labels, along with proposing a two-stage procedure for conditional and interventional sampling of images given a causal graph over binary labels. We propose a two-stage procedure to train a CiGM over binary labels and images, introducing a novel conditional GAN architecture and loss function. Our model, CausalBEGAN, extends BEGAN to accept labels and produces high-quality images that match the image labels. The CiGM training framework is evaluated on CelebA data, showing promising results. CausalBEGAN, a model that produces high-quality images matching image labels, is evaluated on CelebA data. CausalGAN and CausalBEGAN can generate label-consistent images even for interventions not seen during training. Previous works like CGAN and ACGAN have also explored conditioning GANs on image labels. In BID10, ACGAN proposes the discriminator to estimate labels instead of receiving them as input. A comparison between CGAN and ACGAN is made in , with an extension to the semi-supervised setting. BID15 introduces InfoGAN, aiming to maximize mutual information between inputs and generated images. Existing conditional GANs do not allow sampling from label combinations not in the dataset. Existing conditional GANs do not allow sampling from label combinations not in the dataset. Various extensions like BiGAN, ALI, CoGAN, and SD-GAN have been developed to address this limitation by learning mappings between image and latent spaces, enforcing weight sharing between generators and discriminators, and splitting the latent space into \"Identity\" and \"Observation\" portions for generating faces of the same person. SD-GAN is an extension of BEGAN that splits the latent space into \"Identity\" and \"Observation\" portions. It allows for generating faces of the same person by fixing the identity portion of the latent code. Additionally, SD-GAN can be seen as an extension of BEGAN to accept labels, making it useful for applications like changing the age attribute of a face image using a one-hot encoded vector. Generative models can be used for changing attributes of face images, such as age, by conditioning on a one-hot vector. They can also be applied in compressed sensing, with guarantees for recovering data close to the output of a trained generative model. Recent research has focused on using causal principles in deep learning, with connections between GAN layers and structural equation models being explored. Techniques like CGAN are used to learn causal directions between variables in datasets. The authors explore causal principles in deep learning, using techniques like CGAN to learn causal directions between variables in datasets. They also propose causal regularization for training neural networks to ensure predictive causality. Additionally, there is a connection between GANs and causal generative models, with a focus on image causality in neural net weights. The authors discuss the connection between GANs and causal generative models, focusing on image causality in neural net weights. They introduce causality using Pearl's framework of structural causal models (SCMs) with structural equations and directed acyclic graphs. Within the SCM framework, causal models use equations and directed acyclic graphs between random variables. X causing Y implies a function f and an unobserved variable E, independent from X, determine Y. The causal graph is represented as X \u2192 Y, with parents of a node X_i showing its causes. The causal graph in a structural causal model is a directed acyclic graph where the parents of a node represent the causes of that variable. It is constructed from structural equations and contains functions, random variables, and exogenous variables. In a structural causal model, the causal graph is a directed acyclic graph representing the causes of variables. It includes exogenous variables, random variables, and functions. An intervention changes the causal mechanism and corresponding graph structure. An intervention in a structural causal model changes the underlying causal mechanism and corresponding causal graph. It is denoted as do(X i = x i ) and differs from conditioning by removing connections of the node X i to its parents. The post-interventional distribution can be calculated in a Bayesian network. After an intervention in a structural causal model denoted as do(X i = x i), the post-interventional distribution in a Bayesian network can be calculated by factorizing the observational distribution. The true causal graph for a set of variables cannot be identified without experiments or observations. The paper assumes a given causal graph and focuses on learning a causal model, not on identifying the true causal graph for a set of variables without experiments or additional assumptions. The paper discusses learning causal graphs using Bayesian networks to sample from observational distributions. It introduces causal implicit generative models for sampling from both observational and interventional distributions. Causal implicit generative models allow sampling from both observational and interventional distributions, utilizing generative adversarial networks for training. The model is based on a simple causal graph structure and uses feedforward neural networks to represent functions. The feedforward neural networks represent functions in the causal graph structure. The noise terms are chosen as independent, and Gaussian distributed variables can be used for exogenous variables. This neural network can model causal relationships with a graph display. The causal models with graph display show that two causal models with the same observational distribution have the same interventional distributions for any intervention. A feedforward neural network is linked to a causal graph by defining a set of mutually independent random variables. A feedforward neural network is linked to a causal graph by defining a set of mutually independent random variables. This network outputs a vector based on the parents of each variable in the graph. Causal implicit generative models are defined as neural networks consistent with the causal graph, used for adversarial training. CausalGAN architecture uses adversarial training with a generator neural network consistent with the causal graph. It focuses on image generation with binary labels, utilizing a pretrained causal implicit generative model for the labels. The Labeler is trained on real data, while the Anti-Labeler is trained on generated data. The CausalGAN architecture utilizes a pretrained causal implicit generative model for image labels. It divides the task into two subtasks: training a generative model for labels and then for images conditioned on the labels. The architecture and loss function ensure that the generator outputs the label-conditioned image. The CausalGAN architecture introduces a new architecture and loss function called Causal Controller for image generation problems. It ensures that the generator outputs label-conditioned image distributions based on a strictly positive joint distribution over the labels. The adversarial training of a CiGM for binary labels is described as part of this process. The Causal Controller, known as the Causal Controller, is used in the adversarial training of a CiGM for binary labels. The generator is structured to produce labels sequentially according to the causal graph, sampling from a discrete label distribution. Standard GAN training is not ideal for learning a discrete distribution due to challenges with Jensen-Shannon divergence and support alignment. The Causal Controller is utilized in training a CiGM for binary labels, generating labels sequentially from a discrete distribution. To address challenges with Jensen-Shannon divergence, WGAN is employed. A new conditional GAN architecture is designed to generate images based on labels, ensuring optimal performance. Our new conditional GAN architecture ensures the generator outputs label-conditioned image distributions using a pretrained Causal Controller. Two separate labeler neural networks, Labeler and Anti-Labeler, estimate image labels. The generator aims to produce realistic images by competing with the discriminator. The CausalGAN generator aims to produce realistic images by competing with the discriminator, ensuring images are consistent with labels by minimizing Labeler loss and avoiding easy-to-label distributions by maximizing Anti-Labeler loss. CausalGAN's key distinction is the use of an Anti-Labeler network in addition to a Labeler network, crucial for theoretical guarantees and discouraging the generator from outputting only typical faces. The Anti-Labeler loss discourages label-conditioned mode collapse in the generator network, especially for rare label combinations. Using Anti-Labeler helps with faster convergence and is crucial for theoretical guarantees. See Section 9.4 in the Appendix for results. The Anti-Labeler helps prevent label-conditioned mode collapse in the generator network, particularly for rare label combinations, leading to faster convergence. Results for a single binary label are presented, with potential extension to more labels. The analysis assumes a perfect Causal Controller and involves mappings by the generator, discriminator, Labeler, and Anti-Labeler. The perfect Causal Controller 9, shorthand DISPLAYFORM0, and D LG (.) are mappings by the generator, discriminator, Labeler, and Anti-Labeler. The generator loss function in CausalGAN includes label loss terms, GAN loss in Goodfellow et al. FORMULA8, and an additional loss term from the discriminator. This added term in the generator loss proves that the optimal generator outputs the class conditional image distribution. The results hold true for multiple binary labels as well. The Anti-Labeler and Labeler each solve specific optimization problems for a fixed generator. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. The discriminator and labeler networks operate at their optimum for a single binary label. The optimal discriminator, labeler, and anti-labeler networks operate at their best for a single binary label in the conditional generative adversarial network architecture. This result can be extended to multiple binary variables as well. The optimal discriminator, labeler, and anti-labeler networks operate at their best for a single binary label in the conditional generative adversarial network architecture. This is characterized by Proposition 2, Lemma 1, and Lemma 2 in Goodfellow et al. (2014). The generator minimizes the loss function C(G) by sampling from class conditional distributions, achieving the global minimum when the generator output matches the class conditional image distribution. This two-stage procedure can be used for training. The two-stage procedure involves training a causal implicit generative model for any causal graph where the Image variable is a sink node. The generator output matches the class conditional image distribution when given a label, allowing for sampling from the image distribution conditioned on the label. The generator can sample from the image distribution based on labels. The optimum generator samples from class conditional distributions with a single binary label, and the goal is to extend this to multiple binary labels. The Labeler and Anti-Labeler output probabilities of label combinations, and the minimizer of C(G) samples from class conditional distributions with d labels. The authors propose an alternative architecture for handling a large number of labels in image classification tasks. They extend the single binary label setup by using cross entropy loss terms for each label, requiring the Labeler and Anti-Labeler to have only d outputs. This approach ensures that the generator captures the joint label posterior given the image. The generator captures the joint label posterior given the image, ensuring that the class conditional distributions will be true to the data distribution. This guarantee implies that the optimum generator samples from the class conditional distributions. See Section 8.7 for formal results and details. In Section 8.7, the trained causal implicit generative models can also sample from counterfactual distributions by conditioning on an event and sampling from the push-forward of the posterior distributions of exogenous noise terms under the interventional causal graph. This can be achieved through rejection sampling and interventional sampling. In this section, a simple extension of BEGAN involves feeding image labels to the generator using a Labeler network. The Causal Controller is used for interventional sampling, with the network labeling real images well and generated images poorly. This modification is analogous to the original BEGAN discriminator and the CausalGAN Labeler and Anti-Labeler. In this section, CausalGAN and CausalBEGAN are trained on CelebA dataset. The network is analogous to the original BEGAN discriminator and CausalGAN Labeler and Anti-Labeler. Margin modifications are motivated by observations on image and label quality gradients. The training of CausalGAN and CausalBEGAN on the CelebA Causal Graph involves a margin term and comparing margins. The dataset used satisfies certain conditions, such as the relationship between Male and Mustache in the CelebA Causal Graph. The top row of the results shows both males and females with mustaches, even though the label combination {Male = 0, Mustache = 1} was not seen during training. The top row of images in the results shows males and females with mustaches, even though the generator never saw the label combination {Male = 0, Mustache = 1} during training. The bottom row displays only male images sampled from the conditional distribution P(.|Mustache = 1). The CelebA Causal Graph indicates that Mustache does not affect the probability of Male = 1. The generative model can create samples conditioned on labels and sample from interventional distributions. The theoretical analysis provides guarantees for correct sampling under interventions. Intervening/Conditioning on Narrow Eyes label in CelebA Causal Graph with CausalBEGAN is discussed. In CelebA Causal Graph with CausalBEGAN, intervening on Narrow Eyes label increases the proportion of smiling images, although the difference may not be statistically significant. The generator in the dark image appears to rule out Narrow Eyes = 0 instead of showing Narrow Eyes = 1. The generator in the dark image rules out Narrow Eyes = 0 instead of demonstrating Narrow Eyes = 1. Causality leads to more creative generative models like CausalGAN and CausalBEGAN. The research has been supported by various grants and organizations. A structural causal model (M = (V, E, F, P E (.))) consists of functions, random variables, exogenous variables, and a probability distribution. The causal graph D is a directed acyclic graph on the nodes V, where a node X j is a parent of node X i based on specific conditions. The causal graph D is a Bayesian network for the joint probability distribution over observable variables V, with interventional distributions being directly calculable under the causal sufficiency assumption. The causal Bayesian networks D1 and D2 have the same interventional distributions, calculated from conditional probabilities and the causal graph. The joint data distribution is denoted as Pr(l, x) and the joint distribution for the generator is denoted as Pg(l, x). Proposition 2 from Goodfellow et al. (2014) is restated for the discriminator. The optimal discriminator D is given by a specific formula when G is fixed. The optimum Labeler is defined by D LR (x) = P r (l = 1|x), and a similar lemma exists for the Anti-Labeler. The optimum discriminator D is determined by a specific formula when G is fixed. The optimal Labeler is defined as D LR (x) = P r (l = 1|x), with a corresponding lemma for the Anti-Labeler. The model assumes causal sufficiency and a product distribution over exogenous variables. Edges are added to form the complete graph \"cG1\" and the graph rcG1 is utilized. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. The virtual training criterion C(G) is optimized when the generator output matches the class conditional image distribution, ensuring joint distribution equality between labels and images in a causal implicit generative model. The virtual training criterion C(G) is optimized when the generator output matches the class conditional image distribution, ensuring joint distribution equality between labels and images in a causal implicit generative model. This is due to the fact that P r (l = 1) = P g (l = 1) = \u03c1. Suppose C : Z 1 \u2192 L is a causal implicit generative model for the causal graph D = (V, E) where V is the set of image labels and the observational joint distribution over these labels are strictly positive. Let G : L \u00d7 Z 2 \u2192 I be a generator that can sample from the image distribution conditioned on the given label combination L \u2208 L. The concatenated generator neural network in a conditional GAN is consistent with the causal graph D, assuming perfect sampling from true label and image distributions. This allows the model to sample from true observational and interventional distributions, making it a causal model. The concatenated model in a conditional GAN is a causal implicit generative model for graph D, allowing sampling from true observational and interventional distributions. Modifications are explained for extending the proof to cases with multiple binary labels, addressing the challenge of learning the correct joint distribution. The text discusses solutions to the problem of characterizing P r (l|x) in a conditional GAN. Two solutions are proposed: 1) Estimating the probability of each label combination instead of each label, and 2) Using labelers to estimate the probabilities of each label, ensuring P g (l 1 , l 2 , . . . , l d , x) = P r (l 1 , l 2 , . . . , l d , x) at the minimizer of C(G). The extension in (1) ensures P g (l 1 , l 2 , . . . , l d , x) = P r (l 1 , l 2 , . . . , l d , x) at the minimizer of C(G). The optimum Labeler with respect to the loss in (12) has D * LR (x)[j] = P r (l = j|x). If P r (l = j|x) = 0 for a set of (label, image) combinations, they do not contribute to the expectation. The Labeler loss can be written as DISPLAYFORM3 where L x is the discrete random variable such that P(L x = j) = P r (l = j|x). H(L x ) is the Shannon entropy of L x, and it only depends on the data. The loss is lower bounded by \u2212H(L x). The optimum Labeler network gives the posterior probability of a label combination based on the observed image. The constraint that coordinates sum to 1 can be satisfied using a softmax function. The Anti-Labeler network's loss function and lemma are discussed, with the optimization problem defined as DISPLAYFORM5. The optimum Anti-Labeler is shown to have D *LG (x)[j] = P g (l = j|x) according to Lemma 4, as it cannot control the joint distribution between the generated image and labels. The generator optimizes the joint distribution between the generated image and labels, unable to optimize the conditional entropy of labels given the image. Theorem 2 shows that the optimal generator samples from class conditional image distributions given specific label combinations. The global minimum of the virtual training criterion C(G) is achieved when the generator samples from the true joint label distribution, ensuring P g (l, x) = P r (l, x) for the vector of labels. This is proven by optimizing the Labeler, Anti-Labeler, and discriminator, leading to the minimization of the Kullback-Leibler divergence. Theoretical guarantees for the implemented CausalGAN architecture with d labels are provided under the assumption of deterministic relationship between images and labels in the dataset. The implemented CausalGAN architecture with d labels assumes a deterministic relationship between images and labels in the dataset. This assumption guarantees that the global optimal generator samples from class conditional distributions. The Anti-Labeler optimizes for P_g(x|l_j=0) while the Labeler optimizes for P_r(x|l_j=0) given a fixed discriminator. The Anti-Labeler and Labeler optimize for different conditional distributions, with the generator aiming for the global minimum of the virtual training criterion. The generator aims for the global minimum of the virtual training criterion by ensuring the generated distribution samples from the class conditional image distributions. To guarantee correct conditional sampling, the assumption is made that the image x determines all the labels. The assumption is that the image x determines all the labels, which is relevant in practice. In the CelebA dataset, the label vector can be seen as a deterministic function of the image. The lemma states that any discrete joint probability distribution with kronecker delta functions as marginal probabilities is the product of these functions. Lemma 5 states that a discrete joint probability distribution with kronecker delta functions as marginal probabilities is the product of these functions. The joint probability distribution is zero everywhere except at specific points. The joint probability distribution is zero everywhere except at specific points, as stated in Lemma 5. By applying this lemma to the conditional distribution, it is shown that the image distributions and marginals are true to the data distribution. Proposition 3 demonstrates that image distributions and marginals are accurate to the data distribution through Bayes' rule. The joint distribution satisfies the condition that every marginal distribution is a kronecker delta function, leading to a product distribution. This implies equality between P r (x|l 1 , l 2 , . . . , l n ) and P g (x|l 1 , l 2 , . . . , l n ). In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from the class conditional image distributions, as demonstrated by the chain of equalities. BEGAN's boundary equilibrium approach, inspired by control theory, plays a central role in encouraging generator training only when the discriminator is near optimum. In this extension of BEGAN, image labels are fed to the generator to optimize training. A new loss and margins are introduced to reflect the idea that label gradients are most informative when image quality is high. The generator G(z, lg) produces image samples based on labels, extending the BEGAN loss formulation. However, this approach lacks consideration for margins crucial in the BEGAN framework. A well-trained Labeler is essential for meaningful gradients in image generation. The Labeler network is crucial in the BEGAN formulation, requiring a well-trained Labeler for meaningful gradients in image generation. An additional margin-coefficient tuple is introduced to improve the generator's performance. However, there may be a trade-off between image quality and exploiting the Labeler network, as images that best utilize the Labeler network may not always be realistic. The Labeler network in BEGAN is important for meaningful gradients in image generation. A new margin term is introduced to improve the generator's performance, emphasizing the need for good image quality. The margin equations and update rules are adjusted accordingly, with learning rates for the coefficients. BEGAN's advantage of a monotonically decreasing scalar to track gradient descent optimization is preserved in this extension. In this extension, the monotonically decreasing scalar property of the gradient descent optimization in BEGAN is preserved. The study explores the convergence of causal implicit generative models when the true data distribution comes from a different causal graph. The models are tested on synthetic data with three features {X, Y, Z} originating from various causal graphs. The study explores the convergence of causal implicit generative models on synthetic data with three features {X, Y, Z} originating from different causal graphs: \"line\" X \u2192 Y \u2192 Z, \"collider\" X \u2192 Y \u2190 Z, and \"complete\" X \u2192 Y \u2192 Z, X \u2192 Z. Cubic polynomials are used to compute node values, and the results of 20 runs for each model are averaged. The convergence of the joint distribution to the true joint is compared in terms of total variation distance for each data generating graph. The study compares the convergence of causal implicit generative models on synthetic data from different causal graphs: line, collider, and complete. Results are shown in FIG9 for generators structured as line X \u2192 Y \u2192 Z, collider X \u2192 Y \u2190 Z, and complete X \u2192 Y \u2192 Z, X \u2192 Z. Each curve illustrates the convergence behavior of the generator. The study compares the convergence of causal implicit generative models on synthetic data from different causal graphs: line, collider, and complete. Results are shown in FIG9 for generators structured as line X \u2192 Y \u2192 Z, collider X \u2192 Y \u2190 Z, and complete X \u2192 Y \u2192 Z, X \u2192 Z. Each curve shows the convergence behavior of the generator distribution based on the causal graph used. The correct Bayesian network should be able to fit to the true joint distribution, with the complete graph being able to encode all joint distributions. The study explores the convergence behavior of causal generative models on synthetic data from different causal graphs. The complete graph can encode all joint distributions, and the best convergence is seen when using a line graph in the generator architecture. The performance of fully connected networks with 3 layers is also surprisingly good. In the study, different causal graphs are used to test the convergence behavior of causal generative models. The complete graph converges well, while fully connected networks with 3 layers perform well. However, fully connected networks with 5 and 10 layers perform much worse. The number of layers in the generator architecture needs to be tuned for optimal performance. Using the wrong Bayesian network, the collider, results in worse performance. Surprisingly, fully connected generators with 3 and 5 layers show the best performance for the collider graph. For the collider graph, using a fully connected generator with 3 and 5 layers performs the best, while 10 layers show the worst convergence behavior. Complete and collider graphs achieve decent performance, while line graph and wrong Bayesian network perform worse. In the complete graph, fully connected 3 layers perform the best, followed by 5 and 10 layers. Line and collider graphs show the worst performance and no convergence behavior. The curr_chunk discusses the evaluation of using the wrong causal graph on an artificially generated dataset, showing scatter plots for different distributions. It highlights the impact of generator causal graphs on the generated distributions. The curr_chunk discusses the impact of using the wrong causal graph on an artificially generated dataset, showing scatter plots for different distributions. It emphasizes the importance of using the correct graph for generating accurate results. The CelebA dataset experiments involve a causal graph (G1) on image labels, with a completed version (cG1) showing relationships like Male causing Smiling. Reversing edges forms rcG1, highlighting the impact of using the incorrect Bayesian network on data generation. The CelebA dataset experiments involve a causal graph (G1) on image labels, with a completed version (cG1) showing relationships like Male causing Smiling. Reversing every edge in cG1, we check the effect of using the incorrect Bayesian network for the data. Comparison of pairwise distributions in TAB0 demonstrate that for G1 a reasonable approximation to the true distribution is still learned for {Male, Young} jointly. For cG1 a nearly perfect distributional approximation is learned. Despite this inaccuracy, both graphs G1 and cG1 lead to Causal Controllers that never output the label combination {Female, Mustache}. The Wasserstein GAN in its original form assures convergence in distribution of the Causal Controller. The modified Wasserstein GAN ensures convergence in distribution of the Causal Controller output to discretely supported label distributions. The learned outputs demonstrate good convergence, as shown in FIG12, but Total Variation Distance (TVD) may not always be intuitive. The CelebA Causal Graph and its completion allow training of reasonable marginal distributions for all labels, with deviations of no more than 0.03 for the worst label. The Wasserstein Causal Controller is tested on a subset of binary labels from the CelebA dataset using a causal graph. The generator is trained to map continuous noise to a discrete distribution, as shown in FIG12. The proposed Causal Controller outputs are emphasized in the results. The proposed Causal Controller outputs an almost discrete distribution, with 96% of samples appearing near 0 or 1 on the real line. Total variational distance (TVD) is used as a measure of convergence, showing that cG1 and rcG1 have TVD decreasing to 0, while G1 asymptotes to around 0.14, indicating incorrect conditional independence assumptions. In this section, additional CausalGAN results are presented, showing the impact of intervening vs conditioning on wearing lipstick in the CelebA causal graph. The TVD decreases to 0 for cG1 and rcG1, while G1 asymptotes to around 0.14, indicating incorrect conditional independence assumptions. This suggests that Bayesian partially incorrect causal graphs can still give reasonable convergence. Intervening vs Conditioning on Wearing Lipstick in CelebA Causal Graph: The top row shows both males and females wearing lipstick, while the bottom row only shows females due to the dataset distribution. In CelebA Causal Graph, intervening on Narrow Eyes does not affect Smiling, but conditioning on Narrow Eyes increases the proportion of smiling images. CausalBEGAN is trained on CelebA dataset using CelebA Causal Graph. Training CausalBEGAN on CelebA dataset using CelebA Causal Graph, the Causal Controller is pretrained with a Wasserstein loss. Empirically justifying the margin of margins, setting c3=1 deteriorates image quality for rare labels. Illustrating the difference between interventional and conditional sampling for labels Bald and Mouth Slightly Open. Intervening vs Conditioning on Bald label in CelebA Causal Graph. When Bald=1, intervening does not affect Male probability. Top row shows bald males and females, bottom row only males due to dataset distribution. Smiling influences Mouth Slightly Open in CelebA Causal Graph. The conditional distribution P(.|Bald = 1) shows only male images due to dataset distribution. Conditioning on Mouth Slightly Open = 1 increases the proportion of smiling images in the dataset. Additional simulations for CausalGAN are provided in this section. In this section, additional simulations for CausalGAN are presented. Figures 16a-16d demonstrate the conditional image generation properties by sweeping a single label from 0 to 1. Figure 17 shows 256 randomly sampled images to examine mode collapse and image diversity. Simulation results for CausalBEGAN are also provided, highlighting the importance of the third margin term b3 on image quality for rare labels. The study highlights the significance of the third margin term on image quality for rare labels. CausalBEGAN introduces a scalar \"M\" that decreases monotonically during training, with an extension M complete that maintains this property. Conditional image generation properties are demonstrated through label sweeps in CausalBEGAN, showcasing the generator's unique characteristics. The CausalBEGAN architecture learns a discrete function for generators with label input parameters. A random sampling of 256 images is shown to demonstrate image diversity. The approach involves jointly training an implicit causal generative model for labels and images, treating the image as part of the causal graph. In this section, the approach involves training an implicit causal generative model for labels and images, treating the image as part of the causal graph. One way to feed both labels and image to the discriminator is by encoding the label as a constant image in an additional channel. However, in the CelebA Causal Graph experiment, it was observed that the image generation was not learned effectively. The discrepancy between implementation and theory, along with other implementation details for CausalGAN and CausalBEGAN, are explained in this section. The implementation details of the Wasserstein Causal Controller for generating face labels are explained in this section. The total variation distance (TVD) is used as a metric to evaluate the success of the models. The gradient term as a penalty is estimated by evaluating the gradient at points interpolated between real and fake batches. The Wasserstein approach allows training the Causal Controller to output discrete labels. The Wasserstein approach in training the Causal Controller for generating face labels involves using discrete labels and rounding them before passing to the generator. The generator architecture is based on a causal graph, using uniform noise as exogenous variables and neural networks. Training includes 25 Wasserstein discriminator updates per generator update with a learning rate of 0.0008 using stochastic gradient descent. The DCGAN Radford et al. (2015) is utilized for the convolutional neural net-based model. In training the Causal Controller for generating face labels, the model uses DCGAN Radford et al. (2015) with 25 Wasserstein discriminator updates per generator update and a learning rate of 0.0008. The model extends DCGAN by incorporating Labeler networks and a Causal Controller network, making 6 generator updates for each discriminator update on average. The discriminator and labeler networks are updated concurrently in a single iteration. Loss terms in the model contain a single binary label. The model extends DCGAN by incorporating Labeler networks and a Causal Controller network. The loss terms are updated concurrently for every label in a d-dimensional vector, unlike the architecture in Section 8.6. This approach does not guarantee sampling from the class. The discriminator outputs a length-2 d vector to estimate label probabilities for image combinations. This architecture is suitable for labeled image datasets where labels are determined by the image. Swapping the order of terms in the cross entropy expressions for labeler losses has improved image sharpness. For more details, refer to Section 8.7 in the supplementary material. In the implementation, the order of terms in cross entropy expressions for labeler losses was swapped, resulting in sharper images. CausalBEGAN uses labels from the Causal Controller with minimal parameter tuning. The learning rate is 0.00008 for both generator and discriminator, with simultaneous updates. Parameter values like \u03b3 are set to 0.5, and customized margin learning rates \u03bb are specified. Good performance is achieved without extensive hyperparameter tweaking. In the context of achieving good performance without hyperparameter tweaking, customized margin learning rates \u03bb are used to reflect asymmetry in generator response. The best models have all three margins \"active\" near 0 while occasionally taking small positive values. Results comparing CausalGAN with and without Anti-Labeler network are presented. Using Anti-Labeler network in CausalGAN leads to faster convergence and more diverse images for very rare labels. See FIG3, 25."
}