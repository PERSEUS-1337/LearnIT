{
    "title": "SJlgOjAqYQ",
    "content": "We conducted experiments on convolutional and capsules neural networks to test global translation-invariance in deep learning models trained on the MNIST dataset. Both models initially showed poor performance in this aspect, but performance improved with data augmentation. While the capsule network performed better on the MNIST testing dataset, the convolutional neural network generally had better performance on translation-invariance. The success of convolutional neural networks is attributed to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. The capsule network is robust in dealing with different viewpoints by using capsules to represent pose, color, lighting, and deformation of visual entities. It aims for 'rate-coded' equivariance, where weights code viewpoint-invariant knowledge. Viewpoint changes in capsule networks have linear effects on pose matrices between different layers. Changes in capsule network have linear effects on pose matrices between different layers, but it is unclear if they can generalize for global translation invariance. Visualizing and quantifying translation-invariance in deep learning models is crucial for understanding architectural choices and developing generalization models. A method is introduced to test global translation-invariance in convolutional and capsule neural networks trained on the MNIST dataset using a simple testing dataset. Global translational invariance (GTI) of a deep learning model can be assessed by shifting the center of mass in images. The GTI testing dataset consists of images generated by shifting the center of mass of a Helvetica font digit one pixel at a time. There are 2520 testing images covering all possible translational translations. Deep learning models are trained on the MNIST dataset and tested on both MNIST and GTI datasets. MNIST images are mostly centered on the canvas, while GTI images are uniformly distributed. The GTI dataset is used for testing models trained on the MNIST dataset. It consists of images with translational translations. The CNN model has nine layers with different numbers of channels and filters. The GTI dataset helps quantify global invariance in model predictions. The CNN model has nine layers with different numbers of channels and filters. It includes convolutional and max-pooling layers, fully connected layers, and dropout. The model uses ReLU activation function, Adam optimizer, and cross entropy loss. Trained on MNIST data, it achieves high accuracy on the testing set but lower accuracy on the GTI testing dataset. The CNN model trained on MNIST data achieves high accuracy on the testing set but only 42.16% accuracy on the GTI testing dataset, indicating poor performance in dealing with global translational invariance. Images with the digit's center predicted correctly, while those at the corner were assigned to incorrect classes. The model's inability to accurately predict shifted images suggests it is 'place-code' equivariant. CNN is 'place-code' equivariant. To improve performance on the GTI dataset, data augmentation is used by shifting images from the center in x and y-direction. This increases accuracy to 98.05%. Data augmentation implies 'place-code' equivariance in CNN. CapsNet is tested on GTI dataset with the same architecture as CNN but with 8.2M parameters. The CapsNet model in BID9 has 8.2M parameters, much larger than CNN, and was trained with Adam optimizer. It shows robustness in viewpoint invariance but struggles with global invariance. Data augmentation in MNIST training improves CapsNet accuracy on the GTI dataset. The CapsNet model in BID9 has 8.2M parameters, trained with Adam optimizer, shows robustness in viewpoint invariance but struggles with global invariance. Data augmentation in MNIST training improves CapsNet accuracy on the GTI dataset. CNN outperforms CapsNet on GTI dataset, even with wider receptive fields in CapsNet's convolutional layers. CapsNet's lower performance on GTI dataset may be due to the absence of max-pooling layers and 'place-coded' equivalent convolutional layers. There is potential for CapsNet to improve in handling translational invariance. A GTI testing dataset is introduced for deep learning models trained on MNIST to better understand CNN and CapsNet abilities. The GTI testing dataset was introduced to assess the ability of CNN and CapsNet in handling global translational invariance. CapsNet architecture shows potential in this aspect despite current limitations without data augmentation. The testing method involves applying random shifting to MNIST training dataset images. This method is easily implementable for other computer vision tasks."
}