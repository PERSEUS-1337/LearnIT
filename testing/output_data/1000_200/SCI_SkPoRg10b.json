{
    "title": "SkPoRg10b",
    "content": "The approach described involves understanding the generalization properties of deep neural networks by revisiting old ideas in statistical mechanics. A Very Simple Deep Learning (VSDL) model is introduced, controlled by parameters related to data load and effective temperature. This model helps explain the inability of deep neural networks to avoid overfitting training data. The mechanics theory of generalization provides a qualitative description of deep neural networks' inability to avoid overfitting training data and their discontinuous learning properties. Neural networks, including deep neural networks used in deep learning, exhibit complex properties leading to varied conclusions about their behavior regarding noise sensitivity. Some papers discuss the sensitivity of neural networks to noise, while others question the applicability of popular theories like PAC and VC theory. The optimization problems associated with neural networks are noted to be extremely non-convex, leading to issues like local minima. There are differing views on whether convergence to flat or sharp minimizers is more beneficial. These tensions in the neural network field have been recognized for a long time. Recent studies have highlighted the tendency of state-of-the-art neural networks to overtrain when exposed to noisy data. Despite efforts to implement regularization techniques, these networks still struggle to prevent overfitting. This raises concerns about the generalization capabilities of deep learning systems in the presence of realistic noisy data. Regularization methods, such as adding capacity control functions or performing dropout, do not effectively prevent overtraining in neural networks. The only parameter that significantly helps is early stopping. This contrasts with SVMs, where overtraining does not occur even when labels are randomized. The SVM generalization accuracy is bounded above by 90% on test data sets. Randomizing 10% of labels may lead to overtraining with a spurious 90% training accuracy. DNNs behave differently from SVMs in terms of generalization. Understanding DNN-based learning requires rethinking generalization. The statistical mechanics theory of generalization applied to neural networks and deep neural networks provides a qualitative explanation of empirical properties not easily understood by traditional generalization theories like PAC/VC. The approach can be formulated rigorously or non-rigorously, with the latter being more common but still offering precise quantitative insights. The statistical mechanics approach to generalization in neural networks, particularly deep neural networks, offers a more precise quantitative agreement with empirical results compared to traditional theories like PAC/VC. It can explain complex learning behaviors such as phases, phase transitions, and discontinuous learning, based on control parameters like load and temperature. This approach complements but goes beyond the PAC/VC framework, providing a more detailed understanding of generalization in machine learning. The SM approach to generalization in neural networks offers a more precise quantitative agreement with empirical results compared to traditional theories like PAC/VC. It explains complex learning behaviors based on control parameters like load and temperature, providing a more detailed understanding of generalization in machine learning. The VSDL model of classification in DNN learning models involves error plots, phase diagrams, and adjusting algorithm knobs. Zhang et al. propose that control parameters in learning processes are analogous to parameters in the traditional SM approach. The Hopfield model of associative memory and the existence of multiple control parameters are discussed in relation to generalization properties in machine learning. A one-dimensional phase diagram illustrates the behavior of generalization error with increasing load parameter \u03b1, showing a critical value where properties change dramatically. The text discusses the generalization properties in machine learning with the Hopfield model and multiple control parameters. A two-dimensional phase diagram shows sharp transitions in generalization properties based on \u03b1 and \u03c4 parameters. Adding noise and adjusting parameters can affect generalization behavior, as illustrated in FIG1. The text discusses how adjusting parameters in the VSDL model can improve generalization. Adding noise can lead to poor generalization, but this can be offset by modifying the \u03c4 parameter. The SM approach to generalization can be complex, but the focus of the paper is on qualitative results. The text emphasizes the importance of understanding technical complexities in DNN systems. It warns against making broad claims and highlights the intricate interactions of control parameters in realistic DNNs. The focus is on qualitative results and the need for careful interpretation. The text delves into the details of model properties, learning algorithms, data noise, and their impact on generalization in machine learning. It discusses connecting DNN control parameters with load-like and temperature-like parameters for non-trivial generalization behavior. The upcoming sections will provide more in-depth explanations and discussions on these findings. In Section 4, a historical perspective on the SM approach to NNs is provided, dating back to the early days of the field. The SM approach and PAC/VC theory were prominent in the 80s/90s for controlling generalization properties of NNs before the rise of Support Vector Machines (SVMs) and related methods. The ML community shifted from the SM approach to NNs to methods like SVMs and PAC/VC-based analysis for generalization. Recent theoretical work in ML has focused on PAC/VC approach, ignoring the SM approach. This paper discusses how the SM approach can qualitatively describe observed phenomena, leaving quantitative analysis for future research. The SM approach to learning highlights qualitative properties in NN systems, explaining complex generalization patterns beyond gradual improvement with more data predicted by PAC/VC theory. The text explains the complexity of generalization performance in deep learning systems, highlighting the sensitivity to control parameters, model details, algorithms, regularization properties, data properties, and noise. Researchers have observed these counterintuitive properties in modern deep learning systems. The text discusses the limitations of separating algorithmic optimization questions from statistical inference questions in deep learning systems. It mentions the complexity involved in making strong distribution assumptions and the technical challenges in applying this separation. The PAC/VC theory provides upper bounds on generalization accuracy, but smooth upper bounds do not guarantee accuracy. The SM approach to generalization in deep learning involves different phases and phase transitions, leading to non-trivial phase diagrams. These phases represent regions in parameter space where system properties change smoothly, while phase transitions indicate points of discontinuity in these properties. In the context of deep learning, phase transitions represent points of discontinuity in system properties, leading to non-trivial phase diagrams in parameter space. For example, in the Hopfield model of associative memory, different phases can be observed based on load and temperature parameters. The text discusses how the properties of neural networks can change dramatically based on control parameters, leading to different retrieval properties. It also mentions the generalization properties of NNs and presents an idealized model of deep learning computations. This model helps explain aspects of the performance of large modern DNNs. The text discusses a simple model for deep learning computations, explaining aspects of large modern DNN performance. The model captures practical control parameters and has non-trivial phases of learning in the thermodynamic limit. The text discusses a Very Simple Deep Learning (VSDL) model for DNN training, where the function f maps input images to output labels based on parameters \u03b1 and \u03c4. These parameters can be controlled during training, similar to the behavior of water. The VSDL model allows for easy control of parameters \u03b1 and \u03c4 during DNN training. Examples like water's state change based on temperature and pressure, or the Erd\u0151s-R\u00e9nyi random graph model, illustrate the importance of control parameters in determining macroscopic properties. In statistical learning, avoiding sensitivity on parameters is crucial, focusing on values of \"microscopic\" variables. In statistical learning, avoiding sensitivity on parameters is crucial. Adding noise to training data decreases an effective load \u03b1, impacting macroscopic properties of DNN learning systems. This noise can be introduced by randomizing labels or data values, leading to a decrease in the effective load-like control parameter. Adding noise to training data decreases the effective load-like control parameter \u03b1, impacting macroscopic properties of DNN learning systems. This is defined as \u03b1 = m ef f /N, where m ef f is the effective number of data points after randomizing labels and N is the model capacity trained on the data. Adding noise to training data decreases the effective load-like control parameter \u03b1, impacting macroscopic properties of DNN learning systems. The model capacity N obtained by training remains similar or unchanged when noise is added, reducing the load on the network. Realistic DNNs have a model capacity that scales with the number of data points, not the effective number of data points. Training a new DNN model on a set of data points with noisy labels results in a model capacity that is approximately the same as the original model. Adding noise to training data decreases the effective load-like control parameter \u03b1 in DNN learning systems. The model capacity N remains similar when noise is added, reducing the load on the network. Training a new DNN model on data points with noisy labels results in a model capacity that is approximately the same as the original model. Overtraining can occur due to the model having more capacity than needed for the labels, leading to early stopping increasing an effective temperature \u03c4. The iteration complexity in stochastic iterative training acts as a temperature-like control parameter, with early stopping increasing this parameter. The temperature-like control parameter in DNN training corresponds to the learning rate of the stochastic dynamics and is denoted by \u03c4. It depends on the number of steps taken by the stochastic iterative algorithm when terminated. This parameter is influenced by the annealing rate schedule of the SGD algorithm, decreasing the variability of the neural network weights. The VSDL model uses parameters \u03c4 and \u03b1 to control the learning process, such as adding noise or early-stopping. Other factors are ignored for simplicity, but these parameters are key in adjusting the learning process. The VSDL model uses parameters \u03c4 and \u03b1 to control the learning process by adjusting model complexity with the number of parameters. It considers a thermodynamic limit where hypothesis space and data points diverge, contrasting with PAC/VC approach to generalization. Technical complexities are involved in this analysis. The VSDL model uses parameters \u03c4 and \u03b1 to control learning in a thermodynamic limit where hypothesis space and data points diverge. Technical complexities are associated with the SM approach to generalization, with subtleties in the limit. General considerations from the SM theory imply phase diagrams for the VSDL model, showing error plots as a function of \u03b1. The VSDL model utilizes parameters \u03c4 and \u03b1 to control learning in a thermodynamic limit. Phase diagrams for the model show error plots as a function of \u03b1, with a two-dimensional phase diagram illustrating the relationship between generalization and training errors. The VSDL model uses parameters \u03c4 and \u03b1 to control learning in a thermodynamic limit. The generalization error decreases dramatically as \u03b1 decreases from a large value, passing through a critical value \u03b1 c. This transition results in a sharp increase in generalization error, where fitting the training data well leads to poor performance on test data. The phase diagrams illustrate these observations for different values of \u03c4, with the possibility of a single phase of learning for \u03c4 > \u03c4 c. For \u03c4 greater than a critical value, the sharp transition in learning as a function of \u03b1 may disappear, resulting in only one phase of learning. Adding noise to data and adjusting algorithm parameters can be visually represented in the (\u03b1, \u03c4) plane. If data labels are randomly changed, the system moves to a new point where the DNN can still be trained to fit the noisy data. At point B, the DNN can still be trained to fit new noisy data, but if enough data have their labels changed, the generalization properties on new noisy data become much worse. Adjusting the temperature parameter \u03c4 can compensate for this, leading to better generalization properties at point C. Conclusion 1 states that neural networks can easily overtrain due to a lack of global control parameters for generalization. Conclusion 2 discusses how popular regularization methods may or may not help in preventing overfitting in realistic NNs and DNNs. Observation 1 states that the number of iterations is a key control parameter for preventing overfitting in realistic neural networks. This is supported by the idea that decreasing the number of iterations can help prevent overfitting in DNNs. Revisiting old ideas in the SM of NNs offers a powerful way to rethink generalization properties and understand modern DNNs. While different from the PAC/VC approach, this method can be complex but valuable. The simplest model reproducing non-trivial properties is considered for rethinking generalization. The VSDL model simplifies complex DNNs with two control parameters to explain generalization properties. It provides a qualitative description of overfitting, discontinuous learning, and sharp transitions in learning algorithms. Recent similar work has been noted. Recent work with a similar flavor involves a refined scale-sensitive analysis and connections with margin-based boosting methods. Information Bottleneck ideas are used to analyze information compression in stochastic optimization algorithms. These lines of work complement the VSDL model's approach to generalization properties. Revisiting old ideas can be fruitful, as recent empirical evidence suggests. Recent empirical evidence suggests that every DNN has a generalization phase diagram based on its control parameters, with a phase where generalization changes gradually and a \"low temperature\" phase where learning breaks down. Evaluating this conjecture is challenging due to the conflation of optimization and regularization issues in existing methods. The VSDL model and SM approach provide explanations for various empirical phenomena, such as discontinuities in generalization performance, sensitivity to model and algorithm details, implicit regularization effects, data properties, and decay in generalization in the asymptotic regime. In this section, simple models are discussed to explain the generalization behavior of the VSDL model, which exhibits discontinuous properties in the asymptotic regime. These models help understand the implications of general considerations from the SM theory on large DNNs. In this section, an overview is provided on the PAC/VC versus SM approach to generalization, explaining the root of discontinuous generalization properties in simpler models. Evidence in larger DNNs is described, along with a review of popular regularization mechanisms and their limitations in certain situations. The discussion also touches on the \"general considerations from the SM theory of generalization\" and simple network architectures like the fully-connected committee machine and tree-based models. The text discusses simple network architectures like the fully-connected committee machine, tree-based parity machine, and one-layer reversed-wedge Ising perceptron, highlighting their representational capabilities in comparison to modern DNNs. The fully-connected committee machine is a multi-layer network with one hidden layer containing K elements, specified by K vectors connecting the N inputs to the hidden units. The output is determined by the majority vote of the hidden layer, showing discontinuous behavior in the generalization error as a function of control parameters. The curr_chunk discusses different models in neural networks, including the tree-based parity machine and the one-layer reversed-wedge Ising perceptron. These models have specific structures and behaviors in terms of generalization error and control parameters. The one-layer reversed-wedge Ising perceptron is a single layer network with a non-trivial activation function. It uses a parameter \u03bb to determine classification as +1 or -1 based on \u03b3. The generalization error \u03b5 is shown in FIG3 as a function of control parameter \u03b1, demonstrating discontinuous behavior. The discontinuous behavior of \u03b5 as a function of \u03b1 is illustrated in Figs. 2(a), 2(b), and 2(c). There is an abrupt change in the learning curve based on a load-like parameter. Different parameters like the number K of intermediate groups or the value of \u03b3 can affect this behavior. Two simpler models will be discussed in Section A.3 to explain this mechanism, following a review of two approaches to understanding generalization in ML in Section A.2. In Section A.2, two approaches to understanding generalization in machine learning are reviewed. The classification of elements into two classes is considered, with a target rule T and a hypothesis space F. The goal is to select an element from F that approximates T well on the input space X. The generalization error \u03b5 is the probability of disagreement between the student/hypothesis and teacher/target on a randomly chosen subset of X. The student iterates a process to obtain a mapping f * by constructing new mappings based on the teacher's label and previous mappings. If T \u2208 F, the problem is realizable; otherwise, it is unrealizable. In the realizable case of the iterative learning algorithm, the version space is the subset of X compatible with the data seen so far. The training error \u03b5 t quantifies the performance of the student on the training set, while the generalization error characterizes the difference between training error and generalization error. The learning curve characterizes the difference between training error and generalization error. The PAC/VC approach views training set size as a control parameter to understand how the error varies as the set size increases. This framework uses accuracy parameters \u03b4 and \u03b3 to decide which hypothesis will perform well on the complete input. The problem of deciding which hypothesis will perform well on the complete input is related to the convergence of frequencies to probabilities. A uniform bound over the hypothesis space can be constructed by focusing on the worst-case situation, especially when the cardinality of the set F is finite. In the context of hypothesis performance, the worst-case scenario is analyzed by considering the cardinality of set F. The PAC/VC approach uses the growth function and VC dimension to minimize empirical error, leading to a bounded generalization error. The VC dimension is the only problem-specific quantity in these bounds, measuring complexity. The VC dimension measures the complexity of the function class F, with bounds that are universal and hold for any input distribution and target distribution. The thermodynamic limit allows for the divergence of training set size and function class in a well-defined manner. The thermodynamic limit in information theory and error correcting codes allows for easy computation of quantities related to generalization error. The SM approach to generalization describes the learning curve of a parametric class of functions, distinct from associative memory models. The SM approach describes the learning curve of a parametric class of functions for classification tasks. It involves choosing target functions from a sequence of classes, leading to a sequence of target functions. If a limit exists, the number of functions in the class at a given error value may have an asymptotic behavior. In the context of the SM approach for classification tasks, the number of functions in a class at a given error value may exhibit asymptotic behavior. This behavior can be described as a \"competition\" between the error value and the logarithm of the number of functions. The limit of this competition can be analyzed when the sample size and number of functions approach infinity with a fixed ratio \u03b1 = m/N. This ratio is analogous to the load on a network in associative memory models and serves as a control parameter for investigating generalization error. In the context of the SM approach for classification tasks, the number of functions in a class at a given error value may exhibit asymptotic behavior. This behavior can be described as a \"competition\" between the error value and the logarithm of the number of functions. The limit of this competition can be analyzed when the sample size and number of functions approach infinity with a fixed ratio \u03b1 = m/N, serving as a control parameter for investigating generalization error. Two complementary approaches to the SM theory of generalization will be described, along with simpler models illustrating key issues. The behavior of a one-layer perceptron is characterized through rigorous analysis, numerical simulations, and replica-based calculations. The basic single-layer perceptron has a set of weights and an output classification rule based on the angle between the input vector and weights. Lengths of vectors do not affect classification, and normalization is common practice. The behavior of a one-layer perceptron is characterized through rigorous analysis, numerical simulations, and replica-based calculations. In this model, the generalization error depends only on the overlap R between J and T. The perceptron has a set of weights and an output classification rule based on the angle between the input vector and weights. Lengths of vectors do not affect classification, and normalization is common practice. The perceptron model can be divided into two versions: the continuous perceptron where weights are continuous and lie on an N-dimensional sphere, and the Ising perceptron where weights are discrete and lie on the corners of an N-dimensional hypercube. The Ising perceptron exhibits a phase transition common to all spin glass models of neural networks. The Ising perceptron model exhibits a phase transition common to all spin glass models of neural networks. The generalization error decreases as the training set size increases, with vectors grouped into classes based on their overlap with the data. The chance of producing the same output as the teacher on a new example is 1 - \u03b5 for vectors with overlap R. The Ising perceptron model shows a phase transition in neural networks. Generalization error decreases as training set size increases, with vectors grouped based on overlap with data. The volume of vectors with overlap R before data presentation is reduced by 1-\u03b5 on average with each example. Generalization is controlled by a balance between entropy and energy terms. The energy penalty for incorrect predictions in the Ising perceptron model is mathematically described by the extremum condition for a combination of energy and entropy terms. The entropy slowly diverges to -\u221e as \u03b5 approaches 0 or R approaches 1. In the thermodynamic limit, the energy is dominated by the maximum value of the expression in the square brackets. Randomly choosing a student vector from the version space will likely result in the expression in the square bracket being a maximum. The optimization of the difference between s(\u03b5) and e(\u03b5) is used to determine the maximum. In the Ising perceptron model, the entropy approaches zero as \u03b5 approaches 0 or R approaches 1, indicating one state with R = 1. The energy behavior is e(\u03b5) \u223c \u2212\u03b1 ln(1 \u2212 \u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1. In the Ising perceptron model, the entropy approaches zero as \u03b5 \u2192 0 or R \u2192 1, indicating one state with R = 1. The energy behavior is e(\u03b5) \u223c \u2212\u03b1 ln(1 \u2212 \u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1. For small-to-moderate values of \u03b1, there is a solution, but for large values of \u03b1, the optimal value is at the boundary \u03b5 = 0 (or R = 1), leading to a discontinuous change in generalization error with increasing training set size. The behavior of the discrete Ising perceptron is more complex compared to the continuous perceptron. There is a discontinuous change in generalization error with increasing training set size, depending on the value of \u03b1. The system can reside in two phases - one with large, smoothly decreasing generalization and one with small or zero generalization. The discrete Ising perceptron exhibits complex behavior with two phases based on generalization error, influenced by control parameters like \u03b1 and \u03c4. The phase diagram becomes two-dimensional, showing non-trivial behavior as a function of both parameters. The discrete Ising perceptron displays complex behavior with two phases based on generalization error, influenced by parameters \u03b1 and \u03c4. The phase diagram is two-dimensional, showing non-trivial behavior as a function of both parameters. The full phase diagram is shown in FIG5, depicting phases of perfect generalization, poor generalization, spin glass phase, and metastable regimes. The continuous perceptron's phase diagram is trivial, with only one phase varying continuously with \u03b1 and \u03c4. The SM approach to learning theory characterizes generalization as a competition between entropy-like and energy-like terms, providing intuitive explanations for observed results in various figures. The approach provides intuitive pictorial explanations of results observed in various figures. It discusses the version space and the -ball around the target function, providing bounds on generalization error. The text discusses bounds on generalization error for consistent learning algorithms outputting functions within a version space. It provides upper bounds on the probability that a function remains within a certain error threshold, emphasizing the importance of minimizing this error for improved bounds. The text discusses obtaining improved bounds on generalization error for consistent learning algorithms within a version space. It emphasizes the importance of minimizing error for better bounds, with upper bounds not depending on the distribution or target function, but only on the size of the function space. More refined upper bounds can be obtained by tracking errors and the number of hypotheses achieving those errors. The text discusses improving bounds on generalization error for consistent learning algorithms within a version space by tracking errors and the number of hypotheses achieving those errors. It emphasizes minimizing error for better bounds, with upper bounds depending only on the size of the function space. The expression for the trade-off between entropy and energy in the thermodynamic limit is discussed, showing how generalization error can be bounded. The text discusses the trade-off between entropy and energy in the thermodynamic limit, showing that the error value above which the energy term dominates the entropy term is the right-most crossing point of the two functions. This concept is applied to the continuous perceptron and the Ising perceptron, resulting in a gradual decrease of error with increasing alpha. The Ising perceptron demonstrates a gradual decrease of error with increasing alpha, showing a competition between energy and entropy in the thermodynamic limit. The entropy upper bound is represented by a specific function, and the learning curve is plotted based on the energy-entropy competition. The learning curve for the Ising perceptron shows a gradual decrease of error with increasing alpha, indicating a competition between energy and entropy. The plot in FIG5 demonstrates how the crossover point shifts as alpha increases, with a sudden decrease to 0 at a critical value. This behavior is not captured by PAC/VC theory but is consistent with results from Eqn. BID12. Theoretical and empirical work has focused on loss surfaces of NNs/DNNs, with a connection to spin glasses. Results suggest a link to the random energy model (REM) and p-spin spherical spin glass. The REM exhibits certain properties consistent with NNs/DNNs. The random energy model (REM) is the infinite limit of the p-spin spherical spin glass, showing a transition in entropy density at a non-zero temperature parameter \u03c4. Above a critical value \u03c4 c, there are many configurations, while below \u03c4 c, there is a single configuration. This phenomenon of low entropy for configurations with slight loss above the minimum value is crucial for complex learning behavior. The discussion highlights the connection between DNN behavior and regularization methods like early stopping. It references the Tikhonov-Phillips method for solving ill-posed LS problems. The Tikhonov-Phillips method addresses issues in solving ill-posed LS problems by introducing regularization with a parameter \u03bb. The TSVD method replaces the original problem with a rank-k approximation to improve generalization to new data. The Tikhonov-Phillips method introduces regularization with parameter \u03bb to solve ill-posed LS problems. The TSVD method improves generalization by replacing the original problem with a rank-k approximation. The control parameter \u03bb controls the radius of convergence of the inverse of A T A + \u03bb 2 I, while k restricts the domain and range of A k. Adjusting \u03bb or k can prevent overfitting at the expense of underfitting. Adjusting the control parameter \u03bb or k can prevent overfitting but may lead to underfitting due to the linear structure of the models. Non-linear systems like NNs or DNNs do not follow the same pattern. Different approaches can be applied to various problems by considering different objectives, such as SVMs, where closed-form solutions may not be applicable. In cases where closed-form solutions are not applicable, increasing control parameters like \u03bb or k can prevent overfitting, even if it leads to underfitting. Linear regularization approaches historically did not work well on NNs, with early stopping of iterative algorithms being a more effective method. This implicit regularization approach is based on the idea that \u03bb and k are more fundamental control parameters than the number of iterations. In cases where closed-form solutions are not applicable, increasing control parameters like \u03bb or k can prevent overfitting, even if it leads to underfitting. Linear regularization approaches historically did not work well on NNs, with early stopping of iterative algorithms being a more effective method. The regularization approach is based on the idea that \u03bb and k are more fundamental control parameters than the number of iterations. When considering learning algorithms without a well-defined objective, dynamics leading to generalization typically do not optimize linear or convex objectives. The dynamics leading to generalization do not optimize linear or convex objectives but have a stochastic Langevin type form, connected to a Gibbs probability distribution. These dynamics, similar to SGD used in training DNNs, suggest a broader application of the generalization approach. General dynamical systems exhibit phases, phase transitions, and phase diagrams, defining operational sets of inputs mapped to fixed points under iterated dynamics. Phase transitions in general dynamical systems are points in parameter space where nearby points are mapped to different fixed points. Unlike in systems with a thermodynamic limit, there is no structure to obtain generalization bounds or use control parameters as regularization parameters. Adding noise to a system does not guarantee prevention of overfitting, as there may not always be a suitable regularization parameter. The hope is to find a regularization parameter that prevents overfitting, even if it leads to underfitting, with the generalization quality varying smoothly. This can be achieved by increasing the regularization parameter \u03bb in an optimization problem. The PAC/VC approach provides smooth upper bounds, making it easier to reason about the divergence of one quantity rather than two. The results in Section 3 support this approach to generalization. Our results in Section 3 challenge the common practice in machine learning and mathematical statistics of extending results for linear systems to nonlinear systems by assuming large data points and regularity conditions. Empirical evidence for neural networks suggests that these conditions often do not hold, leading to unexplored consequences."
}