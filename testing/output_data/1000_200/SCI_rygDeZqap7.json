{
    "title": "rygDeZqap7",
    "content": "Natural language understanding research has shifted towards complex Machine Learning and Deep Learning algorithms, which often outperform simpler models. To address the challenge of limited labeled data availability, a methodology for extending training datasets and training data-hungry models using weak supervision is proposed. This approach is applied to biomedical relation extraction, a task crucial for drug discovery. Small-scale experiments show consistent performance enhancements of an LSTM network, comparable to hand-labeled data. Optimal settings for applying weak supervision are discussed. The amount of scientific papers in the biomedical field is increasing, with important information encoded in unstructured text. Extracting this information and storing it in a knowledge base can impact tasks like drug design. Efforts have been made to automate Information Extraction due to the labor-intensive nature of manual annotation. This work focuses on automating semantic triple extraction from biomedical abstracts. Automating semantic triple extraction from biomedical abstracts is crucial for tasks like drug design. This work focuses on extracting relations such as Regulations (CPR) and Chemically Induced Diseases (CID) to help researchers filter out or select chemical substances with specific properties faster. Extracting semantic triples involves identifying entities of interest in unstructured text. The focus is on relation extraction in the context of automating semantic triple extraction from biomedical abstracts. A new methodology based on weak supervision is proposed to address the labor-intensive process of annotating training datasets for this task. The methodology combines ideas from semi-supervised and ensemble learning to train multiple base learners on a small labeled dataset and predict labels for a larger unlabeled dataset. The methodology proposed involves training multiple base learners on a small labeled dataset to predict labels for a larger unlabeled dataset. A denoiser is then used to derive weak labels for the unlabeled set, followed by training a strong meta-learner using weak supervision. Key contributions include a detailed methodology for relation extraction, demonstrating effectiveness in a controlled experiment, and investigating denoising methods' impact on system performance. Code is released for reproducibility and further experimentation. The code for the methodology is released on GitHub for reproducibility. The literature review covers information extraction, relation extraction from biomedical text, and semi-supervised learning methods. Unsupervised methods like Open Information Extraction do not use training data, while fully-supervised methods rely on labeled examples. Semi-supervised methods, similar to the approach discussed, leverage both labeled and unlabeled data. Recent semi-supervised algorithms like DIRPE, Snowball, KnowItAll, and TextRunner leverage both labeled and unlabeled data for bootstrapping new examples. Distant supervision is another method that generates weak labels for relation extraction using Knowledge Bases instead of pre-trained classifiers. Despite creating noisy examples, this approach has shown benefits. Our work focuses on utilizing weak labels generated from Knowledge Bases for large-scale datasets in biomedical relation extraction. This approach eliminates the need for human annotation and complements distant supervision algorithms. Research in this field has been driven by BioCreative competitions, with recent advancements showing improved performance through extending training sets using distant supervision. Recent research has shown that extending the training set using distant supervision improves performance in identifying relations between Chemicals and Proteins (or Genes) on a sentence level. The best performing team used an ensemble of LSTM, CNN, and SVMs, while the second highest score was achieved with a Support-Vector Machines algorithm. Other approaches using only Deep Neural Networks faced overfitting issues, highlighting the importance of training data in this domain. The study aims to combine ensemble methods with semi-supervised learning to improve generalization. Our work combines ensemble methods with semi-supervised learning to improve the performance of Machine Learning models, especially when using Deep Neural Networks. This combination has not been thoroughly studied but shows potential benefits in enhancing generalization by providing multiple views. Ensembles can enhance semi-supervised learning by providing multiple views and improving performance with less data. Co-training, a system where two learning algorithms utilize unlabeled data, has shown success even without complete independence. Recent research incorporates expert-defined lexicons and natural language processing to reduce noise and enhance signal in distant supervision without manual labeling. The system utilizes natural language processing and co-training to reduce noise and improve signal in distant supervision. It outperforms state-of-the-art supervised methods in functional genomics without using manually labeled data. Tri-training extends co-training to three learners, while Co-forest involves an ensemble system to make decisions on re-training. The base learners in the ensemble system are not used for final predictions. The methodology described involves using an ensemble system where base learners are used to generate weak labels but not for final predictions. This approach allows for the use of all unlabeled data, unlike previous methods that only re-trained with a few high-confidence examples. Weak supervision and data programming have heavily influenced this methodology, focusing on training models with labels of questionable quality. The methodology involves using weak supervision sources to train models with labels of questionable quality. Data programming is used to create training sets when no ground-truth labels are available. This process includes defining weak supervision sources, encoding them into Labeling Functions, applying them to unlabeled data points, and denoising the vote matrix. Data programming utilizes weak supervision sources to create training labels when ground-truth labels are unavailable. The process involves applying Labeling Functions to unlabeled data points to generate a vote matrix, which is then denoised to derive weak labels close to the true labels using a probabilistic graphical Generative Model. The model's parameters include the probability of a Labeling Function labeling a data point and the accuracy of that label. The structure of the model is a hyperparameter that represents correlations between Labeling Functions and can be estimated automatically. Training the model maximizes the marginal log-likelihood of observed votes occurring under the Generative Model. Based on weak supervision and data programming, a methodology for semi-supervised learning is proposed to leverage multiple learners. It assumes a gold-labeled training set is available but insufficient for training a complex model. The approach suggests augmenting additional lower quality training data for better results. To scale the dataset size, it is proposed to augment lower quality training data instead of relying on heuristics or crowd-sourced labels. Machine learning models of lower complexity are used as weak supervision sources, adapting an existing pipeline with little effort. The requirements include a labeled training set (D B ) of size m, an unlabeled dataset (D U ) of size M m from the same distribution, a validation set (D V ) for hyperparameter tuning, and a test set (D T ) for evaluation. K base learners are trained on solving task T using D B . In a typical ensemble learning scenario, 162 base learners are trained on solving a task by maximizing individual performance and capturing different views of the data through varying hyperparameters and design choices. One important design choice is sentence pruning, where irrelevant words within a sentence can be removed to focus on the entities of interest. This can include keeping only words between the entities or within a certain window before/after them, with more complex approaches like incorporating syntactic information also considered. In this work, different approaches are investigated for text analysis: whole sentences, window of 0, window of 5, and Shortest Dependency Path. Sequential features like tri-grams are used, and text representation is done through token occurrences or TF-IDF weights. Various machine learning algorithms are employed on the feature matrix. Machine learning algorithms, such as Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTMs, and CNNs, were used for text analysis. To maximize performance and diversity, a subset of base learners was selected, discarding those below a performance threshold. This approach helps in avoiding computational costs and including similar classifiers in a disagreement-based method. To maximize performance and diversity, a subset of base learners was selected by discarding those below a performance threshold. A similarity-based clustering method was used to select the most diverse classifiers based on inter-annotator agreement rates. K-means clustering was performed on a similarity matrix constructed from the predictions of the base learners on D V. To select representative base learners, clustering is done on a matrix using silhouette score coefficient BID32. The labels of DU are predicted using these base learners to create a binary prediction matrix. A denoiser is then used to reduce the vote matrix into weak labels. Hyperparameters are selected using a validation dataset, and different denoisers are considered. Finally, a discriminative model is used in the last step. In the last step, an Average Vote denoiser calculates an unweighted average of base learner votes to produce weak labels. A discriminative model is used as a meta-learner, trained with weak supervision to trade label quality for quantity. High-capacity models like Deep Neural Networks are employed to learn features and build accurate representations using a larger, albeit noisy, training dataset. The experiments utilize part of Snorkel's functionality for relation extraction with weak supervision, focusing on BioCreative CHEMPROT and CDR datasets. The framework for relation extraction utilizes data programming and weak supervision with BioCreative CHEMPROT and CDR datasets. The methodology involves creating gold-labeled datasets for training, validation, and testing, ensuring unbiased document selection. The datasets are restructured for training base learners, hyperparameter selection, and utilizing unlabelled documents. This setup guarantees no bias during document selection. The dataset statistics are available in TAB4. Two important requirements are satisfied: no bias during document selection and all documents undergo the same pre-processing steps. This controlled approach allows for comparison of the meta-learner's performance with weak supervision to optimal performance. Text pre-processing is mainly done by SpaCy (v1.0). The text pre-processing pipeline is mainly done by SpaCy (v1.0), which includes tasks like sentence splitting, tokenization, and dependency parsing. Named Entity Tags are manually annotated in both datasets for candidate extraction. Snorkel is used for mapping candidates to their ground-truth labels, and a relationship classifier is important for understanding natural language interactions. In the text pre-processing pipeline, SpaCy is used for tasks like sentence splitting, tokenization, and dependency parsing. Named Entity Tags are manually annotated for candidate extraction in both datasets. A relationship classifier is crucial for understanding natural language interactions. In experiments, entities of interest are replaced with 'ENTITY1' and 'ENTITY2', and other entities of the same type within the same sentence are replaced with 'CHEMICAL', 'GENE', or 'DISEASE'. A bi-directional Long-Short Term Memory network is used for Natural Language tasks, with randomly initialized word embeddings and random under-sampling for class balance. Different hyperparameter settings are explored, based on validation dataset D V. In this section, research questions are formed regarding enhancing biomedical relation extraction using Machine Learning classifiers as weak supervision sources and determining the optimal setting for this task. The related literature suggests that adding weakly labeled data can improve the performance of the meta-learner, with performance expected to improve quasi-linearly as the amount of weakly labeled data increases. The use of Machine Learning classifiers as weak supervision sources in biomedical relation extraction is a critical question that affects the methodology's usability. It is unclear if there is a diverse and sufficiently large set of base learners that meet the necessary conditions for producing meaningful weak labels. The study evaluates the impact of weak supervision on a meta-learner's performance in biomedical relation extraction. Experiments compare full-supervision, weak-supervision, and a combination of both. The optimal number of base learners is also explored to balance performance and diversity. The study examines the impact of weak supervision on a meta-learner's performance in biomedical relation extraction by gradually increasing the number of Base Learners and assessing the quality of weak labels using denoising methods. The denoiser can produce binary or marginal weak labels with varying distributions, affecting the final performance of the meta-learner. The study also investigates whether supervised machine learning classifiers can be used as weak classifiers. The study evaluates the impact of weak supervision on a meta-learner's performance in biomedical relation extraction by increasing the number of Base Learners and assessing weak label quality. Results show training with weak labels consistently outperforms training with fewer gold labels. Training the meta-learner with weak labels and a larger training set size performs better than using fewer gold labels. Including ground-truth labels further improves performance. Weak supervision can achieve results comparable to full supervision, with some cases even slightly better. Differences in performance are not statistically significant due to high variance. The meta-learner's performance is affected by high variance. Undersampling based on weak labels leads to larger training set sizes. Majority Vote often outperforms the meta-learner, but LSTM struggles with small datasets. Learning curves show improvement with weak labels. F1 score on the training set is significant. The F1 score indicates an upward trend with statistically significant results. The meta-learner shows signs of overfitting due to high variance, suggesting the need for more training data. The small dataset size limits definitive conclusions, but analysis based on experimental results will be discussed. The F1 score for weak Majority Vote labels with 5 learners is the lowest, while no significant pattern is observed for Generative model weak marginals. The meta-learner's performance varies based on the type of marginals used and the number of base learners. The F1 score remains consistent with slight deviations when using Generative model weak marginals. The meta-learner performs better with Average Vote marginals, especially with more than 10 base learners. Generative model marginals show improvement with an increase in base learners, except for two cases. Overall, the meta-learner achieves the best performance with Average Marginals. Generative Model marginals also outperform Majority Vote weak labels, except when hyperparameters are chosen based on F1 score validation. The performance of the meta-learner is influenced by the type of weak labels used, with GM marginals depending on hyperparameters chosen based on F1 score validation. Marginal weak labels improve performance compared to binary labels, with GM marginals following a U-shaped distribution. This contrasts with average marginals, which are more uniformly spread. The error analysis on the validation set shows that Average Vote labels are of higher quality compared to GM marginals. The F1 score is not suitable for evaluating marginal weak labels. Training with marginal labels results in higher training error, especially with Average weak marginals. Training with marginal labels results in higher training error, especially with Average weak marginals. LSTM quickly predicts binary training labels accurately, despite a delay with noisy-labeled MV weak labels. The methodology is akin to a regression problem, penalizing the model for inaccurate predictions. Predicted logits become more spread as training marginals distributions become more uniform, resembling regression rather than classification. Efforts are discussed to apply this methodology on the CPR task, expanding labeled and unlabeled datasets. In this section, efforts are made to apply the methodology on the CPR task by expanding labeled and unlabeled datasets. The performance of the meta-learner decreases when weakly labeled data is added, indicating issues with data quality. A predicted class imbalance is observed in the outgoing citations dataset compared to the original dataset. Using the t-SNE algorithm, it is confirmed that most candidates from the new dataset lie in specific regions of the 2D space, making it unsuitable. The methodology applied on the CPR task involved expanding labeled and unlabeled datasets. Weakly labeled data led to a decrease in meta-learner performance, indicating data quality issues. The t-SNE algorithm confirmed that most candidates from the new dataset were unsuitable for the task. Weak supervision can enhance complex model performance by utilizing unlabeled data and multiple base learners. The proposed methodology is feasible for defining a combination of base learners to take advantage of additional, unlabeled data. The methodology shifts human effort from hand-labeling to feature engineering and constructing diverse learners. It allows scaling training datasets while improving performance. The pipeline can be reused for similar tasks with appropriate datasets, eliminating the need for repeated hand-labeling. Further exploration is needed to construct a large unlabelled dataset to improve metalearner performance and draw stronger conclusions. Preliminary experiments show the challenge of collecting an appropriate unlabeled dataset and emphasize the importance of not taking it for granted in semi-supervised algorithms. Further investigation is required to define a more suitable metric than the F1 score for evaluating weak labels. This would impact the performance by optimizing hyperparameters of the Generative Model. Additionally, experimenting with the meta-learner and improving the selection method for Base Learners are areas for further exploration. Further exploration could involve improving the selection method for Base Learners, such as abstaining from voting on uncertain examples, which could provide a modeling advantage for the Generative Model compared to unweighted methods like Majority Voting. This could optimize hyperparameters and impact performance, as discussed in an analysis on weak supervision trade-offs."
}