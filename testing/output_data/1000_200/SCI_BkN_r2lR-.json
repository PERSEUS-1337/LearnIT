{
    "title": "BkN_r2lR-",
    "content": "Identifying analogies across domains without supervision is a key task for artificial intelligence. Recent advances in cross domain image mapping focus on translating images across domains, but visual fidelity often falls short for matching samples. This paper introduces AN-GAN, a matching-by-synthesis approach that outperforms current techniques in finding exact analogies between datasets. The cross-domain mapping task is divided into domain alignment and learning the mapping function, which can be iteratively solved to improve alignment and reach quality comparable to full supervision. Humans have a remarkable ability to make analogies between unseen domains without prior supervision, which is crucial for leveraging previous knowledge in new situations. Recent advances in AI have focused on supervised problems, but analogy identification presents a challenge as no explicit example analogies are given in advance. Unsupervised mapping approaches have been proposed to address this issue, using sets of images from different domains without explicit correspondences. Unsupervised mapping approaches aim to learn a mapping function between two different domains without explicit correspondences. The methods focus on making the distributions of mapped images indistinguishable and ensuring that an image mapped to the other domain and back remains unchanged. The task of analogy identification involves finding pairs of examples related by a fixed non-linear transformation. In this work, the problem of analogy identification is addressed by adding exemplar-based constraints to improve visual fidelity and performance. The current methods focus on distribution constraints, but incorporating exemplar-based constraints can enhance exact matching even when only some sample images have exact analogies. Our method is effective in finding correspondences between sets even when no exact correspondences are available. By aligning domains and using a two-step approach, we can train a domain mapping function that yields better visual quality than previous methods. This approach involves finding analogies between domains using our method and then fitting a translation function between the domains using a fully supervised method. This paper discusses identifying analogies between datasets without supervision, focusing on analogy identification related to image matching methods. Various approaches for image matching have been proposed, including supervised deep neural networks and generic visual features for matching in unsupervised scenarios. In unsupervised scenarios, generic visual feature matching is important for analogies between datasets. However, standard visual features like multi-layer VGG-16 are not effective due to domain differences. Generative Adversarial Networks (GANs) have revolutionized image synthesis, enabling realistic image translation without supervision. Generative Adversarial Networks (GANs) are used to create realistic images by training a generator network G and a second network D. The generative architecture is based on BID12. Unsupervised mapping for image translation does not require supervision, while supervised mapping involves matching pairs of input and output images. Supervised mapping methods can be trained directly with matching pairs of input and output images. The discriminator in GANs receives pairs of images to strengthen the link between source and target images. Our algorithm generates correspondences between domains, allowing for the use of supervised mapping methods on inferred matches. Recently, BID2 showed improved mapping results in supervised settings using perceptual loss without GANs. The method for analogy identification involves finding matching indexes between two sets of images in domains A and B. An iterative approach is used to map images from the source domain to the target domain and search for matches. A GAN-based distribution approach has emerged for mapping images across domains. A mapping function T AB is trained to make x appear as if it came from domain B by optimizing the distribution of T AB (x) to be identical to y. Discriminator D is trained to distinguish between samples from p(T AB (x)) and p(y). The loss function for training T and D is binary cross-entropy. The networks L D and L T are trained iteratively. The GAN-based distribution approach involves training a mapping function T AB to transform images from domain A to appear as if they came from domain B. Additional constraints like circularity and distance invariance have been effective. The cycle approach trains one-sided GANs in both directions and ensures that translated images recover the original. The two-sided cycle loss function yields mapping functions from A to B and back, providing matching between samples and synthetic images in the target domain. However, it does not provide exact correspondences between the domains. In the previous section, a distributional approach was described for mapping images from domain A to domain B. This section introduces a method for exact matches between domains, finding matching indices for each image pair. Once exact matching is achieved, a fully supervised mapping function T AB can be trained to obtain high-quality mappings similar to supervised methods. The proposed match matrix \u03b1 i,j assigns weights to each sample in B for every image in A, enabling precise matching between domains. The section introduces a method for exact matches between domains, finding matching indices for each image pair. The optimization objective involves a binary matrix with weights assigned to each sample in B for every image in A. The optimization is continuous over T AB and binary programming over \u03b1 i,j, with an entropy constraint to encourage sparse solutions. The positivity and constraint enforcement are achieved using an auxiliary variable \u03b2 passed through a Softmax function. The optimization objective involves enforcing constraints using an auxiliary variable \u03b2 passed through a Softmax function. The relaxed formulation can be optimized using SGD. By increasing the entropy term, solutions converge to the original correspondence problem. Iteratively updating T AB for N epochs and updating \u03b2 for N epochs achieves excellent results. The training scheme requires full mapping only once at the beginning of the iteration. The AN-GAN method combines exemplar and distribution-based constraints to achieve cross-domain matching. It includes three types of constraints: distributional loss, cycle loss, and exemplar loss. The optimization problem involves minimizing the AN-GAN loss function through adversarial training. The AN-GAN optimization problem involves adversarially training discriminators D A and D B, with initial \u03b2 values set to 0 for equal likelihood. A burn-in period of 200 epochs with \u03b4 = 0 aligns distributions before individual images. The exemplar loss is optimized over iterations, with shared \u03b2 parameters between mapping directions. In experiments, hyper-parameters were fixed and shared between mapping directions. Euclidean or L1 loss functions were not effective, but Laplacian pyramid loss showed improvement. The best results were obtained using a perceptual loss function, extracting VGG features for each image. The study utilized VGG features for images, incorporating L1 loss for color accuracy. The perceptual loss function was defined using feature maps for image pairs, emphasizing unsupervised matching. Matching experiments were conducted to evaluate the approach. To evaluate our approach, matching experiments were conducted on public datasets. Various scenarios were evaluated, including exact matches. Our method was compared against other existing solutions for cross-domain matching, such as finding nearest neighbors using L1 loss on raw pixels or VGG feature loss. CycleGAN was also used for training and evaluation. The study evaluated different scenarios for cross-domain matching using methods like L1 loss on raw pixels and VGG feature loss. CycleGAN was utilized for training and evaluation on public datasets like Facades and Maps. The method was compared against existing solutions for cross-domain matching. The Maps dataset was scraped from Google Maps and consists of aligned Maps and corresponding satellite images. The dataset includes images of shoes from the Zappos50K dataset and Amazon handbags. The edge images were automatically detected using HED. The datasets were down-sampled to 2k images each for memory complexity. The method was compared with five others for exact correspondence identification. The Maps dataset includes aligned Maps and satellite images, as well as images of shoes and handbags. The datasets were down-sampled for memory complexity. The method was compared with five others for exact correspondence identification, with the objective of recovering the full match function between images in different domains. Matching using pixels or deep features alone was not effective, but using CycleGAN and pixel-losses improved matching performance. Matching perceptual features between source and target images was another baseline method explored. The next baseline method improved image retrieval performance by matching perceptual features between mapped source images and target images using VGG features. Exhaustive search was deemed too computationally expensive, leading to subsampling of features. Linear combinations of mapped images were matched, reducing sensitivity to outliers and using the same parameters for both sides of the match. Significant performance improvements were observed with this method. The AN-GAN method significantly improved image retrieval performance by using a distributional auxiliary loss to aid optimization. The exemplar loss, when optimized with auxiliary losses, was able to converge, showing that they are essential for successful analogy finding. The full-method AN-GAN optimized the mapping function to match each source sample with the nearest target sample, resulting in significantly better performance for all datasets and matching directions. In experiments with unavailable matches, a percentage of samples in each domain do not have a match in the other domain. The task is to identify correct matches for samples with matches in the opposite domain. Evaluation is based on the percentage of images with exact matches. The protocol is similar to previous experiments, with the removal of non-matching pairs. Our method can handle scenarios where not all examples have matches, achieving a 90% match rate with up to 75% of samples not having matches. The quality of mapping function decreases with a low exact match ratio, but our approach still performs well in identifying exact analogies. In an experiment evaluating the method on scenarios without exact analogies, the DiscoGAN architecture was used for mapping in the Shoes2Handbags scenario. Results showed varying quality of matches, with some examples showing poor matches despite iterations. AN \u2212 GAN improved match relevance in some cases. The DiscoGAN mapping quality is lower, with poor matches in both DiscoGAN and DiscoGAN + \u03b1 iterations. AN \u2212 GAN improves match relevance, leading to better analogies. A two-step approach is suggested for aligning datasets: (i) Find analogies using AN \u2212 GAN, and (ii) Train a mapping function using self-supervision. 97% alignment accuracy is achieved on the Facades dataset, used to train a fully self-supervised mapping function with Pix2Pix for facade photos to segmentations task evaluation. Our self-supervised method performs similarly to fully supervised methods and outperforms CycleGAN in image mapping tasks. The quality of images mapped by our method is higher than CycleGAN and comparable to fully supervised Pix2Pix. The method effectively addresses the unsupervised problem by finding correspondences between domains. The supervised stage uses a Pix2Pix architecture with L1 loss, yielding improved performance over CycleGAN and competitive with full-supervision. The method was also evaluated on point cloud matching, showing promising results in low dimensional settings. The experiments were conducted using the Bunny benchmark, rotating the object randomly in 3D. Both CycleGAN and the proposed method used a specific architecture with a fully connected network and a linear affine matrix for mapping. A loss term was added to ensure orthonormality of the weights. The success rate for alignment was compared between the two methods for different rotation angles. Our method outperforms the baseline results in achieving alignment accuracy for large transformation angles. It is effective for low dimensional transformations and settings without exact matches. The algorithm presented allows for unsupervised cross-domain matching, addressing the issue of inaccurate mapped images in previous works. In this work, a new method with exemplar constraint is introduced to improve match performance in unsupervised cross-domain matching. The method significantly outperformed baseline methods in full and partial exact matching on public datasets. It presents an alternative approach to domain translation by aligning domains and training a fully supervised mapping function. Future work aims to explore matching between different modalities like images, speech, and text, requiring the development of new distribution matching algorithms."
}