{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The models are structured based on a causal graph and applied to conditional and interventional sampling of face images with binary feature labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. The text discusses the use of conditional GAN architectures, specifically CausalGAN and CausalBEGAN, for generating images based on binary labels. These architectures allow sampling from observational and interventional image distributions, even for interventions not present in the dataset. Additionally, it mentions the use of generative adversarial networks (GANs) as a successful method for training implicit generative models. Generative Adversarial Networks (GANs) are successful in training implicit generative models by using backpropagation to sample from high-dimensional distributions. A generator network produces samples from noise vectors, refined by a discriminator network that distinguishes between real and generated samples. GANs have been effective in generating images and videos. An extension includes sampling from class conditional data distributions by providing class labels to the generator. Various neural network architectures have been proposed for sampling from class conditional data distributions by feeding class labels to the generator alongside noise vectors. The architecture discussed in the paper can sample from both joint and interventional distributions, capturing the dependence between labels for image generation. In this paper, the focus is on extending previous work on conditional image generation by capturing the dependence and causal effect between labels. The generator maps labels to images in a non-deterministic way, following the causal graph \"Labels cause the Image\". Additionally, the causal relation between specific labels, such as Gender and Mustache, can be included in the model. The causal relation between Gender and Mustache is captured in the model, with Gender causing Mustache. Conditioning on Gender or Mustache allows sampling from different distributions. Interventions fix variable values in the causal graph, affecting descendant distributions but not ancestors. Intervening on Mustache does not change the distribution of Gender. In this work, causal implicit generative models (CiGM) are proposed to sample from joint, conditional, and interventional probability distributions based on a given causal graph. The neural connections of the generator structure are inherited from the causal graph, allowing the use of GANs to train CiGM. The Wasserstein GAN (WGAN) is used to train a CiGM for binary image labels. The text discusses using Wasserstein GAN (WGAN) to train a CiGM for binary image labels and proposes two novel conditional GANs, CausalGAN and CausalBEGAN. It shows that CausalGAN's optimal generator can sample from true conditional distributions and combining it with a CiGM on labels yields a CiGM on both labels and images. The contributions include demonstrating that adversarial training can be used to train a CiGM after structuring the generator architecture based on the causal graph. The text discusses training a CiGM for binary image labels using WGAN and proposes CausalGAN and CausalBEGAN. CausalGAN's optimal generator can sample from true conditional distributions. CausalBEGAN extends BEGAN by accepting labels and produces high-quality images. The framework is evaluated on CelebA data, showing that CausalGAN and CausalBEGAN can produce quality images. The CiGM training framework, evaluated on CelebA data, shows that CausalGAN and CausalBEGAN can produce label-consistent images even for interventions not seen during training. Previous works include conditional GAN (CGAN) and ACGAN, which aim to generate images based on given labels. InfoGAN is another architecture proposed to maximize variational information. The performance of CGAN and ACGAN is discussed, along with an extension to the semi-supervised setting. Various architectures like InfoGAN, BiGAN, ALI, CoGAN, and SD-GAN are also mentioned for their contributions to the GAN framework. The SD-GAN architecture splits the latent space into \"Identity\" and \"Observation\" portions, allowing for the generation of faces with fixed identity codes. It extends BEGAN to accept labels, such as age intervals, for attribute manipulation in face images. Additionally, SD-GAN shows promise in compressed sensing applications by providing guarantees for recovering vectors close to the output of a trained generative model. Recent research has focused on using causal principles in deep learning and deep learning techniques for causal inference. Studies have explored the connection between GAN layers and structural equation models, using CGAN to learn causal directions between variables. Other works have proposed using neural networks to discover causal relations between image class labels and introduced causal regularization for training predictive causal models. In recent research, the connection between GANs and causal generative models has been explored. Authors have used neural networks to learn causal graphs and mimic structural equations. The framework of causality, specifically Pearl's structural causal models, is used to represent causal models with directed acyclic graphs between random variables. The causal sufficiency assumption states that X causes Y through a function f and an unobserved variable E. Causal graphs represent this relation as X \u2192 Y. A causal graph is a directed acyclic graph implied by structural equations, where the parents of a node represent the causes of that variable. A structural causal model includes functions, random variables, and exogenous variables. A causal graph is a directed acyclic graph representing the relationships between variables in a structural causal model. An intervention changes the causal mechanism by altering the connections in the graph. Interventions in a causal graph alter connections by removing node links to parents. Post-interventional distribution in Bayesian networks can be calculated by factorizing the observational distribution. After an intervention on a set of nodes, the post-interventional distribution is determined by the assignment of causal graphs. Learning the causal graph is not addressed in this paper, assuming it is given, and a causal model is learned. There is prior work on learning causal graphs that could be utilized before implementing this method. Learning causal graphs is essential for sampling from correct observational distributions when the true causal graph is unknown. Bayesian networks respecting conditional independences in the data can help with this. Causal implicit generative models allow sampling from both observational and interventional distributions, with the use of generative adversarial networks for training. In the GAN training framework, generator neural network connections reflect the causal graph structure X \u2192 Z \u2190 Y. Feedforward neural networks represent functions f X, f Y, f Z with independent noise terms (N X, N Y, N Z). Gaussian distributed variables can be used for exogenous variables. The feedforward neural network represents causal models with graph DISPLAYFORM2. The proposition in the causality literature states that causal models with the same observational distribution and true causal graph have the same interventional distributions for any intervention. A feedforward neural network is linked to a causal graph by defining sets of mutually independent random variables. Causal implicit generative models are defined based on this connection. Causal implicit generative models, defined as feedforward neural networks linked to a causal graph, can be trained using adversarial training. However, difficulties arise when learning the joint label and image distribution for image generation with binary labels. The CausalGAN architecture focuses on using a pretrained causal implicit generative model for image labels. CausalGAN architecture involves a pretrained causal implicit generative model for image labels, with a focus on training a generative model for images conditioned on labels. The architecture ensures that the optimum generator outputs label-conditioned image distributions under the assumption of a strictly positive joint distribution between labels and images. The Causal Controller, part of the CausalGAN architecture, is trained adversarially for binary labels. It controls image sampling based on label interventions, following a causal graph structure. The generator used can sample from discrete label distributions, which is not ideal for standard GAN training methods. The Causal Controller in the CausalGAN architecture is trained adversarially for binary labels and controls image sampling based on label interventions. To sample from a discrete label distribution, WGAN is employed instead of standard GAN training methods. A new conditional GAN architecture is designed to generate images based on the labels of the Causal Controller, ensuring the optimum generator outputs label-conditioned image distributions. The CausalGAN architecture includes a pretrained Causal Controller for image sampling based on label interventions. It features separate Labeler and Anti-Labeler neural networks to estimate image labels and ensure realistic image generation. The generator's objective is to produce realistic images, consistent with labels, and avoid easy labeling by maximizing the Anti-Labeler loss. CausalGAN stands out by using both Labeler and Anti-Labeler networks in addition to a discriminator. The CausalGAN architecture utilizes both Labeler and Anti-Labeler networks to prevent label-conditioned mode collapse during image generation. The Anti-Labeler discourages the generator from outputting only typical faces for a fixed label combination, helping with faster convergence. This approach is effective in combating mode collapse, especially for rare label combinations. In Section 9.4 of the Appendix, results are presented for a single binary label. The analysis assumes a perfect Causal Controller and uses mappings from the generator, discriminator, Labeler, and Anti-Labeler. The generator loss function in CausalGAN includes label loss terms and an additional loss term from the discriminator, leading to the optimal generator outputting the class conditional image distribution. This result extends to multiple binary labels as shown in the Appendix. The optimal generator outputs the class conditional image distribution for multiple binary labels, as shown in the Appendix. The Labeler, Anti-Labeler, and discriminator each solve specific optimization problems. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. This result holds for single binary labels and can be extended to multiple binary variables. The optimal generator outputs the class conditional image distribution for multiple binary labels, as shown in the Appendix. The generator minimizes the virtual training criterion by sampling from the class conditional distributions. This result holds for single binary labels and can be extended to multiple binary variables. The global minimum of the virtual training criterion is achieved when the generator output matches the class conditional image distribution. This two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The optimum generator samples from class conditional distributions given a single binary label. To extend this to d binary labels, a new architecture using cross entropy loss terms for each label is proposed to simplify implementation. The proposed alternative architecture extends the single binary label setup to d outputs using cross entropy loss terms for each label. While ensuring the generator captures the joint label posterior, it may not guarantee true class conditional distributions. However, for practical joint distributions where labels are determined by the image, the guarantee implies the generator samples from the correct class conditional distributions. Refer to Section 8.7 for formal results and details. The proposed extension of BEGAN involves feeding image labels to the generator using the Causal Controller for interventional sampling. This allows for sampling from counterfactual distributions by conditioning on events and using rejection sampling. Refer to Section 8.8 in the Appendix for more details. In the proposed extension of BEGAN, image labels are fed to the generator using the Causal Controller for interventional sampling. A Labeler network is used for labeling real images well and generated images poorly, similar to the original BEGAN discriminator. Margin modifications are motivated by observations on image and label quality gradients, with a necessary margin of margins term. In this section, CausalGAN and CausalBEGAN are trained on the CelebA Causal Graph. The dataset used satisfies certain conditions, such as the relationship between Male and Mustache. The images generated show both males and females with mustaches, even though the generator was not trained on that specific label combination. The conditional distribution of images with Mustache=1 only shows male images. The conditional distribution P(.|Mustache=1) shows only male images, despite the generator not being trained on the label combination {Male=0, Mustache=1}. A novel generative model can sample from interventional distributions, with provable guarantees. Intervening on Narrow Eyes=1 and conditioning on Narrow Eyes are demonstrated in CelebA. CausalBEGAN shows interventions on Narrow Eyes=1 in CelebA Causal Graph. Intervening on Narrow Eyes=1 increases smiling images proportion, demonstrating causality in generative models. Causal generative models like CausalGAN and CausalBEGAN are more creative as they can produce diverse samples. Structural causal models consist of functions, random variables, and exogenous variables with a joint distribution. This research has been supported by various grants and organizations. The joint distribution of observable variables V is determined by the distributions of E and functional relations F. The causal graph D is a directed acyclic graph on nodes V, where a node Xj is a parent of node Xi if Xj is in the domain of fi. D is a Bayesian network for the joint probability distribution over V, assuming causal sufficiency. Interventional distributions for causal Bayesian networks can be calculated directly from conditional probabilities and the causal graph. Interventional distributions for causal Bayesian networks can be directly calculated from conditional probabilities and the causal graph. The optimal discriminator D is given by a specific formula. The optimum Labeler has a certain relationship with the joint data distribution. The optimum Labeler and Anti-Labeler in causal Bayesian networks are defined based on specific formulas related to conditional probabilities. The model assumes causal sufficiency and the distribution over exogenous variables is mutually independent. Edges are added to form complete graphs for analysis. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. This is based on specific formulas related to conditional probabilities in causal Bayesian networks. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution, as shown by Prop 2, Lemma 1, and Lemma 2. This is based on specific formulas related to conditional probabilities in causal Bayesian networks. The concatenated generator neural network in a conditional GAN is consistent with the causal graph D, allowing it to sample from true observational and interventional distributions. Modifications are explained for extending the proof to cases with multiple binary labels. The proof is extended to cases with multiple binary labels by addressing the challenge of characterizing the joint distribution. Two solutions are presented: (1) Estimating the probability of label combinations and (2) Using Labelers to estimate probabilities of individual labels, ensuring consistency between generated and real distributions. In this section, an extension is presented along with results where \u03c1 j = P r (l = j). The Lemma states that the optimum Labeler for the loss function has D * LR (x)[j] = P r (l = j|x). The proof shows that considering only label combinations with positive probability and functions D LR that are positive on these combinations can achieve a finite loss. The optimum Labeler network gives the posterior probability of a label combination based on the observed image. The loss is lower bounded by the Shannon entropy of the label variable. The unique optimum is achieved when the Labeler network satisfies the distribution of the random variables. The Anti-Labeler network optimizes the posterior probability of label combinations given an observed image. It uses a softmax function to ensure the coordinates sum to 1. The Anti-Labeler's optimization problem involves the joint distribution between generated images and labels. The generator aims to optimize the conditional entropy of labels given the image. The generator, Labeler, and Anti-Labeler work together to optimize the distribution of label combinations for generated images. The global minimum of the virtual training criterion is achieved when the generator samples from the true joint label distribution. The relations between D * LR, Anti-Labeler D *LG, and discriminator D * are defined by Prop 2, Lemma 3, and Lemma 4. Substituting into the generator objective C(G) yields the Kullback-Leibler divergence, minimized when P g = P d jointly over labels and images. Theoretical guarantees for the CausalGAN architecture with d labels are provided under the assumption of a deterministic relationship between images and labels in the dataset. The assumption of deterministic labels in the dataset ensures the global optimal generator samples from class conditional distributions. The Anti-Labeler optimizes for P_g(x|l_j=0), while the generator optimizes for P_g(x|l_j=0) when the discriminator, Labeler, and Anti-Labeler are at their optimum. Proposition 3 characterizes the optimum generator for these conditions. The global minimum of the virtual training criterion C(G) is achieved when the generator samples from class conditional image distributions, assuming the image determines all labels. This assumption is crucial for correct conditional sampling in practice. In the CelebA dataset, the label vector is a deterministic function of the image. The lemma states that any discrete joint probability distribution with kronecker delta functions as marginal distributions is the product of these marginals. The joint probability distribution is zero everywhere except at specific elements (u1, u2, ..., un). By contradiction, it is shown that the distribution must be 1 at these elements. Applying this lemma to the conditional distribution P g (l1, l2, ..., ld | x) shows that the marginals are true to the data distribution. In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The proof shows that the optimum generator samples from the class conditional image distributions, based on Bayes' rule and kronecker delta functions. In this section, a new loss and margins are introduced to extend BEGAN by feeding image labels to the generator. The goal is to optimize generator samples from class conditional image distributions, emphasizing the importance of label gradients for high image quality. The text introduces a new loss and margins to extend BEGAN by incorporating image labels into the generator. The addition of label gradients is crucial for improving image quality in the generator samples. The text introduces a new margin-coefficient tuple to minimize loss terms in the formulation. It encourages the generator to incorporate label loss only when the image quality margin is large. The update rules include a new margin of margins term, and learning rates for the coefficients. BEGAN has a monotonically decreasing scalar to track gradient descent optimization. Our extension of BEGAN includes a monotonically decreasing scalar to track gradient descent optimization. We investigate the convergence of causal implicit generative models on synthetic data from different causal graphs. The study explores the convergence of causal implicit generative models on synthetic data from various causal graphs, including line, collider, and complete graphs. Different generators, such as fully connected neural networks, are also compared in terms of their ability to map random noise to output variables. The results are presented in FIG9. The study compares the convergence of causal implicit generative models on synthetic data from different causal graphs. Results are shown in FIG9, with different generator structures tested. The complete causal graph is expected to work well with all data generation models. Standard fully connected layers correspond to a causal graph with a latent variable causing observable variables. The study explores the convergence behavior of causal implicit generative models on synthetic data from different causal graphs. Results in FIG9 show that different generator structures have varying performance. Fully connected layers with 3 layers show good performance, while 5 and 10 layers perform worse. Using the wrong Bayesian network also leads to decreased performance. When training causal implicit generative models on synthetic data from different causal graphs, the number of layers plays a crucial role in achieving optimal performance. Using the wrong Bayesian network, such as a collider graph, results in decreased performance. Surprisingly, a fully connected generator with 3 and 5 layers shows the best performance for the collider graph. However, using 10 layers leads to the worst convergence behavior. Different graph structures, like complete and collider graphs, show decent performance, while a line graph performs the worst. When training causal implicit generative models on synthetic data from different causal graphs, the number of layers plays a crucial role in achieving optimal performance. Using the wrong Bayesian network, such as a collider graph, results in decreased performance. A fully connected generator with 3 and 5 layers shows the best performance for the collider graph, while using 10 layers leads to the worst convergence behavior. Different graph structures, like complete and collider graphs, show decent performance, while a line graph performs the worst. The correct causal graph gives the closest scatter plot to the original data, while the wrong graph does not show convergence behavior. Using the correct causal graph is crucial for generating accurate data representations. The CelebA Causal Graph (G1) on image labels includes factors like Male and Young, with causal relationships illustrated in the completed graph cG1. Using the incorrect Bayesian network leads to independent generation of Male and Young, which is inaccurate. The incorrect Bayesian network (G1) generates Male and Young independently, leading to inaccurate data representation. Despite this, both G1 and cG1 produce Causal Controllers that never output {Female, Mustache}. Wasserstein GAN ensures convergence of Causal Controller output to discrete label distribution. The modified Wasserstein GAN ensures convergence of the Causal Controller output to discrete label distribution, as demonstrated by sampling the joint label distribution and showing good convergence in histograms. The CelebA Causal Graph and its completion allow training of reasonable marginal distributions for all labels with minimal deviation. The Wasserstein Causal Controller ensures convergence to discrete label distribution by training on a subset of binary labels from the CelebA dataset. The generator learns to map continuous noise to a discrete distribution, with 96% of samples appearing near 0 or 1. The total variational distance measures convergence. The text discusses the convergence of total variational distance (TVD) for CelebA Causal Graph (G1), defined completion (cG1), and cG1 with arrows reversed (rcG1). Both cG1 and rcG1 show TVD decreasing to 0, while G1 asymptotes to around 0.14, indicating incorrect conditional independence assumptions. The results of CausalGAN interventions and conditioning on wearing lipstick are also presented. The text discusses interventions and conditioning on wearing lipstick and narrow eyes in CelebA Causal Graph. It explains how certain interventions do not affect the probability of specific attributes, leading to different distributions in the dataset. In CelebA Causal Graph, interventions on Narrow Eyes do not affect the probability of Smiling. However, conditioning on Narrow Eyes increases the proportion of smiling images in the dataset. CausalBEGAN is trained on CelebA dataset using CelebA Causal Graph, showing the impact of margins on image quality for rare labels. The image quality for rare labels deteriorates when intervening or conditioning on specific attributes like Bald and Mouth Slightly Open in CelebA Causal Graph. Intervening on Bald does not affect the probability of Male, while conditioning on Bald results in only male images being sampled. Similarly, intervening on Mouth Slightly Open does not affect the probability of Smiling, with conditional sampling showing images with Smiling = 1. In this section, additional simulations for CausalGAN and CausalBEGAN are provided. CausalGAN's conditional image generation properties are demonstrated by sweeping a single label from 0 to 1 while keeping other inputs fixed. Image diversity and mode collapse are examined with 256 randomly sampled images in Figure 17. CausalBEGAN's simulation results show that the third margin term introduces complications but does not affect the overall outcome. In this section, additional simulation results for CausalBEGAN are presented. The third margin term is shown to be significant for image quality of rare labels in FIG6. The extension of scalar \"M\" defined in 28, denoted as M complete, is illustrated in FIG9 as decreasing monotonically during training. Conditional image generation properties of CausalBEGAN are demonstrated using \"label sweeps\" in FIG3, revealing the generator's discrete function with respect to label input. The CausalBEGAN architecture learns a discrete function for label input parameters. Image diversity is shown through a random sampling of 256 images. An implicit causal generative model is trained for labels and images, treating the image as part of the causal graph. One approach is to encode the label as a constant image in an additional channel. However, in the CelebA Causal Graph, image generation is not learned, possibly due to the discriminator focusing on labels. The implementation details of the Wasserstein Causal Controller for generating face labels are explained in this section. The total variation distance (TVD) is used as a metric to evaluate the success of the models. The Wasserstein approach allows training the Causal Controller to output discrete labels. The gradient term as a penalty is estimated by evaluating the gradient at points interpolated between real and fake batches. The Wasserstein approach in training the Causal Controller for generating face labels involves using discrete labels and rounding them before passing to the generator. The generator architecture is based on a causal graph, using neural networks and uniform noise. Training involves Wasserstein discriminator updates, stochastic gradient descent, and extending DCGAN into the Causal GAN framework with Labeler networks and a Causal Controller network. In the Causal GAN framework, Labeler networks are added along with a Causal Controller network. The loss functions are modified accordingly, with 6 generator updates for each discriminator update on average. The Labeler and Anti-Labeler loss terms are extended by averaging the loss terms for every label, using d-dimensional label vectors. This differs from the architecture where the discriminator outputs a length-2 d vector to estimate label probabilities. In the Causal GAN framework, the discriminator outputs a length-2 d vector to estimate label probabilities. The architecture may not guarantee sampling from class conditional distributions if data distribution is not restricted. Swapping the order of terms in cross entropy expressions for labeler losses improved image sharpness during training. Labels input to CausalBEGAN are from the Causal Controller with minimal parameter tuning and a shared learning rate of 0.00008 for generator and discriminator. The labels input to CausalBEGAN are taken from the Causal Controller with minimal parameter tuning. A shared learning rate of 0.00008 is used for both the generator and discriminator. Customized margin learning rates are also employed to reflect asymmetry in generator response times. The best performing models exhibit all three margins being \"active\" near 0 while occasionally taking small positive values. The best performing models in CausalBEGAN have all three margins \"active\" near 0 while occasionally taking small positive values. Comparing CausalGAN behavior with and without Anti-Labeler network shows that using Anti-Labeler allows for faster convergence and provides more diverse images for very rare labels. See FIG3, 25."
}