{
    "title": "rk1J969Xz",
    "content": "Estimating image location solely based on image content is challenging due to the need for contextual information. This study introduces a global meshing strategy for image geolocation, addresses data limitations in training models, and shows how additional information can enhance geolocation inference. Delaunay triangles are found to be effective for geolocation in low volume scenarios. The study introduces a global meshing strategy using Delaunay triangles for image geolocation in low volume scenarios. Additional information like time of posting and user metadata can improve geolocation accuracy by up to 11% for country-level and 3% for city-level localities. Advancements in deep learning have expanded the possibilities of machine learning beyond image classification. Recent methods allow for deeper analysis of contextual information in images, enabling researchers to ask more complex questions like determining the geographic origin of a picture. However, estimating the location of ground-level images is challenging due to uneven distribution of geographic information. This complexity complicates model design. The uneven distribution of geographic information complicates the design of models for content-based image geolocation. Challenges include conflicting data and ambiguity in geographic terms. With the rise of image-based social media, inferring the geographic context behind images is becoming increasingly important. The rise of image-based social media has led to a shift towards more visual content. Inferring geographic context from images poses challenges due to the lack of consistent geolocation data. Various approaches have been explored for geolocation from image content. The paper discusses geolocation from image content, building on recent global geolocation work. It utilizes a multi-class approach with one-hot encoding and instance-level scene retrieval for geolocation. Prior work includes data sampling strategies for large-scale classification problems in social media applications. In large-scale classification problems for social media applications, Kordopatis-Zilos et al. (2016) explores weighted sampling of minority classes to bias class selection during deep learning model training. This includes random noising for image regularization to expose models to more rare class examples. The study also considers sampling methods that ensure individual users are only seen once per training epoch, without respect to user, to address concerns related to social media geolocation. The first model discussed focuses on geolocation for image content (M1). In social media geolocation, models M1, M2, and M3 are considered, utilizing alternative mesh, time, and user information for improved geolocation accuracy. Data from YFCC100M BID17 is used for training and validation, with ground truth GPS locations assumed to be accurate. Comparatively, PlaNet used BID19 images for model development. The approach for global-scale geolocation model development involves using YFCC100M data with user-id and posted-time metadata. The globe is divided into a grid for classification regions, similar to PlaNet's approach. True GPS location for an image varies by the time it is uploaded, as shown in Figure 1. The image classifier is trained on a mesh of classification regions, with prior distribution for image longitude differing by the time of day an image is posted. The mesh assigns a probability distribution of geo-labels for input imagery using a Delaunay triangle-based structure. The boxplot analysis shows that images posted at 21:00 UTC are typically far from zero longitude compared to those posted at 01:00 UTC. The mesh assigns probability distributions of geo-labels for input imagery using a Delaunay triangle-based structure, which differs from the PlaNet approach. The triangular mesh is deployed to capture water/land interfaces more effectively without the need for additional refinement compared to quadtree meshes. However, the triangular mesh lacks refinement level information present in a structured quad-tree approach. Cells are adaptively controlled to manage mesh refinement. The structured quad-tree approach allows for control over mesh granularity by adaptively refining cells based on the number of examples they contain. Meshes were initialized with a 31 x 31 structured grid, and options for mesh generation are shown in Table 1. The geolocation classification mesh can be adjusted by modifying the refinement level to control the number of cells in each mesh cell. The geolocation classification mesh can be adjusted by modifying the refinement level to control the number of cells in each mesh cell. Table 1 shows the meshing parameters used for three meshes studied in this work, covering a range of mesh structures. Fine P mesh replicates PlaNet's parameters but is not directly comparable due to different methodology and dataset. The classification models in this paper use a coarse mesh and fine mesh structure, with red triangles indicating regions meeting training criteria. The coarse mesh was generated with an early dataset of 2M YFCC100M images. The fine mesh, generated with 14M images, better represents geographic regions like Spain and Portugal's water/land interface. The Inception v4 CNN architecture is used to develop the mesh-based geolocation model (Model M1), differing from PlaNet's Inception v3. Cells are labeled based on the cell centroid, unlike PlaNet's approach. The geolocation model uses a softmax classification similar to PlaNet, but labels cells based on the center-of-mass of training data in each cell. Significant improvements are expected for coarse meshes, especially in high-density population regions. Models are evaluated by calculating the distance between predicted and ground-truth GPS coordinates using great-circle distance. The geolocation model evaluates models by calculating the distance between predicted and ground-truth GPS coordinates using great-circle distance. Error thresholds of 1 km, 25 km, 200 km, 750 km, 2500 km are utilized to represent different localities. Posting time is utilized in model M2. The geolocation model evaluates models by calculating the distance between predicted and ground-truth GPS coordinates using great-circle distance. Posting time is utilized in model M2, where time-dependence is assumed after conditioning on image content. Variables related to time are appended to the output of the geolocation model (M1) to form a new input for M2. Model M3 simultaneously geolocates multiple images from a single user by utilizing a Bidirectional LSTM model to capitalize on correlations within the user's images. All images from a user are organized sequentially in time into albums of size 24, with the research question focusing on the success of this less informative organization compared to topic or location-based organization. During training, a user is limited to a single random album per epoch. Album averaging assigns images in an album to a mesh cell based on highest average probability, increasing accuracy by borrowing information across related images. User images are also location-determined based on maximum average probability. LSTM is utilized for geolocating multiple images from a user. The study explores different approaches for image classification, including user-averaging and LSTM on time-ordered sequences. Mesh cell probabilities are filtered and normalized, with M2 and M3 trained on validation data from M1. Time inputs are concatenated with outputs for a new training step. The sensitivity to mesh adaptation is also investigated. The study investigates meshing parameters to understand sensitivity to mesh adaptation, showing a trade-off between fine and coarse geolocation. Results in TAB1 display improved large granularity geolocation with coarse mesh and better finer-granularities with fine mesh. Comparisons are made between classifying on training data centroid vs. cell centroid, with significant improvement for coarse mesh. The BID20 model is used with indoor-outdoor labels to filter geolocation inference on outdoor imagery without re-training the model. The study used indoor-outdoor labels to filter geolocation inference on outdoor imagery without re-training the model. Results showed a 4-8% improvement in accuracy for region/country localities. The Im2GPS testing data was used to test the model, demonstrating generality in the approach. The M1 classification model performed comparably to BID19 with less training data and classification regions. The M1 classification model performs comparably to BID19 with less training data and classification regions. The coarse mesh M1 model outperforms PlaNet for large regions. Using time improves geolocation accuracy, with a slight gain in accuracy and a measurable difference in error between using time (M2) and not using time (M1). The hypothesis of matched errors for each image is tested with a Wilcoxon-Signed-Test, showing a significant difference in favor of using time-inputs. The distribution of errors is not uniformly shifted, with time input models having lower-bias class probabilities. The median errors for coarse mesh models are 1627 km for M1 and 1262 km for M2. The median errors for coarse mesh models are 1627 km for M1 and 1262 km for M2. Time input models show lower-bias class probabilities. Cross-entropy was optimized in training for both classification model (M1) and time-inputs models (M2) to minimize class biases. KL-Divergence is calculated for each model to compare model output class frequencies to true class frequencies in validation. \"User-Averaging\" is used for more accurate results but biases cell count frequency. The average probability vector method biases cell count frequency, while using albums for prediction reduces bias. LSTMs on user albums had the lowest class bias. Different models were compared at various spatial resolutions, with coarse and fine mesh having different numbers of triangles. Time inputs were concatenated with M1 output, and albums contain 24 images per user. Using time information (M2) improved accuracy in both coarse and fine mesh models. Time of day was found to be a weak addition to Inception-like results but significantly improved geolocation accuracy. Conditioning on latent variables can enhance geolocation models, with time inputs concatenated with M1 output and albums containing 24 images per user. The best observed accuracy is highlighted in bold, with Coarse Mesh and Fine Mesh Best Possible representing the highest achievable accuracy if every image was correctly classified. The use of time information (M2) improved geolocation accuracy in both coarse and fine mesh models. Accounting for indoor/outdoor scenes in images explained variation in validation accuracy, with outdoor-only results outperforming all images. Future work could involve concatenating the probability of an image being outdoor to the input of M2. Increasing grid granularity reduced accuracy at country and regional levels but improved accuracy at street and city levels. Street-level geoinferencing is not practical with a coarse mesh. Increasing grid granularity reduces accuracy at country and regional levels but improves accuracy at street and city levels. Street-level geoinferencing is not practical with a coarse mesh, as shown by the best possible accuracy in Table 6. A fine mesh is expected to perform better for geolocation, especially at larger resolutions. However, there is no explicit proof that a fine mesh should outperform a coarse mesh beyond 25 km resolutions. The study demonstrates that a coarse mesh is superior for 200 km resolutions and using a Delunary triangle-based mesh allows for training accurate models with fewer examples. Images were divided into training and validation sets for models M1, M2, and M3. Softmax classification struggles with large output classes. A training procedure was developed for large models, starting with pre-training on ImageNet and using Adagrad. The number of training examples was increased. The model training approach involved pre-training on ImageNet with Adagrad, increasing training examples each epoch, biasing classes by oversampling minority classes, reducing class bias after each training cycle, and training the final model with SGD using a decreasing learning rate. The learning rate was reduced at 4% with each epoch, without class biasing and with the full dataset per epoch. The initial value of the learning rate varied for each model. M2 is trained using He initializations, Adaboost, and ADAM at different learning rates. Early stopping is used to detect a sustained decrease in validation accuracy. The generality of the M1 classification model is demonstrated by performing a query-by-example on the 2K random Im2GPS dataset. The church was not present in the training data or the 2K random dataset BID6. Each image is assigned a categorical indicator variable. There is a latent class distribution assumed to be constant between training, testing, and application. The last layer output from networks is a softmax model. When comparing models, accuracy is preferred but unbiased models may also be considered. The KL-divergence between q and p should be low if training is done well. Entropy of p and q is also considered for completeness."
}