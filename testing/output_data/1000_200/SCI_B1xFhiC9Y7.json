{
    "title": "B1xFhiC9Y7",
    "content": "Predicting structured outputs like semantic segmentation requires expensive per-pixel annotations for training convolutional neural networks. To address the challenge of generalizing to new domains without annotations, a domain adaptation method is proposed. This method involves learning discriminative feature representations of patches based on label histograms in the source domain and using an adversarial learning scheme to align feature distributions between source and target patches. The framework also includes a global alignment process and achieves state-of-the-art performance on semantic segmentation. Recent deep learning-based methods have shown significant progress in vision tasks like object recognition and semantic segmentation. However, models trained on annotated data often struggle to generalize to new domains. To address this, domain adaptation methods have been developed to bridge the gap between source and target domains. Various techniques, including patch-level alignment and global alignment processes, have been proposed to improve performance on semantic segmentation tasks. Domain adaptation is crucial for pixel-level predictions due to the high cost of annotating ground truth data. Existing methods use feature-level or output space adaptation to align distributions between source and target domains using adversarial learning. Global distribution alignment is typically exploited, but global statistics may differ between domains. In domain adaptation for pixel-level predictions, methods align distributions between source and target domains using adversarial learning. Instead of global alignment, focusing on matching patches that are likely shared across domains is considered to avoid incorrect bias during adaptation. This approach utilizes patch-level information and aligns distributions through adversarial learning, inspired by recent advances in learning disentangled representations. In domain adaptation for pixel-level predictions, methods align distributions between source and target domains using adversarial learning. Inspired by recent advances in learning disentangled representations, the approach focuses on matching patches shared across domains to avoid bias. By learning discriminative representations for patches and aligning patch-level distributions through adversarial modules, the model aims to better align patches between source and target domains. The approach focuses on aligning global and patch-level distributions between source and target domains using adversarial modules. Pixel-level annotations are used to extract patch representations, which are clustered and used to train a classifier for transferring discriminative patch representations. An adversarial loss is further used to address domain gaps. The approach aligns global and patch-level distributions between source and target domains using adversarial modules. An adversarial loss is used to push target patches' feature representations closer to the source patches' distribution. Experiments include synthetic-to-real and cross-city scenarios, with extensive ablation studies to validate the proposed framework. The proposed framework utilizes global and patch-level adversarial learning modules for domain adaptation in structured output prediction. It includes a method for learning discriminative representations guided by label histograms of patches through clustering. The framework outperforms state-of-the-art methods in terms of accuracy and visual quality, and is applicable to other structured outputs such as depth. The proposed framework for domain adaptation in structured output prediction utilizes global and patch-level adversarial learning modules. It includes a method for learning discriminative representations through clustering of patches. The framework outperforms state-of-the-art methods in accuracy and visual quality, and is applicable to other structured outputs such as depth. Domain adaptation approaches align feature distributions between source and target domains for tasks like image classification, using hand-crafted features or deep architectures to learn domain-invariant features. Adversarial learning schemes are commonly used to minimize domain discrepancies. Algorithms use deep architectures to learn domain-invariant features, often through adversarial learning and minimizing Maximum Mean Discrepancy. Variants involve different classifiers and loss functions. Recent work focuses on enhancing feature representations through pixel-level transfer and domain separation. Domain adaptation for structured pixel-level predictions, like semantic segmentation for road-scene images, is less studied. Adversarial networks are used to align global feature representations across domains, with a category-specific prior transferred as a constraint. The CDA method BID36 applies SVM classifier to capture label distributions on superpixels for training the adapted model on the target domain. Class-wise domain adversarial alignment is performed by assigning pseudo labels to target data, with an object prior extracted from Google Street View to aid alignment for static objects. These domain adaptation methods focus on global distribution alignment and class-specific priors to match statistics between domains, but class-level alignment does not preserve structured output. Our framework proposes learning discriminative representations for patches to aid patch-level alignment without requiring additional priors/annotations. Unlike existing methods focusing on global distribution alignment, our algorithm emphasizes learning patch-level representations for better alignment. Learning a latent disentangled space has shown benefits in tasks like facial recognition and image generation. The curr_chunk discusses various approaches for tasks such as facial recognition, image generation, and view synthesis using pre-defined factors to learn interpretable representations of images. These methods focus on learning disentangled graphic codes for rendering 3D images and synthesizing objects based on rotation factors. Additionally, a generative adversarial network with an auxiliary classifier is developed for conditioning on given factors. The proposed research aims to learn discriminative representations for patch-level alignment without additional priors/annotations. The proposed research aims to learn discriminative representations for patch-level alignment in domain adaptation tasks. The framework utilizes label distributions as disentangled factors without the need for pre-defined factors. It includes an adversarial learning scheme to align distributions across domains and uses discriminative representations for patches to aid in the alignment process. The goal is to align the predicted output distribution of target data with the source distribution. The research aims to align the predicted output distribution of target data with the source distribution using supervised and adversarial loss functions. A classification loss in a clustered space is incorporated to learn patch-level discriminative representations from the source output distribution. An adversarial loss is also employed to align patch-level distributions between the source and target data. The task involves utilizing various loss functions to align the target distribution with the source data. This includes supervised loss functions for structured prediction and discriminative representation, as well as clustering processes. Global and patch-level adversarial loss functions are used for alignment, with different weights assigned to each loss function. The baseline model consists of a supervised cross-entropy loss and an output space adaptation module for global alignment. The loss L s can be optimized by a fully-convolutional network G for global alignment. The adversarial loss L g adv is optimized by G and a discriminator D g for binary classification. The min-max problem is then optimized for G and D g. Patch-level alignment with discriminative representations is also discussed. Based on the observation of transferable structured output representations shared across source and target images from smaller patches, a patch-level domain alignment is proposed. Clustering is performed on patches from the source-domain examples using ground truth segmentation labels to construct prototypical patch patterns. The network architecture consists of a generator G and a categorization module H for learning discriminative patch representations. The proposed patch-level alignment involves clustering source-domain patches using ground truth segmentation labels to create prototypical patch patterns. Target domain patches then adapt to this disentangled space by selecting the closest cluster via adversarial objective. Learning discriminative representations without class labels is challenging, but this work utilizes available information effectively. In this work, per-pixel annotations are used to construct a semantically disentangled space of patch representations. Label histograms for patches are utilized as the disentangled factor, with K-means clustering applied to these histograms. A classification module is added after the predicted output to incorporate the clustered space during training the network on source data. During training, a classification module is added to the network to construct a label histogram and learn a discriminative representation. The learned representation is denoted as F_s through the softmax function, where each data point corresponds to a patch of the input image. The learning process involves formulating a cross-entropy loss for patch-level adversarial alignment. The goal is to align target patches to the clustered space in the source domain using an adversarial loss between F_s and F_t. During training, a classification module is added to the network to construct a label histogram and learn a discriminative representation denoted as F_s through the softmax function. The goal is to align patches regardless of their location in the image by reshaping F into K-dimensional vectors concatenated along the spatial map. This reshaped data is denoted as F and used in the adversarial objective with discriminator D_l. The optimization process involves updating discriminator D_g, discriminator D_l, and integrating the adversarial objectives into a min-max problem. During training, a classification module is added to construct a label histogram and learn a discriminative representation denoted as F_s through the softmax function. The optimization process involves updating discriminator D_g, discriminator D_l, and integrating the adversarial objectives into a min-max problem. The optimization alternates between updating discriminator D_g, discriminator D_l, and updating network G and H while fixing the discriminators to push the target distribution closer to the source distribution. During training, the optimization process involves updating discriminator D_g and D_l to push the target distribution closer to the source distribution. The minimization problem combines supervised and adversarial loss functions, enhancing feature representations in G. The discriminator D_g uses fully-convolutional layers with 5 convolution layers. The architecture for the generator G includes 5 convolution layers with kernel size 4 \u00d7 4, stride 2, and channel numbers {64, 128, 256, 512, 1}. A leaky ReLU activation is added after each convolution layer. The discriminator D_l utilizes 3 fully-connected layers with channel numbers {256, 512, 1} and leaky ReLU activation. The generator also incorporates a categorization module H, following the DeepLab-v2 framework with ResNet-101 architecture pre-trained on ImageNet. The proposed architecture includes an adaptive average pooling layer to generate a spatial map with desired receptive fields. It is implemented using PyTorch on a single Titan X GPU. Training details include using the Adam optimizer for discriminators and Stochastic Gradient Descent for the generator. Ablation study on GTA5-to-Cityscapes using ResNet-101 network is conducted with corresponding loss functions. The study conducted an ablation study on GTA5-to-Cityscapes using the ResNet-101 network, with various loss functions and hyperparameters. The proposed framework for domain adaptation in semantic segmentation was evaluated, showing favorable performance compared to state-of-the-art approaches. The study validates the algorithm on GTA5-toCityscapes scenario and compares it against state-of-the-art approaches on benchmark datasets. Domain adaptation is evaluated for semantic segmentation in various scenarios, including synthetic-to-real and cross-city settings. The adaptation includes datasets like GTA5 BID27 to Cityscapes BID5 and Cityscapes to Oxford RobotCar BID23 for rainy scenes. The study evaluates domain adaptation for semantic segmentation in different scenarios, including synthetic-to-real and cross-city settings. It focuses on the GTA5-to-Cityscapes scenario and compares against state-of-the-art approaches on benchmark datasets. An ablation study on the impact of different loss functions and design choices in the proposed framework is conducted, with intersection-over-union (IoU) ratio used as the evaluation metric. The proposed method in Table 1 includes disentanglement, global alignment, and patch-level alignment. Adding disentanglement alone improves performance. Combining global and patch-level alignments achieves the highest IoU at 43.2%. Losses Ld and Ll adv are crucial for patch-level alignment, with a performance drop if either is removed. The importance of losses Ld and Ll adv for patch-level alignment is highlighted, with a performance drop of 1.9% and 1.5% if either is removed. Reshaping features in the clustered space is crucial for effective patch-level alignment, as shown by a 2.4% drop in IoU without this process. Visualization of feature representations using t-SNE confirms the effectiveness of patch-level adaptation. The t-SNE visualization of patch-level features in the clustered space shows effective adaptation, with source/target representations overlapping well. Experimental results compare the proposed method with state-of-the-art algorithms in various scenarios, including synthetic-to-real and cross-city cases. The approach performs favorably against adaptations via feature, pixel-level, and output space alignments. The proposed method improves IoU by 1.8% and achieves the best IoU on 14 out of 19 categories. Results for adapting SYNTHIA to Cityscapes show similar improvements compared to state-of-the-art methods. Visual comparisons are shown in Figure 5, with more results in the appendix. Adapting between real images across different cities and conditions is demonstrated by adapting Cityscapes to Oxford RobotCar. The proposed method improves IoU by 1.8% and achieves the best IoU on 14 out of 19 categories. Results for adapting SYNTHIA to Cityscapes show similar improvements compared to state-of-the-art methods. The weather condition is different in two cities by adapting Cityscapes to Oxford RobotCar. The method often generates segmentation with more details while producing less noisy regions. The domain adaptation method combines global and patch-level alignments for structured output. The proposed method aims to improve semantic segmentation by learning discriminative representations of patches across domains. It involves constructing a clustered space of source patches and using adversarial learning to align target patch distributions with source ones. Extensive experiments validate the effectiveness of the approach under various challenges, showing favorable performance compared to existing algorithms. Training the model in an end-to-end manner involves randomly sampling one image from each domain in a training iteration. The optimization strategy and image/patch sizes during training and testing are detailed in the paper. The model introduces an entropy regularization method to improve target feature representation alignment with source clusters. This approach achieves an IoU of 41.9%, slightly lower than the patch-level adversarial alignment at 43.2%. The model learns discriminative representations by pushing target patches closer to the source distribution. Our model learns discriminative representations for target patches by aligning them with the source distribution in a clustered space guided by label histogram. Results show high similarity between source and target patches, demonstrating the effectiveness of patch-level alignment. Additional qualitative results are provided for different adaptation scenarios in figures 4, 8, 9, 10, and 11. The study provides qualitative results in figures 4, 8, 9, 10, and 11, showcasing the effectiveness of the proposed method in improving segmentation outputs for various adaptation scenarios. In figures 10 and 11, adapted segmentation results are shown for different adaptation scenarios, comparing output space adaptation BID31 with the proposed method."
}