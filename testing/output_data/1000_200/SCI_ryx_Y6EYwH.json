{
    "title": "ryx_Y6EYwH",
    "content": "Survival function estimation, commonly used in medical analytics, faces privacy concerns due to sensitive patient data leakage. A differentially private estimator is proposed to address this issue, providing confidence intervals and test statistics without compromising privacy. The method is extended to estimate competing risk cumulative incidence function. Empirical evidence from clinical datasets shows the proposed method maintains good utility while ensuring strong privacy guarantees. The survival function estimates from patient data can lead to the disclosure of sensitive information, posing privacy risks. This function is used in various domains such as economics, engineering, and healthcare to model time to events. Personal healthcare information is highly sensitive and requires protection. In healthcare, personal information is highly sensitive and protected by law. Information leakage in healthcare is a serious issue. The Kaplan-Meier method is widely used for estimating survival functions in clinical research. Agencies worldwide use the Kaplan-Meier method to report on population survival or disease-related estimates. No model currently offers formal privacy guarantees for survival function estimation using this method. Existing work on perturbation for regression modeling is limited to multivariate models and cannot be directly applied to private survival function estimation. Generative models like differentially private GANs could potentially be used to generate synthetic data for survival function estimation, but GANs may not generalize well. The proposed method offers differential privacy for estimating survival functions based on the Kaplan-Meier method. It guarantees private estimation, extends to provide confidence intervals and test statistics, and can handle small sample sizes and mixed variable types without data pre-processing. The proposed method offers differential privacy for estimating survival functions, including test statistics for comparing survival function between groups. It also extends to estimate competing risk cumulative incidence function with strong privacy guarantees. Empirical evidence from nine clinical datasets shows good utility of the method with R package for accessibility. The survival function models time to event data, like HIV progression to AIDS. The survival function estimates the probability of not experiencing an event by a certain time, accounting for censored observations. Various methods, including parametric and non-parametric approaches like Kaplan-Meier's method, can be used to estimate the survival function. The Kaplan-Meier estimator is a non-parametric method used to estimate the survival function in clinical literature. It defines the survival function based on distinct failure times and the number of failures at each time point. The estimator results in a step function, characteristic of the Kaplan-Meier estimate. Differential privacy provides a provable privacy notion for randomized algorithms. Differential privacy (Dwork et al., 2006) provides provable privacy notion for randomized algorithms. It ensures privacy by making similar input datasets behave similarly. The algorithm preserves (\u03b5, \u03b4)-differential privacy if neighboring datasets only differ in one row. Smaller \u03b5 and \u03b4 values offer stronger privacy guarantees. Post processing is a crucial property for differentially private survival function estimation. Theorem 1 states that differential privacy is immune to post-processing, meaning an adversary cannot increase privacy loss by acting only on the output of a differentially private algorithm. This concept is central to the approach of ensuring differentially private estimation of the survival function using the Kaplan-Meier method. The method allows for estimating various statistics in a differentially private manner, such as confidence intervals and comparison test statistics. Using a simple approach, it is possible to estimate various statistics differentially privately without extra privacy budget. Notations introduced in Section 2.1 include a vector of time points (t j), number of subjects at risk (r j), and number of subjects experiencing the event (d j). Creating a dataset matrix M with event and at-risk data for each unique time point, noise matrix Z is drawn from Laplace distribution with privacy parameter . Algorithm 1 presents a method for creating a differentially private version of a matrix M by adding noise from a Laplace distribution. The procedure is simple and requires minimal changes to the original estimation process, making it easily implementable with existing software packages. There is no computational overhead compared to the original estimation. Algorithm 1 introduces a method for achieving differential privacy in matrix M by adding Laplace noise, with no additional computational cost. The formal privacy guarantees and extension possibilities are discussed, along with the global L 1 sensitivity of the method. The algorithm is proven to be -differentially private. Theorem 2 proves that Algorithm 1 is -differentially private by adding Laplace noise to matrix M. The approach can easily be extended to include other essential statistics like confidence intervals and test statistics while maintaining privacy guarantees. The extensions with privacy guarantees for survival function estimates include confidence intervals and test statistics for group comparison, such as in clinical trials. Confidence intervals are calculated point-wise at discrete time-points where events are observed. It is essential to provide differentially private counterparts for both confidence intervals and test statistics. The calculations for obtaining confidence intervals for survival function estimates are differentially private. Greenwood's linear-point-wise confidence intervals are commonly used, and by replacing them with their differentially private counterparts, the confidence intervals become differentially private as well. Using differentially private methods in conjunction with survival function estimates allows for the calculation of differentially private confidence intervals without additional privacy cost. This includes hypothesis testing using the Logrank test, which is also shown to be differentially private. Using Algorithm 6, the Logrank test for hypothesis testing is proven to be -differentially private. The test statistic Z is made differentially private by replacing sensitive information with their private counterparts. This ensures privacy without adding to the overall privacy budget. The Logrank test for hypothesis testing is proven to be differentially private using Algorithm 6. The calculation on differentially private data does not affect the overall privacy budget. Competing events, such as death in clinical data, require specialized estimates like competing risk cumulative incidence to avoid biased estimates. Using Algorithm 1, differential privacy can be extended to competing risk scenarios. The Competing risk cumulative incidence is proven to be -differentially private. This estimate extends the Kaplan-Meier estimator and includes statistics like confidence intervals, hazard function, and hazard ratios. The differentially private extension of the Nelson-Aalen estimate of the cumulative hazard is obtained using Algorithm 1. The method is empirically evaluated on nine real-life clinical datasets with time to event information. Dataset details are provided in Table 1. Our proposed method is evaluated on nine real-life clinical datasets with time to event information. Dataset details are provided in Table 1. We compare our differentially private approach to the original non-private version to assess utility and credibility. The evaluation includes estimation of the differentially private survival function and extensions. The evaluation of our proposed method on nine real-life datasets shows that our privacy-preserving estimation of the survival function faithfully estimates the original function with little utility loss. The estimation deteriorates with increased privacy budget, but our method provides good utility while protecting privacy. Small sample sized datasets perform worse compared to larger datasets. Our differentially private estimation method shows good utility in protecting privacy, with larger datasets performing better than smaller ones. For small datasets, adding large noise is necessary for privacy protection, leading to decreased utility. However, moderate to medium-sized datasets yield good results even in high privacy regimes. Median survival time and confidence intervals are important estimates often reported with survival functions. The method shows good utility in protecting privacy, with larger datasets performing better. Median survival time and confidence intervals are important estimates reported with survival functions. The results in Table 2 show high precision in estimating the median survival, even in high privacy regimes. The estimation performs at par with the original non-noisy estimation, with increasing dataset size improving precision. In Table 2, our differentially private estimation performs similarly to the original non-noisy estimation, even in high privacy regimes. The test statistic (Z) follows a \u03c72 distribution with one degree of freedom, and none of the private estimates change the statistical significance threshold. Results for cumulative incidence using new datasets with competing risk information are consistent, showing good utility while protecting privacy. Detailed results are available in the Appendix. The intersection of statistical modeling and differential privacy has seen significant research, with various methods proposed for regression modeling. Differentially private generative models, like differentially private generative adversarial networks, have also been introduced. However, these approaches have limitations and are not suitable for direct differentially private estimation of the survival function. The first method for differentially private estimation of the survival function has been proposed, showing its extension to other statistics. Extensive evaluation on real-life datasets demonstrates a good privacy-utility trade-off. The datasets used for evaluation include data on survival in patients with advanced lung cancer. The dataset includes information on survival in patients with advanced lung cancer, leukemia patients, kidney patients using portable dialysis equipment, and subjects with monoclonal gammopathy of undetermined significance. Time is converted into months, and groups compared include males and females, control and treatment groups, and whether maintenance chemotherapy was given or not. The dataset includes survival information for various medical conditions such as advanced lung cancer, leukemia, kidney patients on portable dialysis, and monoclonal gammopathy of undetermined significance. Time is measured in months, with comparisons between different treatment arms or groups. The curr_chunk discusses the use of differentially private estimation in competing risk scenarios using two datasets related to liver transplants. The results show that the differentially private extension performs well in estimating competing risks. The differentially private extension performs well in estimating competing risk cumulative incidence functions, providing strong privacy guarantees. The algorithm is -differentially private, with good estimation results shown in the plots. Our method effectively estimates competing risk cumulative incidence with strong privacy guarantees, as shown in the plots. The survival function estimation is differentially private, utilizing only the data from M."
}