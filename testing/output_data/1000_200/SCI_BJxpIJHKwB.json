{
    "title": "BJxpIJHKwB",
    "content": "Few shot image classification involves learning a classifier from limited labeled data. Attentive Weights Generation for few shot learning via Information Maximization (AWGIM) addresses the challenge of generating exact and universal classification weights for diverse query samples with very few training samples. AWGIM generates different classification weights for each query sample by allowing them to attend to the entire support set. This approach maximizes the lower bound of mutual information between the generated weights and query as well as support data, making it a novel contribution in the field. AWGIM maximizes mutual information between generated weights and query/support data in few shot learning, achieving state-of-the-art performance. Deep learning methods require large labeled data, while humans can learn from limited data. Few shot learning enables deep models to learn from very few samples. Meta learning is a popular approach for few shot learning, where models extract high-level knowledge across tasks to quickly adapt to new tasks. Different methods like gradient-based and metric-based are used, with weights generation showing effectiveness. In this work, Attentive Weights Generation for few shot learning via Information Maximization (AWGIM) is introduced to address limitations in weights generation methods for different tasks. AWGIM generates classification weights specifically for each query sample by utilizing two encoding paths where the query sample attends to the task context. Simple cross attention between query samples and support set is shown to be insufficient in guaranteeing classification weights fitted to diverse query data, leading to the proposal of a new method. AWGIM proposes to maximize mutual information between generated weights and query, support data in few shot learning. It introduces Variational Information Maximization and eliminates inner update while maintaining performance. AWGIM outperforms existing methods on benchmark datasets and its components are validated through detailed analysis. In few-shot learning, various methods have been developed, including gradient-based approaches and metric-based methods that learn similarity metrics between query and support samples. Some works also consider spatial information or local image descriptors to compute richer similarities. Various methods have been developed for few-shot classification, including generating classification weights directly and using graph neural network denoising autoencoders. Some works also utilize generative models to generate more data. In few-shot classification, generative models and attention mechanisms are utilized to predict query class labels. Attention is effective in modeling interactions between queries and key-value pairs, distinguishing between self and cross attention. This work incorporates both types of attention to encode task and query-task information, similar to Attentive Neural Processes. In few-shot image classification, attention mechanisms are used to encode task and query-task information. The approach focuses on maximizing mutual information, contrasting with regression methods that optimize variational objectives. Mutual information measures the decrease in uncertainty of one variable when another is known, with applications in generative models. Mutual information is maximized in applications like Generative Adversarial Networks and self-supervised learning. The attentive path equips query samples with task knowledge using an attention mechanism. Weight generator g generates classification weights specific for x, maximizing mutual information and forcing g to be sensitive to different query samples. The proposed model maximizes mutual information between two networks, r1 and r2, to generate classification weights sensitive to different query samples. The problem formulation, model description, objective function, and theoretical analysis are provided. The problem is formulated under episodic training paradigm for few-shot classification tasks. Support set contains labeled samples, while the query set requires predicting labels based on the support set. Meta-loss is estimated on the query set during meta-training to optimize the model. During meta-training, the model optimizes the meta-loss on the query set to adapt quickly to novel tasks. The proposed approach follows a framework for generating classification weights, with a focus on feature extraction and task-specific weight generation methods like Latent Embedding Optimization (LEO). Latent Embedding Optimization (LEO) is a weight generation method related to the framework for generating classification weights during meta-training. In LEO, a latent code z is generated by h conditioned on the support set S, and classification weights w can be decoded from z. The objective function of LEO involves updating the latent code z to generate new classification weights w for the query set Q. LEO avoids updating high-dimensional w by learning a lower-dimensional latent space from which z can generate w. Unlike AWGIM, LEO does not require inner updates to adapt the model. AWGIM maximizes mutual information for task adaptation, while LEO generates fixed weights based on the support set. LEO can be seen as a special case of AWGIM under certain conditions. The framework includes a feature extractor processing images in the sampled task T. The feature extractor processes images in the sampled task T using a Convnet or Resnet to generate d-dimensional vectors. Two paths, contextual and attentive, encode task context and query samples. Classification weights are generated to predict labels and maximize mutual information. The contextual path focuses on learning representations for the support set with a multi-head self-attention network. The contextual path focuses on learning representations for the support set with a multi-head self-attention network. Existing weights generation methods may be sub-optimal as they are conditioned on the support set only. Introducing the attentive path allows individual query examples to attend to the task context for generating classification weights. This addresses the issue of lack of adaptation to different query samples. The attentive path introduces a new multi-head self-attention network to encode global task information and generate adaptive classification weights for different query samples. This network differs from the contextual path by providing value context for query samples to attend to in cross attention. Sharing the same self-attention networks between paths may limit the expressiveness of learned representations. The cross attention network is applied to each query sample and task-aware support set to produce Xap. The cross attention network is applied to each query sample and task-aware support set to produce Xap. Multi-head attention is used to learn more comprehensive representations. Xcp and Xap are replicated and concatenated to form Xcp\u2295ap, allowing each query sample to have its own latent representations for generating specific classification weights. The classification weights for each query sample are generated based on task-context and adapt to individual samples. The weights follow a Gaussian distribution, sampled during meta-training. The prediction for query data is computed using the sampled weights. Support data is replicated and reshaped for prediction. The prediction for query data is computed using the generated weights. Support data is replicated and reshaped for prediction. Two decoders reconstruct Xcp and Xap. Reconstruction is used as auxiliary tasks. The weights are query-specific due to attentive and contextual paths. The weights generated from attentive and contextual paths are not sensitive to different query samples. To address this, the mutual information between the weights and support/query data is maximized. Directly computing this mutual information is intractable due to true posterior distributions. The mutual information between weights and support/query data is maximized by using Variational Information Maximization to compute a lower bound. This approach approximates the true posterior distributions, allowing for the maximization of the lower bound as a proxy for the true mutual information. Equation 7 simplifies the objective function by maximizing the log likelihood of labels for support and query data, minimizing cross entropy. Gaussian distributions are assumed for p \u03b8 (x|w) and p \u03b8 (x|w), with r 1 and r 2 approximating their means. The loss function includes terms for reconstructing x cp and x ap with L2 loss, with hyper-parameters \u03bb 1 , \u03bb 2 , \u03bb 3 for balancing different terms. The generated classification weights are influenced by the support data through the last three terms. The generated classification weights in the proposed method are influenced by the support data and specific query samples through hyper-parameters \u03bb 2 and \u03bb 3. The inner update loss in LEO is computed as cross entropy on support data, while the weight generation in LEO does not involve specific query samples, making reconstruction impossible. LEO can be seen as a special case of the proposed method with only a contextual path and \u03bb 2 = \u03bb 3 = 0. The computational complexity of the encoding process in the contextual path is O((N K) 2), and for the attentive path, it is O((N K) 2 + |Q|(N K)), resulting in a total complexity of O((N K) 2 + |Q|(N K)). AWGIM has a computational complexity of O((N K) 2 + |Q|(N K)), with the value of (N K) 2 usually negligible. The cross attention can be implemented parallelly, reducing computational overhead. Inner updates are avoided without compromising performance, reducing training and inference time significantly. Experiments on miniImageNet and tieredImageNet datasets show the model's effectiveness compared to other methods. The miniImageNet dataset contains 100 classes with 600 images each, split into meta-training, meta-validation, and meta-testing sets. tieredImageNet is larger with 608 classes and 779,165 images, divided similarly. Image features from LEO are used, represented by a 640-dimensional vector for input to the model in N-way K-shot experiments. The miniImageNet dataset contains 100 classes with 600 images each, split into meta-training, meta-validation, and meta-testing sets. For N-way K-shot experiments, image features are represented by a 640-dimensional vector. During meta-testing, tasks are sampled and the average accuracy for the query set is reported. TensorFlow is used for implementation, with specific parameters set for feature embeddings and MLPs. The number of heads in the attention module is set to 4, with specific parameters for MLPs. Different models like Meta LSTM, Prototypical Nets, Relation Nets, SNAIL, TPN, MTL, Dynamic, Prediction, DAE-GNN, LEO, and AWGIM are compared for accuracy on various datasets. Accuracy comparison of different models on tieredImageNet shows that AWGIM outperforms other approaches with 63.12% accuracy in 5-way 1-shot and 78.40% accuracy in 5-way 5-shot tasks. MetaOptNet Resnets is used for optimization with specific parameters, and the model is trained for 50,000 iterations with varying batch sizes. The model is trained for 50,000 iterations with batch sizes of 64 for 5-way 1-shot and 32 for 5-way 5-shot tasks. The performance of AWGIM is compared with other methods on tieredImageNet and miniImageNet datasets. The results are presented in Table 1 and 2, along with the backbone network structure used for feature extraction. The results on miniImageNet and tieredImageNet are shown in Table 1 and 2, displaying various meta learning categories and classification weights generation approaches. AWGIM outperforms all methods in the top parts of the tables and remains competitive in the bottom part. It shows the best performance on tieredImageNet and is close to the state-of-the-art on miniImageNet. All methods use WRN-28-10 as the backbone network for fair comparison. AWGIM outperforms LEO in all settings on miniImageNet using WRN-28-10 as the backbone network. The analysis in Table 3 shows the effectiveness of AWGIM, with a comparison to LEO and ablation analysis of different components. The classification weights are shuffled randomly to demonstrate their optimality for different query samples. The results of LEO are included for reference, with a focus on the effect of the attentive path and different generators. The effect of attentive path is investigated by implementing two generators conditioned on support set. \"Generator conditioned on S only\" achieves similar results to \"Generator in LEO\" without inner update. Self-attention is found to be no worse than relation networks in LEO. Information maximization helps the generator perform slightly better than LEO. Attention modules are replaced with 2-layer MLPs in \"MLP encoding\" to encode support and query samples. Even without attention, the MLP encoding shows promising results. The importance of maximizing information in \"MLP encoding\" is highlighted, showing that without attention, it can achieve accuracy close to LEO. Ablation analysis on \u03bb 1 , \u03bb 2, and \u03bb 3 demonstrates the significance of information maximization. When \u03bb 1 = \u03bb 2 = \u03bb 3 = 0, performance drops significantly, emphasizing the need to maximize information. Maximal mutual information between weights and support is crucial, as shown by the degradation in accuracy when \u03bb 1 = \u03bb 2 = 0. In AWGIM, the importance of maximizing mutual information between weights and support is emphasized. The classification weights are tailored for each query sample, and shuffling them between samples and classes is done to study their adaptability. In AWGIM, the focus is on maximizing mutual information between weights and support. Shuffling classification weights between samples and classes reveals adaptability. For 5-way 1-shot experiments, random shuffle between classes reduces accuracy, while shuffle in class has minimal impact. With more labeled data, shuffling results converge in 5-way 5-shot experiments, indicating diverse and specific classification weights for each query sample. In this work, Attentive Weights Generation via Information Maximization (AWGIM) is introduced for few-shot image classification. AWGIM learns to generate optimal classification weights for each query sample by maximizing mutual information between the generated weights and query, support data. This approach demonstrates state-of-the-art performance on benchmark datasets and utilizes mutual information techniques for few-shot learning. AWGIM is a method for few-shot image classification that generates optimal classification weights for query samples by maximizing mutual information with support data. It achieves state-of-the-art performance on benchmark datasets through multi-head attention and cross-attention mechanisms. During meta-training, AWGIM generates weights for query samples by sampling from a Gaussian distribution. For few shot regression tasks, the number of classes is set to 1 and cross entropy loss is adapted to mean square error. The tasks involve sinusoidal or linear regression with a three layer MLP. The study compares the performance of multi-head attention and single-head attention in sinusoidal regression tasks. Results show that multi-head attention improves performance, especially when data is scarce. AWGIM is compared to LEO in terms of convergence speed, with AWGIM showing faster convergence and outperforming LEO. AWGIM converges faster than LEO and outperforms it, except for the initial iterations. Inference time of AWGIM shows minimal computational overhead compared to using \"MLP encoding\" with time complexity O(N K + |Q|). Experiments on miniImageNet with batch size 64 show negligible overhead of self-attention and cross attention in AWGIM compared to MLP encoding. Visualization of classification weights by t-SNE is also conducted. Visualization of classification weights by t-SNE is conducted to compare the generated weights for different query samples. The decoded weights for each class are clustered closer together, showing that the generator can adapt weights effectively. The generator can adapt weights effectively for different query samples, as shown in t-SNE visualization. Query samples from different classes have distinct classification weights."
}