{
    "title": "ryg7jhEtPB",
    "content": "The importance weighted autoencoder (IWAE) is a variational-inference method that achieves a tighter evidence bound by optimizing a multi-sample objective. This method relies on reparametrizations and deals with breakdowns in inference-network gradients as the number of Monte Carlo samples increases. Different approaches, such as 'sticking-the-landing' IWAE (IWAE-STL) and 'doubly-reparametrised' IWAE (IWAE-DREG), have been proposed to address this issue. The importance weighted autoencoder (IWAE) method aims to optimize the proposal distribution in importance sampling, introducing an adaptive-importance sampling framework called AISLE. This framework generalizes the reweighted wake-sleep (RWS) algorithm and includes IWAE-STL and IWAE-DREG as special cases. The generative model p \u03b8 (z, x) = p \u03b8 (z)p \u03b8 (x|z) is used to model observations x and latent variables z, leading to the marginal likelihood p \u03b8 (x) = Z p \u03b8 (z, x) dz. In this work, algorithms for variational inference are analyzed, aiming to learn the generative model and construct a tractable variational approximation. The presentation focuses on a single latent representation-observation pair and assumes no shared parameters between the generative model and the variational approximation. The presentation focuses on algorithms for variational inference, assuming no shared parameters between the generative model and the variational approximation. Two main classes of stochastic gradient-ascent algorithms for optimizing parameters have been proposed, including IWAE-DREG and RWS. The RWS algorithm optimizes two separate objectives for \u03b8 and \u03c6 using self-normalized importance sampling with K particles. RWS is an adaptive importance-sampling approach that improves its proposal distribution while optimizing \u03b8 via stochastic approximation. The IWAE is popular but suffers from \u03c6-gradient breakdown, while the IWAE-STL gradient performs well despite lacking theoretical support. In this work, it is shown that directly optimizing the proposal distribution, as done by RWS, is preferable to optimizing the IWAE multi-sample objective. The IWAE suffers from \u03c6-gradient breakdown and exhibits inferior empirical performance compared to RWS. Modifications of the IWAE \u03c6-gradient that avoid this breakdown can be justified in a more principled manner by taking an adaptive importance-sampling view. Our work formalizes the argument that reparametrizations can make IWAE inferior to RWS, especially for discrete latent variables. We introduce the AISLE framework, a generalization of RWS, which encompasses IWAE-DREG and IWAE-STL gradients. This framework allows for the derivation of various gradient estimators in a principled manner, ensuring non-degeneracy as K approaches infinity. Our work establishes connections between different gradient estimators, showing that IWAE-STL and IWAE-DREG gradients can be derived from the AISLE framework. This provides a theoretical foundation for IWAE-STL and clarifies the scaling of the learning rate for the IWAE \u03c6-gradient. AISLE admits the IWAE-DREG gradient as a special case without the need to scale the learning rate with K. It leads to a new family of gradient estimators for \u03b1-divergences and provides insights into the impact of self-normalization bias on importance-sampling based gradient approximations. The focus is not on deriving new algorithms but on comparing existing ones. The focus of the work is not to derive new algorithms but to compare existing ones empirically on Gaussian models. The shorthand notation p(f) is used to suppress dependence on observations, and expectations of test functions can be estimated using self-normalised importance sampling estimators. The importance weighted autoencoder (IWAE) aims to maximize a lower bound on the log-marginal likelihood by finding optimal generative-model parameters \u03b8 and inference-network parameters \u03c6. The self-normalised estimate may not be unbiased but its bias vanishes at a rate of O(K^-1) under certain assumptions. The IWAE maximizes a lower bound on the log-marginal likelihood by optimizing inference-network parameters \u03c6 and generative-model parameters \u03b8. The bound tightens with optimization of \u03c6, and for K > 1, IWAE extends VAE on an auxiliary-variable space. The IWAE objective's gradient can be approximated using a vanilla Monte Carlo approach. The IWAE objective's gradient can be approximated using a vanilla Monte Carlo approach, but this approximation often has high variance. To address this, the reparametrisation trick is employed, requiring a specific assumption. The IWAE then utilizes a Monte Carlo estimate, and a lemma is stated to generalize a well-known identity. The IWAE gradient relies on reparametrisations to reduce high variance. However, drawbacks include the need for additional implementation and computation costs, as well as a vanishing signal-to-noise ratio in the \u03c6-gradient. The IWAE gradient addresses high variance but faces challenges like vanishing signal-to-noise ratio. Modifications have been proposed to stabilize signal-to-noise ratio and achieve zero variance. IWAE-STL and IWAE-DREG are two proposed gradients with different approaches. The IWAE-DREG gradient proposed by Tucker et al. (2019) removes score-function terms through Lemma 1, allowing for simultaneous optimization of both \u03b8 and \u03c6 gradients. The RWS algorithm by Bornschein & Bengio (2015) approximates intractable quantities using self-normalized importance sampling, with a bias of order O(1/K) discussed in Appendix A. The RWS algorithm approximates intractable quantities using self-normalized importance sampling, with a bias of order O(1/K). The optimization of both \u03b8 and \u03c6 is carried out simultaneously, allowing for shared particles and weights. The lack of a joint objective for both \u03b8 and \u03c6 is seen as a drawback. The simultaneous optimization of \u03b8 and \u03c6 allows for reusing Monte Carlo samples and typically reduces error in gradient approximation. The RWS algorithm uses self-normalized importance sampling to approximate intractable quantities with a bias of order O(1/K). Optimizing both \u03b8 and \u03c6 simultaneously allows for shared particles and weights, reducing error in gradient approximation. Alternative techniques for adapting the proposal distribution q \u03c6 exist, such as minimizing the \u03c7 2 -divergence. The RWS-objective is generalized as \u03b8 := arg max \u03b8 log Z \u03b8 , \u03c6 := arg min \u03c6 D\u0192(\u03c0\u03b8 q \u03c6 ), where D\u0192(p q) is some \u0192-divergence from p to q. The unified framework presented in this work introduces the adaptive importance sampling for learning (AISLE) algorithm, which provides robust \u03c6-gradient estimators that do not degenerate as K \u2192 \u221e. Optimization is carried out using stochastic gradient ascent. The \u03b8-gradient is consistent across all algorithms discussed, with IWAE considering it an unbiased gradient of a biased lower-bound to the evidence, while AISLE interprets it as a self-normalized importance-sampling approximation of the gradient \u2207 \u03b8 log Z \u03b8 for the 'exact' objective. The AISLE algorithm introduces robust \u03c6-gradient estimators for learning, with optimization using stochastic gradient ascent. The \u0192-divergences used in variational inference allow for optimization without knowledge of Z \u03b8. The integral in the expectation with respect to \u03c0 \u03b8 can be expressed as Z. The AISLE algorithm introduces robust \u03c6-gradient estimators for learning without relying on knowledge of Z \u03b8. The integral in the expectation with respect to \u03c0 \u03b8 can be approximated using self-importance sampling, leading to reparametrised estimators in various cases. Using reparametrisation, Equation (13) yields the gradient for IWAE-STL, which can be derived from AISLE without the need for a multi-sample objective. Proposition 1 provides a theoretical basis for IWAE-STL, showing that it is unbiased and can achieve zero variance. This result challenges previous beliefs about IWAE-STL and suggests that its good empirical performance is not due to the breakdown of other methods like RWS. The breakdown of RWS may not be due to a lack of optimizing a joint objective as previously thought. AISLE-KL can potentially reduce bias and variance by approximating the exact RWS gradient. The \u03b1-divergence between two distributions can be expressed in terms of \u03ba and f(y). The \u03b1-divergence between two distributions can be expressed in terms of \u03ba and f(y). Minimizing this divergence is natural in importance sampling. AISLE-\u03b1-NOREP and AISLE-\u03b1 provide methods for optimizing without reparametrization. IWAE-DREG can be derived from AISLE in a principled manner. AISLE-\u03c7 2 can be derived from AISLE in a principled manner without the need for a multi-sample objective. The learning rate needs to be scaled as O(K) for IWAE or IWAE-DREG \u03c6-gradients. The 'exclusive' KL-divergence can lead to faster convergence of \u03c6 than the 'inclusive' divergence. The 'exclusive' KL-divergence proposed in Roeder et al. (2017, Equation 8) can lead to faster convergence of \u03c6 than the 'inclusive' divergence. However, minimizing the exclusive divergence may negatively affect learning of \u03b8. The adaptive-importance sampling paradigm of reweighted wake-sleep (RWS) is preferred over the multi-sample objective paradigm of importance weighted autoencoders (IWAEs) due to achieving the same goals while avoiding drawbacks. The self-normalisation bias in RWS/AISLE involves the number of particles, K, affecting the accuracy of estimators \u2207aisle-kl \u03c6 \u03b8, z and \u2207aisle-\u03c72 \u03c6 \u03b8, z. As K increases, the estimators become more accurate, while for K=1 they reduce to vanilla Monte Carlo approximations. This is similar to the standard IWAE \u03c6-gradient, which also becomes a vanilla Monte Carlo approximation when K=1. The self-normalisation bias in RWS/AISLE involves the number of particles, K, affecting the accuracy of estimators. As K increases, the estimators become more accurate, while for K=1 they reduce to vanilla Monte Carlo approximations. Similarly, the standard IWAE \u03c6-gradient also becomes a vanilla Monte Carlo approximation when K=1. The small-K self-normalisation bias of reparametrisation-free AISLE \u03c6 gradients is challenging to characterize, but it may favor minimizing the exclusive KL-divergence. The main motivation for using IWAEs over VAEs is the ability to reduce bias in the \u03b8-gradient by using self-normalised importance-sampling approximations with K > 1 particles. The error of importance-sampling approximations can be controlled by ensuring that the proposal distribution q \u03c6 is close to the target distribution \u03c0 \u03b8. The family of proposal distributions Q should be flexible enough to contain a distribution q \u03c6 that is approximately equal to \u03c0. The family of proposal distributions Q should be sufficiently expressive to contain a distribution q \u03c6 close to the target distribution \u03c0 \u03b8. If Q is not flexible enough and all its members are far from \u03c0 \u03b8, minimizing the exclusive KL-divergence could result in poorly-behaved importance weights. In such cases, optimizing \u03c6 to minimize KL(\u03c0 \u03b8 q \u03c6) is recommended. In Scenario 1, a gradient-descent algorithm minimizing exclusive divergence may be preferable for flexible Q. It can lead to faster convergence with a smaller number of particles, K, due to self-normalization bias. Setting K=1 for \u03c6-gradients approximation is not always optimal, as increasing K is still desirable for faster convergence. Increasing the number of particles, K, is desirable to reduce variance in gradient approximations even in an ideal scenario. Utilizing all K particles and weights for gradient approximation is important to avoid wastefulness. Setting K=1 may lead to suboptimal gradient estimates in certain scenarios. In the supplementary materials, different \u03c6-gradient estimators are compared for AISLE, based on KL-divergence and \u03c72-divergence, with and without reparametrization. These gradients do not achieve zero variance even if q\u03c6 = \u03c0\u03b8. The gradient for AISLE based on the \u03c72-divergence after reparametrising and exploiting the identity from Lemma 1 is proportional to IWAE-DREG from Tucker et al. (2019). The gradient for IWAE employing the reparametrisation trick from Kingma & Welling (2014) has a signal-to-noise ratio that degenerates with K. IWAE-DREG is a 'doubly-reparametrised' IWAE gradient. The 'doubly-reparametrised' IWAE gradient from Tucker et al. (2019) is proportional to AISLE-\u03c72. The joint law of observations and latent variables factorises, with a fully factored Gaussian proposal distribution for optimization. The parameters to optimize are denoted by a column vector. The proposal distributions are fully factored Gaussians with parameters to optimize denoted by a column vector. The mean of the proposal coincides with the mean of the posterior under certain conditions. This model allows for correlated latent vectors in the generative model, unlike previous benchmarks. In a more realistic scenario, latent vectors can be correlated in the generative model. The variational approximation, however, remains fully factored and may not capture uncertainty about the latent variables effectively. The 'score-function free' \u03c6-gradients achieve near-zero variance for proposal mean parameters when variance parameters are optimal. The text discusses the benefits of reparametrization-trick gradients in Gaussian settings and compares algorithms for varying numbers of particles and model dimensions. The algorithms share the same \u03b8-gradient, focusing on the optimization of \u03c6 while fixing \u03b8. The results are based on 100 repetitions with new synthetic data sets. The text discusses the optimization of \u03c6 in Gaussian settings with reparametrization-trick gradients. Two scenarios are presented with different generative models, showing how the variational approximation may not fully mimic the dependence structure of latent variables. The gradient-ascent algorithm is initialized with values drawn from a standard normal distribution. The gradient-ascent algorithm is used to optimize \u03c6 in Gaussian settings with reparametrization-trick gradients. Initial values are drawn from a standard normal distribution, and different optimization methods like stochastic gradient-ascent and ADAM are employed. The total number of iterations is 10,000 with learning-rate parameters adjusted at each step. The covariance matrix is not diagonal, and logarithmic scaling is applied on the second axis."
}