{
    "title": "rygZJ2RcF7",
    "content": "Neural networks struggle to generalize transformations outside of their training data. A new technique called neuron editing aims to address this by learning how neurons encode transformations in a latent space, allowing for complex transformations with simpler distribution shifts. This technique is showcased in image domain/style transfer and biological applications. The proposed neural network-based method aims to model the effect and potential interactions of treatments in biological experiments, allowing for generalization beyond the measured samples. This technique utilizes neuron editing in a latent space to encode complex transformations with simpler distribution shifts to neuron activations. It is demonstrated in image domain/style transfer and biological applications such as removing batch artifacts and predicting drug synergy. The neural network-based method proposes learning a general edit function for treatment in biological settings using neuron editing in the latent space of an autoencoder neural network. This approach aims to generalize treatment effects beyond measured samples by transforming data distributions. Neuron editing involves extracting differences between pre-and post-treatment activation distributions in the latent space of an autoencoder neural network. This allows for the generation of post-treatment data by applying these differences to pre-treatment data from the rest of the population. Neuron editing in the latent space of an autoencoder neural network enables complex distribution-to-distribution transformations between large samples in high-dimensional space. Autoencoders perform non-linear dimensionality reduction to simplify effects into computationally efficient shifts in distribution. Neuron editing in the latent space of an autoencoder neural network allows for complex transformations between data distributions. Editing in the internal layer captures context dependence, with some neurons showing drastic changes post-treatment. Low-dimensional editing enables modifications on a denoised data version, retaining significant dimensions through bottleneck layers. Neuron editing in the hidden layer of an autoencoder neural network allows for precise transformations between data distributions. By focusing on significant dimensions and avoiding noise, this editing approach demonstrates better extrapolation capabilities compared to generative models. Neuron editing in hidden layers of neural networks outperforms generative models in extrapolation. It produces more accurate predictions on extrapolated data and generates more complex variations by preserving existing data variations. Comparisons with traditional GANs and CycleGAN show the limitations of generation-based approaches in meeting these criteria. Neuron editing in hidden layers of neural networks outperforms generative models in extrapolation by preserving data variations and producing accurate predictions. It is motivated by the limitations of traditional GANs and CycleGAN in meeting these criteria. The method seeks a transformation that aligns source and target distributions while maintaining the identity function on the target. Neuron editing in hidden layers of neural networks outperforms generative models in extrapolation by aligning source and target distributions while maintaining the identity function on the target. A transformation is defined in a learned space using an encoder/decoder pair to map data into an abstract neuron space with high-level features. Piecewise linear transformation called NeuronEdit is applied to distributions of activations from internal layers of the network for inputs from S and T. NeuronEdit is a piecewise linear transformation applied to distributions of activations from internal layers of neural networks for inputs from S and T. It operates on distributions represented via activations over network input samples, transforming them based on the difference between the source and target distributions. The function exhibits properties similar to a GAN generator, ensuring alignment between the source and target distributions while maintaining piecewise linearity. The NeuronEdit function, resembling a GAN generator, transforms neuron activations from source distribution S to extrapolation distribution X. This transformation is applied without further training, turning an autoencoder into a generative model that does not strictly adhere to the identity function. Neuron editing transforms neuron activations from source distribution S to extrapolation distribution X, turning an autoencoder into a generative model. Training a GAN in this setting exclusively utilizes data in S and T, while neuron editing models the intrinsic variation in X unsupervised. GANs are difficult to train due to oscillating optimization dynamics, uninterpretable losses, and mode collapse where the discriminator struggles to detect differences in variability between real and fake examples. Neuron editing avoids mode collapse in GANs by learning an unsupervised model of the data space with an autoencoder. It isolates the variation in neuron activations to generate convincing entire distributions of the post-transformation output. This approach is related to word2vec embeddings in natural language processing. Neuron editing involves isolating the variation in neuron activations to transform entire distributions, similar to word2vec embeddings in natural language processing. It is compared to other generating methods like regularized autoencoder, GANs, ResnetGAN, and CycleGAN in terms of editing capabilities. The regularized autoencoder, GANs, ResnetGAN, and CycleGAN were compared in terms of editing capabilities. The regularized autoencoder used maximal mean discrepancy to penalize differences in distributions. Training involved convolutional layers for image experiments and fully connected layers for other models. A motivational experiment on CelebA dataset illustrated limitations in generative models when mapping between different image sets. The limitations of generative models in mapping between different image sets are illustrated in a motivational experiment on the CelebA dataset. GAN models struggle to successfully transform out-of-sample data, often generating artifacts and inconsistent results, highlighting the benefits of stable training methods like autoencoders for editing tasks. The benefits of stable training methods like autoencoders for editing tasks are highlighted due to the difficulty in training generative models. Neuron editing allows for complex transformations in neural networks, such as changing hair color, to be decomposed into simpler shifts. Another application is batch correction to address differences in data caused by technical artifacts, a common issue in biological experimental data. Batch effects are a common problem in biological experimental data, leading to incorrect conclusions or preventing data combination. One method to address this is by repeatedly measuring a control set of cells with each sample and correcting based on the control variation. This approach was applied to a mass cytometry experiment dataset to remove measurement-induced variation. The dataset investigated in this section is from a mass cytometry experiment measuring protein levels in cells of individuals infected with dengue virus. The data includes 35 dimensions with different observations for Control1, Control2, Sample1, and Sample2. Technical artifacts and true biological differences create variation between the samples, with one batch effect identified in Control1. The model aims to compensate for this variation while preserving other biological differences. The GANs used in the study failed to preserve true biological variation in Sample1, particularly in the protein CCR6 levels. This resulted in all cells being mapped to similar CCR6 values, leading to potential misinterpretation of data. The ResnetGAN also did not address this issue, as it focused on generating output similar to the target distribution rather than preserving original variation. Neuron editing successfully removes batch effects and preserves biological variation in protein levels, unlike other generative models. The results are confirmed to be accurate globally across all dimensions. A PCA embedding of the data space shows the transformation for Control1, Control2, Sample1, and post-transformation Sample1. In a global assessment, CCR6 results are confirmed to be accurate across all dimensions. A PCA embedding shows the transformation for Control1, Control2, Sample1, and post-transformation Sample1, preserving intra-sample variation. Additionally, a combinatorial drug experiment on cells from patients with acute lymphoblastic leukemia is analyzed, demonstrating the successful batch correction of a sample. The results show batch correction in IFNg while preserving biological variation in CCR6 across different treatments in a mass cytometry study. The source is defined as basal cells, the target as Das cells, and extrapolation to Bez cells is done. The study aims to predict the effects of applying Das to cells treated with Bez, with successful correction of batch effects observed. The study defines the source as basal cells, the target as Das cells, and extrapolates to Bez cells. Applying Das results in a decrease in p4EBP1 without affecting pSTATS. Neuron editing accurately models this change, while the regularized autoencoder does not. GAN models fail to accurately predict the combination, introducing vertical shifts and losing original variability within the dataset. Despite the small shift, ResnetGAN struggles to mimic the target distribution. The ResnetGAN struggles to mimic the target distribution despite the small shift, as GANs fail to accurately predict the combination and lose original variability within the dataset. Neuron editing better preserves the variation in the real data and accurately predicts the principle direction and magnitude of transformation across all dimensions. Neuron editing is introduced as a novel approach to tackle a data-transformation problem inspired by biological experimental settings. It applies treatment effects observed in a subset of data to the rest of the dataset by utilizing the encoding learned by the latent layers of an autoencoder. This method results in more realistic transformations of image data compared to traditional GANs. Neuron editing applies treatment effects observed in a subset of data to the rest of the dataset by utilizing the encoding learned by the latent layers of an autoencoder. This method results in more realistic transformations of image data and successfully predicts synergistic effects of drug treatments in biological data. Learning edits in a hidden layer allows for interactions between the edit and other context information from the dataset during decoding."
}