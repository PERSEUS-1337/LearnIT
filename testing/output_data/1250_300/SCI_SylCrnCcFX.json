{
    "title": "SylCrnCcFX",
    "content": "Deep networks aim to understand complex mappings through locally linear behavior. The challenge lies in the instability of derivatives, especially in networks with piecewise linear activation functions. A new learning problem is proposed to ensure stable derivatives over larger regions. The algorithm involves identifying stable linear approximation regions and expanding them. This approach is illustrated with residual and recurrent networks on image and sequence datasets. Complex mappings are often characterized by derivatives at points of interest, playing key roles in learning problems like sensitivity analysis. Derivatives with respect to inputs are used for local linearization to explain model predictions or guide learning through regularization. However, derivatives in deep learning models are unstable due to over-parametrization, leading to instability in both function values and derivatives. This instability affects the robustness of first-order approximations used for explanations. The instability in deep learning models affects both function values and derivatives, leading to unreliable first-order approximations for explanations. Gradient stability, different from adversarial examples, focuses on stable function values rather than gradients. Robust estimation techniques aim to protect against adversarial examples but indirectly impact gradient stability. Extending robust estimation to ensure gradient stability would involve finding distorted derivatives and accessing approximate Hessians of deep networks. This paper focuses on deep networks with piecewise linear activations for tractability. Estimating gradient stability in deep networks with piecewise linear activations involves inferring lower bounds on the maximum radius of p-norm balls around a point where derivatives are stable. The special structure of these networks allows for a regularization problem to maximize the lower bound. However, the resulting objective is rigid and non-smooth, leading to a relaxation of the learning problem similar to support vector machines. Evaluating the gradient of each neuron with respect to inputs poses a computational challenge, but a novel perturbation algorithm for piecewise linear networks can collect exact gradients efficiently. In deep networks with piecewise linear activations, a novel perturbation algorithm efficiently collects exact gradients for high-dimensional data. The algorithm proposes forward propagating carefully crafted samples in parallel without back-propagation, providing stable derivatives and expanding regions of stability. Empirical evaluation includes fully-connected, residual, and recurrent networks on image and time-series datasets. The focus is on neural networks with piecewise linear activation functions like ReLU. The proposed approach focuses on neural networks with piecewise linear activation functions, such as ReLU, and its variants. It is based on a mixed integer linear representation of piecewise linear networks, encoding the active linear piece of the activation function for each neuron. This approach aims to expand regions of stability and efficiently collect exact gradients for high-dimensional data. The activation pattern BID20 encodes the active linear piece of the activation function for each neuron, leading to a linear model when fixed. The feasible set in the input space is a stable region with the same linear function. Different activation patterns may result in the same end-to-end linear coefficients BID23. The feasible set induced by activation pattern BID23 is a linear region, while a complete linear region is a connected subset with the same derivatives. Activation patterns have various applications, including visualizing neurons, reachability of specific output values, and adversarial attacks or defense. In contrast to quantifying the number of linear regions as a measure of complexity, this work focuses on local linear regions and expanding them through learning. The stability notion considered differs from adversarial examples, with methods that certify an exact margin around a point based on its activation pattern. Adversarial example computation is NP-complete and not scalable, while layer-wise relaxations provide bounds instead of exact solutions. Defense methods remain intractable on ImageNet scale images. Our inference algorithm certifies the exact 2 margin around a point based on its activation pattern by forwarding O(D) samples in parallel. The proposed learning algorithm maximizes the 2 margin of linear regions around each data point in an unsupervised manner, akin to transductive/semi-supervised SVM. The idea of margin is also extended to nonlinear classifiers in terms of decision boundaries. The text discusses the development of a smooth relaxation of the margin and perturbation algorithms for gradient stability in deep models. It addresses the issue of establishing robust derivatives and the implications for interpretability and transparency of complex models. The gradient-based explanation methods and their instability are also highlighted. The text introduces approaches for establishing robust derivatives in neural networks with ReLU activations, focusing on the fundamental problem rather than just the instability of gradient-based explanations. It presents notation, inference, and learning algorithms for FC networks with ReLU activations, emphasizing the computation of neurons and activated neurons in each layer. The text discusses the computation of ReLU activations in neural networks using transformation matrices and biases. It emphasizes the linear transformation of the last hidden layer and the piecewise linear property of neural networks. The activation pattern used is defined as a set of indicators for neurons that specify functional constraints. The activation pattern in neural networks is defined as a set of indicators for neurons that specify functional constraints. Each linear region of the network is characterized as a convex polyhedron with linear constraints. The feasible set of the activation pattern is equivalent to a convex polyhedron, and the p margin of x subject to its activation pattern is defined. The p margin of x is constrained by its activation pattern, ensuring \u2202a with respect to a feasible activation pattern. Directional feasibility can be checked using Proposition 4, which applies to 1-ball and \u221e-ball feasibility problems. The number of extreme points in an \u221e-ball is exponential in high dimensions, making it intractable. Proposition 5 can be generalized for an \u221e-ball, but in high dimensions, the number of extreme points becomes exponential, making it intractable. The number of extreme points in a 1-ball is linear to the dimension. Feasibility for directional perturbations and 1-balls can be verified using binary searches. Certification for 1-balls is tractable due to convexity, while 2-balls can be certified analytically. Proposition 6 discusses the minimum 2 distance between a point x and the union of hyperplanes induced by neurons. The computation can be done efficiently using forward passes. The text discusses efficiently computing the number of complete linear regions in a neural network model by certifying the number of regions among data points. It proposes a method to calculate the number of complete linear regions based on activation patterns, which is efficient given certain conditions. The text also mentions the upper and lower bounds for the number of complete linear regions among data points. In this section, methods are discussed to maximize the margin in a neural network model. A regularization problem is formulated to achieve this goal, but the rigid loss surface may hinder optimization. To address this, a hinge-based relaxation similar to SVM is proposed. Additionally, a smoother problem is derived by relaxing certain constraints, leading to a more optimal solution. The text discusses deriving a relaxation to solve a smoother problem in a neural network model by relaxing certain constraints. It also explores maximizing the margin through a regularization problem and proposes a hinge-based relaxation similar to SVM. Additionally, it mentions training a fully connected network with different loss functions to visualize the proposed methods. The text discusses training a fully connected network with different loss functions to visualize piecewise linear regions and prediction heatmaps. It introduces distance regularization to enlarge linear regions around training points and relaxed regularization for smoother prediction boundaries. A generalized loss function is proposed to learn Robust Local Linearity (ROLL) by considering a set of neurons with high losses. The text introduces a generalized loss function for learning Robust Local Linearity (ROLL) in a fully connected network. It focuses on a set of neurons with high losses and discusses the benefits of a simple additive structure without a nonlinear sorting step. The algorithm developed exploits the functional structure of the network to avoid calling back-propagation multiple times. The algorithm developed for learning Robust Local Linearity (ROLL) in a fully connected network avoids calling back-propagation multiple times by exploiting the functional structure of the network. It constructs a parallel algorithm without back-propagation by utilizing linear activation functions to mimic the behavior of the network. The complexity analysis assumes parallel computation without overhead, with the perturbation algorithm taking 2M operations for computing gradients, compared to back-propagation. The proposed algorithm for learning Robust Local Linearity (ROLL) in fully connected networks offers a parallel approach that avoids multiple back-propagation calls. It provides an unbiased estimator for the loss function, allowing for efficient computation of gradient norms. The algorithm can be applied to deep learning models with affine transformations and piecewise functions. The proposed algorithm for learning Robust Local Linearity (ROLL) in fully connected networks offers a parallel approach that avoids multiple back-propagation calls. It provides an unbiased estimator for the loss function, allowing for efficient computation of gradient norms. The algorithm can be applied to deep learning models with affine transformations and piecewise functions. The proposed algorithms can be used on all deep learning models with affine transformations and piecewise linear activation functions by enumerating every neuron that will be imposed a ReLU-like activation function. The experiments were conducted on a single GPU with 12G memory, evaluating accuracy, number of linear regions, and margins of linear regions on a testing set. The models with the largest median margins were reported, with tuned models having specific parameters. The ROLL loss achieved significantly larger margins compared to the baseline model. The tuned models have specific parameters and achieve larger margins with the ROLL loss compared to the baseline model. The Spearman's rank correlation is high among testing data. Parameter analysis shows that accuracy decreases with increased margin. Higher \u03b3 values result in less sensitivity to hyper-parameters C and \u03bb. The proposed method measures running time for mini-batch gradient descent steps with different hyper-parameters. Higher C and \u03bb values decrease accuracy with increased margin. Higher \u03b3 values show less sensitivity to C and \u03bb. The perturbation algorithm achieves comparable accuracy and margin with faster computation compared to back-propagation. The perturbation algorithm achieves about 12 times empirical speed-up compared to back-propagation. The computational overhead of the method is minimal, achieved by the perturbation algorithm and the approximate loss. The RNNs for speaker identification are trained on a Japanese Vowel dataset with variable sequence length and classes using the state-of-the-art scaled Cayley orthogonal RNN. The results are reported in TAB3. The implementation details of the model include using matrices to prevent gradient vanishing/exploding, with LeakyReLU activation. Results show that the approach leads to a model with larger margins compared to the vanilla loss. Sensitivity analysis on derivatives was conducted to identify stability bounds. Experiments on Caltech-256 BID18 dataset were performed using a 18-layer ResNet. The ROLL regularization showed consistently larger stability bounds compared to the vanilla model. The implementation details involve downsizing images, training an 18-layer ResNet on Caltech-256 BID18 dataset, and using ROLL loss with 120 random samples per channel. Evaluation measures focus on the stability of gradients in a high-dimensional space, utilizing a sample-based approach due to computational challenges. The stability of gradients in a high-dimensional space is evaluated using labeled data and gradient distortion metrics. A genetic algorithm is used for black-box optimization to compute the maximum distortion, as gradient-based optimization is not feasible due to the nature of the loss function. The adversarial gradient is found by maximizing distortion over a specified norm ball, with implementation details provided in the appendix. The paper introduces a new learning problem to enhance deep learning models with robust local linearity. A genetic algorithm is used for black-box optimization due to the nature of the loss function. Results show that the ROLL loss provides more stable gradients and slightly better precisions compared to the vanilla loss. Only a small number of gradient-distorted images change prediction labels in both models. Visual examples demonstrate the differences in gradients between the two loss functions. The paper introduces a new learning problem to enhance deep learning models with robust local linearity by constructing locally transparent neural networks with stable gradients. The proposed ROLL loss expands regions with stable derivatives and generalizes the stable gradient property across linear regions. The paper presents Propositions 4, 5, and 6 which establish directional feasibility, 1-ball feasibility, and 2-ball certificate in the context of constructing locally transparent neural networks with stable gradients for deep learning models. The paper discusses the union of hyperplanes in convex polyhedrons and the construction of a neural network with linear activation functions to achieve the same loss as the optimal model. This is done by ensuring the hyperplanes induced from linear constraints are at least 2 units away from the input. The paper discusses constructing a neural network with linear activation functions to achieve the same loss as the optimal model. The complexity of the proposed approach is analyzed by assuming parallel computation and batch matrix multiplication. The paper analyzes the complexity of a neural network with linear activation functions using parallel computation and batch matrix multiplication. The perturbation algorithm computes gradients efficiently, while back-propagation requires sequential computation for each neuron. Dynamic programming is used to compute gradients using the chain-rule of Jacobian. The paper discusses using dynamic programming with the chain-rule of Jacobian to compute gradients efficiently in neural networks. It explains the process for fully connected networks but notes inefficiency for convolutional layers due to the expensive linear transformation representation. Additionally, it introduces derivations for maxout/max-pooling nonlinearity, suggesting caution due to new linear constraints induced by max-pooling neurons. The paper discusses using dynamic programming with the chain-rule of Jacobian to compute gradients efficiently in neural networks, particularly focusing on the inefficiency for convolutional layers. It suggests caution with max-pooling nonlinearity due to new linear constraints induced by max-pooling neurons. The activation pattern in the network can lead to a degeneration into a linear model, with feasible sets in the input space ensuring stable derivatives. The feasible set S(x) for a feasible activation pattern O at x is a convex polyhedron with linear constraints. In a fully-connected model with 4 hidden layers of 100 neurons each, trained with Adam optimizer for 5000 epochs, the loss function is sigmoid cross entropy. Tuned regularization parameters \u03bb are set to 1, and data is normalized. The margin is computed in normalized data and reported in the table. The data is normalized with \u00b5 = 0.1307 and \u03c3 = 0.3081. The FC model has 4 fully-connected hidden layers with 300 neurons each, using ReLU activation function. The loss function is cross-entropy with soft-max. Stochastic gradient descent with Nesterov momentum is used, with a learning rate of 0.01 and batch size of 64. Tuning involves a grid search on \u03bb, C, \u03b3, and the best model is chosen based on validation accuracy. The size is 64. Grid search is done on \u03bb, C, \u03b3 with specific ranges. The data is not normalized. The representation is learned with a single layer scoRNN. LeakyReLU is used as the activation function. The hidden neurons dimension is 512. AMSGrad optimizer is used. The learning rate is 0.001, and batch size is 32. Another grid search is done on \u03bb, C, \u03b3 with different ranges. The models with the largest testing accuracy are reported. The curr_chunk discusses model tuning with grid search on \u03bb, C, and \u03b3 parameters, using a pre-trained ResNet-18 model with architectural modifications for higher dimensional images. The bijection technique is applied for sample-based approach computation. The model is trained with stochastic gradient descent on a modified ResNet-18 architecture to accommodate higher dimensional images. Tuning involves adjusting parameters like learning rate and batch size, and using grid search on \u03bb and C values. A genetic algorithm with 4800 populations is implemented for optimization. The genetic algorithm (GA) BID33 is implemented with 4800 populations and 30 epochs. Samples are sorted based on distance evaluations, with the top 25% kept in the population. Crossover involves replacing 75% of samples with a random linear combination. Projection ensures feasibility, and the sample with the maximum distance is returned. No mutation is implemented due to computational reasons. The crossover operator is likened to a gradient step in GA. The genetic algorithm (GA) with 4800 populations and 30 epochs is implemented. Samples are sorted based on distance evaluations, with the top 25% kept. Crossover involves replacing samples with a random linear combination. Projection ensures feasibility, and the sample with the maximum distance is returned. No mutation is implemented due to computational reasons. The crossover operator is analogous to a gradient step in GA. Visualizations include original image, original gradient, adversarial gradient, image of adversarial gradient, original integrated gradient attribution, and adversarial integrated gradient attribution. The process involves aggregating derivatives, taking absolute values, normalizing by the 99th percentile, and clipping values above 1. The BID28 method visualizes gradients and integrated gradients by aggregating derivatives, taking absolute values, normalizing, and clipping values. The resulting derivatives are then visualized as gray-scaled images. The examples from the Caltech-256 dataset are shown in Figures 5 and 6, highlighting different gradient distortions. The exact values differ slightly from Table 4 due to interpolation methods. The maximum 1 gradient distortions for images in the Caltech-256 dataset are visualized in Figures 5 and 6. The values differ slightly from Table 4 due to interpolation methods. In Figure 5, the maximum distortion is 893.3 for 'Projector', while in Figure 6, it is 1547.1 for 'Bear' and 5473.5 for 'Rainbow' in the vanilla model. In the ROLL model, the maximum distortion is 1367.9 for 'Bear' and 3882.8 for 'Rainbow'."
}