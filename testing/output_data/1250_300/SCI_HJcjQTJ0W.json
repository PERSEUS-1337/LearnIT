{
    "title": "HJcjQTJ0W",
    "content": "Massive data on user local platforms pose challenges for deep neural network (DNN) training. Cloud-based training offers benefits but raises privacy concerns. To address this, a method using intermediate representations of data is proposed, splitting DNNs between local platforms and the cloud. Local NN generates feature representations without training to protect data privacy. Cloud NN is trained based on these representations. The idea is validated by studying privacy loss and accuracy dependency on local NN topology for image classification tasks. PrivyNet is proposed to optimize target task accuracy while minimizing privacy loss. The text discusses the challenges of training deep neural networks (DNN) on local platforms due to computational intensity. A method using intermediate representations of data is proposed to address privacy concerns, where local platforms generate feature representations for cloud-based training. PrivyNet is introduced to optimize target task accuracy while minimizing privacy loss. Different data pre-processing schemes are proposed to protect user data privacy by generating transformed representations locally for target learning tasks. The requirements for these representations are utility and privacy, with the transformation scheme needing to be flexible for different platforms and data types. Privacy and utility trade-off is a key focus in privacy research, with various measures proposed to explore the balance between the two. Measures of privacy and utility are proposed based on rate-distortion theory, statistical estimation, and learnability. Various transformations have been suggested to explore the trade-off between privacy and utility. Syntactic anonymization methods like k-anonymity, l-diversity, and t-closeness are used to protect sensitive attributes in static databases. Differential privacy offers a formal privacy guarantee by adding noise, but it does not limit total information leakage. Existing works often require local platforms for deployment, making it challenging for lightweight applications. Existing works propose various transformations to balance privacy and utility, with linear transformations relying on data-label covariance or LDA for data anonymization. However, linear transformations have limited privacy protection as original data can be reconstructed. Nonlinear transformations like minimax filter or Siamese networks offer better privacy but require an iterative training scheme between cloud and local platforms. The proposed PrivyNet framework involves a local NN derived from pre-trained NNs for feature extraction and a cloud NN trained for the target learning task. PrivyNet is a DNN training framework that divides the model into local and cloud parts for privacy and utility trade-off control. The local NN generates intermediate representations while the cloud NN is trained based on these representations. Privacy protection is achieved through non-linear transformations like convolution and pooling. The local NN is derived from pre-trained NNs to avoid local training. PrivyNet is a framework that splits DNN models for cloud-based training with privacy control. The local NN, derived from pre-trained NNs, extracts general features to optimize utility while protecting privacy. Key contributions include proposing PrivyNet, characterizing privacy loss and utility using CNN, and a hierarchical strategy to optimize utility considering computation, storage, and privacy constraints. The framework is verified using CNN-based image classification. A hierarchical strategy is proposed to determine the topology of the local NN to optimize utility considering constraints on local computation, storage, and privacy loss. PrivyNet is validated using CNN-based image classification, demonstrating efficiency and effectiveness in leveraging pre-trained NN for intermediate representation generation. The utility is measured by the accuracy of the target learning task, and privacy is assessed by the distance between reconstructed and original images. The text discusses reconstructing images from features, measuring utility and privacy, training the IRN with known images and feature representations, and defining the transformation induced by the FEN. The transformation is parameterized by the number of FEN layers and filters selected for each layer. The text discusses evaluating utility and privacy of transformed representations using a classifier for utility and a reconstruction model for privacy. Utility is measured by the accuracy of the classifier, while privacy is measured by the distance between reconstructed and original images. The text discusses the impact of FEN topology on privacy and utility of transformed representations. FEN is derived from VGG16 and uses CNN for image classification and reconstruction tasks. FEN topology is determined by the number of layers, depth of output channels, and selected output channels. Evaluation and comparison of these factors are conducted in this section. The architectures of VGG16, ICN, and IRN are shown in Appendix B. The FEN topology is determined by the number of layers, output depth, and selected output channels. Evaluation of these factors forms the basis for the PrivyNet framework. Changes in FEN topology impact utility and privacy, with different behaviors observed. Privacy loss is smaller with reduced output depth or increased FEN layers, while utility degradation is minimal with certain combinations of FEN layers and output depth. The FEN topology, determined by the number of layers, output depth, and selected output channels, impacts utility and privacy in the PrivyNet framework. Privacy loss is smaller with reduced output depth or increased FEN layers, while utility degradation is minimal with certain combinations. Channel selection also affects privacy and utility, with different behaviors observed for each single channel. The impact of channel selection on privacy and utility in the PrivyNet framework is analyzed by comparing the utility and privacy loss for transformed representations induced by each single channel. Results show significant differences in utility and privacy when using different numbers of VGG16 layers in the FEN. The best channel achieves higher utility and lower privacy loss compared to the worst channel, highlighting the importance of channel selection in preserving privacy and utility. The impact of output channel selection, number of FEN layers, and output depth on privacy and utility in the PrivyNet framework is analyzed. Results show that privacy and utility depend more on the number of FEN layers and output channel depth compared to output channel selection. Leveraging pre-trained CNN for FEN construction allows for exploring the trade-off between utility and privacy by controlling FEN topology. The trade-off between privacy and accuracy can be managed by adjusting the number of FEN layers, output channel depth, and output channel selection. In the PrivyNet framework, the FEN topology can be optimized for utility while considering privacy, local computation capability, and storage constraints. The number of FEN layers and output channel depth have a significant impact on privacy and utility. PrivyNet leverages pre-trained CNN for FEN construction to control the trade-off between privacy and utility. The framework aims to optimize utility while considering privacy, local computation, and storage constraints. The PrivyNet framework optimizes the FEN topology for utility while considering privacy, local computation capability, and storage constraints. Privacy characterization and performance profiling are conducted to determine the number of layers and output depth of the FEN. A supervised channel pruning step is then performed based on private data to optimize the FEN topology. The assumption of availability of original images is crucial for evaluating privacy loss induced by releasing features. The assumption of availability of original images is crucial for evaluating privacy loss induced by releasing feature representations. The attackers may inject images into a database to obtain corresponding representations generated by the FEN. Anonymity protection of the FEN is necessary to prevent sophisticated image reconstruction mechanisms. The pre-characterization stage involves performance and storage profiling of pre-trained neural networks on local platforms and cloud-based privacy characterization. Privacy characterization is done by leveraging cloud-based services and training the reconstruction network on publicly available data. Verification is done by comparing the PSNR for FEN with different topologies using datasets like CIFAR-10 and CIFAR-100. In the pre-characterization stage, performance and storage profiling of pre-trained neural networks is conducted. Privacy characterization is verified by comparing PSNR for FEN with different topologies using datasets like CIFAR-10 and CIFAR-100. The number of samples needed for accurate characterization is determined to be less than 1000 with data augmentation. The topology for the FEN is determined based on the number of FEN layers and output channel depth, which have significant impacts on privacy and accuracy. In PrivyNet, the number of FEN layers and output channel depth significantly impact privacy and accuracy. The strategy involves selecting deeper layers for high privacy requirements and shallow FENs for low privacy requirements, adjusting output depth accordingly. This approach considers constraints on local computation, storage, and privacy loss. In PrivyNet, the selection of FEN layers and output channel depth is crucial for balancing privacy and utility. Choosing shallow FENs with appropriate output depth can minimize local computation and storage consumption based on privacy constraints. The number of layers, output depth, and output channel selection all play a role in achieving the desired privacy level and utility. In PrivyNet, selecting FEN layers and output channel depth is essential for balancing privacy and utility. Large discrepancies in utility and privacy are observed when changing layers or increasing output channel depth. Directly selecting output channels may result in poor utility with privacy leakage, highlighting the need for channel pruning. The correlation between utility and privacy loss for a single channel is negligible, enabling optimization of utility while suppressing privacy loss. The channel pruning process considers both utility and privacy. In PrivyNet, selecting FEN layers and output channel depth is crucial for balancing privacy and utility. The channel pruning process considers both utility and privacy, with Fisher's linear discriminability analysis used to identify ineffective channels. Fisher's LDA measures the distance of representations generated by output channels for different images within the same class, helping to optimize utility while suppressing privacy loss. In PrivyNet, the channel pruning process uses Fisher's linear discriminability analysis to identify ineffective channels based on between-class and within-class variances. This helps optimize utility while suppressing privacy loss by evaluating the representations generated by each channel. The channel pruning process in PrivyNet utilizes Fisher's discriminability to identify and prune ineffective channels, improving accuracy for the learning task. Experimental results show that by leveraging Fisher's discriminability, a significant reduction in bad channels can be achieved compared to random pruning methods. The experimental results demonstrate the effectiveness of supervised channel pruning in PrivyNet, showing a significant reduction in bad channels compared to random pruning methods. The computation complexity of the LDA-based pruning process scales with the number of samples, but the extra computation introduced is minimal. The pruning process is shown to be effective in improving accuracy for the learning task. In the pruning process, the layer of FEN is set to 6 and the output depth to 8. Three settings are compared for privacy and utility of released representations: random selection, channel pruning based on privacy and utility, and channel pruning based on privacy and LDA. Pruning involves removing 64 channels with the worst utility and 32 channels with the largest privacy loss. Results show that after pruning, better utility and less privacy leakage can be achieved simultaneously. After pruning, better utility and less privacy leakage can be achieved simultaneously. Our LDA-based pruning strategy shows 1.1% better accuracy and 1.25 dB smaller PSNR compared to random selection without pruning. The method also achieves similar accuracy with slightly less privacy loss compared to pruning based on characterization results. The effectiveness of our supervised pruning strategy is verified through detailed statistics and comparisons in Table 13. In the paper, detailed discussions on the adversarial model are provided, focusing on protecting the anonymity of the Feature Extraction Network (FEN). Strategies include building a pool of pre-trained NNs like VGG16 and applying channel selection to make it harder for attackers to guess the FEN derivation. These methods enhance privacy protection against powerful attacks. After channel selection in the Feature Extraction Network (FEN), the number and subset of channels become unknown to attackers, making it harder to guess. The privacy and utility are empirically verified by gradually reducing channel depth in VGG16 layers, showing minimal impact on privacy and utility with a significant reduction in runtime. PrivyNet is a flexible framework designed for cloud-based training with fine-grained privacy protection. By reducing channel depth in VGG16 layers, privacy and utility are maintained with a significant decrease in runtime. This approach enhances anonymity in the Feature Extraction Network (FEN), making it challenging for attackers to determine the number and subset of channels. This framework can be beneficial for hospitals to train models for disease diagnosis while protecting patient privacy. PrivyNet is a framework for cloud-based training with fine-grained privacy protection. It allows hospitals to release informative features instead of original patient data for disease diagnosis. It can also enable mobile platforms to upload data to the cloud while protecting personal information. The framework is simple, platform-aware, and flexible for different end-users and situations. In our characterization, we use CIFAR-10 and CIFAR-100 datasets. CIFAR-10 consists of 60000 32 \u00d7 32 color images in 10 classes, while CIFAR-100 has images of objects in 100 classes. We derive the FEN from VGG16, pre-trained on ImageNet dataset, for privacy and accuracy characterization. CNN is used for image classification task and image reconstruction task with specific network architectures. In the experiments, a state-of-the-art generative NN architecture based on ResNet blocks is used for image reconstruction tasks. The network is trained using gradient descent optimizer with specific learning rates and mini-batch sizes. Data augmentation techniques are applied before characterizing the IRN topology for improved performance. In the experiments, a state-of-the-art generative NN architecture based on ResNet blocks is used for image reconstruction tasks. Data augmentation techniques are applied before characterizing the IRN topology. The image recovery capability of IRN is determined by the number of ResNet block clusters, with 2 clusters of 8 blocks each chosen for experiments. Performance and storage characterization is done by profiling pre-trained NNs on local platforms. In the experiments, performance and storage characterization of pre-trained NNs on local platforms is conducted. Profiling of VGG16 on different CPUs shows an increase in computation and storage requirements with the number of layers. Convolution layers contribute significantly to computation, while fully connected layers dominate storage. The necessity for a flexible framework considering local computation and storage differences is highlighted. The extra computation is influenced by the number of samples and output dimension. The extra computation in the second part is determined by the number of samples and output dimension. The complexity is influenced by the characteristics of the FEN and the learning task. The overall computation overhead is small due to the usually small number of samples needed for good pruning results."
}