{
    "title": "BJInEZsTb",
    "content": "In this paper, the authors explore representation learning and generative modeling using three-dimensional geometric data in the form of point clouds. They introduce a deep autoencoder network that excels in reconstruction quality and generalization. The learned representations surpass current methods in 3D recognition tasks and enable shape editing through simple algebraic manipulations. Additionally, the study includes various generative models such as GANs and Gaussian mixture models, with GMMs trained in the autoencoder's latent space producing samples of the highest fidelity and diversity. The curr_chunk discusses the limitations of current 3D object representations in generative modeling, highlighting the challenges in creating realistic and diverse objects. It emphasizes the need for more semantic-rich representations to improve the design and editing process. Recent advances in deep learning offer a data-driven approach for editing and designing new objects, eliminating the need for complex parametric models. Deep learning architectures like autoencoders and Generative Adversarial Networks have shown success in learning complex data representations. Point clouds, a relatively unexplored 3D modality, provide a compact representation of surface geometry that is easily amenable to geometric operations. In this paper, the focus is on point clouds as a 3D modality that offers a compact representation of surface geometry. Deep architectures for 3D point clouds are limited, with only a few existing in the literature. The study introduces deep architectures for learning representations and generative models for point clouds, addressing the challenges of training GAN-based generative pipelines. Generative models for point clouds, particularly GAN-based pipelines, pose challenges in training and evaluation. This study introduces a new AE architecture inspired by recent classification architectures, capable of learning compact representations with high reconstruction quality. The learned representations improve classification accuracy and enable meaningful interpolations and semantic analysis. The study introduces a new AE architecture for learning compact representations of point clouds with excellent reconstruction quality. The learned representations improve classification accuracy, enable meaningful interpolations, and support the training of GANs for generating point clouds similar to the training data. Training a GAN in a fixed latent representation is proposed as a more effective approach, supported by theory and empirical evidence. Latent GANs are easier to train and achieve superior reconstruction quality compared to raw GANs. GMMs trained in the latent space of fixed AEs show the best performance overall. Latent GANs are easier to train and achieve superior reconstruction quality compared to raw GANs. GMMs trained in the latent space of fixed AEs show the best performance overall. Multi-class GANs work almost as well as dedicated GANs trained per-object category in the latent space. Various metrics are evaluated for learning good representations and evaluating generated samples, including fidelity and coverage metrics. The paper is organized into sections outlining background, evaluation metrics, models for latent representations, and evaluation of all. The paper is organized into sections outlining background information on autoencoders and generative adversarial networks (GANs). Autoencoders aim to reproduce their input by compressing data into a low-dimensional representation, while GANs are state-of-the-art generative models based on an adversarial game between a generator and a discriminator. The code for all models is publicly available. Generative Adversarial Networks (GANs) involve a generator and discriminator in an adversarial game to synthesize samples indistinguishable from real data. The improved Wasserstein GAN is used for stability during training. Point clouds present unique challenges due to the lack of grid-like structure for convolution operations. Point clouds pose challenges in network architecture due to the lack of grid-like structure for convolution operations. Recent classification work on point clouds bypasses this issue by avoiding 2D convolutions. Point clouds are unordered, making comparisons between sets difficult, requiring permutation-invariant features. Two metrics for comparing unordered point sets have been proposed in the literature. The Earth Mover's distance (EMD) and Chamfer distance (CD) are metrics for comparing unordered point sets. EMD transforms one set to another, while CD measures the squared distance between points and their nearest neighbors. These metrics are used to evaluate the quality of representation and generative models. The comparison of representation models involves evaluating the faithfulness and diversity of generative models, measuring potential mode-collapse. Metrics like Coverage, MMD, and Jensen-Shannon Divergence are used to assess how well a point-cloud distribution matches a ground truth distribution. Coverage measures the fraction of matched point-clouds, while MMD captures fidelity by calculating the average distance in the matching. Jensen-Shannon Divergence quantifies the difference between distributions. The text discusses the use of MMD and Jensen-Shannon Divergence to evaluate the faithfulness and diversity of generative models for point clouds. It describes the measurement of distances in pairwise matchings and the calculation of Jensen-Shannon Divergence between marginal distributions in a 3D space. Additionally, it outlines the architectures of representation and generative models, including an autoencoder design, a GAN tailored to point-cloud data, and a generative model based on Gaussian Mixtures. The input to the AE network is a point cloud with 2048 points. The text discusses the use of MMD and Jensen-Shannon Divergence to evaluate generative models for point clouds. It describes an AE network for 3D shape representation using 1-D convolutional layers and a latent space based on Gaussian Mixtures. Two AE models, AE-EMD and AE-CD, are explored with efficient EMD-distance and Chamfer-Distance as structural losses. The text discusses the use of MMD and Jensen-Shannon Divergence to evaluate generative models for point clouds. It describes an AE network for 3D shape representation using 1-D convolutional layers and a latent space based on Gaussian Mixtures. Two AE models, AE-EMD and AE-CD, are explored with efficient EMD-distance and Chamfer-Distance as structural losses. The AE models produce a 2048 \u00d7 3 output, with AE-EMD and AE-CD having different architectures. The optimal latent-space size was determined to be k = 128, showing the best generalization error on test data and minimal reconstruction error on the train split. Additionally, a raw point cloud GAN is introduced, the first of its kind, operating directly on the raw 2048 \u00d7 3 point set input. The discriminator's architecture is similar to the AE, with leaky ReLUs used instead of ReLUs. The text introduces a GAN for point clouds, with the discriminator architecture similar to an AE but without batch-norm and using leaky ReLUs. The l-GAN operates on a pre-trained autoencoder's bottleneck variable, with a simpler architecture compared to the r-GAN. Shallow designs for both the generator and discriminator are found to produce realistic results. The text discusses the simplicity of the l-GAN compared to the r-GAN, using shallow designs for the generator and discriminator. Gaussian Mixture Models are also trained on the latent spaces learned by autoencoders, with experiments on varying numbers of Gaussian components and covariance matrices. Reconstructions of shapes from the ShapeNet repository are shown, with specific per-class models trained using an 85%-5%-10% split for training/testing/validation sets. The text discusses evaluating unsupervised representation learning algorithms by using them as feature extractors on supervised datasets. An autoencoder was trained on 57,000 models from 55 categories of man-made objects in the ShapeNet repository. The 512-dimensional bottleneck layer vector extracted from the network was processed by a linear classification SVM for 3D shape classification on the ModelNet benchmark. The text discusses using a linear classification SVM trained on a 512-dimensional bottleneck layer vector extracted from an autoencoder for 3D shape classification on the ModelNet benchmark. Results show that the 512-dimensional feature outperforms a 7168-long feature used by the previous state of the art. CD loss performs better when there is increased variation within the collection, possibly due to its ability to understand rough edges and high frequency geometric details. The experiment also demonstrates the domain-robustness of the learned features. The experiment demonstrates the domain-robustness of the learned features by using autoencoders to reconstruct unseen shapes and showcase shape editing applications like interpolations and part editing. The results show the ability of the learned representation to generalize to unseen shapes and the comparable reconstruction quality on training vs. test splits. The study showcases the domain-robustness of learned features through autoencoders reconstructing unseen shapes and demonstrating shape editing applications. Five generative models are trained on point-cloud data of the chair category, including AEs with 128-dimensional bottleneck, l-GANs, GMMs, and r-GANs. Model selection is based on synthetic results matching the ground truth datasets. The study trains five generative models on chair point-cloud data, including AEs, l-GANs, GMMs, and r-GANs. Model selection is based on how well synthetic results match the ground truth datasets, using JSD or MMD-CD metrics. GMMs perform better with full covariance matrices, suggesting strong correlations between latent dimensions. The study evaluates generative models on chair point-cloud data, selecting models based on how well synthetic results match ground truth datasets using JSD or MMD-CD metrics. GMMs perform better with full covariance matrices, indicating strong correlations between latent dimensions. The optimal number of Gaussian components is 32 for GMMs and 40 when using MMD-CD as the selection criterion. The models are compared based on their ability to generate synthetic samples resembling the train and test splits of the ground truth distribution. The study evaluates generative models on chair point-cloud data, comparing how well synthetic samples match the train and test splits of the ground truth distribution. Results show that training a Gaussian mixture model in the latent space of an EMD-based AE yields the best fidelity and coverage. Training a Gaussian mixture model in the latent space of an EMD-based AE yields the best results in terms of fidelity and coverage. The achieved fidelity and coverage are comparable to the reconstruction baseline, with the performance for training vs. testing splits being similar. Additionally, the number of synthetic point clouds generated for the train split experiment is equal to the size of the train dataset, while for the test split experiment and model selection, synthetic datasets three times bigger are generated. The number of synthetic point clouds generated for the train split experiment is equal to the size of the train dataset. For the test split experiment and model selection, synthetic datasets three times bigger are generated to reduce sampling bias when measuring MMD or Coverage statistics. The MMD-CD distance to the test set for r-GANs appears small, but qualitative inspection shows otherwise, attributed to the inadequacy of the chamfer distance in distinguishing pathological cases. Examples are showcased in Fig. 3 with r-GAN and l-GAN generating point clouds. The text discusses the use of r-GAN and l-GAN to generate synthetic point clouds, comparing their quality using CD and EMD metrics. It highlights that r-GANs tend to generate clouds with points concentrated in specific areas, affecting the CD metric's accuracy in measuring similarity to ground truth. The study compares the quality of synthetic point clouds generated by r-GAN and l-GAN using CD and EMD metrics. r-GAN struggles to provide good coverage of the test set, indicating the difficulty in training end-to-end GANs. The EMD distance penalizes r-GAN results in terms of MMD and coverage due to its one-to-one mapping approach. Training trends show that r-GAN results have low coverage regardless of the metric used. The l-GAN (AE-CD) performs better in terms of fidelity with fewer epochs, but its coverage remains low due to unnatural topologies. Switching to an EMD-based AE (l-GAN, AE-EMD) dramatically improves coverage and fidelity, although both l-GANs suffer from mode collapse issues. The issue of mode collapse arises during training, with coverage dropping significantly. Switching to a latent WGAN helps eliminate this collapse. Comparisons are made with voxel-based methods, and the performance of GANs on point-cloud data is evaluated against other 3D generative methods. The r-GAN and l-GAN models are compared to BID31 in terms of diversity and realism in generating point clouds. The l-GANs outperform BID31 with higher classification and diversity scores, requiring fewer training epochs. The training time for l-GAN is significantly shorter than r-GAN due to its smaller architecture. Qualitative evaluation shows high-quality results from l-GANs and a GMM model trained on AE-EMD latent space, demonstrating the strength of the learned representation. The l-GAN and 32-component GMM models, trained on AE-EMD latent space, produce high-quality results. The l-GAN generates crisper results compared to the r-GAN, showcasing the advantage of using a good structural loss. Synthetic point clouds from multiple classes (chair, airplane, car, table, sofa) were generated using an AE-EMD trained on a mixed set. The multi-class AE with a bottleneck size of 128 was trained for 1000 epochs. The multi-class AE with a bottleneck size of 128 was trained for 1000 epochs, generating datasets for testing. Comparisons were made with class-specific AEs, and l-WGANs were trained for 2K epochs. Results show that l-WGANs based on the multi-class AE perform similarly to dedicated class-specific ones. Visual quality comparisons also indicate minimal sacrifice with the multi-class AE-EMD. MMD-CD measurements for l-WGANs trained on latent spaces of dedicated and multi-class EMD-AEs are presented in Table 4. The study compared l-WGANs trained on the latent spaces of dedicated and multi-class EMD-AEs. Results showed minimal sacrifice in visual quality with the multi-class AE-EMD. Limitations included failure cases in decoding rare geometries and missing high-frequency details. The r-GAN struggled to create realistic shapes for certain classes, indicating the need for more robust raw-GANs for point clouds in future research. Training Gaussian mixture models (GMM) in the latent space of an autoencoder is closely related to VAEs. Over-regularization is a known issue with VAEs, affecting reconstruction quality. Methods exist to gradually increase the regularization weight. Fixing the autoencoder before training generative models yields good results. Novel architectures for 3D point-cloud representation learning and generation were presented, showing good generalization and meaningful semantics encoding. The best-performing generative model in the experiments was a GMM trained in the fixed latent space of an AE, suggesting the effectiveness of classic tools in certain cases. In experiments, a GMM trained in the fixed latent space of an AE performed well. The AE used for SVM-related experiments had specific encoder and decoder configurations, with batch normalization and data augmentation. Other AEs had different architecture and were trained for a maximum of 500 epochs. The encoder and decoder configurations for the AE used in experiments included specific filter sizes at each layer. Different setups like denoising or regularized AEs did not show significant advantages over the \"vanilla\" architecture. The discriminator had 1D-convolutions with varying filter sizes and leaky-ReLU layers. The generator consisted of FC-ReLU layers with different neuron sizes. The r-GAN was trained with Adam optimizer and specific learning rate and beta values. The generator and discriminator in the r-GAN model have specific configurations with different numbers of neurons in each layer. The training process involves using Adam optimizer with specific learning rate and beta values. The noise vector used has a spherical Gaussian distribution. The l-Wasserstein-GAN model includes a gradient penalty regularizer and specific training iterations for the critic. For classification experiments, a linear SVM classifier with specific penalty and class weights is used. In Section 4.1, a one-versus-rest linear SVM classifier was used with an l2 norm penalty and balanced class weights. The training parameters for SVMs used in each dataset with structural loss models are detailed in Table 5. The reconstruction quality of two Autoencoders (CD and EMD-based) is compared using JSD of reconstructed datasets. The AEs show the ability to generalize, with comparable reconstruction quality between training and test datasets. The AE-EMD embedding trained across all 55 object classes is used for shape editing applications, showcasing its feature encoding ability. The AE-EMD embedding trained across all 55 object classes showcases its ability to encode features for different shapes, enabling shape editing applications. Using the latent representation, structural differences between object sub-categories can be modeled. Interpolating between different point clouds is also possible using the latent space representation. By utilizing the latent representation, structural differences between object sub-categories can be modeled, allowing for shape editing applications. Linearly interpolating between latent representations of shapes enables the creation of intermediate variants, supporting morphing between shapes of different appearances and classes. The latent representation allows for morphing between shapes of different appearances and classes, including shape analogies and point-cloud generators for 3D shapes. The study compared latent AE-based GMM models with voxel-based GANs for generating 3D shapes. Results showed that the latent AE-based models outperformed the GAN architecture significantly. Shape analogies using the learned representation were also demonstrated. The latent AE-based GMM models outperform voxel-based GANs significantly, showing a vast improvement in coverage and fidelity. The performance of voxel-based GMM models is comparable at different resolutions, indicating that high-frequency details in the ground-truth data are not the main factor affecting results. Point-cloud-based models outperform voxel-based models in fidelity, as measured by MMD. The coverage boost of voxel-based latent-space models is attributed to the way the coverage metric is computed, despite frequently producing shapes with missing components. The coverage metric for voxel-based models is likely inflated due to poor quality matchings with ground truth shapes, as shown in the histogram. Voxel-based GANs at different resolutions were evaluated against a chair test set, with GMM models outperforming in coverage and fidelity compared to voxel-based models. The voxel-based methods were evaluated using MMD and Coverage metrics at resolutions 32^3, 64^3, and 128^3 against a chair test set. Volumetric models utilized GMMs with full covariances and varying latent codes. The mesh conversion was done using the marching cubes algorithm. Voxel-based AEs were fully-convolutional with specific layer parameters and training for 100 epochs with Adam. The 32 3 decoder with 4 layers does not use non-linearity. The abbreviation \"bn\" refers to batch-normalization. The encoder and decoder architecture is trained for 100 epochs with Adam optimizer and binary cross-entropy loss. Comparison of reconstruction quality with BID28 method on ShapeNetCars dataset using a 0.5 occupancy threshold. Evaluation of GMM-generator against a model memorizing training data for chair class. Random sub-sampling of training set for metric evaluation. The GMM-generator is compared against a model that memorizes the training data for the chair class. Different sets of training data sizes are evaluated for coverage/fidelity with the test split. Using a learned representation allows for compactly representing data and generating novel shapes. Despite some mode collapse, the generative models achieve excellent fidelity. The generative models achieve excellent fidelity despite some mode collapse. Comparisons with BID32 for major ShapeNet classes are provided in Tables 10, 11, 12, showing JSD-based and MMD/Coverage comparisons. Generalization error of various GAN models is also analyzed using JSD and MMD-CD metrics. The text discusses the evaluation of various GAN models using JSD and MMD-CD metrics. GMM models with different numbers of Gaussians and covariance types are trained on latent space learned by an AE with EMD. Models with full covariance matrices achieve smaller JSD than those with diagonal covariance, with 30 or more clusters being sufficient for minimal JSD. The text also mentions the evaluation of five generators on chair data using minimal MMD-CD for model selection. The text discusses evaluating GAN models using JSD and MMD-CD metrics. GMM models with different Gaussian components and covariance types are trained on latent space learned by an AE with EMD. Models with full covariance matrices achieve smaller JSD than those with diagonal covariance. The evaluation of five generators on chair data using minimal MMD-CD for model selection is also mentioned. The reported scores are averages of three pseudo-random repetitions. The selected models' quality remains consistent regardless of the metric used for selection."
}