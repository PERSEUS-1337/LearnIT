{
    "title": "HyeJf1HKvS",
    "content": "This work introduces a two-stage neural architecture for learning structural correspondences between graphs. It utilizes localized node embeddings from a graph neural network to rank soft correspondences initially, followed by synchronous message passing networks to iteratively re-rank correspondences and achieve a consensus in local neighborhoods. The method is shown to be effective in real-world tasks such as computer vision and entity alignment between knowledge graphs, outperforming current state-of-the-art approaches. Graph matching is essential for establishing structural correspondences between nodes in knowledge graphs. It is crucial for various real-world applications such as cheminformatics, bioinformatics, social network analysis, and computer vision. The problem has been extensively studied in theory and practice, often related to domain-agnostic distances and formulated as a quadratic assignment problem. Various neural architectures have been proposed to tackle the task of graph matching or graph similarity in a data-dependent fashion. However, these approaches may have limitations such as only computing similarity scores between whole graphs, relying on inefficient global matching procedures, or not generalizing to unseen graphs. Graph matching is often formulated as an edge-preserving quadratic assignment problem, aiming to find correspondences based on neighborhood consensus. This approach prevents adjacent nodes in the source graph from being mapped to different regions in the target graph. The problem is addressed in this work through supervised and semi-supervised matching of graphs, incorporating the concept of neighborhood consensus as an inductive bias into the model. In this work, the problem of supervised and semi-supervised graph matching is addressed by incorporating neighborhood consensus as an inductive bias. The proposed deep graph matching architecture consists of a local feature matching procedure and an iterative refinement strategy using synchronous message passing networks. The goal is to compute initial correspondence scores based on node embeddings similarity and reach neighborhood consensus for correspondences. The proposed deep graph matching architecture involves a feature matching step based on node embeddings similarity and an iterative refinement strategy for reaching neighborhood consensus. The method is scaled to large inputs in real-world scenarios. The proposed deep graph matching architecture involves computing similarities between nodes in source and target graphs using node embeddings. Sinkhorn normalization is applied to obtain correspondence matrices, and a Graph Neural Network is trained in a supervised fashion to obtain node representations. The curr_chunk discusses the implementation of a Graph Neural Network (GNN) for obtaining localized node representations in a deep graph matching architecture. Various operators from geometric deep learning and relational representation learning are utilized for feature extraction. The local nature of node embeddings may lead to false correspondences, which are addressed by detecting violations of neighborhood consensus criteria in local neighborhoods. The implementation of a Graph Neural Network (GNN) in a deep graph matching architecture aims to detect violations of neighborhood consensus criteria in local neighborhoods. The soft correspondence matrix is used to pass node functions between domains, refining correspondences iteratively. The algorithm utilizes graph neural networks to detect violations and resolve them in an iterative fashion. The algorithm utilizes graph neural networks to distribute global node colorings and resolve ambiguities in correspondences by performing synchronous message passing on both graphs. This process iteratively improves neighborhood consensus and updates correspondence scores based on errors in feature matching and neighborhood consensus. The approach involves a two-stage process to ensure accurate matching. The algorithm uses graph neural networks for global node colorings and correspondence resolution through synchronous message passing. It iteratively enhances neighborhood consensus and updates scores based on feature matching errors. A two-stage process ensures accurate matching, with local operators used in the first stage. Theorems 1 and 2 demonstrate the effectiveness of measuring neighborhood matching between graphs. A permutation equivariant and injective GNN satisfies the criteria for optimal node embeddings. Theorem 1 and 2 show that a permutation equivariant and injective GNN can provide optimal node embeddings. Common GNN architectures are equivariant due to permutation invariant neighborhood aggregators, while injectivity can be achieved by using powerful GNNs like the Weisfeiler & Lehman heuristic. The proposed approach relates to classical graph matching techniques, such as the graduated assignment algorithm, for solving graph structure problems. The graduated assignment algorithm (Gold & Rangarajan, 1996) iteratively computes new solutions by solving a linear assignment problem. The softassign operator uses sinkhorn normalization on rescaled inputs to encourage integer solutions. The approach approximates the linear assignment problem via sinkhorn normalization and utilizes trainable neural networks for updating correspondence scores. This model is a deep parameterized generalization of the graduated assignment algorithm, simplifying graph matching computations. Our approach simplifies graph matching computations by using trainable neural networks to update correspondence scores based on the difference between input similarities. It supports continuous node and edge features through established GNN models and includes optimizations for scalability, such as sparsifying initial correspondences and reducing memory footprint. Our approach simplifies graph matching computations using trainable neural networks to update correspondence scores based on input similarities. It reduces memory footprint by utilizing the KEOPS library without storing its dense version, and sparsifying initial correspondences. Additionally, it proposes replacing node indicator functions with randomly drawn node functions for computational efficiency. Our approach simplifies graph matching computations using trainable neural networks to update correspondence scores based on input similarities. It reduces memory footprint by utilizing the KEOPS library without storing its dense version, and sparsifying initial correspondences. Furthermore, we propose relaxing the constraint of sinkhorn normalization by applying row-wise softmax normalization on the correspondence matrix, allowing our refinement procedure to resolve violations and re-rank false correspondences via neighborhood consensus. Our approach simplifies graph matching computations using trainable neural networks to update correspondence scores based on input similarities. We propose relaxing the constraint of sinkhorn normalization by applying row-wise softmax normalization on the correspondence matrix, allowing our refinement procedure to resolve violations and re-rank false correspondences via neighborhood consensus. Experimentally, we show that row-wise normalization is sufficient for our algorithm to converge to the correct solution. Additionally, we vary the number of refinement iterations for training and testing, which speeds up training runtime and encourages convergence with fewer steps. Our method is verified on synthetic graphs and real-world tasks of supervised keypoint matching in natural images and semi-supervised cross-lingual knowledge graph alignment. Our method is implemented in PYTORCH using the PYTORCH GEOMETRIC and KEOPS libraries for efficient processing of sparse mini-batches with GPU acceleration. Optimization is done via ADAM with a fixed learning rate. Hits@k is used to evaluate the model's performance in experiments on synthetic graphs and real-world tasks. In the first experiment, the method is evaluated on synthetic graphs to learn matching for pairs of graphs. The graphs consist of Erd\u0151s & R\u00e9nyi graphs with different node sizes and edge probabilities. Training and evaluation are conducted on various graph configurations. Additional experiments in Appendix E test the approach's robustness to node changes. The graph neural network operators are implemented with GIN operators for structure distinction. Architecture parameters include three layers, hidden dimensionality of 32, and ReLU activation. Input features are initialized with one-hot encodings of nodes. The method uses MLPs with 2 layers and 32 hidden dimensions, ReLU activation, and one-hot encodings of node degrees. A Jumping Knowledge style concatenation is used to compute final node representations. The proposed two-stage architecture outperforms purely local matching approaches, even with increasing structural noise. Matching consensus is applied to recover all correspondences, highlighting the benefits of the approach. The refined architecture using random node indicator sampling and row-wise normalization outperforms local matching approaches, even with structural noise. The method converges by increasing the number of iterations during testing and shows improved performance on sparsified correspondences. Increasing the top k ranking helps recover correct correspondences, making it scalable for large graphs. Experiments were conducted on PASCALVOC with Berkeley annotations. The experiments were conducted on the PASCALVOC and WILLOW-OBJECTCLASS datasets, with pre-filtered images for training and testing. PASCALVOC dataset includes instances of varying scale, pose, and illumination, while WILLOW-OBJECTCLASS dataset consists of images with consistent orientations and 10 keypoints each. The WILLOW-OBJECTCLASS dataset contains 40 images per category with consistent orientations and 10 keypoints each. The model is pre-trained on PASCALVOC and fine-tuned on 20 random splits with 20 images per class for training. Graphs are constructed using Delaunay triangulation of keypoints, and input features are extracted from a pre-trained VGG16 model. The graph neural network operator used is SPLINECNN with B-spline based kernel function. Results are evaluated for isotropic and anisotropic cases. To align with related work, evaluation is done for isotropic and anisotropic cases using edge features like normalized distances and 2D coordinates. SPLINECNN employs a kernel size of 5, hidden dimensionality of 256, ReLU non-linearity, and a network architecture with two convolutional layers, dropout, and a linear layer. Training involves forming pairs of examples from the same category and model evaluation by sampling a fixed number. Our network architecture includes two convolutional layers, dropout, and a linear layer. Training involves forming pairs of examples from the same category, and evaluation is done using isotropic and anisotropic GNNs. Results show that our refinement strategy outperforms competing methods and reduces errors significantly. Our refinement strategy significantly outperforms competing methods, reducing errors by half on the WILLOW-OBJECTCLASS dataset. Starting from a weaker baseline, improvements of up to 14 percentage points are seen on PASCALVOC. Task-specific isotropic or anisotropic GNNs are used for further enhancement. The model's generalization capabilities are tested on the PASCALPF dataset, showing promising results. For training, a synthetic set of graph pairs is generated by sampling source points and adding Gaussian noise. Outliers are also added to each point cloud, and graphs are constructed by connecting nodes with their k-nearest neighbors. The unmodified anisotropic keypoint architecture is trained with input x i = 1 until 32,000 synthetic examples are seen. The trained model is evaluated on the PASCALPF dataset, showing improved results compared to the state-of-the-art. The method also performs well on the DBP15K datasets. Our method, evaluated on the DBP15K datasets, shows benefits of our consensus stage and works well without visual information. We use monolingual FASTTEXT embeddings for entity input features and a graph neural network operator similar to Xu et al. (2019d). Architecture includes ReLU followed by dropout with probability 0.5 as non-linearity. Our graph neural network operator, inspired by Xu et al. (2019d), uses ReLU and dropout for non-linearity. A three-layer GNN with dimensions 256 and 32 is used for initial similarities and refining alignments. Training involves negative log likelihood in a semi-supervised manner. Results are evaluated using Hits@1 and Hits@10 metrics, comparing our model to previous work. Our approach improves upon the state-of-the-art on all categories with gains of up to 9.38 percentage points. The refinement strategy consistently enhances Hits@1 results, while Hits@10 results are affected by the refinement operating on sparsified top 10 initial correspondences. The scalability of our approach allows for multiple refinement iterations while maintaining large hidden feature dimensionalities. Experimental results show the effectiveness of our proposed approach in solving real-world problems, although it inherits limitations related to the expressive power of GNNs and the WL heuristic for graph isomorphism testing. The limitations of our approach are related to the expressive power of GNNs and the WL heuristic for graph isomorphism testing. One possible limitation is the failure to converge when two nodes are assigned the same color by WL, leading to non-convergence in finding solutions. Adding noise to resolve ambiguities is theoretically possible but unlikely due to the presence of feature noise in real-world datasets. Various domains have studied identifying correspondences between nodes in graphs, with related problems summarized under terms like maximum common subgraph, network alignment, graph edit distance, and graph matching. Recently, graph neural networks have become a focus of research for deep graph matching techniques, aiming to learn node correspondences between graphs. A two-stage neural architecture was presented for supervised or semi-supervised learning, focusing on reaching a neighborhood consensus between matchings and scaling to large input domains. The approach was evaluated on real-world datasets. The proposed algorithm aims to reach a consensus between graph matchings and can handle violations iteratively. Enhancements were made to scale the algorithm to large input domains, and it outperformed existing methods on real-world datasets. The final optimized algorithm is detailed in Algorithm 1. The proposed algorithm extends the graduated assignment algorithm by introducing trainable parameters. It aims to distinguish graph structures using injective node colorings and permutation matrices. The algorithm ensures isomorphisms between subgraphs and handles violations iteratively. Our algorithm extends the graduated assignment algorithm with trainable parameters, improving results compared to fixed-function message passing. It can learn to utilize node and edge features for refinement and offers flexibility in choosing task-dependent GNN operators. The approach's robustness towards node addition/removal was experimentally validated. Our approach, which extends the graduated assignment algorithm with trainable parameters, has been experimentally validated for robustness towards node addition or removal. Graph-pairs are formed using Erd\u0151s & R\u00e9nyi graphs, with the consensus stage showing high robustness to changes in nodes. The neural architecture can detect and reduce false positive influences during refinement. Our neural architecture can detect and reduce false positive influences during refinement by identifying correspondences between nodes of two graphs. The problem of maximum common subgraph isomorphism is NP-hard and difficult to approximate, with exact algorithms available for specific variants relevant in cheminformatics. Different techniques have been developed in bioinformatics and computer vision for solving this problem. The complexity results show that exact polynomial-time algorithms are only available for specific variants in cheminformatics. In bioinformatics and computer vision, the problem is known as network alignment or graph matching, where non-exact techniques are used for large networks without specific structural properties. Graph matching involves minimizing a function for two graphs of order n, with a long line of research focusing on optimization algorithms. Graph matching research focuses on minimizing a function for two graphs of order n using optimization algorithms like the Frank-Wolfe algorithm. Various studies have explored the applicability of relaxation and projection techniques, with some theoretical results existing. The WL heuristic and its modifications have been studied, showing correct solutions for specific graph classes. Different relaxations, their complexity, and properties have also been investigated in the field of graph matching. The problem of graph matching is closely related to the quadratic assignment problem (QAP) and involves spectral properties of adjacency matrices. Various approaches exist, such as spectral relaxations and random walks. Recent literature considers weighted versions, leading to Lawler's QAP formulation. Different studies have proposed factorizing affinity matrices and incorporating global geometric constraints for computational efficiency. Kernelized graph matching has also been explored, utilizing node and edge similarities as kernels. De la Torre (2016) proposed factorizing the affinity matrix into smaller matrices and incorporating global geometric constraints. Zhang et al. (2019c) studied kernelized graph matching using node and edge similarities as kernels, expressing the problem as Koopmans-Beckmann's QAP in the associated Hilbert space. Swoboda et al. (2017) explored Lagrangean decompositions of the graph matching problem solved by dual ascent algorithms. Functional representation for graph matching has been proposed to avoid constructing the affinity matrix. The graph edit distance measures the minimum cost to transform one graph into another by adding, deleting, and substituting vertices and edges, relevant for pattern recognition tasks. The graph edit distance measures the minimum cost to transform a graph by adding, deleting, and substituting vertices and edges. It is related to the quadratic assignment problem and has algorithms for computation, including heuristics based on the assignment problem. The original approach requires cubic running time but can be reduced to quadratic or even linear time with different strategies. Network alignment is defined similarly to the graph edit distance. Network alignment is a problem that can be solved using greedy strategies to reduce time complexity, with some algorithms achieving linear time for certain cost functions. Most algorithms follow a two-step approach involving computing a node-to-node similarity matrix and then solving the assignment problem. Various methods have been proposed, such as ISORANK based on the adjacency matrix of the product graph and efficient approximations to avoid large graph sizes. Extensions supporting vertex and edge similarities have also been presented. Various methods have been proposed for network alignment, including efficient approximations to avoid large graph sizes, extensions supporting vertex and edge similarities, and linearizing the optimization problem to obtain an integer linear program. Recent approaches aim to learn node and edge similarity functions for specific tasks, with a more principled approach focusing on learning correspondences. The method presented in this work is related to deep graph matching procedures, which have been investigated from various perspectives. Recent research has focused on developing supervised deep graph matching networks with differentiable spectral graph matching solvers. Our matching procedure is fully-learnable, unlike previous approaches. Recent research has focused on developing supervised deep graph matching networks with differentiable spectral graph matching solvers. Wang et al. (2019b) use node-wise features and dense node-to-node cross-graph affinities for linear assignment. Zhang & Lee (2019) propose a compositional message passing algorithm for point coordinates. Xu et al. (2019b) relate graph matching to Gromov-Wasserstein discrepancy and enhance the optimal transport objective by learning node embeddings. In recent research, supervised deep graph matching networks have been developed using differentiable spectral graph matching solvers. Various approaches have been explored, such as utilizing node embeddings to enhance the optimal transport objective and leveraging CYCLEGANs for network alignment. Additionally, methods like global and local network topology preservation and graph neural networks have been used for tasks like multi-graph partitioning and matching. In recent research, supervised deep graph matching networks have been developed using differentiable spectral graph matching solvers. Various approaches have been explored, such as utilizing node embeddings to enhance the optimal transport objective and leveraging CYCLEGANs for network alignment. Additionally, methods like global and local network topology preservation and graph neural networks have been used for tasks like multi-graph partitioning and matching. et al. (2018) utilize a fast, but purely local and greedy matching procedure based on local node embedding similarity. Bai et al. (2019) use shared graph neural networks to approximate the graph edit distance between two graphs. In a follow-up work, Bai et al. (2018) proposed to order the correspondence matrix in a breadth-first-search fashion and to process it further with the help of traditional CNNs. Both approaches only operate on local node embeddings, and are hence prone to match correspondences inconsistently. Wang et al. (2019b) enhance the GNN operator by not only aggregating information from local neighbors, but also from similar embeddings in the other graph by utilizing a cross-graph matching procedure. Xu et al. (2019d) leverage alternating GNNs to propagate local features of one graph throughout the second graph. Wang & Solomon (2019) tackle the problem of finding an unknown. In recent research, methods have been developed to improve graph matching by leveraging node embeddings and graph neural networks. Wang et al. (2019b) enhance the GNN operator by aggregating information from local neighbors and similar embeddings in the other graph. Xu et al. (2019d) use alternating GNNs to propagate local features between graphs. Wang & Solomon (2019) address the problem of finding unknown rigid motions between point clouds through a point cloud matching approach. These methods aim to strengthen initial feature matching procedures and improve consistency in correspondences. Consistency of correspondences in local neighborhoods has a rich history in computer vision, with methods dating back several years. A deep neural network for neighborhood consensus using 4D convolution was proposed, but it cannot be efficiently transferred to the graph domain directly. Our algorithm infers errors for the product graph but performs computations on the original graphs. The functional maps framework defines continuous maps between function spaces on manifolds."
}