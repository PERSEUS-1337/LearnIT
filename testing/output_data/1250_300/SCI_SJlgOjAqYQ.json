{
    "title": "SJlgOjAqYQ",
    "content": "We conducted experiments on convolutional and capsules neural networks to test global translation-invariance in deep learning models trained on the MNIST dataset. Both models initially showed poor performance in this aspect, but data augmentation improved their performance. While the capsule network performed better on the MNIST testing dataset, the convolutional neural network generally had better translation-invariance performance. CNNs have achieved state-of-the-art performance in computer vision tasks due to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. CNNs need to learn different models for different viewpoints, requiring big data and high costs, while a more generalized model should perform well across a wider range of viewpoints. Capsule network aims for 'rate-coded' equivariance by including pose, color, lighting, and deformation of visual entities in groups of neurons. It focuses on viewpoint-invariant knowledge coded in weights, not neural activities. Viewpoint changes in capsule networks have linear effects on pose matrices between layers, but their ability to generalize for global translation invariance remains unclear. Analyzing translation-sensitivity maps for the MNIST dataset in CNNs is crucial for understanding architectural choices and developing viewpoint-invariant models. In this study, a simple method is introduced to test global translation-invariance in convolutional and capsule neural network models trained on the MNIST dataset. A testing dataset is created by shifting the centre of mass of a Helvetica font digit one pixel at a time. This dataset consists of 2520 images covering all possible cases of translational translations. The deep learning models are trained on the MNIST dataset and tested on both the MNIST testing dataset and the GTI testing dataset. The study introduces a method to test global translation-invariance in CNN and capsule neural network models trained on the MNIST dataset. The testing dataset includes 2520 images covering all possible translational translations. The models are trained on MNIST and tested on both MNIST and GTI datasets. The GTI dataset allows for capturing tiny differences in models and quantifying global invariance. The CNN model has nine layers, including convolutional layers. The CNN model has nine layers with convolutional and fully connected layers, using ReLU activation function and Adam optimizer. It achieves high accuracy on the MNIST testing set but only 42.16% accuracy on the GTI testing dataset, indicating challenges with global translational invariance. The CNN model trained on MNIST data achieves high accuracy on the MNIST testing set but only 42.16% accuracy on the GTI testing dataset, indicating challenges with global translational invariance. Images with the digit's centre of mass around the canvas centre are predicted correctly, while those at the corner are assigned to incorrect classes. To improve performance on the GTI dataset, data augmentation by shifting images from the centre in x and y-direction increased accuracy to 98.05%. Without Augmentation Shift 20% in training data, we improved CNN performance on the GTI dataset by training MNIST with data augmentation. The accuracy on GTI testing dataset increased to 98.05% by randomly shifting the image center in x and y-direction. Capsule network's performance on global invariance still needs improvement. The Capsule network's performance on global invariance needs improvement, as shown in experiments with MNIST data. Data augmentation in the training dataset helps improve accuracy on the GTI dataset. CNN generally outperforms CapsNet on the GTI dataset, even with wider receptive fields in CapsNet's convolutional layers. The Capsule network's performance on global translational invariance needs improvement, as shown in experiments with MNIST data. CapsNet struggles with handling translational invariance without data augmentation, but its architecture has potential advantages over CNN in learning viewpoints. The GTI testing dataset was introduced to compare CNN and CapsNet performance, with CNN generally outperforming CapsNet even with wider receptive fields. The testing method involves using the GTI dataset to evaluate the accuracy of models trained on CNN and CapsNet with different amounts of random shifting in the MNIST training dataset. This method is quantifiable and easy to implement for other computer vision tasks by applying translational shifting to cover all possible cases."
}