{
    "title": "SyjjD1WRb",
    "content": "We establish a theoretical link between evolutionary algorithms and variational parameter optimization of probabilistic generative models with binary hidden variables. Two models are used to investigate applicability: a noisy-OR Bayes Net and Binary Sparse Coding. Learning of generative models is formulated as approximate maximum likelihood optimization using variational expectation maximization. Evolutionary algorithms can be used for variational optimization by treating latent states as genomes and defining fitness based on joint probabilities from the generative model. The novel evolutionary EM approach is applied to optimize parameters of noisy-OR Bayes nets and binary sparse coding on artificial and real data. Scalable variational EM algorithms efficiently improve data likelihood using point mutations and single-point cross-over. Evolutionary algorithms are introduced as tools for function optimization inspired by biological processes, with potential to address parameter optimization in generative models. Evolutionary algorithms (EAs) have been applied to various tasks such as clustering, reinforcement learning, and deep supervised learning. They are often used to solve specific sub-problems, such as selecting the best architectures or hyper-parameters for Deep Neural Networks. Inspired by previous contributions, the question is raised if EAs and learning algorithms can be more closely linked through probabilistic generative models and expectation maximization (EM) approaches for parameter optimization. This approach provides a general framework that encompasses diverse algorithms for tasks ranging from clustering to deep learning. The probabilistic approach in combination with EM provides a general framework for diverse algorithms in clustering, dimensionality reduction, feature learning, sparse coding, and deep learning. Variational EM is a prominent approximation method for computationally intractable generative data models, continuously developed for efficiency and accuracy. Latent states as variational parameters in the EM algorithm can be optimized using Evolutionary Algorithms (EAs) for parameter optimization in high-dimensional spaces. Evolutionary Algorithms (EAs) are a natural choice for optimizing generative models in the variational loop of EM. The goal is to find maximum likelihood (ML) parameters \u0398* that maximize the data log-likelihood. To efficiently find these parameters, a lower bound of the log-likelihood, the free energy F(q,\u0398), is maximized. This involves variational distributions q(n)(s) and the entropy H(q). In this study, the focus is on training elementary generative models with large state spaces using variational distributions to approximate intractable posterior distributions. The goal is to maximize the free energy F(q,\u0398) to find approximate maximum likelihood solutions. Variational EM algorithms involve iteratively maximizing F(\u039b,\u0398) with respect to the parameters \u039b in the variational E-step. Standard approaches include Gaussian and mean-field variational distributions. The variational EM algorithm involves maximizing F(\u039b,\u0398) iteratively in the E-step with respect to \u039b and in the M-step with respect to \u0398. Truncated variational distributions are chosen for evolutionary algorithms, with populations of hidden states denoted as K n for data points y (n). Expectation values are computed using these distributions, approximating full posteriors well. The variational EM algorithm involves maximizing F(\u039b,\u0398) iteratively in the E-step with respect to \u039b and in the M-step with respect to \u0398. Truncated variational distributions are chosen for evolutionary algorithms, with populations of hidden states denoted as K n for data points y (n). Expectation values are computed using these distributions, approximating full posteriors well. The free-energy takes a simplified form when using truncated distributions as variational distributions, with variational parameters given by populations of hidden states. The variational E-step involves finding the population K n that maximizes p ( y n , s | \u0398) for each data point n. The variational EM algorithm maximizes the free energy in the E-step by selecting individuals with the largest joint probabilities. Increasing the free energy is computationally easier than full maximization, and choosing a fitness function that increases fitness will result in higher free energies. The variational EM algorithm, along with M-step optimizations, monotonously increases the free energy. The freedom to choose a fitness function enables efficient parent selection. The freedom to choose a fitness function enables efficient parent selection in the optimization process. The fitness function is defined to increase the free energy, with logP being a more computable and stable function. The EA seeks to optimize the fitness for a population of individuals iteratively. The EA iteratively optimizes the fitness of a population of unique individuals using genetic operators like parent selection, single-point crossover, and stochastic mutation. The process involves selecting parents with high fitness for exploitation and mutating poor performing parents to increase population diversity over N g generations. In genetic algorithms, the balance between exploiting parents with high fitness and exploring mutations of poor performing parents is crucial for generating diverse children with high fitness. Parent selection can be fitness-proportional or random, followed by crossover where parents swap bits to produce offspring. Mutation is then applied to the children to further enhance population diversity. The Evolutionary Expectation Maximization algorithm involves parent selection, crossover, and mutation to generate diverse offspring. Crossover involves swapping bits, while mutation introduces random bitflips to increase diversity. A refined bitflip algorithm assigns different probabilities to 0's and 1's for sparsity-compatible offspring. If crossover is skipped, a different bitflip mutation is performed on copies of each parent. The algorithm iterates to update model parameters until a sufficient increase in fitness is achieved. The Evolutionary Expectation Maximization algorithm involves parent selection, crossover, and mutation to generate diverse offspring. The algorithm produces new states by updating parameters until fitness increases sufficiently. The learning algorithm aims to optimize log-likelihood with EAs as an integral part. The noisy-OR model is a non-linear bipartite data model with all-to-all connectivity among hidden and observable variables. The noisy-OR model is a highly non-linear bipartite data model with all-to-all connectivity among hidden and observable variables. It assumes a Bernoulli prior for the latents and uses the noisy-OR rule to combine active latents. Binary Sparse Coding (BSC) is a model for continuous data with binary latent variables following a Bernoulli distribution. Latents are combined using a linear superposition rule, and observables are drawn from a Gaussian distribution. The parameters of the model for Binary Sparse Coding (BSC) include \u0398 = (\u03c0, W, \u03c3 2 ), where W is a D \u00d7 H matrix with weights for hidden units and \u03c3 2 determines Gaussian variance. M-step update rules for BSC are derived by optimizing free energy. Numerical experiments test the applicability and scalability of Evolutionary EM (EEM) using different evolutionary algorithms with artificial data. Evolutionary EM (EEM) is applied to the bars test using artificial data with known ground-truth components. Different configurations of the EA are used for noisy-OR, with a focus on reliability as a performance metric. The study focuses on the reliability of Evolutionary EM (EEM) in solving the bars test with artificial data. Different EA configurations are compared, showing that \"fitparents-sparseflips\" is more exploitative than \"randparents-randflips\" on 8x8 images. However, crossover reduces the probability of finding all bars accurately. The study then increases the difficulty by overlapping bars and suggests using a noisy-OR model to handle occlusion effects. Evolutionary EM (EEM) is tested on a bars data-set with sensible overlaps using a noisy-OR model to handle occlusion effects in images. Results show that EEM successfully recovers all bars in 13 out of 25 runs, demonstrating competitive performance without additional assumptions. Additionally, EEM is evaluated on a linear BSC model, solving standard bars tests with high reliability even with random bitflips. Evolutionary EM (EEM) was tested on a bars data-set with overlaps using a noisy-OR model to handle occlusion effects in images. The bars were superimposed linearly BID6, making the problem easier. To increase the challenge, the data dimensionality was increased to D = 10 \u00d7 10 bars images, the number of components to H gen = 20, and the average number of bars per data point to five. With 5,000 training data points, different configurations of the EA were tested, showing that basic approaches like random uniform selection of parents and bitflips work well, but more sophisticated EAs improve performance. The experiment results in Fig. 5 show that basic approaches like random uniform selection of parents and bitflips are effective, but more advanced EAs perform better. Combining bitflips with crossover and selecting parents based on fitness is highly beneficial. However, sparseness-driven bitflips generally lead to poor performance, even with additional strategies like crossover or proportional parent selection. The difficulty for sparseness-driven EAs to explore and find solutions with higher crowdedness may be due to the initialization of K n. Averaged free energy values for the experiment are depicted in FIG5 in appendix C. The experiment involves using natural image patches from the van Hateren database BID35, specifically raw images without preprocessing. These patches are converted to binary entries using a Bernoulli distribution. The non-linear nature of light-intensity images due to occlusion motivates the use of a non-linear generative model like noisy-OR. The experiment involves using natural image patches from the van Hateren database BID35, converted to binary entries using a Bernoulli distribution. A non-linear generative model like noisy-OR is used due to the non-linear nature of light-intensity images. Generative fields resembling curved edges are learned over 200 iterations. Pre-processed image patches using common whitening approaches are considered for sparse coding. The BSC model is trained for 4,000 iterations. The BSC model was trained for 4,000 iterations using ZCA whitening BID0 and generative fields primarily took the form of Gabor functions. Over five units were activated per data point, showing the learned code's multiple causes structure. Generative fields converged faster than noise parameters, with a finit slope of the free-energy after 4000 iterations. The training of generative models in Machine Learning often requires approximations, such as sampling or variational EM, due to the slow convergence of parameters. Evolutionary algorithms (EAs) have been used in conjunction with EM, with EAs optimizing model selection while EM updates parameters conventionally. This approach is similar to DNN optimization, where EAs optimize hyperparameters in an outer loop. Evolutionary algorithms (EAs) have been used in conjunction with EM for training generative models, addressing key optimization problems. This novel approach combines EAs and EM directly, leveraging knowledge from evolutionary approaches for learning algorithms. Numerical experiments show that EAs can effectively train generative models with large hidden spaces and local optima. The experiments demonstrate that evolutionary algorithms (EAs) can train generative models effectively, especially with large hidden spaces and local optima. Basic EAs were used in the experiments, but more specialized EAs tailored to specific optimization problems in generative model training hold promise for future improvements in accuracy and scalability. The results represent the first instances of noisy-OR or sparse coding models being trained with EAs, showcasing a novel mathematically grounded approach for generative models with binary latents. The approach presented involves using generative models with binary latents, specifically focusing on the Noisy-OR model. The M-step equations for updating parameters are derived from the free energy, with the update rule for one parameter being straightforward while the others require a fixed-point equation approach for optimization. The training algorithm aims to converge towards maximizing the free energy, with drops in free energy during training attributed to the optimization process. The training algorithm aims to converge towards maximizing the free energy by exploiting the fact that one evaluation of 13 is enough to move towards convergence. Drops in free energy during training can be corrected by checking misbehaviors of 13. Update rules for model parameters are obtained by optimizing expressions separately. Exact EM is achieved by setting q n to the exact posterior, but for computational tractability, approximate posteriors are used. Sparsity-driven bitflips involve flipping bits with specific probabilities. The truncated free energy takes the form where sparsity-driven bitflips involve flipping bits with specific probabilities. Comparisons with other algorithms show that EMM for noisy-OR performs well, but there are approaches with higher reliability. Most approaches recovering more than 15 bars require additional assumptions, except for MCA 3 and DI. Approaches recovering more than 15 bars on average require additional assumptions, except for MCA 3 and DI. MCA 3 is a generative model without constraints, exploring sparse combinations with up to 3 components. DI is a neural network approach with difficult-to-infer assumptions. MCA 3 evaluates over 60000 states per data point per iteration for learning, while EEM for noisy-OR evaluates around 100 states. Generative fields learned with EEM for noisy-OR show a crowdedness of 1.6 after 175 iterations with 200 latent variables."
}