{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The generator architecture is structured based on a causal graph for conditional and interventional sampling of face images with binary feature labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. The CiGM over labels and images is learned in a two-stage procedure using Wasserstein GAN and conditional GAN. The optimal generator of the CausalGAN samples from image distributions conditioned on labels. The proposed architectures can sample from observational and interventional image distributions, even for interventions not in the dataset. Generative adversarial networks (GANs) are successful in training implicit generative models by sampling from high dimensional distributions. The generator network uses a noise vector to model the sampling process, refined by a discriminator network. Generative adversarial networks (GANs) use a generator to produce samples from a noise vector, refined by a discriminator network. The generator aims to deceive the discriminator by generating samples that resemble real data. GANs have been successful in generating samples from various distributions like images and videos. Extensions include sampling from class conditional data distributions by providing class labels to the generator. Various neural network architectures have been proposed for this task. In this paper, the focus is on extending conditional image generation by capturing the dependence and causal effect between labels. The generator in conditional image generation is a non-deterministic mapping from labels to images, following a causal graph where labels determine the image distribution. The causal relation between labels, such as Gender causing Mustache, can also be included in the model. The paper focuses on extending conditional image generation by capturing the causal relationship between labels. For example, Gender causing Mustache can be represented in a causal graph. Interventions in causal models fix the value of a variable, affecting the distribution of its descendants but not its ancestors. The paper introduces causal implicit generative models (CiGM) that can sample from joint, conditional, and interventional probability distributions based on a given causal graph. The approach uses GANs, specifically Wasserstein GAN (WGAN), to train CiGM for binary image labels. Additionally, two novel conditional GANs, CausalGAN and CausalBEGAN, are proposed for training CiGM for images and image labels. The paper introduces causal implicit generative models (CiGM) using Wasserstein GAN (WGAN) to train CiGM for binary image labels. Two novel conditional GANs, CausalGAN and CausalBEGAN, are proposed for training CiGM for images and image labels. The optimal generator of CausalGAN can sample from true conditional distributions, and combining it with CiGM yields a CiGM for binary labels and images. The paper introduces a two-stage procedure to train a CiGM over binary labels and images, proposing a novel conditional GAN architecture and loss function. They show that the optimal generator samples from class conditional distributions. CausalGAN and CausalBEGAN are evaluated on labeled CelebA data, producing high-quality label-consistent images even for interventions not seen during training. Previous works on conditional GANs are discussed, such as CGAN and ACGAN. In BID6, authors propose conditional GAN (CGAN) to extend generative adversarial networks with extra information like labels. BID10 introduces ACGAN where the discriminator estimates the label instead of receiving it as input. BID15 presents InfoGAN, aiming to maximize mutual information between inputs and images. BiGAN and ALI extend GAN by learning a mapping to a latent space. CoGAN learns a joint distribution over images and binary labels. SD-GAN splits the latent space into \"Identity\". In CoGAN and SD-GAN, the latent space is split into \"Identity\" and \"Observation\" portions. SD-GAN extends BEGAN to accept labels, such as age intervals encoded in a one-hot vector. Generative models can also be used in compressed sensing to recover vectors close to the output of a trained model. Generative models, causal principles, and deep learning techniques are being explored in recent research. Various studies have linked GAN layers to structural equation models and used neural networks for causal inference. New regularization methods like causal regularization are proposed to ensure predictive causality in neural networks. Some works highlight the connection between GANs and causal generative models, focusing on causal graphs and causal relations between variables. In recent research, the connection between GANs and causal generative models is explored. Authors use neural networks to learn causal graphs and mimic structural equations. Causality is introduced using Pearl's framework, which involves structural causal models and directed acyclic graphs to represent causal relationships between random variables. A causal graph represents the relation between variables in a structural causal model. It is a directed acyclic graph implied by the structural equations, showing the causes of each variable. The graph is constructed from the functions and random variables in the model, with observable variables having a joint distribution based on exogenous variables and functional relations. An intervention can be made based on the causal graph. The causal graph D is a directed acyclic graph based on functional relations F, where nodes represent variables and their relationships. An intervention changes the causal mechanism by altering the graph. Interventions remove connections between nodes, unlike conditioning. Post-interventional distribution can be calculated using Bayesian network factorization. After an intervention on a set of nodes in a Bayesian network, the post-interventional distribution can be calculated by factorizing the observational distribution. It is challenging to identify the true causal graph without experiments or additional assumptions, as multiple causal graphs can produce the same joint probability distribution. This paper focuses on learning a causal model assuming the causal graph is known, with prior work available on learning causal graphs. The text discusses the use of Bayesian networks to sample from observational and interventional distributions in causal graphs. It introduces causal implicit generative models that can sample from both types of distributions and proposes using generative adversarial networks for training these models. The text also mentions arranging generator neural network connections to reflect the causal graph structure in the GAN training framework. The text discusses using Bayesian networks to sample from observational and interventional distributions in causal graphs. It introduces causal implicit generative models that can sample from both types of distributions and proposes using generative adversarial networks for training these models. The model can be written as DISPLAYFORM0 DISPLAYFORM1, with generator neural network connections reflecting the causal graph structure. The feedforward neural networks represent functions f X , f Y , f Z , with independent noise terms (N X , N Y , N Z ). Gaussian distributed variables BID8 ) N X , N Y , N Z can be used. The proposition states that two causal models with the same observational distribution have the same interventional distributions for any intervention. Observational and interventional distributions in causal graphs can be sampled using Bayesian networks. Causal implicit generative models, linked to feedforward neural networks, can generate samples from these distributions. Adversarial training is proposed for training these models to align with the causal graph structure. The proposed approach involves using adversarial training to align the generator neural network with the causal graph. The training process focuses on dividing the task into two subtasks: training a generative model for labels and then for images conditioned on the labels. This architecture, known as CausalGAN, ensures that the generator outputs optimal results consistent with the causal structure. The CausalGAN architecture aligns the generator with the causal graph by training a generative model for labels and images conditioned on the labels. The Causal Controller network sequentially produces labels according to the causal graph, ensuring optimal results for binary labels. The Causal Controller network generates labels based on the causal graph. A new conditional GAN architecture is designed to generate images based on these labels, ensuring optimal label-conditioned image distributions. Two separate labeler neural networks, Labeler and Anti-Labeler, are used for estimating labels. Our new architecture and loss function ensure that the generator outputs label-conditioned image distributions. We use a pretrained Causal Controller and have separate Labeler and Anti-Labeler neural networks. The generator's objective is to produce realistic images, consistent with labels, and avoid easy-to-label unrealistic image distributions. CausalGAN's key distinction is the use of an Anti-Labeler network, crucial for discouraging the generator from outputting only typical faces for a fixed label combination. The Anti-Labeler loss discourages label-conditioned mode collapse in the network by promoting diversity in generated images for different label combinations. Using Anti-Labeler aids faster convergence and helps combat mode collapse, especially for rare label combinations. The results for a single binary label are presented, with potential extension to more labels, showcasing the effectiveness of the approach. The CausalGAN model includes mappings for the generator, discriminator, Labeler, and Anti-Labeler. The generator loss function incorporates label loss terms, GAN loss, and an additional loss term from the discriminator. The optimal generator outputs the class conditional image distribution, even for multiple binary labels. The Labeler, Anti-Labeler, generator, and discriminator each have specific optimization problems to solve within the CausalGAN framework. The CausalGAN generator samples from the class conditional image distribution based on the given loss function. The CausalGAN generator solves the optimization problem for a fixed discriminator, Labeler, and Anti-Labeler by sampling from the class conditional image distribution. This architecture guarantees optimal performance when the Causal Controller samples from the true label distribution, and the discriminator and labeler networks operate at their best. The proof extends to multiple binary variables, with the optimal discriminator behavior similar to GAN loss. The generator minimizes the loss function to sample effectively. The optimum discriminator, labeler, and anti-labeler are characterized by Proposition 2, Lemma 1, and Lemma 2 in the appendix. The generator minimizes the loss function to sample from class conditional distributions. The global minimum of the virtual training criterion is achieved when the generator output matches the class conditional image distribution. The two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The generator in a causal graph model samples from image distribution based on given labels. The objective is to extend this to multiple labels. A new architecture using cross entropy loss terms for each label is proposed to simplify implementation. The architecture extends the single binary label setup by using cross entropy loss terms for each label. The generator captures the joint label posterior given the image, ensuring that the joint label posterior will be true to the data distribution. Causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms. The trained causal implicit generative models can sample from counterfactual distributions with known exogenous noise terms. To enable counterfactual sampling, conditioning on an event and sampling from the push-forward of the posterior distributions of the exogenous noise terms is necessary. This involves rejection sampling to observe evidence and interventional sampling. An extension of BEGAN involves feeding image labels to the generator, using a Labeler network for labeling real images well and generated images poorly. Margin modifications are motivated by observations on BEGAN discriminator training. The CausalGAN and CausalBEGAN models are trained on the CelebA Causal Graph, with a focus on margin modifications and observations on label and image quality. The Causal Controller is also trained on the dataset, with a specific example involving the relationship between male and mustache labels in the CelebA Causal Graph. The CausalGAN and CausalBEGAN models are trained on the CelebA Causal Graph, focusing on margin modifications and label-image quality. A novel generative model with label inputs can sample from interventional distributions, providing guarantees on correct sampling under interventions. Our generative model can sample from interventional distributions and provide guarantees on correct sampling under interventions. Intervening or conditioning on the Narrow Eyes label in the CelebA Causal Graph with CausalBEGAN shows an increase in the proportion of smiling images. Causality in generative models leads to creativity by producing samples different from training data. The research demonstrates that causality in generative models, such as CausalGAN and CausalBEGAN, leads to increased creativity by generating samples different from training data. A structural causal model consists of functions, random variables, exogenous variables, and a probability distribution. The causal graph is a directed acyclic graph representing the relationships between variables. The causal graph D is a Bayesian network for the joint probability distribution over observable variables V. Causal sufficiency assumption allows for direct calculation of interventional distributions. Pr(l, x) is the joint data distribution, while Pg(l, x) is the joint distribution for the generator. The optimal discriminator D is determined for a fixed generator G. The optimum Labeler and Anti-Labeler are identified based on specific conditions. Lemmas 1 and 2 provide insights into the optimal strategies for Labeler and Anti-Labeler, respectively. The discussion assumes causal sufficiency in the model. The definition assumes causal sufficiency, where exogenous variables are mutually independent. The complete graph \"cG1\" is formed by adding edges. The global minimum of the virtual training criterion C(G) is achieved when P g (l, x) = P r (l, x). The optimum Labeler, Anti-Labeler, and discriminator are determined based on specific conditions. The generator output G(z, l) has the same distribution as the class conditional image distribution P r (x|l). The optimum Labeler, Anti-Labeler, and discriminator are determined based on specific conditions. In a conditional GAN, the concatenated generator neural network is consistent with the causal graph D. The concatenated generator neural network in a conditional GAN is consistent with the causal graph D, sampling from true label and image distributions. Modifications are explained for extending the proof to cases with multiple binary labels. The central difficulty in generalizing to a vector of labels is that each labeler can only learn about the posterior P(l j |x) for each label. Two solutions are proposed: (1) estimating the probability of each label combination, and (2) using Labelers to estimate the probabilities of each label, ensuring joint distribution equality. The extension and results are presented, with a Lemma provided for optimal Labeler loss. The Lemma presented discusses the optimal Labeler loss in estimating label probabilities based on image data. It highlights the importance of considering label combinations with positive probabilities to achieve a finite loss. The loss function is lower bounded by the Shannon entropy of the label variable, emphasizing the need to match the label distribution with the true posterior probabilities. The optimum Labeler network provides the posterior probability of label combinations based on observed images. The Anti-Labeler network aims to optimize the conditional entropy of labels given the generated image. The proof of Theorem 2 shows that the optimal generator samples from class conditional image distributions given specific label combinations. The global minimum of the virtual training criterion is achieved when the generator samples from the true joint label distribution. Criterion C(G) is achieved when the generator samples from the true joint label distribution, ensuring that P g (l, x) = P r (l, x). Theoretical guarantees for the CausalGAN architecture with d labels are provided under the assumption of a deterministic relationship between images and labels in the dataset. This assumption ensures that the global optimal generator samples from class conditional distributions. The global optimal generator samples from class conditional distributions based on a deterministic relationship between images and labels in the dataset. The generator, Labeler, and Anti-Labeler work together to achieve the global minimum of the virtual training criterion C(G). The global optimal generator achieves the minimum training criterion by sampling from class conditional distributions based on a deterministic relationship between images and labels. This relationship ensures correct conditional sampling given all labels. The lemma states that a discrete joint probability distribution with all marginal distributions as kronecker delta functions is the product of these marginals. The joint probability distribution is zero everywhere except at specific points. The text discusses the application of a lemma on conditional distributions and the proof that the optimum generator samples from class conditional image distributions. In this section, a new extension of BEGAN is proposed where image labels are fed to the generator. The contribution of BEGAN lies in its boundary equilibrium approach, inspired by control theory, which ensures generator training only when the discriminator is near optimum. A new loss and margins are introduced to reflect the idea that label gradients are most informative when image quality is high. The proposed extension of BEGAN involves feeding image labels to the generator. A new loss function and margins are introduced to optimize label gradients when image quality is high, ensuring meaningful gradients for image generation. The extension of BEGAN involves optimizing label gradients for image generation by introducing a new margin of margins term. This ensures meaningful gradients when image quality is high, leading to progressive convergence during optimization. The generator structure incorporates a causal graph to train a causal implicit generative model. In Section 4, a GAN is used to train a causal implicit generative model by incorporating a causal graph into the generator structure. The behavior and convergence of causal implicit generative models are investigated on synthetic data with different causal graphs. The convergence of the joint distribution to the true joint is compared for different generator structures based on line, collider, or complete graphs. In Section 4, a GAN is used to train a causal implicit generative model by incorporating a causal graph into the generator structure. The convergence of the joint distribution to the true joint is compared for different generator structures based on line, collider, or complete graphs. Data is generated from various causal graphs, and the results are shown in FIG9. The generator distribution's convergence behavior is analyzed based on the structured causal graphs used. The correct Bayesian network, such as a complete graph, can fit the true joint distribution well. Different generator structures based on line, collider, or complete graphs are compared for convergence behavior in fitting causal generative models. The number of layers in fully connected networks needs to be tuned for optimal performance in adversarial training. Using the wrong Bayesian network leads to worse performance. In practice, the number of layers in a fully connected generator should be tuned for optimal performance in adversarial training. Using the wrong Bayesian network, such as a collider graph, results in worse performance. Different generator structures show varying convergence behavior, with fully connected 3 and 5 layers performing the best for collider graphs. Line and collider graphs perform poorly compared to complete graphs, which show decent performance. The effect of using the wrong causal graph is evaluated on an artificially generated dataset, demonstrating the importance of choosing the correct Bayesian network. The effect of using the wrong causal graph on an artificially generated dataset is evaluated. Different causal graphs are used for experiments on the CelebA dataset, showing the importance of choosing the correct Bayesian network. The CelebA dataset experiments evaluate the impact of using the wrong causal graph. The CelebA Causal Graph (G1) and its completed version cG1 are analyzed, showing that despite some inaccuracies, both graphs lead to Causal Controllers that avoid certain label combinations. The CelebA Causal Graph (G1) and its completion cG1 lead to Causal Controllers that avoid specific label combinations. Using a modified Wasserstein GAN, the outputs have approximately discrete support, as shown in FIG12. The graphs allow training of reasonable marginal distributions. The CelebA Causal Graph (G1) and its completion cG1 enable training of reasonable marginal distributions for labels, with the Wasserstein Causal Controller outputting an almost discrete distribution. The generator learns a mapping from continuous noise to a discrete distribution, as demonstrated in FIG12. The proposed Causal Controller outputs an almost discrete distribution, with 96% of samples near 0 or 1. Total variational distance (TVD) shows convergence for CelebA Causal Graph (G1), completion (cG1), and reversed arrows (rcG1). TVD decreases to 0 for cG1 and rcG1, while G1 asymptotes to 0.14 due to incorrect assumptions. Bayesian partially incorrect causal graphs still show reasonable convergence. Additional results are presented in FIG3, 13, showing intervention vs conditioning on Wearing Lipstick in CelebA Causal Graph. Intervening/Conditioning on Wearing Lipstick in CelebA Causal Graph: When intervening on Wearing Lipstick=1, it does not affect the probability of Male=1. However, conditioning on Wearing Lipstick=1 results in only female images being shown. Similarly, intervening/conditioning on Narrow Eyes in the CelebA Causal Graph shows that while intervening does not affect the probability of Smiling=1, conditioning on Narrow Eyes=1 increases the proportion of smiling images. In this section, CausalBEGAN is trained on the CelebA dataset using the CelebA Causal Graph. The Causal Controller is pretrained with a Wasserstein loss and used for training the CausalBEGAN model. Empirical justification for the margin of margins introduced is shown by training the model without this margin, resulting in deteriorated image quality for rare labels. The difference between interventional and conditional sampling for the labels Bald and Mouth Slightly Open is illustrated. Conditioning on Bald in the CelebA Causal Graph is discussed, showing that intervening on Bald=1 does not affect the probability of Male=1. In this section, the CelebA Causal Graph is used to train CausalBEGAN. The Causal Controller is pretrained with a Wasserstein loss. Intervening on Bald=1 does not affect the probability of Male=1 in the dataset. Conditional image generation properties of CausalGAN are shown by sweeping a single label from 0 to 1 while keeping other inputs fixed. In this section, additional simulations for CausalGAN and CausalBEGAN are provided. CausalGAN's conditional image generation properties are demonstrated by sweeping a single label from 0 to 1 while keeping other inputs fixed. CausalBEGAN's simulation results show the impact of the third margin term on image quality and the monotonically decreasing scalar \"M\" during training. The conditional image generation properties of CausalBEGAN are also shown using \"label sweeps\" moving a single label input from 0 to 1 while keeping other inputs fixed. The conditional image generation properties of CausalBEGAN are demonstrated by using \"label sweeps\" to move a single label input from 0 to 1 while keeping other inputs fixed. The generator in this architecture learns a discrete function with respect to its label input parameters. A random sampling of 256 images is shown to examine mode collapse and image diversity. The approach attempts to jointly train an implicit causal generative model for labels and images, treating the image as part of the causal graph. The image generation for CelebA Causal Graph is not learned, possibly due to the discriminator focusing on labels without providing useful gradients for image generation. The implementation details of the Wasserstein Causal Controller for generating face labels are explained, using the total variation distance as a metric for model success. The Wasserstein approach allows training the Causal Controller to output discrete labels, although rounding them before passing to the generator still provides benefits. The generator architecture is structured based on the causal graph, utilizing uniform noise as exogenous variables. The generator architecture in the Causal GAN framework is based on a causal graph, using uniform noise as exogenous variables. Training involves 25 Wasserstein discriminator updates per generator update, with a learning rate of 0.0008. The model utilizes DCGAN Radford et al. (2015) and incorporates Labeler networks and a Causal Controller network. Six generator updates are made for each discriminator update on average, with concurrent updates of the discriminator and labeler networks in a single iteration. Loss terms are defined with a d-dimensional label vector and corresponding loss function. The discriminator and labeler networks are updated concurrently in a single iteration. Loss terms are defined with a d-dimensional label vector, and the Labeler and Anti-Labeler loss terms are extended by averaging the loss terms for every label. The architecture differs from the one in Section 8.6, as the discriminator outputs a length-2 d vector. This approach may not guarantee sampling from class conditional distributions if the data distribution is not restricted. However, for labeled image datasets where labels are completely determined by the image, this architecture is sufficient. For more details, refer to Section 8.7 in the supplementary material. The implementation of CausalBEGAN involves swapping the order of terms in cross entropy expressions for labeler losses, resulting in sharper images. Few parameter tunings are used, with a fixed learning rate for both generator and discriminator. Customized margin learning rates are employed to reflect asymmetry in response speeds. The model is not very sensitive to parameter values, achieving good performance without hyperparameter tweaking. The best performing models in CausalBEGAN have all three margins \"active\" near 0 while frequently taking small positive values. Comparing CausalGAN behavior with and without Anti-Labeler network, using Anti-Labeler allows for faster convergence and provides more diverse images for very rare labels."
}