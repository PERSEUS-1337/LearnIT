{
    "title": "rygDeZqap7",
    "content": "Natural language understanding research has shifted towards complex Machine Learning and Deep Learning algorithms, which often outperform simpler models but require large amounts of labeled data. To address this issue, a methodology for extending training datasets and training data-hungry models using weak supervision is proposed. This approach is applied to biomedical relation extraction, a task crucial for drug discovery but challenging to create training datasets for. Small-scale experiments show that this method enhances the performance of LSTM networks comparable to hand-labeled data. The methodology discusses the optimal setting for applying weak supervision in this context. The biomedical field has a growing number of scientific papers with important information encoded in unstructured text. Extracting and storing this information in a structured format can greatly impact tasks like drug design and adverse drug effect detection. Efforts have been made to automate Information Extraction in the past decade due to the labor-intensive nature of manual annotation. This work focuses on automating semantic triple extraction from biomedical abstracts, specifically on relations like Regulations (CPR) and Chemically Induced Diseases (CID) which are crucial for drug design and safety. The curr_chunk discusses the importance of extracting semantic triples from biomedical abstracts, focusing on relation extraction for Regulations (CPR) and Chemically Induced Diseases (CID). The text highlights the challenges of annotating training datasets for this task and proposes a methodology based on weak supervision to address this issue. The curr_chunk proposes a methodology based on weak supervision for relation extraction in biomedical abstracts. It involves training base learners on a small labeled dataset, using them to predict labels for a larger unlabeled dataset, deriving weak labels with a denoiser, and training a meta-learner using weak supervision. The methodology is specific to relation extraction but can be adapted to other supervised learning tasks. The effectiveness of the methodology is demonstrated in a small-scale experiment, investigating the impact of denoising methods on system performance. In a small-scale experiment, the methodology based on weak supervision for relation extraction in biomedical abstracts was effective. Various denoising methods were investigated for system performance. The literature review covers information extraction, relation extraction, and semi-supervised learning methods. Unsupervised methods like Open Information Extraction do not require training data, while fully-supervised methods rely on labeled examples. Semi-supervised methods, similar to the proposed approach, leverage both labeled and unlabeled data. Bootstrapping methods, such as DIRPE, Snowball, KnowItAll, and TextRunner, leverage labeled and unlabeled data to generate new examples. Distant supervision uses Knowledge Bases to create weak labels for relation extraction without human annotation. This approach has proven beneficial for large-scale datasets. Our work complements existing methods by combining learning algorithms for data bootstrapping. Our work complements existing methods by combining learning algorithms for data bootstrapping in biomedical relation extraction. BioCreative competitions have motivated research in this area, with BioCreative V focusing on Chemically-induced Diseases and BioCreative VI on relations between Chemicals and Proteins. Various algorithms, including Support Vector Machines and LSTM, have been used to improve performance in these tasks. The best performing team in the BioCreative competition implemented an ensemble of LSTM, CNN, and SVMs, highlighting the importance of lack of training data and the suitability of ensemble methods for improving generalization. Their work aims to combine techniques with semi-supervised learning, which has not been investigated for this task before. Ensemble learning reduces high variance by combining multiple learners, while semi-supervised learning aims to improve generalization using unlabeled data. Ensemble learning can enhance semi-supervised learning by providing multiple views and improving performance with less data. The combination of ensembles with semi-supervised learning has not been thoroughly studied, but recent research suggests it can be beneficial by increasing diversity between learners. Co-training, where two independent learning algorithms leverage unlabeled data, was the first proposed system of this kind. Recent work incorporates expert-defined lexicons and natural language processing. Recent research explores the use of expert-defined lexicons and natural language processing in semi-supervised learning. Methods like tri-training and co-forest extend co-training to multiple learners, improving performance without the need for manually labeled data. The ensemble system in co-forest makes decisions on re-training using all learners, leading to accurate annotations in functional genomics. The ensemble system in the methodology uses all learners for re-training to generate weak labels, allowing for the use of all unlabeled data. This approach differs from previous methods that only re-trained with a few high-confidence annotated examples. Additionally, weak supervision and data programming paradigms have influenced the development of the methodology, focusing on training models with labels of questionable quality. Weak supervision and data programming have heavily influenced the methodology by focusing on training models with labels of questionable quality. Weak supervision involves training models using labels of questionable quality, while data programming creates training sets when no ground-truth labels are available. The process involves defining weak supervision sources, denoising using a probabilistic graphical Generative Model, and deriving weak labels close to the true labels. Weak supervision and data programming have influenced the methodology by training models with questionable quality labels. Data programming uses a probabilistic graphical Generative Model for denoising and deriving weak labels close to the true labels. The methodology involves training a noise-aware discriminative model using the generated labels as the final predictor. In semi-supervised learning, a methodology is proposed to augment a gold-labeled training set with lower quality data using machine learning models of lower complexity as weak supervision sources. This approach aims to scale the dataset size by adapting an already implemented pipeline with little additional effort. The methodology assumes the existence of a labeled training set and an unlabeled dataset drawn from the same distribution. In semi-supervised learning, a methodology is proposed to augment a gold-labeled training set with lower quality data using machine learning models of lower complexity as weak supervision sources. The approach aims to scale the dataset size by adapting an already implemented pipeline with little additional effort. It assumes the existence of a labeled training set D B of size m, an unlabeled dataset D U of size M m, a validation set D V for hyperparameter tuning, and a held-out test set D T for evaluation. The methodology involves training K base learners on solving a task T, maximizing their individual performance while capturing different views of the data through varying hyperparameters and design choices. One important design choice is sentence pruning, where irrelevant words within a sentence can be removed to focus on the entities of interest. In text analysis, various approaches can be used to extract features for machine learning algorithms. These include considering words between entities of interest, using sequential features like tri-grams, converting text to numerical representations with token occurrences or TF-IDF weights, and employing different machine learning algorithms such as Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTMs, and Convolutional Neural Networks. In text analysis, various approaches can be used to extract features for machine learning algorithms, including Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTMs, and Convolutional Neural Networks. When using LSTMs & CNNs, some feature engineering steps are not applicable. After creating base learners, a subset is selected to maximize performance and diversity by discarding classifiers below a certain threshold. This threshold is set above random guess baseline but low enough to include diverse classifiers. To select diverse classifiers, a similarity-based clustering method is used on predictions of base learners. K-means clustering is performed on a similarity matrix to pick representative base learners. The number of clusters is determined using silhouette score coefficient. Labels are predicted using selected base learners, and a denoiser is used to reduce the vote matrix into weak labels. The Generative Model of data programming is utilized for this process. In the final step, a discriminative model is used as a meta-learner with weak supervision, trading label quality for quantity. High-capacity models like Deep Neural Networks are employed to learn features from a larger, albeit noisy, training dataset for improved accuracy. In experiments using Snorkel, high-capacity models like Deep Neural Networks are utilized as meta-learners to learn features from a larger, noisy dataset for improved accuracy. The BioCreative CHEMPROT and CDR datasets are used, with three gold-labeled datasets and a held-out test set. The original training and development sets are merged and shuffled to create datasets for training, validation, and unlabelled data. This setup ensures important restructuring of the dataset for better performance. The dataset is divided into parts for training, validation, and unlabelled data. This restructuring ensures unbiased document selection and consistent pre-processing. The meta-learner's performance with weak supervision is compared to optimal performance with ground-truth labels. SpaCy is used for most text pre-processing steps. The text pre-processing pipeline for the meta-learner involves tasks such as sentence splitting, tokenization, and dependency parsing using SpaCy. Snorkel is used for candidate extraction and mapping to ground-truth labels, with a focus on relationship classification in Natural Language. Entities of interest are replaced with tokens for prediction, and only relationships within the same sentence are considered. The text discusses using Machine Learning classifiers for biomedical relation extraction and optimizing weak supervision settings. It mentions using a bi-directional Long-Short Term Memory network, random under-sampling for class balance, and experimenting with different hyperparameters. Research questions are formulated and motivation for exploration is provided. In Subsections 6.1 and 6.2, the text explores enhancing biomedical relation extraction with Machine Learning classifiers as weak supervision sources. Theoretical guarantees suggest that adding weakly labeled data can improve the performance of the meta-learner, with accuracy improvements expected to be quasi-linear as the amount of weakly labeled data increases. Requirements for effective weak supervision include sources with better-than-random accuracy, sufficient overlap and disagreement, and diverse problem perspectives. Machine Learning classifiers have not been utilized as weak supervision sources in this context before. To evaluate the effectiveness of weak supervision in enhancing biomedical relation extraction, Machine Learning classifiers have not been used as weak supervision sources before. The study aims to determine if a diverse set of base learners can be trained on the same dataset to produce meaningful weak labels. Experiments are conducted to compare the performance of the meta-learner trained on full-supervision, weak-supervision, and a combination of both. The optimal number of classifiers as base learners is also explored, with the goal of achieving results comparable to full-supervision. The study explores the effectiveness of weak supervision in biomedical relation extraction by training a diverse set of base learners to generate meaningful weak labels. The optimal number of classifiers as base learners is investigated to achieve results comparable to full-supervision. The denoising component plays a crucial role in dictating the quality of weak labels used for training the final learner. Different denoising methods are assessed, including the production of binary or marginal weak labels with varying distributions. An error analysis is conducted to understand the impact of weak labels on the training and final performance of the meta-learner. The study investigates the impact of weak supervision on biomedical relation extraction. It analyzes the effectiveness of using supervised machine learning classifiers as weak classifiers and explores the optimal settings for applying weak supervision. Different denoising methods are evaluated to generate weak labels for training the meta-learner, with results showing that training with weak labels leads to better performance compared to full supervision. Including ground-truth labels further improves performance. Training the meta-learner with weak labels (D U ) and increasing the training set size by 2 \u2212 2.5x outperforms training with fewer gold labels (D B ). Performance is enhanced when ground-truth labels are included (D B + D U ). Weak supervision can achieve comparable performance to full supervision, with some cases showing slightly better results. However, differences are not statistically significant due to high variance in meta-learners' performance. Majority Vote sometimes outperforms the meta-learner, but this does not diminish the importance of weak supervision. The weak supervision approach, based on weak labels, was found to be significant in improving performance. Majority Vote occasionally outperformed the meta-learner, but this does not diminish the importance of weak supervision. Visualizing the learning curves of the meta-learner showed an upward trend, indicating meaningful weak labels. The F1 score on the training set was consistently higher than the test score, suggesting overfitting. Additional training data is expected to enhance the meta-learner's performance. The meta-learner's performance can be improved with additional training data as the model capacity is not fully utilized. The number of base learners affects the F1 score, with the best performance seen when trained with Average Marginals. Generative Model marginals show slight improvement with more base learners, but deviations are observed with weak Majority Vote labels. Generative model marginals tend to improve performance as the number of base learners increases, with exceptions. The metalearner performs best when trained with Average Marginals. GM marginals depend on hyperparameters chosen based on F1 score on a validation dataset. Marginal weak labels enhance meta-learner performance compared to binary labels. GM tends to create marginals following a U-shaped distribution, unlike average marginals. The Generative Model creates marginals following a U-shaped distribution, unlike average marginals. Error analysis shows that Average Vote labels have higher quality, with misclassified labels closer to 0.5. F1 score is deemed unsuitable for evaluating marginal weak labels. Training with marginal labels results in higher error compared to binary labels for LSTM. When using marginal labels, training error remains high, especially with Average weak marginals. LSTM quickly predicts binary training labels accurately. Training with marginal labels is like a regression problem, penalizing the model for inaccurate predictions. Predicted logits become more spread as training marginals become more uniform. Applying methodology on CPR task with expanded datasets shows decreased performance with weakly labeled data. The performance of the meta-learner decreases with weakly labeled data, indicating issues with dataset quality. Class imbalance is observed in the outgoing citations dataset compared to the original. Visualization using t-SNE confirms unsuitability of the new dataset. Weak supervision enhances complex model performance by utilizing unlabeled data and multiple base learners. Further investigation into constructing appropriate unlabeled datasets is necessary. Weak supervision enhances complex model performance by utilizing unlabeled data and multiple base learners. The methodology shifts human effort from hand-labeling examples to feature engineering and construction of diverse learners, allowing for scalability in training datasets and consistent performance improvement. The pipeline can be re-used on similar tasks with appropriate datasets. The method allows for scaling training datasets to high levels, improving performance in supervised learning. Reusing the pipeline on similar tasks requires only providing the right datasets. Further exploration is needed to construct a large unlabelled dataset to enhance metalearner performance and draw stronger conclusions. Challenges include collecting an appropriate unlabeled dataset and defining what is considered \"appropriate\". The preliminary experiments show challenges in collecting an appropriate unlabeled dataset and defining what is considered \"appropriate\". It is important to find a more suitable metric than the F1 score for evaluating weak labels. Further investigation is needed in experimenting with the meta-learner and defining a better selection method for Base Learners. Additionally, exploring how the system would perform if Base Learners abstained from voting on certain examples is of interest. Further exploration is needed in experimenting with the meta-learner and improving the selection method for Base Learners. It would be interesting to see how the system would behave if Base Learners abstained from voting on uncertain examples, potentially providing a modeling advantage for the Generative Model. This could offer insights into the trade-offs of weak supervision methods."
}