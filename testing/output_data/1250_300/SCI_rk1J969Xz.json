{
    "title": "rk1J969Xz",
    "content": "Estimating image location is challenging due to contextual complexities. This work introduces a global meshing strategy for image geolocation, overcoming data limitations with various training procedures. Incorporating additional information improves model performance. Delaunay triangles are effective for geolocation in low volume scenarios compared to quad trees. Additional data like time of posting and user albuming can enhance geolocation accuracy by up to 11% at the country level. The text discusses how incorporating additional information like time of posting and user albuming can improve geolocation accuracy by up to 11% at the country level and 3% at the city level. Advancements in deep learning have expanded the possibilities of machine learning beyond image classification. Recent methods allow for deeper analysis of contextual information in images, enabling researchers to ask more complex questions like determining the geographic origin of a picture. However, estimating the location of a ground-level image is challenging due to uneven distribution of geo-tagged images and potential conflicting data. The work focuses on content-based image geolocation, identifying the geographic origin of ground-level images. With the rise of image-based social data, inferring geographic context from images without explicit geolocation information is a significant challenge. The curr_chunk discusses the challenges of geolocating images without explicit geolocation information. Various approaches have been considered, including using geolocation information associated with linked objects. The paper builds on recent work in global geolocation from ground-based imagery and utilizes a multi-class approach with a one-hot encoding. Instance-level scene retrieval is also used for geolocation of imagery by querying previously geotagged imagery. The curr_chunk discusses biasing class selection during training of deep learning models for social media geolocation. Sampling is done without respect to user, raising concerns about the broader influence of latent variables and communities in geolocation. In this work, sampling is performed without respect to user for training deep learning models for social media geolocation. Different models are considered, including purely geolocation for image content (M1), models incorporating time information (M2), and models using user-album inputs (M3). The study contributes by exploring alternative mesh for geolocation in M1 and showing the use of time and user information to enhance geolocation accuracy in M2 and M3. Data from YFCC100M BID17 is used for training and validation, with ground truth GPS locations assumed to be accurate. The data used for model development includes (91M training/34M validation) images from YFCC100M BID19. Ground truth GPS location accuracy is assumed based on previous results. Each image has associated metadata including user-id and posted-time. The global-scale geolocation model follows a classification approach similar to PlaNet BID19, subdividing the globe into a grid for classification regions. The distribution of image longitude varies by the time of day it is posted, as shown in Figure 1. The image longitude distribution varies by the time of day it is posted. A Delaunay triangle-based meshing architecture is used for classification, different from PlaNet's quad-tree mesh approach. The triangular mesh is deployed for its adaptability to Earth's geometric features. The triangular mesh used for classification is more adaptive to Earth's geometric features compared to a quad-tree approach. Mesh cells are adaptively refined based on the number of examples they contain, with parameters shown in Table 1. Each mesh is initialized with a 31 x 31 structured grid with equal surface area. The mesh used for classification is initialized with a 31 x 31 grid and can be adjusted by modifying the refinement level. Three meshes were studied, covering a range of structures, with parameters shown in Table 1. The fine P mesh replicates PlaNet's parameters but with a different methodology and dataset. The classification structure for models is shown in Figure 2, with red triangles indicating training criteria met in certain regions. The classification structure for models developed in this paper includes a coarse mesh and fine mesh classification structure. The fine mesh better represents geographic regions, such as the water/land interface of Spain and Portugal. The Inception v4 convolutional neural network architecture is used to develop the mesh-based classification geolocation model. Cells are labeled based on the cell centroid. The work presented here utilizes a different architecture than PlaNet BID19, with a focus on cell centroid labeling for geolocation. Significant improvements are expected for coarse meshes, especially in high-density population regions. Models are evaluated based on the distance between predicted and ground-truth GPS coordinates using great-circle distance calculations. The study focuses on geolocation using cell centroid labeling, evaluating models based on the distance between predicted and ground-truth GPS coordinates. Error thresholds are defined for different locality levels, and image metadata like user id and posting time are utilized in the model. The output provides evidence for geolocation class membership, with considerations for time dependence. The study evaluates geolocation models using image metadata like user id and posting time. The operational research hypothesis is that there is time dependence after conditioning on image content. A new model incorporates time-related variables to predict geolocation. Another model uses Bidirectional LSTMs to geolocate images from a single user by leveraging information from other images posted by the user. The Bidirectional LSTMs leverage correlations in a single user's images for geolocation. Images are organized sequentially in time in M3, with albums of size 24. Album averaging assigns a mesh cell based on highest average probability, increasing accuracy by borrowing information across related images. Location of an image is determined as the maximum average probability across all images associated with the posting user. The method involves using Bidirectional LSTMs to leverage correlations in a single user's images for geolocation. Album averaging assigns a mesh cell based on the highest average probability across all images associated with the user. LSTM on a time-ordered sequence of images was considered but did not significantly improve performance. The output of M1 is filtered to output only the top 10 mesh cell probabilities, re-normalized to sum to 1, and used for training M2 and M3 on validation data. The study explores meshing parameters sensitivity and trade-offs between fine-grain and coarse-grain geolocation. Results show improved geolocation performance with different mesh sizes. The impact of classifying on training data centroid versus cell centroid is compared, showing significant improvement for coarse mesh. The BID20 model is used with indoor-outdoor labels for geolocation filtering. The geolocation model is not re-trained on outdoor imagery, only used for filtering during inference. Overall, there is a noticeable improvement in geolocation accuracy. The study examines the impact of using indoor-outdoor labels for geolocation filtering without re-training the model on outdoor imagery. Results show a 4-8% improvement in accuracy for region/country localities. The Im2GPS testing data is used to test the model, demonstrating improved performance. The M1 classification model outperforms PlaNet with less training data and classification regions. Time usage also slightly enhances geolocation accuracy. The study shows that using time improves geolocation accuracy, with a slight gain in accuracy for both coarse and fine mesh models. The difference in error between using time (M2) and not using time (M1) is statistically significant, indicating that the effect of time-inputs is not due to chance alone. The difference in error between using time-inputs (M2) and not using time (M1) is statistically significant (p-value < 10^-16), indicating that the effect of time-inputs is not due to chance alone. The distribution of errors is mean shifted, with images not universally predicted closer to the truth. Time input models show lower-bias class probabilities, with cross-entropy optimized in training for both models. KL-Divergence is calculated for each model to compare model output class frequencies to true class frequencies. The KL-divergence of the model output class frequencies compared to the true class frequencies in validation are in TAB5. \"User-Averaging\" is incorporated into results as a simple method that appears to be more accurate than predicting individual images with M1 or M2, but biases cell count frequency. Using the average probability vector to predict a user's image may result in higher bias, as observed. LSTMs on user albums had the lowest class bias of any model considered. Table 6 shows the percentage accuracy at specific resolutions for researched models. Table 6 compares researched models at different spatial resolutions, with coarse and fine mesh having different numbers of triangles. Time information concatenated with model output improves accuracy. Using time of day in models reduces bias and increases accuracy. Conditioning on latent variables enhances geolocation models. Time information improves both coarse and fine mesh models. The research suggests that incorporating time information improves geolocation accuracy for both coarse and fine mesh models. It is recommended to consider the probability of an image being outdoor as an input to further enhance accuracy. Increasing grid granularity reduces accuracy at country and regional levels but improves accuracy at street and city levels. Fine mesh models are expected to perform better for street-level geoinferencing compared to coarse mesh models. The research shows that a fine mesh is superior for street-level geoinferencing, with a Delunary triangle-based mesh allowing for accurate models with fewer training examples. Images were divided into training and validation sets, and softmax classification performs poorly with a large number of output classes. Training time-based models (M2 and M3) was done without using data from M1 training. Softmax classification struggles with a large number of output classes. A training procedure was developed for large meshes, starting with pre-training on ImageNet with Adagrad. Training examples were increased each epoch by 6%, and minority classes were oversampled initially. Class bias was reduced after each training cycle. The final model (M2) was trained with SGD, using a linearly decreasing learning rate reduced at 4% with each epoch, without class biasing and with the full dataset per epoch. The layers of M2 are described in TAB0. M2 is trained using He initializations, initial iterations of Adaboost, followed by ADAM at learning rates of 0.005 and 0.001. Early stopping is used to detect a sustained decrease in validation accuracy. The generality of the M1 classification model is demonstrated by performing a query-by-example on the 2K random Im2GPS. The model is demonstrated by performing a query-by-example on the 2K random Im2GPS dataset. An image of the Church of the Savior on Spilled Blood is shown. Each image is given a categorical indicator variable. There exists a latent class distribution assumed constant between training, testing, and application. The last layer output from networks is a softmax model. The KL-divergence between q and p is considered low if training is done well. The entropy of p and q is also considered for completeness."
}