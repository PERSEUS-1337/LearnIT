{
    "title": "HJcjQTJ0W",
    "content": "Massive data on user local platforms often can't support deep neural network (DNN) training due to resource constraints. Cloud-based training poses privacy risks from excessive data collection. To address this, a method using intermediate data representations is proposed, splitting DNNs between local platforms and the cloud. Local NN generates feature representations without training to protect data privacy. Cloud NN is trained based on these representations. The idea is validated by studying privacy loss and accuracy dependency on local NN topology for image classification tasks. PrivyNet is proposed to optimize accuracy while minimizing privacy loss. PrivyNet optimizes target learning task accuracy while considering privacy loss, local computation, and storage constraints. It proposes using transformed data representations for cloud-based training to protect user privacy. The method aims to balance utility and privacy requirements for effective learning tasks. The privacy requirement in data transformation should be balanced with utility for effective learning tasks. Various methods like k-anonymity, l-diversity, and t-closeness have been proposed to protect sensitive attributes in databases, but applying them to high-dimensional continuous data is challenging. Differential privacy is proposed for formal privacy guarantees by adding noise to data. Existing methods for data anonymization include linear and nonlinear transformations, with nonlinear transformations offering better privacy protection. Linear transformations suffer from limited privacy as original data can be reconstructed from released representations. PrivyNet is a DNN training framework that divides the model into local and cloud parts for privacy and utility trade-off control. The local NN generates intermediate representations while the cloud NN is trained for the learning task. Privacy protection is achieved through non-linear transformations like convolution and pooling. PrivyNet is a framework that splits DNN models for cloud-based training with privacy control. It uses pre-trained NNs to extract general features and protect privacy by selecting specific features to release. Key contributions include proposing PrivyNet, characterizing privacy loss and utility using CNN, hierarchical strategy for local NN topology, and verification through image classification. In this section, the efficiency and effectiveness of leveraging pre-trained neural networks for intermediate representation generation are validated through image classification. Feature representations are generated by a feature extraction network (FEN) from original data, followed by training an image classification network (ICN) and an image reconstruction network (IRN). Utility is measured by the accuracy of the learning task, and privacy is measured by the distance between reconstructed and original images. The adversarial model is aligned with the training process of the IRN. The text discusses the transformation of training instances using a feature extraction network (FEN) to generate feature representations for image classification. A classifier is learned to minimize empirical risk for the target learning task, with utility measured by the accuracy achieved. The text evaluates the privacy and utility of transformed representations using a reconstruction model and peak signal-to-noise ratio (PSNR). The impact of FEN topology on privacy and utility is characterized, with settings described in detail. The FEN is derived from VGG16 pre-trained on Imagenet, using CNN for image classification and reconstruction tasks. The architectures of VGG16, ICN, and IRN are used to construct h and g for image classification and reconstruction tasks. The FEN topology is determined by the number of layers, output depth, and selected channels. Evaluating the impact of FEN layers and output depth on utility and privacy, it is observed that privacy loss decreases with reduced output depth or increased FEN layers. Utility degradation is minimal with reduced output depth when FEN layers are few. The trade-off between accuracy and PSNR in the PrivyNet framework is shown in FIG2 (c). It is observed that FEN with different topologies have similar utility when privacy loss is high, while FEN with more layers provide better utility when privacy loss is low. The selected subset of output channels also impacts privacy and utility. Comparing the utility and privacy loss for representations generated by each channel reveals the importance of channel selection. The utility and privacy of representations generated by each channel in the FEN with 4 and 6 VGG16 layers are compared in Figure 4. Detailed statistics are provided in Table 4. The best channel achieves significantly higher utility and lower privacy loss compared to the worst channel. The impact of output channel selection is compared with the number of FEN layers and output depth, showing varying levels of privacy and utility. Based on the comparison of output channel selection, utility and privacy depend more on the number of FEN layers and output channel depth. Key observations include leveraging pre-trained CNN for FEN construction, controlling privacy and utility trade-off with FEN topology, and adjusting trade-off with FEN layers and output depth. A framework called PrivyNet is proposed to optimize utility while considering privacy constraints, local computation, and storage. The idea of deriving FEN from a pre-trained NN to control privacy and utility trade-off has been validated. The impact of FEN topology on computation and storage on local platforms, especially for lightweight devices like mobile phones, is crucial. The PrivyNet framework optimizes utility while considering privacy, local computation, and storage constraints. Privacy characterization and performance profiling of NNs are conducted to determine the FEN's layers and output depth. Channel pruning based on private data is done to reduce privacy leakage, and the FEN topology is determined accordingly. The FEN topology is determined based on the availability of original images, which is a key assumption for evaluating privacy loss. The attackers are assumed to be unaware of the transformation induced by the FEN to prevent sophisticated image reconstruction mechanisms. Anonymity protection for the FEN is crucial due to the potential availability of pre-trained NNs' architecture and weights to attackers. The pre-characterization stage involves two main steps. The pre-characterization stage involves performance and storage profiling on local platforms and cloud-based privacy characterization for pre-trained NNs. Privacy characterization is done by leveraging cloud-based services and training the reconstruction network on publicly available data. Experiments are conducted to compare PSNR for FEN with different topologies using datasets like CIFAR-10 and CIFAR-100. In PrivyNet, experiments determine the number of samples needed for accurate characterization with data augmentation. The FEN topology is crucial for privacy and accuracy, with FEN layers and output channel depth impacting the generated representations. Privacy requirements, local computation, and storage constraints guide the selection of FEN topology for high privacy. In PrivyNet, the FEN topology is crucial for privacy and accuracy. When privacy requirement is high, a deep FEN with more layers is selected, while for low privacy requirement, a shallow FEN is chosen to minimize local computation and storage. The output depth is determined based on privacy constraints to achieve the required privacy level efficiently. After determining the FEN layers and output depth based on privacy requirements, the selection of output channels is crucial. Directly choosing channels from the entire set can lead to significant variations in utility and privacy. Channel pruning is necessary to avoid situations where poor utility is achieved with high privacy leakage. Additionally, there is a negligible correlation between utility and privacy loss for individual channels, as shown in Figures 4, 9, and 10. This observation holds true for different output channel depths and FEN layers. In channel pruning, both utility and privacy are considered. Privacy loss for each channel is determined from offline pre-characterization to prune channels with the highest privacy loss. Fisher's linear discriminability analysis is used to identify channels with poor utility based on distance measurements in the output representations. Fisher's LDA is found to be effective in identifying ineffective channels despite being a linear analysis method. The text discusses using Fisher's linear discriminability analysis to identify channels with poor utility in channel pruning. By evaluating the Fisher's discriminability for each channel, ineffective channels can be pruned to improve accuracy in the learning task. The effectiveness of the LDA-based supervised channel pruning algorithm is verified in experiments. In experiments, the effectiveness of leveraging Fisher's discriminability for channel pruning is verified. By using the first 6 VGG16 layers to form the FEN, 69.7% of the worst 32 channels can be pruned on average, compared to 50.3% with random pruning. The LDA-based supervised pruning method shows a 33.5% reduction in the probability of selecting a bad channel randomly. The number of samples required for pruning shows consistent results across different mini-batch numbers. The experimental results demonstrate the effectiveness of supervised channel pruning in reducing computation complexity. By pruning the worst 64 channels based on privacy and utility characterization or LDA, the average PSNR improves compared to random selection without pruning. The experimental results show that after pruning the worst 64 channels based on privacy and utility characterization or LDA, the average PSNR improves compared to random selection without pruning. The LDA-based pruning strategy achieves better accuracy and smaller PSNR compared to random selection and slightly less privacy loss compared to characterization-based pruning. The effectiveness of the supervised pruning strategy is verified through detailed statistics and comparisons. The adversarial model in the paper focuses on protecting the anonymity of the Feature Extraction Network (FEN) derived from pre-trained Neural Networks (NNs). Strategies include building a pool of NNs for FEN derivation and applying channel selection to make it harder for attackers to guess the FEN structure. The study focuses on protecting the anonymity of the Feature Extraction Network (FEN) derived from pre-trained Neural Networks (NNs) by applying channel selection to maintain utility and privacy while reducing runtime. Reducing channel depth for each convolution layer shows minimal impact on privacy and utility with a significant decrease in runtime. This approach makes it challenging for attackers to guess the FEN structure even if they know the pre-trained NN it is derived from. PrivyNet is a flexible framework designed to protect the anonymity of the Feature Extraction Network (FEN) derived from pre-trained Neural Networks (NNs). It enables cloud-based training while providing fine-grained privacy protection, making it difficult for attackers to determine the FEN structure. It can be used in modern hospitals to train models for disease diagnosis while preserving patient privacy. Additionally, it can be applied in mobile platforms to collect and analyze personal health and habit information. PrivyNet is a platform-aware framework that enables mobile platforms to upload collected data to the cloud while protecting personal information. It is simple, flexible, and applicable for different end-users in various situations. The framework uses CIFAR-10 and CIFAR-100 datasets for characterization and derives the Feature Extraction Network (FEN) from pre-trained VGG16 for privacy and accuracy assessment using CNN for image classification. The CNN architecture used for image classification and reconstruction tasks is based on VGG16 and ResNet blocks. The image reconstruction network (IRN) consists of 8 ResNet blocks per cluster. Gradient descent optimizer is used for training, with specific learning rates and batch sizes for each task. Data augmentation includes normalization and random adjustments to brightness and contrast. In the experiments, the image reconstruction network (IRN) is characterized by the number of ResNet block clusters, with 2 clusters of 8 blocks each chosen for optimal performance. Performance and storage profiling of pre-trained NNs like VGG16 on different platforms is conducted to analyze the impact of network layers on storage requirements. The increase in VGG16 layers leads to higher local computation and storage requirements, especially with larger input image sizes. Different platforms may face varying bottlenecks, highlighting the need for a flexible framework. The complexity of extra computations is influenced by the number of samples and output dimensions. The complexity of extra computations in the second part is O((K + N LDA)W2H2 + W3H3), where K and N LDA are determined by the characteristics of the FEN and the learning task. N LDA plays a key role in the additional computation induced by the learning process, but typically a small N LDA is sufficient for good pruning results, resulting in minimal overall computation overhead."
}