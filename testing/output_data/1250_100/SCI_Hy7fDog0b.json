{
    "title": "Hy7fDog0b",
    "content": "Generative models, like AmbientGAN, aim to recover the true underlying distribution from lossy measurements of samples. This method shows significant improvements in training Generative Adversarial Networks (GANs) on benchmark datasets, achieving higher inception scores. The generator's output is passed through a random measurement function, and the discriminator distinguishes between real and generated measurements. This work addresses the challenge of training generative models directly from noisy or incomplete samples. It introduces AmbientGAN, a new approach for training GANs where the discriminator distinguishes between real and simulated measurements of generated images. The method aims to learn generative models from different types of measured samples, assuming known measurement processes that meet specific conditions. The method demonstrates the effectiveness of training generative models from noisy or incomplete samples by using AmbientGAN. It shows that the distribution of measured images uniquely determines the distribution of original images, leading to a pure Nash equilibrium for the GAN game to find a generative model that matches the true distribution. In the measurement model, pixels are set to zero with probability p, and random projection models observe inner products with random Gaussian vectors. Empirical results show improved sample quality when incorporating the measurement process into GAN training, compared to inpainting and denoising methods. In FIG2, a generative model is learned on 2D images from the MNIST dataset using pairs of 1D projections. Two variants are considered: one where the choice of line is forgotten, and one where it is included. AmbientGAN recovers underlying structure well, but the first variant cannot identify the distribution up to rotation or reflection. Neural network based implicit generative models can be constructed using autoregressive and adversarial approaches. Adversarial framework is powerful for modeling complex data distributions like images, video, and 3D models. Generative models have various applications and can be useful for solving ill-posed inverse problems. The utility of generative priors in solving inverse problems is explored in various papers. Synthetic data realism is enhanced using GANs. Operating generators and discriminators on different spaces has been proposed. Training stability is linked to low dimensional projections. A connection to creating 3D shapes from 2D projections is noted. The AmbientGAN framework is used for creating 2D projections from voxel occupancies. The text discusses lossy measurements on samples from a distribution over R^n, with measurements generated by a stochastic function parameterized by \u03b8. The goal is to create an implicit generative model of the unknown distribution p_r_x using a set of realizations from p_r_y. The approach combines the measurement process with adversarial training, similar to a standard GAN setting. The text introduces the AmbientGAN framework for learning a generator G to approximate the distribution p_r_x using measurements from p_r_y. Instead of having access to the desired objects X \u223c p_r_x, only a dataset of measurements Y \u223c p_r_y is available. The approach involves simulating random measurements on generated objects X_g and using a discriminator to distinguish real from fake measurements. The AmbientGAN objective is defined based on a quality function q(x) and the discriminator output. The AmbientGAN framework uses a differentiable quality function q(x) and feedforward neural networks G and D for training. Stochastic gradients are computed using sampled inputs, and updates alternate between D and G parameters. The approach is compatible with various GAN improvements and can incorporate additional information like per sample labels. The AmbientGAN framework utilizes different measurement models for 2D images, including Block-Pixels, Convolve+Noise, Block-Patch, Keep-Patch, Extract-Patch, and Pad-Rotate-Project. These models are tailored for image data but can be adapted for other formats as well. The PadRotate-Project-\u03b8 measurement function involves padding the image with zeros, rotating it by a random angle, and summing pixels along the vertical axis to obtain a measurement vector. Gaussian-Projection projects onto a random Gaussian vector, allowing for the recovery of the true underlying distribution. The uniqueness of the distribution consistent with observed measurements is crucial for AmbientGAN training. The AmbientGAN framework aims to recover the true underlying distribution from given measurement distributions. The uniqueness of the distribution is crucial for training, and various measurement models like Gaussian-Projection and Convolve+Noise satisfy this assumption. The framework can handle Gaussian blurring with additive noise and can be generalized for any continuous and invertible function. Additionally, a finite discrete set of pixel values is assumed in the recovery process. Theorem 5.4 assumes a finite discrete set of pixel values for images, which is common in practical scenarios. It provides a sample complexity result for learning distributions in the AmbientGAN framework. The theorem states that with a probability of at least 1 - \u03b4, an optimal generator G must satisfy a certain condition when given a dataset of IID measurement samples. Three datasets used for experiments are MNIST, CelebA, and CIFAR-10, each with specific image characteristics. The CIFAR-10 dataset contains 32 \u00d7 32 RGB images from 10 classes. Different generative models were used for experiments with MNIST, CelebA, and CIFAR-10 datasets. The models include conditional DCGAN, unconditional Wasserstein GAN with gradient penalty, unconditional DCGAN, and Auxiliary Classifier Wasserstein GAN with gradient penalty. Discriminator architectures varied based on the type of output measurements. The baseline approaches implemented to evaluate the AmbientGAN framework involve creating an implicit generative model for the measurement distribution. Two baselines are discussed: the \"ignore\" baseline where measurements are ignored, and a stronger baseline assuming invertible measurement functions, which is not applicable in the AmbientGAN setting. In the AmbientGAN framework, methods are described for obtaining approximate inverse functions for various measurement models. These methods include blurring images for Block-Pixels measurements, Wiener deconvolution for Convolve+Noise measurements, and Navier Stokes based inpainting for Block-Patch measurements. Other measurement models present challenges in obtaining an approximate inverse function. In the AmbientGAN framework, methods are described for obtaining approximate inverse functions for various measurement models. For the Keep-Patch measurement model, inpainting methods are not suitable due to lack of information outside a box. Inverting Extract-Patch measurements is challenging as the patch position information is lost. Inverting Pad-Rotate-Project-\u03b8 measurements is difficult without sufficient angle information. Only results with AmbientGAN models are reported in this subset of experiments, with samples generated by baselines and our models shown for selected parameter settings. More results are available in the appendix. Our models outperform baselines in generating high-quality images on celebA and CIFAR-10 datasets with different measurement processes. The results show that our models can produce coherent faces by observing only parts of one image at a time, even when information is lost during the measurements process. The study demonstrates the ability to generate images of digits and faces using 1D projections with a DCGAN model. The generated images show consistent orientations and chirality within each class, but lack visual quality. The method highlights the challenges of learning complex distributions with limited projections and the need for better training methods for GANs. The study evaluates the quality of generative models in the AmbientGAN framework using the Inception model for CIFAR-10 and a classification model for MNIST with a 99.2% accuracy. Different models were trained with varying pixel blocking probabilities, showing that AmbientGAN models outperform baselines. Additionally, models were trained with varying levels of noise, demonstrating the impact on the inception score. The study evaluates generative models in the AmbientGAN framework using Inception scores for CIFAR-10. Results show that as noise levels increase, AmbientGAN models outperform Wiener deconvolution and \"ignore\" baseline. Different measurement models impact inception scores, with Pad-Rotate-Project-\u03b8 model achieving 8.12 score. Total variation inpainting method is slow. The study evaluates generative models in the AmbientGAN framework on CIFAR-10, showing superior performance over baselines. The total variation inpainting method was slow, and the Inception score trend was similar to MNIST results. The approach aims to construct generative models from incomplete datasets, relaxing the need for high-quality data. The study evaluates generative models in the AmbientGAN framework on CIFAR-10, showing superior performance over baselines. The total variation inpainting method was slow, and the Inception score trend was similar to MNIST results. The approach aims to construct generative models from incomplete datasets, relaxing the need for high-quality data. In the context of GAN models, it is proven that there is a unique probability distribution that can match all 1D marginals obtained with Gaussian projection measurements. The text discusses the unique distribution that can induce a measurement distribution, showing a bijective map between X and Z. The pdfs of X and Z are related through a Jacobian function. The reverse map from the measurement distribution to a sample distribution is also detailed. The reverse map uniquely determines the true underlying distribution p x. A dataset of measurement samples is considered, and the optimal discriminator for the empirical objective is defined. The optimal generator must satisfy p g y = p r y. The Empirical Risk Minimization version of the loss is equivalent to taking the expectation of the data-dependent term with respect to the empirical distribution. The proof of Theorem 5.4 is given, assuming each image pixel takes values in a finite set P. Assuming each image pixel is in a finite set P, the Block-Pixels measurement model with probability p is considered. By applying a discrete distribution p x over [t] and using a transition matrix A, the distribution over measurements p y can be expressed. If A is invertible, p x can be recovered from p y. The sample complexity is determined by the minimum eigenvalue magnitude of A. The optimal generator in the Block-Pixels measurement model must satisfy certain conditions. Images are divided into classes based on the number of zero pixels. The transition matrix is lower triangular due to the blocking of pixels independently. Unaffected images have a high chance of remaining unchanged. The diagonal entries in the transition matrix correspond to unaffected images. The diagonal entries of the transition matrix in the Block-Pixels measurement model are strictly positive, with a minimum value of (1 \u2212 p) n. The DCGAN model on MNIST uses a noise input with 100 dimensions and follows a specific architecture. The WGANGP model on MNIST utilizes a latent vector of 128 dimensions and has its own architecture. Both models incorporate batch-norm and concatenate labels with inputs in their respective layers. The ACWGANGP model on CIFAR-10 follows a residual architecture with a latent vector of 128 dimensions sampled from a standard Gaussian distribution. The generator includes a linear layer and three residual blocks, each consisting of conditional batch normalization, nonlinearity, and upconvolution layers. The discriminator has one residual block with two convolutional layers followed by three residual blocks. The curr_chunk discusses the robustness of the AmbientGAN approach to systematic mismatches in the parameter distribution of the measurement function. It presents an experiment using the Block-Pixels measurement model on the MNIST dataset, where pixels are blocked with a certain probability to obtain measurements. The study shows that AmbientGAN models trained with this dataset are resilient to parameter distribution inaccuracies. The study demonstrates the robustness of AmbientGAN models to parameter distribution mismatches. By training on the MNIST dataset with a Block-Pixels measurement model, the generators capture the data distribution well. Using the learned generator for compressed sensing, a reduction in the number of measurements is observed compared to Lasso, showcasing the effectiveness of AmbientGAN even with corrupted samples."
}