{
    "title": "BkN_r2lR-",
    "content": "Identifying analogies across domains is a key task for artificial intelligence. Recent advances in cross domain image mapping focus on translating images, but visual fidelity often falls short. This paper introduces AN-GAN, a matching-by-synthesis approach that outperforms current techniques in finding exact analogies between datasets. The cross-domain mapping task involves domain alignment and learning the mapping function, which can be iteratively solved to improve unsupervised translation quality. Humans excel at making analogies between domains without prior supervision, using previous knowledge to establish strong priors in new situations. Recent approaches in Artificial Intelligence focus on identifying analogies between different domains without explicit examples. These methods involve unsupervised mapping between domains using constraints like distributional and cycle constraints to learn a mapping function. For example, mapping aerial photos to Google-Maps images without prior correspondences. In this paper, the task of analogy identification involves finding pairs of examples in two domains related by a non-linear transformation. Current methods for mapping between domains lack exemplar-based constraints, leading to low visual fidelity in translated images. The authors propose adding exemplar-based constraints to improve visual analogy identification performance, even when exact analogies are not present in all sample sets. Their method can find correspondences between sets without exact correspondences available. The paper introduces a method for analogy identification between domains, improving visual quality by adding exemplar-based constraints. It involves finding analogies between domains and training a domain mapping function using a two-step approach. The method aims to identify analogies without supervision and is related to image matching and unsupervised style-transfer techniques. In image matching, various approaches have been proposed, including deep neural networks for supervised matching and generic visual feature matching for unsupervised scenarios. However, standard visual features struggle to create analogies between different domains. Generative Adversarial Networks (GANs) have shown promise in image synthesis, with many image-to-image translation methods utilizing GANs to generate realistic images. GAN methods train a generator network to synthesize samples from a target distribution by jointly training a second network. Generative Adversarial Networks (GANs) are used in image synthesis to create images from a target distribution by training a second network. Unsupervised mapping involves generating images based on input images without random noise, while supervised mapping uses matching pairs of input and output images for training. The U-net architecture is employed to strengthen the link between source and target images in supervised mapping methods. The U-net architecture of BID14 is used to strengthen the target image. Supervision is not used in this work, but successful completion of the algorithm generates correspondences between domains. BID2 showed improved mapping results in supervised settings without GANs. The method for analogy identification involves finding matching indexes between two sets of images in domains A and B. An iterative approach is used to map images from the source domain to the target domain and search for matches. A mapping function T AB is trained to map images from domain A to domain B, optimizing the distribution of T AB (x) to match that of y. A discriminator D is trained to distinguish between samples from p(T AB (x)) and p(y), while T AB is optimized to make this task difficult. Additional constraints like circularity and distance invariance have been found necessary in some datasets. The cycle approach involves training one-sided GANs in both directions to ensure successful image translation between domains. The previous section discussed training a mapping function T AB to translate images from domain A to domain B. In the current section, a method for exact matching between domains is proposed, where each A domain image x i has a corresponding B domain image y mi. The goal is to find the set of indices m i for exact matching, allowing for training a fully supervised mapping function T AB. The proposed method aims to find exact matches between images from domains A and B using a match matrix \u03b1 i,j. The optimization process involves continuous optimization over T AB and binary programming over \u03b1 i,j. To enforce sparsity, an entropy constraint is added to encourage sparse solutions. The relaxed formulation can be optimized using SGD, with the entropy term playing a key role in converging to the original correspondence problem. The proposed method utilizes a match matrix \u03b1 to find exact matches between images from domains A and B. The optimization process involves continuous optimization over T AB and binary programming over \u03b1. A training scheme is suggested where T AB is iteratively updated for N epochs, followed by updating \u03b2 for N epochs. AN-GAN is introduced as a cross-domain matching method that combines exemplar and distribution-based constraints. The AN-GAN loss function includes distributional loss L T dist and cycle loss L T cycle. The AN-GAN optimization problem involves adversarially training discriminators D A and D B, setting \u03b2 to 0 initially for equal likelihood, and using a burn-in period before optimizing the exemplar loss. The learning rate for exemplar loss is decayed after 20 epochs, with shared \u03b2 parameters between mapping directions. In experiments, different loss functions were tested for similarity determination between actual and synthesized examples. While Euclidean or L1 loss functions were not perceptual enough, using Laplacian pyramid loss showed some improvement. The best performance was achieved with a perceptual loss function, as seen in prior works. The loss function extracts VGG features for each image and uses L1 loss on pixels to consider colors. The loss function used in the study is based on the number of pixels and features in each layer. The method is considered unsupervised matching as it utilizes off-the-shelf features. Matching experiments were conducted on various datasets, comparing against different methods such as nearest neighbor using L1 loss on pixels and VGG feature loss. The CycleGAN method was also evaluated. The study evaluated the performance of the method on public datasets including Facades, Maps, Zappos50K, and Amazon handbags. The datasets consist of images aligned with segmentation maps, satellite images, shoes, and handbags. Edge images were automatically detected using HED. Our method was tested on datasets like Facades, Maps, Zappos50K, and Amazon handbags. The datasets were down-sampled to 2k images each for memory constraints. Results showed that generic features couldn't match between domains, but CycleGAN improved matching performance. However, there is still room for improvement in CycleGAN performance. CycleGAN performance can be improved by using perceptual features such as VGG features for image retrieval tasks. Subsampling features was necessary due to computational constraints. Matching linear combinations of mapped images instead of single images showed significant improvements in performance. The exemplar loss alone was not sufficient for convergence, leading to the use of a different optimization approach. The optimization problem did not converge, so a distributional auxiliary loss was used to aid optimization. With the auxiliary losses, the exemplar loss converged after \u03b1 \u2212 T iterations, showing their importance for successful analogy finding. The AN-GAN method, using the full exemplar-based loss, significantly improved performance for all datasets and matching directions. In experiments with M % of matches unavailable, the task was to identify correct matches for samples without matches in the other domain. The evaluation metric is the percentage of images with exact matches. Results show that the method can handle scenarios with unmatched examples. Even with 25% of samples without matches, the method still performs well. AN-GAN achieved a 90% match rate with 75% of samples without matches in some datasets. The method was also tested on finding similar matches when exact analogies are not available. Our method focuses on finding similar matches when exact analogies are not available. We used the DiscoGAN architecture for mapping in the Shoes2Handbags scenario from BID9. Results show that our method can align datasets with high accuracy, achieving a 97% alignment accuracy on the Facades dataset. We proposed a two-step approach for training a mapping function between unaligned datasets: (i) Find analogies using AN-GAN, and (ii) Train a standard mapping function using self-supervision from stage (i). Our method achieved 97% alignment accuracy on the Facades dataset using a fully self-supervised mapping function with Pix2Pix. Results show that our approach outperforms CycleGAN and performs similarly to fully supervised methods. Additionally, we compared our method with CycleGAN on the edges2shoes and edges2handbags datasets, showing superior performance. The supervised stage utilizes a Pix2Pix architecture with only L1 loss, showing improved performance over CycleGAN and competitive with full-supervision. Evaluation on point cloud matching using the Bunny benchmark also yielded successful results. The mapping function consists of layers with hidden units, BatchNorm, and Leaky ReLU activations. A loss term encourages orthonormality of the weights, leading to improved success rates for large transformations. The method is effective for low dimensional transformations and settings without exact matches. An algorithm for unsupervised cross domain matching is presented. In this work, a new method using exemplar constraint was introduced to improve image mapping performance across domains. The method outperformed baseline approaches on various datasets for exact matching. It also proposed aligning domains and training a supervised mapping function as an alternative to end-to-end operations. Future work includes exploring matching between different modalities like images, speech, and text, requiring the development of new distribution matching algorithms."
}