{
    "title": "r1gFDS8aHB",
    "content": "Recent advances in deep learning have shown the usefulness of deep neural networks in extracting task-specific features. However, these features are not general and do not capture task-agnostic features. Variational Auto-Encoders (VAEs) are now used to capture latent variables in a generative sense, with a focus on disentangling informative features from input data. Experiments using a modified joint-vae model aim to learn disentangled features with a mixture of continuous and discrete variables in the latent space. Feature learning is crucial in machine learning, with deep learning making significant advancements in this area. Deep neural networks excel at extracting features from raw data, but these features are often task-specific due to the use of specific loss functions. To achieve true artificial intelligence, it is essential to learn task-agnostic representations that capture all necessary information. Recent efforts focus on learning disentangled representations, where changes in the representation correspond to changes in specific factors. Experimentation with JointVAE explores disentangled representations for this purpose. In this work, we experiment with JointVAE BID2 to explore disentangled representations for a given dataset. Various state-of-the-art VAE variants, such as BID4, BID1, and BID2, aim to extract disentangled representations. The assumption of Gaussian distribution simplifies sampling of latent variables, but for discrete variables, a mixture of continuous and discrete latent variables is used in Joint-VAE to represent disentangled features. The JointVAE model utilizes Gaussian distribution for continuous variables and multinomial distribution for discrete variables. Sampling from continuous latent variables is done using the normal reparameterization trick, while sampling from discrete multinomial variables is achieved using the Gumbel Softmax trick. This approach allows for the representation of disentangled features using both continuous and discrete variables without making assumptions."
}