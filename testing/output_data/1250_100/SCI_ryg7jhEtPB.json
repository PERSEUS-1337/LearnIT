{
    "title": "ryg7jhEtPB",
    "content": "The importance weighted autoencoder (IWAE) is a variational-inference method that achieves a tighter evidence bound than standard variational autoencoders by optimizing a multi-sample objective. However, the method relies on reparametrizations and faces challenges with increasing Monte Carlo samples. Alternative approaches like the 'sticking-the-landing' IWAE gradient and the 'doubly-reparametrised' IWAE gradient have been proposed. This work argues for directly optimizing the proposal distribution in importance sampling, as in the reweighted wake-sleep algorithm, over IWAE-type multi-sample objectives. In this work, an adaptive-importance sampling framework called AISLE is introduced, which generalizes the RWS algorithm. It shows that AISLE includes IWAE-STL and IWAE-DREG as special cases. The focus is on variational inference algorithms to learn the generative model and construct a tractable variational approximation. The presentation is limited to a single latent representation-observation pair to avoid notational clutter. The text discusses variational inference algorithms for learning generative models and constructing tractable variational approximations. It introduces different algorithms like IWAE-DREG and RWS, which use Monte Carlo samples to reduce errors and optimize objectives. These algorithms aim to improve the efficiency and accuracy of variational inference. The importance sampling with K particles induces a bias that diminishes as K increases. RWS is an adaptive importance-sampling approach that improves its proposal distribution and optimizes \u03b8 via stochastic approximation. IWAE is popular but RWS has shown better empirical performance. Directly optimizing the proposal distribution like RWS is preferred over the multi-sample objective approach of IWAE due to \u03c6-gradient breakdown issues. The text discusses the limitations of IWAE due to the \u03c6-gradient breakdown and introduces modifications like IWAE-STL and IWAE-DREG to address this issue. It presents a new adaptive importance-sampling framework called AISLE, which encompasses RWS, IWAE-DREG, and IWAE-STL gradients. The framework ensures that gradient estimators do not degenerate as K increases. The text introduces AISLE, an adaptive importance-sampling framework that includes IWAE-STL and IWAE-DREG gradients. It shows that the IWAE-STL gradient can be recovered through AISLE, providing a theoretical foundation for IWAE-STL. Additionally, AISLE leads to a new family of gradient estimators for \u03b1-divergences. The focus of the work is not to derive new algorithms or determine the best AISLE special case. Empirical comparisons of algorithms on Gaussian models are provided in supplementary materials. Notation shorthand is used for concise representation. Expectations of test functions can be estimated by IID samples according to q \u03c6 and self-normalised approximations for \u03c0 \u03b8. The importance weighted autoencoder (IWAE) aims to maximize a lower bound on the log-marginal likelihood by optimizing the generative-model parameters \u03b8 and inference-network parameters \u03c6. The self-normalised estimate is typically biased but its bias vanishes at rate O(K^-1) as the number of samples K increases. IWAE reduces to the variational autoencoder (VAE) when K = 1. The IWAE extends the VAE to an auxiliary-variable construction, with a gradient approximated using a reparametrisation trick to reduce high variance. The IWAE objective involves maximizing a lower bound on the log-marginal likelihood by optimizing generative and inference-network parameters. The IWAE gradient, \u2207 iwae \u03c6 \u03b8, z, has drawbacks including reliance on reparametrisations and a vanishing signal-to-noise ratio due to the \u03c6-gradient breaking down. This leads to additional implementation costs and computation issues. The IWAE gradient has drawbacks such as a vanishing signal-to-noise ratio and reliance on reparametrisations. Two modifications, IWAE-STL and IWAE-DREG, have been proposed to address these issues. The RWS algorithm and self-normalised importance sampling approximation are used to approximate intractable quantities. The RWS algorithm uses self-normalised importance sampling to approximate intractable quantities. The optimization of both \u03b8 and \u03c6 is done simultaneously, sharing particles and weights. Adapting the proposal distribution q \u03c6 in importance-sampling schemes may not necessarily be based on minimizing bias. The RWS algorithm uses self-normalised importance sampling to approximate intractable quantities. Adapting the proposal distribution q \u03c6 in importance-sampling schemes may not necessarily be based on minimizing bias. Alternative techniques exist for optimizing \u03c6, such as minimizing the \u03c7 2 -divergence. The unified framework allows for the derivation of robust \u03c6-gradient estimators in the AISLE algorithm, optimizing via stochastic gradient-ascent. The \u03b8-gradient remains the same for all algorithms. The \u03b8-gradient is consistent across algorithms in variational inference for intractable models. Different interpretations exist, such as IWAE viewing it as an unbiased gradient of a lower-bound to the evidence, while AISLE and RWS see it as a biased approximation using self-normalised importance sampling. Approximations using Monte Carlo methods show bias and standard deviation orders. Optimization of \u0192-divergences in variational inference can be done without knowing Z \u03b8, allowing for efficient gradient estimation. The integral in (11) can be approximated using self-importance sampling, leading to a reparametrised estimator. Different cases are described, including AISLE-KL-NOREP/RWS and AISLE-KL. Proposition 1 shows that IWAE-STL can be derived from AISLE without the need for a multi-sample objective. Proposition 1 provides a theoretical basis for IWAE-STL, showing it can be derived from AISLE without a multi-sample objective. AISLE-KL is derived by approximating the exact \u03c6-gradient, potentially reducing bias and variance. The \u03b1-divergence between distributions p and q can be expressed in terms of \u03ba and f(y). The text discusses the minimization of a divergence in importance sampling, specifically focusing on AISLE-\u03b1-NOREP and AISLE-\u03b1 methods. It highlights the derivation of IWAE-DREG from AISLE and the scaling of learning rates for IWAE or IWAE-DREG \u03c6-gradients. The implementation of normalizing gradients is also mentioned, showing the equivalence of AISLE-\u03c7 2 to IWAE-DREG under certain conditions. The text discusses the scaling of learning rates for IWAE or IWAE-DREG \u03c6-gradients, focusing on the 'exclusive' KL-divergence and its optimization. It mentions the importance of the adaptive-importance sampling paradigm over the multi-sample objective paradigm in importance weighted autoencoders. The text discusses the self-normalisation bias within RWS/AISLE and the behavior of estimators as the number of particles, K, varies. It compares the estimators to vanilla Monte Carlo approximations and highlights the challenges in characterizing the small-K self-normalisation bias of reparametrisation-free AISLE gradients. The text discusses the challenges of characterizing the small-K self-normalisation bias in RWS/AISLE gradients and the use of importance-sampling approximations with K > 1 particles to reduce bias. It emphasizes the importance of ensuring q \u03c6 is close to \u03c0 \u03b8 to control the error of such approximations. The text discusses the importance of having a flexible variational family Q that is close to the target distribution \u03c0 \u03b8 to control the error of importance-sampling approximations with multiple particles. If Q is not expressive enough, minimizing the exclusive KL-divergence could lead to poorly-behaved importance weights. In such cases, optimizing \u03c6 to minimize KL(\u03c0 \u03b8 q \u03c6 ) is recommended. In some scenarios, divergence may be preferred over gradient-descent algorithms for faster convergence. A smaller number of particles, K, could be preferable for \u03c6-gradients due to self-normalisation bias. Setting K = 1 for \u03c6-gradients approximation is not always optimal as increasing K can reduce variance and improve gradient approximations. Seeking to optimize exclusive KL-divergence could lead to poorly behaved importance-sampling approximations when \u03c6 is far from optimal. In the context of optimizing \u03c6-gradients, different gradient estimators are compared, including AISLE-KL-NOREP, AISLE-KL, AISLE-\u03c72-NOREP, and AISLE-\u03c72. These estimators vary in their approach to reparametrization and divergence types, impacting variance and gradient accuracy. The gradient estimators compared in optimizing \u03c6-gradients include AISLE-\u03c72, IWAE, IWAE-DREG, and RWS-DREG. These estimators differ in reparametrization techniques and divergence types, affecting variance and gradient accuracy. The joint law of observations and latent variables factorizes with parametrized \u03b8. Latent variable-observation pairs are modeled, with known matrix D. Proposal distributions are fully factored Gaussians. The model is similar to benchmarks in previous studies. In a more realistic scenario, latent vectors z can be correlated under the generative model. The variational approximation, however, remains fully factored and may not capture uncertainty about the latent variables. The 'score-function free' \u03c6-gradients achieve near-zero variance for proposal mean parameters when variance parameters are optimal. Further analysis on reparametrisation-trick gradients in Gaussian settings is discussed in Xu et al. (2019). In Xu et al. (2019), the optimization of \u03c6 in Gaussian settings is compared empirically. Different algorithms are tested with varying numbers of particles and model dimensions. The generative model is specified in two scenarios, showing that the variational approximation may not fully capture the dependence structure of latent variables. In Xu et al. (2019), the optimization of \u03c6 in Gaussian settings is compared empirically using different algorithms. The generative model is specified in two scenarios, highlighting issues with variational approximation capturing latent variable dependence structure. The gradient-ascent algorithm is initialised with \u03c6 values drawn from a standard normal distribution. Stochastic gradient-ascent and ADAM are used for optimization with a total of 10,000 iterations. The covariance matrix is non-diagonal, with a logarithmic scaling on the second axis."
}