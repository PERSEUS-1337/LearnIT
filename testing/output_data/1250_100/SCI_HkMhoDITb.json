{
    "title": "HkMhoDITb",
    "content": "Recent theoretical and experimental results suggest the potential of using current and near-future quantum hardware for challenging sampling tasks. This paper introduces free-energy-based reinforcement learning (FERL) as an application of quantum hardware, specifically using a quantum annealer to approximate the free energy of a quantum Boltzmann machine (QBM). The method is applied to reinforcement learning on a grid-world problem using the D-Wave 2000Q quantum annealer, showing promising results in harnessing quantum sampling power for reinforcement learning tasks. The text discusses the use of free-energy-based reinforcement learning (FERL) with a restricted Boltzmann machine (RBM) to approximate a utility function for the agent. RBMs can efficiently calculate free energy using closed formulae, and general Boltzmann machines (GBM) are proposed as universal Q-function approximators. Monte Carlo simulation is traditionally used for approximating free energy, but there are efforts to speed up this process. The text discusses using quantum annealers to approximate the free energy of a physical system, representing the Q-function as the free energy of a quantum annealer. By slowly evolving the state of the physical system towards a Boltzmann-like distribution, samples can be obtained to estimate the Q-function. This approach is a novel application of quantum annealers in reinforcement learning. In recent years, studies have focused on classical Boltzmann machines, but BID10 introduced a quantum-inspired algorithm for approximating free energy in GBMs. Using simulated quantum annealing, they found that using a deep Boltzmann machine can greatly improve learning. However, sampling from a quantum system representing a quantum Boltzmann machine is challenging due to the superposition state. The study introduces the use of a quantum annealer to approximate the free energy of a classical Boltzmann machine and extends the concept to quantum Boltzmann machines in reinforcement learning. The study proposes a novel stacking procedure to reconstruct the full state of superposition from partial information obtained from sampling after each anneal using a quantum annealer. Experimental results using the D-Wave 2000Q quantum processor support the applicability of quantum annealers in reinforcement learning. The Q-function is defined by mapping a tuple of a stationary policy, current state, and immediate action to the expected value of rewards in a Markov chain. The text discusses the optimal policy for a Markov Decision Process (MDP) using Q-learning with neural networks. It focuses on TD(0) Q-learning to find the optimal policy and Q-function by minimizing the distance between T(Q) and Q. It also mentions a clamped Boltzmann machine for energy calculation in the context of neural networks. The text discusses a clamped quantum Boltzmann machine (QBM) with qubits associated to each node of the network, replacing binary random variables. The energy function is substituted by the quantum Hamiltonian of an induced transverse field Ising model (TFIM). A clamped QBM with \u0393 \" 0 is equivalent to a clamped classical Boltzmann machine. In the classical Boltzmann machine case, the equilibrium free energy F pvq is determined by a fixed thermodynamic beta. The negative free energy of a GBM is used to approximate the Q-function in RL. The weights of a GBM can be trained using the TD(0) update rule. The visible nodes of a GBM are divided into state nodes S and action nodes A. The hidden nodes are encoded in a binary format with respect to the Boltzmann distribution of the classical Hamiltonian. The equilibrium free energy F pvq in a Boltzmann machine is determined by a fixed thermodynamic beta. The negative free energy of a QBM is used to approximate the Q-function in RL. The weights of a QBM can be trained using the TD(0) update rule. Visible nodes in a QBM are divided into state nodes S and action nodes A, with hidden nodes encoded in a binary format. The FERL method using QBMs involves training weights with the TD(0) update rule. Quantum annealing is used to approximate values of free energy and expected observables. The quantum adiabatic theorem states that a system remains in its steady state under a slowly changing Hamiltonian. The history of quantum adiabatic computation and quantum annealing inspired manufacturing efforts towards physical realizations of adiabatic evolution via quantum hardware. Contemporary investigations in quantum adiabatic theory are studying adiabaticity in open quantum systems, proving adiabatic theorems for systems coupled to a thermal bath. This work shows promising opportunities to use quantum annealers to sample from the Gibbs state of a TFIM. In quantum annealing, samples gathered are often not in the Gibbs state of the final Hamiltonian due to complications like level crossings and gap closure. The D-Wave 2000Q quantum annealer is used, featuring a Chimera graph structure for qubit connectivity. The goal is to associate a single virtual strength \u0393 and inverse temperature \u03b2 to all TFIMs constructed through FERL. The structure of the quantum annealer, D-Wave 2000Q, features a Chimera graph with 16 qubits serving as the clamped QBM in FERL. A challenge arises in measuring spin configurations along a fixed axis, leading to the collapse of quantum information related to the spin projection. A method called replica stacking based on the Suzuki-Trotter expansion of the TFIM is proposed to overcome this challenge. A grid search is performed over virtual parameters \u03b2 and \u0393 to optimize learning in the early stages of training for FERL. The Suzuki-Trotter decomposition method is used to approximate the partition function of a TFIM by mapping it to a classical Ising model of one dimension higher. This allows for the representation of quantum spins in a classical system through replicas in the z-basis. The method helps in optimizing learning for FERL in the early stages of training by overcoming challenges in measuring spin configurations on a fixed axis. The quantum Boltzmann machine, based on the Suzuki-Trotter decomposition, utilizes hidden nodes to carry more information than classical ones. The connections between hidden nodes are more complex in the quantum case, reflecting correlations. The machine is an undirected graphical model one dimension higher than classical models, with coupling strengths determined by mathematical decomposition. Weight updates require samples from the Boltzmann distribution to estimate certain parameters. The Boltzmann distribution is used to estimate parameters in the quantum Boltzmann machine. Sampling is done using the simulated quantum annealing algorithm, which simulates quantum annealing phenomena. This algorithm is similar to classical simulated annealing and is based on the Suzuki-Trotter expansion. Studies have shown similarities between the behavior of the simulated quantum annealing algorithm and quantum annealing. The simulated quantum annealing algorithm, SQA, can sample from Boltzmann distributions of quantum Hamiltonians with a transverse field. It converges to the Boltzmann distribution of the effective classical Hamiltonian of one dimension higher. However, sampling from the Boltzmann distribution is computationally involved and slow, making it an NP-hard problem. Another option is variational approximation, which also has drawbacks. Quantum annealers can efficiently provide samples from Boltzmann distributions for TFIM. By using quantum annealing, the free energy of a QBM can be approximated. The method involves sampling \u03c3 z-configurations from a quantum annealer operating at a virtual inverse temperature \u03b2 and transverse-field strength \u0393. These configurations represent classical spin configurations from a higher-dimensional effective Hamiltonian. The free energy for TFIM can be approximated by gathering a pool of configurations sampled by the quantum annealer. The quantum annealer samples configurations for TFIM, allowing repetitions. Effective configurations are represented by replicas of classical configurations. The probability mass function is supported by configurations synthesized from candidate replicas. Sampling is done by drawing elements from a set C. The conditional probability can be sampled from by drawing elements from C. The distribution over effective configurations is considered. The MCMC method is used to sample effective spin configurations for the TFIM. Classical spin configurations are attached to the SQA's structure randomly, and transitions are made with a Metropolis acceptance probability. The method allows for sampling from the effective spin configurations, which are then used to approximate the free energy of the TFIM. The number of different configurations sampled is limited due to a small number of hidden nodes in the experiments. The MCMC method is not needed due to limited configurations. Classical spin configurations are randomly attached to the SQA structure. The undirected graphical model uses replica stacking technique with hidden nodes governed by r replicas. The energy function differs from a classical Boltzmann machine, and the free energy approximates the Q-function. The graphical model serves as a function approximator for the Q-function in a 3x5 grid-world problem. The FERL methods are benchmarked using Algorithm 2, which involves updating QBM weights and using replica stacking to obtain effective spin configurations. The MCMC technique is used to gather statistics and return specific values. The task involves finding an optimal policy for an agent in a grid-world using Boltzmann machines with 16 hidden nodes. The agent receives rewards, penalties, and neutral values for different actions. Training samples are used to measure fidelity of policies, and each algorithm is run 100 times. An optimal policy is represented by directional arrows indicating movement directions. The fully connected deep Q-network BID23 consists of 14 state nodes, two layers of eight hidden nodes each, and an output layer of five nodes representing the values of the Q-function for different actions. The network of superconducting qubits is treated as a clamped QBM with two hidden layers. 150 effective classical configurations are constructed for each query to the D-Wave 2000Q chip using the replica stacking method. 10 independent runs of FERL are conducted to find the average fidelity over the runs. The average fidelity of the best known policies generated by different FERL methods is shown in Fig. 6. The curves represent different methods such as D-Wave, SQA Bipartite, SQA Chimera, SA Bipartite, and SA Chimera, each with specific parameters and training configurations. The SA algorithm is run with a linear inverse temperature schedule, with \u03b2 = 2.0 as the final value. The D-Wave Classical curve is generated using samples from the D-Wave 2000Q, while the RBM curve is generated using a different method. Various Q-learning methods are used to solve the grid-world problem, including a fully connected deep Q-network method. The RBM-based free-energy RL method outperforms the deep Q-network method for the problem size considered. The comparison in Fig. 6 shows that replica stacking is successful in estimating classical configurations from a quantum annealer. FERL with the quantum annealer and replica stacking outperforms FERL with classical Boltzmann machines. Quantum annealing chips with more connectivity and control over annealing time can further enhance the replica stacking method in RL tasks. SA-based FERL using a DBM is more effective than using the Chimera graph due to its additional connections. The optimal choice of virtual parameters \u03b2 and \u0393 for TFIMs constructed using FERL is crucial. Quantum annealer samples can approximate Boltzmann distribution samples of classical Ising models. The extended undirected graphical model developed in this paper using replica stacking is versatile beyond Q-function approximation in RL tasks. The paper introduces a free-energy-based reinforcement learning algorithm using a quantum annealer, the D-Wave 2000Q, for approximating quantum Boltzmann machines. The method utilizes the Suzuki-Trotter decomposition and measured configurations as replicas of a classical Ising model. The results show potential for outperforming traditional reinforcement learning algorithms on digital hardware, with future applications in quantum machine learning."
}