{
    "title": "Syxp-1HtvB",
    "content": "Despite the success of Generative Adversarial Networks (GANs) in image synthesis, there is a lack of understanding on how photo-realistic images are composed from random noises. This work reveals a highly-structured semantic hierarchy in generative representations, showing that different layers control spatial layout, objects, and scene attributes. This understanding allows for manipulation of latent semantics in scene synthesis. The success of deep neural networks lies in representation learning, where concept detectors emerge in deep representations trained for classification tasks. Analyzing these representations provides insight into generalization ability and feature transferability. Current efforts focus on interpreting deep representations, with recent advances in Generative Adversarial Networks (GANs) for image synthesis. The nature of generative representations in GANs and how photo-realistic images are composed over different layers of the generator remain less explored. Internal units of CNNs emerge as object detectors when trained to categorize scenes, providing an ideal solution for classifying scenes. Synthesizing a scene requires deep knowledge for generative models to learn, including generating individual objects, deciding room layout, and rendering scene attributes like lighting and color scheme. Recent work visualized internal filters in GANs for interpreting deep representations. Recent work on interpreting GANs visualized that internal filters at intermediate layers are specialized for generating specific objects. However, understanding how GANs compose photo-realistic images with multiple variation factors at different levels is still uncertain. This study provides a deeper interpretation of hierarchical generative representations by matching layer-wise variation factors with human-understandable scene variations. The research reveals a highly-structured semantic hierarchy in deep generative representations, even without explicit supervision. The study explores layer-wise stochasticity in GAN models for scene synthesis without external supervision. It identifies variation factors across layers: spatial layout in early layers, category-guided objects in middle layers, and attributes/color scheme in later layers. This manipulation technique is extended to other GAN models like BigGAN and ProgressiveGAN. Previous research has focused on interpreting CNN representations for image classification tasks. Interpretation techniques for CNNs in image classification tasks have been studied extensively, including analyzing hidden units, computing class saliency maps, interpreting hidden representations, and transferring features. However, these techniques cannot be directly applied to generative models like GANs, which advance image synthesis. Recent advancements in image synthesis, particularly with Generative Adversarial Networks (GANs), have led to the generation of photo-realistic faces, objects, and scenes. These models have found applications in image editing tasks such as manipulation, painting, and style transfer. Despite their success, the underlying semantics of GANs in producing diverse and realistic images remain unclear. While previous studies have analyzed the generator units and their ability to synthesize informative visual content, there is still a need to quantitatively explore the emergence of multi-level features in well-trained GAN models. Our work focuses on exploring the emergence of multi-level semantics in early latent space. Using image classifiers, we assign semantic scores to synthesized images for different variation factors. We learn decision boundaries in the latent space for specific concepts and verify their emergence quantitatively. The process is akin to an artist setting up the layout of a room before adding objects and refining details. In this work, the focus is on how GANs learn to synthesize photo-realistic scenes from scratch. Semantics are extracted from the output image to align with human perception, including layout, object, and attribute. A quantification technique is proposed to identify variation factors encoded in the generative representation, revealing that GANs synthesize scenes in a manner highly consistent with human perception. GAN synthesizes scenes in a manner consistent with human perception by hierarchically composing multi-level abstractions. A method is described to quantify emergent variation factors in the generative representation. Probing and verification steps are used to identify meaningful concepts for scene synthesis. The generator of GAN learns the mapping from latent space to image space, allowing the study of variation factors inside the latent space. To study variation factors in the generative representation, synthesized images are used to extract semantic information from latent codes. Off-the-shelf image classifiers assign semantic scores based on scene attributes like \"indoor lighting\". A hierarchical semantic space is formed by predicting scores at different abstraction levels. Decision boundaries are established for concepts like \"indoor lighting\" to separate latent space into present or absent categories. This approach helps in verifying manipulatable variation factors. In studying variation factors in generative representation, the key issue is defining relevance and verifying if learned representations encode specific factors. By manipulating latent space, such as changing indoor lighting in synthesized images, the GAN model captures these factors. Separation boundaries are established for candidate concepts, and by moving latent codes along normal vectors, semantic scores increase. Rescoring varied latent codes quantifies the relevance of a variation factor to the model. This process is illustrated in Fig.2. The process involves manipulating latent space to capture variation factors in generative representations. By normalizing normal vectors and using a fixed step, relevant latent variation factors can be ranked. The deep representation in models like StyleGAN and BigGAN is derived directly from the latent code, leading to a hierarchy of variation factors in the generative representations. Empirical analysis on StyleGAN shows multi-level variation factors encoded in the latent space. In Sec.3.2, GANs encode multi-level variation factors in the latent space, representing categorical information like bedroom v.s. living room. By controlling activations, categories can be easily changed while preserving layout and attributes. Sec.3.3 demonstrates identifying relevant attributes for scene manipulation. Experiments are conducted on StyleGAN, PGGAN, and BigGAN, training models on specific scene categories and a mixed model for understanding categorical information encoding. The text discusses using image classifiers and GAN models to assign semantic scores to synthesized scenes, including layout estimation, scene category recognition, and attribute classification. It also mentions extracting the color scheme of a scene image. The GAN composes scenes in a hierarchy similar to human perception, manipulating variation factors in images. The manipulation results show changes in layout, categorical objects, and lighting attributes at different layers. The text discusses how StyleGAN model analyzes indoor scenes by feeding latent code to different convolutional layers. It shows that layers in GAN specialize in composing semantics hierarchically, with bottom layers determining layout, lower and upper layers controlling category and attribute variations, and color scheme rendered at the top. The text discusses how GAN synthesizes scene images by manipulating latent vectors at different layers to control variations in layout, category, and attributes. It shows that GAN can learn shared objects and transform them to represent different scene categories, following a structured semantic hierarchy. The text discusses how GAN synthesizes scene images by manipulating latent vectors at different layers to control variations in layout, category, and attributes. It shows that hierarchical variation factors emerge inside the generative representation for synthesizing scenes, facilitating semantic scene manipulation. A user study confirms that bottom layers align with layout, lower layers control scene category, etc., supporting the identification of semantic hierarchy and variation factors across layers. The text discusses how GAN models can manipulate latent codes at different layers to change attributes in scene images. It shows that hierarchical variation factors are present in the generative representation, allowing for manipulation of decoration style, furniture material, cleanliness, room layout, scene category, and scene attributes. GAN models encode hierarchical semantics from layout to scene attributes, with middle layers synthesizing different objects for different scene categories. The text further explores how GAN interprets scene categories and encodes categorical information. The text discusses how GAN models manipulate scene categories by varying latent codes and tracking object transformations. Using a StyleGAN model trained on bedroom, living room, and dining room images, objects are segmented and mapped during category transformations. Most stuff classes remain the same, while objects are mapped into different categories. The GAN model can manipulate scene categories by mapping objects into different classes and sharing objects between categories. This allows for control over image generation without the need for class labels, as seen in BigGAN. The variation factors in scene synthesis depend on the training data used. The GAN model can manipulate scene categories by mapping objects into different classes and sharing objects between categories. Variation factors in scene synthesis depend on the training data. Applying the method to a collection of StyleGAN models captures a wide range of attributes. Results show high consistency with human perception, indicating the effectiveness of the quantification method. Manipulation results with desired semantics are realistically achieved. Some variation factors in the generative representation are more disentangled than others. Our work introduces a new metric for disentanglement analysis in GANs, focusing on moving latent codes along semantic directions to assess changes in other factors. The study shows that GANs can disentangle layout-level semantics from attribute-level ones, although some scene attributes still entangle with each other. The proposed quantification metric aligns with human perception and is effective in evaluating disentanglement. The method is applied to PGGAN and BigGAN models trained on LSUN and Places datasets, showing promising results compared to StyleGAN. Our work introduces a new metric for disentanglement analysis in GANs, focusing on moving latent codes along semantic directions to assess changes in other factors. The study shows that GANs can disentangle layout-level semantics from attribute-level ones, although some scene attributes still entangle with each other. The proposed quantification metric aligns with human perception and is effective in evaluating disentanglement. The method is applied to PGGAN and BigGAN models trained on LSUN and Places datasets, showing promising results compared to StyleGAN. PGGAN feeds the latent vector only to the very first convolutional layer, while BigGAN concatenates the latent vector with a class-guided embedding code before feeding it to the generator, allowing layer-wise analysis. The proposed re-scoring method can help identify manipulatable semantics in PGGAN, and analysis results on BigGAN show that scene attributes can be best modified at upper layers. These results demonstrate the generalization ability of the approach and the emergence of manipulatable factors in other GANs. The GAN model learns to set up layout, generate objects, and render scene attributes and color schemes when trained to synthesize scenes. A re-scoring method is proposed to identify manipulatable semantic concepts within the model. Implementation details, ablation studies, limitations, and future directions are discussed. Results of semantic scene manipulation and model structures of StyleGAN and BigGAN are presented. Experiments are conducted on PGGAN, BigGAN, and ablation studies on layer-wise manipulation are provided. Experiments were conducted on PGGAN, StyleGAN, and BigGAN models trained on LSUN and Places datasets. Various scene categories were synthesized using different models, with additional models trained for indoor and outdoor scenes. Tab.1 shows details of each StyleGAN model, including training samples and Fr\u00e9chet inception distances (FID). The synthesis quality of scene images was evaluated using Fr\u00e9chet inception distances (FID). BigGAN was used to train a conditional generative model for scene images at a resolution of 256 \u00d7 256. Off-the-shelf image classifiers were employed to extract semantic scores from multiple abstraction levels, including layout, category, scene attribute, and color scheme. The classifiers included a layout estimator, a scene category classifier, an attribute predictor, and a color scheme extractor. The category classifier and attribute predictor could output the probability of an image belonging to a certain category. The layout estimator detects the outline structure of an indoor place. A GAN model generates synthesized scene images by sampling latent codes. Image classifiers assign semantic scores for visual concepts. The relative position between image center and walls quantifies layout. A linear SVM is trained for bi-classification using positive and negative samples. The study focuses on verifying manipulatable semantics in synthesized scene images. A re-scoring technique is proposed to filter out invariable attributes in the StyleGAN model trained for bedrooms. The method successfully identifies manipulatable semantics by sorting scene attributes based on semantic scores, SVM classifier accuracy, and a quantification metric. Our method filters out invariable attributes and identifies manipulatable scene semantics like \"wood\" and \"indoor lighting\". It pays attention to score modulation in the latent space, detecting variation factors accurately compared to relying solely on SVM classifiers. The proposed re-scoring technique successfully identifies manipulatable scene semantics but has limitations in detecting spatial layouts for outdoor scenes and relies on off-the-shelf classifiers with accuracy issues. Future improvements include leveraging computational photography tools for universal viewpoint representation and using more powerful discriminative models for better manipulation boundaries. Our proposed method allows for identifying hierarchical variation factors and facilitating semantic scene manipulation using StyleGAN and BigGAN architectures. Experiments are conducted on high-resolution scene synthesis models, showcasing manipulation results at different levels of semantics. The latest GAN models like StyleGAN and BigGAN use layer-wise latent codes for better generation quality. In StyleGAN, layout, category, attribute, and color scheme correspond to different convolutional layers. BigGAN separates layers into two groups for semantic manipulation. The \"class\" code in Fig.17 separates layers into lower and upper groups. BigGAN's attribute-level semantics are better controlled by upper layers, as shown in Fig.9(b). Manipulating attributes at upper layers gives desired output, while lower layers result in unexpected variations. Ablation study on StyleGAN confirms this hierarchy, with manipulating latent codes at attribute-relevant layers improving indoor lighting without affecting other objects (Fig.18). Manipulating latent codes at attribute-relevant layers can increase indoor lighting without affecting other factors. Selecting bottom layers as target layers and manipulating boundaries from all abstraction levels show that modifying the latent code at bottom layers only affects layout semantics, confirming the emergence of semantic hierarchy."
}