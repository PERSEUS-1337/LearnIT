{
    "title": "H1xTup4KPr",
    "content": "In computer vision, CNNs for image classification were developed using biased datasets with large objects. To test CNN architectures for tiny object classification, a testbed with MNIST digits and histopathology images was created. Observations show that signal-to-noise ratio affects generalization, more data improves performance, higher capacity models generalize better, adapting receptive field benefits with known object sizes, and global pooling operation choice impacts very small signal-to-noise ratios. The goal of image classification using Convolutional Neural Networks (CNNs) is to assign image-level labels. In real-life applications like medical or hyperspectral image analysis, low signal-to-noise ratio can result in only a small portion of the input correlating with the label. The Object to Image (O2I) ratio is defined as the input image signal-to-noise ratio. There is a distribution shift between standard classification benchmarks and domain-specific datasets, as shown in Figure 1. In real-life applications like medical or hyperspectral image analysis, low signal-to-noise ratio can result in only a small portion of the input correlating with the label. Recent works have studied CNNs under different noise scenarios, showing that CNNs can mitigate label-corruption noise by increasing training data size, tuning optimizer hyperparameters, or weighting input training samples. This paper focuses on studying CNN performance in tiny object classification with low Object to Image (O2I) ratios. The study investigates the performance of CNNs in tiny object classification and the relationship between input signal-to-noise ratio and model generalization. Two synthetic datasets inspired by Where's Wally? are created, one derived from MNIST digits and the other from histopathology imaging. These datasets are designed to stress-test CNN behavior in low input image signal-to-noise ratio scenarios. The study examines the behavior of CNNs in low input image signal-to-noise ratio scenarios. It develops a classification framework based on CNNs and analyzes factors affecting model optimization and generalization. Observations include the need for sufficient training data for models to generalize, the impact of model capacity on generalization, and the importance of model inductive bias, particularly receptive field size. Different pooling operations show similar performance for larger signal-to-noise ratios but affect optimization ease for very small ratios. The study explores CNN behavior in low signal-to-noise scenarios, analyzing optimization and generalization properties. Two datasets are created for evaluation, one from MNIST and another from CAMELYON. A cluttered MNIST dataset is introduced for binary image classification, with images containing randomly placed MNIST digits on a large canvas. The code for the testbed will be publicly available for reproducibility. The study introduces a cluttered MNIST dataset for binary image classification, with varying object-to-image ratios achieved by increasing canvas resolution. Images contain digit 3 as the object of interest, with clutter digits as distractors. Different O2I ratios correspond to different clutter object densities. Training, validation, and test images are generated for each O2I ratio. Refer to supplementary material for image generation details and additional dataset information. The CAMELYON dataset contains gigapixel histopathology images with pixel-level lesion annotations from 5 different acquisition sites. Datasets are generated for various object-to-image ratios (O2I) and image resolutions. Positive examples are created by cropping lesion annotations, while negative images are randomly cropped healthy images. Class balance is maintained by sampling an equal amount of positive and negative crops. No pixel-wise information is used during training. Refer to supplementary material for more details on the image generation process and dataset visualizations. The CAMELYON dataset contains gigapixel histopathology images with lesion annotations. Positive examples are cropped from lesion annotations, while negative images are randomly cropped healthy images. No pixel-wise information is used during training. The classification pipelines follow BagNets backbone, allowing control over the network receptive field size. The pipelines consist of a topological embedding extractor, global pooling operation, and a binary classifier. Different architectures are tested by varying the embedding extractor and pooling operation. The pipeline for training classification systems on the CAMELYON dataset includes a topological embedding extractor and global pooling operation. Different pooling operations such as max, logsumexp, average, and soft attention are experimented with. The study focuses on optimizing CNNs and their generalization with low O2I ratios, investigating image-level annotations, O2I limit vs. dataset size, and generalization difficulties. The study investigates generalization difficulties in CNNs with low O2I ratios. It explores the impact of model capacity, receptive field adjustment, global pooling operations, and optimization ease. The experiments use RMSProp for training and monitor validation accuracy for model selection. The study analyzes the impact of model capacity, receptive field adjustment, and global pooling operations on CNN generalization with low O2I ratios. Results show the best validation set performance achieved with max pooling and specific training set sizes. Additional details and analysis can be found in the supplementary material. In the nCAMELYON dataset, CNNs achieve reasonable test set accuracies for specific O2I ratios. The influence of training set size on model generalization for nMNIST data is tested, showing better generalization with larger datasets. Heatmaps depict mean validation set results for different O2Is and training set sizes. The study focuses on the impact of training set size and O2I ratio on model generalization for nMNIST and nCAMELYON datasets. Results show that larger training sets lead to better generalization, with CNNs performing better with increased capacity and smaller O2Is. This improvement is attributed to the model's ability to ignore input data noise. The study found that larger training sets improve model generalization, with CNNs performing better with increased capacity and smaller O2Is. The model's ability to learn-to-ignore input data noise is crucial for this improvement. Results suggest that a very large histopathology dataset could enable training CNN models using only image level annotations. Additionally, the study reports test accuracy based on O2I ratio and receptive field size for nMNIST and nCAMELYON datasets. In nMNIST, a larger receptive field leads to better performance, while in nCAMELYON, the smallest receptive field performs best, indicating that class-relevant information is contained in the texture. In this experiment, the performance of four different pooling approaches is compared for nMNIST and nCAMELYON datasets. For nMNIST, max-pooling is the best choice for smaller O2Is, while for nCAMELYON, mean and soft attention poolings perform best. In large scale nMNIST experiments, some configurations struggle to fit the training data. After struggling to fit the training data in some configurations, experiments were conducted using Gaussian samples instead of nMNIST datapoints. Results showed that CNNs could memorize the Gaussian samples but struggled with the nMNIST dataset, indicating that nMNIST noise may be more challenging. The optimization difficulty increased with decreasing O2I ratio, with max pooling being the most robust. Results were consistent across different random seeds. Reasoning about tiny objects in computer vision, like in medical imaging and remote sensing, is of high interest. Most approaches rely on manual dataset curation and additional pixel-level annotations to improve signal-to-noise ratio. Collecting pixel-level annotations is costly and requires expert knowledge, posing a bottleneck in data collection. Some approaches use attention mechanisms to process high-dimensional inputs efficiently. In the context of computer vision, attention mechanisms are used to process high-dimensional inputs efficiently. Recent research has explored attention-based approaches in various learning contexts, but the exact O2I ratio used in experiments is often not reported. Optimizing and generalizing convolutional neural networks (CNNs) in low O2I classification scenarios involves considerations such as model capacity and dataset size. Over-parametrized CNNs tend to generalize better, and higher capacity models perform better with proper regularization. Additionally, CNN performance improves logarithmically with dataset size. Incorporating inductive biases like convolutions in CNNs improves model performance, especially with alterations in network connectivity. CNN accuracy scales logarithmically with the size of the receptive field. This paper addresses image classification in low signal-to-noise scenarios, an unexplored machine learning problem. The study focuses on image classification in low signal-to-noise scenarios, highlighting the challenges faced by CNNs in generalizing for low and very low signal-to-noise ratios. The experiments show that properly designed CNNs can be trained without pixel-level annotations, but the amount of training data needed for generalization increases rapidly with the inverse of the signal-to-noise ratio. The paper invites the community to work on data-efficient solutions for this problem. The study used the nMNIST dataset for analysis due to limited control over input signal-to-noise ratios. Real-life histopathology data from the CAMELYON dataset was also used, but the small number of unique lesions limited the scalability of the experiments. MS COCO dataset showed correlations between objects and image backgrounds. Larger datasets improved model generalization, but scaling datasets like CAMELYON to tens of thousands of samples may be challenging. In this section, additional details about the datasets used in the experiments are provided. The nMNIST dataset is utilized for binary classification tasks with varying object-to-image ratios. Positive images contain one digit 3, while negative images do not. The study aims to stimulate research in image classification for low signal-to-noise input scenarios. The nMNIST dataset is used for binary classification tasks with varying object-to-image ratios. Positive images contain one digit 3, while negative images do not. The canvas size is adjusted to generate images at different resolutions. Positive images have one digit 3 and n digits from clutter subset, while negative images have n + 1 instances from clutter subset. Training, validation, and testing images are split evenly between positive and negative images for each O2I ratio. The nCAMELYON dataset consists of positive and negative images for binary classification tasks related to breast cancer metastases detection. Positive samples are extracted from pixel-level annotations, while negative samples are randomly selected from healthy images. Training, validation, and test sets are split based on the center where the images were acquired to prevent data contamination. The nCAMELYON dataset includes positive and negative images for breast cancer metastases detection. Images are split into validation and test sets based on the acquisition center. Images are generated at different resolutions and O2I ratios. Global pooling operations and different architectures are tested using four pooling functions: max-pooling, mean-pooling, logsumexp, and soft attention. The curr_chunk discusses different pooling operations for topological embedding, including max pooling, logsumexp pooling, average pooling, and attention-based pooling with additional weighting. The soft-attention mechanism is parametrized following a specific model, and the BagNet architecture is adapted for the experiments. The BagNet architecture is adapted for experiments with different receptive field sizes, varying the number of convolution filters and downsampling using convolutions with stride 2. The architectures differ in the number of 3x3 convolutions, with a decrease in receptive field achieved by replacing them with 1x1 convolutions. The number of convolution filters is increased by a factor of 2.5 to compensate for the loss of trainable parameters. Additionally, network capacities are tested by scaling the number of convolutional filters by a constant factor. In this experiment, the nMNIST dataset is used to test CNNs generalization under class-imbalanced scenarios. The training set class balance is altered by changing the proportion of positive images, with balance values ranging from 0.01 to 0.99. The dataset size remains constant, and experiments are conducted with different receptive field sizes and pooling operations. Results show that model performance decreases as training data becomes more unbalanced, with max pooling and logsumexp being the most robust to class imbalance. The impact of network capacity on generalization performance in CNNs is tested using the nMNIST dataset under class-imbalanced scenarios. Results show that increasing model capacity does not necessarily improve generalization for small datasets. Various global pooling operations are compared based on O2I limit and dataset size, with heatmaps illustrating validation results and minimum training examples needed for specific accuracy levels. The impact of network capacity on generalization performance in CNNs is tested using the nMNIST dataset under class-imbalanced scenarios. Results show that increasing model capacity does not necessarily improve generalization for small datasets. Validation set accuracy heatmaps for different pooling methods are analyzed, along with the minimum training set sizes required to achieve specific validation accuracy levels. Object localization capabilities of the classification models are also examined through saliency maps. The study analyzes the impact of network capacity on generalization performance in CNNs using the nMNIST dataset. Results suggest that increasing model capacity may not always improve generalization for small datasets. Object localization capabilities of classification models are assessed through saliency maps, with a focus on the average precision for detecting the object of interest. The saliency is used as a confidence measure for detection, with wrongly localized objects counted as false positives and false negatives. The study also explores the dependence of average precision on pooling methods and receptive fields. The study evaluates object localization in classification models using saliency maps. Detection performance deteriorates for smaller object-to-image ratios, with max-pooling performing best for small ratios and logsumexp for larger ratios."
}