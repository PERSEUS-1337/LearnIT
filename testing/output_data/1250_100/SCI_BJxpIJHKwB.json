{
    "title": "BJxpIJHKwB",
    "content": "Few shot image classification involves learning a classifier from limited labeled data. Attentive Weights Generation for few shot learning via Information Maximization (AWGIM) addresses the challenge of generating exact and universal classification weights for diverse query samples with very few training samples. AWGIM generates different classification weights for each query sample by allowing them to attend to the entire support set. By maximizing the lower bound of mutual information between generated weights and query as well as support data, AWGIM achieves state-of-the-art performance on benchmark datasets. AWGIM achieves state-of-the-art performance on benchmark datasets by generating exact and universal classification weights for diverse query samples with very few training samples. Meta learning is the most popular approach for few shot problems, allowing models to quickly adapt to new tasks by extracting high-level knowledge across different tasks. In this work, Attentive Weights Generation for few shot learning via Information Maximization (AWGIM) is introduced to address limitations in weights generation methods for different tasks. AWGIM generates classification weights specifically for each query sample by maximizing mutual information between generated weights and query, support data. This approach aims to ensure classification weights fitted to diverse query data, achieving state-of-the-art performance on benchmark datasets. AWGIM introduces Variational Information Maximization in few shot learning, minimizing computational overhead. By maximizing mutual information, it eliminates inner updates without performance loss. AWGIM outperforms existing methods on benchmark datasets, with detailed component analysis. Previous methods include gradient-based approaches and metric-based methods for few shot learning. In few-shot learning, various methods have been explored to learn similarity metrics between query and support samples, including considering spatial information and generating classification weights directly. Some methods involve using graph neural network denoising autoencoders or generating \"fast weights\" from loss gradients. Generative models are also used to generate more data for few-shot classification tasks. In few-shot learning, methods like attention mechanisms have shown success in computer vision and natural language processing. This work utilizes self and cross attention for encoding task and query-task information in few-shot image classification. The approach focuses on maximizing mutual information between random variables x and y to decrease uncertainty. The mutual information between random variables x and y is maximized to decrease uncertainty. This is achieved through attention mechanisms in few-shot image classification, enabling task knowledge to be incorporated into query samples. The weight generator generates classification weights specific for x, aiding in class label prediction and input reconstruction. The proposed model maximizes the lower bound of mutual information and generates classification weights sensitive to query samples. The problem is formulated under episodic training paradigm for few-shot classification tasks. During meta-training, the meta-loss is estimated on the query set to optimize the model, while during meta-testing, the model's performance is evaluated on the query set with labeled support set. The model learns transferable knowledge across tasks and quickly adapts to novel tasks. The proposed approach aims to generate classification weights for different tasks by utilizing a feature extractor to output image feature embeddings. Latent Embedding Optimization (LEO) is a method related to this work, where a latent code z is generated by h conditioned on a support set S. The classification weights w are decoded from z and used to compute the loss on the support set. The updated latent code z is then used to decode new classification weights for the query set. The objective function of LEO is to minimize a certain function involving the parameters of h and l. The proposed method involves utilizing a feature extractor to generate classification weights for different tasks. Latent Embedding Optimization (LEO) avoids updating high-dimensional weights by learning a lower-dimensional latent space. Unlike AWGIM, LEO does not require inner updates to adapt the model. The framework includes a feature extractor processing images into d-dimensional vectors, with contextual and attentive paths for encoding task context and query samples. The proposed method involves utilizing a feature extractor to generate classification weights for different tasks. The encoding process includes two paths, the contextual path and attentive path, which aim at learning representations for the support set. Existing weight generation methods may be sub-optimal as they rely solely on the support set for classification weights. The proposed method introduces an attentive path to address the issue of lack of adaptation in classification weights for different query samples. A new multi-head self-attention network is employed to encode global task information, different from the contextual path. The cross attention network is then applied to produce X ap. The proposed method utilizes multi-head attention to learn comprehensive representations from different subspaces. Query samples have their own latent representations for support set, generating specific classification weights. These weights follow a Gaussian distribution with diagonal covariance, sampled during meta-training. The mean value on K classification is computed to reduce complexity. The method uses multi-head attention to learn representations from different subspaces. Specific classification weights are generated for query samples, following a Gaussian distribution with diagonal covariance. The mean value on K classification weights is computed to simplify the process. The method utilizes multi-head attention to learn representations from various subspaces and generates query-specific classification weights. However, the generated weights are not sensitive to different query samples, indicating a limitation in retaining information from the attentive path. To address this, the proposal is to maximize mutual information between the generated weights and support/query data. This involves using Variational Information Maximization to approximate true posterior distributions and compute a lower bound. The method aims to maximize mutual information between generated weights and support/query data by using Variational Information Maximization to approximate true posterior distributions and compute a lower bound. The objective function involves maximizing log likelihood of labels for support and query data, minimizing cross entropy, and reconstructing data with L2 loss. Hyper-parameters \u03bb1, \u03bb2, \u03bb3 are used for trade-off. The method involves maximizing mutual information between generated weights and support/query data using Variational Information Maximization. It computes a lower bound by approximating true posterior distributions. The objective function includes maximizing log likelihood of labels, minimizing cross entropy, and reconstructing data with L2 loss. Hyper-parameters \u03bb1, \u03bb2, \u03bb3 are used for trade-off of different terms. The encoding process in contextual path results in computational complexity O((N K) 2), while the computational complexity of attentive path is O((N K) 2 + |Q|(N K)). The method avoids inner updates and can be seen as a more general approach compared to LEO. The empirical evaluation includes experiments on miniImageNet and tieredImageNet datasets, comparing with other methods. miniImageNet has 100 classes with 600 images each, while tieredImageNet has 608 classes and 779,165 images. Image features from LEO are used, which trained a 28-layer Wide Residual Network. The authors trained a 28-layer Wide Residual Network on the meta-training set, representing each image with a 640-dimensional vector. They conducted N-way K-shot experiments, training 5-way 1-shot and 5-shot models on two datasets. During meta-testing, 600 N-way K-shot tasks were sampled, and the average accuracy for the query set was reported. TensorFlow was used to implement the method, with specific parameters set for feature embeddings, attention module, and MLPs. The code will be made available for further reference. The authors trained a 28-layer Wide Residual Network on the meta-training set, representing each image with a 640-dimensional vector. They conducted N-way K-shot experiments, training 5-way 1-shot and 5-shot models on two datasets. During meta-testing, 600 N-way K-shot tasks were sampled, and the average accuracy for the query set was reported. TensorFlow was used to implement the method, with specific parameters set for feature embeddings, attention module, and MLPs. The code will be made available for further reference. In a comparison with other approaches on tieredImageNet, the AWGIM model achieved the highest accuracy. MetaOptNet Resnets (2017) is optimized with weight decay 1 \u00d7 10 \u22126 and initial learning rates of 0.0002 for 5-way 1-shot and 0.001 for 5-way 5-shot. The model is trained for 50,000 iterations with batch sizes of 64 and 32 respectively. The approach AWGIM is compared with state-of-the-art methods on miniImageNet and tieredImageNet datasets. The results are shown in Table 1 and 2, with the backbone network structure provided for reference. The top half of Table 1 and 2 categorizes meta learning methods, while the bottom part compares classification weights generation approaches including AWGIM. AWGIM outperforms all methods in the top parts and shows competitive performance in the bottom part. A detailed analysis of AWGIM is provided in Table 3, showcasing its superiority over LEO in all settings. In Table 3, a detailed analysis of AWGIM is presented, comparing it with LEO. Different generators are studied, with results showing that self-attention performs similarly to relation networks. The impact of attention is explored by replacing attention modules with MLPs, demonstrating that even without attention, performance is maintained. In the study, the importance of maximizing information in MLP encoding for query samples is highlighted. Ablation analysis was conducted by varying \u03bb 1 , \u03bb 2, and \u03bb 3, showing that maximizing mutual information between weights and support is crucial for accuracy. The impact of classification on support and reconstruction was also investigated, with \u03bb 1 = 0 significantly affecting performance, indicating the importance of support label prediction for information maximization. In the study, the importance of maximizing information in MLP encoding for query samples is highlighted. Ablation analysis showed that maximizing mutual information between weights and support is crucial for accuracy. The impact of classification on support and reconstruction was investigated, with \u03bb1 = 0 significantly affecting performance, indicating the importance of support label prediction for information maximization. The classification weights in AWGIM are generated specifically for each query sample, with results showing that shuffling weights between query samples within the same classes and between different classes affects accuracy in 5-way 1-shot experiments. In this work, Attentive Weights Generation via Information Maximization (AWGIM) is introduced for few-shot image classification. AWGIM learns to generate optimal classification weights for each query sample by maximizing the mutual information between generated weights and query, support data. This is the first work to utilize mutual information techniques for few-shot learning. The effectiveness of AWGIM is demonstrated through state-of-the-art performance on benchmark datasets. The attentive path is instantiated by attention in a multi-head setting. AWGIM introduces a method for few-shot image classification by maximizing mutual information between generated weights and query, support data. The attentive path utilizes attention in a multi-head setting, with a focus on few-shot regression tasks. During meta-training, the number of classes is set to 1, adapting cross entropy loss to mean square error. The model generates weight and bias parameters for a three-layer MLP with a hidden dimension of 40, consistent with few-shot regression experimental settings. The study compares AWGIM with LEO in terms of convergence speed and performance in few-shot regression tasks using single-head attention. AWGIM shows faster convergence and outperforms LEO, except in the initial iterations, with minimal computational overhead. The study compares AWGIM with LEO in few-shot regression tasks using single-head attention. AWGIM shows faster convergence and outperforms LEO with minimal computational overhead. Self-attention and cross attention in AWGIM have negligible overhead compared to MLP encoding due to small values of N, K, and |Q|. Visualization of classification weights using t-SNE shows decoded weights for each class. The study compares AWGIM with LEO in few-shot regression tasks using single-head attention. AWGIM shows faster convergence and outperforms LEO with minimal computational overhead. Visualization of classification weights using t-SNE shows decoded weights for each class in (c) are clustered closer than (a) in general. Blue and red dots in (b, d) denote the classification weights for two query samples from two classes within one task. g can generate adapted weights for different query samples, consistent with distinct classification weights for query samples from different classes."
}