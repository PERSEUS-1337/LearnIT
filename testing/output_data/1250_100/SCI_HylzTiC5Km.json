{
    "title": "HylzTiC5Km",
    "content": "The Subscale Pixel Network (SPN) is proposed as a conditional decoder architecture for generating high fidelity images. It addresses challenges in encoding vast context and preserving global coherence and detail exactness. SPN generates images as a sequence of slices, capturing spatial dependencies efficiently. Multidimensional upscaling is used to grow images in size and depth. SPNs achieve state-of-the-art likelihood results in generating CelebAHQ and ImageNet images. The Subscale Pixel Network (SPN) generates high fidelity images by addressing challenges in encoding vast context and preserving global coherence. It achieves state-of-the-art likelihood results in multiple settings and sets new benchmark results in previously unexplored settings. The Autoregressive (AR) models have excelled in producing high-fidelity samples across various domains, but struggle with long-range structure and semantic coherence in large-scale image generation. The relationship between maximum likelihood estimation (MLE) scores and sample fidelity poses challenges in achieving both aspects simultaneously. The challenges in large-scale image generation arise from the high dimensionality of images and the need for architectural connections to learn dependencies. Multidimensional upscaling techniques are used to map subimages to target resolutions, ensuring model fidelity and generalization. The challenges in large-scale image generation arise from the high dimensionality of images. To address this, the model aims to learn the full distribution over 8-bit RGB images up to 256 \u00d7 256 size with high fidelity. Two visually salient subsets are identified: sub-images of smaller size and the most significant bits of each RGB channel. Multidimensional upscaling is used to map between these subsets, training three networks for the process. The Subscale Pixel Network (SPN) architecture addresses difficulties in training decoders for generating large, high-depth images from small, low-depth image slices. It divides images into sub-images and uses two networks to predict target slices, enabling implicit size upscaling. SPN acts independently as an image decoder with an implicit size upscaling mechanism. The Subscale Pixel Network (SPN) is an independent image decoder with an implicit size upscaling mechanism. It can also be used as an explicit size upscaling network by initializing the first slice of the SPN input separately. The performance of SPN and upscaling methods is evaluated quantitatively and from a fidelity perspective on CelebAHQ-256 and ImageNet benchmarks. State-of-the-art results are achieved on CelebAHQ-256 and ImageNet-64, with successful samples produced on ImageNet-128. The Subscale Pixel Network (SPN) produces successful samples on unconditional ImageNet-128, showcasing the impact of SPN and multidimensional upscaling on sample quality. A standard AR image model like PixelCNN generates a color image pixel by pixel, with conditional distributions parametrized by a deep neural network. An alternative ordering divides large images into slices, enabling compact encoding of long-range dependencies and inducing spatial structure with a size upscaling effect. The Subscale Pixel Network (SPN) utilizes subsampled slices with implicit size upscaling. The ordering divides images into smaller slices for consistent application of the decoder. The subscale ordering captures size upscaling implicitly through multidimensional upscaling. The Subscale Pixel Network (SPN) utilizes subsampled slices with implicit size upscaling. It can act as a full-blown image model and a size upscaling model simultaneously. Another formulation is the Parallel Multi-Scale BID12 ordering, where pixels are doubled at every stage by distinct neural networks in parallel. Multidimensional upscaling applies to the height, width, and channel depth of the image in stages. Depth upscaling in the Subscale Pixel Network is performed in stages, with each network generating the most significant bits of an image sequentially. Lower significance bits are only generated once all more significant bits have been generated. We do not share weights among networks at different stages. The goal is to focus on visually salient bits of an image. The Subscale Pixel Network (SPN) addresses challenges in modeling large images by embodying subscale ordering and generating image bits sequentially. It avoids superlinear computation and memory requirements of existing approaches, focusing on visually salient bits without sharing weights among stages. The Subscale Pixel Network (SPN) uses a scaling factor to obtain slices of the original image, maintaining a constant size of 32x32. The architecture consists of an embedding part for preceding slices to condition the decoder for the current slice being generated. Empty padding slices are used to preserve relative meta-positions of each preceding slice with respect to the current target slice. The Subscale Pixel Network (SPN) utilizes padding slices to maintain meta-positions of preceding slices in the input. The embedding architecture achieves equivariance with respect to slice offsets and includes meta-position and pixel intensity embeddings. The decoder processes the target slice in raster-scan order using a hybrid architecture of masked convolution and self-attention. The Subscale Pixel Network (SPN) utilizes padding slices to maintain meta-positions of preceding slices in the input. The slice is reshaped into a 1D tensor before input to masked 1D self-attention layers, with masking over previous pixels only. The output is concatenated with the slice embedding network and given to a Gated PixelCNN. Memory requirements are significantly lower due to smaller spatial size of slices. The log-likelihood decomposes as a sum over slices, with an unbiased estimator obtained by sampling a target slice conditioned on previous slices. The Subscale Pixel Network (SPN) uses padding slices to maintain meta-positions of preceding slices in the input. It performs maximum likelihood learning through stochastic gradient descent on a Monte Carlo estimate. The SPN can upscale image depth by dividing the image into slices and concatenating them along the channel dimension. This allows for modeling with low bit data. The Subscale Pixel Network (SPN) is a normal SPN trained on low bit depth data, capable of producing high fidelity samples at high resolution. It outperforms the Glow model BID7 and improves MLE scores, with state-of-the-art log-likelihoods on high-resolution ImageNet images. The network operates on small images and can train large networks with multiple convolutional and self-attention layers. The masked decoder consists of a PixelCNN with 15 layers, and the 1D Transformer in the decoder has 8-10 layers. See Table 4 for dataset-specific hyperparameter details. The hybrid decoder alone performs well on 32 \u00d7 32 and 64 \u00d7 64 Downsampled ImageNet, achieving state-of-the-art log-likelihoods. SPN improves log-likelihood over other models on 128 \u00d7 128 ImageNet, with significant gains in the 5-bit setting. The study shows improved performance in generating high-fidelity samples of celebrity faces from the CelebAHQ dataset at 256 \u00d7 256 resolution. The samples exhibit semantic coherence and success rates are increased with multidimensional upscaling. The achieved MLE scores are significantly better than previous reports, and the quality of the samples compares favorably to other models like Glow and GANs. The SPN and Multidimensional Upscaling model achieves state-of-the-art MLE scores on large-scale images like CelebAHQ-256 and ImageNet-128. It generates high fidelity 8-bit samples without altering the sampling process, showing semantic coherence and exactness of details. Experiments involve large-scale compute and network sizes. The SPN architecture uses large batch sizes achieved through data parallelism on Google Cloud TPU pods. Different tensorcores are used based on the dataset, with architectures having between \u223c50M and \u223c250M parameters. Depth-upscaling doubles parameters, while sizeupscaling adds more for a separate decoder-only network. The SPN architecture utilizes large batch sizes on Google Cloud TPU pods with varying parameter counts. In the multidimensional upscaling setting for ImageNet 128, the total parameter count can reach approximately 650M, with the decoder-only network for the first slice containing around 150M parameters."
}