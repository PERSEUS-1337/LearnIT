{
    "title": "rygDeZqap7",
    "content": "Natural language understanding research has shifted towards complex Machine Learning and Deep Learning algorithms, which often outperform simpler models. To address the challenge of limited labeled data availability, a methodology for extending training datasets and training data-hungry models using weak supervision is proposed. This approach is applied to biomedical relation extraction, a task crucial for drug discovery but costly to create datasets for. Small-scale experiments show consistent performance enhancements of an LSTM network using this method, comparable to hand-labeled data. The methodology discusses the optimal setting for applying weak supervision in the biomedical field, where the abundance of scientific papers contains valuable but unstructured information. Automating Information Extraction from biomedical abstracts is crucial for tasks like drug design and adverse drug effect detection. Efforts have been made to automate this process due to the labor-intensive nature of manual annotation. The focus is on extracting semantic triples related to Regulations (CPR) and Chemically Induced Diseases (CID) to aid in drug design and safety. This structured information extraction is essential for filtering and selecting chemical substances with specific properties efficiently. The focus of Disease BioCreative V -CDR Disease (CID) is on extracting semantic triples through relation extraction. To address the labor-intensive process of annotating training datasets, a new methodology based on weak supervision is proposed. This methodology involves training multiple base learners on a small labeled dataset, using them to predict labels for a larger unlabeled dataset, deriving weak labels for the unlabeled set using a denoiser, and finally training a strong meta-learner using weak labels. The methodology proposed involves training base learners on a small labeled dataset, using them to predict labels for a larger unlabeled dataset, deriving weak labels using a denoiser, and training a strong meta-learner with weak supervision. Key contributions include a detailed methodology for relation extraction, effectiveness demonstrated in a controlled experiment, and investigation of denoising methods' impact on system behavior. The related literature discusses information extraction, relation extraction from biomedical text, and semi-supervised and ensemble learning methods. Fully-supervised methods require manual annotation of labeled examples, while semi-supervised methods like bootstrapping leverage both labeled and unlabeled data. Bootstrapping algorithms like DIRPE, KnowItAll, and TextRunner extract patterns from seed examples to find new positive examples. Distant supervision generates weak labels for relation extraction using Knowledge Bases instead of pre-trained classifiers. This approach benefits from large-scale datasets without human annotation. Our work focuses on weakly-labeled datasets for biomedical relation extraction, complementing distant supervision methods. BioCreative competitions drive research in this area, with BioCreative V focusing on Chemically-induced Diseases at a document-level and BioCreative VI on relations between Chemicals and Proteins at a sentence level. Various algorithms, including ensemble models and Support Vector Machines, have been successful in these tasks. Our work aims to combine ensemble methods with semi-supervised learning to improve generalization in Machine Learning models. Ensembles reduce high variance by combining multiple learners, while semi-supervised learning utilizes unlabeled data for better generalization. The combination of these techniques has not been thoroughly studied but shows potential benefits. Ensembles can enhance semi-supervised learning by providing multiple views, allowing the system to perform better with less data. Co-training, a system where two learning algorithms take advantage of unlabeled data, has shown success in real-world settings. Recent work incorporates co-training to reduce noise and improve accuracy in functional genomics without using manually labeled data. Tri-training extends co-training to three learners for improved labeling agreement. In this work, an extension of co-training to three learners is described. The methodology involves two learners agreeing on the label of a new data point and then teaching the third learner using this example. Additionally, Co-forest BID18 extends this concept to include even more learners, with an ensemble system making decisions on re-training using all learners. The base learners in the ensemble system are not used for final predictions, only for generating weak labels. This approach allows for the use of all unlabeled data, unlike previous paradigms that only used a few examples with high confidence labels for re-training. This work is complementary to research on learning language representations and tuning them for specific machine learning tasks using a small labeled set. Weak supervision and data programming are key methodologies influencing the development of the methodology described. Weak supervision involves training models with labels of questionable quality, while data programming focuses on creating training sets programmatically when ground-truth labels are unavailable. The process involves defining weak supervision sources, encoding them into Labeling Functions (LF), applying LFs to unlabeled data points to create a vote matrix, and denoising to derive weak labels close to the true labels using a probabilistic graphical Generative Model (GM). Data programming, as a denoiser, utilizes a probabilistic graphical Generative Model (GM) based on agreements and disagreements of Labeling Functions. It trains the GM without ground truth by maximizing the marginal log-likelihood of observed votes. The methodology proposes a noise-aware discriminative model using generated labels for training. This approach combines weak supervision and data programming for semi-supervised learning to leverage multiple learners. In contrast to scenarios without ground-truth labels, a gold-labeled training set (D B) is available but insufficient in size for training a complex model. Augmenting lower quality data is proposed using machine learning models of lower complexity as weak supervision sources. The approach involves training K base learners on task T to capture different views of the data in an ensemble learning scenario. To create multiple learners, varying hyperparameters and design choices are used in the relation extraction pipeline, resulting in 162 base learners. Key design choices include sentence pruning, sequential features up to tri-grams, and converting the corpus to a numerical representation. In the relation extraction pipeline, various machine learning algorithms are employed on a feature matrix created from the corpus. Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTMs, and CNNs are used as base learners. A subset of these learners is selected based on performance and diversity, with a threshold set to discard lower-performing classifiers. To enhance diversity in the ensemble, a performance threshold is set above random guessing but low enough to include less accurate classifiers. A similarity-based clustering method is used to select diverse classifiers, with a K-means clustering approach to identify representative base learners. The silhouette score coefficient helps determine the number of clusters and base learners. The selected base learners predict labels for a dataset, generating a binary prediction matrix. A denoiser is then used to refine the matrix into weak labels, utilizing a probabilistic Generative Model of data. In the process of reducing the vote matrix into weak labels, a Majority Vote denoiser and an Average Vote denoiser are considered. A discriminative model is used as a meta-learner, trading label quality for quantity during training. High-capacity models like Deep Neural Networks are employed as meta-learners to learn features from a larger, albeit noisy, training dataset. The experiments are conducted using Snorkel, a framework for relation extraction with data programming and weak supervision. In experiments using the BioCreative CHEMPROT and CDR datasets, the methodology involves creating gold-labeled datasets for training, validation, and testing. The original training and development sets are merged and shuffled to form the training, validation, and unlabeled datasets. This ensures no bias in document selection and uniform pre-processing steps for all documents. The text discusses the use of labeled datasets with manually annotated entities for training a meta-learner with weak supervision. SpaCy is used for text pre-processing tasks such as sentence splitting, tokenization, and dependency parsing. Snorkel is used for candidate extraction and mapping to ground-truth labels within the same sentence. Cross-sentence relations are not considered in this controlled approach. In the text, a relationship classifier is used to understand Natural Language by replacing entities with tokens for prediction. A bi-directional Long-Short Term Memory network is employed with random under-sampling and different hyperparameter settings. Research questions are formed to explore biomedical relations further. The text discusses research questions (RQ1 and RQ2) related to enhancing biomedical relation extraction using Machine Learning classifiers as weak supervision sources. The literature suggests that adding weakly labeled data can improve the performance of the meta-learner, with specific requirements for the accuracy and diversity of weak supervision sources. Machine Learning classifiers have not been used in this context before. The text explores the use of weak supervision sources in enhancing biomedical relation extraction. It raises questions about the diversity and size of base learners trained on the same dataset. Experiments are conducted to compare the performance of the meta-learner under different training setups. The optimal number of base learners is also discussed, with a trade-off between performance and diversity. The denoising component is crucial for increasing the number of Base Learners and benchmarking weak label performance. Different denoising methods are used to assess the quality of weak labels, which can be binary or marginal. An error analysis is conducted to understand the impact of weak labels on training and meta-learner performance. The study answers questions about using supervised machine learning classifiers as weak classifiers and the optimal settings for weak supervision. Base learners are selected based on a strategy outlined in the text, with experiments conducted to determine the optimal number of base learners for maximizing silhouette scores. The study evaluates the performance of Base Learners, weak labels produced by denoisers, and the meta-learner trained on weak labels. Training with weak labels shows improved performance compared to full supervision, especially when combined with ground-truth labels. Weak supervision can achieve comparable results to full supervision, with some cases even showing slightly better performance. However, these differences are not statistically significant due to high variance in meta-learner performance. The study shows that training with weak labels can improve performance compared to full supervision, especially when combined with ground-truth labels. Weak supervision can achieve comparable results to full supervision, with some cases even showing slightly better performance. However, the under-sampled training set size of the final learner in weak supervision was bigger, and a simple Majority Vote often outperformed the meta-learner. The learning curves of the meta-learner indicate that weak labels are meaningful and improve performance, but the F1 score on the training set is much higher than the test score, suggesting high variance. Additional training data are expected to improve the meta-learner's performance. The study discusses the performance of the meta-learner when trained with different types of weak labels. The F1 score varies depending on the number of base learners used, with Average Marginals generally yielding the best results. Generative Model marginals show improvement compared to Majority Vote weak labels in most cases. The study compares the performance of different weak labels for the meta-learner. Generative Model marginals outperform Majority Vote weak labels, except for one case. Marginal weak labels improve meta-learner performance compared to binary labels, with Generative Model marginals showing a U-shaped distribution. Average Marginals perform better than Majority Vote weak labels without hyperparameter tuning. The F1 score is not suitable for evaluating marginal weak labels. Training with marginal labels is like a regression problem, penalizing the model for inaccurate predictions. The predicted logits become more spread as training marginals become more uniform. In this section, the methodology is applied on the CPR task using labeled and unlabeled datasets from CHEMPROT documents. The performance of the meta-learner decreases with weakly labeled data, indicating issues with data quality. A class imbalance is observed in the outgoing citations dataset compared to the original. Using the t-SNE algorithm, it is confirmed that the new dataset is unsuitable for the task. Best practices for constructing appropriate unlabeled datasets are emphasized. Weak supervision can enhance the performance of complex models like deep neural networks by utilizing unlabeled data and multiple base learners. The methodology shifts human effort from hand-labeling to feature engineering and diverse learner construction, allowing for scalability in training datasets and consistent performance improvement. The unlabeled data must be from the same domain as labeled data for base learners to generalize effectively. This approach can be applied to similar tasks, reducing the need for manual labeling. The supervised learning paradigm can be enhanced by weak supervision, utilizing unlabeled data and multiple base learners. It shifts human effort from hand-labeling to feature engineering and diverse learner construction, allowing for scalability in training datasets and consistent performance improvement. Further exploration is needed to construct a large enough unlabeled dataset to improve metalearner performance and draw stronger conclusions. Collecting an appropriate unlabeled dataset is challenging, and semi-supervised algorithms should not take its existence for granted. It is crucial to consider a more suitable evaluation metric than the F1 score for weak label assessment. The absence of such a metric hinders direct conclusions from weak labels, necessitating an additional step of training the meta-learner. Exploring different approaches for the meta-learner and defining better selection methods for base learners are areas for further investigation. Additionally, examining how the system performs when base learners abstain from voting on uncertain examples could provide valuable insights. This could involve deleting votes near the classification boundary or setting a confidence threshold for abstaining from voting. These adjustments could significantly impact the overall performance of the generative model. The Generative Model could gain an advantage by setting a threshold for abstaining from voting, impacting its overall performance."
}