{
    "title": "r1l73iRqKm",
    "content": "In open-domain dialogue, intelligent agents struggle to incorporate knowledge into conversations. Existing models often rely on generic responses rather than recalled knowledge. To address this, a new dataset grounded in Wikipedia knowledge was created. Dialogue models were developed to retrieve, read, and generate responses based on this knowledge. These models performed well in discussing open-domain topics, paving the way for further advancements in AI research towards enabling humans to communicate effectively with machines. The goal of natural language research is for humans to communicate with machines. Machines need to master skills like language comprehension, memory retention, reasoning, and generating captivating responses. Current state-of-the-art models, such as sequence to sequence models, lack the ability to utilize memory and knowledge effectively. To have intelligent conversations, direct knowledge memory mechanisms need to be employed. This work focuses on open-domain dialogue where speakers engage in open-ended conversations on various topics. The curr_chunk discusses the design of Transformer Memory Networks for open-ended dialogue conversations. A dataset of human-human conversations was created using crowd-sourced workers, with topics connected to Wikipedia for knowledge retrieval. The goal is to improve text representations and sequence models for generating outputs in conversations. Our Transformer Memory Network architectures are designed to train a knowledgeable conversation agent by recalling and grounding knowledge from existing text. They are tested using automatic metrics and human evaluations, showing their ability to engage in knowledgeable conversations with humans. A new benchmark in ParlAI aims to encourage further improvements in this research direction. Many existing dialogue tasks do not explicitly study the use of knowledge, highlighting the importance of our approach. Our work focuses on investigating unstructured knowledge across a wide range of topics, potentially spanning all of Wikipedia. Unlike goal-directed dialogue systems that rely on API calls for knowledge access, we aim to train a conversation agent to recall and ground knowledge directly from text. This is crucial for engaging in knowledgeable conversations with humans, as demonstrated by our Transformer Memory Network architectures. The curr_chunk discusses the use of Memory Networks and Transformers in dialogue systems that incorporate unstructured knowledge from sources like Wikipedia. Unlike previous works that use structured knowledge bases, the focus here is on grounding dialogues directly from text. This approach aims to improve the conversational agent's ability to engage in knowledgeable conversations with humans. The curr_chunk introduces a dialogue setting where two participants engage in chitchat, with one playing the role of a knowledgeable expert (wizard) and the other as a curious learner (apprentice). The apprentice aims to delve deeply into a chosen topic while keeping the conversation engaging and fun. This setting is different from previous works that focus on structured knowledge bases, as it involves unstructured dialogue directly from text. The task involves a dialogue setting where one participant plays the role of a knowledgeable expert (wizard) and the other as a curious learner (apprentice). The wizard's goal is to inform their conversation partner about a chosen topic using information retrieved from Wikipedia. The conversation flow includes choosing a topic, engaging in dialogue, and crafting relevant replies based on observed knowledge. The conversation between a wizard and an apprentice involves the wizard choosing relevant knowledge from Wikipedia to respond to the apprentice's messages. The dialogue continues until one participant ends the chat, with topics ranging from commuting to Arnold Schwarzenegger. The goal is to eventually replace the human wizard with a learned agent in similar experiments. The wizard selects knowledge from Wikipedia to respond to the apprentice's messages. The retriever used is similar to the one in the Open-SQuAD dataset. The top articles are retrieved for the last two turns of dialogue and the original topic. The wizard can click on article titles to expand and select a relevant sentence for their response during data collection. The wizard uses knowledge from Wikipedia to respond to the apprentice's messages. Dialogue models are developed to replace the wizard, with access to Wikipedia for grounding conversations. Two classes of models are developed: retrieval models and generative models, both using knowledge to generate responses. The model uses dialogue context to generate responses, with a large knowledge base organized hierarchically. Information retrieval techniques are used to select candidates for response generation. The model uses dialogue context to generate responses by merging top articles into one query. Knowledge sentences are selected independently using an attention mechanism, and the output utterance for the next dialogue turn is predicted based on the hidden state derived from the memory attention process. The model encodes knowledge sentences and dialogue context with a Transformer, calculates input encoding using dot-product attention, and selects candidate responses using a separate Transformer. The model is trained to minimize cross-entropy loss and considers Two-stage and End-to-end versions. Both versions find the most relevant knowledge and allow the decoder to attend over both knowledge and dialogue when formulating responses. A beam search of 5 is employed to select the best response. The model utilizes a beam search of 5 for response selection and employs BPE encoding BID16. In the End-to-end version, a shared Transformer encoder encodes candidates and dialogue history, with attention prediction over memory. The model is trained to minimize negative log-likelihood and can add supervision for knowledge selection. The Two-stage version uses separately trained models for response selection. In the Two-stage version, two separately trained models are used for knowledge selection and utterance prediction. Knowledge dropout (K.D.) is employed to improve decoder performance by preventing the model from attending to knowledge during training. Experimental setups and results are described, focusing on the ability of models to select knowledge and perform dialogue tasks. The feasibility of predicting knowledge selected by human wizards is also assessed before tackling the full Wizard dialogue task. The study compares Transformers with various baselines for a two-stage architecture, showing that Transformers perform best when pretrained on a large dataset like Reddit. The best performing Transformer model is used for a generative Memory Network in dialogue generation tasks, evaluating models on knowledge selection and dialogue generation. Transformer Memory Networks are also applied, which attend over knowledge, with models evaluated using Recall@1 metric. The addition of knowledge improves all models, with Transformer Memory Networks showing significant performance improvements. Generative experiments comparing End-to-end and Two-stage models to baselines demonstrate the utilization of knowledge in response predictions, leading to substantial improvements in performance. The Two-stage model performs well with predicted knowledge, while the End-to-end model excels with gold knowledge. The End-to-end model benefits from additional knowledge selection supervision, improving performance on all metrics. Knowledge dropout also proves to be beneficial. The Two-stage model and End-to-end model show different strengths in handling knowledge. The Two-stage model performs well with predicted knowledge, while the End-to-end model excels with gold knowledge. Additionally, human evaluation of the models is conducted using crowd-sourced workers to assess engagingness and knowledge exhibited in conversations. The study collected 546 conversations with ratings from 464 workers, showing that retrieval models outperform generative models in human engagingness. Retrieval models with knowledge trend towards higher Wiki F1 scores, while generative models benefit significantly from knowledge use. Generative models convey more knowledge than retrieval models, especially on unseen data. In this work, dialogue agents are developed with large memory systems containing encyclopedic knowledge for engaging open-domain conversations. Transformer Memory Network models are used to retrieve and output responses. The Wizard of Wikipedia dataset is collected for training and evaluation, showing the effectiveness of the models in both automatic and human experiments. A new benchmark is introduced to encourage further exploration in this research direction. The curr_chunk discusses future research directions in knowledge-grounded dialogue systems, including bridging the gap between retrieval and generative models, simultaneous retrieval and reasoning, and the relationship with existing QA tasks. The dataset includes conversations between a wizard with access to an information retrieval system and an apprentice, with knowledge retrieval based on dialogue history. The dataset used in the study involves apprentices asking questions in 13.9% of training set utterances, answering questions 39.5% of the time, and making new statements 49.3% of the time. Conversations between the wizard and apprentice include various dialogue acts. The study utilized the Persona-Chat dataset to select natural topics, with \u223c1000 personas each describing interests. These personas were mapped to relevant Wikipedia pages, resulting in 1,431 topics for the task. The study utilized the Persona-Chat dataset to select natural topics, resulting in 1,431 topics for the task. Additional experiments were conducted to test the performance of the knowledge selection tasks and the retrieval system. Human-human conversations were found to be different from bot conversations, with humans engaging in more small talk and using the topic of discussion more effectively. The study compared human-human conversations with bot conversations, noting that humans engage in more small talk and use topics effectively. The models in the study attempted to produce more factual sentences, with some rounds showing humans treating the bot as a question-answer machine. The retriever without knowledge tended to go off-topic, while the retriever with knowledge stuck to the chosen topic but struggled if the human changed the subject. The study compared human-bot conversations, noting humans engage in small talk and use topics effectively. Best-performing model chose a knowledge sentence for dialogue retrieval, outperforming in F1 but not Recall@1. Two-stage retrieval system optimized for gold knowledge sentence improved performance. Human experiments showed knowledge produced similar but factually inaccurate answers. The model with knowledge in conversations exhibits fewer issues with repetition and can act as a selfish conversationalist. It sometimes produces inaccurate statements but generally provides accurate information. The generator with knowledge can generalize to unseen topics using information from Wikipedia, despite sometimes giving formulaic responses. Selected conversations with this generator can be found in Figure 5."
}