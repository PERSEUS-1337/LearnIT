{
    "title": "SJlgOjAqYQ",
    "content": "We conducted experiments to test global translation-invariance in deep learning models trained on the MNIST dataset. Both convolutional and capsules neural networks showed poor performance in this aspect, but data augmentation improved their performance. While the capsule network performed better on the MNIST testing dataset, the convolutional neural network generally had better translation-invariance performance. CNNs have achieved state-of-the-art performance in computer vision tasks due to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. CNNs need to learn different models for different viewpoints, requiring big data and high costs. Capsule networks aim for 'rate-coded' equivariance by encoding viewpoint-invariant knowledge in weights, not neural activities. Viewpoint changes in capsule networks have linear effects on pose matrices between layers. It is unclear if capsule networks can generalize for global translation invariance. Analyzing translation-sensitivity in deep learning models is crucial for understanding architectural choices and developing viewpoint-invariant models. A method to test global translation-invariance in convolutional and capsule neural networks trained on MNIST dataset is introduced. Global translational invariance (GTI) testing dataset for deep learning models trained on MNIST includes images generated by shifting the centre of mass of a digit. The dataset covers all possible cases of translational translations and is used to test the robustness of the models. Training is done on the MNIST dataset with 60000 samples and testing on both MNIST and GTI datasets. The GTI dataset distributes images uniformly on the canvas, unlike the MNIST dataset where images are located at the center. This method is robust against random noise and mislabeling compared to traditional translation-sensitivity maps. The CNN model used in the study has nine layers, including convolutional and fully connected layers with specific channel sizes and filter dimensions. Dropout is applied to certain layers, and ReLU is used as the activation function except for the last layer. The total number of parameters is significantly smaller compared to Capsule networks. The optimizer is Adam with default parameters, and the objective function is cross entropy loss. The CNN model in the study uses Adam optimizer with default parameters and cross entropy loss function. Results show high accuracy on MNIST testing set but low accuracy on GTI testing set due to global translational invariance issues. Images with digit's center predicted correctly, while those at corners are assigned incorrect classes. CNN is 'place-code' equivariant and struggles with shifts in GTI dataset. Training without data augmentation leads to poor performance. To improve CNN performance on the GTI dataset, data augmentation was done by shifting MNIST images from the center in x and y-direction. This increased accuracy on the GTI testing dataset to 98.05%. Capsule network performance on global invariance still needs improvement, as shown in the experiment. CapsNet has 8.2M parameters, much larger than CNN, and was trained with Adam optimizer and margin loss. Reconstruction loss was also added but scaled down. The CapsNet model trained on MNIST with data augmentation improves accuracy on the GTI dataset compared to the model without augmentation. However, CNN performance on the GTI dataset remains better than CapsNet, possibly due to differences in architecture. There is room for improvement in CapsNet's handling of translational invariance. A new GTI testing dataset was introduced for deep learning models trained on MNIST to further assess performance. The GTI testing dataset was created to evaluate CNN and CapsNet models' ability to handle global translational invariance. CapsNet architecture shows potential in dealing with this issue, but currently requires data augmentation. The testing method involves shifting images in the MNIST dataset to assess model accuracy. This approach can be easily implemented for other computer vision tasks."
}