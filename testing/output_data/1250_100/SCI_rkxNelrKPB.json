{
    "title": "rkxNelrKPB",
    "content": "Various gradient compression schemes have been proposed to reduce communication costs in distributed training of large-scale machine learning models. Sign-based methods, like signSGD, are gaining popularity due to their simplicity and connection to adaptive gradient methods. This paper presents a general analysis of sign-based methods for non-convex optimization, focusing on success probabilities without relying on specific noise distributions. The theory is extended to a distributed setting with a parameter server framework, showing exponential variance reduction with increasing nodes while maintaining 1-bit compression. Experimental validation of the theoretical findings is conducted. Deep learning models in industry use large datasets split across compute nodes for parallel processing. Stochastic gradient descent is a popular algorithm for optimization, where workers compute stochastic gradients that are aggregated at a master node. The aggregated vector is broadcast back to nodes for parameter updates. Communication of local gradients is essential in this distributed training setup. In distributed training setups for deep learning models, communication of local gradient estimators to the master node is a bottleneck. Various compression schemes have been proposed to reduce the communication load, with sign-based compression showing promising results. Biased compression schemes, such as those based on communicating signs of update entries only, have been found to perform better than unbiased schemes in some cases. Sign-based methods like signSGD and adaptive methods like ADAM are popular in deep learning optimization. While ADAM has convergence and generalization issues, it behaves similarly to a momentum version of signSGD. Investigating signSGD can improve our understanding of adaptive methods. The connection between sign-based and adaptive methods dates back to Rprop and RMSprop. The main contributions of this work are summarized in Table 1, highlighting the importance of bounded variance assumption in improving convergence. The entropy of probability distribution under the bounded variance assumption is bounded, while under the SPB assumption it could be arbitrarily large. Gaussian distribution has the maximum differential entropy for continuous random variables. Two methods for 1-node setup are studied for minimizing a smooth non-convex function. The key novelty is in relaxing requirements on the gradient estimator, allowing it to be biased with one additional weak assumption for convergence. The text discusses the necessity of assumptions in sign descent methods, the geometry of l1-l2 methods, complexity analysis of certain methods, and their application in distributed settings with sign-based compression. The text discusses the necessity of assumptions in sign descent methods, particularly focusing on the key assumption of Success Probability Bounds for gradient estimators in sign-based compression. This assumption plays a central role in the convergence of sign-based methods, emphasizing the importance of the sign of stochastic gradients in showing the true gradient direction. The text discusses the extension of theory to more general sign-based methods with a stochastic sign oracle, without the need for unbiasedness or uniform boundedness assumptions. It presents a counterexample to signSGD, showing how it can get stuck along a line despite the sign of stochastic gradients. In a counterexample to signSGD, the stochastic gradient sign is ineffective in a conic region, leading to low success probabilities and violating key assumptions. The stochastic gradient sign is ineffective in a conic region, leading to low success probabilities and violating key assumptions. The SPB assumption holds under general assumptions on gradient noise, with Lemmas providing conditions for unbiased estimators and bounded variances to ensure the assumption holds. An adaptive condition on mini-batch size is also given for the SPB assumption to hold. In this section, a norm-like function called \u03c1-norm is introduced, induced from success probabilities to measure gradients in convergence rates. The \u03c1-norm is a technical tool enabling analysis, defined as a weighted l1 norm with positive weights. It is not a norm under the SPB assumption, but is positive definite and can be lower bounded by a weighted l1 norm with positive constant weights. Additionally, it can be lower bounded by a mixture of the l1 and squared l2 norms, which are positive definite, continuous, and order preserving. The \u03c1-norm, induced from success probabilities, is introduced as a tool for measuring gradients in convergence rates. It is a weighted l1 norm with positive weights and can be lower bounded by a mixture of l1 and squared l2 norms. This norm is important for analyzing convergence rates under various assumptions and settings in optimization algorithms. The convergence result for Algorithm 1 under the general SPB assumption shows that signSGD with specific step sizes converges to a neighborhood of the solution for non-convex functions. This result is the first general one for signSGD without mini-batching and with step sizes independent of the total number of iterations K. The convergence rates can be slow depending on the probabilities \u03c1 i. The presence of the \u03c1-norm in the convergence rates of signSGD suggests that the geometry is induced from the success probabilities, supporting the practice of using a constant step size for a period of time and then halving it. The method will eventually converge if \u03c1 i > 1/2. Theorem 2 presents the convergence rate of Algorithm 1 with Option 2 under the SPB assumption. It shows that a small modification in the algorithm can improve convergence by removing the log-dependent factor. Option 2 is beneficial for derivative-free optimization when function evaluations are feasible. Additionally, the convergence result of distributed signSGD with majority vote is discussed within a parameter server framework. The convergence rate of distributed signSGD with majority vote is discussed under the SPB assumption. The algorithm involves receiving one sign from each node and sending back the majority sign. Convergence is shown with constant step sizes and variance reduction is achieved. The number of nodes involved in the distributed setting introduces a new norm, leading to exponential variance reduction. Theoretical analysis shows no difference between 2l\u22121 and 2l nodes in sign aggregation. Removing one node in a parameter server framework with odd nodes cancels out the little probability of voting failure. Experimental verification is done using MNIST dataset and Rosenbrock function. The Rosenbrock function minimization problem involves biased stochastic gradient descent. Increasing the number of nodes in distributed training improves convergence rate. The robustness of the SPB assumption in convergence rate is demonstrated with varying noise levels. SignSGD performance with variable step size is evaluated under different noise conditions. Figure 5 shows the performance of signSGD with variable step size under different noise levels using the Rosenbrock function. The plots illustrate the relationship between success probabilities and convergence rate. Oscillations are observed in low success probability regimes, while they are mitigated in high success probability regimes. The experiment varied the step size to detect divergence and observe convergence to the minimizer. Gauss's inequality on unimodal distributions is also mentioned. The text discusses the application of Gauss's inequality on unimodal and symmetric distributions to derive bounds on success probabilities. It also introduces a gradient estimator with mini-batch size \u03c4 and establishes success probability bounds in terms of mini-batch. The text presents methods for success probability bounds based on mini-batch size, with two lemmas for different randomness cases. Lemma 4 deals with i.i.d. random variables with non-zero mean and finite variance, while Lemma 5 considers variables with positive variance and finite 3rd central moment. The proof involves approximating i.i.d. random variables with normal distribution using the Central Limit Theorem and computing success probabilities with the error function erf. The Berry-Esseen inequality is applied to account for approximation errors, resulting in a better bound for high randomness but not optimal for low randomness. The Central Limit Theorem is used to approximate i.i.d. random variables with normal distribution, leading to a condition on mini-batch size for the SPB assumption to hold. The Berry-Esseen inequality is applied to compute success probabilities, with the error function erf used to show that the SPB assumption holds under certain conditions. The i-th component of \u011d k and L is the average value of L i's. Conditional expectation given current iteration x k yields success probabilities \u03c1 i. Convergence analysis shows Algorithm 1 does not increase function value in any iteration. The proof of Theorem 3 follows similar steps as Theorem 1, with Lemma 7 used in place of (16)-(19). The sum of stochastic signs aggregated from nodes is represented by g(M)(x), where success probability for coordinate i is denoted by \u03c1i > 1/2."
}