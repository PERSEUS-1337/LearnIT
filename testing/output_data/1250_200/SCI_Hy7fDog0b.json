{
    "title": "Hy7fDog0b",
    "content": "Generative models, like AmbientGAN, aim to model complex distributions using partial, noisy observations instead of fully-observed samples. This approach allows for the recovery of the true underlying distribution even with information loss. AmbientGAN shows significant improvements in training Generative Adversarial Networks (GANs) on benchmark datasets, achieving higher inception scores compared to baselines. The method involves passing the generator's output through a simulated random measurement function for the discriminator to distinguish between real and generated measurements. Generative models, such as AmbientGAN, train directly from noisy or incomplete samples to overcome the challenge of collecting enough data to start with. The approach involves using different types of measurements or projections to learn a generative model, with the discriminator distinguishing between real and simulated measurements. AmbientGAN is a generative model that uses measurements to distinguish between real and simulated data. It can construct good generative models from noisy observations and low-dimensional projections, as demonstrated on three datasets. The method shows qualitative visual quality and quantitative comparison to baseline methods. Theoretical results show that the distribution of measured images uniquely determines the distribution of original images in a noisy, blurred scenario. Incorporating measurement models into GAN training improves sample quality. Results on celebA dataset with occlusions and noisy, blurred images show significant enhancement in sample generation. Incorporating measurement models into GAN training improves sample quality on celebA dataset with occlusions and noisy, blurred images. Learning a GAN on images denoised by Wiener deconvolution leads to poor sample quality, while our models can produce cleaner samples. Additionally, learning a generative model on 2D images in the MNIST dataset from pairs of 1D projections shows that AmbientGAN recovers underlying structure effectively. There are two approaches to constructing neural network based implicit generative models: autoregressive and adversarial. The adversarial framework is powerful for modeling complex data distributions like images, videos, and 3D models. Generative models have various applications, such as solving inverse problems and translating images between domains. Training stability can be improved by operating generators and discriminators on different low-dimensional projections of the data. The work involves creating 3D object shapes from 2D projections using the AmbientGAN framework. Measurements are obtained from a real distribution through a stochastic measurement function f\u03b8. The distributions prx and p\u03b8 induce a distribution over the measurements y denoted by pry. The task involves creating an implicit generative model of a distribution prx using measurements obtained from a known distribution p\u03b8. By combining the measurement process with adversarial training, a generator G is trained to produce samples close to prx without direct access to the objects themselves. The main idea is to simulate random measurements on generated objects Xg using a discriminator to distinguish real from fake measurements. The AmbientGAN objective involves a quality function q(x) and requires differentiable functions for G and D. The model is trained using a gradient-based GAN approach by sampling Z, \u0398, and Yr in each iteration. The AmbientGAN learning framework is end-to-end differentiable and can be trained using a gradient-based GAN approach. It involves sampling Z, \u0398, and Yr in each iteration to compute stochastic gradients for the generator and discriminator. The approach is compatible with various GAN improvements and can incorporate additional information like per sample labels. The measurement models used are tailored for 2D images in theoretical and empirical results. The AmbientGAN learning framework is versatile and can be applied to different data formats and measurement models. For 2D images, various measurement models are considered, such as Block-Pixels, Convolve+Noise, Block-Patch, Keep-Patch, Extract-Patch, and Pad-Rotate-Project. Each model has specific ways of manipulating the image data for analysis. The PadRotate-Project-\u03b8 method involves rotating images by a random angle and padding to keep original pixels within boundaries. Gaussian-Projection projects onto a random Gaussian vector. The goal is to recover the true underlying distribution of data from observed measurements, ensuring consistency with the AmbientGAN training procedure. Lemma 5.1 provides a consistency guarantee with the AmbientGAN training procedure, assuming uniqueness of the true underlying distribution given the measurement distribution. Theorems following show this assumption holds under various measurement models, such as Gaussian-Projection and Convolve+Noise, allowing recovery of the true distribution with the AmbientGAN framework. Theorem 5.4 extends the consistency guarantee to a finite set of pixel values in images, providing a sample complexity result for learning distributions in the AmbientGAN framework. It states that with a dataset of IID measurement samples, an optimal generator must satisfy a certain condition with high probability. The experiments used three datasets: MNIST for handwritten digits and CelebA for face images. The experiments used three datasets: MNIST for handwritten digits, CelebA for face images of celebrities, and CIFAR-10 for images from 10 different classes. Various generative models were used for each dataset, with specific architectures and hyperparameters detailed in the appendix. The experiments used three datasets: MNIST for handwritten digits, CelebA for face images of celebrities, and CIFAR-10 for images from 10 different classes. For measurements with 2D outputs, the same discriminator architectures as in the original work were used. Fully connected discriminators were used for 1D projections. Baseline approaches were implemented to evaluate the AmbientGAN framework, including an \"ignore\" baseline and a stronger baseline based on invertible measurement functions. In the AmbientGAN setting, the baseline approaches include an \"ignore\" baseline and a stronger baseline using invertible measurement functions. Despite violations of assumptions, an approximate inverse function is used to train a generative model with estimated samples. For Block-Pixels measurements, blurring the image is a simple method to obtain an approximate inverse function. Inverse functions for various measurement models are discussed. For Block-Pixels measurements, blurring the image or using total variation inpainting can be used as an approximate inverse function. Wiener deconvolution is suggested for Convolve+Noise measurements. Navier Stokes based inpainting method is used for Block-Patch measurements. Inverting other measurement models is challenging, especially for Keep-Patch and Extract-Patch measurements. For Pad-Rotate-Project-\u03b8 measurements, conventional techniques like sampling angles are not readily applicable due to limited projections. Inverting Pad-Rotate-Project measurements is challenging due to limited information about \u03b8. Results with AmbientGAN models are reported on a subset of experiments, showing samples generated by baselines and our models. Samples are provided for selected parameter settings, with more results in the appendix. Results on MNIST are deferred to the appendix. Samples on celebA with DCGAN and CIFAR-10 with ACW-GANGP show degradation in the measurement process, making it difficult for baselines to produce good samples. Our models, however, are able to generate images with good visual quality. Our models are able to create coherent faces by observing only parts of one image at a time, while other measurement models exhibit drastic signal degradation. The second measurement model produces upright digits, showing that the model prefers consistent orientation per class. Our method demonstrates the ability to generate images of digits using only 1D projections, with a focus on consistent orientation per class. The model trained on celebA dataset shows a crude outline of a face but lacks details, indicating the challenge of learning complex distributions with 1D projections. Inception scores are used to evaluate the quality of generative models in the AmbientGAN framework, with a high test set accuracy achieved on the MNIST dataset. On MNIST, a classification model with two conv+pool layers and two fully connected layers achieved a final test set accuracy of 99.2%. Different models were trained with varying probabilities of blocking pixels, showing that AmbientGAN models outperformed baselines as pixel blocking increased. For Convolve+Noise measurements on MNIST, increasing noise levels caused baseline models to deteriorate in performance. The AmbientGAN models outperform baselines as noise levels increase, maintaining high inception scores. Different measurement models show varying performance, with the Pad-Rotate-Project-\u03b8 model achieving an inception score of 8.12. Total variation inpainting method is slow and performs similarly to unmeasured-blur baseline on MNIST. The total variation inpainting method is slow and performs similarly to the unmeasured-blur baseline on MNIST. In the CIFAR-10 dataset, the trend shows the superiority of our approach over baselines, as seen in the plots. Generative models require a high-quality dataset, but we propose learning from incomplete, noisy measurements to construct new models. Assuming a unique probability distribution can match all 1D marginals obtained with Gaussian projection measurements, the Convolve+Noise measurement model is considered. The Fourier transform and support of a function are denoted, with the proposal to learn from incomplete, noisy measurements for constructing new models. The Convolve+Noise measurement model involves unique distributions to induce measurement distributions. The Fourier transform relates the probability density functions of X and Z through a bijective, differentiable function. The pdf of Y is a convolution of individual pdfs, with a relation expressed through Fourier transforms. The reverse map from the measurement distribution to the sample distribution uniquely determines the true underlying distribution. The empirical version of the vanilla GAN objective is defined for a dataset of measurement samples, with optimal discriminator and generator conditions specified. The empirical risk minimization version of the loss is equivalent to taking the expectation of the data-dependent term with respect to the empirical distribution. If each image pixel takes values in a finite set P, then there is a unique distribution p if p < 1 in the Block-Pixels measurement model. The distribution over measurements p y can be written in terms of p x and the transition matrix A if the matrix A is invertible. The distribution over measurements p y can be written in terms of p x and A if the matrix A is invertible. The sample complexity is determined by the minimum eigenvalue of A. For Block-Pixels measurement, images are divided into classes based on the number of zero pixels. The transition matrix A ensures that images with i pixels must have at least j \u2265 i zero pixels after measurement. The transition matrix A for Block-Pixels measurement is lower triangular, with diagonal entries being strictly positive and minimum value of (1 \u2212 p) n. This proves A is invertible, with the smallest eigenvalue being (1 \u2212 p) n. The DCGAN model on MNIST follows a specific architecture with a noise input of 100 dimensions sampled from a Uniform distribution on [\u22121, 1]. The DCGAN model on MNIST and the WGANGP model on MNIST have different architectures. The DCGAN model uses a noise input of 100 dimensions sampled from a Uniform distribution on [\u22121, 1], while the WGANGP model uses a latent vector of 128 dimensions with coordinates sampled from the same distribution. Batch-norm is used in both models, except in the discriminator of the WGANGP model. The unconditional DCGAN model on celebA has a latent vector of 100 dimensions with coordinates sampled from a Uniform distribution on [\u22121, 1]. The ACWGANGP model on CIFAR-10 follows a residual architecture with a latent vector of 128 dimensions sampled from a standard Gaussian distribution. The generator consists of a linear layer followed by three residual blocks, while the discriminator includes one residual block and three residual blocks. The measurement models assume known parametric forms and distributions for simulating the stochastic measurement process. The study explores the robustness of the AmbientGAN approach to parameter distribution mismatches in the measurement function. Using the Block-Pixels measurement model on the MNIST dataset, the experiment shows that the method is somewhat resilient to such mismatches, as evidenced by the inception score peaking at a blocking probability of 0.5. The study demonstrates the robustness of the AmbientGAN approach to parameter distribution mismatches in the measurement function. The generator learned through AmbientGAN captures the data distribution well, showing improvement in sensing over sparsity-based approaches. Using the AmbientGAN trained with corrupted samples for compressed sensing, a reduction in the number of measurements is observed compared to a regular GAN trained with fully observed samples."
}