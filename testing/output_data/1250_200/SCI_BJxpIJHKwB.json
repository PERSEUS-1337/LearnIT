{
    "title": "BJxpIJHKwB",
    "content": "Few shot image classification involves learning a classifier from limited labeled data. Attentive Weights Generation for few shot learning via Information Maximization (AWGIM) addresses the challenge of generating exact and universal classification weights for diverse query samples with very few training samples. AWGIM generates different classification weights for each query sample by allowing them to attend to the entire support set. By maximizing the lower bound of mutual information between generated weights and query as well as support data, AWGIM achieves state-of-the-art performance on benchmark datasets. Meta learning is a popular approach for few shot learning, allowing models to quickly adapt to new tasks by extracting high-level knowledge across different tasks. This approach is promising for deep learning methods that require large amounts of labeled data. In this work, Attentive Weights Generation for few shot learning via Information Maximization (AWGIM) is introduced to address limitations in weights generation methods for few shot learning. AWGIM generates classification weights specifically for each query sample by utilizing two encoding paths where the query sample attends to the task context. Simple cross attention between query samples and support set is shown to be insufficient in guaranteeing classification weights fitted to diverse query data. AWGIM proposes maximizing mutual information between generated weights and query, support data to address limitations in weights generation for few shot learning. It introduces Variational Information Maximization and eliminates inner updates without compromising performance. AWGIM achieves state-of-the-art performance on benchmark datasets and undergoes detailed analysis to validate its components. Previous works in few shot learning focus on meta learning and gradient-based approaches for optimal task initialization. In gradient-based approaches, optimal task initialization is learned. Meta-learning LSTM is used to optimize few-shot classification tasks. Metric-based methods focus on learning similarity metrics between query and support samples. Some works consider spatial information and local image descriptors for richer similarities. Generating classification weights directly is explored, with methods like linear combinations and using trained feature extractor activations. Graph neural network denoising autoencoders are also utilized. Fast weights generation is proposed in some works. In the context of few-shot classification, various methods have been explored, including generative models for data augmentation, closed-form solutions for classification, and attention mechanisms for encoding task and query information. Self attention and cross attention are utilized to model interactions between queries and context. In this work, attention is used for few-shot image classification by maximizing mutual information. Mutual information measures the decrease of uncertainty in one random variable when another is known. It has been widely applied in various applications such as Generative Adversarial Networks and self-supervised learning. In this work, attention is utilized for few-shot image classification by maximizing mutual information. The proposed model includes an attentive path and a weight generator to predict class labels and reconstruct inputs. The problem is formulated under episodic training paradigm, following popular meta-learning methods. Our proposed approach follows the episodic training paradigm for few-shot classification, where a N-way K-shot task includes support and query sets. The meta-loss is estimated on the query set during meta-training to optimize the model, while performance is evaluated on the query set during meta-testing. The model learns transferable knowledge across tasks and quickly adapts to novel tasks by generating classification weights for different tasks using a feature extractor and meta-learner. The feature extractor outputs image embeddings, and the meta-learner generates classification weights for tasks. Latent Embedding Optimization (LEO) is a method related to this work, where a latent code z is generated by h conditioned on the support set S. Classification weights w are decoded from z with l. LEO updates the latent code z to generate new classification weights w without inner updates. The proposed method involves a feature extractor processing images for tasks, with two paths for encoding task context and query samples. Generated classification weights are used for label prediction. The key difference from Latent Embedding Optimization (LEO) is that the model does not require inner updates to adapt. The proposed method involves two paths for encoding task context and query samples. The contextual path learns representations for the support set, while the attentive path addresses the issue of sub-optimal classification weights by adapting to different query samples. The proposed method involves two paths for encoding task context and query samples. The attentive path introduces adaptive classification weights by utilizing a multi-head self-attention network on the support set to generate task-aware weights for different query samples. This approach differs from the contextual path, which focuses on generating classification weights. The cross attention network is then applied to each query sample and task-aware support set to produce representations. The method involves two paths for encoding task context and query samples. Multi-head attention is used to learn comprehensive representations from different subspaces. The tensors are concatenated to generate specific classification weights, which are task-aware and adaptive to individual query samples. Classification weights follow a Gaussian distribution, and are sampled from a learned distribution during meta-training. The method utilizes Gaussian distribution with diagonal covariance to sample classification weights for query samples. The prediction for query data is computed using the generated weights. Additionally, two decoders reconstruct support data based on the generated weights. The use of reconstruction as auxiliary tasks is discussed. The analysis focuses on one query sample without loss of generality. The method samples classification weights for query samples using Gaussian distribution with diagonal covariance. It is observed that the generated classification weights are not sensitive to different query samples, indicating a limitation in information retention from the attentive path. To address this, the proposal is to maximize mutual information between generated weights and support/query data. Directly computing mutual information is intractable due to unknown posterior distributions. The method proposes to maximize mutual information between generated weights and support/query data by using Variational Information Maximization. This involves approximating the true posterior distributions and maximizing a lower bound as a proxy for the true mutual information. The objective function includes terms for maximizing log likelihood of labels and minimizing cross entropy between prediction and ground-truth. Gaussian distributions are assumed for the posterior distributions. The proposed method aims to maximize mutual information between generated weights and support/query data using Variational Information Maximization. It involves approximating posterior distributions and maximizing a lower bound as a proxy for true mutual information. The loss function for training the network involves reconstructing x cp and x ap with L2 loss, with hyper-parameters \u03bb 1 , \u03bb 2 , \u03bb 3 for trade-off. The method forces the generated classification weights to carry information about support data and specific query samples, unlike in LEO where weight generation does not involve specific query samples. The proposed method involves maximizing mutual information between generated weights and support/query data using Variational Information Maximization. It reduces computational complexity through contextual and attentive paths, resulting in negligible overhead. Empirical evaluation on miniImageNet and tieredImageNet datasets shows improved performance without compromising training and inference time. The miniImageNet dataset contains 100 classes with 600 images each, while tieredImageNet has 608 classes and 779,165 images. Image features from LEO are used, with a 640 dimensional vector as input. N-way K-shot experiments are conducted, with 5-way 1-shot and 5-shot models trained on both datasets. During meta-testing, 600 N-way K-shot tasks are sampled. The study involves training 5-way 1-shot and 5-shot models on two datasets using TensorFlow. Meta-testing includes sampling 600 N-way K-shot tasks, with results compared to previous works. Various models like Prototypical Nets and Relation Nets are evaluated for accuracy on different datasets. Table 2 shows the accuracy comparison of different approaches on tieredImageNet, with results averaged on 600 tasks from the meta-testing set. Best results are highlighted, and models like MAML, Prototypical Nets, and Relation Nets are evaluated for accuracy on different datasets. MetaOptNet Resnets (2017) is used for network optimization with specific parameters for training iterations and batch size. The model is trained on meta-training and meta-validation sets with fixed hyper-parameters. Performance comparison with state-of-the-art methods on two datasets is conducted. Results on miniImageNet and tieredImageNet are shown in Tables 1 and 2, respectively, categorizing methods into metric-based and gradient-based approaches. The top half of Tables 1 and 2 categorizes methods into different meta learning categories such as metric-based, gradient-based, and graph-based. The bottom part shows classification weights generation approaches including Dynamic, Prediction, DAE-GNN, LEO, and AWGIM. AWGIM outperforms all methods in the top parts of the tables and shows competitive performance in the bottom part. A detailed analysis of AWGIM is provided in Table 3, comparing it with LEO and conducting ablation analysis on different components. Random shuffling of generated classification weights demonstrates their optimality for different query samples. In Table 3, a detailed analysis of AWGIM is conducted, comparing it with LEO and exploring the impact of different components. The study includes the effects of attentive path and the use of generators conditioned on support sets. Results show that self-attention is comparable to relation networks in LEO. By incorporating information maximization, the generator in AWGIM achieves slightly better performance than LEO. Additionally, replacing attention modules with 2-layer MLPs, labeled as \"MLP encoding,\" is investigated. Replacing attention modules with 2-layer MLPs, known as \"MLP encoding,\" shows promising results even without attention. However, setting \u03bb 1 = \u03bb 2 = \u03bb 3 = 0 for MLP encoding leads to a significant drop in performance, highlighting the importance of information maximization. Ablation analysis on \u03bb 1, \u03bb 2, and \u03bb 3 reveals the crucial role of maximizing mutual information between weights and support. Notably, \u03bb 1 = 0 noticeably affects performance, emphasizing the importance of classification on support and reconstruction. The study investigates the impact of classification weights on support and reconstruction in AWGIM. Shuffling weights between query samples within and between classes shows that weights for query samples from the same class are similar, while distinct for different classes. Random shuffling between classes degrades accuracy, indicating the importance of generated weights for query samples. In this work, Attentive Weights Generation via Information Maximization (AWGIM) is introduced for few-shot image classification. AWGIM learns to generate optimal classification weights for each query sample by maximizing the mutual information between generated weights and query, support data. This approach is the first to utilize mutual information techniques for few-shot learning and has shown effectiveness in state-of-the-art results. AWGIM is the first to use mutual information techniques for few-shot learning, achieving state-of-the-art performance on benchmark datasets. The multi-head attention model encodes global task information to support samples through self-attention networks. Classification weights are generated following a Gaussian distribution during meta-training. The classification weights follow Gaussian distribution with diagonal covariance and are sampled during meta-training. Few shot regression tasks are modified by setting N=1 and using mean square error. The model generates weight and bias parameters for a three-layer MLP with hidden dimension 40. Sinusoidal and linear regression tasks are constructed, with multi-head attention improving performance in experiments on miniImageNet dataset. Single-head attention struggles with extremely scarce data in 5-way 1-shot experiments. In a comparison between AWGIM and LEO in terms of convergence speed, AWGIM outperforms LEO on 5-way 1-shot miniImageNet experiments. AWGIM shows faster convergence and minimal computational overhead, especially when compared to MLP encoding. The experiments were conducted with small values for N, K, and |Q|, resulting in negligible overhead for self-attention and cross attention in AWGIM. The usage of self-attention and cross attention in AWGIM incurs minimal overhead compared to MLP encoding due to small values of N, K, and |Q|. Visualization of classification weights using t-SNE shows that the generated weights are clustered closer for each class, indicating adaptability to different query samples. The results show that query samples from different classes have distinct classification weights, as seen in the t-SNE visualization. Blue and red dots represent classification weights for query samples in the same task."
}