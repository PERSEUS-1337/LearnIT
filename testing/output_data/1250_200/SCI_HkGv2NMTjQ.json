{
    "title": "HkGv2NMTjQ",
    "content": "State of the art sound event classification uses neural networks to learn associations between class labels and audio recordings in a dataset. Ontologies define a structure that relates sound classes with more abstract super classes, serving as a source of domain knowledge representation. However, ontology information is rarely considered and underexplored in modeling neural network architectures. Two ontology-based neural network architectures are proposed for sound event classification, showing improved performance by incorporating ontological information. Ontologies provide a formal representation of domain knowledge through categories and relationships, aiding in structuring training data and neural network architecture design. Sound event classification often overlooks the potential benefits of utilizing ontologies despite their availability in datasets. Ontologies are formal representations of domain knowledge through categories and relationships, providing structure to training data and neural network architecture. They are based on abstraction hierarchies defined by linguistics, such as super categories representing subcategories. Different types of taxonomies can be defined, including interactions between objects and materials, actions and descriptors, and physical properties like frequency and time patterns. Hierarchical relations in sound event classifiers offer benefits such as allowing the classifier to back-off to more general categories, disambiguating acoustically similar but not semantically similar classes, and penalizing classification differently. Ontologies provide structure to training data and neural network architecture by representing domain knowledge through categories and relationships. They can disambiguate acoustically similar classes, penalize classification differently, and serve as domain knowledge for modeling neural networks. Ontology-based network architectures have shown performance improvement in various fields, including computer vision and music. Examples include using a deep restricted Boltzmann machine for textual topic classification and using perceptrons for each node in a hierarchy to improve class disambiguation. The authors propose ontology-based networks to improve performance by disambiguating classes and sub-classes. They present a framework for incorporating ontological information into deep learning architectures, including a Feed-forward model and Siamese Neural Networks for ontology-based embeddings. The framework is designed for ontologies with two levels but can be generalized to more levels. The framework presented by the authors incorporates ontological information into deep learning architectures, specifically focusing on ontologies with two levels. The framework allows for the mapping of classes between different levels in the ontology, enabling inference of labels at higher levels based on known labels at lower levels. This mapping is formalized using a probabilistic formulation. The authors' framework integrates ontological information into deep learning architectures, focusing on two-level ontologies. It enables mapping of classes between levels for label inference. A probabilistic formulation formalizes this mapping, allowing estimation of labels at higher levels based on known labels at lower levels. The proposed framework is used to design ontology-based neural network architectures, improving model performance by leveraging knowledge of class relationships during training. The authors' framework integrates ontological information into deep learning architectures, focusing on two-level ontologies. It enables mapping of classes between levels for label inference. The Feed-forward Network (FFN) with Ontological Layer consists of a base network (Net), an intermediate vector z, and two outputs for each ontology level. The ontological layer reflects the relation between super classes and sub classes given by the ontology, enhancing model performance by leveraging class relationships during training. The authors' framework integrates ontological information into deep learning architectures, focusing on two-level ontologies. They used Equation 3 to describe the layer, which can be rewritten as a directed graph. The ontological layer defines weights for connections and is part of the training data. A gradient-based method is applied to minimize the loss function, a convex combination of two categorical cross-entropy functions. The goal is to create embeddings that preserve the ontological structure using a Siamese neural network (SNN). The authors integrated ontological information into deep learning architectures using a Siamese neural network (SNN) to create embeddings that preserve the ontological structure. The SNN architecture enforces samples of the same class to be closer while separating samples of different classes based on subclass and superclass relationships. The ontological embeddings are used to compute a similarity metric, with the goal of minimizing the distance between embeddings of samples from the same subclass. The dataset for the Making Sense of Sounds Challenge 2 - MSoS aims to classify abstract classes in a taxonomy with two levels. The ontological-based neural network architectures are evaluated for sound event classification performance, utilizing ontological embeddings to minimize distances between samples from the same subclass. The architecture includes red rows showing output probabilities for different levels, and a Feed-forward Model with Ontological layer is trained using gradient-based methods. The dataset for the Making Sense of Sounds Challenge 2 aims to classify abstract classes in a taxonomy with two levels. The ontology has 97 classes at the lowest level and 5 classes at the highest level. Audio files were sourced from various databases, with 1500 files in the development dataset and 500 files in the evaluation dataset. The files are in a standardized format and were randomly partitioned for training and testing. The Urban Sounds dataset is designed for urban sound classification, with a taxonomy adjusted to avoid redundant levels. The ontology for the dataset has been adjusted to have two levels, with 10 classes at the lowest level and 4 classes at the highest level. The audio files used were from Freesound database, with 8,732 files in 10 subsets. A convolutional neural network was used to process the audio recordings, with a feed-forward multi-layer perceptron network architecture. The study utilized a neural network with layers of different dimensionalities and activation functions. Baseline models were considered for two levels of data sets, without ontological information. Results of baseline models for MSoS and US8K data sets were presented in Table 1. The study evaluated baseline models for MSoS and US8K data sets at different levels. By incorporating an ontological layer with varying values of \u03bb, performance improvements were observed. For MSoS, \u03bb = 0.8 yielded 5.4% and 6% accuracy improvements in levels 1 and 2 respectively. In contrast, for US8K, \u03bb = 0.7 resulted in smaller improvements of 2.5% and 0.2% in levels 1 and 2. The study evaluated baseline models for MSoS and US8K data sets at different levels, showing performance improvements with varying values of \u03bb. For MSoS, \u03bb = 0.8 resulted in 5.4% and 6% accuracy improvements in levels 1 and 2. On the other hand, for US8K, \u03bb = 0.7 led to smaller improvements of 2.5% and 0.2% in levels 1 and 2. The ontology-based embeddings produced tighter and better defined clusters in t-SNE plots, showcasing the effectiveness of the approach for sound event classification. The Siamese neural network was trained with ontology-based embeddings for 50 epochs using the Adam algorithm. Hyper-parameters were tuned for optimal performance with 100,000 pairs of input training data. The loss function was adjusted with lambda values for classifiers in level 1 and 2, and similarity metric. Results showed improved accuracy compared to the baseline, but slightly lower than the method without embeddings. The architecture with ontology-based embeddings outperformed the baseline but slightly underperformed the method without embeddings. Ontology-based embeddings showed better grouping with tighter clusters in t-SNE plots. Performance on the US8K dataset was limited due to a similar number of sub classes and super classes. The contribution of ontology was negligible when the ratio of sub classes to classes was small. In the Making Sense of Sounds Challenge, the Feed-forward Network with Ontological Layer achieved higher accuracy than the baseline. In this paper, a framework for designing neural networks for sound event classification using hierarchical ontologies is proposed. Two methods are presented to incorporate structure into deep learning models without adding more parameters. A Feed-forward Network with an ontological layer and a Siamese neural Network for ontology-based embeddings are introduced. Results from datasets and the Making Sense of Sounds Challenge show improvements over baselines, paving the way for further exploration of ontologies in sound event classification."
}