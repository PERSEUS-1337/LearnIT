{
    "title": "r1l73iRqKm",
    "content": "In open-domain dialogue, intelligent agents struggle to incorporate knowledge into conversations. To address this, a new dataset grounded in Wikipedia knowledge is introduced. Dialogue models are designed to retrieve, read, and generate responses based on this knowledge. These models show promising results in conducting knowledgeable discussions on various topics, paving the way for advancements in AI research towards more human-like interactions with machines. The current state-of-the-art AI models aim to improve natural language understanding and conversation skills by incorporating memory and knowledge. Existing sequence to sequence models lack the ability to effectively utilize memory in conversations. To have intelligent discussions, direct knowledge memory mechanisms should be employed to enhance conversational abilities. In this work, the authors propose using Transformer Memory Networks, which combine Memory Network architectures and Transformer architectures, to improve open-domain dialogue. They emphasize the need for direct knowledge memory mechanisms in conversation models and create a supervised dataset of human-human conversations for training. The authors build a supervised dataset of human-human conversations using crowd-sourced workers, with diverse discussion topics and conversations involving 201,999 utterances. Each topic is linked to Wikipedia, and a memory component is used to recall and ground knowledge from existing text. Transformer Memory Network architectures are tested for engaging knowledgeable conversations with humans, showing improvement compared to baselines. A new benchmark in ParlAI aims to encourage further research in this direction. The authors focus on studying the use of knowledge in dialogue tasks, particularly in recalling unstructured knowledge from a wide range of topics like Wikipedia. Unlike existing dialogue tasks that mainly rely on sequence-to-sequence models, their work emphasizes the importance of retrieving and conditioning knowledge for factual question answering. In this work, the authors emphasize the importance of retrieving and conditioning knowledge for dialogue tasks, focusing on natural human dialogues with a diverse set of utterances. They reference previous works that incorporate unstructured knowledge from sources like Wikipedia and Reddit to facilitate open-ended discussions and recommendations. The authors discuss using Wikipedia summaries and Foursquare tips as knowledge in dialogue tasks. They compare different models like Bag-of-Words Memory Networks and Transformers for multi-turn dialogues in an open-domain setting. Their work focuses on incorporating external knowledge into dialogues, unlike previous works that do not involve dialogue authored with the given knowledge. In an open-domain dialogue setting, two participants engage in chitchat where one is a knowledgeable expert (wizard) and the other a curious learner (apprentice). The apprentice delves deeply into a chosen topic, aiming to keep the conversation engaging. The wizard's goal is to inform the apprentice about a topic using an information retrieval system that shows Wikipedia paragraphs. The wizard in an open-domain dialogue setting uses an information retrieval system to provide relevant knowledge to the apprentice during their conversation. The wizard is instructed to craft engaging responses based on the retrieved information, without simply repeating it. The conversation flow involves the wizard choosing a relevant sentence from the retrieved knowledge to respond to the apprentice's messages, continuing until one of the participants ends the chat. The Wizard in an open-domain dialogue setting uses an information retrieval system to provide relevant knowledge to the apprentice. The conversation involves the wizard responding to the apprentice's messages based on chosen sentences, repeating until one participant ends the chat. Topics for conversation are diverse, and the wizard has access to passages of knowledge relevant to the dialogue context. The Wizard uses an information retrieval system to provide relevant knowledge to the apprentice during open-domain dialogue. The system retrieves top articles for the last two turns of dialogue and the original topic, presenting them to the wizard for response generation. The wizard can select a relevant sentence from the articles to respond to the apprentice. The wizard uses a dialogue model to replace themselves in learning tasks, accessing knowledge from sources like Wikipedia. They develop models that retrieve relevant information from memory, read and attend to it, and generate dialogue responses. Two classes of models are created: retrieval models that choose from a set of candidate responses, and generative models that produce responses word-by-word. The input to both models is the current dialogue turn. The input to the dialogue models is the current dialogue context, and the goal is to output the next utterance. A large knowledge base is hierarchically organized into documents, and information retrieval techniques are used to return a smaller set of candidates for selection. The retriever operates on the topic and the last two turns, providing better performance compared to merging into one query. The dialogue models use a large knowledge base organized into documents for input. Information retrieval techniques are employed to select candidates for the next utterance, with the retriever operating on the topic and last two turns. This method of retrieving candidates individually and using attention mechanisms for selection improves performance compared to merging queries. The dialogue models use a knowledge base for input and employ information retrieval techniques to select candidates for the next utterance. The model encodes knowledge sentences and dialogue context with a Transformer, predicts the output utterance, and is trained to minimize cross-entropy loss. Two versions of the model are considered: Two-stage and End-to-end. The Two-stage and End-to-end versions of the model select the most relevant knowledge and encode it with the dialogue context. A shared Transformer encoder is used in the End-to-end version to encode all candidates and dialogue history. The model is trained to minimize negative log-likelihood of the response. The End-to-end model uses a Transformer decoder to generate responses, trained to minimize negative log-likelihood. Additional supervision can be added for knowledge selection. In the Two-stage version, separate models are used for knowledge selection and utterance prediction. Knowledge dropout is employed to improve decoder performance. The novel technique proposed, Knowledge Dropout (K.D.), enhances training speed and is similar to other dropout techniques. Experimental setups and results are described, focusing on model's ability to select knowledge and perform dialogue tasks. Transformers outperform baselines when pretrained on Reddit data, with marginal impact from multitasking on SQuAD. Further analysis using other models is provided in the appendix. The study evaluates models for dialogue generation with knowledge in two settings: using gold knowledge chosen by a human or predicting which knowledge to use. Transformer Memory Networks are applied, improving model performance. Results show that adding knowledge enhances all models, with significant improvements when using gold knowledge. Generative experiments are conducted to compare model performance. The study evaluates models for dialogue generation with knowledge in two settings: using gold knowledge chosen by a human or predicting which knowledge to use. Transformer Memory Networks are applied, improving model performance. Results show that adding knowledge enhances all models, with significant improvements when using gold knowledge. Generative experiments compare model performance, showing that both End-to-end and Two-stage models utilize knowledge in response predictions. The Two-stage model excels with predicted knowledge, while the End-to-end model performs better with gold knowledge. The study evaluates models for dialogue generation with knowledge, showing that both End-to-end and Two-stage models utilize knowledge in response predictions. The End-to-end model is better at employing selected knowledge, with additional knowledge selection supervision improving performance. Knowledge dropout also helps, and both Two-stage models outperform retrieval models. Participants prefer physical books over e-books due to the sensory experience and ownership feeling. The study evaluates dialogue generation models using human evaluation and a metric called Wiki F1 score to measure engagingness and knowledge. Results from 546 conversations with ratings from 464 workers are presented in TAB4. The study compared retrieval and generative models in dialogue generation, finding that retrieval models outperformed generative models in human engagingness evaluation. Retrieval models with and without knowledge showed no significant difference, but both trended towards using knowledge for higher Wiki F1 scores. Generative models improved engagingness ratings significantly with knowledge use, conveying more knowledge than retrieval models on both seen and unseen data. Retrieval models were limited in generating responses for unseen topics, resulting in a larger gap with generative models on unseen data. In this work, dialogue agents are developed with large memory systems containing encyclopedic knowledge for engaging open-domain conversations. Transformer Memory Network models are used to retrieve and output responses in retrieval or generative modes. The Wizard of Wikipedia dataset is collected for training and evaluation, showing the effectiveness of the models in both automatic and human experiments. The publicly available benchmark aims to encourage further model exploration for significant advances in research. The new benchmark dataset aims to encourage model exploration for advances in research on dialogue agents with encyclopedic knowledge. Future work includes bridging the gap between retrieval and generative models, simultaneous retrieval and reasoning, and investigating knowledge-grounded dialogue. The dataset includes conversations between a wizard with access to an information retrieval system and an apprentice, with knowledge retrieval based on dialogue history. The dataset for dialogue agents with encyclopedic knowledge involves conversations between a wizard and an apprentice, where knowledge retrieval is based on dialogue history. The dataset includes \u223c61 knowledge candidates per turn, with wizards clicking no sentence used 6.2% of the time. Apprentices ask questions in 13.9% of training set utterances, answer questions 39.5% of the time, and make new or follow-on statements 49.3% of the time. Topics of interest are based on personas from the Persona-Chat dataset, with each persona consisting of 4-5 sentences describing interests mapped to relevant Wikipedia pages. The dataset includes 1,431 topics mapped to relevant Wikipedia pages for dialogue agents. Additional experiments show that the retrieval system performance can be improved with auxiliary loss. Analysis of dialogues from human evaluation experiments is conducted, with 20 conversations sampled from each experimental setting. In human evaluation experiments, conversations are analyzed in a single-blind setup. Human-human conversations differ significantly from bot conversations, with humans engaging in more small talk and using the topic as an icebreaker. Models attempt to mimic human behavior by producing factual sentences. The retriever without knowledge is prone to non sequiturs during unseen conversations. The retriever without knowledge is prone to non sequiturs during unseen conversations, while the retriever with knowledge sticks to the chosen topic but struggles if the subject changes. A two-stage retrieval system outperformed the best retrieval method in terms of F1 but not Recall@1, suggesting that improving performance on the knowledge selection subtask could enhance the retrieval system. Human experiments calculate the Wiki F1 score for the wizard and apprentice in the dataset. The curr_chunk discusses the performance of a model with knowledge in generating responses, noting that it sometimes provides factually inaccurate answers but can also produce inviting responses. The model without knowledge exhibits typical behaviors of seq2seq systems, such as local and global repetition. Selected conversations with the retriever with knowledge are shown in FIG5 for both seen and unseen topics. The generator with knowledge exhibits fewer issues with repetition and can act as a selfish conversationalist. It sometimes produces inaccurate statements but can successfully generalize to unseen topics using Wikipedia knowledge. Selected conversations with the generator with knowledge are available in Figure 5."
}