{
    "title": "HJcjQTJ0W",
    "content": "Massive data on user local platforms pose challenges for deep neural network (DNN) training. Cloud-based training offers benefits but raises privacy concerns. To address this, a method leveraging intermediate data representations is proposed, involving splitting DNNs between local platforms and the cloud. Local NN generates feature representations without training to protect data privacy. Cloud NN is trained using these representations for the target task. The idea is validated by analyzing privacy loss and accuracy dependency on local NN topology for image classification. PrivyNet is introduced to optimize target task accuracy while minimizing privacy loss. PrivyNet is proposed to optimize target task accuracy while minimizing privacy loss in cloud-based training schemes. Transformed representations of data are generated locally to protect user privacy, enabling deep model training without excessive data collection. The utility and privacy requirements of intermediate representations are crucial for effective target learning tasks. The utility and privacy requirements of intermediate representations are essential for effective target learning tasks. Various methods, such as k-anonymity, l-diversity, and t-closeness, have been proposed to balance privacy and utility in data transformations. Differential privacy offers a formal privacy guarantee by adding noise to data, but it does not limit total information leakage. Existing methods for data anonymization include non-invertible linear and non-linear transformations, which may rely on covariance or linear discriminant analysis. PrivyNet is a DNN training framework that offers fine-grained control over the trade-off between privacy and utility. It divides the DNN model into two parts deployed on local platforms and the cloud separately. The local NN is used for feature extraction, while the cloud NN is trained for the target learning task. The framework allows for better privacy protection compared to linear transformations, with control over privacy and utility trade-off through the topology of the local NN. PrivyNet splits a DNN model for cloud-based training with privacy control. The local NN extracts features while the cloud NN is trained. Privacy is protected through non-linear transformations like convolution and pooling. By deriving the local NN from pre-trained models, utility is maintained with specific feature control. Key contributions include proposing PrivyNet for fine-grained privacy control in DNN training. PrivyNet is a framework for splitting DNN models for cloud-based training with privacy control. It uses CNN as the local NN to extract features, optimizing utility while considering constraints on computation, storage, and privacy loss. The idea is validated through CNN-based image classification, demonstrating efficiency and effectiveness. The framework PrivyNet utilizes a pre-trained NN to extract feature representations (FEN) for training an image classification network (ICN) and an image reconstruction network (IRN). The utility is measured by the accuracy of the learning task, while privacy is assessed by the distance between reconstructed and original images. The IRN is trained assuming knowledge of original images and feature representations, but not the transformation FEN. The transformation induced by the FEN has a depth of D and feature dimension of W x H. The utility is evaluated by learning a classifier with minimized empirical risk, while privacy is assessed by minimizing the distance between reconstructed and original images. The reconstruction model minimizes the distance between reconstructed and original images using a loss function based on pixelwise Euclidean distance. Privacy loss is measured by the peak signal-to-noise ratio (PSNR) of the reconstructed images. The FEN topology impacts the privacy and utility of transformed representations, determined by factors like number of layers and output channels. The FEN topology is evaluated based on the number of layers, output depth, and selected channels. Changes in these factors impact utility and privacy in the PrivyNet framework. Privacy loss is observed with smaller PSNR in reconstructed images, while utility degradation varies with the number of FEN layers and output depth. The trade-off between accuracy and PSNR in the PrivyNet framework is shown in FIG2 (c). Two key observations are made: FEN with different topologies have similar utility when privacy loss is high, and FEN with more layers provide better utility when privacy loss is low. The selected subset of output channels also impacts privacy and utility. Utility and privacy loss for transformed representations induced by each single channel are compared, with a focus on FEN consisting of 4 VGG16 layers. When comparing utility and privacy loss for representations generated by each channel in the FEN with 4 VGG16 layers, significant differences are observed. The best channel achieves around 4 times the utility of the worst channel and 6 dB less privacy loss. Similar discrepancies are seen with 6 VGG16 layers. The impact of output channel selection is compared to the number of FEN layers and output depth, showing varying privacy and utility changes. The comparison of utility and privacy for representations generated by different output channels in the FEN with VGG16 layers shows significant differences. The number of FEN layers and output channel depth have a larger impact on privacy and utility compared to output channel selection. Leveraging pre-trained CNN for FEN construction allows for controlling the trade-off between utility and privacy. The framework PrivyNet is proposed to optimize utility while maintaining privacy and considering local computation capability and storage constraints. The framework PrivyNet is designed to optimize utility while maintaining privacy and considering local computation capability and storage constraints. It determines the FEN topology by leveraging pre-trained NNs and controlling the trade-off between privacy and utility. The number of layers and output depth of the FEN are determined based on privacy, local computation, and storage constraints. Performance profiling of NNs on local platforms is conducted to optimize utility under these constraints. The FEN output depth is determined considering privacy, local computation capability, and storage constraints. A supervised channel pruning step is conducted based on private data to remove ineffective channels. Output channels are randomly selected to determine the FEN topology. The assumption of availability of original images is crucial for worst-case privacy evaluation. The attackers are assumed to be unaware of the FEN transformation to prevent sophisticated image reconstruction mechanisms. The FEN anonymity protection is crucial to prevent attackers from reconstructing images using pre-trained NNs. The pre-characterization stage involves profiling NNs on local platforms and cloud-based privacy characterization. Different platforms have varying computation capabilities and storage configurations, influencing the FEN topology. The reconstruction network is trained on publicly available data for privacy characterization. The reconstruction network for FEN is trained on publicly available data of the same dimension and distribution. Privacy characterization is done for different datasets like CIFAR-10 and CIFAR-100, comparing PSNR for FEN with different topologies. Experiments show that less than 1000 samples are needed for accurate characterization with data augmentation. The number of FEN layers and output channel depth impact privacy and accuracy more than output channel selection. In PrivyNet, the FEN topology is determined based on privacy and accuracy considerations. Deeper FEN layers are chosen for high privacy requirements, while shallow FENs are selected for low privacy requirements. The output channel depth is adjusted accordingly to meet privacy constraints. The strategy is based on the relation between privacy, local computation, and storage on a mobile CPU. In PrivyNet, FEN topology is chosen based on privacy needs. Shallow FENs are preferred for low privacy requirements, with output channel depth adjusted accordingly. Privacy constraints determine the number of layers and output depth, optimizing local computation and storage. Output channel selection is crucial for balancing utility and privacy. In PrivyNet, the FEN topology is selected based on privacy requirements, with shallow FENs preferred for lower privacy needs. Output channel selection is crucial for balancing utility and privacy, as shown in Figure 9 and Figure 10. Channel pruning is necessary to optimize utility while suppressing privacy loss, considering both factors in the process. In channel pruning for PrivyNet, privacy loss is considered alongside utility. Privacy loss is determined from offline pre-characterization to prune channels with high privacy loss. Fisher's LDA is used to identify channels with poor utility by analyzing the distance between representations within and across classes. Fisher's criterion evaluates the effectiveness of each channel based on the covariance matrix. The Fisher's LDA method is utilized in channel pruning for PrivyNet to assess both privacy loss and utility. It identifies ineffective channels by analyzing representation distances within and across classes. By evaluating Fisher's discriminability, channels with poor utility are pruned to enhance learning accuracy. In channel pruning for PrivyNet, Fisher's LDA method is used to identify ineffective channels based on discriminability. The method prunes 32 output channels with poor utility, showing a 33.5% reduction in bad channel probability compared to random pruning. VGG16 layers are utilized for the pruning process, with similar results observed when pruning 64 channels. The number of samples required for LDA-based pruning is explored, showing consistent results across different mini-batch numbers. The experimental results demonstrate the effectiveness of supervised channel pruning in PrivyNet. The pruning process involves identifying and removing ineffective channels based on privacy and utility characterization. By pruning 64 channels with the worst utility and 32 channels with the largest privacy loss, significant improvements in performance are achieved. The computation complexity of the LDA-based pruning process scales with the number of samples, but the extra computation introduced is minimal. The experimental results show the effectiveness of supervised channel pruning in PrivyNet. Pruning is done based on privacy and utility characterization, resulting in improved performance. Comparing different pruning strategies, the LDA-based method achieves better accuracy and smaller PSNR. The method also shows similar accuracy but less privacy loss compared to characterization-based pruning. Overall, the supervised pruning strategy is proven effective. In this section, detailed discussions on the adversarial model adopted in the paper are provided. The FEN transformation is assumed to be unknown to attackers to prevent powerful attacks and enhance privacy protection. Strategies to protect the anonymity of the FEN include building a pool of pre-trained NNs for FEN derivation and applying channel selection procedures. By enlarging the pool of NNs, it becomes harder for attackers to guess how the FEN is derived. In this section, the paper discusses the adversarial model and strategies to protect the anonymity of the FEN. The channel selection procedure is applied to both output and intermediate channels, making it harder for attackers to guess the FEN derivation. The privacy and utility are empirically verified by gradually reducing the channel depth of convolution layers in VGG16. The results show minimal impact on privacy and utility, with a significant reduction in runtime. The study demonstrates the effectiveness of reducing channel depth in convolution layers for privacy protection in the FEN model. This approach maintains privacy and utility while significantly reducing runtime. The PrivyNet framework enables cloud-based training with fine-grained privacy protection, addressing resource constraints and policy limitations. It has practical applications in healthcare for disease diagnosis and treatment using patient data. PrivyNet provides a framework for hospitals to release informative features from patients' data while protecting privacy. It can also enable mobile platforms to upload data to the cloud while maintaining privacy. The platform is simple, platform-aware, and flexible for different end-users and situations. The CIFAR-10 and CIFAR-100 datasets contain color images in 10 and 100 classes respectively, with specific numbers of training and test images per class. VGG16, pre-trained on ImageNet, is used for privacy and accuracy characterization in image classification and reconstruction tasks using CNN and generative NN architecture based on ResNet blocks. In experiments, image recovery tasks like super resolution and denoising autoencoder are performed using an image IRN constructed following BID12. The structure includes 8 ResNet blocks per ResNet block cluster. Training process uses gradient descent optimizer, with learning rates and mini-batch sizes set accordingly. Data augmentation involves normalization, brightness, and contrast modifications. The topology of IRN is determined before characterization to ensure accurate privacy evaluation. Image recovery capability is influenced by the number of ResNet block clusters. The image recovery capability of IRN is determined by the number of ResNet block clusters. In experiments, 2 ResNet block clusters with 8 blocks each are chosen. Performance profiling of VGG16 on different platforms shows an increase in computation and storage requirements with the number of layers. Most computation comes from convolution layers, while storage is mainly affected by fully connected layers. The computation and storage requirements increase rapidly, with convolution layers contributing most to computation and fully connected layers to storage. The complexity of the second part of the computation is determined by the number of samples and output dimensions. The complexity is O((K + N LDA)W^2H^2 + W^3H^3). The complexity of the second part of the computation is determined by the characteristics of the FEN and the target learning task. N LDA is a key factor that determines the extra computation induced by the learning process. Usually, a small N LDA is sufficient to achieve good pruning results, resulting in a small overall computation overhead."
}