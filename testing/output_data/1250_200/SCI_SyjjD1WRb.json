{
    "title": "SyjjD1WRb",
    "content": "We establish a theoretical link between evolutionary algorithms and variational parameter optimization of probabilistic generative models with binary hidden variables. Two models are used to investigate applicability: a noisy-OR Bayes Net and Binary Sparse Coding. Learning of generative models is formulated as approximate maximum likelihood optimization using variational expectation maximization. Evolutionary algorithms can be used for variational optimization by treating latent states as genomes and defining fitness based on joint probabilities from the generative model. The novel evolutionary EM approach is applied to optimize parameters of noisy-OR Bayes nets and binary sparse coding on artificial and real data. Scalable variational EM algorithms efficiently improve data likelihood using point mutations and single-point cross-over. Evolutionary algorithms are introduced as tools for function optimization inspired by biological processes, offering potential for addressing parameter optimization in generative models. Evolutionary algorithms (EAs) have been used in various tasks such as classification with Deep Neural Networks (DNNs) to select the best architectures or hyper-parameters. The combination of EAs with probabilistic generative models and expectation maximization (EM) offers a unified framework for parameter optimization. EM is computationally challenging for most generative data models, but EAs provide a potential solution for addressing parameter optimization in these models. Variational EM is a prominent approximation for optimization problems in high-dimensional spaces. Latent states can be used as variational parameters, with EAs being a natural choice for optimization. A probabilistic generative model generates data points using hidden variables, and learning aims to adjust model parameters for better data generation. Learning seeks to adjust model parameters to maximize data log-likelihood using variational distributions and free energies. Elementary generative models with large state spaces can be trained efficiently with this approach. The approach discussed here involves training joint distributions with binary latents using variational distributions to approximate intractable posterior distributions. A variational EM algorithm iteratively maximizes the free-energy w.r.t. variational parameters in the E-step and w.r.t. model parameters in the M-step, using truncated variational distributions instead of parametric functions like Gaussians. The approach involves training joint distributions with binary latents using truncated variational distributions to approximate intractable posterior distributions. The variational E-step consists of finding populations of hidden states that maximize the likelihood for each data point. The variational E-step involves maximizing the free-energy by finding individuals with the largest joint probabilities, which is computationally challenging but increasing the free-energy is sufficient for approximate likelihood maximization. Mutations that increase fitness will result in increased free-energies, along with M-step optimizations of model parameters in variational EM. The variational EM algorithm involves maximizing free-energy by selecting individuals with high joint probabilities, along with M-step optimizations of model parameters. The fitness function is chosen to ensure increased free-energies, with logP used for efficiency and numerical stability. Different fitness functions can be chosen as long as certain conditions are met. The EA algorithm optimizes F(s) for a population of unique individuals using genetic operators like parent selection, single-point crossover, and mutation over N generations. The selection process balances exploitation of high fitness parents and exploration of mutations in poor performing parents. The EA algorithm optimizes F(s) for a population of unique individuals using genetic operators like parent selection, single-point crossover, and mutation over N generations. The selection process balances exploitation of high fitness parents and exploration of mutations in poor performing parents. In our numerical experiments, we explored fitness-proportional and random uniform selection of parents, crossover where random pairs swap bits to produce offspring, and mutation to generate children with high fitness and increase population diversity. The Evolutionary Algorithm (EA) optimizes F(s) for a population of unique individuals using genetic operators like parent selection, crossover, and mutation over N generations. The crossover step can be skipped to make the EA more lightweight but decrease offspring variety. Each child undergoes random bitflips to increase diversity, with a refined sparsity-driven bitflip algorithm used for better results. If crossover is skipped, a different bitflip mutation is performed on identical copies of each parent. The algorithm produces N g N c N p children, updating model parameters until sufficient improvement is achieved. The Evolutionary Algorithm (EA) optimizes F(s) for a population of unique individuals using genetic operators like parent selection, crossover, and mutation over N generations. The algorithm produces N g N c N p children, updating model parameters until sufficient improvement is achieved. The EEM Algorithm formulates a learning algorithm with EAs as its integral part, never decreasing the free-energy. The objective is the optimization of the log-likelihood in an unsupervised learning algorithm, utilizing the noisy-OR model with Bernoulli priors for latent variables and all-to-all connectivity among hidden and observable variables. Binary Sparse Coding (BSC) is a model for continuous data with binary latent variables following a Bernoulli distribution. The observables are drawn from a Gaussian distribution, and the model parameters include weights and variance. M-step update rules for BSC can be derived by optimizing the free energy. The details and expressions are provided in the appendix. The final expressions for Binary Sparse Coding (BSC) rules can be derived by optimizing the free energy. Numerical experiments were conducted to test the applicability and scalability of the Evolutionary EM (EEM) algorithm. Different evolutionary algorithms were used with various parent selection procedures and bitflip algorithms. EEM was investigated using artificial data in the standard bars test setup, where ground-truth components are known. The noisy-OR model and BSC model are compared using the standard bars test with 16 different bars. Evolutionary EM (EEM) is applied with different configurations of the EA, showing higher reliability with \"fitparents-sparseflips\" over \"randparents-randflips\" on 8x8 images. Evolutionary EM (EEM) with noisy-OR model is tested on a bars dataset with increased overlap among bars. Results show that all 16 bars were recovered in 13 out of 25 runs, demonstrating competitive performance without additional assumptions. EEM is evaluated on a bars test with increased complexity, including higher dimensionality, more components, and more bars per data point. The experiment used 5,000 training data points and tested different configurations of the EA. Results are shown in a figure. The experiment involved sampling individuals to vary K n and running 20 independent runs of an EA with 300 iterations each. Results showed that basic approaches like random selection of parents and bitflips work well, but more advanced EAs perform better. Sparseness-driven bitflips generally lead to poor performance, attributed to the initialization of K n. The experiment's averaged free energy values are depicted in FIG5. The approach was then tested on natural data using patches. The experiment involved sampling individuals to vary K n and running 20 independent runs of an EA with 300 iterations each. Results showed that basic approaches like random selection of parents and bitflips work well, but more advanced EAs perform better. Sparseness-driven bitflips generally lead to poor performance, attributed to the initialization of K n. The averaged free energy values for this experiment are shown in FIG5. Next, the approach was tested on natural data using patches of natural images from the van Hateren image database BID35. Light-intensity image patches were used, with the brightest 1% pixels removed and data points scaled to have gray-scale values in the range [0, 1]. Binary data points were created by sampling pixels from a Bernoulli distribution. The experiment involved using an evolutionary algorithm with parameters H = 100, S = 120, N g = 2, N p = 8, N c = 7 to learn generative fields over 200 iterations. Image patches were pre-processed using whitening approaches, with N = 100,000 patches of size D = 16 \u00d7 16. The BSC model was trained for 4,000 iterations using the \"fitparents-cross-sparseflips\" EA with H = 300. The BSC model was trained for 4,000 iterations using the \"fitparents-cross-sparseflips\" EA with H = 300 hidden units and S = 200 variational states. The generative fields obtained primarily consist of Gabor functions with different characteristics. More than five units were activated per data point on average, indicating the use of the generative model's multiple causes structure. The generative fields converged faster than prior and noise parameters, with a slow change in parameters after 4000 iterations. Training generative models is a well-studied area in Machine Learning, often requiring approximations when using EM for training. The training of generative models in Machine Learning often requires approximations. Sophisticated approaches like sampling or variational EM are developed for precise and efficient learning algorithms. Evolutionary algorithms have been used in conjunction with EM, such as for clustering with Gaussian mixture models. EAs are used to select the best GMM models, similar to DNN optimization, where EAs optimize hyperparameters in an outer loop. Other approaches have used EAs to directly optimize clustering objectives, replacing EM approaches for optimization. The study shows that evolutionary algorithms (EAs) can be integrated with Expectation Maximization (EM) for training generative models. This close theoretical link between EAs and EM allows for leveraging knowledge from evolutionary approaches. Basic EAs were used in experiments to train generative models, showing potential for future improvements in accuracy and scalability. EAs have the ability to handle large hidden spaces and local optima in training generative models. In experiments, Evolutionary Algorithms (EAs) were used to train generative models, showing potential for improved accuracy and scalability. The results represent the first examples of noisy-OR or sparse coding models trained with EAs. A novel mathematically grounded approach for using EAs in generative models with binary latents was introduced, with straightforward application. The update rule for \u03c0 is straightforward, but the update equations for weights W dh do not have a closed form solution. The update rule for weights W dh does not have a closed form solution. Instead, a fixed-point equation is used to move towards convergence, ensuring that drops in free energy during training can be corrected if needed. Update rules for the model parameters can be obtained separately, with Exact EM requiring setting q n to the exact posterior p( s | y (n) , \u0398). The exact EM can be obtained by setting q n to the exact posterior p( s | y (n) , \u0398), but this becomes computationally intractable with higher latent dimensionality. Truncated variational distributions are used to approximate exact posteriors for BSC, with constraints on flipping probabilities p 0 and p 1. Comparisons with other algorithms show that EMM for noisy-OR performs well, but there are approaches with higher performance. Comparing EMM for noisy-OR to other approaches like NMF, neural nets, and MCA shows that while EMM performs well, there are approaches with higher reliability. Most approaches recovering more than 15 bars require additional assumptions, such as constraints on weights and latent activations. MCA 3 stands out as a generative model without constraints, exploring sparse combinations with up to 3 components. EEM for noisy-OR evaluates around 100 states per data point per iteration, while MCA 3 evaluates over 60000 states. Generative fields learned with EEM for noisy-OR show a crowdedness of 1.6 after 175 iterations with 200 latent variables."
}