{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The models are structured based on a causal graph and applied to conditional and interventional sampling of face images with binary feature labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. The CiGM over labels and images is learned in a two-stage procedure combining Wasserstein GAN and conditional GAN. The conditional GAN, combined with a trained CiGM for labels, forms a CiGM over labels and generated images. Proposed architectures allow sampling from observational and interventional image distributions, even for interventions not in the dataset. Generative adversarial networks (GANs) are successful in training implicit generative models by sampling from high-dimensional distributions.GANs use a generator network to sample from noise vectors and a discriminator network to distinguish between generated and real samples. The generator aims to maximize the discriminator's loss to produce samples resembling real data distribution. Generative adversarial networks (GANs) aim to generate samples that mimic real data distribution by maximizing the discriminator's loss. GANs have been successful in generating samples from various distributions such as images and videos. An extension of GANs involves sampling from class conditional data distributions by providing class labels to the generator. Different neural network architectures have been proposed to address this issue. However, existing architectures lack the ability to capture dependencies between labels, limiting their capability to sample images given a subset of labels. This paper focuses on extending the capabilities of these architectures. In this paper, the focus is on extending the capabilities of existing architectures for conditional image generation by capturing the dependence and causal effect between labels. The generator in conditional image generation is a non-deterministic mapping from labels to images, following a causal process where labels determine the image distribution. The causal graph between labels can be included in the model, such as the example of the causal relation between Gender and Mustache labels. Conditioning on specific labels allows for sampling images based on the population distribution. Causal models allow sampling from conditional and interventional distributions, illustrating the concept on variables like Bald and Mustache. Causal implicit generative models aim to sample from correct joint, conditional, and interventional probability distributions. The focus is on capturing the causal effect between labels in conditional image generation architectures. The text discusses using Generative Adversarial Networks (GANs) to train causal implicit generative models by structuring the generator architecture based on the given causal graph. The approach involves using Wasserstein GAN (WGAN) to train a CiGM for binary image labels and proposing two novel conditional GANs, CausalGAN and CausalBEGAN, for further training. The study shows that adversarial training can be effective in learning a CiGM that outputs discrete labels, demonstrating the potential of combining CausalGAN with a CiGM for image and label generation. The text discusses training a CiGM using GANs based on a causal graph for binary labels. It introduces CausalBEGAN, a model that produces high-quality images capturing image labels. The framework is evaluated on CelebA data, showing label-consistent images even for interventions not seen during training. CausalBEGAN can generate label-consistent images for label combinations not seen during training. Previous works include CGAN, ACGAN, InfoGAN, BiGAN, ALI, and CoGAN, each extending GANs in different ways to incorporate extra information or learn mappings between image and latent spaces. In extending the GAN framework, BiGAN and ALI learn a mapping from image to latent space. CoGAN enforces weight sharing between generators and discriminators to learn a joint distribution over image and binary label. SD-GAN splits the latent space into \"Identity\" and \"Observation\" portions, allowing for generation of faces with fixed identity. CGAN with a one-hot encoded vector can change the age attribute of a face image. Generative models like Bora et al. (2017) provide compressed sensing guarantees for recovering a vector. Generative models have various applications, including in compressed sensing. Recent research has focused on using causal principles for deep learning and deep learning techniques for causal inference. Authors have explored the connection between GAN layers and structural equation models, using CGAN to learn causal direction between variables. Other studies propose using neural networks to discover causal relations between image class labels and introduce causal regularization for training predictive models. Researchers have also highlighted the connection of GANs to causal generative models. In the context of using causal principles for deep learning, authors have explored neural networks to learn causal graphs and mimic structural equations. They utilize Pearl's framework of structural causal models (SCMs) to represent causal relationships between random variables. The causal graph is represented by directed acyclic graphs, where the parents of a node represent the causes of that variable. Unobserved variables are also considered in the causal model. The causal graph in a structural causal model is a directed acyclic graph where the parents of a node represent the causes of that variable. It can be constructed from the structural equations and involves interventions that change the underlying causal mechanism. An intervention in a structural causal model changes the causal graph by disconnecting a node from its parents. The post-interventional distribution can be calculated using Bayesian network factorization. The post-interventional distribution in a structural causal model is calculated using Bayesian network factorization. It is not possible to identify the true causal graph without experiments or additional assumptions. The paper assumes the causal graph is given and focuses on learning a causal model. Bayesian networks can be used when the true causal graph is unknown to sample from correct observational distributions. The effect of the Bayesian network used is explored in Section 8.10, 8.11. Implicit generative models can sample from the data distribution but do not allow sampling from interventional distributions. Causal implicit generative models extend implicit generative models by allowing sampling from both observational and interventional distributions. Generative adversarial networks can be used to train these models by aligning the generator neural network connections with the causal graph structure. The feedforward neural networks represent the functions f X , f Y , f Z, with independent noise terms (N X , N Y , N Z ) chosen to be Gaussian distributed variables. A feedforward neural network can represent causal models with a graph by using Gaussian distributed variables. Two causal models with the same observational distribution will have the same interventional distributions for any intervention. The network output is defined based on the set of parents in the causal graph. Causal implicit generative models involve a feedforward neural network that outputs vectors based on a set of independent random variables. Causal implicit generative models involve a feedforward neural network G with output DISPLAYFORM7, defined for the causal model DISPLAYFORM8. Adversarial training is used to ensure the generator neural network aligns with the causal graph. CiGMs are trained with samples from a joint distribution given the causal graph, focusing on image generation with binary labels. The CausalGAN architecture divides the task into training a generative model for labels and then for images conditioned on the labels. The CausalGAN architecture divides the task into training a generative model for labels and then for images conditioned on the labels. The new architecture and loss function (CausalGAN) ensure that the optimum generator outputs the label conditioned image distributions, assuming a strictly positive joint distribution over the labels. The Causal Controller generative model is used for controlling image sampling based on labels, structured to produce labels according to the causal graph. The Causal Controller network is designed to produce labels sequentially according to the causal graph. To sample from a discrete label distribution, WGAN is employed. A new conditional GAN architecture is used to generate images based on the labels, ensuring the optimum generator outputs label-conditioned image distributions. The pretrained Causal Controller is not updated further. The CausalGAN architecture includes a Labeler and Anti-Labeler neural network, along with a generator that aims to produce realistic images consistent with labels. The Anti-Labeler discourages the generator from outputting only typical faces for a fixed label combination, ensuring diverse image distributions. The Anti-Labeler loss in the CausalGAN architecture discourages mode collapse by promoting diversity in generated images for different label combinations. This approach helps with faster convergence and can be extended to multiple labels. The analysis assumes a perfect Causal Controller and uses specific mappings for the generator, discriminator, Labeler, and Anti-Labeler. The CausalGAN architecture includes mappings for generator, discriminator, Labeler, and Anti-Labeler. The generator loss function contains label loss terms and an added loss term from the discriminator. The optimal generator outputs the class conditional image distribution. The Anti-Labeler, Labeler, and discriminator each have their own optimization problems to solve. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution and the discriminator and labeler networks operate optimally. The CausalGAN architecture ensures optimal operation of the discriminator and labeler networks. The generator minimizes the loss by sampling from the class conditional distributions. The global minimum of the training criterion is achieved when the generator output matches the class conditional image distribution. The two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The generator output must match the class conditional image distribution for optimal operation. The objective is to extend this result to cases with multiple binary labels by training the Labeler and Anti-Labeler to output posterior probabilities of label combinations given the image. The proposed alternative architecture extends the single binary label setup by using cross entropy loss terms for each label, requiring the Labeler and Anti-Labeler to have only d outputs. This ensures that the generator captures each label's posterior distribution, although it does not guarantee that the class conditional distributions will be true to the data distribution. However, for many practical joint distributions where labels are determined by the image, it is shown that the joint label posterior will be true to the data distribution. The proposed architecture extends the single binary label setup by using cross entropy loss terms for each label, ensuring the generator captures each label's posterior distribution. For practical joint distributions where labels are determined by the image, the joint label posterior will be true to the data distribution. Trained causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms, requiring conditioning on an event and interventional sampling. A simple extension of BEGAN involves feeding image labels to the generator, with details in the Appendix. The Causal Controller is used for interventional sampling, utilizing a Labeler network for labeling real images effectively. In architecture modifications, a Labeler network is used for labeling real images well and generated images poorly. Margin modifications are motivated by observations on image and label quality, leading to the training of CausalGAN and CausalBEGAN on the CelebA Causal Graph. The Causal Controller is trained on the dataset, satisfying conditions for causal relationships in the graph. The dataset used satisfies causal relationships in the CelebA Causal Graph. The generative model can create samples based on labels and interventional distributions. Theoretical analysis supports the model's capabilities. Our generative model can sample from interventional distributions and create samples conditioned on labels. The CelebA Causal Graph shows interventions and conditioning on Narrow Eyes label, affecting the proportion of smiling images. Causality in generative models like CausalGAN and CausalBEGAN leads to creativity in producing diverse samples. The research discusses the creativity of generative models like CausalGAN and CausalBEGAN in producing diverse samples. It explains the concept of a structural causal model and the causal graph in Bayesian networks. The research has been supported by various grants and organizations. The text discusses the concept of causal sufficiency in Bayesian networks and how interventional distributions can be calculated. It also introduces the joint data distribution and the optimal discriminator for fixed G in generative models. The text discusses the optimal discriminator for fixed G in generative models and introduces the optimal Labeler and Anti-Labeler. It also mentions the assumption of causal sufficiency in Pearl's model and the formation of complete graphs. The text discusses the formation of complete graphs and introduces the concept of the global minimum of the virtual training criterion C(G) in generative models. It also explains the conditions under which the global minimum is achieved. The text discusses a causal implicit generative model for a causal graph, where a generator can sample from the image distribution based on given labels. The concatenated generator neural network is consistent with the causal graph, assuming perfect sampling from true label and image distributions. This allows sampling from true observational and interventional distributions. The concatenated model serves as a causal implicit generative model for a graph D, allowing sampling from true observational and interventional distributions. Modifications are needed for multiple binary labels, with solutions proposed to address the challenge of characterizing the correct joint distribution. The section discusses the use of Labelers to estimate label probabilities, ensuring equality between predicted and true probabilities. It introduces an extension and presents results, along with a Lemma. The optimum Labeler minimizes loss by considering only combinations with positive probability and functions that are positive on these combinations. The Labeler loss is defined in terms of Shannon entropy and KL divergence. The optimum Labeler network gives the posterior probability of a label combination based on the observed image. The Anti-Labeler network solves a different optimization problem, with its optimum defined by a specific probability distribution. The optimum Anti-Labeler aims to optimize the conditional entropy of labels given the image, but lacks control over the joint distribution. The generator's optimization problem involves achieving the global minimum of the virtual training criterion by sampling from class conditional image distributions. Theoretical guarantees for the implemented CausalGAN architecture with d labels are provided under the assumption of deterministic relationship between image and labels in the dataset. This assumption ensures the global optimal generator samples from class conditional distributions. The global optimal generator samples from class conditional distributions, ensuring the generator loss is minimized when the discriminator, Labeler, and Anti-Labeler are at their optimum. This does not imply the generated distribution samples are equivalent to the real distribution. The assumption that the image determines all labels is crucial for correct conditional sampling. Any discrete joint probability distribution with kronecker delta functions as marginal probabilities is the product of these marginals. The joint probability distribution is zero everywhere except at specific points. Applying the lemma on the conditional distribution shows that the marginals are true to the data distribution. In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from class conditional image distributions, as shown through a chain of equalities. This approach extends the control theory-inspired boundary equilibrium concept of BEGAN to include label gradients for informative training. In this extension of BEGAN, image labels are incorporated into the generator to optimize the training process. A new loss function and margins are introduced to enhance the informative nature of label gradients in high-quality images. The formulation includes the use of margins, crucial for meaningful gradients in image generation. A well-trained Labeler is essential for generating useful gradients, similar to the importance of a well-trained BEGAN discriminator. In this extension of BEGAN, image labels are integrated into the generator to improve training. A new loss function and margins are introduced to enhance the informative nature of label gradients in high-quality images. The generator aims to minimize two loss terms, but image quality may suffer if the Labeler network is exploited without regard for realism. To address this, a new margin of margins term is introduced, ensuring label loss is incorporated only when the image quality margin is significantly larger than the label margin. This approach maintains the monotonically decreasing scalar characteristic of BEGAN for tracking gradient descent optimization. In this study, the convergence of causal implicit generative models is investigated on synthetic data generated from different causal graphs. Three causal graphs are considered: \"line\" X \u2192 Y \u2192 Z, \"collider\" X \u2192 Y \u2190 Z, and \"complete\" X \u2192 Y \u2192 Z, X \u2192 Z. A cubic polynomial computes the value of each node given its parents and an exogenous variable. The convergence of the joint distribution to the true joint is compared for each data generating graph. The study investigates the convergence of causal implicit generative models on synthetic data from different causal graphs: \"line\", \"collider\", and \"complete\". Results are compared in terms of total variation distance, showing the convergence behavior of the generator distribution structured based on each causal graph. The complete graph is expected to work well as it can encode all joint distributions. The study explores the convergence behavior of causal implicit generative models on synthetic data from different causal graphs: \"line\", \"collider\", and \"complete\". Results show that using the correct Bayesian network is crucial for fitting to the true joint distribution, with the complete graph expected to perform well. However, the number of layers in fully connected networks needs to be tuned for optimal performance in adversarial training. Using the wrong Bayesian network, such as the collider, leads to worse performance. The study examines the impact of using different causal graphs on the performance of causal implicit generative models. It is crucial to use the correct Bayesian network for optimal performance, with the number of layers in fully connected networks playing a significant role. The collider graph surprisingly shows better performance with 3 and 5 layers, while using 10 layers leads to the worst convergence behavior. Complete and collider graphs achieve decent performance, while the line graph performs the worst. Data is generated based on the causal graph X1 \u2192 X2 \u2192 X3, with scatter plots illustrating the distributions. The study explores the impact of different causal graphs on causal implicit generative models. Data is generated using the causal graph X1 \u2192 X2 \u2192 X3. The correct graph yields the closest scatter plot to the original data, while using the wrong Bayesian network results in a different distribution. The CelebA dataset is used for experiments with a causal graph called CelebA Causal Graph (G1). The completed graph cG1 includes labels like Young, Male, Eyeglasses, Bald, Mustache, Smiling, Wearing Lipstick, Mouth Slightly Open, and Narrow Eyes. The completed graph G1, cG1, and the effect of using the incorrect Bayesian network on data distribution are explored. Comparison of distributions for G1 and cG1 shows a reasonable approximation for {Male, Young} in G1 and a nearly perfect approximation in cG1. Both graphs lead to Causal Controllers that never output {Female, Mustache}. Wasserstein GAN with a modified version assures convergence in distribution of Causal Controller output. The text discusses the use of a modified Wasserstein GAN for training a causal controller on a subset of binary labels from the CelebA dataset. The results show good convergence and reasonable marginal distributions for all labels, with minimal deviation. The causal graph used in the experiment is illustrated in FIG6. The Wasserstein Causal Controller performance is tested on a subset of binary labels from the CelebA dataset using a causal graph. Results show convergence and reasonable marginal distributions for all labels. The total variational distance decreases with training, indicating a nearly perfect implicit causal generator over labels. In this section, additional CausalGAN results are presented, showing interventions and conditioning on specific labels in the CelebA dataset causal graph. The results demonstrate the impact of variables like Wearing Lipstick and Narrow Eyes on the generated images, highlighting the conditional independence assumptions made by the model. In this section, the CelebA Causal Graph is used to train CausalBEGAN. Intervening on Narrow Eyes does not affect Smiling probability, but conditioning on Narrow Eyes increases the proportion of smiling images. Training without the margin of margins deteriorates image quality for rare labels. The difference between interventional and conditional sampling is illustrated for Bald and Mouth Slightly Open labels. In this section, the difference between interventional and conditional sampling is demonstrated using the Bald and Mouth Slightly Open labels in the CelebA Causal Graph. Intervening on Bald does not affect the probability of being male, while conditioning on Bald results in only male images being sampled. Similarly, intervening on Mouth Slightly Open does not affect the probability of smiling, but conditioning on it increases the proportion of smiling images. Additional simulations for CausalGAN are provided in Figures 16a-16d for conditional image generation. In this section, additional simulations for CausalGAN and CausalBEGAN are provided. CausalGAN demonstrates conditional image generation properties by sweeping a single label from 0 to 1. CausalBEGAN shows the impact of the third margin term on image quality and introduces an extension M complete that decreases monotonically during training. Generators are also analyzed using \"label sweeps\" in CausalBEGAN. In this section, the CausalBEGAN architecture learns a discrete function for label input parameters. A random sampling of 256 images is shown to demonstrate image diversity. The approach involves training an implicit causal generative model for labels and images, treating the image as part of the causal graph. One hypothesis is that the discriminator focuses on labels without providing useful gradients for image generation. The implementation details of the Wasserstein Causal Controller for generating face labels are explained in this section. The total variation distance (TVD) is used as a metric to evaluate the success of the models. The generator architecture is based on a causal graph, using uniform noise as exogenous variables and 6 layer neural networks. The Wasserstein approach allows training the Causal Controller to output discrete labels, although rounding them before passing to the generator still provides benefits. The implementation details of the Causal GAN framework involve using uniform noise and 6 layer neural networks. Training involves 25 Wasserstein discriminator updates per generator update. The model is based on DCGAN and includes Labeler networks and a Causal Controller network. Loss functions are modified accordingly, with concurrent updates of discriminator and labeler networks. The label vectors determine the loss terms, which are averaged for each label. The architecture in Section 8.7 differs from the one in Section 8.6, as the discriminator outputs d-dimensional vectors for each label. This approach may not sample from class conditional distributions if data distribution is not restricted. However, for labeled image datasets where labels are determined by the image, this architecture suffices. Swapping the order of terms in cross entropy expressions for labeler losses improved image sharpness. Labels for CausalBEGAN are from the Causal Controller, with minimal parameter tuning and a shared learning rate of 0.00008 for generator and discriminator updates. In the Causal Controller, minimal parameter tuning is used with a shared learning rate of 0.00008 for both the generator and discriminator. Customized margin learning rates are also employed, with the best models having all three margins active. Comparing CausalGAN behavior with and without Anti-Labeler network shows that using Anti-Labeler allows for faster convergence and more diverse images for very rare labels."
}