{
    "title": "BJeOioA9Y7",
    "content": "In this paper, a new approach called knowledge flow is developed to transfer knowledge from multiple deep nets (teachers) to a new deep net model (student). The teachers and student can have different structures and be trained on different tasks. The student becomes independent of the teachers after training with knowledge flow, outperforming fine-tuning and other methods in various learning tasks. Research communities have developed various deep net architectures for different tasks, with some architectures trained from scratch and others fine-tuned using structurally similar deep nets. In reinforcement learning, different approaches involving teachers have been explored, such as progressive neural nets, PathNet, 'Growing a Brain', Actor-mimic, and Knowledge distillation. These methods aim to transfer knowledge from multiple teachers to a new deep net model, improving performance in various learning tasks. Knowledge flow is a new approach developed to address limitations in existing techniques like progressive neural nets, PathNet, 'Growing a Brain', and actor-mimic for transferring knowledge from multiple teachers to a student model. This method ensures the student becomes independent during training and maintains a constant size, offering flexibility in choosing teacher models without restrictions on network size. Our framework allows for knowledge transfer from multiple teachers to a student model, ensuring independence and a constant network size. It is applicable to various tasks, including reinforcement learning and fully-supervised training. The approach is flexible in choosing teacher models and evaluates knowledge flow across different tasks. To optimize policy parameters \u03b8 \u03c0, a loss function based on negative log-likelihood and negative entropy regularizer is common. The value function is approximated by a deep net V \u03b8v(x) with parameters \u03b8 v. By minimizing the empirical expectation, we learn a policy and a value function that maximize expected return. Knowledge flow is a framework that transfers knowledge from multiple pre-trained deep nets, referred to as 'teachers,' to a deep net being trained, called the 'student.' The student's parameters are randomly initialized, while the teachers' parameters are fixed and obtained from pre-trained models on different source tasks. This process allows the student to gradually become independent as training progresses. In the knowledge flow framework, knowledge from multiple pre-trained teachers is transferred to a student deep net by adding transformed teacher representations to the student net. The student net is modified to incorporate these teacher representations, which are scaled and normalized to determine the level of trust in each layer. The goal is for the student model to eventually capture all the knowledge without relying on teachers. The knowledge flow framework encourages high weight on student representation, initially relying on teacher knowledge for better performance. As training progresses, the student becomes more independent. Additional loss functions are introduced to measure student reliance on teachers and ensure stable behavior when teacher influence decreases. This leads to the student mastering tasks independently. The transformed program for supervised and reinforcement learning includes modifications to the deep net with cross-connections, introducing additional loss terms to control teacher influence. Parameters \u03b8 and \u03b8 old are used to adjust the strength of teacher guidance, gradually decreasing it as training progresses. The method aims to reduce negative transfer effects and promote student independence without assuming alignment of teacher and student objectives. The proposed method modifies deep nets with cross-connections to reduce negative transfer effects and promote student independence. It decreases the weight for teacher layers to minimize initial negative transfer, allowing students to benefit from low-level representation of teachers. The method introduces loss functions to successively decrease teacher influence and uses normalized weights to decide which representation to trust at each layer of the student net. The proposed method modifies deep nets with cross-connections to reduce negative transfer effects and promote student independence. It introduces loss functions to decrease teacher influence and uses normalized weights to decide which representation to trust at each layer of the student net. In practice, it is recommended to link one teacher layer to one or two student layers to avoid introducing irrelevant features. In the proposed method, trainable parameters Q and w are introduced as auxiliary knobs to help the student learn faster. The influence of teachers is gradually decreased during training to encourage the student to become more independent. By minimizing the dependence cost, the student's weights increase, leading to independence from teachers' transformed representations. The influence of teachers is gradually decreased during training to encourage the student to become independent. A fast decrease in teacher influence can degrade performance, so a Kullback-Leibler regularizer is used to prevent rapid changes in the student's output distribution. Knowledge flow is evaluated on reinforcement and supervised learning tasks, with results reported using only the student model to avoid any influence from teacher nets. Atari games used by BID23 BID6. Agent predicts actions based on rewards and input images. Model architecture includes 3 hidden layers with convolutional and fully connected layers. Two sets of output: softmax for action probabilities and scalar for value function. Hyperparameters similar to BID17 except for using Adam optimizer. Learning rate set to 10^-4 and gradually decreased to zero. In experiments, Adam with shared statistics is used for training baselines with a learning rate of 10^-4. \u03bb 1 and \u03bb 2 are selected by randomly sampling from specific ranges. Each experiment is repeated 25 times with different random seeds. Evaluation metrics involve playing each game for 30 episodes and following a 'no-op' procedure. The framework is compared with PathNet and progressive neural net using their experimental settings. The comparison between our transfer framework and state-of-the-art reinforcement learning frameworks, PathNet and progressive neural net (PNN), shows that our approach achieves higher scores in multiple experiments. Our student model outperforms PNN with fewer parameters and shows significant performance improvement when the number of teachers increases. Training curves demonstrate the effectiveness of knowledge transfer from teachers to the student, and experiments with different environment/teacher settings further validate our approach. Our approach to knowledge flow involves experimenting with different environment/teacher settings to evaluate knowledge transfer. Results show that knowledge flow with an expert teacher outperforms the baseline, demonstrating successful transfer of knowledge. Additionally, knowledge flow with non-expert teachers also outperforms fine-tuning, as the student model can learn from multiple teachers. In knowledge flow, the student model can benefit from learning from multiple teachers, avoiding negative impacts from insufficiently pretrained teachers. Training curves are shown in FIG5, with the student achieving scores ten times larger than learning without a teacher. Various image classification benchmarks are used for supervised learning. The study evaluates student models using multiple teachers on various image classification benchmarks like CIFAR-10 and CIFAR-100. Parameters are determined using validation sets, and top-1 error rates are reported. Training is done with standard data augmentation and Densenet as a baseline. Results are compared to fine-tuning and baseline models, showing improvement in the CIFAR-10 target task. The study evaluates student models using multiple teachers on image classification benchmarks like CIFAR-10 and CIFAR-100. Results show improvement in the CIFAR-10 target task by leveraging knowledge flow from good teachers. Knowledge flow can avoid misleading influence and is further demonstrated on the CIFAR-100 dataset. Additional results are available in the appendix. PathNet BID6 allows multiple agents to train the same deep net while reusing parameters and avoiding catastrophic forgetting. Progressive Net BID23 introduces lateral connections to previously learned features to prevent forgetting. Our method also uses lateral connections but ensures the student's independence during training. Distral BID26 combines distillation and transfer learning for joint training of multiple tasks, promoting consistency between policies. Knowledge flow focuses on single-task learning, transferring information similar to multi-task learning frameworks. In multi-task learning, information from different tasks is shared to improve performance, while in knowledge flow, information from multiple teachers helps a student learn a new task. The approach allows training a deep net from any number of teachers, showing improvements in reinforcement and supervised learning. Future plans include learning when to use which teacher and how to swap teachers during training. The study focuses on actively swapping teachers during student training to distill knowledge from larger models to smaller ones. Experiments were conducted on various datasets using different teacher-student model setups. The framework consistently outperformed traditional knowledge distillation methods by leveraging both output layer behavior and intermediate layer representations of the teacher model. The 'EMNIST Letters' and 'EMNIST Digits' datasets consist of images of handwritten letters and digits, with balanced classes. Training and test sets have varying numbers of images. The study used the MNIST model as a baseline, teacher, and student model, training teachers on different datasets. Results showed that student learning with expert, semi-expert, and non-expert teachers outperformed baseline and fine-tuning methods on the EMNIST dataset. In our experiment, student learning with expert, semi-expert, and non-expert teachers showed better performance on the EMNIST dataset. The STL-10 dataset consists of colored images with 10 classes, and we used 5,000 labeled images for training. Comparing our results to fine-tuning and the baseline, we found that pretraining on CIFAR-10 and CIFAR-100 reduced test errors by more than 10%. Fine-tuning from pretrained weights on CIFAR-10 and CIFAR-100 reduced test errors by over 10%. Student model training in the framework further decreased test error by 3%. Results are based on training with labeled data only, making direct comparisons with other approaches challenging. The study also includes comparisons with Distral BID26, a multi-task reinforcement learning framework, on Atari games with three tasks. Our model is trained for 40M steps and compared to Distral's task 1 model, which aims to learn a multi-task agent but is suboptimal. Our framework can decrease a teacher's influence to reduce negative transfer. Averaged normalized weight (p w ) for teachers and the student in the C10 experiment show that the C100 teacher has a higher p w value than the SVHN teacher. An ablation study confirms the student benefits from teacher knowledge. The study conducted at the end of training verifies the benefit of teacher knowledge by comparing learning with untrained teachers to learning with knowledgeable teachers. Results show that learning with knowledgeable teachers achieves higher rewards in different environments and settings. The KL term prevents drastic changes in the student's output distribution when the teachers' influence decreases. An ablation study investigates the importance of the KL term by setting the KL coefficient to zero, showing the impact on the target task of MsPacman with Riverraid and Seaquest experts as teachers. At the end of training, learning with the KL term achieves higher rewards compared to learning without it. Using different architectures for the teacher and student models, the teacher model has 3 convolutional layers and a hidden fully connected layer, while the student model has 2 convolutional layers and a hidden fully connected layer. The student model has 2 convolutional layers with 16 and 32 filters, followed by a fully connected layer with 256 ReLUs. The teachers' architectures differ from the student's, but learning with them yields similar performance. For the target task KungFu Master, teachers for Seaquest and Riverraid were used, resulting in an average reward of 37520 for different architectures and 35012 for the same architecture. Using an average network to obtain parameters \u03b8 old achieves similar performance as using a single model, as shown in FIG0. For the target task Boxing with a Riverraid expert teacher, using an average network results in an average reward of 96.2 compared to 96.0 with a single network. More results on using an average network are available in FIG0 (b, c). The discussed method involves using multiple teacher nets trained for knowledge transfer, contrasting with techniques like PathNet and Progressive Net that reuse parameters and avoid catastrophic forgetting through lateral connections. In contrast to these methods, the discussed approach introduces scaling with normalized weights. The discussed method involves using lateral connections for knowledge transfer with scaling and normalized weights. Distral combines distillation and transfer learning for joint training of multiple tasks, while knowledge flow focuses on transferring information from multiple teachers to help a student learn a new task. Knowledge distillation distills information from a larger model. Our proposed technique enables knowledge transfer between different domains, allowing an agent to learn multiple tasks simultaneously and generalize the extracted knowledge. It combines feature regression and cross entropy loss to encourage the student to produce similar actions and representations. Additionally, it retains old capabilities when adding a new task to a deep net, unlike other techniques that only use data from the new task. Our proposed technique enables knowledge transfer between different domains, allowing an agent to learn multiple tasks simultaneously and generalize the extracted knowledge. It combines feature regression and cross entropy loss to encourage the student to produce similar actions and representations. Additionally, it retains old capabilities when adding a new task to a deep net, unlike other techniques that only use data from the new task. The old networks output is recorded on the new data, and knowledge is transferred more explicitly from teacher networks."
}