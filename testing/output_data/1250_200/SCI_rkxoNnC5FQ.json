{
    "title": "rkxoNnC5FQ",
    "content": "Deep Learning for Computer Vision relies on supervision sources. A new unsupervised domain adaptation algorithm, SPIGAN, uses Simulator Privileged Information (PI) and Generative Adversarial Networks (GAN). The approach improves semantic segmentation by training on real-world and synthetic data with z-buffer PI. This method outperforms current unsupervised domain adaptation techniques, addressing the challenge of learning with minimal human supervision in Machine Learning and Computer Vision. Training in simulation has shown improvements in various tasks like optical flow, object detection, tracking, pose estimation, action recognition, and semantic segmentation. The main challenge remains the domain gaps between synthetic and real data. Unsupervised domain adaptation algorithms using Generative Adversarial Networks (GANs) have been effective in addressing this issue by leveraging Privileged Information (PI) from simulators. This additional information is not available in the real world. In this paper, a novel adversarial learning algorithm called SPIGAN is proposed to leverage Simulator PI for GAN-based unsupervised learning of a target task network from unpaired unlabeled real-world data. The algorithm involves training four networks: a generator G, a discriminator D, a task network T, and a privileged network P. The privileged network P is used to predict privileged information z from synthetic and adapted images, acting as an auxiliary task and regularizer for the task network T. The approach is evaluated on semantic segmentation in urban scenes using the Cityscapes dataset. SPIGAN is an adversarial learning algorithm that leverages Simulator PI for unsupervised learning of a target network T for semantic segmentation in urban scenes. It uses synthetic data from the SYNTHIA dataset and outperforms other unsupervised domain adaptation methods. The paper also includes a review of related works, details of the SPIGAN algorithm, experimental results, and a conclusion. In Section 4, quantitative experiments on semantic segmentation are reported, focusing on unsupervised adaptation methods in deep learning. The Domain Adversarial Neural Network (DANN) is a popular approach for learning domain invariant features. Curriculum Domain Adaptation is a recent evolution for semantic segmentation that reduces the domain gap via a curriculum learning approach. Recent advancements in semantic segmentation include Curriculum Domain Adaptation, which reduces the domain gap through a curriculum learning approach. Adversarial domain adaptation techniques, such as GANs and Variational Auto-Encoders, have shown promising results for unsupervised domain adaptation at the pixel level. CycleGAN, SimGAN, and Sadat are examples of methods that leverage generative models for image translation and address the domain gap between synthetic and real-world images. Sadat BID40 leverages synthetic data to refine images realistically by treating foreground and background differently. The SPIGAN learning algorithm involves four networks jointly learning to generate realistic images from a simulator. PixelDA BID1 is a domain adaptation method that uses simulation as its source domain. PixelDA BID1 is a pixel-level domain adaptation method that uses simulation as its source domain without privileged information. It focuses on simple tasks with low domain gaps. BID21 studies semantic segmentation in adversarial training with a curriculum learning approach. BID41 conducts domain adaptation using task-specific decision boundaries. BID42 leverages the GAN framework for shared representation learning. BID5 uses target guided distillation for network imitation. BID57 combines appearance and representation adaptation. BID49 adapts in the output space with adversarial learning. BID59 generates pseudo-labels based on confidence scores and proposes an iterative self-training framework. The main novelty is the use of Privileged Information from a simulator in a generic way. In a novel approach, the use of Privileged Information from a simulator significantly improves semantic segmentation in urban scenes by augmenting the learning objective. Inspired by Learning Using Privileged Information (LUPI), the goal is to leverage additional data only available at training time for unsupervised domain adaptation. Several works have utilized privileged information for domain adaptation, such as leveraging RGBD information to aid in object adaptation. Our goal is to utilize privileged information from simulators for sim-to-real unsupervised domain adaptation in order to learn a model for perception tasks without using ground truth data from the target domain. This involves adapting from a synthetic domain with labeled images and privileged information to a real domain with unlabeled images. The simulated source domain provides control over environmental factors for training neural networks. The simulated source domain offers control over environmental factors for training neural networks with labeled images and privileged information. The challenge is bridging the gap between synthetic and real domains for generalization without target supervision. Leveraging the simulator's privileged information within a GAN framework, called SPIGAN, is proposed to guide and constrain the training of the target task network. SPIGAN is a GAN framework that aims to make the adapted domain statistically close to the target domain to maximize the accuracy of the task predictor during testing. The generator transforms images from the source domain to the adapted domain, while the discriminator distinguishes between fake and real images. The target task network is trained on synthetic images to predict labels, and the privileged network is trained to predict privileged information. During testing, only the task predictor is needed for inference. The main learning goal is to ensure label and privileged information preservation. The SPIGAN framework aims to align the adapted domain with the target domain to enhance task predictor accuracy. The model is trained jointly to utilize all available information and ensure label and privileged information preservation. The learning objective includes a set of loss functions and constraints, with a minimax objective optimized using weights for adversarial, task prediction, PI regularization, and perceptual regularization. A least-squares based adversarial loss is used for stability and improved image results. The SPIGAN framework utilizes a least-squares based adversarial loss for stability and improved image results. Task prediction loss is optimized over synthetic images and their adapted versions, assuming label preservation. Different tasks require different loss functions, such as cross-entropy loss for semantic segmentation. PI regularization is also employed for predicting privileged information. In the SPIGAN framework, different losses are used for various tasks, such as PI regularization and perceptual regularization. The optimization process involves alternating updates between the discriminator and the generator, privileged network, and task network. The method is evaluated for unsupervised domain adaptation in semantic segmentation without access to training labels. In the experiment, an unsupervised domain adaptation method is evaluated for semantic segmentation using the SYNTHIA dataset as the source domain and Cityscapes and Mapillary Vistas datasets as target domains. Cityscapes dataset consists of urban street images in Europe, while Mapillary Vistas offers a wider variety of scenes, cameras, and conditions. The experiment evaluates unsupervised domain adaptation for semantic segmentation using SYNTHIA as the source domain and Cityscapes and Mapillary Vistas as target domains. Mapillary Vistas dataset has a wider variety of scenes, cameras, locations, weathers, and illumination conditions. The adaptation involves using a single sim-to-real generator with specific architecture and a PatchGAN discriminator network. The evaluation includes adaptation from SYNTHIA to Cityscapes on 16 classes and using standard intersection-over-union (IoU) as the main validation metric. The architecture for the semantic segmentation model includes ResNet blocks and a PatchGAN discriminator network. The model uses the FCN8s architecture for the task predictor and privileged network. Hyperparameters were set through grid search on a validation set. The joint adversarial loss weights are determined for the GAN and task losses. The key factors in the objective are the GAN and task losses, with regularization terms playing a secondary role. Stopping criterion for unsupervised learning is based on discriminator loss outperforming generator loss. Evaluation is done at two resolutions: 320 \u00d7 640 and 512 \u00d7. During training, images are resized to 320 \u00d7 320 or 400 \u00d7 400 for different resolutions. The Adam optimizer is used with an initial learning rate of 0.0002. Semantic Segmentation results for adapting from SYNTHIA to Cityscapes are evaluated using the SPIGAN algorithm. Depth maps from SYNTHIA are utilized in the process. In our evaluation of the SPIGAN algorithm for adapting a semantic segmentation network from SYNTHIA to Cityscapes, depth maps from SYNTHIA are used as PI. Results show SPIGAN achieves state-of-the-art semantic segmentation adaptation on Cityscapes, with a 3% improvement in mean IoU for layout-related and object-related classes. SPIGAN achieves a 3% improvement in mean IoU for layout and object classes by leveraging synthetic data and PI from the simulator. The algorithm shows better generalization performance across the sim-to-real domain gap. Further experiments compare SPIGAN with and without PI, as well as with perceptual regularization. Results on the Vistas dataset demonstrate challenging adaptation due to image diversity. SPIGAN, with perceptual regularization, shows improved adaptation results in Cityscapes and Vistas datasets. The mean IoU is increased by 17.1% in Cityscapes, with an additional 7.4% improvement from PI. SPIGAN-no-PI outperforms SPIGAN-base in both datasets, indicating the effectiveness of perceptual regularization in stabilizing adaptation during training. SPIGAN shows significant improvements in various categories and a +15% increase in IoU for the \"human\" category. On the Vistas dataset, SPIGAN reduces the domain gap by +4.3% mean IoU. The use of PI is crucial for generalization performance, as SPIGAN-no-PI performs -13% worse than the FCN source without adaptation. The difference in results between Cityscapes and Vistas is attributed to the visual diversity of the datasets. Cityscapes is a visually uniform benchmark recorded in German cities, while Vistas contains diverse data from around the world. Cityscapes is more suitable for image translation methods like SPIGAN. SPIGAN with PI shows consistent improvement in reducing domain gap and avoiding artifacts compared to SPIGAN-no-PI. PI imposes useful constraints for better training and reduces domain shift. The study shows that Privileged Information (PI) helps in task-oriented training and reduces domain shift. Unsupervised adaptation methods show improvement in the \"vehicle\" category for both Cityscapes and Vistas datasets. However, the \"human\" category did not see the same improvement due to the lack of human data in the SYNTHIA subset used. The study introduces SPIGAN, a method that leverages synthetic data and PI for unsupervised domain adaptation of deep networks. Our approach addresses domain gaps between synthetic data and real-world domains, improving tasks like semantic segmentation of urban scenes. Future work includes exploring SPIGAN for additional tasks with different types of privileged information."
}