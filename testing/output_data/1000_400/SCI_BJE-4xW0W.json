{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The models are structured based on a causal graph and applied to conditional and interventional sampling of face images with binary feature labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. We train a CiGM over binary labels using a Wasserstein GAN, followed by combining it with a conditional GAN to generate images conditioned on the labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed. The architectures allow sampling from observational and interventional image distributions, even for interventions not present in the dataset. The proposed architectures can sample from observational and interventional image distributions, including interventions not in the dataset. Generative adversarial networks (GANs) are successful in training implicit generative models by using backpropagation to sample from high-dimensional nonparametric distributions. The generator network produces samples from a noise vector, refined by a discriminator network that distinguishes between generated and real samples. Generative adversarial networks (GANs) use a generator network to model the sampling process and a discriminator network to distinguish between generated and real samples. The objective is for the generator to convince the discriminator that its output is from the real data distribution. GANs have been successful in generating samples from various distributions such as images and videos. Extensions include sampling from class conditional data distributions by feeding class labels to the generator. Various neural network architectures have been proposed for this purpose. In extending Generative Adversarial Networks (GANs), class labels are fed to the generator to sample from class conditional data distributions. Different neural network architectures have been proposed for this purpose. The focus is on capturing the dependence between labels to enable sampling images given a subset of labels. In extending Generative Adversarial Networks (GANs), neural network architectures aim to capture the dependence between labels for conditional image generation. The generator maps labels to images in a non-deterministic manner, following a causal process where labels determine the image distribution. The goal is to include causal relationships between labels, such as Gender (G) and Mustache (M). The generator in Generative Adversarial Networks is a non-deterministic mapping from labels to images, following a causal process where labels determine the image distribution. Causal relationships between labels, like Gender (G) and Mustache (M), can be included in the model. Conditioning on different labels allows for sampling from conditional and interventional distributions. When we condition on Mustache = 1, we sample from males only. Causal models allow sampling from interventional distributions by fixing variables in a causal graph. Intervening on Mustache = 1 does not change the distribution of Gender. See Figure 1 for examples of conditional and interventional samples on Bald and Mustache variables. Intervening on Mustache = 1 does not alter the distribution of Gender in the causal graph. Causal implicit generative models (CiGM) sample from correct joint, conditional, and interventional probability distributions. The neural connections of the generator structure are based on the causal graph, allowing GANs to train CiGM. When the generator structure inherits its neural connections from the causal graph, GANs can be used to train causal implicit generative models. Wasserstein GAN is used to train a CiGM for binary image labels, followed by the proposal of two novel conditional GANs - CausalGAN and CausalBEGAN. The optimal generator of CausalGAN can sample from true conditional distributions, and combining it with a CiGM on labels yields a CiGM on both labels and images. Adversarial training can be used post-structuring the generator architecture based on the causal graph to train a CiGM. Our contributions include showing that combining CausalGAN with a CiGM on labels results in a CiGM on both labels and images. We demonstrate that WGAN can train a CiGM for binary labels, propose a two-stage procedure for conditional and interventional sampling of images, and extend BEGAN to accept labels. We propose a two-stage procedure to train a CiGM over binary labels and images using a novel conditional GAN architecture. Our model, CausalBEGAN, extends BEGAN to accept labels and produces high-quality label-consistent images. Empirical evaluation on CelebA data shows that CausalGAN and CausalBEGAN can generate images for label combinations not seen during training. The CiGM training framework evaluates CausalGAN and CausalBEGAN on labeled CelebA data, showing label-consistent image generation even for interventions not seen during training. Previous works include conditional GAN (CGAN), ACGAN, and InfoGAN for image label conditioning. In BID10, ACGAN is proposed where the discriminator estimates the label. BID15 introduces InfoGAN to maximize mutual information between inputs and images. BiGAN and ALI extend GAN by learning a mapping to a latent space. CoGAN learns a joint distribution over image and binary label. SD-GAN is a similar architecture. In BID18, BiGAN and ALI extend the GAN framework by learning a mapping to a latent space. CoGAN learns a joint distribution over image and binary label, while SD-GAN splits the latent space into \"Identity\" and \"Observation\" portions. SD-GAN can be seen as an extension of BEGAN to labels, and it is challenging to extend CoGAN and SD-GAN to more than two labels. BID0 uses CGAN with a one-hot encoded vector for age intervals. SD-GAN is an extension of BEGAN to labels, challenging to extend to more than two labels. BID0 uses CGAN with a one-hot encoded vector for age intervals. Generative models have applications in compressed sensing, with recent attention on causal principles in deep learning. BID3 connects GAN layers with structural equation models. Recent research has focused on using causal principles in deep learning, such as connecting GAN layers with structural equation models. Various studies have explored using neural networks to discover causal relationships between variables or image class labels. Some propose new regularization techniques, like causal regularization, to ensure models are predictive in a causal sense. Additionally, the connection between GANs and causal generative models has been highlighted in recent work. In a recent study, Bahadori et al. (2017) introduced causal regularization for training neural networks to ensure predictive causality. Besserve et al. (2017) connected GANs to causal generative models, viewing images as causes of neural net weights. Goudet et al. (2017) also used neural networks to learn causal graphs, mimicking structural equations. Pearl's framework of structural causal models (SCMs) with directed acyclic graphs represents causal relationships between random variables. In this section, a brief introduction to causality is given using Pearl's framework of structural causal models (SCMs). SCMs represent causal relationships between random variables through structural equations and directed acyclic graphs. The causal graph shows the causal relation between two random variables X and Y, where X causes Y if there exists a function f and an unobserved random variable E independent from X. The causal graph is constructed from the structural equations, with the parents of a node representing the causes of that variable. A causal graph represents the relation between variables X and Y in a structural causal model. It is a directed acyclic graph implied by structural equations, with parents of a node representing the causes of that variable. The model includes functions, random variables, exogenous variables, and a probability distribution over the exogenous variables. The joint distribution of observable variables is determined by the distribution of exogenous variables and functional relations. A causal graph D is a directed acyclic graph on nodes V, where a node Xj is a parent of node Xi if Xj is in the domain of function fi. An intervention changes the causal graph by disconnecting node Xi from its parents, denoted as do(Xi = xi). This differs from conditioning on Xi as it does not alter the causal graph. An intervention changes the causal graph by disconnecting a node from its parents. This differs from conditioning on the node as it does not alter the causal graph. The post-interventional distribution can be calculated for a set of nodes in a Bayesian network. After an intervention in a Bayesian network, the post-interventional distribution can be calculated by factorizing the observational distribution. It is not always possible to determine the true causal graph without experiments or additional assumptions. This paper does not focus on learning the causal graph, assuming it is already known. In general, identifying the true causal graph for variables requires experiments or assumptions. This paper focuses on learning a causal model when the causal graph is given, exploring the impact of using a Bayesian network to sample from correct observational distributions. In this section, the paper discusses the use of Bayesian networks to sample from correct observational distributions and the proposal of causal implicit generative models for sampling from both observational and interventional distributions. Generative adversarial networks are also mentioned as a tool for training causal implicit generative models. Generative adversarial networks can be used to train causal implicit generative models by arranging the generator neural network connections to reflect the causal graph structure. This model can represent causal models with a feedforward neural network architecture, using Gaussian distributed variables for the noise terms. A feedforward neural network can represent causal models with a graph structure, using Gaussian distributed variables for the noise terms. Two causal models with the same observational distribution have the same interventional distributions for any intervention. A feedforward neural network can represent causal models with a graph structure, using Gaussian distributed variables for the noise terms. Two causal models with the same observational distribution have the same interventional distributions for any intervention. P V and Q V represent distributions induced on variables in V by P N1 and Q N2. A feedforward neural network G is tied to a causal graph, where P N1 (.), Q N2 (.) are strictly positive densities. Causal implicit generative models are defined as feedforward neural networks consistent with a causal graph. Causal implicit generative models are defined as feedforward neural networks consistent with a causal graph. Adversarial training is proposed for training these models, where the generator neural network aligns with the causal graph. CausalGAN architecture focuses on image generation with binary labels, using a causal controller, labeler, and anti-labeler components. The generator minimizes the labeler loss in this setup. The CausalGAN architecture divides the task of learning a CiGM into two subtasks: training a generative model over the labels and then training a generative model for the images conditioned on the labels. The architecture and loss function ensure that the generator outputs the label conditioned image distributions, assuming the image node is always the sink node of the causal graph for image generation problems. The CausalGAN architecture ensures that the generator outputs label-conditioned image distributions, assuming the image node is the sink node of the causal graph. The Causal Controller model is used for controlling image distribution based on binary labels. The Causal Controller model, known as the Causal Controller, is used to control image distribution based on binary labels. The model employs WGAN to sample from a discrete label distribution, as standard GAN training is not suitable for learning a discrete distribution. The model uses WGAN to sample from a discrete label distribution for learning a CiGM over labels and image variables. A new conditional GAN architecture is designed to generate images based on labels of the Causal Controller, ensuring the optimum generator outputs label-conditioned image distributions. Two separate labeler neural networks, Labeler and Anti-Labeler, are utilized in the process. The new conditional GAN architecture uses a pretrained Causal Controller to generate images based on labels. It includes two separate labeler neural networks, Labeler and Anti-Labeler, to estimate image labels. The generator's objective is to produce realistic images, consistent with labels, and avoid unrealistic image distributions. CausalGAN differs from existing conditional GANs in its approach. The Causal Controller Generator in CausalGAN aims to produce realistic images by competing with the discriminator, ensuring consistency with labels, and preventing label-conditioned mode collapse by using an Anti-Labeler network. This approach differs from traditional conditional GAN architectures. The Anti-Labeler loss in the Causal Controller Generator prevents label-conditioned mode collapse by discouraging the generator from outputting only typical faces for a fixed label combination. This technique helps with faster convergence and is effective for rare label combinations. Results for a single binary label are presented, with the potential for extension to more labels. The data distribution between images and labels is denoted by P r (l, x), while P g (l, x) represents the joint distribution between generator-assigned labels and generated images. The results for a single binary label are presented, with the potential for extension to more labels. P r (l, x) represents the data distribution between images and labels, while P g (l, x) denotes the joint distribution between generator-assigned labels and generated images. The generator loss function in CausalGAN includes label loss terms, GAN loss, and an additional loss term from the discriminator, leading to the optimal generator outputting the class conditional image distribution. This result holds true for multiple binary labels as well. The optimal generator in CausalGAN outputs the class conditional image distribution by incorporating label loss terms, GAN loss, and an additional loss term from the discriminator. This result holds for multiple binary labels as well. The CausalGAN generator, when the Causal Controller samples from the true label distribution and the discriminator and labeler networks operate optimally, samples from the class conditional image distribution. The CausalGAN generator, with optimal discriminator, labeler, and anti-labeler, samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. This architecture is the only one with this guarantee after CGAN. The optimal discriminator for a fixed generator in adversarial network architecture behaves the same as in GAN. The generator minimizes the loss by sampling from class conditional distributions, achieving the global minimum when the generator output matches the class conditional image distribution. This two-stage procedure can train a causal implicit generative model. The global minimum of the virtual training criterion is achieved when the generator output matches the class conditional image distribution. This two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The global minimum of the virtual training criterion is achieved when the generator output matches the class conditional image distribution. In Theorem 1, it is shown that the optimum generator samples from the class conditional distributions given a single binary label. The objective is to extend this result to the case with d binary labels. The Labeler and Anti-Labeler are trained to output 2d scalars, each representing the posterior probability of a label combination given the image. The minimizer of C(G) samples from the class conditional distributions given d labels, as shown in Theorem 2. However, for large d, this architecture may be difficult to implement. An alternative solution is proposed. The proposed alternative architecture extends the single binary label setup by using cross entropy loss terms for each label, requiring Labeler and Anti-Labeler to have only d outputs. While the generator captures each label's posterior distribution, it does not guarantee that the class conditional distributions will be true to the data distribution. The generator captures each label's posterior distribution, but this does not ensure that the class conditional distributions align with the data distribution. However, for practical joint distributions where labels are determined by the image, the joint label posterior will reflect the data distribution. Causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms. In this section, a simple extension of BEGAN is discussed where image labels are fed to the generator for interventional sampling using the Causal Controller. Architecture modifications are made to accommodate this. In this section, a simple extension of BEGAN is discussed where image labels are fed to the generator for interventional sampling using the Causal Controller. Architecture modifications are made to accommodate this, including the use of a Labeler network with dual purposes. The CausalGAN Labeler and Anti-Labeler are trained on the CelebA Causal Graph. Margin modifications are motivated by observations on label and image quality gradients. The Causal Controller is trained first, and the dataset used satisfies the conditions for causal relationships. The Causal Controller was trained on the CelebA Causal Graph, where the dataset meets the conditions for causal relationships. The top row of images shows males and females with mustaches, despite not being seen during training. The bottom row displays only male images, indicating the causal relationship between Male and Mustache in the CelebA Causal Graph. The distribution P(.|Mustache = 1) shows only male images in the CelebA Causal Graph. Despite not being seen during training, the top row displays both males and females with mustaches. Our generative model can sample from interventional distributions and provides guarantees for correct sampling under interventions. The bottom row of images sampled from P(.|Mustache = 1) shows only male images. Our generative model can sample from interventional distributions and provide guarantees for correct sampling under interventions. Intervening/Conditioning on Narrow Eyes label in CelebA Causal Graph with CausalBEGAN shows an increase in the proportion of smiling images when conditioning on Narrow Eyes = 1. Conditioning on Narrow Eyes = 1 increases the proportion of smiling images in the dataset, although the difference may not be statistically significant with only 10 images. Generative models like CausalGAN and CausalBEGAN can produce samples creatively by exploring causality. This research has been supported by various grants and organizations. The research has been supported by various grants and organizations. A structural causal model consists of functions, random variables, exogenous variables, and a probability distribution. The causal graph is a directed acyclic graph based on the functional relations between variables. The causal graph in a structural causal model is a directed acyclic graph based on functional relations between variables. It represents the projection of the joint probability distribution onto observable variables. The Bayesian network captures the causal relationships, with each variable having parents based on functional dependencies. Interventions can be calculated directly from the conditional probabilities and causal graph, assuming causal sufficiency. The causal Bayesian networks allow for direct calculation of interventional distributions from conditional probabilities and the causal graph. The joint data distribution is denoted as P r (l, x) for a binary label l and image x, while P g (l, x) represents the distribution for the label fed to the generator and the generated image x. The optimal discriminator D is determined by a specific formula, and the optimum Labeler is identified based on certain conditions. Theorem 2 generalizes l to a vector. Proposition 2 states the optimal discriminator D for fixed G. Lemma 1 defines the optimum Labeler as D LR (x) = P r (l = 1|x). Lemma 2 defines the optimum Anti-Labeler as D LG (x) = P g (l = 1|x). The definitions assume causal sufficiency with no exogenous variables affecting more than one observable variable. The text discusses the definitions of the optimum Labeler and Anti-Labeler under causal sufficiency, along with the assumptions made in Pearl's model. It also introduces the complete graph \"cG1\" and its reverse graph rcG1. Theorem 1 defines the generator loss when the discriminator, Labeler, and Anti-Labeler are at their optimum, assuming the Causal Controller samples from the true label distribution. The text discusses the global minimum of the virtual training criterion C(G) in relation to the generator output and class conditional image distribution. It explains the relations between the optimum Labeler, Anti-Labeler, and discriminator, and how the Kullback-Leibler divergence is minimized when P g = P d jointly over labels. The text discusses the relations between the optimum Labeler, Anti-Labeler, and discriminator in the context of the virtual training criterion C(G). It explains how the Kullback-Leibler divergence is minimized when P g = P d jointly over labels and images in a causal implicit generative model. The text discusses the generator G in a causal implicit generative model, showing that it is consistent with the causal graph D. It explains how the joint distribution over labels and images is preserved when the generator samples from the true label joint distribution and conditional image distribution. The text explains how the concatenated model serves as a causal implicit generative model for graph D, sampling from true observational and interventional distributions. It addresses the challenge of extending the proof to multiple binary labels and presents two solutions to this issue. The text discusses the challenge of generalizing to a vector of labels in a concatenated model for graph D. Two solutions are presented: (1) estimating the probability of label combinations and (2) using Labelers to estimate probabilities of individual labels to ensure correct joint distribution. The text presents an extension in (1) to estimate label probabilities and discusses the optimum Labeler with respect to loss in (12). It introduces a Lemma and explains the conditions for label combinations to contribute to the expectation. The text discusses the conditions for label combinations to contribute to the expectation in the context of estimating label probabilities and the optimum Labeler with respect to loss. It emphasizes the importance of considering only combinations with strictly positive probability to achieve a finite loss. The optimum Labeler network provides the posterior probability of a label combination given an observed image, with the constraint that coordinates sum to 1 using a softmax function. The Anti-Labeler network solves an optimization problem to estimate label probabilities. The Anti-Labeler network solves an optimization problem to estimate label probabilities, with the constraint that coordinates sum to 1 using a softmax function. The optimum Anti-Labeler has D *LG (x)[j] = P g (l = j|x), showing that it cannot optimize the conditional entropy of labels given the image under this distribution. The generator then solves an optimization problem to sample from the optimal distribution. The generator aims to optimize the conditional entropy of labels given the image, while the Anti-Labeler estimates label probabilities with a softmax function. The generator's optimal distribution is achieved when P g (l, x) = P r (l, x) for the vector of labels. The global minimum of the virtual training criterion C(G) is achieved when P g (l, x) = P r (l, x) for the vector of labels. This is ensured by the optimum Labeler and Anti-Labeler, with the generator objective C(G) minimizing the Kullback-Leibler divergence. Relabeling combinations of binary labels as a 2 d label may be challenging for a large number of labels, so an alternative approach is provided in this section. The Kullback-Leibler divergence is minimized when P(g) = P(d) for labels and images. Relabeling binary labels as a 2d label may be impractical for many labels. The CausalGAN architecture assumes a deterministic relationship between images and labels, ensuring optimal generator sampling from class conditional distributions. The CausalGAN architecture assumes a deterministic function mapping images to label vectors, ensuring optimal generator sampling from class conditional distributions. The global optimal generator is characterized by a virtual training criterion that minimizes the generator loss. The global optimal generator for the CausalGAN architecture is characterized by a virtual training criterion that minimizes the generator loss. To ensure correct conditional sampling, the assumption is made that the image determines all labels. The assumption is made that the image determines all labels, ensuring correct conditional sampling. This is relevant in practice, such as in the CelebA dataset, where labels can be seen as a deterministic function of the image. The lemma states that any discrete joint probability distribution with kronecker delta functions can be represented. The lemma states that any discrete joint probability distribution with kronecker delta functions can be represented as the product of marginals. The joint probability distribution is zero everywhere except at specific points. The joint probability distribution is zero everywhere except at specific points, where it should be 1. Applying the lemma on the conditional distribution shows that the image distributions and marginals are true to the data distribution. The conditional distribution P g (l 1 , l 2 , . . . , l d |x) can be analyzed using Bayes' rule. The joint distribution P g (x, l 1 , l 2 , . . . , l d ) satisfies the condition that every marginal distribution p(l i |x) is a kronecker delta function, leading to a product distribution. This implies that the optimum generator samples from the class conditional image. In this section, an extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from the class conditional image distributions, as shown by the joint distribution satisfying the condition of a product distribution. The central contribution of BEGAN is a boundary equilibrium approach that encourages generator training when the discriminator is near optimum. Label gradients are most informative when image quality is high, leading to the introduction of a new loss and margins reflecting this idea. The proposed extension of BEGAN involves feeding image labels to the generator. A new loss and margins are introduced to reflect the idea that label gradients are most informative when image quality is high. The extension of BEGAN involves incorporating image labels into the generator. A new loss function and margins are introduced to emphasize the importance of label gradients for high-quality image generation. The extension of BEGAN involves incorporating image labels into the generator by introducing a new loss function and margins to emphasize the importance of label gradients for high-quality image generation. A trained Labeler is crucial for meaningful gradients, motivating the introduction of a margin-coefficient tuple (b2, c2). The generator aims to minimize two loss terms, but image quality may suffer as images exploiting the Labeler network may not be realistic. To address this, a new margin of margins term, b3, is introduced, with specific update rules and learning rates for the coefficients. The extension of BEGAN involves incorporating image labels into the generator by introducing a new margin of margins term, b3, to emphasize the importance of label gradients for high-quality image generation. This new term, along with specific update rules and learning rates for the coefficients, aims to improve image quality while training a causal implicit generative model. In Section 4, a GAN was used to train a causal implicit generative model by incorporating the causal graph into the generator structure. The behavior and convergence of causal implicit generative models were investigated on synthetic data with three features arising from different causal graphs. A cubic polynomial computes the value of each node given its parents and an exogenous variable, with results averaged over 20 runs for each model. A cubic polynomial computes the value of each node in a causal model, generating synthetic datasets for different causal graphs. Results are compared in terms of convergence to the true joint distribution, including line, collider, and complete graphs. Additionally, fully connected neural networks are used as generators with no knowledge of causal structure. Fully connected neural networks (f c3, f c5, f c10) are used as generators without knowledge of causal structure, mapping random noise to 3 output variables with 3, 5, or 10 layers. Results are shown in FIG9 for data generated from different causal graphs (line, collider, complete). Convergence behavior of the generator distribution is analyzed based on the structured causal graphs, expecting convergence when the generator matches the true causal graph. The complete graph is expected to work well with all data generation models. The generator's structure is based on the true causal graph, with the ability to generate the joint distribution. Different graph types (complete, line) affect convergence behavior in data generation models. The performance of fully connected networks with 3 or 5 layers is also analyzed. In exploring different graph types in data generation models, the best convergence behavior is seen when using a line graph in the generator architecture. Fully connected networks with 3 layers perform well, but those with 5 and 10 layers perform much worse. The number of layers is crucial for achieving optimal performance, as using the wrong Bayesian network or collider graph can result in worse convergence behavior. Using the wrong causal graph, such as a collider or line graph, leads to worse performance in data generation models. Fully connected generators with 3 and 5 layers show the best performance, while 10 layers result in the worst convergence behavior. Complete and collider graphs achieve decent performance, while line graphs perform the worst and show no convergence behavior. The study evaluates the impact of using different causal graphs on data generation models. Fully connected generators with 3 and 5 layers perform the best, while 10 layers show poor convergence behavior. Line and collider graphs perform poorly and do not show convergence. Adding the correct edges in the causal graph improves the generated distribution accuracy. The study evaluates the impact of using different causal graphs on data generation models. Fully connected generators with 3 and 5 layers perform the best, while 10 layers show poor convergence behavior. Line and collider graphs perform poorly and do not show convergence. Adding the correct edges in the causal graph improves the generated distribution accuracy. The CelebA dataset experiments use a causal graph (G1) where Male and Young labels are treated as independent, but adding the edge Young \u2192 Male improves the learned distribution significantly. The CelebA Causal Graph (G1) is illustrated in FIG6 and using the correct graph gives the closest scatter plot to the original data. The CelebA dataset experiments involve using a causal graph (G1) to analyze the relationship between image labels. The graph cG1 is a completed version of G1, with edges reversed to form rcG1. Comparing the effects of different Bayesian networks on the data, G1 incorrectly generates Male and Young labels independently. Despite this, a reasonable approximation to the true distribution is still learned for {Male, Young} jointly in G1, while a nearly perfect distributional approximation is achieved in cG1. The incorrect Bayesian network G1 generates Male and Young labels independently, leading to inaccurate results. Despite this, both G1 and cG1 produce Causal Controllers that never output the label combination {Female, Mustache}. The Wasserstein GAN with a modified version assures convergence in distribution of the Causal Controller output to the discretely supported distribution of labels. The Lipshitz discriminator ensures convergence in distribution of the Causal Controller output to the discretely supported label distribution. A modified version of Wasserstein GAN with a penalized gradient is used. The learned outputs have \"approximately discrete\" support, as shown in FIG12. The causal controller learns the correct distribution for a pairwise subset of nodes and allows training of reasonable marginal distributions for all labels. The CelebA Causal Graph and completion (cG1) allow training of reasonable marginal distributions for all labels, with no more than a 0.03 difference for the worst label. The Wasserstein Causal Controller performance is tested on a subset of binary labels from the CelebA dataset, using a causal graph for training. The generator learns a mapping from continuous noise to a discrete distribution, ensuring convergence in distribution of the output to the label distribution. The Wasserstein Causal Controller performance is tested on a subset of binary labels from the CelebA dataset using a causal graph. The generator learns a mapping from continuous noise to a discrete distribution, with 96% of samples appearing near 0 or 1. Total variational distance (TVD) shows convergence for CelebA Causal Graph, completion (cG1), and reversed completion (rcG1) towards 0.14. The text discusses the convergence of the total variational distance (TVD) for CelebA Causal Graph, completion (cG1), and reversed completion (rcG1) towards 0.14. It also highlights the implications of incorrect conditional independence assumptions in the causal graph. Additional results on CausalGAN intervention and conditioning on the \"Wearing Lipstick\" label are presented in FIG3 and FIG13. In this section, additional results on CausalGAN intervention and conditioning on the \"Wearing Lipstick\" and \"Narrow Eyes\" labels are presented. The top row shows both males and females wearing lipstick, while the bottom row only shows female images due to conditional probabilities in the dataset. The bottom row of images from the dataset only shows females wearing lipstick, as the conditional distribution indicates P(Male=0|Wearing Lipstick=1) \u2248 1. Intervening on Narrow Eyes does not affect the probability of Smiling, but conditioning on Narrow Eyes=1 increases the proportion of smiling images in the dataset. CausalBEGAN is trained on the CelebA dataset using the CelebA Causal Graph. In this section, CausalBEGAN is trained on the CelebA dataset using the CelebA Causal Graph. Conditioning on Narrow Eyes=1 increases the proportion of smiling images in the dataset. The Causal Controller is pretrained with a Wasserstein loss and used for training the CausalBEGAN model. Removing the margin of margins deteriorates image quality for rare labels. Intervening vs Conditioning on Bald is illustrated for the labels Bald and Mouth Slightly Open in the CelebA Causal Graph. The image quality for rare labels deteriorates. Intervening vs Conditioning on Bald and Mouth Slightly Open is illustrated in the CelebA Causal Graph. Male \u2192 Bald in CelebA Causal Graph, showing both bald males and females. Smiling \u2192 Mouth Slightly Open in CelebA Causal Graph, affecting the probability of Smiling = 1. In this section, additional simulations for CausalGAN are provided. The conditional image generation properties of CausalGAN are demonstrated by sweeping a single label from 0 to 1 while keeping other inputs fixed. Image diversity and mode collapse are examined by showing 256 randomly sampled images. In this section, additional simulation results for CausalBEGAN are presented. The impact of the third margin term on image quality is shown in FIG6, highlighting the importance of this factor. The extension of the scalar \"M\" in BEGAN to \"M complete\" is demonstrated in FIG9, showcasing its monotonically decreasing behavior during training. The CausalBEGAN architecture introduces a scalar \"M complete\" that decreases monotonically during training, as shown in FIG9. It also demonstrates conditional image generation with label sweeps in FIG3, showcasing the generator's discrete function learning. Additionally, the optimization process transitions label interpolation towards a step function. Random sampling is used to display image diversity and prevent mode collapse. The CausalBEGAN architecture introduces a discrete function generator for label input parameters. Random sampling of 256 images is shown to examine mode collapse and image diversity. The approach involves training an implicit causal generative model for labels and images, treating the image as part of the causal graph. One hypothesis is that the discriminator may focus on labels, hindering useful gradients for image generation. The implementation details of CausalGAN and CausalBEGAN are explained, including the use of Wasserstein Causal Controller for generating face labels. The total variation distance (TVD) is used as a metric to evaluate model success, with a gradient penalty estimated by interpolating between real and fake batches. The approach aims to address issues where the discriminator may focus on labels, impeding image generation. The Wasserstein Causal Controller is utilized for generating face labels, with the total variation distance (TVD) used as a metric for model evaluation. The gradient penalty is estimated by interpolating between real and fake batches. The approach allows training the Causal Controller to output discrete labels, with the generator architecture structured based on a causal graph. Training involves 25 Wasserstein discriminator updates per generator update, using stochastic gradient descent with a learning rate of 0.0008. The architecture is based on a causal graph, using uniform noise and 6 layer neural networks. Training involves 25 Wasserstein discriminator updates per generator update, with a learning rate of 0.0008. DCGAN is extended into the Causal GAN framework by adding Labeler networks and a Causal Controller network. 6 generator updates are made for each discriminator update on average. Loss terms contain a single binary label. In the Causal GAN framework, Labeler networks are used to modify loss functions, with 6 generator updates per discriminator update on average. The labeler and discriminator networks are updated concurrently, with loss terms defined for d-dimensional label vectors. This approach differs from the architecture in Section 8.6, as it does not guarantee sampling from class conditional distributions. The labelers determine loss terms for label i in d-dimensional vectors. This approach differs from Section 8.6 as it does not guarantee sampling from class conditional distributions. Swapping the order of terms in cross entropy expressions for labeler losses has improved image sharpness during training in CausalBEGAN. In the implementation of CausalBEGAN, the order of terms in cross entropy expressions for labeler losses was swapped to improve image sharpness during training. Parameter tunings were kept minimal, using the same learning rate for both the generator and discriminator. Customized margin learning rates were also utilized to reflect the asymmetry in how quickly the generator can respond to each margin. In the CausalBEGAN implementation, customized margin learning rates were used to reflect the generator's response to each margin. The model with Anti-Labeler network showed faster convergence and provided more diverse images for rare labels."
}