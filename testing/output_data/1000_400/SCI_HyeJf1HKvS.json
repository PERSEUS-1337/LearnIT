{
    "title": "HyeJf1HKvS",
    "content": "This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs. It uses localized node embeddings computed by a graph neural network to rank soft correspondences between nodes initially. Then, synchronous message passing networks are employed to iteratively re-rank the soft correspondences to achieve a matching consensus in local neighborhoods between graphs. The message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, guiding the re-ranking process. The architecture scales well to large inputs and consistently recovers global correspondences. The method is effective in tasks such as computer vision and entity alignment between knowledge graphs. Our method uses a localized node embeddings graph neural network to establish structural correspondences between graphs, improving upon the current state-of-the-art in tasks like computer vision and entity alignment. Graph matching involves establishing meaningful correspondences between nodes in graphs, crucial for various real-world applications such as cheminformatics and bioinformatics. Graph matching is essential for various real-world applications like cheminformatics, bioinformatics, social network analysis, and computer vision. It has been extensively studied in theory and practice, often using domain-agnostic distances or formulating it as a quadratic assignment problem. Recent advancements in graph matching have seen the emergence of neural architectures to address the issue, adapting to data distribution and incorporating continuous node embeddings for better node semantics understanding. Various neural architectures have been proposed for graph matching and similarity in a data-dependent manner. Graph matching approaches using neural architectures have been developed recently to address the issue of graph similarity. These approaches may struggle with computing similarity scores between whole graphs, rely on inefficient global matching procedures, or fail to generalize to unseen graphs. Graph matching is typically formulated as an edge-preserving quadratic assignment problem. In graph matching, the problem is formulated as an edge-preserving quadratic assignment problem, aiming to find correspondences based on neighborhood consensus to prevent adjacent nodes from being mapped to different regions. The approach considers supervised and semi-supervised matching of graphs while utilizing the intuition of neighborhood consensus. The text discusses the problem of supervised and semi-supervised graph matching using neighborhood consensus as an inductive bias in the model. The proposed deep graph matching architecture is described in detail, aiming to generalize to unseen graph pairs in the supervised setting and utilize complete graph structures in the semi-supervised setting. The proposed deep graph matching architecture consists of two stages: a local feature matching procedure and an iterative refinement strategy using synchronous message passing networks. The feature matching step computes initial correspondence scores based on the similarity of local node embeddings, while the refinement strategy aims to reach neighborhood consensus for correspondences using a differentiable validator for graph isomorphism. The method is scalable to large, real-world inputs. The deep graph matching architecture involves two stages: initial correspondence scores are computed based on local node embeddings similarity, followed by an iterative refinement strategy for reaching neighborhood consensus using a differentiable validator for graph isomorphism. The method is scalable to large, real-world inputs and utilizes a two-stage neighborhood consensus architecture. The deep graph matching architecture involves initial correspondence scores computed based on node embeddings similarity, followed by iterative refinement for neighborhood consensus using a differentiable validator for graph isomorphism. Injective node coloring is transferred between graphs via a neural network, updating based on pair-wise color differences. Local feature matching is modeled by computing similarities between nodes in the source and target graphs. Sinkhorn normalization is applied to obtain correspondence matrices fulfilling constraints. The deep graph matching architecture involves training a shared neural network \u03a8 \u03b81 for source and target graphs to obtain initial soft correspondences. Sinkhorn normalization is used to ensure doubly-stochastic correspondence matrices that meet specific constraints. The network is implemented as a Graph Neural Network (GNN) for localized node representations. The text discusses using a Graph Neural Network (GNN) to obtain localized node representations for feature matching in a deep graph matching architecture. Various operators from geometric deep learning and relational representation learning are utilized to control the properties of extracted features. The text discusses utilizing graph neural networks to detect violations in neighborhood consensus for feature matching in a deep graph matching architecture. Various operators from relational representation learning provide precise control over extracted features. The algorithm aims to iteratively refine correspondences starting from an initial matrix, S(0). The algorithm utilizes graph neural networks to detect violations in neighborhood consensus for feature matching in a deep graph matching architecture. It iteratively refines correspondences starting from an initial matrix, S(0), by passing node functions along soft correspondences. Our consensus method utilizes graph neural networks to map node indicator functions between graphs and improve neighborhood consensus through synchronous message passing. This process iteratively refines correspondences by measuring neighborhood consensus error and feature matching error, optimizing the objective in an end-to-end fashion using stochastic gradient descent. The consensus method uses graph neural networks to refine correspondences by measuring neighborhood consensus error and feature matching error. It optimizes the objective using stochastic gradient descent and distributes global node colorings to resolve ambiguities and false matchings. The process involves trainable updates of correspondence scores based on an MLP and is applied iteratively to improve consensus. The two theorems presented in the curr_chunk demonstrate the effectiveness of using a two-stage approach with a permutation equivariant GNN to measure neighborhood consensus between isomorphic or non-isomorphic graphs. The GNN must satisfy criteria for permutation equivariance and injectivity to provide accurate node embeddings. Theorem 2 highlights the importance of using a permutation equivariant and injective GNN for accurate node embeddings in graph analysis. Common GNN architectures fulfill permutation equivariance, while injectivity can be achieved by using powerful GNNs like the Weisfeiler & Lehman heuristic. Injectivity of graph neural networks is a key topic in recent literature, achieved by using powerful GNNs like the Weisfeiler & Lehman heuristic. The proposed approach relates to classical graph matching techniques, such as the graduated assignment algorithm. The graduated assignment algorithm (Gold & Rangarajan, 1996) is a seminal work in graph matching. It involves iteratively computing new solutions from initial feasible solutions by solving a linear assignment problem. The softassign operator uses sinkhorn normalization on rescaled inputs to encourage integer solutions. The approach approximates the linear assignment problem via sinkhorn normalization and utilizes trainable neural networks for updating correspondence scores. Our approach utilizes trainable neural networks for updating correspondence scores in graph matching, allowing for continuous node and edge features. This deep parameterized generalization of the graduated assignment algorithm is experimentally verified to be beneficial. Our approach utilizes trainable neural networks for updating correspondence scores in graph matching, supporting continuous node and edge features. The algorithm is optimized for scalability to large input domains by sparsifying initial correspondences and reducing memory footprint. Our approach utilizes trainable neural networks for updating correspondence scores in graph matching, supporting continuous node and edge features. The algorithm is optimized for scalability to large input domains by sparsifying initial correspondences and reducing memory footprint. The sparsification process involves computing top k correspondences without storing the dense version of the graph, reducing memory requirements and refining the time complexity of the refinement phase. Additionally, optimizing the initial feature matching loss is crucial for efficient performance. Optimizing the initial feature matching loss is crucial for efficient performance in graph matching. To accelerate this process, sparsified correspondences with ground-truth entries can be used. Node indicator functions can be replaced with randomly drawn node functions to reduce parameter complexity. Empirical verification of this refinement strategy is discussed in Section 4.1. Softmax normalization is proposed as a solution to resolve ambiguities in the refinement strategy for graph matching. It relaxes constraints by applying row-wise softmax normalization, allowing the supervised procedure to naturally address violations. This approach aims to prevent early inconsistent integer solutions and avoid inefficiencies in computation. In the refinement strategy for graph matching, row-wise softmax normalization is proposed to relax constraints and allow the supervised procedure to address violations naturally. This approach aims to prevent early inconsistent solutions and inefficiencies in computation. Additionally, varying the number of refinement iterations for training and testing can speed up runtime and encourage convergence with fewer steps. The proposed method suggests varying the number of refinement iterations for training and testing to speed up runtime and encourage convergence with fewer steps. Empirical results show that decreasing the number of iterations during training does not affect the convergence abilities during testing. The method is validated on synthetic graphs and real-world tasks like supervised keypoint matching and cross-lingual knowledge graph alignment. Our method is implemented in PYTORCH using the PYTORCH GEOMETRIC and KEOPS libraries for efficient processing of sparse mini-batches with GPU acceleration. Optimization is done via ADAM with a fixed learning rate. Hits@k is used to evaluate our model in comparison to previous work. In experiments, optimization is done via ADAM with a fixed learning rate. Hits@k is used to evaluate the model on synthetic graphs, aiming to learn matching for pairs of graphs in a supervised fashion. Training and evaluation are conducted on 1,000 graphs for different configurations. The study involves training and evaluating a graph neural network on Erd\u0151s & R\u00e9nyi graphs with varying node sizes and edge probabilities. The network architecture includes GIN operators with three layers and ReLU activation. Input features are initialized with one-hot encodings of node degrees. Additional experiments test the model's robustness to node addition or removal. The study utilizes a GIN operator with three layers and ReLU activation on Erd\u0151s & R\u00e9nyi graphs. Input features are one-hot encodings of node degrees. A two-stage architecture is proposed to recover correspondences despite increasing structural noise. The study introduces a two-stage architecture that can recover correspondences despite increasing structural noise. The proposed approach outperforms purely local matching and global sinkhorn normalization methods. The benefits of matching consensus and scalability enhancements are highlighted, showing the ability to converge even with non-convergence during training. The study introduces a two-stage architecture that can recover correspondences despite increasing structural noise. The proposed approach outperforms purely local matching and global sinkhorn normalization methods. The benefits of matching consensus and scalability enhancements are highlighted, showing the ability to converge even with non-convergence during training. The refinement strategy operates on sparsified top k correspondences, consistently converging to the perfect solution with increasing k, making it an excellent option to scale the algorithm to large graphs. The study introduces a two-stage architecture that can recover correspondences despite increasing structural noise. It consistently converges to the perfect solution with increasing k, making it an excellent option to scale the algorithm to large graphs. Experiments were conducted on datasets with labeled keypoint locations, resulting in annotated images for training and testing. The study introduces a two-stage architecture for recovering correspondences in datasets with labeled keypoint locations. The PASCALVOC dataset is pre-filtered to exclude difficult objects, while the WILLOW-OBJECTCLASS dataset has consistent orientations for each category. The model is pre-trained on PASCALVOC and fine-tuned on 20 random splits with 20 per-class images used for training. The model is pre-trained on PASCALVOC and fine-tuned on 20 random splits with 20 per-class images used for training. Graphs are constructed via Delaunay triangulation of keypoints, and input features are from a pre-trained VGG16 on IMAGENET. The architecture adopts SPLINECNN as the graph neural network operator, evaluating both isotropic and anisotropic results. The model is pre-trained on PASCALVOC and fine-tuned on 20 random splits with 20 per-class images used for training. Graphs are constructed via Delaunay triangulation of keypoints, and input features are from a pre-trained VGG16 on IMAGENET. The architecture adopts SPLINECNN as the graph neural network operator, evaluating both isotropic and anisotropic results with edge features between node-pairs. The SPLINECNN model uses edge features for normalized relative distances and 2D Cartesian coordinates. It has a kernel size of 5, hidden dimensionality of 256, ReLU non-linearity function, two convolutional layers, dropout with probability 0.5, and a final linear layer. During training, pairs are formed between training examples of the same category, and the model is evaluated by sampling test graph pairs of the same category. Our network architecture includes two convolutional layers, dropout with probability 0.5, and a final linear layer. Training involves forming pairs between examples of the same category and evaluating the model with test graph pairs. Results show superior performance using negative log-likelihood compared to displacement loss. Hits@1 results are presented for PASCALVOC and WILLOW-OBJECTCLASS datasets. The network architecture includes two convolutional layers, dropout, and a linear layer. Training involves forming pairs within the same category and evaluating with test graph pairs. Hits@1 results for PASCALVOC and WILLOW-OBJECTCLASS datasets show superior performance using negative log-likelihood. Isotropic and anisotropic GNNs are evaluated for L \u2208 {0, 10, 20}, with ablation results using \u03a8 \u03b81 = MLP for local node matching. Results in Table 1 and 2 show our refinement strategy outperforms competitors and non-refined baselines. On WILLOW-OBJECTCLASS, the refinement stage reduces initial model errors by half. Starting from a weaker baseline (\u03a8 \u03b81 = MLP) shows improvements of up to 14 percentage points on PASCALVOC. Task-specific isotropic or anisotropic methods are used in the consensus stage. The second stage of the network architecture shows significant improvements, especially when starting from a weaker initial feature matching baseline. Task-specific isotropic or anisotropic GNNs are used for local node matching. The model's generalization capabilities are tested on the PASCALPF dataset, where synthetic graph pairs are generated for training. The model's generalization capabilities are tested on the PASCALPF dataset by following the experimental setup of Zhang & Lee (2019). Synthetic graph pairs are generated for training, with results showing improvements in Hits@1 on the dataset. Our consensus architecture, trained on synthetic examples, outperforms the state-of-the-art results on the PASCALPF dataset. Hits@1 results are shown in Table 3, demonstrating improvements across various categories. Additionally, our model performs well on the DBP15K datasets, linking entities from different knowledge graphs. Our method performs well on the DBP15K datasets, linking entities from Chinese, Japanese, and French knowledge graphs into the English version. Entity input features are obtained using monolingual FASTTEXT embeddings and aligned into the same vector space. The graph neural network operator architecture mostly matches the one proposed in previous works. The study aligns entity input features from different languages using graph neural networks. The architecture involves a three-layer GNN with specific parameters and training using negative log likelihood in a semi-supervised manner. The study uses a three-layer GNN with dimensionality 256 and 32 for initial similarities and alignment refinement. Training is done semi-supervisedly with negative log likelihood. Results show improvement over previous models in all categories. Our approach, utilizing a three-layer GNN with dimensionality 256 and 32 for initial similarities and alignment refinement, outperforms previous models in all categories with gains of up to 9.38 percentage points. The refinement strategy significantly improves Hits@1 of initial correspondences and operates on sparsified top 10 initial correspondences. The scalability of our approach allows for multiple refinement iterations while maintaining large hidden feature dimensionalities, effectively solving challenging real-world problems. The proposed approach utilizes a three-layer GNN with dimensionality 256 and 32 for initial similarities and alignment refinement, outperforming previous models. The method operates on sparsified top 10 initial correspondences and can handle multiple refinement iterations while solving challenging real-world problems. However, a limitation is that when two nodes are assigned the same color by WL, the approach may fail to converge to one of the possible solutions. Identifying correspondences between nodes in graphs has been extensively studied in various domains. Related problems include maximum common subgraph, network alignment, graph edit distance, and graph matching. The approach may fail to converge if two nodes are assigned the same color by WL due to equal neighborhood sets. Adding noise to initial correspondence distributions could resolve ambiguities, but real-world datasets typically have enough feature noise to prevent this scenario. Graph matching techniques have been extensively studied in various domains, with related problems including maximum common subgraph, network alignment, graph edit distance, and graph matching. Recent research has focused on deep graph matching techniques using graph neural networks. The proposed two-stage neural architecture aims to learn node correspondences between graphs in a supervised manner. Detailed discussions on related work in this field are provided in the appendices. The text discusses a two-stage neural architecture for learning node correspondences between graphs, aiming to reach a neighborhood consensus and scale to large input domains. The algorithm was evaluated on real-world datasets and outperformed existing methods. The final optimized algorithm is provided in Algorithm 1. The architecture was evaluated on real-world datasets and consistently improved upon existing methods. The final optimized algorithm is presented in Algorithm 1, which maps neighborhoods around nodes to vectorial representations. The algorithm is as powerful as the WL heuristic in distinguishing graph structures. The algorithm in Algorithm 1 maps neighborhoods around nodes to vectorial representations, distinguishing graph structures as powerful as the WL heuristic. It can distinguish any graph structure from j using injective node colorings, with the ability to describe isomorphisms between T-hop subgraphs. The algorithm in Algorithm 1 distinguishes graph structures using injective node colorings and can describe isomorphisms between T-hop subgraphs. It is a generalization of the graduated assignment algorithm, extended by trainable parameters for refinement. Using trainable neural networks consistently improves results compared to non-trainable methods. The algorithm extends the graduated assignment algorithm with trainable parameters for refinement. Using trainable neural networks consistently improves results compared to non-trainable methods, allowing for the learning of meaningful similarities between node and edge features. This approach also enables the selection of task-dependent GNN operators and the potential use of higher-order GNNs for enhanced theoretical expressivity in future work. The algorithm enhances the graduated assignment algorithm with trainable parameters for refinement, enabling the selection of task-dependent GNN operators and potential use of higher-order GNNs for theoretical expressivity. Experimental validation was done by conducting synthetic experiments similar to Xu et al. (2019b), forming graph-pairs from Erd\u0151s & R\u00e9nyi graphs with varying nodes and edge probabilities. Our consensus stage is robust to node additions or removals, while the first stage struggles with matching. Unmatched nodes do not affect neighborhood consensus error, as they do not receive a color from the functional map. The neural architecture can identify and reduce false positive influences in the refinement stage. In graph theory, the problem of identifying correspondences between nodes in two graphs is studied. The maximum common subgraph isomorphism problem is NP-hard and difficult to approximate. The survey by Kriege et al. (2019b) provides more information on this topic. The problem of finding the largest common subgraph in two graphs is NP-hard, even in trees, unless the subgraph is required to be connected. Most variants of the problem are difficult to approximate with guarantees. Different techniques are used in bioinformatics and computer vision, where it is known as network alignment or graph matching. In bioinformatics and computer vision, network alignment or graph matching is a common problem involving large networks. Techniques used are non-exact and involve minimizing a function for two graphs of order n. Research has focused on minimizing this function using a Frank-Wolfe type algorithm. Equation (12) is equivalent to Equation (1) in terms of optimal solutions. Research has focused on minimizing Equation (12) using a Frank-Wolfe algorithm and projecting the fractional solution. The applicability of relaxation and projection is still not well understood, with only a few theoretical results available. The WL heuristic distinguishes between two graphs if there is no fractional solution that makes the objective function in Equation (12) equal to 0. The Frank-Wolfe algorithm can be modified to achieve this. The WL heuristic distinguishes graphs based on fractional solutions in Equation (12). Various approaches to graph matching exist, including spectral relaxations and random walks. The problem is related to the quadratic assignment problem. The problem of graph matching is closely related to the quadratic assignment problem (QAP). Recent literature considers a weighted version, leading to Lawler's QAP formulation. Zhou & De la Torre proposed factorizing the affinity matrix for computational efficiency. Zhang et al. studied kernelized graph matching. Lawler's QAP involves an affinity matrix of size n 2 \u00d7 n 2 and is computationally demanding. Zhou & De la Torre proposed to factorize the matrix for efficiency. Zhang et al. studied kernelized graph matching using Koopmans-Beckmann's QAP. Swoboda et al. studied Lagrangean decompositions solved by dual ascent algorithms for graph matching tasks. Swoboda et al. (2017) studied Lagrangean decompositions for MAP inference in conditional random fields, using dual ascent algorithms for graph matching tasks. Message passing schedules and update mechanisms leading to state-of-the-art performance were identified. Graph edit distance measures the minimum cost to transform a graph, proposed for pattern recognition tasks over 30 years ago. The graph edit distance is a concept in computer vision that measures the cost to transform one graph into another by adding, deleting, and substituting vertices and edges. It is related to pattern recognition tasks and has been studied for over 30 years. Computation of the graph edit distance is NP-hard and is closely related to the maximum common subgraph problem and the quadratic assignment problem. Various algorithms have been proposed for computing the graph edit distance, with heuristics based on the assignment problem being widely used in practice. The graph edit distance is a concept in computer vision that measures the cost to transform one graph into another. Heuristics based on the assignment problem have been proposed for computing the distance, with algorithms like ISORANK being used for network alignment. The ISORANK algorithm computes node-to-node similarity using a similarity function and graph topology. It then solves the assignment problem using a similarity matrix. Various approaches have been proposed to improve efficiency and support vertex and edge similarities in network alignment. Various techniques have been proposed to improve efficiency and support vertex and edge similarities in network alignment. These methods aim to find an optimal correspondence based on a defined objective function, with recent advancements focusing on learning node and edge similarity functions. In network alignment, the goal is to find optimal correspondences between vertices of two graphs with a limited number of matches. Recent approaches involve learning node and edge similarity functions for specific tasks. Deep graph matching techniques utilize local node feature matchings and cross-graph embeddings to refine correspondences. The method presented in this work focuses on deep graph matching procedures, refining local feature matchings by enforcing neighborhood consistency. Recent research has heavily investigated graph matching in a deep fashion, with various approaches such as supervised deep graph matching networks based on displacement and combinatorial objectives. Recent research has focused on deep graph matching procedures, with approaches like supervised deep graph matching networks based on displacement and combinatorial objectives. Different methods include using node-wise features with dense node-to-node cross-graph affinities, sinkhorn normalization, and a compositional message passing algorithm for point coordinates. However, these approaches struggle to resolve inconsistent neighborhood assignments. In contrast to existing approaches for graph matching, our work introduces a supervised optimal transport method for sets of graphs, allowing for generalization and resolution of inconsistent neighborhood assignments. This method builds on previous work related to Gromov-Wasserstein discrepancy and node embeddings to enhance the matching procedure. In a supervised optimal transport method for sets of graphs, our approach generalizes to unseen instances by learning node embeddings that consider noise in graphs. Other recent works have explored network alignment using different techniques such as CYCLEGANs for aligning NODE2VEC embeddings and utilizing local node embedding similarity for matching. In graph matching, various approaches utilize embeddings to find matchings based on nearest neighbors in the embedding space. Different methods include deep graph models, local and greedy matching procedures, and shared graph neural networks for approximating graph edit distance. These techniques aim to enhance node embeddings within and across graphs for more consistent match correspondences. In graph matching, approaches use embeddings to find matchings based on nearest neighbors in the embedding space. Wang et al. (2018) proposed ordering the correspondence matrix in a breadth-first-search fashion and processing it with traditional CNNs. Wang et al. (2019b) and Xu et al. (2019d) enhance GNN operators by aggregating information from local neighbors and similar embeddings in other graphs. Wang & Solomon (2019) relate finding unknown rigid motion between point clouds to a point cloud matching problem with a differentiable SVD module. In graph matching, Wang et al. (2018) proposed using embeddings for matchings based on nearest neighbors. Xu et al. (2019d) and Wang & Solomon (2019) improve GNN operators by considering local features and cross-graph matching. However, these methods alone may not achieve consistent matchings, but can enhance initial feature matching procedures. Neighborhood consensus methods in computer vision have a history of improving local feature matching results efficiently. A recent deep neural network approach using 4D convolution was proposed, but it cannot be directly applied to the graph domain. Our algorithm improves local feature matching results efficiently by inferring errors on the original graphs, avoiding the computational complexity of applying a GNN on the product graph. The functional maps framework defines continuous maps between function spaces on manifolds and is commonly used in solving tasks related to functional maps."
}