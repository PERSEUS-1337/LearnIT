{
    "title": "rygDeZqap7",
    "content": "Natural language understanding research has shifted towards complex Machine Learning and Deep Learning algorithms, which often outperform simpler models. To address the challenge of limited labeled data, a methodology for extending training datasets and training data-hungry models using weak supervision is proposed. This approach is applied to biomedical relation extraction, a task crucial for drug discovery. Small-scale experiments show consistent performance enhancements of an LSTM network, comparable to hand-labeled data. The optimal setting for applying weak supervision using this methodology is discussed. Extracting information from scientific papers in the biomedical field is crucial but challenging due to unstructured text. Weak supervision can enhance the performance of LSTM networks in extracting this information, with results comparable to hand-labeled data. Storing structured data in a knowledge base can greatly impact tasks like drug design and adverse drug effect detection. Automation of Information Extraction has been pursued to alleviate the manual annotation burden. Automating Information Extraction in the biomedical field is crucial for tasks like drug design and adverse drug effect detection. Efforts have been made to automate the extraction of semantic triples from biomedical abstracts, focusing on relations such as Regulations (CPR) and Chemically Induced Diseases (CID) to aid in faster selection of chemical substances with specific properties. Automating Information Extraction in the biomedical field is crucial for tasks like drug design and adverse drug effect detection. Efforts have been made to automate the extraction of semantic triples from biomedical abstracts, focusing on relations such as Regulations (CPR) and Chemically Induced Diseases (CID) to aid in faster selection of chemical substances with specific properties. Extracting semantic triples involves identifying entities of interest in unstructured text and building a classifier to recognize target relationships. This is particularly important for drug design, safety, and discovery. The focus is on relation extraction in the biomedical field, aiming to automate the process by using weak supervision methodology to train multiple base learners on a small labeled dataset and predict labels for a larger unlabeled dataset. This approach combines ideas from semi-supervised and ensemble learning to address the labor-intensive task of annotating training datasets for relation extraction. The proposed methodology for relation extraction in the biomedical field involves training multiple base learners on a small labeled dataset to predict labels for a larger unlabeled dataset. This approach combines ideas from semi-supervised and ensemble learning to address the labor-intensive task of annotating training datasets. Key contributions include a detailed methodology specific to relation extraction, demonstrating effectiveness in a small-scale experiment, and investigating denoising methods' impact on system performance. The methodology proposed for relation extraction in the biomedical field involves training multiple base learners on a small labeled dataset to predict labels for a larger unlabeled dataset. Key contributions include a detailed methodology specific to relation extraction, effectiveness demonstrated in a small-scale experiment, and investigation of denoising methods' impact on system performance. The literature review discusses information extraction, relation extraction from biomedical text, and semi-supervised and ensemble learning methods. The literature review covers information extraction, relation extraction from biomedical text, and semi-supervised and ensemble learning methods. Information extraction is modeled as fully-, semi-, or un-supervised learning. Unsupervised methods like Open Information Extraction BID4 are used for unstructured extraction, while fully-supervised methods rely on labeled examples. Semi-supervised methods, like bootstrapping algorithms such as DIRPE BID6, leverage both labeled and unlabeled data. Other algorithms include Snowball BID0, KnowItAll BID11, and TextRunner BID4. Recent approaches in semi-supervised learning focus on bootstrapping new data using a combination of learning algorithms. Distant supervision is another method that generates weak labels for unlabeled data in relation extraction tasks by utilizing Knowledge Bases instead of pre-trained classifiers. Despite creating noisy examples, this approach has shown to be beneficial. Our work complements distant supervision by utilizing weak classifiers from such algorithms. Research in biomedical relation extraction is often driven by BioCreative competitions, with a focus on extracting Chemically-induced Diseases at a document-level. The top-performing team in BioCreative V (CID task) used an ensemble approach. Most research on biomedical relation extraction is driven by BioCreative competitions, focusing on extracting Chemically-induced Diseases at document and sentence levels. Teams have used ensembles of Support Vector Machines, LSTM, CNN, and SVMs to improve performance. The best performing team in the CPR task used an ensemble of LSTM, CNN, and SVMs, while the second highest score was achieved with Support-Vector Machines. Overfitting issues were observed with approaches using only Deep Neural Networks due to limited training data. The study aims to combine ensemble methods with semi-supervised learning, a novel approach for this task. Our work combines ensemble learning techniques with semi-supervised learning to improve Machine Learning model performance, especially with Deep Neural Networks. This novel approach aims to take advantage of unlabeled data to enhance generalization and reduce high variance. Despite the potential benefits of combining ensembles with semi-supervised learning, this area has not been thoroughly studied. Ensembles can enhance semi-supervised learning by providing multiple views and improving generalization. Co-training was the first system proposed for this combination, but recent research has shown that complete independence between learners may not be necessary for success. Recent research has shown that complete independence between learners may not be necessary for success in semi-supervised learning. Methods like BID5 and BID25 utilize unlabeled data effectively, while techniques such as co-training and tri-training improve annotation accuracy in functional genomics without manual labeling. Their system learned to accurately annotate data samples in functional genomics and outperform state-of-the-art supervised methods. Tri-training is an extension of co-training to three learners, where two learners agree on the label of a new data point and teach the third learner using this example. Co-forest extends to more learners, with an ensemble system making decisions on re-training using all learners. The base learners in the ensemble system are not used for final prediction, only for generating weak labels, allowing the use of all unlabeled data. The methodology described involves using an ensemble system where base learners are used to generate weak labels but not for final prediction. This approach allows for the utilization of all unlabeled data, contrasting with previous methods that only re-trained with a few high-confidence examples. Additionally, weak supervision and data programming paradigms have influenced the development of this methodology. Weak supervision and data programming paradigms have heavily influenced the development of the methodology, focusing on training models using labels of questionable quality and creating training sets without ground-truth labels. This involves defining weak supervision sources and encoding them into Labeling Functions for each unlabeled data point. The methodology involves defining weak supervision sources and encoding them into Labeling Functions for each unlabeled data point. K weak supervision sources provide labels or abstain from voting, resulting in a vote matrix \u039b. A denoiser uses a probabilistic graphical Generative Model to derive weak labels close to the true labels. Data programming aims to derive weak labels close to true labels using a probabilistic graphical Generative Model. The model incorporates trainable parameters for labeling function accuracy and probability. The structure of the model is a hyperparameter that can be estimated automatically. The methodology involves maximizing the marginal log-likelihood of observed votes occurring under the Generative Model. Predicted label distributions are used as probabilistic weak labels, and a noise-aware discriminative model is trained using these labels for final prediction. Based on weak supervision and data programming, a methodology for semi-supervised learning is proposed to leverage multiple learners. It assumes a gold-labeled training set is available but insufficient for training a complex model. The approach suggests augmenting additional lower quality training data. The methodology proposes leveraging weak supervision and data programming for semi-supervised learning by augmenting lower quality training data. This approach allows for scaling the dataset size using machine learning models of lower complexity as weak supervision sources. In semi-supervised learning, the methodology involves adapting an existing pipeline to similar tasks with minimal additional effort. It requires a labeled training set, an unlabeled dataset drawn from the same distribution, a validation set for hyperparameter tuning, and a test set for evaluation. Multiple base learners are trained on the task by maximizing individual performance and capturing different views of the data. Various design choices, such as sentence pruning, lead to the creation of 162 base learners. To produce multiple learners, varying hyperparameters and design choices are used in the relation extraction pipeline, resulting in 162 base learners. The most important design choices include sentence pruning and sequential features. Sentence pruning involves keeping only relevant words between entities of interest or within a certain window, while sequential features focus on capturing different views of the data. In this work, various approaches are explored for relation extraction, including whole sentences, window sizes, and Shortest Dependency Path. Sequential features like tri-grams are used, and text representation is done through token occurrences or TF-IDF weights. Different machine learning algorithms such as Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTM Networks, and CNNs are employed on the feature matrix. Machine learning algorithms like Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTM Networks, and CNNs are used on the feature matrix. After producing the base learners, a subset is selected to maximize individual performance and diversity. Some feature engineering steps are not applicable when using LSTM & CNN models. The base learners are selected to maximize individual performance and diversity by discarding classifiers below a performance threshold. A similarity-based clustering method is used to select the most diverse classifiers. The base learners are selected based on performance and diversity, with a clustering method used to choose the most diverse classifiers. A similarity-based clustering method is employed to select diverse classifiers, using a KxK similarity matrix and K-means clustering. The number of clusters is determined using the silhouette score coefficient. The selected base learners predict labels for D U, creating a KxM prediction matrix. To select diverse base learners, a clustering method is used to choose classifiers closest to cluster centroids. The silhouette score coefficient helps determine the number of clusters. Base learners predict labels for D U, creating a prediction matrix. A denoiser reduces the vote matrix into weak labels. Different denoisers are considered, including Majority Vote and Average Vote. A discriminative model is used as a meta-learner in the final step. In practice, training the meta-learner with weak supervision sacrifices label quality for quantity, which can be beneficial when the meta-learner's performance is limited by the training set size. High-capacity models like Deep Neural Networks are used as meta-learners to learn their own features and improve accuracy by leveraging a larger, albeit noisy, training dataset. The experiments are conducted using part of the functionality of Snorkel, a framework designed for relation extraction. In experiments using part of Snorkel's functionality, high-capacity models like Deep Neural Networks are employed as meta-learners to learn their own features and improve accuracy by leveraging a larger, albeit noisy, training dataset. The official BioCreative CHEMPROT and CDR datasets BID15 are used, consisting of annotated PubMed abstracts split into training, development, and test sets. The methodology requires three gold-labeled datasets and a held-out test set, with the original test sets used as the held-out test set. The original training and development sets are merged and shuffled to create the remaining three datasets for training the base model. The methodology requires three gold-labeled datasets and a held-out test set. The original training and development sets are merged and shuffled to create three datasets for training the base model. This setup ensures no bias in document selection and uniform pre-processing steps for all documents. The methodology involves using a setup to ensure no bias in document selection and uniform pre-processing steps for all documents. This controlled approach allows for comparison of the meta-learner's performance with weak supervision to optimal performance with ground-truth labels. Text pre-processing is mainly done using SpaCy (v1.0), an open-source NLP library. The text pre-processing pipeline involves using SpaCy for tasks like sentence splitting, tokenization, and dependency parsing. Named Entity Tags are manually annotated for candidate extraction, focusing on relationships within the same sentence. Snorkel is used for candidate extraction and mapping to ground-truth labels. The text pre-processing pipeline involves using SpaCy for tasks like sentence splitting, tokenization, and dependency parsing. Named Entity Tags are manually annotated for candidate extraction, focusing on relationships within the same sentence. Snorkel is used for candidate extraction and mapping to ground-truth labels. In the Candidate Extraction step, relationship candidates are identified within the same sentence using Snorkel. Entities of interest are replaced with tokens like 'ENTITY1' and 'ENTITY2' for prediction, along with 'CHEMICAL', 'GENE', or 'DISEASE' for additional entities of the same type. A bi-directional Long-Short Term Memory network is used for Natural Language tasks. In our experiments, we use a bi-directional Long-Short Term Memory network for Natural Language tasks. We employ random under-sampling for class balance and explore different hyperparameter settings. The research questions we aim to answer are discussed, with more details provided in subsequent subsections. In our experiments, we use a bi-directional Long-Short Term Memory network for Natural Language tasks. We employ random under-sampling for class balance and explore different hyperparameter settings. The research questions we aim to answer are discussed in this section, focusing on enhancing biomedical relation extraction using Machine Learning classifiers as sources of weak supervision and determining the optimal setting for using weak supervision on this task. The related literature suggests that adding weakly labeled data can improve the performance of the meta-learner, with the performance expected to improve quasi-linearly as the amount of weakly labeled data increases. The performance of the meta-learner BID30 improves with labeled data, and as weakly labeled data increases, performance is expected to improve quasi-linearly. Weak supervision sources need to have accuracy better than random guess, overlap, disagree enough, and capture diverse 'views' of the problem. Machine Learning classifiers have not been used as weak supervision sources in this setting before. Machine Learning classifiers have not been used as weak supervision sources in this setting before. To evaluate whether weak supervision helps, experiments were conducted under different setups to compare the performance of the meta-learner trained on full-supervision, weak-supervision, and a combination of both. The goal is to determine if weak-supervision can achieve results comparable to full-supervision. The study evaluates the performance of a meta-learner trained on full-supervision, weak-supervision, and a combination of both. It aims to determine if weak-supervision can achieve results comparable to full-supervision by examining the number of base learners and the quality of weak labels used in training. The study examines the impact of increasing the number of Base Learners on performance while using weak labels and a meta-learner. The denoising component is crucial for determining the quality of weak labels. Different denoising methods are used to assess the results, which can produce binary or marginal weak labels with varying distributions. An error analysis is conducted to understand the effect of weak labels on training and final performance. Subsections address the use of supervised machine learning classifiers as weak classifiers and their impact on the meta-learner's performance. The study investigates the impact of different distributions of weak labels on the training and final performance of a meta-learner. It explores the use of supervised machine learning classifiers as weak classifiers and the optimal setting for applying weak supervision. The selection of base learners is based on a specific strategy, and experiments are conducted with varying numbers of base learners to maximize silhouette scores. Performance comparisons are made between weak supervision and full supervision. Training the meta-learner with weak labels results in improved performance compared to training with fewer gold labels. Including ground-truth labels further enhances performance. Weak supervision can achieve comparable performance to full supervision, almost as good as using ground-truth data. Including ground-truth labels enhances performance when using weak supervision. Weak supervision can achieve comparable results to full supervision, sometimes even slightly better. However, differences are minor and not statistically significant due to high variance in meta-learners' performance. Majority Vote often outperforms the meta-learner, which is an expected result. The under-sampled training set size of the final learner in weak supervision was larger due to undersampling based on weak labels. Majority Vote can outperform the meta-learner, as shown by the model (LSTM) unable to outperform Majority Voting with a small training dataset. Learning curves of the meta-learner with weak labels show improved performance, with statistically significant results indicated by confidence intervals. The learning curves of the meta-learner with weak labels show improved performance, with statistically significant results indicated by confidence intervals. The F1 score on the training set is higher than the test score, suggesting overfitting. Additional training data is needed to improve the meta-learner's performance. The small dataset size limits definitive conclusions, but analysis based on experimental results will be discussed. The performance of the meta-learner is analyzed based on experimental results. The F1 score of weak Majority Vote labels for 5 learners is the lowest. The meta-learner performs better with more than 10 base learners compared to only 5. Performance slightly improves with an increase in base learners when using Generative model marginals. The meta-learner's performance is analyzed with different weak label distributions. When trained with Average Marginals, it consistently outperforms other methods. Generative Model marginals show improvement in performance compared to Majority Vote weak labels, except for one case. GM marginals depend on hyperparameters chosen based on F1 score validation, but this measure may not fully reflect performance under various weak label distributions. The Generative Model marginals, dependent on hyperparameters chosen for F1 score validation, may not fully reflect performance under different weak label distributions. Marginal weak labels improve meta-learner performance compared to binary labels, with marginals following a U-shaped distribution close to 0 or 1, unlike average marginals spread more uniformly. The Generative Model tends to create marginals following a U-shaped distribution close to 0 or 1, unlike average marginals which are more uniformly spread. Error analysis on the validation set shows that Average Vote labels have higher quality, with misclassified labels closer to 0.5. The F1 score is deemed unsuitable for evaluating marginal weak labels. Training loss and validation scores change as the LSTM is trained for more epochs. The training loss and validation scores change as the LSTM is trained for more epochs. When using marginal labels, the training error remains high, especially with Average weak marginals. It only takes a few epochs for the LSTM to accurately predict binary training labels. Training with marginal labels is like a regression problem, where the model predicts an exact number and is penalized for errors. The distributions of predicted logits are also observed. In practice, training with marginal labels is akin to a regression problem where the model predicts an exact number and is penalized for errors. The predicted logits become more spread as the training marginals distributions become more uniform, resembling regression rather than classification. Efforts are made to apply this methodology on the CPR task, expanding datasets with both labeled and unlabeled data. The performance of the meta-learner decreases with the addition of weakly labeled data, indicating issues with data quality. In applying the methodology on the CPR task, the meta-learner's performance decreases with the addition of weakly labeled data, suggesting issues with data quality. An imbalance in class distribution is observed in the outgoing citations dataset compared to the original, indicating different dataset distributions. Validation using the t-SNE algorithm reveals that the new dataset is unsuitable for the task. The t-SNE algorithm BID20 was used to validate the unsuitability of the new dataset for the task at hand. Weak supervision can enhance the performance of complex models by utilizing unlabeled data and multiple base learners. The proposed methodology is feasible and successful in defining a combination of base learners to take advantage of additional data. The proposed methodology utilizes deep neural networks and multiple base learners to leverage unlabeled data effectively. By shifting human effort from hand-labeling to feature engineering, diverse learners can be constructed to scale training datasets and improve performance in supervised learning. The methodology shifts human effort from hand-labeling to feature engineering and constructing diverse learners, allowing for scaling training datasets and improving performance in supervised learning. It can be re-used on similar tasks with appropriate datasets, eliminating the need for repeated hand-labeling. Further exploration is needed to construct a large unlabelled dataset to enhance metalearner performance and draw stronger conclusions. Further exploration is crucial to construct a large unlabelled dataset to improve metalearner performance and draw stronger conclusions on research questions. Collecting an appropriate unlabeled dataset is challenging, and semi-supervised algorithms should not assume its existence. The importance of defining an appropriate unlabeled dataset for semi-supervised algorithms is highlighted. It is crucial to establish a more suitable evaluation metric than the F1 score for weak labels. Additionally, exploring different approaches such as using pre-trained word embeddings for the meta-learner and optimizing hyperparameters of the Generative Model can significantly impact performance. The importance of optimizing hyperparameters of the Generative Model and exploring different approaches for the meta-learner, such as using pre-trained word embeddings, is emphasized. Further investigation areas include defining a more appropriate selection method for Base Learners and examining the behavior of the system when Base Learners abstain from voting on uncertain examples. This could provide a modeling advantage for the Generative Model compared to unweighted methods like Majority Voting. One approach to improve the Generative Model is to delete votes near the classification boundary or set a minimum confidence threshold for voting. This can give the Generative Model an advantage over unweighted methods like Majority Voting."
}