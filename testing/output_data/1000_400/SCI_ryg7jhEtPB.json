{
    "title": "ryg7jhEtPB",
    "content": "The importance weighted autoencoder (IWAE) is a variational-inference method that achieves a tighter evidence bound than standard variational autoencoders by optimizing a multi-sample objective. This method relies on reparametrizations and deals with breakdowns in inference-network gradients as the number of samples increases. Different approaches, such as 'sticking-the-landing' IWAE (IWAE-STL) and 'doubly-reparametrised' IWAE (IWAE-DREG), have been proposed to address these issues. The importance weighted autoencoder (IWAE) method addresses breakdowns in inference-network gradients by removing high-variance score-function terms. This can be done heuristically or through an identity, resulting in IWAE-STL and IWAE-DREG gradients. Directly optimizing the proposal distribution in importance sampling is preferred over IWAE-type multi-sample objectives. An adaptive-importance sampling framework called AISLE is introduced, which generalizes the reweighted wake-sleep (RWS) algorithm. AISLE encompasses IWAE-STL and IWAE-DREG as special cases. The AISLE framework generalizes the RWS algorithm and includes IWAE-STL and IWAE-DREG as special cases. It focuses on variational inference algorithms to learn the generative model and construct a tractable variational approximation. The generative model aims to find a value \u03b8 close to the maximum-likelihood estimate. A tractable variational approximation q \u03c6,x (z) of p \u03b8 (z|x) is constructed. The setting assumes a single latent representation-observation pair and no shared parameters between the generative model and the variational approximation. The framework covers amortised inference and refers to \u03c6 as the parameters of an inference network. The generative model aims to find a value \u03b8 close to the maximum-likelihood estimate. No parameters are shared between the generative model and the variational approximation. The setting covers amortised inference and refers to \u03c6 as the parameters of an inference network. Stochastic gradient-ascent algorithms for optimising \u03c8 := (\u03b8, \u03c6) using Monte Carlo samples have been proposed. IWAE-DREG removes problematic score-function terms from the IWAE \u03c6-gradient. RWS optimises two separate objectives. The IWAE-DREG method removes biased score-function terms from the IWAE objective, while the RWS algorithm optimizes two separate objectives for \u03b8 and \u03c6 using self-normalized importance sampling. RWS iteratively improves its proposal distribution and optimizes \u03b8 via stochastic approximation, with \u03c6-gradients that do not degenerate as K \u2192 \u221e. In contrast to the IWAE-DREG method, the RWS algorithm optimizes separate objectives for \u03b8 and \u03c6 using self-normalized importance sampling. RWS iteratively improves its proposal distribution and optimizes \u03b8 via stochastic approximation, with \u03c6-gradients that do not degenerate as K \u2192 \u221e. The IWAE method suffers from \u03c6-gradient breakdown and exhibits inferior empirical performance compared to RWS. The preference between the multi-sample objective approach of IWAE and the adaptive importance-sampling approach of RWS remains unclear. In this work, it is shown that directly optimizing the proposal distribution, as done by RWS, is preferable to optimizing the IWAE multi-sample objective. The IWAE method can suffer from \u03c6-gradient breakdown, making it inferior to RWS, especially for discrete latent variables. This conclusion complements previous findings by Le et al. (2019) and is based on formalizing the argument that reparametrizations in IWAE can lead to inferior performance compared to RWS. Our work formalizes the argument that reparametrizations in IWAE can lead to inferior performance compared to RWS. We introduce the AISLE framework, a generic adaptive importance-sampling framework for variational inference. AISLE admits RWS, IWAE-DREG, and IWAE-STL gradients as special cases, ensuring non-degeneracy as K \u2192 \u221e. The AISLE framework introduces novel material in Section 3, deriving various gradient estimators in a principled manner. It establishes connections such as recovering the IWAE-STL gradient as a special case of AISLE, providing a theoretical foundation for IWAE-STL previously only heuristically justified. Our work provides a theoretical foundation for IWAE-STL and proves that AISLE admits the IWAE-DREG gradient as a special case. The learning rate for IWAE \u03c6-gradient should be scaled as O(K), while AISLE does not require scaling with K. AISLE leads to a new family of gradient estimators for \u03b1-divergences. AISLE does not require scaling the learning rate with K, unlike IWAE-DREG. It introduces a new family of gradient estimators for \u03b1-divergences. The focus is not on deriving new algorithms but on comparing existing ones empirically. The focus of the work is not to derive new algorithms but to compare existing ones empirically. The shorthand notation p(f) is used to suppress dependence on the observation x. Expectations of test functions can be estimated using unbiased estimators. The expectation of a test function can be estimated using unbiased estimators, such as the importance weighted autoencoder (IWAE) introduced by Burda et al. (2016). The IWAE seeks to find the generative-model parameters \u03b8. The importance weighted autoencoder (IWAE) seeks to maximize a lower bound on the log-marginal likelihood by optimizing the inference-network parameters \u03c6 and the number of samples, K \u2265 1. As K \u2192 \u221e, the evidence bound tightens, and for K > 1, the IWAE differs from the variational autoencoder (VAE). The IWAE tightens the evidence bound by optimizing the inference-network parameters \u03c6 and the number of samples, K. For K > 1, it constitutes another VAE on an extended space based on an auxiliary-variable construction. The gradient of the IWAE objective involves approximating an intractable quantity E G \u03c8 (z) using a Monte Carlo approach, but this often leads to impractically noisy results. The reparametrisation trick is commonly used to address this issue. The IWAE objective involves approximating an intractable quantity using a Monte Carlo approach, which can be noisy. The reparametrisation trick is used to address this issue by making certain assumptions. The IWAE uses a Monte Carlo estimate and the reparametrisation trick to address noise in approximating intractable quantities. Lemma 1 generalises the identity q \u03c6 (\u2207 \u03c6 log q \u03c6 ) = 0. The IWAE gradient has drawbacks related to high-variance terms and reliance on reparametrisations. The \u03c6-gradient in IWAE faces challenges such as high-variance terms and vanishing signal-to-noise ratio. Reparametrisations are needed to address these issues, but alternative approaches like control-variate methods or continuous relaxations come with additional costs. Modifications have been proposed to avoid scorefunction terms and achieve stability. The IWAE gradient faces challenges with high-variance terms and a vanishing signal-to-noise ratio. Modifications like IWAE-STL and IWAE-DREG have been proposed to avoid scorefunction terms and achieve stability. The IWAE-DREG gradient proposed by Tucker et al. (2019) removes score-function terms through Lemma 1, allowing for stable optimization of both \u03b8 and \u03c6 simultaneously. The RWS algorithm by Bornschein & Bengio (2015) approximates intractable quantities using self-normalised importance sampling, reducing bias in the gradients. The RWS algorithm approximates intractable quantities using self-normalised importance sampling, reducing bias in the gradients. The optimization of both \u03b8 and \u03c6 is carried out simultaneously, allowing both gradients to share the same particles and weights. However, the lack of a joint objective for both \u03b8 and \u03c6 is seen as a drawback. The self-normalised importance weights are transformed using the function F(w) := w(1 \u2212 w), mainly supported on the two particles with the largest weights. Optimizing \u03c6 can reduce error in approximating the \u03b8-gradient. Adapting the proposal distribution in importance-sampling schemes may not always involve minimizing the KL-divergence. Other techniques like minimizing the \u03c7 2 -divergence exist in the literature. Importance-sampling schemes can be based on various techniques, not just minimizing the KL-divergence. Another popular approach is minimizing the \u03c7 2 -divergence. The RWS-objective is slightly generalized, and alternative approaches for optimizing \u03c6 are possible. The resulting algorithm is called adaptive importance sampling for learning (AISLE). This unified framework allows for a straightforward approach. The unified framework of adaptive importance sampling for learning (AISLE) allows for a principled derivation of robust \u03c6-gradient estimators that do not degenerate as K \u2192 \u221e. Optimization is done through stochastic gradient ascent, with the \u03b8-gradient being the same for all algorithms discussed. The IWAE paradigm sees it as an unbiased gradient of a biased lower-bound to the evidence, while AISLE interprets it as a self-normalized importance-sampling approximation of the gradient \u2207 \u03b8 log Z \u03b8 for the 'exact' objective. The IWAE paradigm and AISLE interpret the gradient differently, with IWAE seeing it as unbiased and AISLE as biased. Integrals involving \u03c0 \u03b8 ([F \u2022 w \u03c8 ]\u2207 \u03c6 log q \u03c6 ) can be approximated using the vanilla Monte Carlo method. Most \u0192-divergences used in variational inference have a function f with an exponent \u03ba and constant C(\u03b8) independent of \u03c6 for optimization. The \u0192-divergences used in variational inference have a bias of order O(K \u22121 ) and a standard deviation of order O(K \u22121/2 ). These divergences can be optimized without knowing Z \u03b8, using self-importance sampling and reparametrised estimators. KL divergence is a specific case of these divergences. The text discusses importance-sampling approximation in variational inference, reparametrised estimators, and the derivation of IWAE-STL from AISLE without the need for a multi-sample objective. The text discusses the derivation of IWAE-STL from AISLE without the need for a multi-sample objective, providing a theoretical basis for IWAE-STL and highlighting its good empirical performance. The text discusses the derivation of IWAE-STL from AISLE without the need for a multi-sample objective, providing a theoretical basis for IWAE-STL and highlighting its good empirical performance. The \u03b1-divergence between two distributions p and q is given by Z (p(z)/q(z)) \u03b1 q(z) dz for some \u03b1 > 1. AISLE-KL is derived by applying Lemma 1 to the exact \u03c6-gradient and then approximating the expression to reduce bias and variance. The \u03b1-divergence between distributions p and q is expressed as Z \u03ba \u03b8 Zf (w \u03c8 (z))q \u03c6 (z) dz with \u03ba = \u2212\u03b1 and f (y) = y \u03b1. Minimizing this divergence is important in importance sampling. AISLE-\u03b1-NOREP and AISLE-\u03b1 are discussed without reparametrisation, with Equation (13) yielding a special case proportional to the 'score gradient'. The importance of minimizing the \u03c72-divergence in importance sampling is highlighted in AISLE-\u03b1-NOREP and AISLE-\u03b1. Reparametrisation is used in Equation (12) to derive IWAE-DREG, showing the relationship between AISLE and IWAE. The learning rate scaling for IWAE or IWAE-DREG \u03c6-gradients is discussed, emphasizing the importance of normalizing gradients for equivalence to IWAE-DREG. The need for a multi-sample objective is discussed, highlighting the importance of normalizing gradients for equivalence to IWAE-DREG. The 'exclusive' KL-divergence is explored, showing a faster convergence of \u03c6 compared to the 'inclusive' KL-divergence. This approximation is recognized as a simple average over K independent replicates of the 'sticking-the-landing' estimator for VAEs. The 'exclusive' KL-divergence can lead to faster convergence of \u03c6 than the 'inclusive' KL-divergence. However, minimizing the exclusive divergence may negatively affect learning of \u03b8 due to potential issues with importance weights. The adaptive-importance sampling paradigm of reweighted wake-sleep (RWS) is preferred over the multi-sample objective paradigm of importance weighted autoencoders (IWAEs). The adaptive-importance sampling paradigm of reweighted wake-sleep (RWS) is preferred over the multi-sample objective paradigm of importance weighted autoencoders (IWAEs) due to its ability to achieve all the goals of the latter while avoiding its drawbacks. The self-normalised importance-sampling approximation with varying number of particles provides insights into the estimators \u2207 aisle-kl \u03c6 \u03b8, z and \u2207 aisle-\u03c7 2 \u03c6 \u03b8, z. The self-normalised importance-sampling approximation with varying number of particles provides insights into the estimators \u2207 aisle-kl \u03c6 \u03b8, z and \u2207 aisle-\u03c7 2 \u03c6 \u03b8, z as they become increasingly accurate approximations with more particles. For K = 1, these estimators reduce to vanilla Monte Carlo approximations. The use of IWAEs instead of VAEs allows for self-normalised importance-sampling approximations with multiple particles to reduce bias in the \u03b8-gradient. The small-K self-normalisation bias of AISLE gradients favors minimizing the exclusive KL-divergence. The use of self-normalised importance-sampling approximations with multiple particles in IWAEs reduces bias in the \u03b8-gradient by ensuring q \u03c6 is close to \u03c0 \u03b8. The error can be controlled by minimizing the 'inclusive' KL-divergence KL(\u03c0 \u03b8 q \u03c6) in the variational family Q. The family of proposal distributions Q, indexed by \u03c6, can be flexible or insufficiently expressive. If Q is sufficiently expressive, minimizing the exclusive KL-divergence can yield well-behaved importance weights. If Q is not flexible enough, all members may be far from \u03c0 \u03b8. In cases where the family of proposal distributions Q is not flexible enough, minimizing the exclusive KL-divergence may lead to poorly-behaved importance weights. It is important to optimize \u03c6 to minimize the exclusive divergence in such scenarios. In some cases, using a gradient-descent algorithm to minimize the exclusive divergence can be more beneficial than minimizing the inclusive divergence, as it may lead to faster convergence. Using a gradient-descent algorithm to minimize the exclusive divergence can be preferable over minimizing the inclusive divergence, as it may result in faster convergence. In some scenarios, a smaller number of particles K could be more suitable for certain \u03c6-gradients due to the self-normalization bias outweighing the standard deviation, potentially favoring faster convergence. Increasing K is still desirable to reduce the variance of gradient approximations, even if setting K = 1 may not be optimal. Increasing the number of particles K is desirable to reduce gradient approximation variance, even in scenarios where setting K = 1 may not be optimal. Using all K particles and weights for gradient approximation is more efficient, as not doing so would be wasteful. If K = 1, certain \u03c6-gradients result in vanilla Monte Carlo estimates of 0. The text discusses different \u03c6-gradient estimators for AISLE, comparing AISLE-KL-NOREP and AISLE-KL. The former is based on the KL-divergence without reparametrisation, while the latter involves reparametrising and exploiting an identity from Lemma 1. The gradient for AISLE can be computed using different divergences such as KL and \u03c7 2, with or without reparametrisation. These gradients do not require R1 but may not achieve zero variance even if q \u03c6 = \u03c0 \u03b8. The normalization of gradients is also discussed. The gradient for AISLE based on the \u03c7 2 -divergence after reparametrising and exploiting the identity from Lemma 1 is proportional to IWAE-DREG from Tucker et al. (2019). The gradient for IWAE employing the reparametrisation trick from Kingma & Welling (2014) degenerates with K and cannot achieve zero variance even if q \u03c6 = \u03c0 \u03b8. IWAE-DREG, the 'doubly-reparametrised' IWAE gradient from Tucker et al. (2019), is proportional to AISLE-\u03c7 2. The 'doubly-reparametrised' IWAE gradient from Tucker et al. (2019) is proportional to AISLE-\u03c7 2. The 'doubly-reparametrised' RWS \u03c6-gradient is given in (8). The joint law of observations and latent variables factorises as each latent variable-observation pair is modeled. The proposal is taken for any \u03b8. The generative model, parametrised by \u03b8, factorises as each latent variable-observation pair is modeled. The proposal distributions are fullyfactored Gaussians. The parameters to optimize are denoted by A. The model is similar to benchmarks in previous studies. In a more realistic scenario, the latent vectors z can be correlated under the generative model, while the variational approximation remains fully factored. This may lead to uncertainty about the latent variables. The proposal distribution coincides with the posterior if certain conditions are met. The model is similar to benchmarks in previous studies. In a more realistic scenario, latent vectors z can be correlated under the generative model. The variational approximation may fail to fully capture uncertainty about the latent variables. The 'score-function free' \u03c6-gradients achieve near zero variance for proposal mean parameters. The 'score-function free' \u03c6-gradients achieve near zero variance for proposal mean parameters in the model. Empirical comparisons of algorithms are conducted with varying numbers of particles and model dimensions. The study compares algorithms with different numbers of particles and model dimensions, using new synthetic data sets. The focus is on optimizing \u03c6 while fixing \u03b8. Two model settings are explored, one with a specific generative model and another where the variational approximation struggles to mimic the latent variable dependence structure. The study compares algorithms with different numbers of particles and model dimensions, using new synthetic data sets. The generative model is specified in two scenarios, one where q \u03c6,x (z) = \u03c0 \u03b8,x (z) and another where the variational approximation cannot fully mimic the dependence structure of the latent variables. The gradient-ascent algorithm is initialized with IID standard normal distribution values for \u03c6 0 and uses stochastic gradient-ascent and ADAM optimization methods. The study compares algorithms using different particles and model dimensions on new synthetic data sets. The gradient-ascent algorithm is initialized with IID standard normal distribution values for \u03c6 0 and uses stochastic gradient-ascent and ADAM optimization methods. The total number of iterations is 10,000 with learning-rate parameters at the ith step being i \u22121/2. The covariance matrix is not diagonal, with a logarithmic scaling on the second axis."
}