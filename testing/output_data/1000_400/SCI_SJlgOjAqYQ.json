{
    "title": "SJlgOjAqYQ",
    "content": "We conducted experiments on convolutional and capsules neural networks to test global translation-invariance in deep learning models trained on the MNIST dataset. Both models initially showed poor performance in this aspect, but data augmentation improved their performance. While the capsule network performed better on the MNIST testing dataset, the convolutional neural network generally had better translation-invariance performance. The success of convolutional neural networks (CNN) in computer vision tasks is attributed to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. The success of CNN in computer vision tasks is attributed to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. Capsule networks, on the other hand, aim for 'rate-coded' equivariance by including pose, color, lighting, and deformation of visual entities in groups of neurons called capsules. Capsule networks are robust in dealing with different viewpoints and aim to code viewpoint-invariant knowledge through weights, not neural activities. Capsule networks are robust in dealing with different viewpoints and aim for 'rate-coded' equivariance by including pose, color, lighting, and deformation of visual entities in groups of neurons called capsules. The network's viewpoint changes are linear effects on pose matrices between different layers, but it is unclear if they can generalize for global translation invariance. Understanding translation invariance in deep learning models is essential for developing generalization models that are invariant to viewpoint changes. The curr_chunk discusses the testing of global translation invariance in convolutional and capsule neural network models trained on the MNIST dataset using a simple method with a testing dataset. The GTI testing dataset consists of images generated by shifting the centre of mass of a Helvetica font digit one pixel at a time. The size of the testing images is 28 \u00d7 28, the same as MNIST images. The deep learning model trained on the MINST data is tested using a simple testing dataset. The GTI testing dataset consists of images generated by shifting the centre of mass of a Helvetica font digit one pixel at a time. The testing images are 28 \u00d7 28 in size, covering all possible cases of translational translations. The deep learning models are trained on the MNIST dataset with 60000 samples and tested on both MNIST and GTI testing datasets. The GTI dataset distributes images uniformly on the canvas compared to the MNIST dataset where images are located at the centre of the canvas. The CNN model with nine layers is robust to random noise in the MNIST dataset and benefits from the smaller GTI training dataset. The GTI dataset allows for quantifying global invariance and testing model accuracy in dealing with translational invariance. The CNN model with nine layers, including convolutional and fully connected layers, has 361578 parameters and uses ReLU activation except for the softmax in the last layer. The GTI dataset helps quantify global invariance and test model accuracy in dealing with translational invariance. The CNN model has fully connected layers with sizes 256, 128, and 10, with a total of 361578 parameters. Dropout is applied to certain layers, ReLU activation is used except for the last layer, and Adam optimizer with cross entropy loss is employed. The model achieves high accuracy on the MNIST dataset but performs poorly on the GTI dataset, indicating challenges with global translational invariance. The CNN model trained on the MNIST dataset has high accuracy but struggles with global translational invariance when tested on the GTI dataset. Images with the digit's center predicted correctly, while those at the corner were assigned incorrect classes. The model's performance suggests it is 'place-code' equivariant and struggles with shifts in image placement. Training the CNN model on MNIST images showed high accuracy but struggled with global translational invariance on the GTI dataset. Data augmentation by shifting images from the center improved performance, increasing accuracy on the GTI testing dataset to 98.05%. This implies 'place-code' equivariance in CNN, activating neurons at the corner of feature maps when objects are at the edge. CapsNet was tested on the GTI dataset with similar architecture based on Keras. CapsNet with 8.2M parameters tested on GTI dataset using Adam optimizer and margin loss. Capsule network shows robustness in viewpoint invariance but struggles with global invariance. Model trained on MNIST without data augmentation fails. The Capsule network with 8.2M parameters tested on the GTI dataset using Adam optimizer and margin loss. While Capsule network shows robustness in viewpoint invariance, it struggles with global invariance. Data augmentation in the MNIST training dataset improves CapsNet accuracy on the GTI dataset. CNN generally outperforms CapsNet on the GTI dataset. The Capsule network struggles with global invariance on the GTI dataset, while CNN generally outperforms CapsNet. The generated images resemble handwriting even when the input images are in Helvetica font. The CapsNet's lower performance on the GTI dataset may be due to the removal of max-pooling layers and the use of wider receptive fields in the convolutional layers. There is potential for improvement in CapsNet's ability to handle translational invariance. A new GTI testing dataset was introduced to evaluate deep learning models trained on MNIST. The Capsule network struggles with global invariance on the GTI dataset, while CNN generally outperforms CapsNet. Despite CapsNet's limitations in handling global translational invariance without data augmentation, its architecture shows potential for improvement over CNN in this aspect. A new GTI testing dataset was introduced to evaluate deep learning models trained on MNIST, providing a better understanding of CNN and CapsNet's ability to deal with global translational invariance. CNN and CapsNet struggle with global translational invariance, with CapsNet underperforming compared to CNN on the GTI dataset. A new testing method using MNIST training data with random shifting was introduced to evaluate model accuracy. This method is easily implementable for other computer vision tasks by applying translational shifting to cover all possible cases."
}