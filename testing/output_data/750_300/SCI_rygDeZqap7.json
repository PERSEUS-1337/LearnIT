{
    "title": "rygDeZqap7",
    "content": "Natural language understanding research has shifted towards complex Machine Learning and Deep Learning algorithms, which often outperform simpler models. To address the challenge of limited labeled data availability, a methodology for extending training datasets and training data-hungry models using weak supervision is proposed. This approach is applied to biomedical relation extraction, a task crucial for drug discovery. In biomedical relation extraction, a methodology for extending training datasets and enhancing LSTM network performance using weak supervision is demonstrated. This approach proves to be effective in improving performance comparable to hand-labeled data, especially in tasks like drug discovery. The increasing number of scientific papers in the biomedical field poses a challenge due to the unstructured nature of the text, making it difficult for researchers to extract important information. Extracting important information from the increasing number of scientific papers in the biomedical field, especially in drug discovery, is challenging due to the unstructured nature of the text. Utilizing weak supervision can enhance LSTM network performance and extend training datasets effectively. Automation of Information Extraction BID15 has been pursued to address the labor-intensive manual annotation process by domain experts. The optimal setting for applying weak supervision in this methodology is discussed for storing structured information in a knowledge base, which can significantly impact tasks such as drug design and detecting adverse drug effects. Efforts have been made towards automating Information Extraction BID15 in the biomedical field to address the labor-intensive manual annotation process by domain experts. The focus is on automating semantic triple extraction from biomedical abstracts, specifically on Regulations and Chemically Induced Diseases, which are crucial for drug design, safety, and discovery. Semantic triple extraction from biomedical abstracts focuses on two key relations: Regulations (up-regulates or down-regulates production of a Protein) and Chemically Induced Diseases (CID). This process is crucial for drug design, safety, and discovery, enabling researchers to filter or select chemical substances with specific properties faster. Protein/Gene BioCreative VI -CHEMPROT Chemically-Induced Chemical Disease BioCreative V -CDR Disease (CID) Extracting semantic triples is a structured Information Extraction problem. The main focus is on relation extraction, which involves identifying entities of interest in unstructured text and building a classifier to recognize target relationships. Increasing the learning algorithm's capacity should align with an increase in the training dataset size. The main focus is on relation extraction, aiming to increase the learning algorithm's capacity with a larger training dataset. To address the labor-intensive annotation process, a new methodology based on weak supervision is proposed, combining ideas from semi-supervised and ensemble learning. Multiple base learners are trained on a small labeled dataset to predict labels for a larger unlabeled dataset, followed by using a denoiser to derive weak labels. The methodology proposed combines ideas from semi-supervised and ensemble learning for relation extraction. It involves training multiple base learners on a small labeled dataset to predict labels for a larger unlabeled dataset, using a denoiser to derive weak labels, and training a strong meta-learner using weak supervision. The effectiveness of this methodology was demonstrated in a small-scale controlled experiment. Our main contributions include proposing a detailed methodology for relation extraction, demonstrating its effectiveness in a small-scale experiment, and investigating denoising methods' impact on system behavior. We also discuss related literature on information extraction, relation extraction from biomedical text, and semi-supervised and ensemble learning methods. The code for the methodology is available on GitHub. Literature on information extraction, relation extraction from biomedical text, and semi-supervised learning methods is discussed. Information extraction can be fully, semi, or unsupervised. Fully-supervised methods require manual annotation, while unsupervised methods like Open Information Extraction BID4 do not use training data. Semi-supervised methods are similar to the approach discussed. The curr_chunk discusses different methods for Information Extraction, including unsupervised methods like Open Information Extraction BID4 and semi-supervised methods like DIRPE, Snowball, KnowItAll, and TextRunner. It also mentions the use of contextual data augmentation in recent approaches. The curr_chunk discusses distant supervision as a method for generating weak labels for relation extraction problems using Knowledge Bases (KB) instead of pre-trained classifiers. Other semi-supervised algorithms mentioned include Snowball, KnowItAll, and TextRunner, which focus on bootstrapping new data to avoid manual annotation. Distant supervision is a method for generating weak labels for relation extraction using Knowledge Bases (KB) instead of pre-trained classifiers. This approach benefits large-scale datasets by eliminating the need for human annotation. Our work complements distant supervision by incorporating weak classifiers from such algorithms. Our work complements distant supervision by incorporating weak classifiers from such algorithms for biomedical relation extraction, particularly focusing on Chemically-induced Diseases. BioCreative competitions have motivated research in this area, with recent studies showing improved performance by extending the training set using distant supervision. The best performing team in a BioCreative competition implemented an ensemble of Support Vector Machines, LSTM, CNN, and SVMs for identifying relations between Chemicals and Proteins. Other approaches using Deep Neural Networks showed overfitting problems. The best performing team in a BioCreative competition used ensemble methods like Support Vector Machines, LSTM, and CNN to identify relations between Chemicals and Proteins. Overfitting issues were observed with approaches solely using Deep Neural Networks. The lack of training data in this domain emphasizes the importance of ensemble methods for generalization improvement. The study aims to combine these techniques with semi-supervised learning, which has not been explored for this task before. Neural Networks are combined with semi-supervised learning to improve Machine Learning models. Ensemble learning reduces high variance by combining multiple learners, while semi-supervised learning utilizes unlabeled data for generalization improvement. The combination of ensembles with semi-supervised learning has not been extensively studied. Ensembles can enhance semi-supervised learning by providing multiple views and improving performance with less data. The combination of ensembles with semi-supervised learning has not been thoroughly studied, despite indications of mutual benefits. Ensembles can improve semi-supervised learning by providing multiple views and enhancing performance with less data. Co-training, a system where two independent algorithms utilize unlabeled data, was the first of its kind. Recent research suggests that independence may not be necessary for success, as long as the data distribution is expanded. Recent research suggests that independence may not be necessary for success in semi-supervised learning. Using expert-defined lexicons and natural language processing, a system learned to annotate data samples accurately in functional genomics without manually labeled data. Tri-training extends co-training to three learners for improved performance. Tri-training BID37 is an extension of co-training to three learners, where two learners agreeing on a label teach the third learner. Co-forest BID18 extends this concept to more learners, with an ensemble system making decisions on re-training. The methodology differs from previous approaches as base learners in the ensemble system are not used for the final decision. The ensemble system in the re-training stack decides whether to add an unlabeled example, using all learners. Unlike previous methods, the base learners in the ensemble system are only used to generate weak labels, not for final prediction or re-training. This approach allows for the use of all unlabeled data, rather than just a few examples with high confidence annotations. Weak supervision and data programming have heavily influenced the development of the methodology described. Weak supervision involves training models using labels of questionable quality, while data programming allows for the use of all unlabeled data. This approach contrasts with previous methods that only added a few examples with high confidence annotations to the re-training stack. Weak supervision and data programming have heavily influenced the methodology development. Weak supervision involves training models with labels of questionable quality, while data programming allows for using all unlabeled data. It involves defining weak supervision sources and encoding them into Labeling Functions for each data point. Weak supervision involves defining weak sources as Labeling Functions for each data point, which can provide labels or abstain. Denoising aims to derive weak labels close to the true labels from a vote matrix. Data programming uses a Generative Model to derive weak labels from a vote matrix, incorporating probabilities of labeling and label accuracy without access to ground truth. The Generative Model in data programming assigns weak labels to data points based on Labeling Functions' correlations, aiming to maximize the likelihood of observed votes. These weak labels are used to train a noise-aware discriminative model for final prediction. Based on weak supervision and data programming, a methodology for semi-supervised learning is proposed to leverage multiple learners. It assumes a gold-labeled training set is available but insufficient in size for complex training. The predicted label distributions are used as probabilistic weak labels for training a noise-aware discriminative model. For semi-supervised learning, it is beneficial to augment additional training data using machine learning models of lower complexity as weak supervision sources. This approach allows for scaling the dataset size without relying on heuristics or crowd-sourced labels. Using machine learning models of lower complexity as weak supervision sources offers the advantage of easily adapting an existing pipeline to similar tasks. The required datasets include a labeled training set, an unlabeled dataset drawn from the same distribution, a validation set for hyperparameter tuning, and a test set for evaluation. Training K base learners on the labeled set helps in solving the task efficiently. The study involves using a dataset D U of size M m drawn from the same distribution as D B, along with a validation set D V for hyperparameter tuning and a test set D T for evaluation. 162 base learners are trained on solving task T by maximizing individual performance and capturing different views of the data through varying hyperparameters and design choices. The most important design choice highlighted is sentence pruning to remove irrelevant words. The relation extraction pipeline involves creating 162 base learners by utilizing varying hyperparameters and design choices. One key design choice is sentence pruning, where irrelevant words within a sentence are removed to focus on the entities of interest. This can be achieved by keeping only the words between the entities or including words within a certain window. More advanced methods, such as constructing a dependency-based parse tree, can also be considered. In relation extraction, different approaches can be used to focus on entities of interest, such as constructing a dependency-based parse tree and including words within a certain window. Various techniques like whole sentences, different window sizes, sequential features like tri-grams, and text representation using token occurrences or TF-IDF weights are explored. In addition to the bag-of-words approach, contiguous sets of tokens up to tri-grams are used as features. The corpus is converted to numerical representation using token occurrences or TF-IDF weights. Machine learning algorithms such as Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTMs, and CNNs are employed on the feature matrix. Note that some feature engineering steps are not applicable when using LSTMs and CNNs. After using various machine learning algorithms on the feature matrix, including Logistic Regression, Support Vector Machines, Random Forest Classifiers, LSTMs, and CNNs, a subset of base learners is selected to maximize performance and diversity. Some feature engineering steps are not applicable with LSTMs and CNNs. The objective is to avoid including similar classifiers in a disagreement-based method, considering computational cost and complexity. Our objective is to maximize the individual performance and diversity of base learners by discarding classifiers below a certain performance threshold. This threshold is set above random guess baseline but low enough to include less accurate and more diverse classifiers in the ensemble. The most diverse classifiers are selected to maximize diversity in the ensemble. The base learners were automatically created with limited hyperparameter tuning, set above a random guess baseline but low enough to include diverse classifiers. A similarity-based clustering method was used to select the most diverse classifiers, constructing a similarity matrix based on inter-annotator agreement rates. K-means clustering was performed on this matrix to pick the base learners closest to the cluster centroids. We use K-means clustering on a matrix of pairwise inter-annotator agreement rates to select representative base learners. The silhouette score coefficient helps determine the number of clusters. The selected base learners predict labels for data and generate a binary prediction matrix. A denoiser is then used to convert the matrix into weak labels. In the final step, a discriminative model is used to unify the weak labels generated by different denoisers, including a Majority Vote denoiser and an Average Vote denoiser, to produce marginal weak labels. The hyperparameters are selected using a validation dataset, and a probabilistic Generative Model of data programming is employed to refine the predictions made by the base learners. In the final step, a discriminative model is used to unify weak labels from different denoisers, such as Majority Vote and Average Vote, to create marginal weak labels. Training the meta-learner with weak supervision sacrifices label quality for quantity, which can benefit when the meta-learner's performance is limited by the training set size. High-capacity models like Deep Neural Networks are used as meta-learners to learn their own features and improve accuracy. In experiments using high-capacity Deep Neural Networks as meta-learners, the goal is to improve performance limited by training set size. The study utilizes part of Snorkel framework for relation extraction with weak supervision. Official BioCreative datasets are used for training, development, and testing. In experiments using high-capacity Deep Neural Networks as meta-learners, the study utilizes the Snorkel framework for relation extraction with weak supervision. Official BioCreative datasets, including CHEMPROT and CDR, are used for training, development, and testing. The methodology requires three gold-labeled datasets and a held-out test set, with the original test sets used as the held-out test set. The training and development sets are merged and shuffled to create datasets for training base learners and validation. The study utilizes the Snorkel framework for relation extraction with weak supervision using high-capacity Deep Neural Networks. The original training and development sets are merged and shuffled to create three datasets for training base learners, validation, and unlabeled data. This ensures no bias in document selection and all documents undergo the same pre-processing steps. The study ensures no bias in document selection by drawing all datasets from the same distribution and applying the same pre-processing steps. This controlled approach allows for comparison of the meta-learner's performance with weak supervision to optimal performance. The study uses a controlled approach to compare the performance of the meta-learner trained with weak supervision to optimal performance. SpaCy is used for text pre-processing tasks such as sentence splitting, tokenization, and dependency parsing. Named Entity Tags are manually annotated for candidate extraction. SpaCy is used for text pre-processing tasks like sentence splitting, tokenization, and dependency parsing. Named Entity Tags are manually annotated for candidate extraction. Snorkel is used for candidate extraction and mapping to ground-truth labels, with a focus on relationship classification in Natural Language understanding. In experiments, entities of interest are replaced with tokens like 'ENTITY1' and 'ENTITY2', while additional entities of the same type are replaced with 'CHEMICAL', 'GENE', or 'DISEASE' in the same sentence. A bi-directional Long-Short Term Memory network is used for tasks related to Natural Language processing. In experiments, entities are replaced with tokens like 'ENTITY1' and 'ENTITY2', while additional entities of the same type are replaced with 'CHEMICAL', 'GENE', or 'DISEASE' in the same sentence. A bi-directional Long-Short Term Memory network is used for Natural Language processing tasks. Randomly initialized word embeddings and random under-sampling are used to maintain class balance. Different hyperparameter settings are explored based on validation dataset D V. Research questions and motivation for exploration are discussed. In this section, different dropout values (0, 0.25, 0.5) and training epochs (1-30) are explored based on the validation dataset DV. Research questions are formed regarding enhancing biomedical relation extraction using Machine Learning classifiers for weak supervision and determining the optimal setting for weak supervision. The related literature suggests that adding weakly labeled data can improve the performance of the meta-learner BID30. The related literature suggests that weakly labeled data can improve the performance of the meta-learner BID30 by quasi-linearly increasing performance as the amount of weakly labeled data increases. The optimal setting for using weak supervision on this task requires accurate weak supervision sources that overlap and disagree enough to estimate their accuracy. Machine Learning classifiers have not been used as weak supervision sources in this setting, raising questions about the availability of a diverse and sufficiently large set of base learners. Machine Learning classifiers have not been utilized as weak supervision sources in this context, leading to uncertainty about the availability of a diverse and large enough set of base learners. This raises a critical question that impacts the usability of the methodology. Several experiments are conducted to assess the impact of weak supervision on the performance of the meta-learner trained on different modes. To evaluate the impact of weak supervision on meta-learner performance, experiments were conducted using different training modes: full-supervision on D B, weak-supervision on D U, and a combination of weak-supervision on D U with full-supervision on D B. The study also aimed to determine if weak-supervision could achieve results comparable to full-supervision when using all ground-truth labels (D U + D B). Selecting the optimal number of base learners was noted as a challenging task, with the need to balance performance and the number of classifiers used. The study aimed to evaluate the impact of weak supervision on meta-learner performance by using all ground-truth labels (D U + D B). Selecting the optimal number of base learners is crucial, balancing performance and diversity. The denoising component plays a key role in determining the quality of weak labels for the final learner. Three denoising methods were used to assess results. The denoising component is crucial for determining the quality of weak labels used by the final learner. Three denoising methods were evaluated, producing binary or marginal weak labels with varying distributions. An error analysis was conducted to assess their impact on training and the meta-learner's performance. The study evaluated three denoising methods for weak labels, which varied in distribution from U-shaped to uniformly distributed. An error analysis was conducted to assess their impact on training and the meta-learner's performance. The optimal setting for applying weak supervision was determined by experimenting with different numbers of base learners and maximizing silhouette scores. Performance of base learners and weak classifiers was reported in detail. In the study, different denoising methods for weak labels were evaluated, with a focus on their impact on training and the meta-learner's performance. Experimentation with varying numbers of base learners and maximizing silhouette scores determined the optimal setting for weak supervision. Training the meta-learner with weak labels consistently outperformed training with fewer gold labels, showing a 2-2.5x increase in performance with a larger training set size. Training the meta-learner with weak labels consistently outperforms training with fewer gold labels, showing a 2-2.5x increase in performance with a larger training set size. Weak supervision can achieve performance comparable to full supervision, sometimes even slightly better. Weak supervision can achieve performance comparable to full supervision, sometimes even slightly better. Differences in performance are minor and not statistically significant due to high variance on the meta-learners' performance. Under-sampled training sets in weak supervision were larger, based on weak labels instead of real ones. Majority Vote often outperforms in some cases. The under-sampled training set size in weak supervision was larger due to using weak labels instead of real ones. Majority Vote sometimes outperforms the meta-learner, but this does not diminish the significance of the results. The LSTM model cannot outperform Majority Voting with a small training dataset, even with gold quality labels. Visualizing the learning curves of the meta-learner confirms the meaningfulness and improvement of weak labels. The LSTM model struggles to outperform Majority Voting even with gold quality labels on a small training dataset. Visualizing the meta-learner's learning curves shows that weak labels do improve performance. The F1 score on the training set consistently surpasses the test score, indicating overfitting. Additional training data is needed to enhance performance. The F1 score on the training set consistently outperforms the test score, indicating overfitting in the meta-learner. Additional training data is needed to improve performance. The analysis will be based on experimental results and discuss findings. Based on experimental results, the F1 score of weak Majority Vote labels for 5 learners is the lowest. The performance of the meta-learner improves with more than 10 base learners when trained with Average Vote marginals. Using Generative model marginals also shows a slight performance improvement. The meta-learner's performance improves with more than 10 base learners when trained with Average Vote marginals. Generative model marginals also show a slight performance improvement, with exceptions. The metalearner achieves the best performance with Average Marginals in most cases. Generative Model marginals outperform Majority Vote weak labels, but depend on hyperparameters chosen based on F1 score validation. The performance of the meta-learner improves with more than 10 base learners when trained with Average Vote marginals. Generative model marginals also show improvement compared to Majority Vote weak labels, except for one case. GM marginals depend on hyperparameters chosen based on F1 score validation, but this measure may not fully reflect performance under different weak label distributions. Marginal weak labels enhance the meta-learner's performance over binary labels. Denoisers can generate weak labels, either binary or marginal. Marginal weak labels improve meta-learner performance compared to binary labels. Generative Model produces marginals following a U-shaped distribution, while average marginals are more evenly spread. Error analysis on validation set shows misclassified weak labels. The error analysis on the validation set reveals that Average Vote labels are of higher quality compared to Generative Model marginals, as most misclassified labels are closer to 0.5. The figures also highlight the unsuitability of the F1 score for evaluating marginal weak labels. The training loss and validation scores change as the LSTM is trained for more epochs. Training error remains high when marginal labels are used, especially with Average weak marginals. LSTM starts predicting binary training labels accurately after a few epochs, despite a delay with noisy-labeled MV weak labels. Training a classifier using marginal labels can be challenging. The LSTM quickly starts predicting binary training labels accurately after a few epochs, despite a delay with noisy-labeled MV weak labels. Training a classifier using marginal labels can be seen as a regression problem, penalizing the model for any prediction errors. The distributions of predicted logits become more spread as the training marginals become more uniform, resembling regression rather than classification. In applying the methodology on the CPR task, the performance of the meta-learner decreases with the addition of weakly labeled data, indicating issues with the quality of the datasets or weak labels. Predicted class imbalance is also observed. The performance of the meta-learner decreases with the addition of weakly labeled data, indicating issues with dataset quality or weak labels. A predicted class imbalance is observed, with a ratio of 1:14 on the outgoing citations dataset compared to 1:4 on the original dataset. Using the t-SNE algorithm and features from the best-performing base-learner, candidate samples from the original set are visualized, showing that most candidates from the new dataset lie in specific regions. The t-SNE algorithm BID20 is used with features from the best-performing base-learner to visualize candidate samples from the original set versus samples from both sets. Most candidates from the new dataset are found in specific regions, indicating its unsuitability. Weak supervision can enhance complex models like deep neural networks by utilizing unlabeled data and multiple base learners. Further investigation into constructing appropriate unlabeled datasets is necessary. Weak supervision can enhance the performance of complex models like deep neural networks by utilizing unlabeled data and multiple base learners. The methodology proposed is feasible for the task at hand, requiring unlabeled data from the same domain as labeled data for base learners to generalize and perform adequately. The methodology proposed in weak supervision shifts human effort from hand-labeling examples to feature engineering and construction of diverse learners. It allows for scaling training datasets while consistently improving performance over supervised learning. The same pipeline can be re-used on similar tasks with the requirement of providing unlabeled data from the same domain as labeled data. The methodology proposed in weak supervision shifts human effort from hand-labeling examples to feature engineering and construction of diverse learners. It allows for scaling training datasets while consistently improving performance over supervised learning. The same pipeline can be re-used on similar tasks with the requirement of providing appropriate datasets. Further exploration is needed to construct a large enough unlabelled dataset to improve metalearner performance. Further exploration is crucial to construct a large unlabelled dataset for improving metalearner performance and drawing stronger conclusions on research questions. Preliminary experiments show the need to inspect performance improvements with increased dataset size and determine any performance thresholds. The preliminary experiments highlight the challenge of collecting an appropriate unlabeled dataset and the importance of defining an appropriate metric for evaluating weak labels. It is crucial to determine if there is a performance threshold that cannot be surpassed using weak supervision. It is crucial to find an appropriate metric for evaluating weak labels, as the absence of one hinders drawing direct conclusions from them without additional steps. Further investigation areas include experimenting with the meta-learner and defining a better selection method. Further investigation areas include experimenting with the meta-learner and defining a more appropriate selection method for Base Learners. It would be interesting to explore how the system would behave if Base Learners abstained from voting on uncertain examples. This could involve deleting votes near the classification boundary or setting a minimum confidence threshold for voting. One approach to improve the system is to delete uncertain votes near the classification boundary or set a minimum confidence threshold for voting, providing a modeling advantage compared to unweighted methods. This could enhance the Generative Model's performance in weak supervision scenarios."
}