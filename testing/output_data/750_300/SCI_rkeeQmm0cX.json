{
    "title": "rkeeQmm0cX",
    "content": "Deep neural networks (DNNs) have emerged as a powerful solution this year for addressing longstanding issues in Artificial Intelligence. In this paper, DNNs are applied to three cyber security use cases: Android malware classification, incident detection, and fraud detection using real data sets from Cybersecurity Data Mining Competition (CDMC) 2017. Efficient network architecture for DNNs is determined through experiments on network parameters and structures, with configurations run for up to 1000 epochs and learning rates ranging from 0.01 to 0.5. The experiments conducted on efficient network architecture for DNNs in cyber security use cases showed superior performance compared to classical machine learning algorithms. DNNs extracted better features leading to higher accuracy rates, with the best accuracy obtained on Android malware classification, incident detection, and fraud detection. In cyber security, DNNs outperform classical machine learning algorithms by extracting better features for higher accuracy rates in tasks such as Android malware classification, incident detection, and fraud detection. The accuracy of DNNs is comparable to the top systems in CDMC 2017 tasks, showcasing their potential in modern technical environments where security measures are crucial due to emerging threats. In the era of technical modernization, new opportunities and resources have emerged, but they also bring threats to the economy. Hacking has become common in organizations to steal data, emphasizing the need for efficient cyber security measures to detect and prevent fraudulent activities, especially against malware, which remains a significant threat on the Internet. Cyber security focuses on protecting systems, networks, and data from fraudulent activities, particularly malware. Malware poses a significant threat on the Internet by causing harm to systems. Antivirus and blacklists are commonly used for defense, but they are not entirely effective and only provide initial protection. Machine learning algorithms, particularly deep learning approaches, have shown remarkable performance in cyber security, surpassing traditional methods like antivirus and blacklists. These new approaches are effective in detecting new malware variants created using advanced techniques. This paper evaluates the effectiveness of deep neural networks (DNNs) in cyber security use cases such as Android malware classification, incident detection, and fraud detection. Sections include related work, background knowledge of DNNs, methodology description, dataset details, results, and conclusion. Section II discusses related work in cyber security use cases such as Android malware classification, incident detection, and fraud detection. Section III covers the background knowledge of deep neural networks (DNNs), while Section IV presents the proposed methodology including data set description. Results are displayed in Section V, and the conclusion is in Section VI. Static and dynamic analysis are commonly used approaches in Android malware detection, with static analysis involving collecting android permissions by unpacking or disassembling the app, and dynamic analysis focusing on run-time execution characteristics like system calls and network connections. In Android malware detection, static analysis involves collecting android permissions by unpacking or disassembling the app, while dynamic analysis focuses on run-time execution characteristics like system calls and network connections. Commercial systems often use a combination of both approaches. Static analysis is preferred in Android devices for its advantages such as low computational cost and resource utilization, while dynamic analysis can detect metamorphic and polymorphic malwares. \"In Android devices, static analysis is preferred for its advantages such as low computational cost and resource utilization. Dynamic analysis can detect metamorphic and polymorphic malwares. BID3 evaluated traditional machine learning classifiers for android malware detection using permission, API calls, and a combination of both as features. Performance was better with the combination of API calls and permission features compared to using them individually.\" \"API calls and permission features were collected from 2510 APK files. Traditional machine learning classifiers performed well with the combination of API calls and permission feature set. MalDozer by BID4 uses deep learning to detect Android malware and classify them. BID5 briefly discussed privacy and security issues in cloud computing, categorizing 28 issues into five major categories. BID6 proposed machine learning-based solutions.\" Recently, cloud security issues were discussed by BID5, categorizing 28 issues into five major categories. BID6 proposed machine learning-based anomaly detection for different layers. BID7 addressed intrusion detection for cloud infrastructure and the combination of rule-based and machine learning systems. BID8 discussed security problems in the cloud and proposed an incident detection system. In BID9, a comparative study of traditional machine learning classifiers for identifying financial fraud was conducted. BID10 discussed the use of data mining approaches for financial fraud detection. Deep learning, a sub-model of machine learning, has been widely used for various cyber security applications in recent research (BID11, BID12, BID13, BID14). The curr_chunk discusses the application of deep learning in cyber security, proposing a unique DNN architecture for various use cases. It aims to explain the concepts and techniques behind training DNNs, which are represented as directed graphs with artificial neurons. The curr_chunk discusses the concepts of deep neural networks (DNNs) architecture and techniques for training DNNs, focusing on artificial neural networks (ANNs) as directed graphs with artificial neurons. It explains the structure of feed forward networks (FFN) and the commonly used multi-layer perceptron (MLP). A feed forward network (FFN) is a type of artificial neural network (ANN) where units are connected in a single direction without forming cycles. Multi-layer perceptron (MLP) is a subset of FFN with 3 or more layers - input, hidden, and output. The number of hidden layers can be increased for complex data, with the complexity determining the parameterization of the hidden layers. A feed forward network (FFN) is a type of artificial neural network (ANN) where units are connected in a single direction without forming cycles. Multi-layer perceptron (MLP) is a subset of FFN with 3 or more layers - input, hidden, and output. The number of hidden layers can be increased for complex data, with the complexity determining the parameterization of the hidden layers. The hidden layers form an acyclic graph that passes information forward without depending on past input. Each hidden layer's computation can be mathematically formulated. The computation of each hidden layer in a feed forward network can be defined mathematically. Rectified linear units (ReLU) are efficient for accelerating training, especially with large datasets. They speed up the training process and offer advantages over traditional activation functions. ReLU is a more efficient activation function for training large datasets, speeding up the process and offering advantages over traditional functions like logistic sigmoid and hyperbolic tangent. TensorFlow and Keras are used as software frameworks, with GPU-enabled TensorFlow for faster gradient descent computations in deep learning architectures. Task 1 involves Android Malware Classification using a dataset of unique API information from APK files collected from the Opera Mobile Store in 2014. The APIs are related to permissions and are executed when a user runs an application. The curr_chunk discusses the collection of APK files from the Opera Mobile Store in 2014, detailing how APIs are related to permissions in Android. It also mentions the different types of permissions and how they are specified in the AndroidManifest.xml file. Additionally, it introduces Task 2, which involves an operational log file from Unified Threat Management of UniteCloud. The dataset contains operational log files from Unified Threat Management of UniteCloud BID25, a private cloud infrastructure providing e-learning and e-research services in New Zealand. The log files consist of nine features representing sensors in the UTM system, each labeled based on incident status. The dataset contains operational log files with nine features representing sensors in the UTM system, labeled based on incident status. Task 3 involves fraud detection using anonymized data unified with a rule-based approach. Experiments were conducted to find an optimal learning rate for the tasks. The experiments aimed to find the optimal learning rate for tasks involving operational log files with nine features in the UTM system. The highest accuracy was achieved at a learning rate of 0.1, with fluctuations at 0.2 before reaching peak accuracy at 0.35, 0.45, and 0.45. Running experiments for 1000 epochs may further enhance accuracy. The experiments aimed to find the optimal learning rate for tasks involving operational log files with nine features in the UTM system. The highest accuracy was achieved at learning rates of 0.35, 0.45, and 0.45, surpassing the accuracy at 0.1. Running experiments for 1000 epochs may have contributed to this enhanced accuracy. Different network topologies were tested, including DNNs with 1 to 5 layers, with 2 trials for each topology, running until 500 epochs. The experiments aimed to find the optimal network topology for input data, running trials for different DNN architectures with varying numbers of layers. Most architectures learned normal category patterns within 600 epochs, but malicious data required more iterations. Complex networks needed more epochs to achieve best accuracy. The best performing network topology varied for each use case, with 4-layer DNNs performing well for Task 2 and Task 3. The experiments aimed to find the optimal network topology for input data, running trials for different DNN architectures with varying numbers of layers. The best performing network topology varied for each use case, with 4-layer DNNs performing well for Task 2 and Task 3, while 5-layer DNNs showed good performance for Task 1. The decision was made to use 5-layer DNNs for the rest of the experiments. 10-fold cross validation accuracy of each DNNs network topology for all use cases is shown in TAB0. An overview of the proposed DNNs architecture, Deep-Net, is illustrated in FIG0 with an input layer, 5 hidden layers, and an output layer. The experiments focused on determining the best network topology for different tasks, with 5-layer DNNs performing well overall. The architecture of the proposed Deep-Net includes an input layer with varying neuron numbers for each task and fully connected layers. Training is done using backpropagation. Details of the DNNs architecture can be found in TAB0. The proposed DNN architecture includes fully-connected layers, batch normalization, and dropout layers. Fully-connected layers have connections to every unit in the succeeding layer, mapping data into high dimensions for accurate output determination using ReLU activation. The fully-connected layer in the DNN architecture maps data into high dimensions for accurate output determination using ReLU activation. Batch normalization and dropout layers are used for regularization and to prevent overfitting during model training. In DNN architecture, BID27 and Batch Normalization BID28 are used between fully-connected layers. Dropout removes neurons randomly to prevent overfitting. The final fully connected layer uses sigmoid activation for Task 1 and Task 2, and softmax for Task 3. The prediction loss is estimated using binary cross entropy for Task 1 and Task 2. The fully connected layer processes non-linear kernel and sigmoid output for benign (0) and malicious (1) classes, with softmax providing class probabilities. Prediction loss is calculated using binary cross entropy for Task 1 and Task 2, and categorical cross entropy for Task 3, optimized with sgd. The DNN model is evaluated against classical methods. The DNN model is evaluated using categorical-cross entropy to compare against classical machine learning classifiers on three cyber security use cases: identifying Android malware, incident detection on UniteCloud, and fraud detection in financial transactions. Different matrix shapes are passed to the input layer during training for each use case. The DNN model is used for incident detection on UniteCloud and fraud detection in financial transactions. Different matrix shapes are passed to the input layer during training for each use case. XGBoost is utilized for supervised learning problems. XGBoost is a model used for supervised learning problems, based on Gradient Boosting. It is used for tasks like classification, with a max depth of 20 for the tree. Data is loaded using Pandas, with NaN values replaced by 0. Task 1 involves a term-document matrix representation. The winner of CDMC 2017 tasks achieved high accuracy using Random Forest classifier with Python scikit-learn BID11. The proposed method outperformed the winner of CDMC 2017 on Task 2 using Random Forest classifier. DNNs achieved slightly lower accuracy compared to the winner. Adding hidden layers can enhance DNNs' performance. The method can automatically obtain the best features. This paper evaluates DNNs for cyber security. The performance of deep neural networks (DNNs) for cyber security applications, including Android malware classification, incident detection, and fraud detection, has been evaluated. DNNs outperformed classical machine learning classifiers in all use cases. Adding hidden layers can further enhance the performance of DNNs. The performance of DNNs is superior to classical machine learning classifiers in various cyber security applications. Adding more layers to the existing architectures can further improve the results, pointing towards future work."
}