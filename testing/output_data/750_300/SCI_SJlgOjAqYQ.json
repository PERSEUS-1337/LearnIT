{
    "title": "SJlgOjAqYQ",
    "content": "The study examines global translation-invariance in deep learning models trained on the MNIST dataset. Both convolutional and capsules neural networks show poor performance in this aspect, but data augmentation improves their performance. While capsules perform better on the testing dataset, convolutional networks generally excel in translation-invariance. CNNs are known for their state-of-the-art performance in computer vision tasks. Convolutional neural networks (CNN) have better performance on translation-invariance tasks compared to human beings. The success of CNN is attributed to reduced computation cost with weight sharing in convolutional layers and generalization with local invariance in subsampling layers. CNNs need to learn different models for different viewpoints, requiring big data and expensive costs. Capsule network is robust in dealing with different viewpoints by using groups of neurons to include pose, color, lighting, and deformation of visual entities. It aims for 'rate-coded' equivariance, where weights code viewpoint-invariant knowledge, not neural activities. Viewpoint changes in capsule network have linear effects. Capsule network focuses on achieving 'rate-coded' equivariance by using groups of neurons to represent pose, color, lighting, and deformation of visual entities. Viewpoint changes in capsule network have linear effects on pose matrices between different layers, but its ability to generalize for global translation invariance remains unclear. Visualizing and quantifying translation-invariance in deep learning models is crucial for understanding architectural choices and developing viewpoint-invariant generalization models. In this paper, a simple method is introduced to test the performance of global translation-invariance in convolutional and capsule neural network models trained on the MNIST dataset. Global translational invariance (GTI) of deep learning models can be tested using a simple testing dataset. The study introduces a method to test global translation-invariance in convolutional and capsule neural network models trained on the MNIST dataset. Testing dataset consists of images generated by shifting the centre of mass of a Helvetica font digit one pixel at a time. There are 2520 testing images covering all possible cases of translational translations. The study tests global translation-invariance in neural network models using images generated by shifting the centre of mass of digits. The testing dataset includes 2520 images covering all possible translational translations. Deep learning models are trained on the MNIST dataset and tested on both MNIST and GTI datasets. MNIST images are mostly centered, while GTI images are uniformly distributed on the canvas. The method compares translation-sensitivity maps based on average images in MNIST testing dataset to all possible translations. Our method is robust to random noise in the MNIST testing dataset and utilizes a smaller GTI training dataset. The GTI dataset allows for capturing tiny differences in models and quantifying global invariance. Additionally, it enables accurate model predictions on the GTI testing dataset. The CNN model used in the study has nine layers, including convolutional and fully connected layers with specific channel sizes and filter configurations. Dropout with a drop rate of 0.5 is applied to the first layer. The GTI dataset is advantageous for capturing model differences and assessing global invariance in model predictions. The CNN model used in the study consists of 9 layers with specific channel sizes and filter configurations. Dropout with a drop rate of 0.5 is applied to the first layer. The total number of parameters is 361578, much smaller than Capsule networks. ReLU is used as the activation function for all layers except the last one, which uses softmax. The optimizer is Adam with default parameters, and the objective function is cross entropy loss. The CNN models were trained on MNIST data, achieving results shown in FIG2 and TAB0. The CNN model used ReLU for all layers except the last one, which used softmax. The optimizer was Adam with default parameters, and the objective function was cross entropy loss. Results of the CNN on MNIST data showed high accuracy on the testing set but low accuracy on GTI testing dataset, indicating poor performance on global translational invariance. Images with the digit's centre of mass around the canvas centre were predicted correctly. The CNN model showed high accuracy on MNIST data but low accuracy on GTI testing dataset, indicating poor performance on global translational invariance. Images with the digit's centre of mass around the canvas centre were predicted correctly, while those at the corner were assigned to incorrect classes. The model's inability to accurately predict images shifting towards the corner in the GTI dataset suggests that CNN is 'place-code' equivariant. The CNN model trained on MNIST data struggled to accurately predict images in the GTI dataset, indicating poor performance on global translational invariance. To improve performance, data augmentation was used by shifting the image from the centre in x and y-direction during training, resulting in an increased accuracy of 98.05% on the GTI testing dataset. Data augmentation improved the accuracy of the CNN model on the GTI testing dataset to 98.05% by shifting images in x and y-direction. CapsNet, with 8.2M parameters, was tested on the GTI dataset using the same architecture as CNN. The CapsNet model, with 8.2M parameters, was tested on the GTI dataset using the same architecture as CNN. The model was trained with Adam optimizer and margin loss, but performance on global invariance needs improvement. The model trained on MNIST without data augmentation failed to predict the class correctly. The CapsNet model's performance on global invariance needs improvement, as shown in the experiment on MNIST dataset. Data augmentation in training helps improve accuracy on the GTI dataset, with nearly all images being predicted correctly. The generated images resemble handwriting even when the input images are in Helvetica font. The CapsNet model's performance on global invariance needs improvement, as shown in the experiment on MNIST dataset. CNN's performance on GTI dataset is generally better than CapsNet, with accuracy consistently higher even with different amounts of shifting. The removal of max-pooling layers in CapsNet may contribute to its lower performance on the GTI dataset. The CapsNet model struggles with global translational invariance, especially compared to CNN on the GTI dataset. The removal of max-pooling layers in CapsNet may be a factor in its lower performance. There is potential for improvement in CapsNet's handling of translational invariance, as shown in experiments with a new GTI testing dataset. The CapsNet model struggles with global translational invariance compared to CNN on the GTI dataset. CapsNet architecture has potential for improvement in handling translational invariance, as capsules can learn viewpoints regardless of information source. Testing on MNIST dataset shows CapsNet's limitations without data augmentation. The CapsNet model struggles with global translational invariance compared to CNN on the GTI dataset. Testing on MNIST dataset shows CapsNet's limitations without data augmentation, but the testing method is sample Figure 5: GTI dataset accuracy of models trained on CNN and CapsNet with different amount of random shifting in MNIST training dataset. It is quantifiable and easy to implement for other computer vision tasks."
}