{
    "title": "ryg7jhEtPB",
    "content": "The importance weighted autoencoder (IWAE) is a variational-inference method that achieves a tighter evidence bound than standard variational autoencoders by optimizing a multi-sample objective. However, as the number of samples (K) is increased, the inference-network gradients break down, leading to the need to remove high-variance score-function terms to avoid this issue. In this work, the breakdown of inference-network gradients as K is increased is addressed by removing high-variance score-function terms. This can be achieved through heuristically ignoring them (yielding the 'sticking-the-landing' IWAE gradient) or using an identity from Tucker et al. (2019) (yielding the 'doubly-reparametrised' IWAE gradient). The authors argue for directly optimizing the proposal distribution in importance sampling, as in the reweighted wake-sleep (RWS) algorithm, over IWAE-type multi-sample objectives. In this work, the authors introduce an adaptive-importance sampling framework called AISLE, which generalizes the RWS algorithm. They argue that optimizing the proposal distribution in importance sampling is preferable to optimizing IWAE-type multi-sample objectives. AISLE encompasses IWAE-STL and IWAE-DREG as special cases. AISLE admits IWAE-STL and IWAE-DREG as special cases, modeling observations x and latent variables z via a generative model. The work analyzes algorithms for variational inference to learn the generative model and construct a variational approximation. The work analyzes algorithms for variational inference to learn the generative model and construct a variational approximation, aiming to find values for \u03b8 and \u03c6 that approximate the maximum-likelihood estimate and the generative model respectively. The presentation focuses on a single latent representation-observation pair to avoid notational clutter. The presentation focuses on a single latent representation-observation pair (z, x) to avoid clutter. Parameters are not shared between the generative model and the variational approximation. The setting covers amortised inference and stochastic gradient-ascent algorithms for optimising \u03c8 have been proposed. The presentation focuses on a single latent representation-observation pair (z, x) to avoid clutter. Parameters are not shared between the generative model and the variational approximation. Stochastic gradient-ascent algorithms for optimising \u03c8 have been proposed, including IWAE-DREG and RWS. IWAE-DREG and RWS are stochastic gradient-ascent algorithms for optimizing parameters in generative models and variational approximations. IWAE-DREG removes problematic score-function terms from the IWAE \u03c6-gradient, while RWS optimizes two separate objectives for \u03b8 and \u03c6 using self-normalized importance sampling with K particles. RWS is an adaptive importance-sampling approach that iteratively improves its proposal distribution and does not degenerate as K \u2192 \u221e. The IWAE and RWS are stochastic gradient-ascent algorithms for optimizing parameters in generative models and variational approximations. The RWS method uses self-normalized importance sampling with K particles to optimize two separate objectives for \u03b8 and \u03c6. The IWAE method is popular but suffers from \u03c6-gradient breakdown, while RWS does not degenerate as K \u2192 \u221e. However, RWS can break down empirically and may not optimize a joint objective for \u03b8 and \u03c6. In this work, it is shown that directly optimizing the proposal distribution, as done by RWS, is preferable to optimizing the IWAE multi-sample objective due to the \u03c6-gradient breakdown issue. Directly optimizing the proposal distribution, as done by RWS, is preferred over optimizing the IWAE multi-sample objective due to the \u03c6-gradient breakdown issue. This conclusion is supported by Le et al. (2019) based on numerical experiments, showing that IWAE can be inferior to RWS, especially for discrete latent variables. Our work formalizes this argument by slightly generalizing the RWS algorithm. Our work complements the findings of Le et al. (2019) by formalizing the argument that the need for reparametrizations can make IWAE inferior to RWS, especially for discrete latent variables. We introduce the adaptive importance sampling for learning (AISLE) framework, which generalizes the RWS algorithm and includes IWAE-DREG and IWAE-STL gradients as special cases. Novel material is presented in Section 3, where AISLE is introduced, allowing for the derivation of various gradient estimators. In Section 3, the AISLE framework is introduced, which generalizes the RWS algorithm and includes IWAE-DREG and IWAE-STL gradients as special cases. The derived gradient estimators are guaranteed to not degenerate as K \u2192 \u221e. Specifically, the IWAE-STL gradient can be recovered as a special case of AISLE via a novel application of the 'double-reparametrisation' identity. Our work establishes a theoretical foundation for IWAE-STL and AISLE, showing that IWAE-STL gradient can be recovered through a novel application of the 'double-reparametrisation' identity. Additionally, AISLE also includes IWAE-DREG gradient as a special case, with the learning rate scaled as O(K) for IWAE. AISLE provides theoretical foundation for IWAE-STL and IWAE-DREG gradients, with learning rate scaling as O(K) for IWAE. It leads to new gradient estimators for \u03b1-divergences, generalizing previous literature. In contrast, AISLE does not require scaling up the learning rate with K. It introduces a new family of gradient estimators for \u03b1-divergences and provides insights on the impact of self-normalization bias on importance-sampling based gradient approximations. The focus is not on deriving new algorithms but on comparing existing ones empirically. The focus of the work is not to derive new algorithms but to compare existing ones empirically. The notation is kept concise by suppressing dependence on observations. The work compares existing algorithms empirically, focusing on notation conciseness by suppressing observation dependence. Expectations of test functions can be estimated using self-normalised importance sampling estimators. The self-normalised importance sampling estimators approximate expectations of test functions. The importance weighted autoencoder (IWAE) aims to find generative-model parameters that minimize bias and standard deviation. The importance weighted autoencoder (IWAE) seeks to maximize a lower bound on the log-marginal likelihood by optimizing the inference-network parameters. As the number of samples K increases, the evidence bound tightens, and the IWAE reduces to the variational autoencoder (VAE) when K = 1. The IWAE tightens the evidence bound as K increases, reducing to VAE when K = 1. For K > 1, IWAE extends VAE on an auxiliary-variable space. The gradient of the IWAE objective approximates E G \u03c8 (z) unbiasedly. The IWAE tightens the evidence bound as K increases, extending VAE on an auxiliary-variable space. The gradient of the IWAE objective approximates E G \u03c8 (z) unbiasedly, but often requires the reparametrisation trick to reduce high variance. The IWAE tightens the evidence bound as K increases, extending VAE on an auxiliary-variable space. To reduce high variance, the reparametrisation trick is employed, assuming the existence of a distribution q on space E and a family of differentiable mappings. The IWAE uses a vanilla Monte Carlo estimate and focuses on the \u03c6-portion. Lemma 1 generalizes the identity q \u03c6 (\u2207 \u03c6 log q \u03c6 ) = 0. The drawbacks of the IWAE \u03c6-gradient include reliance on reparametrisations and high-variance terms. Control-variate approaches can be used for discrete models that violate R1. The drawbacks of the IWAE \u03c6-gradient include reliance on reparametrisations, high-variance terms, and vanishing signal-to-noise ratio in the \u03c6-gradient portion. Control-variate approaches can be used for discrete models that violate R1. The drawbacks of the IWAE \u03c6-gradient include vanishing signal-to-noise ratio and inability to achieve zero variance. Modifications have been proposed to address these issues, such as IWAE-STL. The IWAE gradient has drawbacks like vanishing signal-to-noise ratio and inability to achieve zero variance. Modifications like IWAE-STL and IWAE-DREG have been proposed to address these issues. IWAE-STL ignores score function terms, introducing bias when K > 1, while IWAE-DREG removes score-function terms through Lemma 1. The 'doubly-reparametrised' IWAE (IWAE-DREG) gradient removes score-function terms through Lemma 1, with \u03b8-and \u03c6-gradients approximated using self-normalised importance sampling. The bias relative to IWAE-STL is of order O(1/K), discussed in Appendix A. The self-normalised importance sampling approximation in RWS allows for simultaneous optimisation of both \u03b8 and \u03c6, sharing particles and weights. The lack of a joint objective is a drawback, but the gradient in expectation is derived using Lemma 1. The lack of a joint objective in RWS is a drawback, but optimizing \u03c6 can reduce errors in \u03b8-gradient approximation. Monte Carlo samples can be reused to approximate both gradients. Optimizing \u03c6 in RWS can reduce errors in \u03b8-gradient approximation by reusing Monte Carlo samples. Various techniques exist for adapting the proposal distribution q \u03c6, including minimizing the \u03c7 2 -divergence. Based on minimizing the \u03c7 2 -divergence, a slightly generalized RWS-objective is proposed. Alternative approaches for optimizing \u03c6 could be used, but for concreteness, the algorithm adaptive importance is defined as \u03b8 := arg max \u03b8 log Z \u03b8 , \u03c6 := arg min \u03c6 D\u0192(\u03c0\u03b8 q \u03c6 ). Based on minimizing the \u03c7 2 -divergence, a slightly generalized RWS-objective is proposed. The algorithm adaptive importance sampling for learning (AISLE) is introduced, allowing for a straightforward derivation of robust \u03c6-gradient estimators. Optimization is done through stochastic gradient ascent, with the \u03b8-gradient being the same for all algorithms discussed in the work. The IWAE paradigm sees it as an unbiased gradient of a biased lower-bound. The \u03b8-gradient is the same for all algorithms discussed in this work, viewed differently by IWAE and AISLE. Integrals of the form \u03c0 \u03b8 ([F \u2022 w \u03c8 ]\u2207 \u03c6 log q \u03c6 ) naturally appear in derivations, approximated with the vanilla Monte Carlo method. In variational inference for intractable models, \u0192-divergences are optimized without knowing the normalizing constant Z \u03b8. The approximation using Monte Carlo method has bias O(K \u22121) and standard deviation O(K \u22121/2). In variational inference for intractable models, optimization of \u0192-divergences is done without knowing the normalizing constant Z \u03b8. The integral can be approximated using self-importance sampling, leading to a reparametrised estimator. In variational inference for intractable models, optimization of \u0192-divergences is done without knowing the normalizing constant Z \u03b8. Self-importance sampling can be used to approximate the integral, leading to a reparametrised estimator. This approach can be applied to derive IWAE-STL in a principled manner from AISLE. The gradient \u2207 rws \u03c6 \u03b8, z equals AISLE-KL. IWAE-STL can be derived from AISLE without a multi-sample objective, providing a theoretical basis for IWAE-STL. Proposition 1 provides a theoretical basis for IWAE-STL, derived from AISLE without relying on a multi-sample objective. IWAE-STL showed good empirical performance even when RWS broke down, suggesting the breakdown may not be due to RWS' lack of optimizing a joint objective. The breakdown of RWS may not be due to its lack of optimizing a joint objective, as previously conjectured. The variance reduction technique using self-normalized importance-sampling approximation can potentially reduce bias and variance in AISLE-KL. The \u03b1-divergence between two distributions p and q is given by Z (p(z)/q(z)) \u03b1. AISLE-KL is derived by applying Lemma 1 to the exact \u03c6-gradient and then approximating the expression to reduce bias and variance. The \u03b1-divergence between distributions p and q is expressed as Z \u03ba \u03b8 Zf (w \u03c8 (z))q \u03c6 (z) dz, with \u03ba = \u2212\u03b1 and f (y) = y \u03b1. Minimizing this divergence is natural in importance sampling. 3.3.1, g(y) = (\u03b1 \u2212 1)y \u03b1\u22121 and h (y) = \u03b1(\u03b1 \u2212 1) y \u03b1\u22121. Minimizing this divergence is important in importance sampling. AISLE-\u03b1-NOREP and AISLE-\u03b1 are special cases related to score gradient. IWAE-DREG can be derived from AISLE in a principled manner. IWAE-DREG can be derived from AISLE in a principled manner, demonstrating that the learning rate needs to be scaled as O(K) for the IWAE or IWAE-DREG \u03c6-gradients. The 'exclusive' KL-divergence is also discussed in relation to importance sampling. The 'exclusive' KL-divergence is related to importance sampling and can lead to faster convergence of \u03c6 than other methods. The 'exclusive' KL-divergence, a simple average over K independent replicates of the 'sticking-the-landing' estimator for VAEs, can lead to faster convergence of \u03c6. However, minimizing this divergence may negatively affect learning of \u03b8 due to potential issues with importance weights. The adaptive-importance sampling paradigm of the reweighted wake-sleep (RWS) is discussed as a solution. The adaptive-importance sampling paradigm of the reweighted wake-sleep (RWS) is preferable to the multi-sample objective paradigm of importance weighted autoencoders (IWAEs) due to its ability to achieve goals while avoiding drawbacks. The self-normalised importance-sampling approximation plays a crucial role in this paradigm. The self-normalised importance-sampling approximation in RWS/AISLE involves interpolating between accurate approximations with varying numbers of particles, K. As K increases, the estimators become more accurate, while for K=1, they reduce to vanilla Monte Carlo approximations. The self-normalised importance-sampling approximation in RWS/AISLE involves interpolating between accurate estimators with varying numbers of particles, K. As K increases, the estimators become more accurate, while for K=1, they reduce to vanilla Monte Carlo approximations. The small-K self-normalisation bias of the reparametrisation-free AISLE \u03c6 gradients is challenging to characterize, especially for K=1. The use of IWAEs instead of VAEs aims to reduce bias in the \u03b8-gradient by employing self-normalised importance-sampling with K > 1 particles. The small-K self-normalisation bias of AISLE gradients favors minimizing the exclusive KL-divergence. The bias of gradients in IWAEs favors minimizing exclusive KL-divergence to reduce bias in the \u03b8-gradient. The error of importance-sampling can be controlled by ensuring q \u03c6 is close to \u03c0 \u03b8, with small 'inclusive' KL-divergence implying well-behaved importance weights. The error in importance-sampling can be controlled by minimizing exclusive KL-divergence to reduce bias in the \u03b8-gradient. The family Q of proposal distributions should be flexible enough for well-behaved importance weights. The family Q of proposal distributions should be sufficiently expressive to minimize exclusive KL-divergence and reduce bias in the \u03b8-gradient. If Q is not flexible enough, importance weights may not behave well. In Scenario 1, if the family Q is not flexible enough, minimizing exclusive KL-divergence could lead to poorly-behaved importance weights. It is important to optimize \u03c6 to minimize the divergence between \u03c0 \u03b8 and q \u03c6. In Scenario 1, optimizing \u03c6 to minimize the divergence between \u03c0 \u03b8 and q \u03c6 is crucial to avoid poorly-behaved importance weights. Using a gradient-descent algorithm to minimize exclusive divergence may be more effective than inclusive divergence in some cases, leading to faster convergence. In such scenarios, a smaller number of particles, K, could be preferable due to the self-normalization bias outweighing the standard deviation. In some scenarios, a smaller number of particles, K, may be preferable for \u03c6-gradients due to the self-normalization bias outweighing the standard deviation, potentially leading to faster convergence. Simply setting K = 1 is not always optimal as increasing K can help reduce the variance of gradient approximations. Increasing the number of particles, K, is desirable to reduce gradient approximation variance and utilize all sampled/calculated information for optimal performance. Increasing the number of particles, K, is desirable to reduce gradient approximation variance and utilize all sampled/calculated information for optimal performance. However, not using the information contained in all K particles and weights seems wasteful. Different \u03c6-gradient estimators are compared in the supplementary materials, including AISLE-KL-NOREP which is based on the KL-divergence without reparametrisation. In this work, various gradient estimators are compared for AISLE, including AISLE-KL-NOREP, AISLE-KL, and AISLE-\u03c7 2 -NOREP, each based on different divergences and reparametrisation techniques. The gradient estimators for AISLE include AISLE-\u03c7 2 -NOREP, AISLE-\u03c7 2, and AISLE-KL, each based on different divergences and reparametrisation techniques. The gradients do not require R1 but do not achieve zero variance even if q \u03c6 = \u03c0 \u03b8. When normalising the gradients, they are proportional to IWAE-DREG from Tucker et al. (2019). The gradient estimators for AISLE include AISLE-\u03c7 2 -NOREP, AISLE-\u03c7 2, and AISLE-KL, each based on different divergences and reparametrisation techniques. The gradient for IWAE employing the reparametrisation trick from Kingma & Welling (2014) is proportional to IWAE-DREG from Tucker et al. (2019). The reparametrisation trick from Kingma & Welling (2014) is discussed, along with the IWAE-DREG gradient from Tucker et al. (2019) and the RWS-DREG gradient. The joint law of observations and latent variables is parametrised by \u03b8. The joint law of observations and latent variables, parametrised by \u03b8, factorises as a fully-factored Gaussian proposal distribution for optimization. The parameters to optimize are denoted by a column vector formed by elements in the dth row of A. The proposal distribution for optimization is a fully-factored Gaussian, with parameters represented by a column vector from A's dth row. The model is similar to benchmarks in previous studies by Rainforth et al. and Tucker et al. The proposal distribution in (20) matches the posterior in (19) when A = P and b. This model is akin to benchmarks in Rainforth et al. (2018, Section 4) and Tucker et al. (2019, Section 6.1), where isotropic Gaussians were used for both the generative model and variational approximation. In this study, we allow for correlated latent vectors z in the generative model, while maintaining a fully factored variational approximation. In a more realistic scenario, the latent vectors z are allowed to be correlated in the generative model. The variational approximation, however, remains fully factored and may not fully capture uncertainty about the latent variables. The variance of the A and b-gradient portion of certain models approaches zero as C approaches 1/2I. These 'score-function free' \u03c6-gradients achieve near-optimal performance in this model. In Gaussian settings, reparametrisation-trick gradients lead to near-zero variance for the proposal mean parameters, showing optimal performance. Further analysis of these benefits is discussed in Xu et al. (2019). The benefits of reparametrisation-trick gradients in Gaussian settings are further analyzed in Xu et al. (2019). Empirical comparisons of algorithms are conducted with varying numbers of particles and model dimensions, each configuration repeated independently 100 times using new synthetic data sets. The study conducted empirical comparisons of algorithms with varying numbers of particles and model dimensions, repeated independently 100 times using new synthetic data sets. The focus was on optimizing \u03c6 while fixing \u03b8 throughout. Results were shown for different model settings, including scenarios with specific generative model specifications. The study compared algorithms with different particles and dimensions, focusing on optimizing \u03c6 while keeping \u03b8 constant. Results for various generative model settings were presented, showing scenarios where the variational approximation couldn't fully mimic the latent variable dependence structure. The study compared algorithms for optimizing \u03c6 while keeping \u03b8 constant in different generative model settings. Gradient-ascent algorithms were used with normalised gradients and ADAM. The total number of iterations was 10,000 with learning-rate parameters i \u22121/2 at each step. The covariance matrix was non-diagonal. The study compared algorithms for optimizing \u03c6 while keeping \u03b8 constant in different generative model settings. The total number of iterations was 10,000 with learning-rate parameters i \u22121/2 at each step. The covariance matrix was non-diagonal with logarithmic scaling on the second axis."
}