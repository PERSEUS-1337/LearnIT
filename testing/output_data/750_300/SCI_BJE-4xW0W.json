{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) that allow sampling from both observational and interventional distributions. Adversarial training can be used to learn a CiGM with a structured generator architecture based on a causal graph. A two-stage procedure is devised for learning a CiGM over binary labels and images, preserving the dependency structure between the labels with the causal graph. The text discusses a two-stage procedure for learning a CiGM over binary labels and images, preserving the dependency structure with a causal graph. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed for generating images conditioned on binary labels. The optimal generator of CausalGAN samples from image distributions conditioned on the labels, showing that the conditional GAN combined with a trained CiGM forms a CiGM over the labels and the generated images. The text introduces two new GAN architectures, CausalGAN and CausalBEGAN, for generating images based on binary labels. It demonstrates that the optimal generator of CausalGAN samples from image distributions conditioned on the labels, allowing for sampling from observational and interventional image distributions. Additionally, it discusses implicit generative models like BID7, which can sample from probability distributions without explicit parameterization. Generative adversarial networks (GANs) are successful in training implicit generative models by sampling from high-dimensional nonparametric distributions. GANs consist of a generator network that uses feedforward computation to sample from noise vectors, refined by a discriminator network. Generative adversarial networks (GANs) use a generator network to sample from noise vectors, refined by a discriminator network. The generator aims to maximize the loss of the discriminator to output samples convincing enough to be from the real data distribution. GANs have been successful in generating samples from distributions like images and videos. An extension allows sampling from class conditional data distributions by providing class labels to the generator. Generative adversarial networks (GANs) have been successful in generating samples from distributions like images and videos. An extension allows sampling from class conditional data distributions by providing class labels to the generator. Various neural network architectures have been proposed for this task. The architecture can sample from both the joint distribution and the interventional distribution, showing clear differences between the two. Our architecture extends previous work on conditional image generation by capturing the dependence between labels, allowing sampling from both joint and interventional distributions. In this paper, the focus is on extending previous work on conditional image generation by capturing the dependence and causal effect between labels. The generator maps labels to images in a non-deterministic way, following the causal graph \"Labels cause the Image\" denoted by L \u2192 I. The generator is a non-deterministic mapping from labels to images, following the causal graph \"Labels cause the Image\" denoted by L \u2192 I. Using a finer model, causal relations between labels can also be included. For example, the causal graph between Gender (G) and Mustache (M) labels shows that Gender causes Mustache, denoted by G \u2192 M. Conditioning on specific labels allows for the generation of images based on the population distribution. Gender causes Mustache, denoted by the graph G \u2192 M. Causal models allow sampling from conditional and interventional distributions. Interventions fix variable values in a causal graph, affecting descendant distributions. Unlike conditioning, interventions do not alter the distribution of the intervened variable. Interventions in causal graphs fix variable values, affecting descendant distributions but not ancestors. Gender does not change when Mustache is intervened upon. Causal implicit generative models (CiGM) are proposed for sampling from conditional and interventional distributions. Causal implicit generative models (CiGM) propose mechanisms for sampling from conditional and interventional distributions, using GANs to train models that inherit neural connections from the causal graph. Using GANs, causal implicit generative models (CiGM) can sample from conditional and interventional distributions when the generator structure inherits neural connections from the causal graph. Wasserstein GAN (WGAN) is used to train a CiGM for binary image labels, followed by the proposal of two novel conditional GANs - CausalGAN and CausalBEGAN. CausalGAN's optimal generator can sample from true conditional distributions, and combining it with a CiGM on labels yields a CiGM on images. The proposed approach involves using CausalGAN and CausalBEGAN, two novel conditional GANs, to sample from true conditional distributions. By combining CausalGAN with a CiGM on labels, a CiGM on both labels and images can be created. Adversarial training is used to structure the generator architecture based on the causal graph, allowing for the training of a CiGM using WGAN to output discrete 1 labels for binary image labels. The text discusses the use of WGAN to train a CiGM for binary labels, proposing a two-stage procedure involving a novel conditional GAN architecture. Additionally, an extension of BEGAN to accept labels is suggested for sampling from class conditional distributions. In a two-stage procedure, a novel conditional GAN architecture and loss function are proposed for training a CiGM for binary labels. An extension of BEGAN to accept labels, called CausalBEGAN, is introduced, producing high-quality images that capture image labels. The CausalGAN and CausalBEGAN models are shown to produce label-consistent images even for label combinations not seen during training. The CiGM training framework uses CausalGAN and CausalBEGAN to generate label-consistent images based on image labels. Previous works have proposed conditional GAN (CGAN) and ACGAN for similar purposes. Conditional GANs (CGAN) and ACGAN are used for generating label-consistent images. ACGAN tasks the discriminator with estimating the label, while CGAN and ACGAN are compared for performance. InfoGAN introduces a new architecture to maximize mutual information between inputs and images. InfoGAN proposes a new architecture to maximize mutual information between inputs and images, extending existing GAN frameworks like BiGAN, ALI, CoGAN, and SD-GAN. These architectures aim to learn mappings between image and latent spaces, allowing for sampling from label combinations not present in the dataset. In CoGAN BID1, authors learn a joint distribution over images and binary labels by enforcing weight sharing between generators and discriminators. SD-GAN splits the latent space into \"Identity\" and \"Observation\" portions, allowing for generation of faces of the same person by fixing the identity portion of the latent code. SD-GAN can be seen as an extension of BEGAN to labels, making it the only extension of BEGAN to accept labels before CausalBEGAN. Extending CoGAN and SD-GAN to more than two labels is not trivial. Authors in BID0 use CGAN with a one-hot encoded vector to change the age attribute of a face image. Generative models can also be used in compressed sensing, providing guarantees for recovering a vector close to the output of a trained generative model. Using causal principles for deep learning and deep learning techniques for causal inference has been gaining attention. In BID3, the authors connect GAN layers with structural equation models and use CGAN in BID6 to determine causal direction between variables. In BID5, a neural network is proposed to discover causal relations between image class labels. In recent works, authors have explored the connection between GANs and causal generative models, introducing concepts like causal regularization in neural networks to ensure predictive causality. In a recent work, authors discuss the connection of GANs to causal generative models, emphasizing the importance of predictive causality. They use neural networks to learn causal graphs, similar to our approach of using structural equations and directed acyclic graphs to represent causality. In this section, a brief introduction to causality is provided using Pearl's framework of structural causal models (SCMs). It explains how X causes Y within the SCM framework, where a function f and an unobserved random variable E determine the value of Y based on X and E. The causal graph representing this relation is X \u2192 Y. In a structural causal model, a function f and an unobserved random variable E determine the value of Y based on X and E through the function f. The causal graph X \u2192 Y represents this relation, with unobserved variables known as exogenous. The causal graph is a directed acyclic graph implied by the structural equations, where the parents of a node X i represent the causes of that variable. The causal graph in a structural causal model is constructed from the structural equations, with parents of a variable being those that appear in the equation determining its value. The model includes functions, random variables, exogenous variables, and a probability distribution over the exogenous variables. The observable variables have a joint distribution based on the exogenous variables and functional relations. The causal graph is a directed acyclic graph representing the relationships between variables. The causal graph in a structural causal model is a directed acyclic graph on observable variables V, with nodes representing variables and their relationships determined by functions. An intervention changes the causal mechanism and corresponding graph, denoted as do(Xi = xi), distinct from conditioning on Xi. An intervention changes the causal mechanism and corresponding graph. It removes connections of a node to its parents, altering the causal graph. The post-interventional distribution can be calculated for a set of nodes. After an intervention on a set of nodes, the post-interventional distribution can be calculated by factorizing the observational distribution in a Bayesian network. After an intervention on a set of nodes, the post-interventional distribution is calculated by factorizing the observational distribution in a Bayesian network. It is challenging to identify the true causal graph for variables without experiments or additional assumptions, as multiple causal graphs can produce the same joint probability distribution. This paper assumes the causal graph is known and focuses on learning a causal model. This paper assumes a known causal graph and focuses on learning a causal model from the structural equations for exogenous variables. Learning causal graphs has been extensively studied in prior work, including Bayesian networks that respect conditional independences in data. In this section, the paper discusses the use of Bayesian networks to sample from observational distributions when the true causal graph is unknown. It also introduces causal implicit generative models that can sample from both observational and interventional distributions, utilizing generative adversarial networks for training. Causal implicit generative models allow sampling from observational and interventional distributions using generative adversarial networks. The model is based on a causal graph structure, with neural networks representing functions and noise terms. See FIG3 for the architecture. In the GAN training framework, the generator neural network connections reflect the causal graph structure. Feedforward neural networks represent functions f X , f Y , f Z with independent noise terms (N X , N Y , N Z ). Gaussian distributed variables can be used for the exogenous variables. The feedforward neural network represents causal models with a graph structure. In causal modeling, Gaussian distributed variables can be used as exogenous variables in a feedforward neural network. Two causal models with the same observational distribution will have the same interventional distributions for any intervention. In causal modeling, Gaussian distributed variables can be used as exogenous variables in a feedforward neural network. P V and Q V represent distributions induced by P N1 and Q N2 on variables in V. A feedforward neural network is linked to a causal graph through Definition 1, where Z is a set of independent random variables. Causal implicit generative models are defined as CiGM according to Definition 2. A causal implicit generative model (CiGM) is a feedforward neural network that outputs a vector based on the parents of i in a causal model. Adversarial training is proposed to ensure the generator neural network aligns with the causal graph. CiGMs are trained using samples from a joint distribution given the causal graph between variables. Causal implicit generative models (CiGMs) are trained with samples from a joint distribution based on the causal graph between variables. However, for image generation with binary labels, it is challenging to learn the joint label and image distribution simultaneously. The CausalGAN architecture divides the task by using a pretrained causal implicit generative model for image labels, a Labeler trained on real data, and an Anti-Labeler trained on generated data. The Generator minimizes Labeler loss and maximizes Anti-Labeler loss. The CausalGAN architecture divides the task of learning a CiGM into two subtasks: training a generative model over the labels and then training a generative model for the images conditioned on the labels. The image node is always the sink node of the causal graph for image generation problems. The new architecture and loss function (CausalGAN) ensure the optimum generator. The CausalGAN architecture divides the task of learning a CiGM into two subtasks: training a generative model over the labels and then training a generative model for the images conditioned on the labels. The image node is always the sink node of the causal graph for image generation problems. Our new architecture and loss function (CausalGAN) assures that the optimum generator outputs the label conditioned image distributions, under the assumption of a strictly positive joint probability distribution over the labels. The CausalGAN architecture divides the task of learning a CiGM into two subtasks: training a generative model over the labels and then training a generative model for the images conditioned on the labels. Combining CiGM for only the labels with a label-conditioned image generator gives a CiGM for images and labels. The Causal Controller, a generative model for binary labels, is used to control the distribution of images sampled when intervened or conditioned on labels. The Causal Controller network produces labels sequentially according to the causal graph. The Causal Controller network is structured to produce labels sequentially according to the causal graph. To sample from a discrete label distribution, WGAN is employed instead of standard GAN training due to the challenge of learning a discrete distribution with Jensen-Shannon divergence. The Causal Controller network uses WGAN to sample from discrete label distributions, ensuring meaningful gradients for image generation based on labels. Our new conditional GAN architecture generates images based on labels from the Causal Controller. It includes a pretrained Causal Controller and two separate labeler neural networks. The generator aims to produce realistic images by competing with the discriminator. The CausalGAN architecture includes an Anti-Labeler network in addition to a Labeler network. The Anti-Labeler is trained to estimate image labels sampled from the generator, crucial for the theoretical guarantee provided in Section 5.2.3. The generator's objective is three-fold: producing realistic images, consistent with labels, and avoiding easy-to-label unrealistic image distributions. CausalGAN utilizes an Anti-Labeler network alongside a Labeler network to prevent label-conditioned mode collapse. The Anti-Labeler loss discourages the generator from outputting only typical faces for a specific label combination, enhancing diversity within image batches. The Anti-Labeler network in CausalGAN prevents label-conditioned mode collapse by discouraging the generator from outputting typical faces for specific label combinations, enhancing batch image diversity. Rare label combinations can render popular techniques like minibatch-features ineffective in combating mode collapse. Using Anti-Labeler aids in faster convergence, with results presented for a single binary label that can be extended to more labels. In Section 9.4 of the Appendix, results are presented for a single binary label, which can be generalized to multiple labels. The analysis assumes a perfect Causal Controller and involves mappings by the generator, discriminator, Labeler, and Anti-Labeler. The generator loss function in CausalGAN includes label loss terms, GAN loss, and an additional loss term from the discriminator. The mappings in CausalGAN involve generator, discriminator, Labeler, and Anti-Labeler. The generator loss function includes label loss terms, GAN loss, and an added loss term from the discriminator. The optimal generator outputs the class conditional image distribution. Anti-Labeler and Labeler solve specific optimization problems. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. The discriminator and labeler networks operate at their optimum for multiple binary labels. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. The discriminator and labeler networks always operate at their optimum. This is the only conditional generative adversarial network architecture with this guarantee. The proof can be extended to multiple binary variables. The optimal discriminator for a fixed generator in a conditional generative adversarial network architecture behaves the same as in GAN. The generator minimizes its loss by sampling from class conditional distributions, achieving the global minimum of the virtual training criterion. The generator minimizes its loss by sampling from class conditional distributions to achieve the global minimum of the virtual training criterion. This two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. Corollary 1 states that a causal implicit generative model can be trained for a causal graph with a generator that samples from the image distribution conditioned on the given label combination. The optimum generator samples from the class conditional distributions given a single binary label, and the minimizer of C(G) samples from the class conditional distributions given d labels. The proposed alternative architecture extends the single binary label setup by using cross entropy loss terms for each label, requiring the Labeler and Anti-Labeler to have only d outputs. This allows the generator to capture the joint label posterior given the image. The extended architecture uses cross entropy loss terms for each label, requiring the Labeler and Anti-Labeler to have only d outputs. The generator captures the joint label posterior given the image, ensuring the posterior distribution of each label. However, this does not guarantee that the class conditional distributions will be true to the data distribution. For joint distributions where labels are determined by the image, the guarantee implies that the joint label posterior will be true to the data. The class conditional distributions will be true to the data distribution, implying that the optimum generator samples from the class conditional distributions. Trained causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms. Counterfactual sampling requires conditioning on an event and sampling from the push-forward of the posterior. See Section 8.7 for formal results and details. In this section, a simple extension of BEGAN involves feeding image labels to the generator for counterfactual sampling. This process requires conditioning on an event and sampling from the posterior distributions of exogenous noise terms under the interventional causal graph. In this section, a simple extension of BEGAN involves feeding image labels to the generator for counterfactual sampling. The extension includes using a Labeler network for labeling real and generated images, inspired by the Causal Controller and CausalGAN. The extension of BEGAN involves using a Labeler network to label real and generated images, inspired by Causal Controller and CausalGAN. The network serves the dual purpose of labeling real images well and generated images poorly, with margin modifications motivated by observations on image and label quality gradients. In this section, CausalGAN and CausalBEGAN are trained on the CelebA Causal Graph. The dataset used satisfies the condition where Male \u2192 Mustache in the graph, indicating that changing the probability of Mustache does not affect the probability of Male. The dataset used in training CausalGAN and CausalBEGAN on the CelebA Causal Graph satisfies the condition where Male \u2192 Mustache, showing that changing the probability of Mustache does not affect the probability of Male. The generated images include both males and females with mustaches, even though the label combination {Male = 0, Mustache = 1} was not seen during training. The conditional distribution P(.|Mustache = 1) shows only male images, as Male \u2192 Mustache in CelebA Causal Graph. The top row displays both males and females with mustaches, despite not being seen during training. The generative model can create samples conditioned on labels and sample from the distribution. The generative model proposed can create samples conditioned on labels and sample from interventional distributions. The theoretical analysis provides guarantees about correct sampling under interventions, as shown in Figure 7 with Narrow Eyes label intervention in CelebA Causal Graph using CausalBEGAN. Intervening on Narrow Eyes label in CelebA Causal Graph with CausalBEGAN shows that conditioning on Narrow Eyes = 1 increases the proportion of smiling images, although the difference may not be statistically significant. The generator in one image appears to rule out Narrow Eyes = 0 instead of demonstrating Narrow Eyes = 1. The research on CelebA Causal Graph with CausalBEGAN shows that conditioning on Narrow Eyes = 1 increases the proportion of smiling images, although the difference may not be statistically significant. The generator in one image appears to rule out Narrow Eyes = 0 instead of demonstrating Narrow Eyes = 1. Generative models like CausalGAN and CausalBEGAN can produce samples that are different from their training data in multiple ways, leading to more creative outcomes. The research has been supported by various grants and organizations. The research on CelebA Causal Graph with CausalBEGAN demonstrated that conditioning on Narrow Eyes = 1 increased the proportion of smiling images. The structural causal model includes functions, random variables, exogenous variables, and a probability distribution. This research was supported by NSF Grants, ARO YIP, NVIDIA Corporation, and ONR. The text discusses a causal graph representing exogenous random variables and observable variables with a joint distribution. The graph is a Bayesian network showing the relationships between variables based on functional relations. The text discusses a causal graph representing exogenous random variables and observable variables in a Bayesian network. It shows the relationships between variables based on functional relations, with nodes V and parents P a i. The causal sufficiency assumption allows for direct calculation of interventional distributions, making M 1 and M 2 have the same interventional distributions. The text discusses causal Bayesian networks and interventional distributions under the causal sufficiency assumption. It introduces joint data distribution P r (l, x) and joint distribution P g (l, x) for a binary label l and image x. Proposition 2 from Goodfellow et al. (2014) is restated for the discriminator. The text discusses the optimal discriminator and Labeler for binary labels and images. The optimum Labeler has D LR (x) = P r (l = 1|x), following similar lines as the proof for the optimal discriminator. The optimum Labeler has D LR (x) = P r (l = 1|x). The proof follows similar lines as the optimal discriminator. The lemma for Anti-Labeler states that the optimum Anti-Labeler has D LG (x) = P g (l = 1|x). The definition assumes causal sufficiency with no exogenous variables affecting more than one observable variable. Pearl's model assumes the distribution over exogenous variables is a product. The definition assumes causal sufficiency with no exogenous variables affecting more than one observable variable. Pearl's model assumes a product distribution over exogenous variables. The complete graph \"cG1\" is formed by adding edges, and the graph rcG1 is obtained by reversing the direction of every edge in cG1. Define C(G) as the generator loss when discriminator, Labeler, and Anti-Labeler are at their optimum. The Causal Controller samples from the true label. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. The global minimum of the virtual training criterion is achieved when the generator output matches the class conditional image distribution, as shown by the relations between the Labeler, Anti-Labeler, and discriminator. This is due to the Kullback-Leibler divergence being minimized when the distributions of labels and images are joint. The global minimum of the virtual training criterion is achieved when the generator output matches the class conditional image distribution, as shown by the relations between the Labeler, Anti-Labeler, and discriminator. This is due to the fact that the distributions of labels and images are joint. The concatenated generator neural network in a conditional GAN is consistent with the causal graph D, assuming perfect sampling from true label and image distributions. The concatenated model in a conditional GAN aligns with the causal graph D, assuming perfect sampling from true label and image distributions. It serves as a causal implicit generative model for graph D, with modifications needed for multiple binary labels. The modifications required to extend the proof to the case with multiple binary labels involve the challenge of learning the correct joint distribution. Two solutions are proposed: (1) Estimating the probability of each label combination theoretically, and (2) Adopting a practical approach to address the issue. From a theoretical perspective, two solutions are proposed to address the challenge of learning the joint distribution of multiple binary labels. The first solution involves estimating the probability of each label combination, while the second solution suggests using labelers to estimate the probabilities of individual labels. This approach ensures the equality of probabilities at the minimizer of C(G). The results of this extension are presented, including the Lemma where \u03c1 j = P r (l = j). The extension presented involves estimating the probability of each label combination to ensure equality of probabilities at the minimizer of C(G). The optimum Labeler with respect to the loss has D * LR (x)[j] = P r (l = j|x), where certain label combinations with zero probability are not considered. The Labeler loss can be written as DISPLAYFORM3 where L x is the discrete random variable such that P(L x = j) = P r (l = j|x). H(L x ) is the Shannon entropy of L x , and it only depends on the data. Since KL divergence is. The optimum Labeler network gives the posterior probability of a specific label, achieving a lower bound loss of -H(L x) by satisfying P(Z x = j) = P r (l = j|x). The optimum Labeler network provides the posterior probability of a label, while the Anti-Labeler network solves a different optimization problem. The Anti-Labeler network's loss function and lemma are discussed in relation to optimization problems. The optimum Anti-Labeler is defined in terms of conditional probabilities. The generator optimizes the conditional entropy of labels given the image, solving an optimization problem with a fixed discriminator, Labeler, and Anti-Labeler. Theorem 2 shows that the optimal generator samples from class conditional image distributions based on specific label combinations. Theorem 2 states that the global minimum of the virtual training criterion is achieved when the generator samples from true joint label distribution. This is proven by showing the relations between the optimum Labeler, Anti-Labeler, and discriminator. The optimum Labeler, Anti-Labeler, and discriminator relations are crucial for achieving the global minimum of the virtual training criterion. The Kullback-Leibler divergence is minimized when P g = P d jointly over labels and images. Relabeling combinations of binary labels as a 2 d label may be impractical for a large number of labels. Instead, theoretical guarantees are provided in this section. In this section, theoretical guarantees are provided for the implemented CausalGAN architecture with d labels, assuming a deterministic relationship between images and labels in the dataset. This ensures the global optimal generator samples from class conditional distributions. The implemented CausalGAN architecture assumes a deterministic relationship between images and labels, ensuring the global optimal generator samples from class conditional distributions. The Anti-Labeler and Labeler optimize different problems, leading to the characterization of the optimum generator for the optimum Labeler. The generator in the CausalGAN architecture aims to optimize the virtual training criterion by ensuring that the generated samples match the class conditional distributions of the real data. The global minimum of the criterion is achieved when the generator's output matches the real data distribution. The global minimum of the virtual training criterion in CausalGAN is achieved when the generator's output matches the real data distribution, ensuring correct conditional sampling given all labels. This is relevant in practice, such as in the CelebA dataset. The assumption that the image determines all labels is crucial for correct conditional sampling in the CelebA dataset. The lemma states that the label probabilities given the image can be expressed as a product of individual label probabilities. The lemma explains that a discrete joint probability distribution with all marginal probabilities as kronecker delta functions can be expressed as the product of these marginals. The kronecker delta function is defined as 1 at a single point and 0 elsewhere. The joint probability distribution is zero everywhere except at specific points (u1, u2, ..., un) due to the kronecker delta function. This is shown by contradiction, where the marginal probabilities are expressed as the product of these marginals. The joint distribution is zero everywhere except at specific points (u1, u2, ..., un) due to the kronecker delta function. Applying the lemma on the conditional distribution P g (l1, l2, ..., ld | x) shows that the image distributions and marginals P g (li | x) are true to the data distribution by Bayes' rule. The vector (l1, ..., ln) is a deterministic function of x, making P r (li | x) and P g (li | x) kronecker delta functions. The joint distribution satisfies the condition that every marginal distribution is a kronecker delta function, leading to a product distribution. This implies equality between P r (x|l1, l2, ..., ln) and P g (x|l1, l2, ..., ln) given P r (l1, l2, ..., ln) = P g (l1, l2, ..., ln). In this section, an extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from the class conditional image distributions, as proven by the equality between P r (x|l1, l2, ..., ln) and P g (x|l1, l2, ..., ln) given P r (l1, l2, ..., ln) = P g (l1, l2, ..., ln). In an extension of BEGAN, image labels are used to guide the generator. The approach is inspired by control theory and aims to train the generator when the discriminator is near optimal. A new loss and margins are introduced to reflect the idea that label gradients are most informative when image quality is high. In an extension of BEGAN, a new loss and margins are introduced to incorporate image labels in guiding the generator. The approach aims to utilize label gradients effectively when image quality is high. The generator in the image labeling process aims to minimize loss functions and incorporate margins for better training and meaningful gradients. This extends the BEGAN formulation to include labels effectively. The generator in the image labeling process aims to minimize loss functions and incorporate margins for better training and meaningful gradients. To improve image generation, a well-trained Labeler is necessary. An additional margin-coefficient tuple (b2, c2) is introduced to jointly minimize loss terms. However, image quality may suffer as images exploiting the Labeler network may not be realistic. Label loss is only encouraged when the image quality margin b1 is significantly larger than the label margin b2. The generator in the image labeling process aims to minimize loss functions and incorporate margins for better training. Label loss is encouraged only when the image quality margin b1 is large compared to the label margin b2. A new margin of margins term, b3, is introduced to achieve this. The extension preserves the property of a monotonically decreasing scalar to track convergence in gradient descent optimization. Our extension of BEGAN maintains the monotonically decreasing scalar property for tracking gradient descent optimization convergence. We explore training causal implicit generative models using GANs and investigate their behavior and convergence when the true data distribution comes from a different causal graph. Incorporating causal graphs into generative models, we study the convergence of causal implicit generative models on synthetic data from different causal graphs: \"line\", \"collider\", and \"complete\". Each node's value is computed by a cubic polynomial in n + 1 variables representing its parents and an exogenous variable. Results are averaged across different causal models. For each causal model, a cubic polynomial computes node values based on parents and an exogenous variable. Results are averaged across models, comparing convergence of joint distribution to true joint using different graph structures. Generators include fully connected neural networks mapping random noise to outputs. The study compares convergence behavior of generators structured based on different causal graphs: line, collider, and complete. Generators include fully connected neural networks mapping random noise to outputs. Data is generated from specific causal graphs X \u2192 Y \u2192 Z, X \u2192 Y \u2190, and X \u2192 Y \u2192 Z, X \u2192 Z. Results are shown in FIG9. The study compares convergence behavior of generators structured based on different causal graphs: line, collider, and complete. Each curve shows the convergence behavior of the generator distribution based on these causal graphs. Convergence is expected when the generator is structured based on the correct Bayesian network capable of generating the joint distribution. The complete graph is expected to work well with all data generation models. The study explores the convergence behavior of generators structured based on different causal graphs: line, collider, and complete. The complete graph is expected to work well with all data generation models. The convergence behavior of adversarial training across these models is being investigated. The study investigates the convergence behavior of generators based on different causal graphs: line, collider, and complete. The best convergence is seen with the line graph, followed by the complete graph with a slight delay. Fully connected networks with 3 layers perform well, but those with 5 and 10 layers perform worse. The number of layers in fully connected networks needs to be tuned for optimal performance in adversarial training. Using the wrong Bayesian network, such as the collider, results in poorer performance. In theory, connected generators can encode joint distribution. Adversarial training requires tuning the number of layers for optimal performance. Using the wrong Bayesian network, like the collider, leads to worse results. Fully connected generators with 3 and 5 layers show the best performance for the collider graph. The number of layers is crucial, with 10 layers showing the worst convergence behavior. Complete and collider graphs perform similarly well, while the line graph performs worse. Fully connected 3 layers perform the best for the complete graph. The number of layers is crucial for optimal performance in connected generators. Using 10 layers results in the worst convergence behavior. Complete and collider graphs perform similarly well, while the line graph performs worse. Fully connected 3 layers show the best performance for the complete graph. Evaluating the effect of using the wrong causal graph on an artificially generated dataset is important. The evaluation of using the wrong causal graph on an artificially generated dataset is crucial. The graph with 10 layers performs the worst and shows no convergence behavior. The scatter plot for a three-dimensional distribution is shown, highlighting the impact of different causal graphs on the generated distribution. The causal graph used in experiments for the CelebA dataset shows that the correct graph gives the closest scatter plot to the original data, while using the wrong Bayesian network results in a different distribution. The graph also highlights that women have no mustaches. The CelebA dataset experiments show that the correct causal graph closely matches the original data, while using the wrong Bayesian network results in a different distribution. The CelebA Causal Graph (G1) is illustrated in FIG6, with cG1 being the complete graph associated with specific image labels. The graph rcG1 is formed by reversing every edge in cG1. The CelebA dataset experiments show that the correct causal graph closely matches the original data. In cG1, Male causes Smiling due to their ordering. Using the incorrect Bayesian network leads to a different distribution. G1 generates Male and Young independently, which is incorrect. Despite this, both G1 and cG1 provide a reasonable approximation to the true distribution. The distributions in TAB0 show that G1 and cG1 provide accurate approximations to the true distribution. Despite some inaccuracies, both graphs lead to Causal Controllers that never output {Female, Mustache}. The Wasserstein GAN ensures convergence of the Causal Controller output to the label distribution. The Causal Controller output converges to the discretely supported label distribution using a modified Wasserstein GAN. The learned outputs have \"approximately discrete\" support, as shown in FIG12. The convergence is demonstrated effectively in both graphs, although Total Variation Distance (TVD) may not always be intuitive. In FIG12, good convergence is shown for both graphs, despite Total Variation Distance (TVD) not always being intuitive. The CelebA Causal Graph (G1) and its completion (cG1) allow training of reasonable marginal distributions for all labels, with a maximum deviation of 0.03 for the worst label. The Wasserstein Causal Controller is tested on a subset of binary labels from the CelebA dataset using a causal graph. The training allows the generator to map continuous noise to a discrete distribution, as shown in FIG12. The Wasserstein training enables the generator to map continuous noise to a discrete distribution, as demonstrated in FIG12. The Causal Controller outputs an almost discrete distribution, with 96% of samples near 0 or 1. Total variational distance (TVD) shows convergence for CelebA Causal Graph (G1), defined completion (cG1), and reversed completion (rcG1) with training. The total variational distance (TVD) measures convergence for CelebA Causal Graph (G1), defined completion (cG1), and reversed completion (rcG1) during training. Both cG1 and rcG1 show TVD decreasing to 0, while G1 asymptotes to around 0.14, indicating incorrect conditional independence assumptions. This suggests that any complete causal graph can lead to a nearly perfect causal generator, and partially incorrect causal graphs can still achieve reasonable convergence. Additional CausalGAN results are presented in FIG3 and 13. In this section, additional CausalGAN results are presented in FIG3 and 13, focusing on intervening and conditioning on the label \"Wearing Lipstick\" in the CelebA Causal Graph. The analysis shows that the probability of \"Male\" remains unaffected by the intervention \"Wearing Lipstick=1\", indicating a causal relationship in the graph. The analysis in FIG3 and 13 focuses on intervening and conditioning on the label \"Wearing Lipstick\" in the CelebA Causal Graph. The probability of \"Male\" remains unaffected by the intervention \"Wearing Lipstick=1\", indicating a causal relationship in the graph. The bottom row of images sampled from the conditional distribution shows only female images due to the dataset's characteristics. The dataset shows that intervening on \"Narrow Eyes\" does not affect the probability of \"Smiling\", but conditioning on \"Narrow Eyes\" increases the proportion of smiling images in the CelebA dataset. Training CausalBEGAN on CelebA dataset using CelebA Causal Graph is discussed in this section. Conditioning on Narrow Eyes = 1 increases the proportion of smiling images in the dataset. CausalBEGAN is trained on CelebA dataset using CelebA Causal Graph. The Causal Controller is pretrained with a Wasserstein loss. Removing the margin of margins deteriorates image quality for rare labels like Bald and Mouth Slightly Open. After removing the margins in the CausalBEGAN model, image quality for rare labels like Bald and Mouth Slightly Open deteriorates. The difference between interventional and conditional sampling for specific labels is illustrated in FIG4. The CelebA Causal Graph shows that intervening on Bald does not affect the probability of Male being 1. Intervening on Bald in CelebA Causal Graph does not affect the probability of Male being 1. Sampling from conditional distribution P(.|Bald = 1) shows only male images due to P(Male = 1|Bald = 1) \u2248 1. Conditioning on Mouth Slightly Open does not affect the probability of Smiling being 1. Intervening on Bald in CelebA Causal Graph does not affect the probability of Male being 1. Sampling from conditional distribution P(.|Bald = 1) shows only male images. Conditioning on Mouth Slightly Open does not affect the probability of Smiling being 1. Additional simulations for CausalGAN show conditional image generation properties by sweeping a single label from 0 to 1. In this section, additional simulations for CausalGAN are provided. Figures demonstrate the conditional image generation properties of CausalGAN by sweeping a single label from 0 to 1. Additionally, image diversity is shown with 256 randomly sampled images. Simulation results for CausalBEGAN are also presented, highlighting the importance of the third margin term in maintaining image quality for rare labels. The third margin term in CausalBEGAN is crucial for maintaining image quality of rare labels, as shown in FIG6. The scalar \"M\" in BEGAN has an extension, M complete, that decreases monotonically during training (FIG9). CausalBEGAN's conditional image generation properties are demonstrated through \"label sweeps\" in FIG3, where a single label input is varied while others are fixed. Generators in CausalBEGAN exhibit implicit characteristics. The CausalBEGAN architecture shows a discrete function for label input parameters, with label interpolation initially and later becoming more step-like. Image diversity is demonstrated through a random sampling of 256 images. In this section, the results of training an implicit causal generative model for labels and images are presented. The approach involves treating the image as part of the causal graph and encoding the label as a constant image in an additional channel. However, the image generation for CelebA Causal Graph was not successfully learned. The implementation details of feeding both labels and images to the discriminator are not clear. One approach is to encode the label as a constant image in an additional channel, but this method did not work well for CelebA Causal Graph. The discriminator may focus on labels without providing useful gradients for image generation. The differences between theory and implementation, along with details for CausalGAN and CausalBEGAN, are explained. Additionally, the implementation details of the Wasserstein Causal Controller for generating face labels are discussed, using the total variation distance (TVD) between the generator and data distribution. The implementation details of the Wasserstein Causal Controller for generating face labels involve using the total variation distance (TVD) as a metric to evaluate model success. The gradient term penalty is estimated by evaluating gradients between real and fake batches, allowing for training the Causal Controller to output discrete labels. Rounding the labels before passing them to the generator was found beneficial in practice. The Wasserstein approach allows training the Causal Controller to output discrete labels. The generator architecture is based on a causal graph, using neural networks to map parents to children. Training involves 25 Wasserstein discriminator updates per generator update with a learning rate of 0.0008. Stochastic gradient descent is used for model training. In practice, a 6 layer neural network is used as a function mapping parents to children. The model is trained using 25 Wasserstein discriminator updates per generator update with a learning rate of 0.0008. The DCGAN Radford et al. (2015) is extended into a Causal GAN framework by adding Labeler networks and a Causal Controller network. Unlike DCGAN, 6 generator updates are made for each discriminator update on average, and the discriminator and labeler networks are updated concurrently. In the Causal GAN framework, Labeler networks are added and a Causal Controller network is trained. 6 generator updates are made for each discriminator update on average, and the discriminator and labeler networks are updated concurrently. The loss terms are modified to accommodate a d-dimensional label vector. In the Causal GAN framework, Labeler networks are added and a Causal Controller network is trained. The loss terms are modified to accommodate a d-dimensional label vector, where the labelers determine the loss terms for each label. This approach differs from the architecture in Section 8.6, as it does not guarantee sampling from class conditional distributions. In the Causal GAN framework, Labeler networks are added to determine loss terms for each label. The order of terms in the cross entropy expressions for labeler losses has been swapped to improve image sharpness during training. Labels input to CausalBEGAN are taken from the Causal Controller. In the implementation of CausalBEGAN, the order of terms in cross entropy expressions for labeler losses has been swapped to enhance image sharpness. Few parameter tunings are used, with a fixed learning rate for both generator and discriminator. The model achieves good performance without extensive hyperparameter tweaking. Customized margin learning rates are also utilized. In CausalBEGAN, customized margin learning rates are used with fixed parameter values. The best models have all three margins active, near 0, and occasionally taking small positive values. In CausalBEGAN, customized margin learning rates are used with fixed parameter values. The best models have all three margins active, near 0, and occasionally taking small positive values. Comparing CausalGAN behavior with and without Anti-Labeler network, using Anti-Labeler allows for faster convergence and provides more diverse images for very rare labels. See FIG3, 25."
}