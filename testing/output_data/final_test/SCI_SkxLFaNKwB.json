{
    "title": "SkxLFaNKwB",
    "content": "The allocation of computation resources in object detection is a crucial issue. To address this, CR-NAS (Computation Reallocation Neural Architecture Search) is introduced to learn efficient computation reallocation strategies directly on the target detection dataset. A two-level reallocation space is proposed for stage and spatial reallocation, with a hierarchical search procedure to navigate the complex search space. CR-NAS applied to various backbones, such as CR-ResNet50 and CR-MobileNetV2, achieved significant improvements in COCO AP without additional computation budget. The models discovered by CR-NAS can be integrated into other detection systems. Object detection is a fundamental task in computer vision. The backbone feature extractor is usually taken from classification literature. However, directly using classification network backbones for object detectors is sub-optimal. To address this, various approaches modify the backbone network, including a neural architecture search (NAS) framework proposed to improve detection performance. The Effective Receptive Field (ERF) is crucial for designing an effective backbone dedicated to detection tasks, as it handles scale variance across instances. Unlike image classification tasks, object detection tasks require larger ERF capacities due to varying object sizes. The Effective Receptive Field (ERF) is essential for detection tasks to handle scale variance. Experiment shows computation allocation impacts ERF, with spatial position affecting detector performance. ERF of FPN features varies with resolution, ResNet50 shows redundant ERF for high resolution features and limited ERF for low resolution features. In this paper, the authors propose computation reallocation NAS (CR-NAS) to automatically design the computation allocation of backbone for object detectors. Unlike existing detection NAS works, they reallocate the computation cost in a more efficient way by searching for the best strategy to distribute the computation among different resolutions and spatial positions. The authors introduce CR-NAS for automatic computation allocation in object detection. They propose a hierarchical search algorithm to optimize the search space, reducing searching costs. CR-NAS improves models like ResNet, MobileNetV2, and ResNeXt on the COCO dataset, achieving higher AP without extra computation. Additionally, CR-NAS is applied to instance segmentation tasks using Mask RCNN. The paper introduces CR-NAS for automatic computation allocation in object detection, improving models like ResNet, MobileNetV2, and ResNeXt on the COCO dataset. CR-NAS utilizes a hierarchical search algorithm to optimize the search space, reducing searching costs. It also extends to instance segmentation tasks using Mask RCNN, showing significant improvements in various types of networks. Neural Architecture Search (NAS) focuses on automating network architecture design, with recent approaches like weight sharing to reduce computational costs. One-shot NAS methods build a supernet to search for architectures, while our work differs by allocating computations across different resolutions. Our work differs from previous NAS methods by carefully designing a search space that allocates computations across feature resolutions. Existing NAS methods for object detection introduce additional computation budget and inherit the search space from classification tasks, which is suboptimal. We focus on searching for the number of blocks in each stage, crucial for object detection. Our search method, based on Faster RCNN with FPN, reallocates computation within the backbone for fair comparison. We adopt the one-shot NAS method, using a supernet to encompass all architectures in the search space. CR-NAS distributes computation resources across different resolution stages. The backbone reallocates computation resources across different resolution stages to generate intermediate-level features with increasing downsampling rates. Each stage contains branches with a certain number of blocks, allowing for different computational budgets within the stage. The text discusses reallocating computation resources in different resolution stages of a network to generate intermediate-level features. It mentions the number of blocks in each stage and the allocation strategy for ResNet101. The goal is to find the best allocation strategy among many choices, considering different computation budgets. The search space covers candidate instances in the ResNet series with varying numbers of blocks for different stages. Dilated convolution is used to reallocate computation across spatial positions, enhancing the Effective Receptive Field (ERF) without introducing additional parameters. Dilated convolution is utilized to reallocate computation across spatial positions in ResNet models. A hierarchical search procedure is proposed to find the best computation allocation for different resolutions and improve architecture with better spatial allocation. The operation set includes dilated convolutions with different dilation rates, resulting in a vast search space of possible architectures. The text discusses the use of uniform sampling in supernet training to improve spatial allocation in models. It also mentions evaluating allocation strategies directly on the task detection task to find the best strategy. The process involves sampling operations in different blocks to generate temporary architectures for evaluation. In the architecture search process, a greedy algorithm is proposed to make sequential decisions for obtaining the final result. The algorithm involves maintaining the top K partial architectures in each choice step and evaluating candidate operations from the first to the last choice block. The hyper-parameter K is set to 3 in the experiment, with the partial architecture extended in the first block choice. In the architecture search process, a greedy algorithm is used to select the best architecture. The top 3 partial architectures are expanded into the whole length, resulting in 9 partial architectures in other block choices. Each architecture is validated on a mini-batch, and the best architecture is chosen. The method is evaluated on the MS COCO benchmark dataset, with training and evaluation splits. The final model is fine-tuned on the whole COCO trainval135 and validated on COCO minival. VOC trainval2007+trainval2012 is used as the training dataset and VOC test2007 as the validation dataset. The input images are resized to have a short side of 800 pixels or a long side of 1333 pixels. Stochastic gradient descent (SGD) is used as the optimizer with 0.9 momentum and 0.0001 weight decay. Models are trained for 13 epochs with a total batch size of 16 over 8 1080TI GPUs. The initial learning rate is 0.00125 per image and is divided by 10 at 8 and 11 epochs. The final architectures, denoted by 'CR-', utilize computation reallocation and show improved performance compared to baseline models. CR-ResNet50 and CR-ResNet101 outperform the baseline by 1.9% and 1.6% respectively, with consistent improvements observed in longer settings. Our CR-ResNet50 and CR-ResNet101 show significant improvements for large objects, reallocating capacity in deep stages for better performance. Dilated convolutions in deep stages help detect large objects efficiently, balancing the effective receptive field. Additionally, CR-ResNet18 and CR-MobileNetV2 enhance performance by 1.7% AP over baselines. Our CR-ResNet18 and CR-MobileNetV2 improve AP by 1.7% over baselines. Capacity reallocation benefits small objects through FPN pathway. Model transferred to VOC dataset shows 1.0% and 0.7% AP 50 improvement. Computation reallocation network applied to instance segmentation task in Mask RCNN framework on COCO dataset. Our CR-MobileNetV2, CR-ResNet50, and CR-ResNet101 outperform baseline in instance segmentation and bounding box AP. The CR-Res101 with Cascade Mask RCNN achieves 44.5% AP, a 1.2% gain over regular Res101. Replacing FPN with NAS-FPN neck strengthens results, with CR-Res50 achieving 41.0% AP. More detailed results can be found in Appendix A.4. Our design includes two parts, stage reallocation search and block operation search. The stage reallocation brings a solid average 1.0% AP improvement across different models. There is a trend to reallocate computation from shallow to deep stages, resulting in a balanced ERF and enhanced ability to detect medium and large objects. In this study, the authors explore the performance correlation between classification and detection tasks using different network architectures. They find that better classification accuracy does not always lead to better detection accuracy, highlighting a gap between the two tasks. The authors introduce CR-NAS, a neural architecture search method that can learn computation reallocation strategies across different resolutions and spatial positions. The authors introduce CR-NAS, a neural architecture search method that can learn computation reallocation strategies across different resolutions and spatial positions. Extensive experiments show the effectiveness of the approach, with great transfer-ability to other detection tasks and datasets. The CR-NAS can be used as a plugin to boost performance in detection backbones under certain computation resources. The supernet is trained with 0.9 momentum and 0.0001 weight decay for 150 epochs using cosine learning rate decay. Supernet fine-tuning involves resizing input images and training for 25 epochs with SGD optimizer. Multi-GPU training is used with a total batch size of 16, and the learning rate is adjusted at specific epochs. Warm-up and synchronized BatchNorm are employed for convergence. The stage allocation space for ResNeXt is the same as the ResNet series. MobileNetV2 uses a specific block allocation defined by n=[1, 1, 2, 3, 4, 3, 3, 1, 1, 1]. The architecture is built on the bottleneck operator with fixed stem and tail components. The final model is represented by a series of allocation codes. Training is done on VOC trainval2007+trainval2012 and tested on VOC test2007 with a pretrained model. Input images are resized to have a short side of 600 pixels or a long side of 1000 pixels. Stochastic gradient descent (SGD) is used as the optimizer with 0.9 momentum and 0.0001 weight decay for 18 epochs. Multi-GPU training is utilized. The models are trained for 18 epochs with a total batch size of 16 using multi-GPU training. The initial learning rate is 0.00125 per image and is adjusted at specific epochs. Warm-up and synchronized BatchNorm are used for convergence. The Cascade Mask RCNN detector is trained for 20 epochs with similar training settings. NAS-FPN is a scalable feature pyramid architecture searched for object detection. NAS-FPN (7 @ 384) is a powerful feature pyramid architecture used for object detection, implemented in Faster RCNN under 1\u00d7 setting."
}