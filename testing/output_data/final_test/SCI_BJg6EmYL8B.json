{
    "title": "BJg6EmYL8B",
    "content": "The interplay between inter-neuronal network topology and cognition has been deeply studied by connectomics researchers and network scientists. The deep learning revolution has not focused much on topological aspects, unlike biological neural networks. Deep Connectomics Networks (DCNs) are presented as DNNs with topologies inspired by real-world neuronal networks, showing high classification accuracy. This bridges the gap between biological and artificial neural network architectures. The field of deep neural networks has focused on optimization and generalization techniques, with convolutional layers inspired by cats' visual cortex. However, there is a lack of inspiration from brain connectomics in post-AlexNet neural network architectures. The small-world network model introduced by Watts & Strogatz in 1998, exemplified by the neuronal network of C. Elegans, marked a departure from traditional literature by considering network topology. The small-world network model introduced by Watts & Strogatz in 1998, exemplified by the neuronal network of C. Elegans, serves as an attractive model for brain organization. Bridging neural connectomics and deep learning, there is potential in designing neural network wiring based on connectomic structures. Designing neural network wiring based on connectomic structures is an intersection between network sciences, neuroscience, and deep learning. Small-world networks, proposed by Watts and Strogatz in 1998, exhibit high clustering and small average path length. These networks are present in various systems such as C. Elegans's connectome, power grid networks, and protein interactions. In neuroscience, the small-world model captures individual cognition and has a physiological basis. In development psychology, small-world modules and hubs are present during mid-gestation, and early brain network topology can predict later behavior and cognitive performance. Different network models like ER, BA, and WS have been applied for image classification, showing that randomly wired neural networks can achieve competitive accuracy on the ImageNet benchmark. ResNets and DenseNets have been successful in surpassing human-level performance on ImageNet due to creative wiring patterns with skip connections between convolutional layers. DCNs are constructed based on biological neuronal network patterns, inspired by small-world structures in deep CNNs. Wired graphs adopt connectomics structure from mouse and C. Elegans connectomes, with colored nodes indicating localized clusters in DCNs. Neuronal networks of C. Elegans and the mouse visual cortex are treated as undirected graphs converted to directed acyclic graphs (DAGs) for analysis. The curr_chunk discusses the construction of Directed Acyclic Graphs (DAGs) for neural networks, following a similar approach as Xie et al., 2019. It introduces source and sink nodes to ensure singular input and output. The architecture is based on the \"small regime\" RandWire model with modifications in the number of layers and wiring modules used. The curr_chunk describes the training process and evaluation of different graph structures, including the RandWire architecture with weighted sums and convolutions. It compares models with and without DAGs, evaluating them on MNIST and C. Elegans datasets. The curr_chunk discusses the evaluation of different graph structures on MNIST, Fashion-MNIST, and KMNIST datasets. It compares the performance of DCNs with WS graphs against baselines without graphs, showing that biologically wired DCNs outperform both. The significance of graph topology is highlighted by experiments where freezing the graph still results in improved performance for the Mouse visual cortex model. The performance of C. Elegans DCN was evaluated on MNIST, KMNIST, and Fashion MNIST datasets, achieving 99%, 93%, and 90% mean test accuracy respectively. Experiments demonstrated the trainability of DNN based on neuronal network topologies, outperforming WS graphs. Future work will focus on constructing a DAG from these networks and analyzing the impact of graph topologies on proposed architectures. The architecture proposed by Xie et al., 2019, and the graph topologies used in the architectures were extended to other connectomes."
}