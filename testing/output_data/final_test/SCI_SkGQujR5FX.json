{
    "title": "SkGQujR5FX",
    "content": "Distributed computing can reduce neural network training time, but it is not widely adopted due to difficulties in scaling and the need for extensive hyperparameter tuning. DANA is a novel approach that scales to large clusters using the same hyperparameters optimized for single worker training, maintaining similar accuracy without extra overhead. It adapts Nesterov Accelerated Gradient to a distributed setting to estimate future model parameters and mitigate gradient staleness in scaling SGD to more workers. DANA scales well on state-of-the-art network architectures and datasets without hyperparameter tuning. Achieving 75.73% accuracy on ImageNet with ResNet-50 and 16 workers, it addresses the challenge of training deep neural networks efficiently on multiple GPUs. Data Parallelism is a common practice for distributing computation, with Synchronous SGD (SSGD) being a straightforward method for training neural networks. However, SSGD limits scalability and model accuracy due to synchronization issues. Asynchronous SGD (ASGD) addresses these drawbacks by removing synchronization. Several works attempt to address the gradient staleness issue in distributed ASGD, but none have successfully overcome the problem when scaling to a large number of workers. Many ASGD algorithms require re-tuning of hyperparameters when scaling to different numbers of workers, leading to slow convergence and reduced final accuracy. Tuning is often done in parallel, with each worker independently evaluating a single configuration. Distributed Accelerated Nesterov ASGD (DANA) is a new algorithm that achieves state-of-the-art accuracy on existing architectures without the need for additional hyperparameter tuning or changes to the training schedule. It scales as well or better than existing ASGD approaches, without any extra overhead. Our DANA implementation achieves state-of-the-art accuracy on ImageNet when training ResNet-50 with 16 and 32 workers, as well as on CIFAR-10 and CIFAR-100. The goal of SGD is to minimize an optimization problem J(\u03b8) where J is the objective function and \u03b8 is the model's parameters. Momentum accelerates SGD convergence and reduces oscillation by adding a fraction \u03b3 of the previous update vector to the current update vector. Nesterov Accelerated Gradient (NAG) improves convergence rate by giving the ball a \"sense\" of where it is going, allowing it to slow down in advance. It approximates the future value of parameters using the previous update vector and computes gradients on the approximated future value. Nesterov Accelerated Gradient (NAG) computes gradients on the approximated future value of parameters, allowing it to slow down near minima before overshooting and climbing back up. This look-ahead approach helps estimate future gradients accurately even with large update vectors. The master receives up-to-date parameters from workers, computes gradients, and applies them to its current parameters with a lag \u03c4. Gradient staleness due to lag \u03c4 is a challenge for scaling ASGD, as it decreases gradient accuracy. The difference between master and worker parameters is denoted as \u2206 \u03b8, and the gap is defined as the sum of layer-wise RMSE. Ideally, there should be no difference between the current and lagged parameters. In asynchronous methods, more workers lead to increased lag \u03c4 and a larger gap between computed and applied parameters, resulting in less accurate gradients. Momentum and Nesterov methods improve convergence but make scaling to more workers challenging, exacerbating gradient staleness. In asynchronous methods, adding workers or using momentum increases the lag \u03c4 and gap G(\u2206 \u03b8 ). Nesterov Accelerated Gradient (NAG) and momentum increase the magnitude of updates to \u03b8 t, improving convergence but challenging scaling to more workers. DANA is a distributed optimizer that reduces the gap in training by computing worker's gradients on parameters closer to the master's future position. It extends NAG to a common distributed setting with N workers and one master, achieving similar look-ahead as the traditional method with a single worker. This results in a reduced gap compared to traditional methods. In DANA-Zero, the master maintains separate update vectors for each worker, allowing for look-ahead using recent update vectors. Instead of sending current parameters, DANA-Zero sends estimated future positions after N updates. DANA-Zero master algorithm is shown in Algorithm 3, using the standard ASGD worker code. The gap of DANA-Zero is calculated similarly to Equation 3. Empirical results show that DANA-Zero's gap is similar to ASGD, even with momentum. With one worker, DANA-Zero reduces to a single standard NAG optimizer. In DANA-Zero, the master maintains an update vector for every worker and computes \u03b8 at each iteration, adding overhead. DANA is a variation that achieves the same look-ahead without extra memory or computation. Bengio-Nesterov Momentum simplifies the Nesterov update rule and is used in deep learning frameworks for easier implementation. The Bengio-Nesterov update rule simplifies the update process by storing only one set of parameters in memory. DANA leverages Bengio-Nesterov Momentum to optimize the update process, eliminating overhead at the master. It uses the same master algorithm as ASGD but changes the worker side to achieve the same benefits as DANA-Zero. DANA is similar to DANA-Zero and offers benefits like out-of-the-box functionality, look-ahead for gap reduction, fast convergence, and high accuracy. It was implemented using PyTorch and mpi4py, evaluated through simulations on single and multiple machines with different scheduling models. The gamma distribution BID0 is used to model task execution time, with parameters V = 0.1 and \u00b5 = B * V 2. The main evaluation metric is final test error, and speedup is measured using the distributed DANA implementation. DANA is compared to algorithms that do not introduce new parameters or require re-tuning. In the early stages of training, various asynchronous SGD algorithms are proposed, including SSGD, ASGD, NAG-ASGD, Multi-ASGD, and DANA. A gradual warm-up approach is used to overcome training error spikes, and momentum correction is applied to stabilize training. DANA is evaluated on CIFAR-10, CIFAR-100, and ImageNet datasets. DANA was evaluated on CIFAR-10, CIFAR-100, and ImageNet datasets. CIFAR-10 has 60k RGB images with 50k training and 10k test images, while CIFAR-100 has 100 classes. ImageNet BID24 consists of 1.28 million training images and 50k validation images. DANA's final test error remains similar to baseline with up to 24 workers. It outperforms other algorithms with 24-32 workers without tuning, but is no longer superior beyond that due to the smaller size of CIFAR-10 and CIFAR-100. DANA's superiority diminishes on CIFAR-10 and CIFAR-100 due to small data per worker, impacting gradient similarity and momentum mitigation. ImageNet results show DANA scales well with 32 workers. NAG-ASGD suffers from momentum's negative impact on gradient staleness, leading to high test error with more than 16 workers. ASGD without NAG is scalable but has high test error even with 2 workers. SSGD offers a balance of accuracy and scalability, but synchronization limits speedup and tuning is needed for good accuracy. DANA outperforms other algorithms on ImageNet with SSGD, ASGD, and DANA. It achieves the best final accuracy while scaling to many workers without changing hyperparameters or learning schedules. Multi-ASGD's poor scalability shows that maintaining update vectors for every worker is not sufficient. DANA's update rules are necessary for high test accuracy. DANA outperforms other algorithms on ImageNet without changing hyperparameters or learning schedules. It achieves high test accuracy with up to \u00d716 speedup when training with N = 24 workers on the Google Cloud Platform. DANA achieves up to \u00d716 speedup when training with 24 workers on the CIFAR-10 dataset. The parameter server becomes a bottleneck at 24 workers, consistent with literature on ASGD. Existing techniques like sharding the parameter server and gradient compression are compatible with DANA. DANA is up to 21% faster than SSGD, with potential for further speedup not accounted for in simulations. DANA achieves out-of-the-box scaling by mitigating gradient staleness effects. Other approaches like DC-ASGD and EASGD introduce additional hyperparameters and computation requirements. Staleness-aware ASGD is also proposed for worker gradients. New hyperparameters must be tuned for scaling methods like Staleness-aware ASGD, which weights worker gradients based on update lag. DANA scales without additional hyperparameters, achieving comparable accuracy to a single worker. Other approaches include SSGD learning rate schedulers, such as linear scaling rules and warmup epochs introduced by BID8. BID30 introduces LARS, which adjusts learning rates independently for each layer. BID25 suggests increasing batch size instead of decaying learning rate. DANA is a new asynchronous SGD algorithm for training neural networks that scales to large clusters without the need for additional hyperparameters. It mitigates gradient staleness effects and maintains similar final accuracy to training on a single worker. DANA is an asynchronous SGD algorithm for training neural networks in large clusters without extra hyperparameters. It maintains final accuracy similar to training on a single worker and can be extended to other optimization procedures without adding parameters. DANA-Zero reduces to a single NAG optimizer when running with one worker. Algorithm 5 Fused DANA-Zero worker/master (when N = 1) computes gradients and updates weights for network architectures on CIFAR-10 and CIFAR-100 datasets. Experiments were conducted with different worker update orders: Round Robin, Block Random, and Gamma Distribution. The gamma distribution model is used for task execution time, leading to stragglers naturally. Parameters are set as V = 0.1 and \u00b5 = B * V^2, with B as the batch size. For a batch size of 128, the distribution yields a mean execution time of 128 simulated time units. Tables 3 and 4 display the final test error of the ResNet-20 architecture under different training schedules (BID10 and BID31) with specific learning rates, batch sizes, momentum, and optimization algorithms."
}