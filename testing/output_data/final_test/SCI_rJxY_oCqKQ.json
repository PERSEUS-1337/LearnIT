{
    "title": "rJxY_oCqKQ",
    "content": "Existing tools for detecting image duplication in scientific publications are mostly manual or semi-automated. This paper proposes a solution using a 3-branch Siamese Convolutional Neural Network to determine if one image is a manipulated version of another through various geometric and statistical manipulations. The model maps images into a 128-dimensional space and can improve surveillance of image manipulation. Our study suggests using a 3-branch Siamese Convolutional Neural Network to detect image manipulation in scientific literature. Data duplication, especially with altered images, is a common issue in biomedical research. Various manipulations like changing orientation or introducing skew can affect experimental outcomes. The network also learns useful representations for semantic segmentation, comparable to domain-specific models. Efforts to prevent the inclusion of duplicative or flawed image data in scientific literature are ongoing. Current methods rely on visual identification and qualitative similarity measures, but automation tools are being developed to detect manipulated images. However, a consistent approach to screening problematic image data has not been established yet. Automated tools are needed to detect potential image manipulation in scientific literature. This tool would assist in more focused evaluation of problematic image data. The field of computer vision has studied the detection of similar images, with recent advancements in deep Convolutional Neural Networks for facial recognition. In this paper, modern methods in metric learning are applied to detect image manipulation in scientific work using deep Convolutional Neural Networks. A ConvNet is trained to learn an image embedding that groups altered images with the same original content together. The model is tested on manipulated images from known instances of image duplication/manipulation, focusing on biological images but applicable to any image domain. This is the first application of deep learning to detect image re-use in scientific literature. The model described is agnostic to the image domain and is tested on new/unseen data for duplicate-detection and semantic segmentation. Features learned in the siamese network's convolution layers can be used in a pixel classifier, producing comparable results to domain-specific architectures. The model is based on BID3, BID14, and BID8, and utilizes a siamese neural network for image similarity. During training, pairs of images are fed to the network to learn a representation that minimizes the L1 distance between similar images and maximizes it for dissimilar ones. In BID14, a triplet loss was used with image triplets (anchor, positive, negative) to encourage a locally Euclidean embedding space. Hard negative mining was employed for fast convergence. In BID8, a non-conventional metric was used with a 2-branch architecture to learn a binary output for image similarity, eliminating the need for a proximity threshold. However, the proposed loss function was unstable for similar images, leading to a modification with a threshold of 1 for image dissimilarity. The text discusses using a triplet network architecture to determine if two images are the same or different, with a threshold of 1 for dissimilarity. The network learns the appropriate scaling for the metric to comply with this threshold. Various techniques such as batch normalization and residual learning are also employed for better performance. The model utilizes a triplet network architecture with batch normalization and residual learning techniques. The image representation is a vector of dimension 128. The forensic metric is defined with parameters to be learned. The triplet loss function enforces a threshold of 1 for similarity criteria. The study utilized a triplet network architecture with batch normalization and residual learning techniques to address image manipulation detection. A threshold of 1 for similarity criteria was enforced using a triplet loss function. Simulated examples of image manipulation were generated to train the model, which included various operations such as identity, rotation, translation, scale, or perspective transform, local or global histogram adjustment, partial erasing, and jpeg-like compression artifacts. The study gathered data from various sources including biomedical images and public databases like the NYU Mouse Embryo Tracking Database and the Broad Bioimage Benchmark Collection. The dataset consisted of 20 classes of images from different cell types and model organisms. Images were cropped into patches of 256 \u00d7 256 pixels for training, totaling 5215 images. A separate set of images from 10 biological subjects was used for testing. Training involved sampling two batches of images at each step. During training, batches of images are sampled for the anchor, similar, and different branches of the siamese net. On-the-fly deformations of varying degrees and types are applied to the anchor images using pseudo-code functions like random reflection, perspective transform, similarity transform, crop, jpeg compression, gamma adjustment, and local edit. During training, batches of images are sampled for the anchor, similar, and different branches of the siamese net. On-the-fly deformations are applied to the anchor images using functions like random reflection, perspective transform, crop, jpeg compression, gamma adjustment, and local edit. The \"anchor\" and \"different\" images are center-cropped to 128 \u00d7 128 to match the size of the \"different\" image. Random clutter can be added to all images in the triplet. Specific deformation parameters will be available with the source code release. Examples of deformations are shown in FIG1. The algorithm described in Subsection 3.3 trains the model with a momentum optimizer for 20k steps using a batch size of 128. Accuracy on the validation set reaches around 0.96. The test set includes 108 classes of duplicates, each containing multiple manipulations of the same image. Performance is evaluated by randomly selecting images from different classes and measuring correct predictions. The synthetic test set has 402 classes with 10 replicates each, where 9 deformations are created per class from a single fixed image not present in the training set. The algorithm trained the model with a momentum optimizer for 20k steps using a batch size of 128, reaching around 0.96 accuracy on the validation set. The synthetic test set had 402 classes with 10 replicates each, with 9 deformations per class from a single fixed image not in the training set. SN[G] performed worse on the synthetic set due to more deformations, but similarly on the real-world test set. Real-world example images couldn't be published due to copyright issues, but synthetic images were shown in Figure 3. The 128-dimensional vector in each branch of the siamese network is useful for image clustering, search, or classification. In this study, the features of convolution layers are explored for image segmentation by upsampling and concatenating feature maps similar to U-Net architecture. A hybrid siamese net + random forest model is compared with U-Net in background/foreground segmentation tasks using different datasets. The hybrid model consists of upsampling and concatenating feature maps of the last 3 convolution layers. The model concatenates feature maps of the last 3 convolution layers, resulting in a feature vector of dimension 128+64+32. Training is done on the original dataset without augmentation. The U-Net for cell segmentation has 4 downsampling layers, while the one for nuclei segmentation has 3. Training datasets are augmented by a factor of 40 with rotations, reflections, and distortions. The likelihood of image pairs being the same is visualized in Figure 3. The matrices show similarity between classes of duplicates in real-world and synthetic test sets. The datasets are organized with classes from the same category indexed nearby. Each fixed image has 5 nearest neighbors below it. The last line discusses a siamese net trained with only geometric deformations, resulting in faster training with no substantial loss. Siamese networks trained with geometric deformations are faster to train with improved performance for nuclei segmentation. Using images from the nuclei segmentation task for training suggests a new approach for segmentation with small annotated datasets. This method may not definitively determine image duplication but can narrow down the pool of images for surveillance in published literature. The study aims to improve accuracy by exploring synthetic manipulations and addressing errors in real-world test sets. Improvements are needed for detecting different images from the same category. A major challenge is the lack of a large-scale database for testing the model due to legal issues. The dataset is continuously expanding to overcome this roadblock. The application of semantic segmentation was discovered to address issues with the U-Net, such as the need for a large corpus of annotations and difficulty in setting hyperparameters. The forensic siamese net's representation is easier to deploy with a random forest classifier. The dataset is continuously expanding to overcome legal issues."
}