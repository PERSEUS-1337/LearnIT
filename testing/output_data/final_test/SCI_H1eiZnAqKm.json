{
    "title": "H1eiZnAqKm",
    "content": "Gated recurrent units (GRUs) were developed as a simpler alternative to LSTM for capturing temporal structure in various tasks. Despite their success in language processing, speech, and music, little is known about the specific dynamic features of GRU networks. A new theoretical framework is proposed in this paper to analyze the dynamical features of one and two dimensional GRUs as continuous systems. The study explores the dynamic features of GRU networks, revealing limitations in replicating certain attractor dynamics. RNNs are commonly used for sequential data analysis due to their ability to retain past information, allowing for memory in temporal sequences. Training vanilla RNNs to capture long-range dependencies is challenging due to the vanishing gradient problem. Special RNN architectures like LSTM and GRU have been proposed to address this issue. GRUs, a simplification of LSTM, have gained popularity in various machine learning tasks. While GRUs reduce the number of parameters by omitting an output gate, LSTM has been shown to outperform GRU in neural machine tasks. LSTM outperforms GRU in neural machine translation tasks by reducing parameters. LSTM excels in tasks like unbounded counting, while GRU lacks systematic understanding of its memory structure. RNNs evolve over time with input x t and hidden state h t, representing future output. The hidden state h t can evolve independently, forming a trajectory of a dynamical system. The text discusses using dynamical systems theory to study the limits of RNNs in terms of their temporal features, specifically focusing on GRUs. It introduces a theoretical framework and validates it by training GRUs to predict time series with prescribed dynamics. The GRU model includes update and reset gates to control the hidden state and interaction with input. The GRU model includes parameter matrices, bias vectors, and activation functions to control the hidden state dynamics. The update gate regulates the decay of each dimension in the hidden state, allowing for adaptive memory retention. Autoregressive weights support evolving memory capabilities in the GRU model. The continuous-time limit of the GRU model is analyzed by considering the dynamics of the hidden state in the absence of input. The update gate acts as a state-dependent time constant for memory decay, and the effects of the update gate can be ignored for theoretical analysis. The continuous-time GRU model can be analyzed by considering the dynamics of the hidden state without input effects. For a single GRU, the system reduces to a one-dimensional dynamical system with limited stability structures. Three possible topologies exist, each corresponding to different temporal features. Bistability in the system can capture a binary latent state in the sequence. It is important to note that a one-dimensional continuous-time autonomous system cannot exhibit oscillatory behavior. The topology of a single GRU is determined by its parameters, leading to a saddle-node bifurcation where the system changes its stability. Bifurcation is a change in the dynamical system's topology due to parameter variations, with the bifurcation point marking the transition. The codimension of a bifurcation is the number of parameters needed for it to occur. A saddle-node bifurcation is codimension-1. Slow points near a half-stable node can exhibit arbitrarily slow flow. Adding a second GRU opens up various topological structures. The flow fields can be visualized in 2D phase portraits, showing stable states and fixed points. The curr_chunk discusses the stability structures attainable by two GRUs, showcasing various local dynamical features and non-local dynamical features. The focus is on demonstrating the observed topologies and their parameters, with a catalog available in the appendix. The global geometry is nonlinear, with 4 stable states and 9 fixed points. The fixed points exhibit locally linear dynamics, but their topological structures can vary. The curr_chunk describes the bifurcation fixed points observed in two GRUs, including codimension-1 and codimension-2 bifurcation points. These points act as hybrids between stable, unstable, and saddle points, leading to a richer set of dynamics. The codimension-1 bifurcation includes saddle-node fixed points, classified into two types. The curr_chunk discusses the observation of bifurcation fixed points in a two GRU system, including codimension-2 bifurcation points that act as hybrids of stable, unstable, and saddle points. These fixed points are depicted in figures and show a potential interpretation as a continuous analogue of 5-discrete states with input-driven transitions. The curr_chunk discusses the system depicted in FIG2 with eleven fixed point structures obtainable with two GRUs, implying the need for additional GRUs for Markov processes with more than five discrete states. The addition of bifurcation fixed points allows for the realization of more sophisticated models, such as the trajectory flowing towards the codimension-2 bifurcation fixed point at the origin when the hidden state is initialized in the first quadrant of phase space. Introducing noise through the input can stochastically cause the trajectory to approach the stable fixed point at (-1,-1). The curr_chunk discusses the existence of homoclinic orbits in two GRUs, leading to bounded planar regions where trajectories flow into a codimension-2 bifurcation fixed point. This behavior enables accurate modeling of neuron spiking dynamics. The curr_chunk explains how two GRUs can exhibit an Andronov-Hopf bifurcation, leading to a stable fixed point bifurcating into an unstable fixed point surrounded by a limit cycle. This phenomenon is demonstrated by adjusting parameters, with a stable spiral at \u03b1 = \u03c0/3 and an Andronov-Hopf bifurcation around \u03b1 = \u03c0/3.8. The orbital period increases as \u03b1 decreases, with trajectories forming a stable periodic orbit around the unstable fixed point. The system exhibits a single stable fixed point at the origin as \u03b1 decreases continuously, leading to a limit cycle emerging around the fixed point. Further decreasing \u03b1 increases the size and orbital period of the limit cycle. The question arises whether two GRUs can have an infinite number of fixed points. Two GRUs cannot have an infinite number of fixed points. Any two-dimensional GRU can only have finitely many simple fixed points, as proven in Lemma 1. Theorem 1 extends this result to finite-dimensional GRUs, showing they can only have finitely many simple fixed points and bifurcation fixed points. The compact set [\u22121, 1] d follows from Lefshetz theory that there are finitely many simple fixed points in a GRU. Bifurcation fixed points can only exist within a stability structure if there exists a separate topology, leading to finitely many isolated bifurcation fixed points. A finite dimensional GRU cannot have a continuous attractor. In a GRU system, it is shown that there is no continuous attractor in any direction. However, a pseudo-line attractor can be approximated using two GRUs, which can closely mimic an actual line attractor on a finite region in phase space. This phenomenon allows for computational needs to be met on an arbitrary interval when scaled. Additionally, slow points in the two GRU system occur where the nullclines are close together. In a single GRU system, slow points occur where the nullclines are close together but do not intersect. Slow points can only exist if a saddle-node bifurcation fixed point is possible in the desired location, resulting from the collision of two fixed points. A maximum of five slow points are possible in the single fixed point case, with four simultaneous slow points obtainable. In this section, the text explores examples of time series prediction using two GRUs in continuous time planar dynamical systems. The network consists of two GRUs in the hidden layer followed by a linear output layer, trained to make a 29-step prediction from a given initial observation. The results from previous sections indicate the dynamical features that can be learned by this RNN and suggest cases where training may fail. The RNN is trained to predict a 29-step trajectory using hidden layer dynamics only. The network minimizes a multi-step loss function and is trained for 4000 epochs using ADAM. Experimental results show the RNN's attempt at learning different dynamical systems. In testing two GRUs' ability to learn a limit cycle, the FitzHugh-Nagumo Model with specific parameters was used. The experiment confirmed that two GRUs can represent the system's dynamics accurately, including a pseudo-line attractor along the y-axis. The experiment involved adding Gaussian noise to the training data of a dynamical system representing a standard ring attractor. Two GRUs were unable to accurately capture the system's continuous attractor dynamics, as shown in FIG7. The experiment demonstrated in FIG7 shows that the RNN fails to capture the proper dynamical features of the ring attractor. The hidden state dynamics fall into a fixed point topology, and the quality of approximation improves with higher GRU dimensionality (FIG8). A new theoretical framework was developed to analyze GRUs as a continuous dynamical system, revealing their ability to exhibit various dynamic features but unable to replicate the dynamics of an arbitrary continuous attractor. The experiment showed that RNNs struggle to capture the dynamics of a ring attractor. GRUs were analyzed as a continuous dynamical system, revealing their limitations in replicating arbitrary continuous attractors. The study suggests new research directions for the trainability of recurrent neural networks. The derivation process involves rewriting equations with bounded functions and taking limits to obtain a continuous time system. The fixed points of the continuous time system are where the derivative equals zero, and in the single GRU case, the Hadamard product simplifies to standard scalar multiplication. In the study, the update gate does not affect the system's stability. Various topologies of multiple-fixed point structures using two GRUs are analyzed. Parameters for each case are listed, with all update gate parameters set to zero. The cases were discovered by hand considering geometric constraints on nullcline structures for both decoupled and coupled systems. An exhaustive analysis on the two-dimensional decoupled GRU was conducted, exploring different intersection patterns of nullclines using the reset gate. Thirty-six multiple fixed-point topologies were identified in phase space, showcasing trajectories and fixed points. The update gate parameters were set to zero for each case, with geometric constraints guiding the discovery of these structures. Figure 10 shows thirty-six fixed-point topologies with two GRUs in phase space. Orange and pink lines represent nullclines, red dots indicate fixed points, and trajectories are depicted with purple lines. The flow direction is shown by black arrows, and the color map represents flow velocity magnitude in log scale. The text chunk discusses the topology of fixed points with two GRUs in phase space. It mentions that all fixed points obtained with two GRUs are Lefschetz fixed points. The proof involves expanding notation and setting certain elements to zero. If 0 is not an eigenvalue of the Jacobian matrix at a fixed point, it is considered a Lefshetz fixed point. The text discusses Lefshetz fixed points in the context of two GRUs in phase space. It involves the Jacobian matrix at a fixed point and eigenvalues. The characteristic equation is derived for the fixed points. The text discusses Lefshetz fixed points in the context of two GRUs in phase space. It involves the Jacobian matrix at a fixed point and eigenvalues. The characteristic equation is derived for the fixed points. The equations are rewritten in terms of u(x, y, \u03b8) and v(x, y, \u03b8). Setting \u03bb = 0 yields a constraint that implies \u03bb = 0 for all \u03b8, making it a Lefschetz map. Trajectories initialized outside the trapping region transition into it, reaching a point in the range of [-1, 1] 2. The transition of the initial condition into the trapping region implies a finite number of simple fixed points exist on a compact set."
}