{
    "title": "HJxkvlBtwH",
    "content": "The first end-to-end verifier of audio classifiers is presented, allowing analysis of audio processing and recurrent neural network architectures. Novel convex relaxations verify audio processing operations like Fast Fourier Transform, while a binary relaxation certifies recurrent unit updates. The verifier scales to large networks and provides tighter bounds than existing methods for audio classification benchmarks, certifying 95% more inputs on the Google Speech Commands dataset. Recent work has focused on certifying the robustness of automated speech recognition systems against noise injected by adversaries, following concerns about the safety of neural networks in consumer devices. Various studies have shown that adversaries can manipulate networks to misclassify by injecting undetectable noise. This poses a serious security threat that needs to be addressed to ensure the system's reliability. The audio domain presents unique challenges not addressed by prior certification work for vision models. Audio models require complex preprocessing stages and recurrent architectures, unlike vision models. This work proposes an end-to-end verification method for neural network-based audio systems. The text proposes an end-to-end verification method for neural network-based audio classifiers called DAC. The method aims to certify that the neural network correctly classifies signals even when subjected to noise-based perturbations. Verification is done using abstract interpretation to capture all possible behaviors of the audio processing stage and the neural network. The audio processing stage involves abstract transformers for each operation like FFT, producing abstraction x (i). This is then fed into the LSTM unit with transformers for each operation, resulting in hidden state h (i). The final hidden state h (T) is passed through a fully connected layer using abstract transformers in the neural network. The POPQORN verifier for recurrent neural networks (RNN) does not handle the audio preprocessing pipeline, resulting in a significant slowdown when integrated with DAC. In contrast, using custom abstract transformers for LSTM allows for certification of audio classifiers without such slowdown. Using custom abstract transformers for LSTM non-linearities, DAC can certify end-to-end robustness of audio classifiers efficiently. The method handles noise-based perturbations and includes verification and provably robust training. DAC outperforms other scalable methods with 97% to 2% precision on audio classification benchmarks. The text discusses audio processing using Mel-Frequency Cepstrum (MFC) and LSTM updates, along with a verification method for signal perturbations. The threat model assumes attackers can add noise to the signal, and the goal is to verify correct classification under small perturbations. The use of MFC for audio preprocessing in speech recognition systems is highlighted. The text discusses audio processing using Mel-Frequency Cepstrum (MFC) for speech recognition systems. MFC models human acoustic perception with Mel-frequencies and computes log-scaled values of filtered spectra. The resulting vector serves as a feature representation for downstream tasks like audio classification. Sahidullah & Saha (2012) proposed an approach for MFCC computation using matrix operations integrated into a verification framework. Audio preprocessing with MFCC involves pre-emphasizing, windowing, and transforming the signal. The text discusses audio processing using Mel-Frequency Cepstrum (MFC) for speech recognition systems. It involves pre-emphasizing, windowing, FFT, filter bank log energy, and DCT. The resulting features are used as input for a neural network, including Long-Short Term Memory (LSTM) architectures. In modern speech recognition systems, Long-Short Term Memory (LSTM) architectures play a crucial role. LSTM units utilize updates defined by horizontal concatenation of vectors for forget, input, and output gates, as well as cell state calculations. These units allow for maintaining states across timesteps, making them suitable for processing audio inputs of varying lengths. The goal of the work is to certify the robustness of an audio classification pipeline, including LSTM, against noise perturbations in the input. The goal is to certify the robustness of an audio classification pipeline, including LSTM, against noise perturbations in the input by leveraging abstract interpretation and introducing new abstract transformers for handling non-linear operations in audio processing. The text discusses using the DEEPPOLY abstraction to approximate non-linear functions in audio processing for robustness certification. Unlike in computer vision tasks, audio models first perform MFCC preprocessing to extract features before inputting to the neural network. The text discusses using the DEEPPOLY abstraction to approximate non-linear functions in audio processing for robustness certification. Audio models typically perform MFCC preprocessing to extract features before inputting to the neural network. Preprocessing operations are represented as green boxes in Fig. 2, including Fast Fourier Transform (FFT) and Filterbank transform (FB). The square operation is optimized using an abstract transformer to obtain linear bounds on the intermediate representation \u03b8 (t). The text discusses using a novel logarithm transformer to obtain bounds on the output of the logarithm in audio processing. The logarithm operation is followed by Discrete Cosine Transform (DCT) and ReLU in the neural network. The analysis produces positive values for x (t), which remains unchanged after ReLU. Using back-substitution, x is derived within a range of 0.17 to 12.83. In the next paragraph, we provide a technical overview of our LSTM transformer, formalized in Section 5 and visualized in Fig. 4. We calculate the result of the transformation on the first neuron of the LSTM hidden layer, with detailed mathematical basis provided in Appendix D. For a toy example, let the gates be updated as f 2/4, and assume the previous states are bounded by [0.90, 1.00]. Applying our transformers, we obtain bounds for the cell state c and further apply our abstract transformer to get 0.48c. The LSTM transformer is used to minimize the area between planes under given bounds. Robustness certification is done using DeepPoly by proving a specific inequality. Back-substitution technique is applied to establish robustness. The back-substitution technique is used to establish robustness in the process of replacing variables with constraints. Tighter bounds are obtained through detailed calculations, and the number of back-substitution steps is tuned for a tradeoff between speed and precision. Robustness cannot be proved by concretizing expressions to intervals, as shown in the example provided. In the verification process, the hidden state and cell state are passed to the next analysis timestep instead of computing the final output. The first part of the process involves handling audio processing using MFCC. The verification process involves handling audio processing using MFCC, which includes non-linear operations like square and logarithm. New abstract transformers are created to handle these operations, minimizing the area between lower and upper bounds for minimal loss of precision. This approach has been proven effective in previous studies. The logarithm operation is approximated using interval bounds for minimal loss of precision. Lower and upper bound functions are defined based on the concavity of the logarithm, ensuring accurate approximation. The square operation assigns y := x^2 where x, y \u2208 X. Interval bounds are computed for the output l y and u y, with the lower bound function y l set to 0. The upper bound function y u is set using the convexity of the square function. Most prior work on verification of neural networks focuses on feed-forward or convolutional architectures. To verify recurrent architectures, handling updates of the recurrent unit is necessary. The pre-activations of gates in LSTM can be captured exactly, but updating cell and hidden states require approximation due to non-linear operations. Three elementwise products are involved, two between sigmoid and tanh, and one between sigmoid and another function. Custom binary approximation transformers are designed to handle elementwise products in the update of the recurrent unit, specifically between sigmoid and tanh functions. Unlike DeepPoly transformers, these new transformers take two abstract elements as operands to construct linear bounds. The goal is to bound a function between two planes to minimize the volume between them. The computation is divided into 3 cases based on the signs of certain variables. An anchor point and reference point are defined, and bounds are chosen to minimize the volume. The Sigmoid Identity transformer is handled similarly. Our Sigmoid Tanh transformer is proven to be optimal for minimizing the volume between bounding planes under specific assumptions. The assumptions ensure that our transformer produces bounds better than interval analysis by computing planes with a smaller volume. The proof is detailed in Appendix B. The Sigmoid Tanh transformer is optimal for minimizing volume between bounding planes under specific assumptions, leading to better bounds than interval analysis. DAC is evaluated on various datasets and neural architectures, implemented in C for performance, and will release datasets, trained networks, and source code. Verification is done on an Intel Core i9-9900K CPU. Experimental setup includes evaluation on audio classification benchmarks FSDD and GSC, with GSC achieving 96.9% accuracy using attention RNN. Our verified model achieves 89% accuracy on GSC, while de Andrade et al. (2018) achieved 96.9% using attention RNN. Verification success rate is defined as the ratio of certified samples to correctly predicted ones. We conducted experiments by shuffling test data and inferring labels until 100 samples were correctly classified. The provability was determined by the number of provably correct samples out of the 100. A verification method based on interval analysis was used as a baseline. The effect of back-substitution depth on performance was studied in an experiment using DAC on an FSDD network. Increasing the back-substitution depth in the experiment on an FSDD network led to higher provability due to cancellation of common terms in expressions. However, this resulted in an exponential increase in runtime. Depth 3 was chosen for a balance between high verification rate and reasonable speed. Additionally, audio classifiers were trained to be provably robust against noise-based perturbations for the first time, achieving 80% provability for -80 dB. The network in Fig. 5b achieves 80% provability for -80 dB, outperforming the undefended network. DAC proves more robustness properties than intervals. The defended network has 95% accuracy compared to the baseline's 98%. Our work approximates \u03c3(x) \u00b7 tanh(y) using linear bounds, differing from POPQORN. POPQORN produces smaller volume approximations but at a higher runtime cost. Integration of POPQORN bounds into our verification framework was attempted but found challenging. The study attempted to integrate POPQORN bounds into their verification framework but found it impractical for audio tasks due to a significant increase in runtime. In contrast, their proposed verifier, DAC, only takes 1-2 minutes on average to verify examples with multiple frames. The key idea behind DAC is the creation of abstract transformers for non-linear operations in audio processing and recurrent networks, enabling efficient verification. DAC was found to be effective and achieved high verification rates on various datasets. DAC is highly effective with high verification rates on different datasets. It minimizes the expected difference between the true curve and a lower bound plane by choosing the plane with a larger volume underneath it. The proof of upper bounds follows similar steps, with adjustments for different cases. The Sigmoid Tanh transformer is proven to be optimal in minimizing the volume between the lower and upper planes under certain assumptions. The proof involves choosing the anchor point based on the convexity of the function and adjusting slopes accordingly. The DeepPoly abstraction maintains constraints for every element, including lower and upper linear constraints and interval constraints. New abstract transformers are introduced to handle non-linear operations. The Fast Fourier Transform (FFT) is the first operation in the audio processing stage, involving a two-step process. The pre-emphasized input signal undergoes an affine transform jointly with the FFT, resulting in a single affine transform on the input. The next step is the elementwise square operation on the transformed input. After the FFT computation, the elementwise square operation on the transformed input is performed using a new square abstract transformer. This transformer provides optimal linear lower and upper bounds for the square function in terms of area. The interval bounds are then calculated, leading to \u03b8 [4, 16]. The analysis then continues with the computation of filter banks of the input signal, involving an affine transform using \u03c8 2. After the FFT computation, the input undergoes elementwise square operation using a new square abstract transformer, providing optimal linear bounds. Interval bounds are calculated as \u03b8 [4, 16]. The input then goes through filter banks with an affine transform using \u03c8 2, followed by Discrete Cosine Transform, Lifting, and FC layer with ReLU activation, combined in an affine transform with interval bounds x [0.1708, 12.8321]. The input undergoes various transformations including an affine transform with interval bounds x [0.1708, 12.8321], followed by a ReLU activation. The LSTM cell receives input from the verifier and computes pre-activations for the forget gate f and updates the cell state using binary abstract transformers. The LSTM cell computes pre-activations for the forget gate f and updates the cell state using binary abstract transformers. Applying abstract transformers on the summands produces bounds for h(t) and c(t-1). The next hidden state is computed as h1. To certify the neural network classification, we need to prove l1 - l2 > 0 using back-substitution technique. The LSTM cell computes pre-activations for the forget gate f and updates the cell state using binary abstract transformers. Applying abstract transformers on the summands produces bounds for h(t) and c(t-1). The next hidden state is computed as h1. To certify the neural network classification, we need to prove l1 - l2 > 0 using back-substitution technique. Comparability of different bounding methods is discussed, showing that POPQORN is non-comparable with the method presented. In an experiment comparing bounds produced by POPQORN and DAC on synthetic test cases, both methods use input bounds for sigmoid and tanh functions. The volume between the curve \u03c3(x) \u00b7 tanh(y) and bounding planes was compared using Monte Carlo sampling. The experiment focused on a portion of data involving LSTM cells. In an experiment comparing bounds produced by POPQORN and DAC on synthetic test cases involving LSTM cells, the volume obtained by POPQORN was smaller than DAC. POPQORN took 14.37 seconds on average while DAC finished in milliseconds. The experiment did not reflect actual performance on audio benchmarks. Uniform sampling was done for arguments involving \u03c3(x) \u00b7 tanh(y) and \u03c3(x) \u00b7 y. The experiment compared bounds produced by POPQORN and DAC on synthetic test cases involving LSTM cells. POPQORN often produced less precise bounds than interval bounds due to limitations in the gradient descent approach. Gradient descent struggles when inputs are far from the origin or too close together, leading to imprecise bounds. In some cases, gradient descent may not find the minimum volume bounds. POPQORN failed to find lower planar bounds with minimum volume, but the error is bounded within [-1, 1]. Using POPQORN bounds in DAC resulted in 0 verified samples, while DAC verified 4 samples due to many pathological cases. In experiments, errors from pathological cases can lead to suboptimal solutions with worse outcomes than interval bounds. Provability measurements were conducted following Singh et al. (2019b), with results showing consistent provabilities across multiple experiments. The training procedure for a provably defended network involves defining lower and upper bounds for logits under perturbation, ensuring worst-case logits satisfy the target label, and using a combination of standard and worst-case cross-entropy losses. Gradual adjustment of parameters during training is crucial for success. During training, gradual adjustment of parameters is crucial for success. Functions \u03ba(t) and (t) were set based on the number of training epochs E. Training speed was tracked by increasing t only if 85% accuracy and 80% provability were achieved. Models were built with E = 60, and defended GSC had 82% accuracy. Experiments were conducted with the same architecture but different model parameters for FSDD and GSC, with both defended and undefended networks sharing the same parameters for each dataset."
}