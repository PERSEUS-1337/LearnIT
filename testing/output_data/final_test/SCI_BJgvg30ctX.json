{
    "title": "BJgvg30ctX",
    "content": "We present an information-based optimization problem for supervised classification using invertible neural networks. By controlling information terms in the latent features and parameter matrix, we achieve improved interpretability and classification performance. Our framework is validated through experiments comparing with state-of-the-art models, showcasing the effectiveness of information theoretic methods in machine learning. The Information Bottleneck problem is formulated as finding a minimal sufficient representation of signal X for label Y. The mutual information between signal X and feature T in intermediate layers is argued to be infinite, as the transformation from X to T is deterministic. Layers equipped with ReLU do not compress information too much, as shown experimentally. The Information Bottleneck problem aims to find a minimal representation of signal X for label Y. ReLU-equipped layers do not compress information significantly. A new objective is proposed to maximize relevant information for classification while preventing overfitting. In optimization problem (3), the goal is to maximize relevant information I(Y ; Y ) while constraining irrelevant information I(X; Y ) \u2212 I(Y ; Y ). The proposed constraint addresses overfitting by preferring models that do not overfit to spurious factors of variation in X. Modern neural networks tend to be overly confident in their predictions, which can lead to incorrect decisions. The text proposes compressing irrelevant information to reduce overfitting in high capacity neural networks. By minimizing I(X; Y) and maximizing I(Y; Y), the confidence in all predictions decreases while increasing confidence in correct predictions. This optimization problem involves transforming high-dimensional signals into linearly separable data in deep neural networks. The text discusses the use of an invertible feature map in deep neural networks to make data almost linearly separable. It also explains how the classification stage works with the weight matrix and Softmax function. The objective function and optimization problem are derived, showing improved classification performance and more interpretable features. The optimal solution is challenging to achieve in practice. The text discusses the use of an invertible feature map in deep neural networks to improve classification performance. It introduces a novel information optimization problem for supervised classification and emphasizes the importance of controlling the latent feature directly. The invertibility property is empirically demonstrated for complex non-linear deep neural networks. The text introduces a novel information optimization problem for supervised classification, proposing an objective function that enhances deep learning performance and interpretability. It justifies the use of regularization from an information perspective, focusing on the mutual information between random variables in a classification problem. The text introduces a novel information optimization problem for supervised classification, proposing an objective function that enhances deep learning performance and interpretability. It justifies the use of regularization from an information perspective, focusing on the mutual information between random variables in a classification problem. The entropy of Y is defined as H(Y) = - p(y) log p(y), with assumptions on marginal densities and unique true labels for every sample of X. Mutual information is bounded, and gradient updates are ineffective when logits are initially small for true labels. Alternative terms are introduced to address this issue, with Propositions 2.1 and 2.2 showing the maximization of I(Y;Y) and the minimization of classical cross entropy objective. The proposed objective function is validated in experimental results. The experimental results in Section 4.1 confirm that the proposed objective function effectively compresses irrelevant information. The binary classification problem is considered, focusing on compressing the norm of the classifier w and feature F(X) to reduce mutual information I(F(X); Y). Proposition 2.1 demonstrates that I(X; Y) = I(F(X); Y) can be well estimated empirically, sharing a unique minimum with DISPLAYFORM0. The proof is provided in Appendix A. The text discusses the relationship between maximizing mutual information and minimizing cross entropy in binary supervised classification. It introduces an objective function for the classification problem and mentions Proposition 2.2, which relates to the estimation of mutual information. The proof is provided in Appendix B. The objective function for binary supervised classification aims to maximize mutual information I(Y;Y) while constraining I(X;Y). The hyper-parameter \u03b1 is chosen to be a small number to prevent overfitting. Neural networks may minimize I(F(X);Y) at the expense of I(Y;Y) if I(X;Y) is compressed harshly. The regularizer should favor models that do not overfit, with neural networks assigning large logits to true labels for each signal. In the multi-class case, the constraint for I(F(X);Y) can be simplified to constraining the weight matrix w. The proposed objective function aims to compress irrelevant information I(X;Y) - I(Y;Y) by constraining the weight matrix w in binary supervised classification. This approach encourages a smaller amount of compression throughout the training process, as demonstrated in experiments. Recent experimental work has shown that neural networks with invertible structures have better performance. Various studies have explored invertibility in deep architectures, such as reconstructing images from latent features in AlexNet and using invertible activation schemes like CReLU. Theoretical analyses have also been conducted on the invertibility of CNNs, with some proposing invertible structures comparable to ResNet. Invertibility is considered an intriguing design principle that can benefit the performance of neural networks. In deep learning, Information Bottleneck (IB) was introduced in BID11 and further explored in Shwartz-Ziv & Tishby (2017), showing how DNN structure forms a markov chain and compresses information layer by layer. BID0 proposed the Information Maximization (RIM) approach for classification, while BID6 added information ingredients to GANs to encourage disentangled representations. The framework decomposes neural networks into nonlinear transformations and linear probabilistic models, with origins in BID5's blind separation problem. BID2 and Kolchinsky et al. (2017) also studied IB in a stochastic setting, with explicit regularization on weights and predictions related to margin-based methods. In our experiments, we introduce explicit regularization on weights and feature maps in deep learning models like ResNet and InvNet. We demonstrate the invertibility of ResNet under certain assumptions and denote models trained under our objective as \"RegResNet/RegInvNet\". Comparing our proposed regularization with naive regularization on weights, we observe a drop in performance of ResNet-32 under naive regularization as the regularization parameter increases. RegResNet outperforms ResNet by introducing a constraint on irrelevant information, improving classification performance. Over-fitting is addressed, with ResNet-Wide showing larger improvements due to higher capacity. An invertible structured neural network on MNIST dataset is introduced, analyzing the feature F (X) learned in the last layer qualitatively. The feature map F is built to be LeNet-300-100 and the decoder D has the opposite structure. During training, the autoencoder F + D and the InvNet F + w are updated alternatively with regularization applied to w. Results are reported with \u03b1 1 = \u03b1 2 = 0.002. Testing samples of digit 9 are fed into the neural network to obtain features F (X) of dimension 100. The entry-wise products w 10 T i F (X) i become sparse under regularization, indicating that only a few entries contain relevant information for classification logits. The regularization applied to the autoencoder results in sparse entry-wise products, indicating that only a few entries contain relevant information for classification logits. The features of digit 9 are encoded into 10 entries, with high values in these entries expected to be features of digit 9.ROC metrics are used to validate this conjecture. The regularization applied to the autoencoder results in sparse entry-wise products, indicating that only a few key entries contain relevant information for classification. The features learned in the model are highly indicative and interpretable, simplifying deep learning to regularized linear regression. The feature vector size is 64, and the classifier matrix size is 64x10, with the product representing class probabilities. The regularization applied to the model results in sparse entry-wise products, indicating that only key entries contain relevant information for classification. The 2-norm of w is suppressed, while the 2-norms of feature F(X) remain similar. Rows of w are trained to be zero, implying irrelevant information for classification. Compression of the RegResNet-32 and the original ResNet-32 on CIFAR-10 is shown in Figure 4. The regularization applied to the model results in sparse entry-wise products, indicating that only key entries contain relevant information for classification. The norm of the feature learned remains similar, and the norm of classifier w is smaller, making it less sensitive to \"support\" and \"outlier\" features. Invertibility allows us to treat F(X) as transformed data that preserves all the information from X, working on the information regularization problem under a linear scheme. ResNet is proven to be fairly invertible, while PlainNet lacks theoretical guarantee for invertibility. PlainNet lacks theoretical guarantee for invertibility, making it more sensitive to regularization. The classifier w in the last layer plays a crucial role due to the feature map F being invertible. This allows for attacking the information optimization problem in supervised deep learning using mutual information quantities. Our theory justifies direct regularization terms on w, F(X) for neural networks with invertibility property, improving performance and encouraging interpretability of learned features. Proposition 2.1 connects I(X, Y) with |wTF(X)| for binary case, showing decreasing model confidence reduces mutual information. I(X; Y) is well estimated by its empirical version with high probability, sharing the same unique minimum with DISPLAYFORM0. Apply assumption (II), the marginal distribution of Y is uniformly distributed. The marginal distribution of Y is uniformly distributed when assumption (II) is applied. Hoeffding's inequality for bounded random variables is used to show that with probability at least 1 \u2212 \u03b4, the Monte Carlo estimation of I(X; Y) is bounded by [0, log(2)]. The conclusion follows from the fact that n k=1 y\u2208C p( y|x k ) log(2p( y|x k ))/n has a unique global minimum at wTF(x k) = 0 for each x k. The training samples are fed into a deep probabilistic model to predict outcomes. The mutual information between predictions and true values can be increased by boosting the model's confidence in correct predictions. The text discusses how increasing the confidence in correct predictions can boost the mutual information between predictions and true values in a deep probabilistic model. Propositions and lemmas are used to show the relationship between variables and the estimation error in the model. The text discusses using propositions and lemmas to estimate empirical mutual information in a deep probabilistic model. It shows how increasing confidence in correct predictions can boost mutual information between predictions and true values. The text discusses using propositions and lemmas to estimate empirical mutual information in a deep probabilistic model. It shows how increasing confidence in correct predictions can boost mutual information between predictions and true values. The Monte Carlo estimation provides unbiased empirical joint probability. By leveraging Hoeffding's inequality, upper and lower bounds for the random variable are estimated using Taylor's theorem, leading to a refined formula for estimating the bounds of the sigmoid function. The text discusses using propositions and lemmas to estimate empirical mutual information in a deep probabilistic model. It shows how increasing confidence in correct predictions can boost mutual information between predictions and true values. The empirical mutual information I(\u03c0) shares the same unique (global) maximum with a specific formula. By differentiating and calculating critical points, the global maximums are found on the boundaries of the domain. The text discusses how an invertible feature map F can improve the performance of a classifier w in a deep probabilistic model. Proposition C.1 shows that the classification error is lower bounded by a constant, which is achieved when F is invertible. Invertibility preserves information as it flows through the neural network, allowing the classifier to perform better. Lemma C.1 supports Proposition C.1 by stating that the information Z = F(X) maximizes true label Y when F is invertible. This preservation of key information aids in classification accuracy. The mutual information between Y and Z given X is 0 in a Markov Chain setting. A lower bound for classification error is related to mutual information I(Y ; F(X)), with an invertible feature map F yielding better classifier performance. Lemma C.1 and the Chain Rule support these findings. ResNet is designed to allow the model to \"learn\" the identity map easily, with building blocks related by a specific equation. If the operator norm is less than 1, then the building blocks are guaranteed to have an inverse, enabling information preservation among layers. Experimental verification shows that this condition holds during training. Operations like ReLU, pooling, and drop-out are commonly used in ResNet. ResNet is designed to ensure invertibility of building blocks during training, even with non-invertible components like pooling. Experimental verification confirms this property, with the operator norm less than 1 enabling information preservation. The regularization does not significantly improve performance in very deep ResNet models, suggesting potential information loss with depth. The operator norm of L in each building block of ResNet-32 is measured over 80k training steps, showing that norms are bounded by 1, confirming ResNet's invertibility. Models are implemented using Tensorflow, with learning rate schemes from the original code. Regularization is applied every 30 iterations, revealing specific high-value entries for each digit. The regularization is applied every 30 iterations, showing high-value entries for each digit. Results are reproduced on i-RevNet and Reg-i-RevNet for CIFAR10, with similar statistics and ROC curves. The sparsity of weights depends on hyperparameters, with about 60% of entries being zero in RegResNet for CIFAR10. The objective is to note that functions in (60) are composed of. The objective is to minimize the effect of punishing large logits by using a surrogate function to make the regularization effect clearer. The gradient decays exponentially for large logits, leading to unclear effects on the objective. The regularizer achieves the same goal for multi-label softmax functions. Our regularizer achieves the same goal as the mutual information objective but provides a better gradient for training."
}