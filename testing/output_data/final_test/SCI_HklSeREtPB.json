{
    "title": "HklSeREtPB",
    "content": "Recent work suggests goal-driven training of neural networks can model neural activity in the brain, with similarities in response properties to actual neurons. Researchers investigated if unconstrained neural network architectures could recover both neural representations and anatomical properties of neural circuits. Using the head direction circuit of rodents and fruit flies as a model, recurrent neural networks were trained to estimate head direction. The artificial neural networks naturally exhibited the distinct classes of neurons observed in the head direction system, demonstrating the potential for neural networks to capture both connectivity and functional organization. Recent studies have shown that artificial neural networks can mimic the structure and function of biological circuits, suggesting they can be used to study the brain at the level of neural activity and anatomical organization. Specifically, convolutional neural networks trained for visual object classification have matched neural responses in visual processing stages. Recurrent neural networks trained on goal-driven tasks can also replicate neural activity, indicating the potential for neural networks to capture both connectivity and functional organization in biological circuits. Artificial neural networks, including convolutional and recurrent neural networks, have shown promise in mimicking the structure and function of biological circuits. While these networks have replicated neural responses in visual and cognitive tasks, it remains unclear if they have converged upon similar architectures as the brain. To address this question, understanding the functional, structural, and mechanistic properties of artificial neural networks and relevant neural circuits is crucial. The head direction system, a well-studied system in the brain, is being used to tackle these challenges. Artificial neural networks have accumulated substantial data in rodents and fruit flies. RNNs trained to perform an AV integration task show similarities to biological networks. Goal-driven training of artificial neural networks provides a framework to study neural systems at the level of neural activity and anatomical organization. The RNN model consists of recurrently connected units that accurately track the current head direction by integrating angular velocity over time. The network is trained to estimate the agent's head direction with randomly initialized connections. The RNN model integrates angular velocity to track the head direction accurately. Units receive input through weight matrices and have biases and noise terms. Inputs encode initial head direction and angular velocity. The RNN model integrates angular velocity to track head direction accurately, with momentum for smooth movement trajectories. Angular velocity is updated using a zero mean Gaussian random variable with momentum. Parameters are set to match the angular velocity distribution of rats and flies. The trained RNN accurately tracks angular velocity, with parameters optimized to minimize error and metabolic cost. Results show the network can track angular velocity and model units are compared to experimental data from rodents and flies. The neural activity of units in the head direction system of rodents and flies was analyzed based on their tuning to head direction (HD) and angular velocity (AV). Two classes of neurons were identified: one with minimal AV tuning and another tuned to both HD and AV, further divided into sub-populations favoring either clockwise or counterclockwise rotation. The neurons formed a ring-like structure in 3D space, with distinct separation between the classes. Neurons in the anterodorsal thalamic nucleus (ADN) of the rat brain are selectively tuned to head direction (HD) but not angular velocity (AV), with a tuning profile similar to what the model predicts. This pattern may also be true for ellipsoid body (EB) ring neurons in the fruit fly HD system. Previous studies have shown differences in the temporal relationship of cell firing to the rat's head direction between cells recorded from the PoS and ADN. In the ADN and PoS, neurons encode rat's directional heading. Time shift analysis conducted on 17 L M N H D cells, excluding those with overlapping tuning curves. Optimal time shifts for peak firing rate, range width, and information illustrated in Figure 5A-C. The temporal relationship of cell firing to the rat's head direction differs across HD cells recorded from the PoS and ADN. HD cells in the ADN encode the rat's future directional heading by \u03f325 msec, while HD cells in the PoS encode the rat's present or recent past directional heading. Time shift analysis was conducted on 17 LMN HD cells, excluding those with overlapping tuning curves. Optimal time shifts for peak firing rate, range width, and information were illustrated in Figure 5A-C. The optimal time shifts of an LMN HD cell for peak firing rate, range width, and information were analyzed. Previous studies have shown differences in the temporal relationship of cell firing to the rat's head direction between ADN and PoS HD cells. Out of the 20 LMN HD cells recorded, a second HD cell was simultaneously recorded on the same electrode wire for three cells, compromising the accuracy of the time shift analysis. The accuracy of time shift analysis was compromised for some cells due to overlap, leading to their exclusion. Time shift analyses were conducted on 17 remaining LMN HD cells, showing head turn modulation in different brain areas. Previous studies have highlighted differences in cell firing temporal relationship between PoS and ADN HD cells. LMN HD cells in the PoS and ADN encode the rat's directional heading differently. Time shift analysis was conducted on 17 LMN HD cells, excluding those with overlapping tuning curves. The optimal time shifts for peak firing rate, range width, and information were determined for each cell. Neurons tuned to both head direction (HD) and angular velocity (AV) have been observed in rodents and fruit flies. In rodents, cells display HD and AV tuning, while in fruit flies, neurons on each side of the protocerebral bridge are tuned to clockwise (CW) and counterclockwise (CCW) rotation. These findings suggest that neurons in the model can be mapped to specific units in the EB. Neurons in the model can be mapped to specific units in the EB, with \"Ring\" units corresponding to neurons tuned to both head direction (HD) and angular velocity (AV), and \"CW/CCW Shifters\" corresponding to neurons on the left and right protocerebral bridge tuned to CW and CCW rotation. The tuning curves of Ring units and Shifters vary with AV, showing a bias towards CW angles at CW velocities and vice versa. This observation is consistent with findings in rodents and fruit flies. The majority of units in the trained RNN could be mapped onto the biological head direction system, showing graded response profiles and diverse angular velocity tuning curves. The neural response properties are the result of a network solving an angular integration task optimally, unifying experimental observations. The trained network exhibits structured connectivity similar to the fly central complex. Neurons are sorted by functional classes and preferred head direction, showing integration capabilities. Connectivity is represented by colored connections between units, reflecting excitatory and inhibitory connections. The network exhibits structured connectivity similar to the fly central complex, with neurons sorted by functional classes and preferred head direction. Connectivity is shown through colored connections, highlighting recurrent connections to ring units and specific connectivity patterns between different cell types and ring units based on head direction preferences. The trained RNN exhibits structured connectivity patterns similar to the fruit fly central complex, with neurons organized by functional classes and preferred head direction. The connectivity between Ring units and Shifters shows a pattern of local excitation and global inhibition, with positive weights connecting neurons with similar preferred head directions. The connectivity patterns in the trained RNN show positive and negative weights between neurons with anti-phase preferred head directions. Ring units maintain stable activity bumps in the absence of inputs, similar to previous theoretical models. CW shifters excite Ring units with clockwise preferred head directions and inhibit those counterclockwise to its own. The trained RNN exhibits asymmetric connections between Shifters and Ring units, resembling connectivity patterns in the fruit fly central complex. CW Shifters excite Ring units with preferred head directions clockwise to their own, while CCW shifters inhibit those counterclockwise. The model's connectivity profile is broad, with a single CW Shifter exciting multiple Ring units. In the model, there are specific recurrent connections between CW and CCW Shifters, as well as inhibitory connections from Shifters to Ring units that facilitate neural bump rotation during turning. These predictions can be tested using EM reconstructions, functional imaging, and optogenetics in the future. Neurons have been segregated into Ring and Shifter populations based on their HD and AV tuning, showing different connectivity patterns. The model includes recurrent connections between CW and CCW Shifters, with inhibitory connections from Shifters to Ring units for neural bump rotation during turning. Lesioning specific connections resulted in the disappearance of activity bumps in Ring units, CW Shifters, and CCW Shifters, leading to inaccurate heading direction estimation. Lesioning specific connections impaired neural bump rotation in Ring units and Shifters, affecting heading direction estimation. Lesioning CW Shifters to all units disrupted CW rotation and increased CCW rotation speed, while lesioning CCW Shifters had the opposite effect. This supports the hypothesis that CW/CCW Shifters control bump shifting in respective directions. The lesion experiments showed that inhibiting Shifter units in the fruit fly heading system impairs the integration of heading direction. The system can spontaneously generate an activity bump through recurrent connections mediated by Ring units. Lesioning connections from CW Shifters to all units resulted in a CCW rotation of heading direction. Lesion experiments on the fruit fly heading system revealed that inhibiting Shifter units impairs heading direction integration. Results showed that CW and CCW Shifters activate the ring, with mutually cancelling signals, maintaining heading stability. Lesioning connections during constant angular velocity rotation led to accurate integration in the network. Lesion experiments on the fruit fly heading system support the role of CW/CCW Shifters in shifting the activity bump in corresponding directions. Lesioning CW Shifters impairs CW rotation but increases CCW rotation speed, while lesioning CCW Shifters has the opposite effect. These findings suggest modular components maintain and update heading during angular motion. The system adapts to input statistics during angular motion. RNNs trained with different angular velocities show varying unit behaviors. More head direction tuning units emerge with small velocities, while fewer ring units appear with large inputs. Increasing angular velocity leads to more Shifter-like units with both head direction and angular velocity tuning. The overall angular velocity tuning is quantified by computing the slope of each neuron's tuning curve at its preferred head direction angle. Increasing AV inputs leads to more neurons developing strong AV tuning. Allocating more resources for a stable activity bump requires more ring units, while rapidly updating the activity bump for integrating head direction requires more shifter units. This prediction may help understand the diversity of HD systems in different animal species. Previous work in sensory systems has focused on obtaining an optimal representation. Using the head direction system, goal-driven optimization of recurrent neural networks can help understand the functional, structural, and mechanistic properties of neural circuits. Perturbation analysis reveals the dynamics of trained RNNs, while fixed point analysis suggests attractor dynamics. This approach offers insights into the relation between trained networks and brain circuit anatomy and function. In the study, evidence of attractor dynamics was found in the head direction system. Future research using Neuropixel probes and calcium imaging will provide a more detailed understanding of HD circuits. No additional structural constraints were imposed during training to observe emergent properties in the RNNs. Consideration of how additional constraints impact representation and computation in trained RNNs is an interesting avenue for further exploration. Future work should explore the possibility of having input or output units connect to only a subset of RNN units or freezing connections during training. Training was found to be necessary for joint HD*AV tuning to emerge, which is computationally more complex than a simple binary classification task. Stable HD tuning requires accurate integration of AV and storing values over time, which may be challenging for a random network to perform. This approach contrasts with previous models based on hand-crafted connectivity for the HD system. The modeling approach optimizes task performance through stochastic gradient descent, showing that different input statistics lead to varied heading representations in an RNN. This insight suggests that the optimal neural network architecture depends on task demands, challenging traditional hand-crafted solutions. The framework is relevant for understanding neural computation across various systems and can be a foundation for AI systems in general navigation tasks. In order to navigate in complex environments, agents need to construct a cognitive map and update their position. Heading integration and motion magnitude integration circuits are essential for dead reckoning. Training RNNs with multiple sensory inputs can help build robust navigational systems and enhance our understanding of navigation mechanisms in the brain. After training, units in the network are tuned to HD \u00d7 AV, except for 12 inactive units that do not affect the network."
}