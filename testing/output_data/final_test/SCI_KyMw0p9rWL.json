{
    "title": "KyMw0p9rWL",
    "content": "Recent visual analytics systems utilize multiple machine learning models instead of a single pre-defined model. However, the complexity of multi-model systems can pose usability concerns as users need to interact with parameters of multiple models. Gaggle is introduced as a solution, a multi-model visual analytic system that simplifies navigating the model space and automatically finds the best model to support various user tasks. Gaggle is an intuitive and easy-to-use visual analytic system that supports interactive model space navigation and automated model selection for classification and ranking tasks. It simplifies the process for users without requiring technical expertise, leveraging machine learning to provide effective systems for gaining insights into data. The vast number of different model types in the model space can be sampled using a combination of learning algorithms and hyperparameters. When the right model is chosen, existing VA techniques can support users effectively. Recent VA systems use multiple ML models to assist with various user tasks like Regression and Clustering. The VA system Clustervision and Snowcat allow users to inspect and select clustering and ML models based on quality and preference. Multimodel systems are more complex to use compared to single-model alternatives, requiring users to be well-versed in model metrics. The interactive exploration of parameter and hyperparameter combinations is referred to as model space navigation. Gaggle is a visual analytic tool that leverages multiple models to simplify data exploration. It automatically finds classification and ranking models using a bayesian optimization technique. Users can navigate the model space by interacting with the system, such as dragging data items into specific classes to record preferences. Gaggle utilizes machine learning to assist users in data exploration and structuring tasks, allowing them to categorize and rank data items within a class. This interactive tool is beneficial for tasks like grouping student applications or clustering potential clients, focusing on classification tasks without predicting labels for future data. This approach helps prevent model overfitting by adjusting models to specified criteria. Gaggle addresses the problem of datasets lacking ground truth by allowing users to define classes and add labels iteratively. A user study showed that the workflow in Gaggle is intuitive, and users can effectively perform classification and ranking tasks. The system incorporates user feedback into model space navigation, facilitated by Bayesian optimization hyperparameter tuning. A model space navigation technique called Gaggle uses Bayesian optimization for hyperparameter tuning and automated model selection. It supports interactive classification and ranking tasks through user interactions. Various types of models can be built using this approach, including classification, interactive labeling, metric learning, decision trees, and dimensional reduction. Our technique searches through multiple types of models with various hyperparameter settings for classification and ranking tasks. User interaction is interpreted as feedback on the full hyperparameter space using Bayesian optimization, directly changing model behavior in parallel. Stumpf et al. found that user feedback includes suggestions for re-weighting of features, proposing new features, relational features, and changes to the learning algorithm. User feedback can improve ML systems by extending learning algorithms to assimilate feedback. Interactive model steering through demonstration-based interaction allows users to visually demonstrate partial results for models to learn parameters. For example, repositioning points in a scatterplot can show an appropriate distance function without directly manipulating model hyperparameters. Kim et al. introduced InterAxis, where users can drag data objects on a scatterplot to interpret, define, and change axes. The user can define constraints in a scatterplot to interpret and change axes for a linear dimension reduction technique. Visual interaction with data points helps users construct a projection and clustering algorithm based on their preferences. Gaggle's interaction design allows users to manipulate visual results to navigate the model space incrementally. Visual analytics systems now allow users to interact with multiple models simultaneously, enabling them to adjust model hyperparameters to better suit their goals. Various studies have explored interactive multi-model inspection and steering, tuning hyperparameters of machine learning models, and enabling user interactions with ensemble models through coordinated contextual views. Various techniques have been developed to support model validation and comparison in regression and clustering models. M\u00fchlbacher et al. introduced a method to rank variables for regression analysis, while HyperMoVal visualizes model outputs for validation. Kwon et al. demonstrated a technique for selecting cluster models, and Clusterophile 2 allows exploration of clustering parameters. StarSpire by Bradel et al. showcases semantic interactions for steering text analysis. Our work focuses on tabular data and supports interactive navigation of model space for classification and ranking models by tuning hyperparameters. It is designed for non-experts in machine learning and emphasizes human-centered machine learning processes. Holzinger et al. discussed the benefits of automatic machine learning methods in various domains, noting the importance of considering human factors in algorithm modification. The curr_chunk discusses the limitations of static training sets in machine learning and the potential solution of interactive machine learning with user input. It also mentions the concept of computational models fostering human and machine collaboration. Additionally, it highlights works on model space navigation and visualization techniques for understanding model outputs better. The curr_chunk discusses exploring parameter space in model building, including visualization techniques and tools like AutoWeka and SigOpt to aid non-experts in selecting optimal settings. Our work explores incorporating domain expertise into automated model selection by allowing users to assign data points to classes and demonstrate classification and ranking. Gaggle constructs a model space and samples multiple variants of models, searching various sub-regions for optimal solutions. Gaggle searches model space to find optimal classification and ranking models based on performance metrics. Users interact with the system to provide feedback and iterate until satisfied with the model. A usage scenario is presented to demonstrate the tool's workflow in solving a problem space related to assessing baseball players' potential. Jonathan, with experience in player assessment, categorizes baseball players into \"Best Players\", \"In-form Players\", and \"Struggling Players\" using user-provided labeling in Gaggle. He imports a dataset of 400 players with 17 attributes, assigns labels based on merit, and receives recommendations for similar players for labeling. Jonathan uses Gaggle to label baseball players into different classes based on their performance. He corrects misclassifications, updates the model with his feedback, and reviews the results. Jonathan then identifies players with high batting average and home runs, assigning them to appropriate labels. Jonathan uses Gaggle to classify baseball players based on performance, adjusting the model with his feedback. He ranks players within each class by dragging them up or down, checking the updated optimal ranking model. Jonathan moves struggling players like Norm Cash and Walker Cooper to the top of their class, while adjusting the placement of Hal Chase in the best players category. Gaggle helps Jonathan classify and rank baseball players based on his domain knowledge. The design goal is to allow interactive navigation of classification and ranking models, with direct manipulation of model outputs for user feedback. The Data Viewer in Gaggle allows users to interact with data items, assign labels, and specify ranking order within bins. User feedback serves as training data for model creation, enabling generalization across model types. The Data Viewer in Gaggle enables users to interact with data items by assigning labels and specifying ranking order within bins. Users can hover over data items to view attribute details, represented as glyphs on a horizontal line. The color of the glyph indicates the attribute quality in comparison to other instances. The Gaggle tool recommends similar data instances based on cosine distance metric to expedite class assignment during data exploration. Users can accept or ignore these recommendations. The Interacted Row Visualization shows interacted data items with color encoding for correct and incorrect label matches. The tool also allows users to give feedback on predictions. Gaggle allows users to provide feedback to the system, reassign classes, reorder data items within classes, and pin data items to specific classes for future iterations. These interactions help steer the hyperparameters of the classifier and improve the ranking model. The text discusses the process of constraining the classifier in Gaggle to improve the ranking model. It explains the concept of a model mapping from input space to prediction space in semi-supervised learning models. The learning algorithm maps a training set to a model by searching through a parameter space, with model parameters and hyperparameters playing distinct roles. The process of navigating the model space in machine learning involves varying learning algorithms and hyperparameters to create a diverse set of new models. ML practitioners use data science principles to search for optimal models within this high-dimensional model space by testing various candidate models based on defined metrics like accuracy. Gaggle constructs a model space by sampling multiple random forest models to find the best model for the task. Gaggle constructs a model space by sampling random forest models with predefined hyperparameters within a set domain range. The optimization method can work with other learning algorithms and hyperparameter combinations. Gaggle uses Bayesian optimization for interactive user feedback and navigation of the model space. Gaggle utilizes Bayesian optimization to sample models with predefined hyperparameters within a domain range. The optimization module computes a score for each model based on custom-defined performance metrics. It uses a Gaussian process to find an expected improvement point in the search space of hyperparameter values. Gaggle utilizes Bayesian optimization to sample models with predefined hyperparameters, ensuring consistently better models are found in regions of the model space. The module finds the best model score based on user-defined metrics for both classification and ranking models. Gaggle's unconventional training pipeline starts with an unlabeled dataset, adding labels as the user interacts with the data items. Gaggle's training pipeline starts with an unlabeled dataset, adding labels as users interact with data items. If the number of labeled instances is below a threshold, similar data instances are added to the training set. The size of the training set grows as users interact with more data, improving classifier robustness. Gaggle calculates class probabilities for each classifier to enhance ranking computation. The class probability in Gaggle is used to augment ranking computation by representing the model's confidence in a data item's class membership. Gaggle's interactive labeling approach is similar to active learning, allowing users to freely label data items to construct a classifier. User feedback is incorporated to classify and rank data items, inspired by techniques for interactive navigation of the model space. Gaggle uses a random forest model to classify between pairs of data instances, chosen for its better performance. Gaggle uses random forest models for ranking data instances based on user-defined metrics. The ranking technique is augmented with feature selection based on interacted rows, selecting attributes that best represent why one instance should be ranked higher than another. The model space navigation approach uses Bayesian optimization to find the best performing model. Gaggle uses random forest models for ranking data instances based on user-defined metrics. The technique selects attributes that best represent why one instance should be ranked higher than another. Features satisfying interactions are retained, and a final ranking score is computed by combining ranking and class probabilities. A final ranking score is computed by combining the ranking score of each data item and its class probability, with weights based on model accuracy. Gaggle selects an optimal model based on classification metrics like wrongly labeled instances and cross-validation scores. Other metrics such as precision and F1-score can also be specified. The final metric is computed as a sum of components with weights based on classification metric components. Different weight values were tested to improve model accuracy. Gaggle evaluates models for ranking tasks using three ranking metrics based on the absolute distance from a data instance's position before and after applying a model. The first ranking metric computes absolute distances only between interacted rows. The ranking metrics in Gaggle evaluate model performance by computing absolute distances between interacted rows, immediate neighbors, and all data instances before and after applying a model. The final ranking metric is a weighted sum of these metrics to determine model fit. In Gaggle, weights for ranking metrics W u , W v , W w were chosen based on model accuracy. Z u captures user-defined ranking interactions, while Z v and Z w preserve user progress. Metrics like NDCG and BPR were not used as they focus on document relevance and implicit behavior, respectively, which are less relevant for capturing user preferences in this context. Our work allows users to subjectively rank data, considering negative examples. A user study was conducted to evaluate Gaggle's model space navigation for classification and ranking tasks. Feedback on system features, design, and workflow was collected through a qualitative lab study with 22 non-expert participants. Participants in the study were non-experts in machine learning and had knowledge of movies and cities, the datasets used. They were compensated with a $10 gift card and used a laptop with a 17-inch display and a mouse in a lab environment. The experiment lasted 60-70 minutes, where participants completed 4 tasks on 2 datasets: multi-class classification and ranking of items, as well as binary classification and ranking. Tasks and datasets were randomized to avoid learning effects. Each participant performed 8 tasks in total. Participants performed 4 tasks in 15 minutes, including multi-class classification and ranking, and binary classification and ranking on the Cars dataset. They built classifiers for movies and cities datasets with specific classes like sci-fi, horror/thriller, fun-cities, and work-cities. The binary classification task had labels for popular and unpopular movies. Participants provided subjective feedback and observational data during the experiment sessions with Gaggle. They were encouraged to think aloud while interacting with the system. Qualitative feedback was collected through semi-structured interviews and likert scale questionnaires after each trial. Participants provided subjective feedback and observational data during the experiment sessions with Gaggle. User preference ratings were collected for tasks using a Likert scale (1-5). Gaggle was rated 3.97 for multi-class classification and 4.17 for binary classification. Users preferred Gaggle for binary classification due to higher accuracy. Log data was collected to track model selection and hyperparameter changes during interactive navigation. The hyperparameters for max-depth and Criteria varied for different datasets and tasks. The average number of hyperparameter changes was higher for multi-class classification compared to binary classification. Participants liked the drag and drop interaction feature in Gaggle. Participants appreciated the drag and drop interaction in Gaggle for demonstrating examples to the system. They found the system easy to use and liked the feature of recommending data while dragging items into various labels. Users found the recommendation feature accurate and helpful for labeling data items. The interacted row visualization helped users understand constraints on classification and ranking models. Some participants adjusted their labeling strategy while using Gaggle. Few participants adjusted their labeling strategy while using Gaggle, initially concerned about confusing the system. However, they were surprised to find that Gaggle adapted well and still met most user-defined class definitions. One participant noted that despite changing their classification approach, Gaggle accurately labeled non-interacted movies. The challenge of searching models in a large model space was addressed by using Bayesian optimization. In this work, Bayesian optimization is used for ranking models in a given model space. Scalability issues may arise in larger search spaces, and too many user constraints can lead to poor results. The current design supports small to moderate dataset sizes, with limitations on dataset size in user studies. Future plans involve addressing handling large datasets using Auto-ML cloud services and progressive visual analytics. Users may encounter abrupt model and result changes while navigating the model space. Users may encounter abrupt changes in model parameters while exploring different models interactively. These changes can significantly impact the results of the models, especially if users are unaware of the parameterizations. Providing feedback on what changed in the output can help ease these transitions. Additionally, updating the class definition or showing better examples can affect the decision boundary of the classifier, requiring correct mapping. In interactive model exploration, users may encounter abrupt changes in model parameters. Gaggle helps find optimal models with new hyperparameter settings. The technique uses the full dataset, with interacted data items as the training set and the rest as the test set. As users construct classifiers iteratively, the training set grows while the test set reduces. This approach accounts for user preferences through iterative interactions, following the conventional ML principle of training the classifier independently of the test data. In interactive model exploration, Gaggle helps users find optimal models with new hyperparameter settings by training classifiers independently of the test data. The challenge of model overfitting is addressed by allowing users to navigate the model space interactively to find a model suited to their goals. Our technique, Gaggle, facilitates classification and ranking of data items by helping users find a model suited to their goals through interactive navigation of the high-dimensional model space. A qualitative user study showed that Gaggle is easy to use, intuitive, and effective in assisting users to find an optimal classification and ranking model."
}