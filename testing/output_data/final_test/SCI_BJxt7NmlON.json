{
    "title": "BJxt7NmlON",
    "content": "Learning disentangled representation from unlabelled data is a challenging task. The Information Maximising Autoencoder (InfoAE) proposed in this paper aims to achieve this by maximizing mutual information between the representation and given information in an unsupervised manner. The model was tested on the MNIST dataset, achieving a test accuracy of approximately 98.9% with complete unsupervised training. Self-supervised learning and Generative Adversarial Neural Networks (GANs) are also discussed as potential methods for learning disentangled representation from unlabelled data. The InfoGAN model, a modification of GAN, can learn interpretable and disentangled representation from unlabelled data. However, the representation learned is dependent on the generation of the model, posing a challenge if the generator fails to generate data manifold. Adversarial autoencoder (AAE) is another successful model for learning disentangled representation directly from the data. The InfoAE model aims to learn accurate disentangled representation by utilizing both training data and generated samples. It consists of an encoder, decoder, and generator network to maximize mutual information between random conditions and representation space. The encoder learns the mapping of training samples to the latent variable space generated by the generator. The InfoAE model includes an encoder, decoder, and generator network to learn disentangled representations. The encoder maps training samples to the latent variable space, while the generator generates latent variables from random conditions. The decoder validates the generated samples. The InfoAE model consists of encoder, decoder, and generator networks to learn disentangled representations. The discriminator network forces the decoder to create samples from the data distribution, while the generator can easily ignore the given condition. To maximize Mutual Information (MI) between conditions and generated samples, a classifier network is used. The encoder is trained to encode samples into the latent variable space and ensure that the distribution of latent variables approximates the true distribution. The model is trained using multiple losses. The InfoAE model is trained with multiple losses including Reconstruction loss, Discriminator loss, Encoder loss, Self Critic loss, and Two classification losses. The total loss is minimized by updating the weights of the E, D, C, and G networks, while the weights of the S and D i networks are updated to maximize their respective losses. The training objective is expressed in equations 1 and 2. Our model components include Convolutional Neural Network (CNN) for E, D i, and S, with Batch Normalization used. No maxpool layer is used, down sampling is done by increasing the stride. Classifier C and generator G use a simple two-layer feedforward network. Decoder D uses Transpose CNN. Training is sensitive to \u03b1, \u03b2, and \u03b3, with best results at \u03b1 = 1, \u03b2 = 1, and \u03b3 = 0.4. Random one hot encoding of size 10 is used for c, and z is randomly sampled from a uniform distribution. Adam Optimizer is used to update network weights with a learning rate of 0.0002. The model components include CNN for E, D i, and S, with Batch Normalization. Classifier C and generator G use a two-layer feedforward network. Decoder D uses Transpose CNN. Training is sensitive to \u03b1, \u03b2, and \u03b3. Random one hot encoding of size 10 is used for c, and z is randomly sampled. Adam Optimizer with a learning rate of 0.0002 is used. The model was evaluated on MNIST dataset with outstanding results. InfoAE achieved a classification accuracy of 98.9 (\u00b1.05), outperforming other methods. The latent variable produced by the encoder on test data is visualized using t-SNE in FIG1. The encoder in the model was able to disentangle the digits category in the representation space, leading to superior performance. The generator generated latent space according to the condition, and the decoder disentangled the digit category. The paper introduces InfoAE, which learns disentangled representation in an unsupervised manner. InfoAE was tested on the MNIST dataset, achieving a competitive test accuracy of 98.9 (\u00b1.1) compared to InfoGAN. The encoder successfully disentangles digit categories and styles in the representation space, leading to superior performance. InfoAE can learn from unlabeled data and be used for data augmentation. Ongoing research aims to mathematically explain the results and analyze performance on large-scale audio and image datasets."
}