{
    "title": "Syx2tJnNtr",
    "content": "Universal probabilistic programming systems (PPSs) offer a powerful framework for complex probabilistic models, but inference can be challenging due to varying model support. A new inference framework, Divide, Conquer, and Combine (DCC), divides the program into sub-programs with fixed support for more efficient local inference before recombining outputs. DCC is implemented as a general-purpose PPS inference engine, showing promising results empirically. In this paper, the focus is on addressing the challenges posed by variables with stochastic existence in universal probabilistic programming systems (PPSs) like Church, Venture, Anglican, and Pyro. These systems aim to support a wide range of models but complicate automation of inference due to mixed variable types and varying dimensionalities. The new inference engine presented, Divide, Conquer, and Combine (DCC), aims to improve performance by dividing the program into sub-programs with fixed support for more efficient local inference before recombining outputs. In addressing challenges with stochastic variables in probabilistic programming systems, various inference algorithms like importance sampling, Sequential Monte Carlo, variational approaches, and MCMC are considered. MCMC approaches are difficult due to the need for efficient proposals that can switch between variable configurations. This poses challenges in achieving automation and efficiency in inference processes. The new framework introduced, Divide, Conquer, and Combine (DCC), aims to address the challenges of inference in models with no effective PPS-suitable methods. DCC divides the program into separate sub-programs, conquers them efficiently using fixed support, and combines the results to approximate the posterior. This approach simplifies the estimation of marginal likelihood for different configurations. The new framework, Divide, Conquer, and Combine (DCC), simplifies estimating the marginal likelihood for different models by dividing the program into sub-problems and introducing meta-strategies for resource allocation. This approach allows for explicit control of the exploration-exploitation trade-off and has shown substantial performance improvements in automated inference engines like PPS Anglican. The density of an Anglican program is determined by executing it in a forward manner, tracking density components from sample and observe terms. Random variables {x i } nx i=1 are generated from sample statements, with each statement having a lexical program address a i. The program's stochastic support means the path of the program varies between realizations, leading to different configurations of sampled variables. Unlike traditional inference methods targeting full program density, DCC simplifies estimating marginal likelihood by dividing the program into sub-problems and introducing resource allocation strategies. DCC breaks the full program density problem into individual sub-problems with fixed support. It divides the program into straight-line sub-programs based on execution paths, runs inference locally on each sub-program, and combines the results. Each straight-line program has a fixed support and draws variables based on a particular path encountered during execution. The DCC approach breaks down the program density problem into sub-problems by dividing the program into straight-line sub-programs based on execution paths. Each sub-program has a fixed support and defines a sub-model on a corresponding sub-space. The density of each sub-program is defined with respect to specific variables and addresses, with inference run locally on each sub-program. The DCC approach divides the program into straight-line sub-programs with fixed supports and specific variables. Each sub-program defines a sub-model on a corresponding sub-space, with local inference carried out for each. The density of each sub-program is defined with respect to specific variables and addresses. The conquer step involves carrying out local inference for each sub-program to estimate individual SLP densities and marginal likelihoods. Various conventional inference methods can be used, such as Metropolis-with-Gibbs and PI-MAIS algorithm. It is not necessary to obtain equally high fidelity estimates for each sub-program. The conquer step involves local inference for each sub-program to estimate individual SLP densities and marginal likelihoods. Resource allocation is beneficial in generating estimates in an online manner. The last stage of DCC combines local estimates from individual SLPs to an overall estimate of the conditional distribution for the original program. The conquer step involves estimating individual SLP densities and marginal likelihoods for each sub-program. Specific strategies for implementation are detailed in Appendix C, including a GMM model with unknown mixture numbers and means. The convergence of the overall log marginal likelihood Z is examined, with DCC outperforming baselines by orders of magnitude. The posterior distribution of K is investigated, showing accurate estimates with DCC. The second model involves function induction using a Probabilistic Context Free Grammar. The Probabilistic Context Free Grammar (PCFG) model is used to infer the posterior distribution of function structure and parameters from training data. DCC outperforms baselines in predictive accuracy and stability, as shown in Table 1. DCC samples capture periodicity in training data well and interpolate effectively. RMH also finds good functions but may get stuck in a particular mode. In this paper, the Divide, Conquer and Combine (DCC) inference strategy is proposed for probabilistic programs with stochastic support. By breaking down the inference problem into separate subprograms, DCC shows significant performance improvements over existing approaches. An automated engine in the PPS Anglican implements DCC, demonstrating its effectiveness through example problems. Anglican's syntax is based on Clojure, with special forms for defining the program's distribution. The Anglican program defines distribution using sample and observe statements. Samples draw random variables, while observes condition on data. The program's density is derived by executing it forward, tracking density components from samples and observes. Random variables and observed values are represented, each with lexical addresses and corresponding densities. The program density in an Anglican program is defined by sample and observe statements, with lexical addresses and corresponding densities. Everything is a random variable but deterministically calculable given certain variables. The execution trace is denoted by the sequence of addresses of sample statements and variables. A program with stochastic support has varying paths between different realizations. The program is divided into constituent SLPs, each defining a sub-model on a corresponding sub-space. The unnormalized density of SLPs is defined with respect to variables and addresses. The density of SLPs is calculated as a ratio with a normalization factor. The support of the problem is fixed, while some variables remain stochastic. Inference algorithms for models with stochastic support can be challenging. Basic schemes like importance sampling from the prior may work for low-dimensional models but struggle as the dimension increases. Particle-based methods like Sequential Monte Carlo offer improvements for models with sequential structure but face issues with high dimensions. Variational approaches are not well-suited for this setting and require significant approximations. In contrast to basic schemes like importance sampling, reversible jump Markov chain Monte Carlo methods offer a potential solution for tackling more difficult problems with stochastic support. However, designing efficient proposals for transitioning between configurations remains a fundamental challenge due to the loss of locality when switching configurations. Designing efficient proposals for transitioning between configurations in reversible jump Markov chain Monte Carlo methods is a fundamental challenge due to the loss of locality when switching configurations. RJMCMC estimates the relative mass of each configuration through the relative frequency of transitions, leading to a slow mixing rate for the overall sampler. This difficulty is further exacerbated in universal probabilistic programming systems (PPSs) where automated proposal construction is desired. Though RJMCMC has been applied in the PPS context, manual specification of proposals is often required, losing the automation that is a core motivation for PPSs. In reversible jump Markov chain Monte Carlo methods, designing efficient proposals for transitioning between configurations is a challenge due to the loss of locality. This difficulty is exacerbated in universal probabilistic programming systems (PPSs) where automated proposal construction is desired. One method that can be fully automated for PPSs is the Lightweight Metropolis Hastings algorithm (LMH), which is based on a Metropolis-within-Gibbs approach. The Lightweight Metropolis Hastings algorithm (LMH) in reversible jump Markov chain Monte Carlo methods focuses on efficient proposal design for transitioning between configurations. When the downstream path remains the same, downstream draws can be reused, but if it changes, the trace is redrawn by simulating from the prior. This new sample is accepted or rejected with an additional term in the acceptance ratio. LMH proposes from the prior whenever the configuration changes for downstream variables. LMH performs poorly for programs with stochastic support, especially in high dimensions. A DCC framework for Anglican has been implemented for automated inference. Strategies for unspecified components include Metropolis-with-Gibbs and PI-MAIS algorithms for local inference, dynamic model discovery for SLPs, and resource allocation based on a specific approach. The model discovery approach for establishing SLPs involves a resource allocation strategy based on exploration-exploitation. Local inference aims to estimate the local target density \u03c0 k (x) and the local marginal likelihood Z k. Conventional MCMC samplers like MH, HMC, or MwG can be used to approximate \u03c0 k (x) due to the fixed support of each SLP, simplifying the inference process. We use MwG in our implementation to estimate Z k and run N independent MwG samplers for each SLP to encourage sample diversity. To estimate Z k, we use the PI-MAIS approach, which generates marginal likelihood estimates from MCMC chains. The PI-MAIS approach introduces a mixture proposal distribution using separate proposals centered on each chain in MwG samplers. This produces a marginal likelihood estimate\u1e90 k based on importance sampling, with the option to use either MCMC samples or importance samples for estimating\u03c0 k (x). The choice between these approaches depends on the specific problem at hand. The PI-MAIS approach introduces a mixture proposal distribution for estimating\u1e90 k based on importance sampling. In high-dimensional problems, using original MCMC samples may be more effective than the PI-MAIS estimator. Identifying the dominant Z k is crucial for achieving a good approximation of the posterior. One approach to discovering sub-models dynamically at run time is proposed as an alternative to static analysis of program source code. This method avoids the complexity of analyzing all possible programs in a universal PPS and is particularly useful when dealing with countably infinite sub-models. Our approach involves executing the program forward to generate sample execution traces, recording the paths traversed, and initializing a set of SLPs. Subsequent iterations involve performing global LMH proposals based on chosen sub-models, adding unseen paths as new SLPs to our stack of models. This method dynamically discovers sub-models at runtime, avoiding the complexity of analyzing all possible programs in a universal PPS. The new SLP is not considered for resource allocation until a threshold is reached. Different starting points are provided for N MCMC changes. Partitioning SLPs into separate models for discrete variables can aid in mixing the local MCMC sampler. A resource allocation scheme is introduced to prioritize accurate estimates for SLPs with large Zk values. The resource allocation scheme, based on an Upper Confidence Bound (UCB) scheme, updates estimates for the SLP with the largest utility. The optimal allocation strategy is to choose each A k in proportion to certain parameters. DCC is compared against IS and RMH on convergence. DCC is compared against IS and RMH on the convergence of log marginal likelihood and the posterior distribution of the number of clusters over 15 independent runs. The ground truth is estimated using a large number of samples with a manually adapted proposal. DCC outperforms the baselines for both metrics. The reward function in UCB is typically in [0, 1], with the target exploration term being a subjective estimate on improving local inference. Extracting additional information from log weights helps in estimating Z k accurately, especially in the early stages of inference. Defining p k as the probability of obtaining a sample with weight exceeding a threshold, it aids in exploration by considering the cumulative density estimator of log local weights. In the model, hyperparameters like w th can be set to the maximum weight among all SLPs. A high p k suggests higher estimates of Z k with more budget. The function is generated by sampling its structure from PCFG R and determining parameters from the prior distribution. The goal is to infer the posterior distribution p(\u0398|D) and calculate the predictive distribution for test data. The number of sub-models is controlled by using the PCFG in a restricted way. The model uses the PCFG in a restricted way, generating a synthetic dataset for training data comparison. DCC, IS, and RMH are compared on estimating posterior distribution and predictive performance. DCC captures periodicity well and interpolates training data effectively, while RMH struggles to fully explore modes. Table 2 compares the test log marginal likelihood (LML) estimates of three algorithms - DCC, IS, and RMH. DCC outperforms the baselines in predictive accuracy and stability, while RMH struggles with high variance and uncertainty in the model. The effectiveness of DCC's resource allocation strategy is tested by comparing computational resource spent on sub-models with the convergence of local marginal likelihood estimates. DCC focuses more on sub-models with high probability mass, while also exploring other sub-models occasionally. Four sub-models out of 26 contain most of the probability mass, with two being functions of a specific form and the other two matching the data well in a specific region."
}