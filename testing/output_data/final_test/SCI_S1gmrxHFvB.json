{
    "title": "S1gmrxHFvB",
    "content": "Modern deep neural networks can achieve high accuracy when the training distribution and test distribution are identically distributed, but this assumption is frequently violated in practice. Accuracy can plummet when the train and test distributions are mismatched. Few techniques currently exist to improve robustness to unforeseen data shifts during deployment. AugMix, a data processing technique, improves the robustness and uncertainty estimates of image classifiers with limited computational overhead. It significantly enhances performance on challenging image classification benchmarks, bridging the gap between previous methods and the best possible performance in some cases by more than half. Modern deep neural networks struggle to generalize across shifts in data distribution, leading to overconfident predictions and miscalibration. Training data may not accurately represent real-world scenarios, causing mismatches between train and test data. Models need to identify when they are likely to be wrong and estimate uncertainty to mitigate fragility. Existing techniques like AugMix aim to improve robustness and uncertainty estimates in image classifiers, enhancing performance on challenging benchmarks. Miscalibration is worsened by mismatched training and testing distributions, leading to increased classification errors on corrupted data sets. Existing techniques struggle to improve corruption robustness, with modern models showing a significant rise in error rates on corrupted test sets. Training against corruptions can lead to memorization of specific corruptions, hindering generalization to new ones. Existing techniques struggle to improve corruption robustness, with modern models showing a significant rise in error rates on corrupted test sets. In this work, a new method called AUGMIX is proposed to enhance both the robustness and uncertainty estimates of classifiers under data shift. AUGMIX achieves state-of-the-art results for robustness and uncertainty estimation while maintaining or improving accuracy on standard benchmark datasets through stochasticity and diverse augmentations. AUGMIX improves corruption robustness using diverse augmentations and a consistency loss, reducing error rates on CIFAR-10 and CIFAR-100 from 28.4% to 12.4% and 54.3% to 37.8% respectively. On ImageNet, it decreases perturbation instability from 57.2% to 37.4%. Code is available at https://github.com/google-research/augmix. Vasiljevic et al. (2016) found that training with various blur augmentations may not generalize well to unseen blurs or blurs with different settings. Hendrycks & Dietterich (2019) introduced benchmarks for measuring generalization to unseen corruptions. Kang et al. (2019) developed an adversarial benchmark for this purpose. Gilmer et al. (2018) and Gilmer & Hendrycks (2019) highlighted the importance of robustness to data shift in machine learning systems. Guo et al. (2017) and Nguyen & O'Connor (2015) proposed metrics for evaluating model calibration. Lakshminarayanan et al. (2017) showed that ensembling classifier predictions can improve calibration. Hendrycks et al. (2019a) demonstrated that pre-training can also enhance calibration. Ovadia et al. (2019) revealed that model calibration deteriorates significantly under data shift. Data augmentation techniques such as random flipping, cropping, Cutout, CutMix, and Mixup can improve model generalization performance. These techniques involve manipulating images to create variations and enhance accuracy on clean data. Controlling the number of composition steps can prevent images from drifting too far from the original. Multiple variations can be generated to increase diversity in the dataset. AUGMIX is a data augmentation technique that improves model robustness and uncertainty estimates, easily integrating into existing training methods. It enhances model performance by mixing multiple augmented images and utilizing an adaptive mixing policy to prevent manifold intrusion. Additionally, Patch Gaussian augments data with Gaussian noise applied to a randomly chosen portion of an image. AugMix is a data augmentation technique that enhances model performance by mixing multiple augmented images using simple augmentation operations and a consistency loss. This approach generates diverse transformations to induce robustness and prevent memorization of fixed augmentations. AugMix is a data augmentation technique that enhances model performance by mixing multiple augmented images using simple augmentation operations and a consistency loss. The algorithm involves mixing the results of several augmentation chains in convex combinations to mitigate image degradation and maintain augmentation diversity. Operations from AutoAugment are used, excluding those that overlap with ImageNet-C corruptions. AugMix is a data augmentation technique that combines multiple augmented images using simple operations like rotate, without using image noising or blurring. It randomly samples k augmentation chains, each composed of one to three operations. The resulting images are mixed using elementwise convex combinations for simplicity. The AugMix technique combines multiple augmented images using convex coefficients randomly sampled from distributions. A \"skip connection\" is used to combine the augmented image with the original image through a second random convex combination. The final image incorporates randomness from various sources. A Jensen-Shannon Divergence Consistency Loss is used to enforce smoother neural network responses by minimizing the Jensen-Shannon divergence among the posterior distributions of the original sample and its augmented variants. The Jensen-Shannon Divergence Consistency Loss is used to measure the average information revealed by samples from different distributions. It is computed by averaging the distributions and then calculating the Jensen-Shannon divergence. This loss helps stabilize and make the model consistent. Training with this loss shows marginal improvement. The Jensen-Shannon Consistency Loss promotes stability and consistency in the model across various inputs. Ablations are discussed in Section 4.3 and Appendix A. The CIFAR datasets consist of small color images with 10 or 100 categories, while the ImageNet dataset contains 1,000 classes of large-scale images. Evaluation on CIFAR-10-C, CIFAR-100-C, and ImageNet-C datasets measures the model's resilience to data shift through corrupted test sets. The CIFAR-10-P, CIFAR-100-P, and ImageNet-P datasets introduce smaller perturbations than CIFAR-C to measure prediction stability. Each example is a video showing gradual changes like brightness. These datasets assess the network's consistency in predictions over frames. Clean Error measures classification accuracy on uncorrupted data. In experiments, corrupted test data appears at five severity levels. The average error across these severities creates the unnormalized corruption error. On CIFAR-10-C and CIFAR-100-C, values are averaged over all 15 corruptions. On ImageNet, corruption error is normalized by AlexNet's error. The Mean Corruption Error is computed from 15 corruption errors. Perturbation robustness is measured by flip probability in video frame predictions. In experiments, perturbation robustness is measured by flip probability in video frame predictions. The mean Flip Probability (mFP) is determined for adjacent frames with different brightness levels. The mean Flip Rate (mFR) is obtained by normalizing flip probabilities. Model uncertainty is assessed through miscalibration, where calibrated classifiers should accurately predict their confidence levels. The idealized RMS Calibration Error is calculated as the squared difference between predicted and actual confidence levels. In experiments, perturbation robustness is measured by flip probability in video frame predictions. The mean Flip Probability (mFP) is determined for adjacent frames with different brightness levels. Model uncertainty is assessed through miscalibration, where calibrated classifiers should accurately predict their confidence levels. The idealized RMS Calibration Error is calculated as the squared difference between predicted and actual confidence levels. AUGMIX enhances robustness in various network architectures like All Convolutional Network, DenseNet-BC, 40-2 Wide ResNet, and ResNeXt-29. ResNet, DenseNet, and ResNeXt require different epochs for convergence. AUGMIX improves corruption robustness and uncertainty estimates across architectures. Compared to the baseline, AUGMIX achieves lower corruption error. The gains transfer across architectures without additional tuning. AUGMIX enhances corruption robustness in various network architectures. AUGMIX improves corruption robustness and calibration error on CIFAR-10 and CIFAR-10-C, achieving the lowest mFP on CIFAR-10-P. Results are compared to various techniques on ImageNet, showing utility and success in training adversarially robust models. Other techniques like Stylized ImageNet have shown to improve performance on ImageNet-C. Patch Uniform, similar to Cutout, injects random regions of the image with uniform noise. AutoAugment searches for high-performing data augmentation policies, with results denoted as AutoAugment*. Random AutoAugment* and AUGMIX offer more augmentation variety with less computation compared to AutoAugment. Random AutoAugment* differs from RandAugment by sampling magnitudes for each operation and using the same operations as AUGMIX. MaxBlur Pooling smooths pooling results, while Stylized ImageNet (SIN) involves training models with original and stylized ImageNet images. Adjusting content and style loss coefficients in Stylized ImageNet decreases mCE by 0.6%. Using 0.5 content and style loss coefficients decreases mCE by 0.6%. SIN and AUGMIX can be combined for greater corruption robustness. Models are trained with ResNet-50 following standard training scheme. AUGMIX reduces corruption error and improves clean accuracy. Our method achieves 68.4% mCE on ImageNet-C. Our method, AUGMIX, achieves 68.4% mCE on ImageNet-C, down from the baseline 80.6% mCE. It allows stacking with other methods like SIN for a lower corruption error of 64.1% mCE. AUGMIX also shows state-of-the-art results on ImageNet-P with an mFR of 37.4%, down from 57.2%. Scaling up AUGMIX from CIFAR to ImageNet leads to improved robustness and uncertainty estimation. The utility of AUGMIX lies in training set diversity, Jensen-Shannon divergence consistency loss, and mixing techniques. Improving training set diversity with increased variety of augmentations can greatly enhance robustness. AUGMIX improves perturbation stability by approximately 20% and reduces error rates on CIFAR-10-C. Adding Jensen-Shannon divergence consistency loss further decreases error rates. Mixing random augmentations without this loss results in a lower error rate. AUGMIX, a data processing technique, combines randomly generated augmentations with Jensen-Shannon loss to enforce consistency. It achieves state-of-the-art performance on various datasets like CIFAR-10/100-C, ImageNet-C, CIFAR-10/100-P, and ImageNet-P. The careful combination of variety, consistency loss, and mixing explains its performance. AUGMIX models achieve state-of-the-art performance on various datasets and maintain calibration even with distribution shifts. The hyperparameters of AUGMIX are not highly sensitive, allowing for reliable performance without extensive tuning. Performance of different AUGMIX models with varying hyperparameters is shown in Figure 8, with minimal change in mCE under these variations. The lack of robustness in deep neural networks is attributed to their tendency to latch onto spurious high-frequency correlations in the data. To understand this reliance, model sensitivity to additive noise at different frequencies is measured using a 32 \u00d7 32 sensitivity heatmap on the CIFAR-10 test set. Each point on the heatmap represents the error rate after adding a Fourier basis vector, with low frequency vectors at the center and high frequency vectors further out. The baseline model shows robustness in Fourier sensitivity analysis. In Figure 9, the baseline model is robust to low frequency perturbations but lacks robustness to high frequency perturbations, with error rates exceeding 80%. The model trained with Cutout also lacks robustness. However, the model trained with AUGMIX maintains robustness to low frequency perturbations and is more robust on mid and high frequencies. AUGMIX uses specific augmentation operations shown in Figure 10, avoiding augmentations that may overlap with ImageNet-C test set corruptions. Careful augmentation choice is necessary to prevent augmented images from being classified differently. Histogram color swapping augmentation, as shown in Figure 11, can lead to a manifold intrusion by changing a bird's class. Histogram color augmentation can cause a bird's class to change, resulting in manifold intrusion. Various results for CIFAR-10, CIFAR-10-C, and CIFAR-10-P are included, such as accuracy for each corruption and calibration results for different architectures. Adversarial training performs well on CIFAR-10-P but leads to a drop in accuracy on clean CIFAR-10, unlike AUGMIX. The RMS Calibration Error is estimated by partitioning test set examples into bins. The RMS Calibration Error is estimated by partitioning test set examples into bins based on prediction confidence scores. This estimation is separate from classification error and is used to calculate the Brier Score."
}