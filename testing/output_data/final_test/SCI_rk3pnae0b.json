{
    "title": "rk3pnae0b",
    "content": "The paper focuses on question generation for chatbots, introducing a new problem that requires input of a target topic along with descriptive text. The proposed neural network can generate topic-specific questions, addressing the challenge of asking relevant questions in conversations. The model can be trained directly using a question-answering corpus without additional annotations. Experimental results show it outperforms the state-of-the-art baseline. Question generation is important for chatbot and dialogue systems, generating questions for reading comprehension and large-scale question-answering training. Question generation is crucial for chatbot and dialogue systems, as well as for reading comprehension and question-answering training. Previous methods used human-crafted rules, but deep neural networks have shown success in transforming descriptive sentences into questions. End-to-end learning approaches have improved performance and stability, with attention-based sequence models outperforming rule-based systems. Serban et al. (2016) applied a neural network to Freebase to generate questions from facts. In addition to existing question generation studies, BID7 proposed two approaches - retrieval-based and generation-based, focusing on topic-based question generation. They argue that specifying a relevant topic in addition to the given sentence or paragraph is important for generating targeted questions related to the current conversation. This paper introduces a novel neural network for generating topic-based questions without the need for additional annotations. It addresses the problem of question generation based on a given sentence and topic, proposing a model that can handle different question types for the same topic. The model also explores a pre-decode mechanism to enhance performance. The proposed model for generating topic-based questions can be trained without additional topic labeling. It is evaluated using the Amazon community question-answering corpus, showing effectiveness. Inspired by sequence to sequence models, question pattern prediction, and multi-source sequence-to-sequence learning, the model utilizes a bidirectional LSTM encoder. The model for generating questions uses a bidirectional LSTM encoder and LSTM decoder to create fluent questions without relying on hand-crafted rules. However, it may produce poorly focused questions. Question pattern prediction and topic selection are key components in the question generation engine. This approach divides questions into independent parts - question pattern and topic - to control question type and content during generation. To enhance question generation, two extra pieces of information, Topic (T) and Question Type (QT), are integrated into the sequence-to-sequence learning framework. Multi-source learning combines information from various sources to improve performance. Building on this concept, independent encoders for question type, topic, and answer are designed, with a mechanism to integrate them into the decoder. This approach aims to improve the focus and content of generated questions. The task of topic-based question generation involves generating a question related to a given topic and question type from an input sentence. The model uses a global attention mechanism to maximize the conditional likelihood of the generated question. This approach allows for training directly using a question-answering corpus without additional annotations. The proposed method aims to identify topics shared in question and answer pairs by extracting content that is common between them. This is based on the observation that shared content can be considered as the topic. The process involves extracting the topic from the answer based on the question, represented as sequences of tokens. The proposed method extracts topics from question and answer pairs by considering tokens as candidates for the topic. Voting is done based on the similarity between tokens, and question type is also taken into account. The method extracts topics from question-answer pairs by considering tokens as topic candidates and using voting based on token similarity. Question type is also considered in the process. The model can generate meaningful questions given an answer and a related topic, even if the topic has not appeared in the training corpus. The question generation model described in the paper uses internal vector representations for answer sentences and topics to generate questions. Similar sentences are clustered together based on their LSTM hidden states, indicating that they have similar internal representations. The model utilizes two internal representations to generate questions. Our model uses internal representations to generate questions based on answers and topics. It requires sufficient training data to learn distribution and mapping relationships. The model can generate topic-specific questions using a TQT Encoder, Answer Encoder, and Decoder components. The framework includes an Encoder and Decoder with a pre-decode mechanism. The model uses a TQT Encoder to encode topic information. The 'full connection' components have the same structure with different parameters. The topic and question types are divided into 7 categories represented by type embeddings. The model utilizes a TQT Encoder to encode topic information divided into 7 categories represented by type embeddings. The question type encoder and answer encoder both use bidirectional LSTMs to encode information. The hidden states are concatenated for the question type encoder, and a similar formula is used for the answer encoder. The bidirectional LSTM is used to encode information in the TQT encoder and answer encoder. The hidden states are concatenated for initialization of the decoder hidden state in the model. The decoder LSTM is used to generate questions based on the internal representation. The pre-decode mechanism involves using another LSTM to filter out noise and improve model performance. It generates a pre-decode result to influence the final prediction by rewriting the conditional likelihood formula. The pre-decode mechanism involves using another LSTM to filter noise and improve model performance by generating a pre-decode result to influence the final prediction. The proposed model is evaluated for topic-based question generation using the Amazon question/answer corpus for training and testing. The Amazon question/answer corpus (AQAD) BID20 is used for training and testing, containing around 1.4 million answered questions. Pre-processing involves removing question-answer pairs with irrelevant answers and those with multiple questions or long question lengths. Approximately 900k question-answer pairs are left for experiments. The approach in section 4.1 is used to extract topics and determine question type, with pretrained word embedding BID16 for similarity calculation. Topic selection threshold K is set to 0.4 and word similarity threshold \u03bb to 0.3. The system sets the selection threshold K to 0.4 and word similarity threshold \u03bb to 0.3. The corpus is divided into training, development, and test sets. Hyper-parameters include shared word embedding, limited vocabulary, 600 hidden units, 300 word embedding dimension, 1 layer LSTM in encoder and decoder, and Adam algorithm for parameter updates. In the conventional question generation setting, a sentence classification model BID10 is used to predict questions. The text discusses the use of a sentence classification model BID10 for predicting question types and a sequence labeling model BID12 for extracting topics from answers. Evaluation metrics include BLEU, METEOR, and ROUGE L. Experimental results show the model outperforms rule-based systems. The experimental results show that the model with the pre-decode mechanism outperforms the state-of-the-art baseline in question generation. The model significantly outperforms the basic model, demonstrating the validity of the pre-decode mechanism. The experimental results demonstrate that models with the pre-decode mechanism outperform the baseline in question generation. Human evaluation also shows that the quality of questions generated by the system is rated higher compared to the baseline. Our model outperforms the baseline in question generation based on human evaluation. The model generates more natural questions with higher scores for grammaticality, fluency, and rationality. The Case Study section provides examples of questions generated by our model compared to the baseline. Our model outperforms the baseline in question generation, showing higher quality questions in terms of grammaticality, fluency, and rationality. It demonstrates an anti-interference ability by generating relevant questions even with inaccurate topics. However, there are instances where the model generates irrelevant questions due to incorrect topics. The model's performance is shown in Table 5 with questions generated based on different question types and topics. In this paper, a new task of topic-based question generation is proposed, which has not been explored before. The model can adapt the questioning method based on different question types and topics, showing rational and consistent results. The proposed network architecture outperforms the baseline in generating high-quality questions, even with inaccurate topics. The proposed network architecture outperforms the baseline in generating high-quality questions, showing better performance in a new setting compared to the conventional setting."
}