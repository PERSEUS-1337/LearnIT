{
    "title": "B1ffQnRcKX",
    "content": "The paper introduces the compositional problem graph as a formalism to relate tasks of different complexity by leveraging shared subproblems. It proposes the compositional generalization problem to measure how easily old knowledge can be reused. The compositional recursive learner is introduced as a domain-general framework for learning algorithmic procedures, enabling reasoning about computation by making analogies to previous tasks. This paper introduces a compositional approach to generalization in problem-solving, focusing on leveraging prior experience to solve more complex problems. It aims to formalize and understand compositional generalization in tasks with a structured composition, where solutions involve combining reusable partial solutions to tackle subproblems sequentially. The paper introduces a compositional approach to problem-solving by sequencing reusable partial solutions to tackle subproblems. It frames shared structure across tasks as a compositional problem graph, evaluates compositional generalization, and introduces the compositional recursive learner for composing representation transformations. The key idea is to view generalization as learning algorithmic procedures over representation transformations. The paper introduces the compositional recursive learner (CRL) framework for learning reusable primitive transformations and their composition with sparse supervision. CRL iteratively re-represents input into familiar representations for computation, encapsulating transformations into computational modules controlled by a sequential program. The paper introduces the compositional recursive learner (CRL) framework for learning reusable primitive transformations and their composition with sparse supervision. The training scheme encourages spontaneous specialization of modules around the compositional structure of the problem distribution by exposing the learner to diverse compositional problems, enforcing a local view of the global problem for each module, and training with a curriculum to build off old solutions for new problems. The paper introduces the compositional recursive learner (CRL) framework for learning reusable primitive transformations and their composition with sparse supervision. The application of a sequence of modules can be likened to the execution trace of the program that CRL automatically constructs, where a computation is the application of a module to the output of a previous computation. The construction of a program is framed as a reinforcement learning problem in a meta-level Markov decision process (MDP), allowing for the implementation of loops and recursion using deep reinforcement learning techniques. The paper introduces the compositional recursive learner (CRL) framework for learning reusable primitive transformations and their composition with sparse supervision. The proposed training scheme involves using deep reinforcement learning techniques to implement loops, recursion, and decide on applying modules to re-use sub-solutions for solving larger problems. Experimental results show that the meta-reasoning approach for deciding which modules to execute achieves better generalization to complex problems. Humans can navigate foreign cities and understand novel conversations by extrapolating from limited observations. The paper introduces the concept of compositional generalization, where harder problems are composed of easier problems. Problems in the test set can be solved by combining solutions learned from the training set in novel ways. The paper discusses compositional generalization, where complex problems are broken down into simpler subproblems. These subproblems can be solved individually and then combined to solve the larger problem. The space of compositional problems forms a graph with nodes representing different representations. Learners must construct edges or paths between nodes to transform between representations. There are multiple ways to solve a problem, such as directly learning a transformation or making analogies with other problems. The paper discusses compositional generalization, breaking down complex problems into simpler subproblems. Learners can solve subproblems individually and combine them to solve the larger problem. Problems in machine learning can be viewed as transformations between representations. The compositional problem graph perspective provides a methodological way to relate different representations. The compositional problem graph perspective offers a methodological way to relate different problems of various forms and complexity, useful in lifelong learning. It involves modifying and expanding connections between nodes to solve problems by combining knowledge from subproblems. For example, latent variable reinforcement learning architectures simultaneously solve image reconstruction and action prediction problems by transforming visual observations into a latent representation. Continuing to make connections between nodes expands the frontier of explored nodes in lifelong learning. The paper discusses how compositional generalization can be achieved by re-using computations learned from solving past problems. It introduces challenges to evaluate a learner's capacity for generalization to problems with different subproblem combinations and longer subproblem combinations. The goal is to encapsulate shared functionality across tasks into specialized computational modules. The compositional recursive learner (CRL) framework trains modules to capture primitive subproblems and compose them as solutions to form a path between nodes in a problem graph. The framework includes a controller, modules, and an evaluator, producing a modular recursive program that transforms input into output by selecting and executing modules based on the current state. The controller in the compositional recursive learner framework selects and executes modules based on the current state to produce the next state of the program. This allows for reusing modules across different program executions and within the same execution, creating recursive behavior. The decision problem is formalized as a meta-MDP, with the state space corresponding to intermediate computation states, action space to modules, and transition model to the evaluator. In the bounded-horizon and infinite-horizon versions of CRL, the meta-MDP determines the program's finite or infinite horizon. The program halts when the controller selects the HALT signal, producing the current state as output. CRL receives a terminal reward based on the output match and incurs a cost for each computation to customize complexity. Unlike standard reinforcement learning, CRL's state and action spaces can vary in dimensionality across episodes. CRL trains on problems of different complexity, reducing complex problems to simpler ones. The controller shapes the meta-MDP by choosing which modules get trained, affecting the controller through its dynamics. The desired solution lies between extremes of specialized modules for every pair of nodes or one module for all pairs. The best solution for compositional generalization in CRL involves learning modules and a controller that reflect the original problem graph, encouraging the modules to capture the most important subproblems. To encourage compositional generalization in CRL, modules should capture primitive subproblems with a local view of the global problem. By restricting representation vocabulary and function class based on input, modules can learn task-agnostic functionality that generalizes across problems. Using a curriculum can help solutions for simpler subproblems converge before introducing more complex ones. To encourage compositional generalization in CRL, modules capture primitive subproblems with a local view of the global problem. Using a diverse distribution of compositional problems helps the controller generalize to new node combinations by re-using partial solutions learned during training. This analogy-making ability aids in solving new or more complex subproblem combinations by re-using modules trained on simpler problems. Pretraining the RNN on domain-specific tasks does not benefit compositional problems of longer length. Comparing CRL with and without a curriculum shows the advantage of gradually increasing problem complexity during training. Forward transfer in CRL is observed for longer expressions after a million iterations. The accuracy is shown only for the maximum length expressions added to the curriculum. The experiments aim to test if decomposing a learner based on problem structure improves generalization over training a single architecture. Disjoint subsets of node pairs are used for training and evaluation to assess compositional generalization. The compositional graph is applied to multilingual arithmetic and transformed-MNIST classification domains, showing promising results. In experiments testing learner decomposition for improved generalization, composing representation transformations with CRL showed better results compared to generic learners. The controller and modules start as randomly initialized neural networks, trained with Adam. The model uses proximal policy optimization BID58 for training in a multi-objective, variable-length input, symbolic reasoning multi-task setting. The study evaluates compositional generalization by training on arithmetic expressions in a source language and testing on different lengths and languages. The CRL controller handles multiple target languages using reducers and translators to make local progress on the global problem. The CRL controller uses reducers and translators to handle multiple target languages, transforming tokens in sequences for compositional generalization in arithmetic expressions. The CRL controller achieves better compositional generalization in arithmetic expressions compared to a recurrent neural network baseline, even when pretrained or given more data. It shows significant improvement for complex image transformations and extrapolates to 100-term problems with 60% accuracy. The curriculum-based training scheme helps CRL design its own strategies to solve harder problems. The CRL controller uses edges and paths to connect nodes in the compositional problem graph, solving complex problems by building on solutions from simpler ones. It develops its own internal language to construct solutions for novel problems, mixing different external representations together. The experiment evaluates CRL in a high-dimensional multi-task setting, showing that the modules tend to learn operations specific to the output language only. In a high-dimensional multi-task setting, the CRL controller aims to learn to compose appropriate spatial affine transformations to convert transformed MNIST digits into a \"canonical\" one for classification. This scenario mirrors compositional generalization in humans, where they can recognize objects from different angles. The experiment tests if CRL can generalize to different combinations of spatial transformations. In a high-dimensional multi-task setting, the CRL controller learns to compose spatial affine transformations to convert MNIST digits for classification. The compositional structure is latent, and CRL is initialized with different modules for rotation, scaling, translation, and expressions. The input expression in Pig Latin is transformed to seis in Spanish. The purple modules are reducers, the red modules are translators, and the controller learns the order of operations. Task-agnostic modules force learning of transformations by the controller. The task-agnostic modules in CRL force learning of transformations by the controller, enabling it to generalize solutions from previous experiences, even for non-compositionally structured problems like translating Pig Latin to Spanish. The internal computation involves reducing expressions to numerical evaluations and then translating them using specific modules. This approach allows for generalization to different and longer compositions of generative transformations. The task-agnostic modules in CRL enable the controller to learn transformations for various tasks, even non-compositionally structured ones. Modules are initialized to perform the identity transformation, with symmetry breaking due to stochasticity. CRL creatively uses modules for scaling and translation, with results showing successful generalization. The controller in CRL achieves better compositional generalization compared to baselines like finetuning CNNs and affine-STN preprocessing. CRL's internal language for problem graph representation is showcased in its transformation sequences. Several recent works are referenced. This paper proposes an approach to building a learner that exhibits compositional generalization by bridging deep learning and reformulation. It draws inspiration from meta-reasoning in humans and aims to strengthen connections between different research areas. The paper discusses meta-reasoning in humans and how it relates to compositional generalization in deep learning. It contrasts with traditional meta-learning approaches and focuses on graph-based architectures for modeling physical systems. In contrast to traditional meta-learning, the focus is on factorizing computations in deep learning to uncover the latent organization of tasks. Compositional approaches aim to discover reusable primitive transformations through pre-specified transformations and learning structures. The curr_chunk discusses various approaches in program induction, including neurosymbolic approaches and reinforcement learning. It also mentions the inspiration drawn from lifelong learning research on learners designing their own primitives and subprograms. The curr_chunk complements the idea of factorizing computations in deep learning to uncover the latent organization of tasks. The curr_chunk discusses the optimization in CRL inspired by cognitive development and the usefulness of hierarchy in compositional generalization. It also mentions learning both the controller. The curr_chunk discusses the use of monolithic architectures for compositional generalization in CRL, relating it to hierarchical reinforcement learning literature. It mentions the idea of selecting different weights at different computation steps and compares CRL to a recurrent mixture of experts. This paper focuses on building machines that can leverage prior experience to solve complex problems by formalizing compositional problems and introducing compositional architectures. It addresses the limitations of existing works in multi-task learning and emphasizes the importance of learning how to compose modules for more effective problem-solving. The paper introduces a compositional generalization evaluation scheme for measuring the reusability of old knowledge in machine learning. It presents the compositional recursive learner framework for learning reusable primitive transformations and their composition. Challenges include stabilizing optimization between discrete composition and continuous parameters, generating computation graphs beyond linear functions, and inferring the number of functions needed for a problem family. Discovery of subproblem decomposition without a curriculum is a major challenge. This paper argues that reasoning about computation by making analogies to previous problems leads to higher compositional generalization in machine learning. Encapsulating computational modules based on subproblem structure can improve neural network interpretability. The framework presented can address problems in supervised, unsupervised, and reinforcement learning through transformations between representations in a compositional problem graph. The dataset for multilingual arithmetic contains arithmetic expressions with integers from 0 to 9 and operators in five languages. Training involves 20 language pairs, with 5 pairs held out for testing. The learner sees a small fraction of the training distribution, and the extrapolation set has a vast number of possible problems. The generative process for transforming the standard MNIST dataset involves scaling, rotating, and translating the images on a 42x42 black background. Different transformations are applied based on the size of the digit in the image. The generative process for transforming the standard MNIST dataset involves scaling, rotating, and translating the images based on the size of the digit. Different transformation operations are used, with a total of 16 individual operations. The ordering of transformations is defined as scale, rotate, then translate. Training, validation, and test sets are randomly selected for different compositions of generative transformations. The generative transformations for the MNIST dataset involve scaling, rotating, and translating images. Different operations like scale-small-then-rotate-then-translate and scale-big-then-rotate-then-translate are evaluated. Learners are implemented in PyTorch, with a baseline RNN using a sequence-to-sequence GRU. The controller includes a policy network and a value function to estimate the current expression in numerical arithmetic and multilingual arithmetic tasks. The policy network selects a reducer and location in the input expression, while for multilingual tasks, it samples actions like halt, reduce, or translate. The reducer is then applied based on the choice made. The code for the implementation is available at https://github.com/mbchang/crl. The controller includes a policy network and a value function, each implemented with the same architecture as the CNN baseline. The affine-STN predicts all 6 learnable affine parameters. The rotate-STN's localization network outputs the sine and cosine of a rotation angle, the scale-STN's localization network outputs the scaling factor, and the translate-STN's localization network outputs spatial translations. Training procedure follows the standard Proximal Policy Optimization. The training procedure for the controller in the context of the Proximal Policy Optimization involves sampling episodes, updating the controller and training modules every k episodes. A grid search determined k values of 1024 and 256. The curriculum of CRL is updated every 10^5 episodes, while the RNN's curriculum is updated every 5*10^4 episodes. HALT and reduction operator handling are addressed as no-ops in specific scenarios. The training procedure for the controller in Proximal Policy Optimization involves updating the controller and training modules every k episodes. Symmetry breaking occurs due to random initialization of modules and the controller, leading to certain modules being selected more often. The training procedure for the controller in Proximal Policy Optimization involves updating the controller and training modules every k episodes to minimize negative log likelihood for the arithmetic problem. The controller's objective is to maximize reward by selecting the correct answer token, receiving a reward of 1, and a penalty of -0.01 for each computation step taken. During training, a penalty of -0.01 was found to balance accuracy and computation time. The training procedure involved updating the policy every 256 episodes and the modules every 64 episodes. A curriculum was used to gradually increase translation direction until reaching specific widths for different digit sizes. Unlike in the multilingual arithmetic case, training did not continue on earlier stages during later curriculum stages. In the bounded-horizon setup, CRL is manually halted based on the length of generative transformation combinations. Symmetry breaking occurs with randomly initialized localization networks across modules. The training objective is to classify transformed MNIST digits correctly using negative log likelihood, with the controller aiming to maximize reward. The input is a numerical arithmetic expression and the desired output is the evaluation of the expression modulo 10. Training involves a curriculum of length-2 to length-10 expressions, with limited data (6510 training expressions) to generalize well to unseen length-10 expressions and extrapolate to length-20 expressions. Comparison is made with an RNN architecture directly trained to map input to output. CRL, with its modular disentangled structure, shows better generalization compared to RNN in numerical math tasks. The controller learns windows centered around operators, improving sample complexity. However, CRL's extrapolation accuracy is not perfect. Our learner, compared with RNN baseline, performs well on training set and generalizes to testing and extrapolation set. RNN requires more data to generalize. Accuracy shown for expressions with maximum length in curriculum. Sparse supervision leads to high extrapolation accuracy without step-by-step supervision. The study explores the impact of varying the number of modules available to the learner in a stack-based model of execution. It is observed that using four reducers and zero translators leads to overfitting, while adding five translators to the four reducers improves generalization, even though the translators may not be necessary to fit the training set. The study investigates the impact of different numbers of modules in a stack-based model. Adding five translators to four reducers improves generalization and avoids overfitting, showing robustness in extrapolation performance. The study explores the impact of varying numbers of modules in a stack-based model, showing improved generalization and robustness in extrapolation performance. Training on a curriculum from 2 to 5 terms, the model achieves about 60% accuracy on 100-term problems in a multilingual arithmetic task. Additionally, the controller in the model demonstrates the ability to translate fully reduced answers into the target language, showcasing a novel composition of problem-solving and language translation knowledge. The study explores the impact of varying numbers of modules in a stack-based model, showing improved generalization and robustness in extrapolation performance. The controller in the model demonstrates the ability to translate fully reduced answers into the target language. CRL uses softmax distributions over the vocabulary and follows the rules of order of operations, even if it may make mistakes. The CRL model receives sparse rewards and does not get explicit feedback on its mistakes. Despite a calculation error, it does not affect the outcome as the subexpression would be multiplied by 0 anyway."
}