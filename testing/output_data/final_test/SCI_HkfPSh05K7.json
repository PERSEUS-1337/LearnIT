{
    "title": "HkfPSh05K7",
    "content": "The paper introduces a new framework for open-domain question answering where the retriever and reader interact iteratively. The retriever uses fast nearest neighbor search to scale to large corpora. A gated recurrent unit updates the query based on the reader's state, improving paragraph ranking. Analysis shows iterative interaction helps retrieve informative paragraphs. The multi-step-reasoning framework consistently improves reader architectures on various datasets. The paper introduces a new framework for open-domain question answering, involving a retriever and machine reading comprehension model. Efforts have been made to design neural MRC architectures for short context, but performance degrades in open-domain settings due to the retriever's failure to find relevant paragraphs. The performance degradation in open-domain question answering is attributed to the retriever's inability to locate relevant paragraphs for the machine reading model BID18. Two key desiderata for an effective QA system are proposed: a fast retriever to find context quickly and an interactive system where the retriever can learn to provide more relevant context if needed. Existing QA systems like R3 BID42 and DS-QA BID25 have sophisticated retriever models that are jointly trained with the reader model. The paper introduces an open domain architecture for QA systems where the retriever and reader interact iteratively. The model pre-computes and caches context representations, allowing the retriever to return top paragraphs for re-ranking. The reader model then reads the new retrieved paragraph to find the correct answer. Our framework allows for iterative interaction between the retriever and reader in an open domain QA system. The multi-step-reasoner component facilitates reformulating queries based on previous interactions, improving performance of MRC architectures like DrQA and BiDAF. The retriever quickly finds relevant contexts for the reader to process, enhancing the overall efficiency of the system. Our architecture enhances the performance of MRC architectures like DrQA and BiDAF by allowing the model to combine information across multiple paragraphs. It includes a gated recurrent unit that generates a new query vector for re-ranking the context. The retriever and reader are trained jointly using reinforcement learning, inspired by how students take reading comprehension tests. This paper introduces a new framework for open-domain QA, enhancing MRC architectures by combining information across multiple paragraphs. The model uses a gated recurrent unit for re-ranking the context and is trained using reinforcement learning, inspired by reading comprehension tests. The paper introduces a new framework for open-domain QA where the retriever and reader interact via multistep-reasoning, allowing information retrieval from multiple paragraphs. The paragraph representations are query-independent, making the architecture scalable. The model consists of a paragraph retriever and a reader, showing improvements on neural reading comprehension models. The model includes a paragraph retriever that scores paragraphs for potential answers to a question, and a multi-step-reasoner for iterative interaction between the retriever and reader. The input is a question and a set of paragraphs, with the model extracting a text span as the answer. The paragraph representations are query-independent and not updated once computed. The paragraph representations are computed independently of the query and cached offline. The relevance score is calculated by taking the inner product between paragraph and query vectors. A multi-layer recurrent neural network encodes each token in the paragraph, using a bidirectional LSTM network. The final paragraph vector is computed by combining all token representations with weights. The paragraph representations are computed independently of the query and cached offline. A bidirectional LSTM network encodes each token in the paragraph, and the final paragraph vector is obtained by combining all token representations with weights. The query is encoded by another network to obtain a query vector, and the relevance score of a paragraph with respect to the query is computed using a simple inner product. The paragraph retriever returns the top scoring paragraphs to the reader, utilizing fast nearest neighbor search algorithms for efficiency. The paragraph retriever utilizes fast nearest neighbor search algorithms to find the k paragraphs with the highest inner products w.r.t query, reducing the problem to maximum inner product search (MIPS). By modifying paragraph and query vectors, the search for k-nearest neighbors in L2 distance is equivalent to finding the k nearest paragraph vectors in the inner-product space, allowing for sublinear time complexity. The architecture utilizes fast algorithms for k-NN search with sublinear time complexity in finding the nearest paragraphs. SGTree is used for NN/MIPS due to its quick construction time and efficient performance. Paragraph representations are fixed and cached after training, unlike other models that update representations. The architecture design allows for efficient retrieval of paragraph representations by caching them after training. Positive and negative labeled paragraphs are used for training, with a focus on maximizing or minimizing the log(\u03c3(score(p, q))). The bi-directional LSTM encoder has three layers, and Adam is used for optimization. Once training is complete, paragraph representations are pre-computed and cached for each dataset in the experiments. The reader model is a sophisticated neural machine reading comprehension (MRC) model that processes the top paragraphs. Our model is a sophisticated neural machine reading comprehension (MRC) model that processes multiple paragraphs to output an answer span. It is effective on various neural machine reading models and emphasizes the importance of aggregating evidence across paragraphs for QA tasks. The model computes start and end scores for each token in the paragraph to identify answer spans, and normalizes scores across paragraphs to gather evidence effectively. Our model aggregates the log-probability of scores for answer spans in paragraphs, maximizing the sum of objectives for start and end words. Score aggregation during inference is based on the position of tokens in paragraphs. The model aggregates scores for answer spans in paragraphs based on token positions, with a maximum span length of 15. It combines scores of spans with the same surface form across paragraphs, considering only the top 10 scoring spans per paragraph for aggregation. The architecture includes a multi-step-reasoner for iterative interaction between retriever and machine reader. The multi-step-reasoner module facilitates communication between the retriever and the machine reader by updating the query based on the reader's state. This interaction allows the search engine and QA model to cooperate and solve tasks through communication. The reader state is computed from hidden memory vectors of the reader, capturing encoded information from the paragraphs sent by the retriever. Hidden representations for each token in the paragraph are used to compute the reader state, which involves soft-attention weights and combining hidden vectors with these weights. The reformulated query for the paragraph retriever is calculated using a multi-step-reasoner module with a 3 layer GRU network and a feed forward network. Reinforcement learning is used to train the query reformulation by evaluating the reader's performance after reading the modified query. The problem is defined as a deterministic finite horizon Partially Observed Markov decision process (POMDP). The problem is defined as a deterministic finite horizon Partially Observed Markov decision process (POMDP). POMDP states consist of the entire text corpora, query, answer, and selected paragraphs. The agent observes a function of the current state, which includes the query vector and reader model memory. The action space is formed by all paragraphs in the text corpora, with the retriever selecting top k paragraphs based on the query. Reward is measured by how well the answer extracted by the reader model matches. The reward in this approach is determined by the F1 score, which measures the overlap between the predicted and ground-truth answers. The policy is parameterized by the GRU and FFN of the multi-step-reasoner. The objective is to maximize the expected reward by optimizing the parameters. The gradient of the objective is computed using the REINFORCE algorithm. Pretraining the multi-step-reasoner is effective for QA tasks. Normalizing scores with softmax and avoiding variance reduction baseline improves final performance. Training involves ranking similarity between query and paragraph vectors. The text chunk discusses the use of a Bayesian Personalized Ranking approach to maximize log(\u03c3(q p * \u2212 q p )) in a QA model. The model involves a multi-step interaction between a retriever and reader, with the reader returning the answer based on the top k paragraphs ranked by the retriever. The model returns a text span as the answer from a large text corpora. The text chunk describes the training process of the reader model in a QA system, where the top k paragraphs are sent to the reader for answer span prediction. The reader is trained using supervised learning with correct spans as supervision, while the GRU network parameters are trained using reinforcement learning. Initially, the reader model is pre-trained with T=1 multi-step reasoning steps, then the GRU network parameters are trained using policy gradients. The text discusses training the GRU network in a QA system using policy gradients. Open-domain QA has gained popularity with the introduction of various datasets. Recent work has shown improvement by using a trained retriever, but query-dependent paragraph representations may not scale to full open-domain settings. The text discusses the limitations of current architectures in open-domain settings for ranking paragraphs and the effectiveness of query reformulation in information retrieval. Unlike previous work, the model in this study directly optimizes question answering system performance, showing improved recall in the retriever. Active Question Answering is identified as closely related to the research. Our model improves question answering system performance by reformulating queries in vector space, outperforming Active Question Answering. It utilizes iterative reasoning similar to memory networks for text and knowledge base question answering. This approach is a generalization of iterative reasoning in reading comprehension, showing effectiveness in an open-domain setting. Our proposed multi-step-reasoner framework improves retrieval performance by utilizing query-reformulation in an open-domain setting. The model outperforms Active Question Answering and shows effectiveness in iterative reasoning for question answering. The exact k-NN search using SGTree BID50 enhances performance compared to other strategies. The multi-step-reasoner framework is not limited to any specific k-NN technique. After a few steps, the performance increases, indicating that re-ranking via query-reformulation retrieves relevant evidence from the corpus. The effectiveness of each component of our framework is demonstrated through experiments on large open-domain QA datasets. The paragraph retriever model is evaluated based on inner product between query and pre-computed paragraph vectors. The evidence corpus was created by retrieving the top-5 wikipedia documents for fair comparison to baselines. The paragraph retriever model in the framework is compared to R3 and DS-QA retrievers, showing R3 has better performance. Query reformulation improves re-ranking and overall retriever performance. Scalability is tested by increasing paragraphs from 500 to 100 million, with experiments conducted on a single Titan-X GPU. The GPU implementation of the retriever model outperforms DS-QA, with faster processing and better memory management. SG-Tree also shows impressive performance on CPU. Multi-step-reasoner improves QA performance, as shown by F1 scores on benchmark datasets. The experiment shows that multiple steps of interaction between retriever and reader improve performance on benchmark datasets. Performance peaks around 5 to 7 steps and does not benefit from further increases. A large-scale experiment on TRIVIAQA-open with 1.6M paragraphs per query was conducted to test the model. The experiment conducted on TRIVIAQA-open with 1.6M paragraphs per query showed that iterative interaction between retriever and reader improves performance. The baseline DrQA model achieved an EM score of 39.76 and F1 score of 44.30 with 3 steps of interaction. The overall performance decreased from 61 to 44.3 F1, indicating the challenge of handling large context in open-domain QA. Further analysis of the results is discussed in this section. In analyzing the effectiveness of increasing the number of interaction steps between the retriever and the reader in gathering relevant evidence, results from the SEARCHQA development set are presented in table 4. The quality of retrieved paragraphs improves with more interaction steps, as shown in row 1 of the table. Examples in Figure 4 illustrate how the multi-step-reasoner iteratively modifies the query to find more relevant paragraphs by reading context. The analysis of results on the dev. set of SEARCHQA shows that increasing the number of interaction steps between the retriever and reader improves the quality of retrieved paragraphs. The policy explores different paragraphs initially, with the mean number of unique paragraphs retrieved around 2 when the number of steps is small. The policy explores different paragraphs initially, with the mean number of unique paragraphs retrieved around 2 when the number of steps is small. As the number of steps increases, it chooses to exploit good paragraphs rather than explore. Iterative interaction is shown to be helpful in finding relevant paragraphs for answering queries. This paper introduces a new framework for open-domain question answering where the retriever and reader interact iteratively. The new framework for open-domain question answering involves iterative interaction between the retriever and reader, improving machine reading performance across various datasets. The method allows for scaling to millions of paragraphs and is compatible with different machine reading architectures, enhancing performance for models like Dr. QA and BiDAF."
}