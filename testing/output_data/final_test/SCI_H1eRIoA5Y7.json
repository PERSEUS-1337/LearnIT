{
    "title": "H1eRIoA5Y7",
    "content": "Convolutional Neural Networks (CNNs) use spatial convolution operators with point-wise nonlinearities to filter input data. To reduce computational cost, new architectures are proposed with sparser coupling between channels, decreasing the number of parameters and computational complexity in CNNs. Our new residual neural network architectures are based on discretizations of Partial Differential Equations (PDEs), resulting in predictable theoretical properties. The first architecture utilizes a sparse convolution operator applicable to a wide range of CNNs, while the second architecture is a discretization of a diffusion reaction PDE and employs three different convolution operators. Despite significantly reducing the number of trainable weights, our experiments show that these architectures achieve comparable accuracy to fully coupled CNNs in the channel dimension. Convolutional Neural Networks (CNNs) are effective for processing high-dimensional input data like speech and image recognition tasks. They replace linear transformations with convolution operators, leading to computational efficiency and reduced weight numbers. Features in CNNs can be grouped into channels for defining interactions between them. The common approach in CNNs is to fully couple features across channels, leading to a large number of convolution operators. This can be problematic for wide architectures or high-dimensional data due to computational expenses and memory limitations. To address this, the paper proposes four novel ways to parameterize CNNs more efficiently based on ideas from Partial Differential Equations. The paper proposes efficient ways to parameterize CNNs based on ideas from Partial Differential Equations, aiming to reduce the number of weights and computational costs. By using spatial convolutions for each channel individually and coupling them with 1x1 convolutions, the architectures are inspired by ResNets interpreted as time-dependent nonlinear PDEs. The approach is motivated by a Reaction-Diffusion model for modeling highly nonlinear processes. The new architectures are derived by discretizing a continuous model using 1x1 convolutions and spatial convolutions similar to depth-wise convolutions. These networks have distinct theoretical properties based on ODEs and PDEs. The first approach replaces traditional convolutions with a linear sum of depth-wise and 1x1 convolutions, while the second approach applies operators separately with a non-linear activation function following the 1x1 convolution. The third architecture proposes a semi-implicit scheme for forward propagation through the network, coupling all pixels in the image in one layer using a depth-wise 3x3 convolution. It replaces the depth-wise convolution structure with circulant connectivity between channels, aiming to improve stability and spatial coupling of features. The scheme involves an inverse of the depth-wise convolution preceded by a non-linear step with a 1x1 convolution, efficiently computed using Fast Fourier Transforms (FFT). The convolution structure with circulant connectivity between channels is motivated by efficient tensor product definitions. It reduces computational complexity from O(c^2) to O(c log c) by extending FFT-based convolutions along the channel dimension. Comparisons in Table 1 show reduced weights and computational complexity for forward propagation in the reduced architecture. Our architectures are based on a mix of 1 \u00d7 1 and \"depth-wise\" convolutions similar to MobileNet. They are a discretization of PDEs, allowing for stability control and new analysis methods. The paper describes the mathematical formulation of the supervised classification problem with deep residual neural networks. The paper introduces novel parameterizations of CNNs for supervised classification using deep residual neural networks. Experimental results on CIFAR10, CIFAR 100, and STL10 datasets show comparable performance to fully-coupled convolutions with reduced trainable weights. The mathematical formulation is based on BID6 and can be applied to various structured data types. The paper introduces novel parameterizations of CNNs for supervised classification using deep residual neural networks. The goal is to find network parameters and weights of a linear classifier to minimize a regularized empirical loss function. The optimization problem is solved using standard variants of the stochastic gradient descent algorithm. The performance of image classification relies on designing an effective neural network. The paper discusses the design of effective neural networks for image classification, focusing on convolutional ResNets. Recent works have highlighted a connection between ResNets and partial differential equations, allowing for the analysis of stability in ResNet architectures. The network parameters and weights are optimized to minimize a regularized empirical loss function using stochastic gradient descent. In a ResNet, the nonlinear term typically involves a rectified linear unit (ReLU) activation function. The weight vector is divided into two parts parameterizing linear operators, and a normalization layer may be included. In CNNs, the linear operator is formed by combining spatial convolution operators, offering various modeling options. The focus is on the coupling between different feature channels, with the common choice being full coupling across channels. The operator K(\u03b8) in CNNs consists of convolution matrices parametrized by different stencils, leading to high computational costs. More efficient coupling strategies are introduced to address this issue. The first convolution operator combines depth-wise and 1 \u00d7 1 convolutions, while the next two networks are inspired by reaction-diffusion PDEs. The proposed architectures in the context of CNNs introduce efficient coupling strategies by combining depth-wise and 1 \u00d7 1 convolutions. Inspired by reaction-diffusion PDEs, a block circulant structure is imposed on the diffusion operator in the reaction-diffusion PDE. Detailed instructions on implementing these architectures are provided for efficiency. The MobileNets BID13 architecture combines depth-wise and 1 \u00d7 1 convolutions in separate neural network layers, with non-linear activation and batch-normalization. The depth-wise convolution is related to structurally sparse convolutions in BID27, but with a different kernel arrangement. A simplified version of the coupled convolution equation 4 is proposed by combining diagonal and off-diagonal weights into one operator. The diagonal part of M(\u03b8 (2)) can be ignored as the same coefficients appear in K dw (\u03b8 (1)). This type of convolution can be used in CNNs with equal input and output channels. A new class of CNNs based on reaction-diffusion equations is introduced, which model highly nonlinear processes. These equations lead to expressive patterns, making them intriguing for learning and a natural extension for ResNets. The RD equation is discretized using a ResNet structure with a small time step h. The first convolution operates as diffusion. The convolution in the current chunk involves a diffusion operation on each channel separately and a 1x1 convolution for modeling reactions between features in different channels without spatial coupling. The operations can be efficiently implemented using matrix multiplication and standard convolutions. The depth-wise operator can also be computed using FFT. The cost of the computation for the convolution scales linearly with the number of channels compared to the square of the standard fully connected convolution. The second type of CNN is an \"implicit\" version of the previous convolutional layer, utilizing semi-implicit time-stepping for better stability. This behavior is well-known in the context of forward propagation equations. The implicit convolutional layer offers advantages over its explicit counterpart in the context of time-dependent PDEs. It allows for global coupling between pixels in one application, impacting features across the image. The special structure of the depth-wise kernel enables efficient solving of the linear system using O(c \u00b7 n log(n)) operations. The inverse of the block diagonal kernel is computed by solving individual blocks in parallel, utilizing 2D FFT for efficient computation. The computational efficiency of CNNs can be increased by treating image data as a 3D tensor with channels. Using a block circulant operator and tensor SVD has shown promising results on the MNIST dataset. Matrix-vector products with circulant blocks can be done efficiently using FFT under periodic boundary conditions. The computational complexity of the product is proportional to (nc) log(nc) where n is the number of pixels, requiring much fewer parameters compared to standard convolution. Experimental comparisons with ResNet and MobileNet architectures show similar accuracy with considerably fewer weights. All experiments are conducted using PyTorch software with a base architecture that is a modified version of the one described previously. The study compares different network sizes with similar structures to demonstrate comparable performance to a standard ResNet using fewer parameters. The networks consist of blocks with an opening layer, followed by batch normalization and ReLu activation. Each block includes a ResNet-based part with four steps, varying in experiments. The architectures for the steps include ResNet, MobileNet, and LinearMix. The study compares different network sizes with similar structures to demonstrate comparable performance to a standard ResNet using fewer parameters. The networks consist of blocks with various architectures such as ResNet, MobileNet, and LinearMix. Each series of steps is followed by a connecting layer that concatenates images and applies depth-wise convolution and batch normalization. This doubles the number of channels, followed by an average pooling layer that downsamples the images. Different connecting layers were experimented with, leading to similar results. Three networks with varying channel numbers are used, with the last block consisting of a pooling layer that averages the image. The last block in the network consists of a pooling layer that averages image intensities of each channel to a single pixel. A fully-connected linear classifier with softmax and cross entropy loss is used for training without regularization. The ADAM optimizer is utilized with default parameters, running 300 epochs with a learning rate reduction every 60 epochs. Standard data augmentation techniques are applied, and datasets like CIFAR-10, CIFAR-100, and STL-10 are used for training. The STL-10 dataset contains 13,000 color images divided into training and test sets. Classification results show that the architectures used are on par or better than other networks. The efficiency of the architecture increases with the number of channels, making it computationally efficient. The runtime of FFT-based convolutions is compared to fully connected layers. The runtime comparison of FFT-based convolutions to fully connected layers is conducted using the cudnn package version 7.1 on a Titan Xp GPU. Circular and depth-wise convolutions are implemented using cufft, with PyTorch's implementation for direct depth-wise convolution. The experiments report the relative computation time ratio between the two implementations, with the possibility of using cudnn for certain convolutions. The results are presented in FIG0 based on 100 convolutions. The runtime comparison of FFT-based convolutions to fully connected layers is conducted using the cudnn package version 7.1 on a Titan Xp GPU. The presented runtime ratio in FIG0 shows the execution time ratio with respect to image size, stencil size, and number of channels for different convolution methods. The FFT-based implementation is favorable for wider stencils in depth-wise convolution models. The execution ratio is linear in the number of channels, reaching a ratio of 1 at around 200 channels for FFT-based implementations. New convolution models aim to reduce parameters and computational costs by proposing alternative ways to traditional channel coupling. These models are related to continuous models in terms of PDEs, ensuring stability and paving the way for more extensive theory. Our new convolution architectures show stability and promise for image classification, almost as effective as fully coupled CNNs but more cost-efficient. These architectures can also be applied to audio, video, and other tasks traditionally handled by CNNs. They are particularly advantageous for 3D or 4D problems like analyzing time series of medical or geophysical images, where traditional convolutions are costly and computationally complex. The number of weights also poses challenges for hardware with limited memory."
}