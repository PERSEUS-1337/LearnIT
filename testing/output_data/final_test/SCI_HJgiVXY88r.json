{
    "title": "HJgiVXY88r",
    "content": "Deep predictive coding networks are unsupervised learning models inspired by neuroscience that predict future sensory states. The study investigates if these models can predict brain activity in the visual cortex using representational similarity analysis (RSA) with fMRI and MEG data. Results suggest that unsupervised models trained to predict videos may outperform supervised image classification baselines in correlating with spatial and temporal brain data. The study evaluates predictive coding networks trained on varying amounts of unlabeled videos to assess their performance compared to supervised baselines. The PredNet architecture, based on predictive coding theory, utilizes recurrent convolutional layers to predict future video frames by capturing latent structure in image sequences. The more data used for training, the higher the correlation scores achieved. The study evaluates PredNet architecture trained on unlabeled videos from the Moments in Time dataset to improve common sense understanding of events. The model is trained unsupervised to predict future frames using a top-down generative model. The study evaluates PredNet architecture trained on unlabeled videos from the Moments in Time dataset to improve common sense understanding of events. The model is trained unsupervised to predict future frames using a top-down generative model. In terms of architecture, the model uses four modules (PredNet-4) with specific hyperparameter settings and input frame dimensions. Additionally, a larger 5-layer model (PredNet-5) is trained with higher resolution input frames. Brain data feature extraction and evaluation are performed on two datasets of object images and brain data recorded using fMRI and MEG in response to visual stimuli. The PredNet model is used to extract features from visual stimuli datasets for comparison with brain data. Features are transformed into representational dissimilarity matrices to capture differences between models. Each image is repeated ten times to align with the PredNet architecture. The study compares different models by creating representational dissimilarity matrices (RDMs) from features extracted using the PredNet model. The RDMs are then compared to brain data from fMRI and MEG, with similarity computed using Spearman's correlation. Correlation scores are normalized by the noise ceiling, providing a best estimate of the subject-averaged RDM. The study compares different models using representational dissimilarity matrices (RDMs) from features extracted with the PredNet model. The subject-averaged RDM is considered the best estimate of an RDM generated by an ideal model. CORnet-S is the top-performing model according to the Brain-Score benchmark, outperforming AlexNet and ResNet-50 on a 92-images dataset. On a 118-images dataset, CORnet-S (V2) excels in fMRI but is surpassed by AlexNet (conv2) in MEG data. Despite being outperformed in specific cortical areas like V4, CORnet-S remains a competitive model overall. The predictive coding model used in experiments learns without labeled data by minimizing error between predicted and actual sensory data. Trained on videos of activities like cooking, walking, and dancing, it outperforms AlexNet in correlation to fMRI and MEG data with just 1 hour of training. Scaling unsupervised learning with PredNet models improves correlation with brain data by learning more about how events unfold over time. The architecture of PredNet fulfills properties of a brain-like model and is designed to process spatiotemporal information efficiently. More experiments are needed to separate the impact of training data and model size on correlation scores. The use of recurrence in CORnet and other convolutional models has been shown to capture neural dynamics, but they cannot replicate real-world dynamics from static images. Semantic divisions in neural activity require experiencing how objects behave in space and time. Unsupervised predictive coding models may be a better starting point than supervised image recognition models to explain visual brain data. The results show potential for improvement in visual brain data analysis by scaling model architecture and training data. State-of-the-art machine learning models rely on large-scale unsupervised pre-training with millions of parameters. Fine-tuning the model, combining features, and annotating RDMs based on semantic categories can enhance correlation scores. Previous studies have successfully applied these approaches. Our goal is to evaluate the capacity of transferring representations learned from unlabeled out-of-domain datasets, not to outperform all models in a specific dataset. Future plans include testing predictive coding representations in brain-likeness benchmarks like Brain-Score."
}