{
    "title": "B1eibJrtwr",
    "content": "The demand for abstractive dialog summary is increasing in real-world applications like customer service centers and hospitals. A new dataset based on MultiWOZ is proposed for abstractive dialog summarization. To address drawbacks in applying document summarization methods to dialogs, the Scaffold Pointer Network (SPNet) is introduced, utilizing speaker role, semantic slot, and dialog domain annotations for better summarization. A new evaluation method is also proposed to overcome limitations of ROUGE in capturing these drawbacks. Summarization aims to condense text by retaining critical information. Dialog summarization has real-world applications in saving time for doctors and tracking project progress in industries. Multi-party conversations are more challenging to summarize than single-speaker documents, making dialog summarization a potential field. There are two types of summarization: extractive and abstractive. Dialog summarization is a potential field that aims to condense multi-party conversations. Extractive summarization selects important utterances from a dialog, but struggles to produce coherent discourses. Abstractive methods, on the other hand, generate novel expressions to condense information, but currently focus more on single-speaker documents due to the lack of dialog summarization corpora. In this work, a dataset for abstractive dialog summarization based on MultiWOZ is introduced. The Scaffold Pointer Network (SPNet) addresses issues with applying news summarizers to dialog by incorporating semantic scaffolds such as speaker role, semantic slot, and dialog domain. The Scaffold Pointer Network (SPNet) enhances abstractive dialog summarization by incorporating speaker roles, semantic slot values, and dialog domain scaffolds. It outperforms existing models on MultiWOZ dataset, achieving superior results in both automatic and human evaluation metrics. The curr_chunk discusses the use of copy mechanism, coverage mechanism, reinforcement learning, and pre-training methods in abstractive summarization. It mentions the challenges of deep reinforcement learning and the success of BERT and GPT in NLP tasks, including summarization. The curr_chunk discusses the adaptation of pre-trained models for dialog summarization, specifically in meeting summarization. Previous work focused on statistical machine learning methods for extractive dialog summarization, while abstractive dialog summarization was less explored. Recent research has shown promising results in abstractive dialog summarization. Recent work has focused on creating benchmarks for abstractive dialog summarization using existing dialog corpora. Goo & Chen (2018) annotated topic descriptions in the AMI meeting corpus for summarization but with coarse topics. Li et al. (2019) developed a model for summarizing audio-visual meeting data abstractively. In response to the limitations of existing document summarizers in conversation settings, the Scaffold Pointer Network (SPNet) was proposed, incorporating semantic scaffolds to enhance abstractive dialog summarization. The Pointer-Generator model combines Seq2Seq and pointer network for dialog summarization. It uses attention distribution to compute context vectors from encoder hidden states. The Pointer-Generator model utilizes a pointing mechanism to combine copying words from the source text with generating words from a fixed vocabulary. It includes a dynamic vocabulary for out-of-vocabulary words and computes the final probability distribution on the extended vocabulary. The Scaffold Pointer Network is based on the Pointer-Generator model and incorporates separate encoding for different roles, semantic slot scaffold, and dialog domain scaffold. The encoder-decoder framework uses separate encoding for user and system utterances, with attention distributions and context vectors calculated accordingly. The pointing mechanism in the model follows a specific equation to obtain the context vector. The Scaffold Pointer Network integrates semantic slot scaffold through delexicalization in dialog modeling. Delexicalization replaces slot values with semantic slot names to reduce vocabulary size. The model uses separate encoding for user and system utterances, with a pointing mechanism to fill slot values into slot tokens for a complete summary. The SPNet integrates domain classification and delexicalization in dialog summary to simplify dialog modeling. The model fills slot values into slot tokens using a copy and pointing mechanism, training with delexicalized utterances and attention distribution over source tokens. The SPNet integrates domain classification and delexicalization in dialog summary through a multi-task framework. Dialog domain scaffold is incorporated to handle different conversation tasks like booking hotel, restaurant, and taxi. Domain classification aids in learning better representations by providing domain-specific information for the encoder. The SPNet integrates domain classification and delexicalization in dialog summary through a multi-task framework. Loss functions for summarization and domain classification are denoted as loss 1 and loss 2 respectively. The domain classification task involves multi-label binary classification. The experimental settings validate SPNet on the MultiWOZ-2.0 dataset, consisting of multi-domain conversations between a tourist and an information center clerk. During MultiWOZ data collection, dialogs were categorized into single-domain and multidomain, with instructions provided for crowd workers. The dataset was split into training, validation, and testing sets. ROUGE metrics were used to evaluate the summarization model, but it was deemed insufficient. The ROUGE metrics were found to be insufficient in evaluating the summarization model due to its limitations in capturing the relevance and readability of the summary. A new evaluation metric called Critical Information Completeness (CIC) is proposed to address this drawback by focusing on the recall of semantic slot information in the summary. Critical Information Completeness (CIC) is a recall metric for semantic slot information in summaries. It complements ROUGE by focusing on essential entities in dialog domains. CIC is computed as the mean over all domains and is applicable to tasks with predefined critical information. It is implemented with OpenNMT framework and delexicalizes utterances accordingly. Our model is built on the OpenNMT framework and delexicalizes utterances based on belief span annotation. We combine slots referring to the same information across dialog domains. Word embeddings are trained from scratch with specific dimensions for LSTM encoders and decoder. Adam optimizer is used with specific parameters, and learning rate is adjusted to prevent overfitting. Hyperparameters are set for the objective function, batch size, and beam search during decoding. Model parameters are selected using the validation set. SPNet model is compared with PointerGenerator and Transformer in document summarization. Transformer uses attention mechanisms for sequence transduction. Results show SPNet outperforms in ROUGE and CIC scores. SPNet outperforms Pointer-Generator and Transformer in document summarization, achieving the highest scores in ROUGE and CIC. The baselines have room for improvement in preserving critical slot information. SPNet incorporates semantic scaffolds, with semantic slot contributing the most to its increased performance. The client is looking for a guesthouse with free wifi and parking for 6 people for 4 nights starting Sunday. The help desk books them at the Alexander Bed and Breakfast with 3 rooms and provides a reference number. The client is looking for an Italian restaurant in the same price range in the center of Cambridge. The help desk suggests booking at Ask restaurant, confirms the booking for 6 people on Sunday at 18:45, and provides a reference number. The client is looking for a guesthouse in Cambridge with free wifi and a cheap price range for 6 people and 4 nights starting from Sunday. They also need information on Ask restaurant, including the price range and postcode. The client is looking for a guesthouse in Cambridge with free wifi and a cheap price range for 6 people and 4 nights starting from Sunday. They also need information on an Italian restaurant in the same price range and area as the hotel for a table booking at 18:45 on the same day. The study involves human evaluation of summaries generated by Pointer-Generator and SPNet models. 100 test samples from MultiWOZ test set were randomly selected and shown to 150 crowd workers for scoring on relevance, conciseness, and readability. Results show that the model outperforms PointerGenerator in all three evaluation metrics. SPNet outperforms PointerGenerator in scoring on relevance and readability. Ground truth is perceived as more relevant and readable, but not high in absolute score. Evaluators found ground truth lacking necessary information and unnatural. SPNet excels in ranking evaluation, with performance close to ground truth. Table 3 shows SPNet outperforming Pointer-Generator in human evaluation metrics with significant differences. Pointer-Generator's summary lacks essential information like restaurant booking details. Separately encoding speakers reduces repetition and inconsistency in summaries. Our method, SPNet, addresses repetition and inconsistency in summaries by considering dialog properties. While it may have limitations in including additional information beyond the ground truth, it can still accurately summarize content not covered in the reference summary. However, SPNet requires extra annotations for semantic scaffolds, such as speaker roles in dialog datasets. SPNet is an end-to-end model that incorporates speaker roles, semantic slots, and dialog domains as semantic scaffolds to improve abstractive summary quality. The model adapts the MultiWOZ dataset for dialog summarization and introduces an automatic evaluation metric called CIC to measure semantic slot relevance. SPNet, an end-to-end model, incorporates semantic slots to enhance abstractive summarization quality. It outperforms baseline methods in both automatic and human evaluation metrics, showing the effectiveness of semantic scaffolds in dialog summarization. The model can be extended to other summarization tasks, such as news summarization, by annotating critical entities for accurate capture in generated summaries. Additionally, plans include collecting a diverse human-human dialog dataset for further evaluation. The hotel should be a guesthouse or in the moderate price range for 6 people and 4 nights starting from Sunday. Find a restaurant in the center. Evaluators prefer SPNet for its coherence and relevance. The client inquires about expensive 0-star hotels in the town center, but none are available. The help desk suggests the Cityroomz Hotel, which is moderately priced with free internet and parking. The client books a room for 3 guests for one night after the original dates were filled. The help desk books a hotel room at Cityroomz for 3 people for one night. A taxi is also booked for the client to go from the restaurant to the hotel. The client is satisfied with the arrangements and ends the conversation. The client is looking for a hotel with no free parking for 3 people and 5 nights starting from Sunday, with a backup option for 1 night. They also want to dine at a moderate-priced restaurant in the center of Cambridge and book a taxi to commute between the two places. The client is looking for a hotel for 3 people and 5 nights starting from Sunday, with a backup option for 1 night. They also want to dine at a moderate-priced restaurant in the center of Cambridge and book a taxi to commute between the two places. The dialog involves discussing semantic slots in the conversation related to restaurant, hotel, and taxi domains, with incorrect and correct slot values highlighted in red and green respectively."
}