{
    "title": "HklaEUUtON",
    "content": "Sequential data often originates from diverse environments, with shared regularities and environment-specific characteristics. Disentangled state space models (DSSM) are introduced to learn robust cross-environment descriptions of sequences, separating environment-invariant state dynamics from environment-specific information. Empirical results show that this separation enables robust prediction, sequence manipulation, and environment characterization. An unsupervised VAE-based training procedure is proposed to learn DSSM as Bayesian filters. Experimental results demonstrate state-of-the-art performance in generating and predicting bouncing ball video sequences under varying gravitational influences. Learning dynamics and models from sequential data is crucial in various domains such as natural language and videos. The curr_chunk discusses the importance of managing input of diverse complexity for building interactive agents using reinforcement and control algorithms. It mentions the use of state space models (SSM) like Kalman filters and the benefits of learning model-free SSM. The text also highlights the introduction of additional structure into SSM for separating confounders, actions, observations, rewards, and dynamics, especially for transfer learning and extrapolation. The curr_chunk discusses learning structured state space models (SSM) to decouple system dynamics into generic and environment-specific components for robust extrapolation across different environments in a panel data setting. The focus is on modeling environment as a static element in the latent space to separate sequence dynamics into invariant and environment-specific parts. The curr_chunk discusses decoupling sequence dynamics into generic and environment-specific parts in structured state space models (SSM) for robust extrapolation across different environments. This approach aims to enhance predictive robustness, domain adaptation, and environment characterization. Examples include Michaelis-Menten model, bouncing ball kinematics, ODE dynamics, and bat swinging motion. The curr_chunk introduces disentangled state space models (DSSM) for exploiting invariance in sequential data from diverse environments. It implements DSSM using Bayesian filters with unsupervised training and amortized variational inference. The approach enhances robustness, allows extrapolation to unseen environments, and is applied to video prediction and manipulation tasks. Video prediction and manipulation using disentangled state space models (DSSM) involves analyzing video sequences with varying gravity. Outperforming K-VAE BID8 in predictions, interventions are made by \"swapping environments\" to enforce specific dynamic behaviors. Related approaches focus on structured and disentangled representation of videos, separating pose from content. DSSM introduces environments to model environment-specific effects on sequence dynamics. Proposed models improve prediction and enable controlled generation with \"feature swapping\". Content-based disentanglement is performed in speech analysis, separating sequence-and segment-level attributes. VAE frameworks extended to sequence modeling and applied to speech, videos, and text. Alternative methods learn SSM to \"image the world\" directly from the latent space, bypassing autoregressive feedback. DVBF trains SSM using VAE-based learning procedure. In DVBF BID19, SSM is trained using VAE-based learning procedure allowing gradient propagation through time. K-VAE by Fraccaro et al. FORMULA0 decomposes object representation from dynamics. DKF BID22 and DMM BID23 have SSM structure but state inference is conditioned on past and future observations. Our approach focuses on dynamics-based disentanglement, complementing existing methods. Our Bayesian filter blends ideas from amortized variational inference BID19 BID25 for novel DSSM implementation. In this work, the authors adapted recent ideas in amortized variational inference for a novel DSSM architecture. They assume a deterministic underlying system with uncorrelated latent process noise and observation noise. The goal is to jointly learn the generative model and recognition networks to infer process noise, environment, and initial state. The framework overview is provided in figure 3. The generative model assumes a joint distribution for observed sequences, with prior probabilities set as zero-mean unit-variance Gaussian. Inference involves a variational distribution over unobserved variables, while learning aims to match posterior distributions of environment and initial state. The text discusses utilizing a reparametrization trick to match posterior distributions to prior probabilities for end-to-end training. The objective function is defined using the variational lower bound, which is maximized during training. The KL term simplifies into a sum of KL terms, and Algorithm 1 details the training procedure for one iteration. The text discusses optimization challenges in training a model with bi-directional LSTM and multilayer perceptron. A regularization term penalizes step-wise changes in time embeddings to enforce time invariance. This idea is related to maximum mean discrepancy approaches. The text discusses using a KL annealing scheme to prevent convergence to local minimums in training a model with bi-directional LSTM and multilayer perceptron. The model is tested on a 2D bouncing ball problem with varying gravity settings to evaluate robustness across environments. The gravity vector is randomly changed during video sequence generation. More details can be found in the experiments at: https://sites.google.com/view/dssm. The text discusses generating trajectories with varying gravity vectors in 32x32 binary image frames. It compares forecasting methods and demonstrates controlled and uncontrolled generation by manipulating video sequences. Environment embeddings are visualized for intuition. The text discusses using OpenCV to detect ground truth ball positions in each time frame for trajectory forecasting. A DSSM-based Bayesian filter is compared against K-VAE for long-term forecasting of ball velocities, showing improved prediction quality in both magnitude and cosine similarity metrics. The text discusses using OpenCV to detect ground truth ball positions for trajectory forecasting. A DSSM-based Bayesian filter is compared against K-VAE for improved prediction quality. Controlled generation involves extracting initial state from a baseline video sequence and manipulating the environment. An auxiliary classifier is trained to map environment to true gravity values with 99.15% accuracy. Uncontrolled generation involves sampling from priors for sequences. The text proposes a novel approach for learning dynamics from diverse environments using disentangled state space models. By separating generic system dynamics from environment-specific information, robust cross-environment models can be learned. The application focuses on learning the video dynamics of a bouncing ball affected by varying gravitational influences, achieving state-of-the-art results. Future work will include exploring other types of data. The text discusses a lower bound derivation and experiments involving a shallow convolutional network for compressed image representation. The approach aims to learn dynamics from diverse environments using disentangled state space models, separating generic system dynamics from environment-specific information. The text discusses using a deconvolutional network with transposed convolutions and different settings for KL annealing in the model to learn time-invariant components. Down-weighing the reconstruction term with scaling coefficients helps in faster convergence during training. The text discusses using ADAM optimizer with specific parameters, OpenCV's BID17 functions for ball detection in images, and backpropagation with different loss functions for training the model."
}