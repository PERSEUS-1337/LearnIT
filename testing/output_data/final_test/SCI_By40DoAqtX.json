{
    "title": "By40DoAqtX",
    "content": "In this work, a novel adversarial learning framework is proposed to integrate discriminative models into structured prediction models. Discriminative models act as energy-based models, estimating scores to improve the quality of predicted outputs. This approach addresses the gradient vanishing problem and enhances the performance of structured prediction models. The proposed adversarial learning framework integrates discriminative models into structured prediction models to address the gradient vanishing problem. This approach improves the quality of predicted outputs for tasks like multi-label classification and image segmentation. Empirical results validate the effectiveness of the learning method. Existing methods rarely use discriminative models to improve structured prediction models at the inference stage due to gradient vanishing problems caused by training instability in adversarial learning frameworks. Most adversarial learning methods treat discriminative models as classifiers, hindering the refinement of structured prediction models. In the proposed framework, discriminative models are trained as energy-based models to address gradient vanishing problems. They assign scores to evaluate predicted outputs, guiding structured prediction models to predict outputs with maximum scores. This approach allows discriminative models to approximate continuous value functions and provide non-zero gradients for predicted outputs, enabling the refinement of structured prediction models. The proposed method, known as Learning Discriminative Models to Refine Structured Prediction Models (LDRSP), utilizes data generated by structured prediction models to train discriminative models. Training involves generating extra samples using the inference algorithm and augmenting the training set with adversarial samples. The proposed method, LDRSP, uses data from structured prediction models to train discriminative models. Experiments show that the method can effectively refine structured prediction models by learning discriminative models. The method introduces a novel adversarial learning framework and learns discriminative models to approximate continuous value functions, addressing gradient vanishing problems. The method utilizes discriminative models to improve training stability and address model collapse issues in image to image translation, semantic image segmentation, and neural dialogue generation. Discriminative models are learned to capture distributions between generated samples and training data, enhancing the realism of generated samples. Previous research has used iterative inference methods, while Denoising Autoencoders are proposed to estimate energy distribution gradients for capturing realistic image probability distributions. In contrast to previous methods using feed-forward networks for iterative refinement, our approach utilizes gradient-based inference to find samples with zero task loss. We propose learning discriminative models as energy-based models to evaluate the quality of generated samples and generate extra training samples to better capture probability distributions. There is a growing interest in energy-based structured prediction methods. Previous approaches include adding constraints to neural network parameters to ensure convex output, introducing Structured Prediction Energy Network (SPEN) with a max-margin objective, and proposing an end-to-end version of SPEN for gradient-based energy minimization. Deep Value Network (DVN) was also introduced to evaluate output quality. Our method focuses on adversarially learning energy-based and structured prediction models. Our method introduces a novel adversarial learning framework for structured prediction, incorporating discriminative models to refine structured prediction models during inference. Discriminators, treated as energy-based models, predict scores for input objects and possible outputs. Training involves learning to mimic oracle value functions, such as IOU and F1 metrics for image segmentation and multi-label classification. The proposed method introduces discriminators to refine structured prediction models by estimating a value function v*(y, y*) using regression. Discriminators are learned to estimate v*(y, y*) by optimizing a surrogate loss function. The proposed method introduces discriminators to refine structured prediction models by estimating a value function v*(y, y*) using regression. Discriminators are learned to predict oracle values for samples predicted by structured prediction models. The second term of the modified least-square GAN loss regularizes structured prediction models to have higher scores for predicted samples. Discriminators refine structured prediction models using gradient-based inference. The proposed method uses discriminators to refine structured prediction models by estimating a value function. To overcome small gradients during gradient-based inference, the normalized gradient method is employed. Extra training samples are generated to learn discriminators, consisting of tuples (input x, output y, oracle value v). The method utilizes two methods to generate training samples: inference samples and adversarial samples. Inference samples are generated using structured prediction models and gradient-based inference, while adversarial samples maximize loss with respect to y using a gradient-based optimizer. These samples help refine structured prediction models by estimating a value function and learning discriminators. The method generates adversarial samples during training to learn discriminators, adding a new loss term to the objective function. The Adam optimizer with momentum is used to train structure prediction models and discriminators. Experiments are conducted on multi-label classification, binary image segmentation, and 3-class face segmentation tasks, comparing results with other adversarial learning methods. The code is implemented in Tensorflow. The code is implemented using Tensorflow BID0 for structured prediction models and discriminators. Different adversarial learning methods are utilized, such as GAN, WGAN+GP, LSGAN, and EBGAN. Hyper-parameter exploration is performed for all methods. The experimental results of the proposed LDRSP show that it successfully learns discriminators that refine structured prediction models, achieving state-of-the-art performance on Bibtex and Bookmarks datasets. The refinement improves the performance of the models by 3.6% on Bibtex and 1.1% on Bookmarks datasets. In contrast, other adversarial learning methods show negligible improvements or even performance decrements. For example, EBGAN improves performance by 0.2% on Bookmarks dataset, while LSGAN decreases performance by 0.1%. Our method greatly improves the performance of structured prediction models by jointly learning them with discriminators. It outperforms other state-of-the-art methods on both Bibtex and Bookmarks datasets. Our method outperforms DVN and SPEN on Bibtex and Bookmarks datasets, as well as feed-forward models like logistic regression and neural networks. The image segmentation task is challenging due to high-dimensional output space and complex correlations. We use the Weizmann horses dataset for binary image segmentation. The Weizmann horses dataset consists of 328 left oriented horse images with binary segmentation masks resized to 32 \u00d7 32. Segmentation at this low resolution is challenging, requiring models to capture strong priors of the horse shape. The experiment uses a fully convolutional network (FCN) baseline model with discriminators designed to map (x, y) to score matrices. The experiment utilizes a FCN baseline model with discriminators designed to map (x, y) to score matrices for image segmentation. The discriminators are modified with a sigmoid function for pixel-level multi-label classification, using F1 metric instead of IOU. Adam optimizers with learning rates of 0.01 are employed, along with data augmentation techniques. The experiment uses a FCN baseline model with discriminators for image segmentation. The proposed method involves cropping images, setting specific parameters for inference, and averaging segmentation masks. Comparison of IOU scores with other adversarial learning methods on the Weizmann horses dataset is shown in Table 2. The proposed LDRSP outperforms other state-of-the-art methods on image segmentation, showing a 4.2% improvement in Mean IOU and 4.1% in Global IOU on the Weizmann horses dataset. The LDRSP's discriminators refine the FCN, indicating stronger horse shape priors. Other adversarial learning methods, such as GAN and LSGAN, show decreased performance in comparison. The proposed LDRSP outperforms DVN BID12 in jointly learning energy-based and structured prediction models, improving FCN performance on the Weizmann horses dataset. Qualitative results show enhanced segmentation, especially in thin parts like legs, by utilizing discriminators to refine predictions. The Labeled Faces on the Wild (LFW) dataset is used for 3-class face segmentation, with annotations providing superpixel-level labels for face, hair, and background. Pixel-level labels are mapped to superpixel-level labels, and the network architecture and data augmentation are similar to those used on the Weizmann horses dataset. Various models are evaluated, with the best performing model achieving 95.54% accuracy. The proposed method outperforms the FCN baseline by 1.11% on the LFW dataset, showing significant improvement over the DVN BID12. The qualitative results demonstrate high-quality hair and face segmentation masks close to ground-truth labels. The paper proposes a novel learning framework for refining structured prediction models using discriminative models trained as energy-based models. This method is applied to multi-label classification and image segmentation tasks, showing that discriminative models can effectively refine generative models. Future work will focus on generating extra training samples and applying the method to more challenging tasks."
}