{
    "title": "R44626",
    "content": "The Internet has revolutionized communications, making it easier to reach wide audiences globally. However, it is also used by terrorist groups like ISIS, Al Qaeda, and Hamas to spread their ideology, recruit members, and claim responsibility for attacks. This content can influence individuals to sympathize with or adopt violent beliefs, leading to potential acts of terrorism. Anwar al Awlaki's sermons have been linked to influencing individuals involved in terrorist activities. Anwar al Awlaki, a U.S. citizen targeted and killed by a drone strike, left behind digital videos preaching his interpretation of Islam. Some videos promote controversial messages, such as inciting followers to kill Americans, which reportedly influenced the San Bernardino and Boston Marathon attackers. The Islamic State organization and other extremist groups use popular Internet services like Twitter and YouTube to disseminate propaganda, recruit new members, and claim credit for terrorist attacks. Social media platforms have terms of service prohibiting speech advocating violence and terrorism. Efforts to disable terrorist-related accounts on social media platforms like Twitter have not been entirely successful, as new accounts quickly replace disabled ones. Policymakers, including Members of Congress, are concerned about the influence of terrorist speech on individuals and the ease of radicalization. This raises questions about whether the federal government should restrict or prohibit the distribution of speech advocating terrorist acts. The report discusses the First Amendment issues surrounding government restrictions on speech advocating terrorism on the Internet. It also explores the potential application of the federal ban on providing material support to foreign terrorist organizations to online platforms like Twitter and Facebook. The First Amendment protects freedom of speech, but it is not absolute. Certain types of speech, such as fighting words and incitements to violence, can be restricted by the government. Courts apply strict scrutiny to speech restrictions based on content or viewpoint, requiring them to serve a compelling government interest in the least restrictive way. The government can impose reasonable regulations on speech, with restrictions upheld if they advance a substantial government interest and are narrowly tailored. The First Amendment protects advocacy of lawbreaking and violence, as seen in Brandenburg v. Ohio where a conviction was overturned. The Supreme Court overturned convictions of Ku Klux Klan members for advocating violence at a rally, stating that advocating violence is protected by the First Amendment unless it directly incites imminent lawless action. The Supreme Court ruled that speech inciting violence is protected by the First Amendment unless it directly incites imminent lawless action. The Court invalidated Ohio's criminal syndicalism statute for failing to distinguish between abstract teaching and preparing a group for violent action. For speech advocating violence to be punishable, the speaker must intend to incite imminent violent or lawless action likely to occur. The Supreme Court clarified that speech inciting violence is protected by the First Amendment unless it directly incites imminent lawless action. In Hess v. Indiana, the Court provided guidance on the \"imminence\" of violence advocated in speech, overturning a conviction for disorderly conduct based on advocacy of illegal action. The Supreme Court in Hess v. Indiana overturned a conviction for disorderly conduct, stating that speech inciting violence is protected unless it directly incites imminent lawless action. The Court found that the defendant's statement did not meet the \"imminence\" requirement as it was not directed at any specific person or group and did not indicate imminent disorder. Some argue that the Court's decision in Hess set a strict standard for imminence, but state and federal courts have not always applied this requirement so strictly. Rubin was charged with solicitation of murder after offering money for anyone to harm a member of the American Nazi Party during a protest against a planned march. The state appeals court reversed the trial court's decision, stating that his speech incited lawless action likely to occur imminently, despite the march being scheduled five weeks later. The court justified its decision by emphasizing the relative nature of time and imminence in connection to the event. The imminence of solicitation of murder in connection with a public event, even if scheduled five weeks away, can be considered incitement to imminent lawless action. This standard was previously applied in NAACP v. Claiborne Hardware, where the Supreme Court overturned civil judgments against defendants advocating violence during a boycott for racial equality. The Court clarified that mere advocacy of force or violence in speech does not remove speech protection. The Court clarified that advocacy of force or violence in speech does not remove speech protection under the First Amendment. Evers's speech, which included strong language that could be seen as advocating violence, was deemed protected despite the potential for unlawful conduct. The Court also noted that while speech related to illegal activity has limits, it upheld a statute outlawing offers or requests for child pornography in United States v. Williams. The Court upheld a statute outlawing offers or requests for child pornography, stating that it falls within constitutional bounds as child pornography is not protected by the First Amendment. The statute prohibits attempts to give or receive child pornography, which are categorically excluded from First Amendment protection. The boundaries of the Brandenburg standard regarding permissible restrictions on pure advocacy of violence or lawlessness remain unclear. The Brandenburg standard's boundaries are unclear, especially regarding advocacy of terrorism. In Holder v. Humanitarian Law Project, the Supreme Court upheld the criminal prohibition on providing support to designated foreign terrorist organizations. The plaintiffs in the case sought to provide services to FTOs but were concerned about the law prohibiting such assistance. They argued that the law was unconstitutional when applied to the support they intended to provide for the FTOs' non-terrorism-related activities, such as teaching them how to apply for humanitarian aid and giving legal advice. The Court agreed that the prohibition on material support also restricted speech, burdening the plaintiffs' First Amendment rights. The Court upheld the application of the statute to the speech in question, finding that the material support statute was carefully drawn to cover only speech coordinated with foreign terrorist groups, making it easier for the government to demonstrate the restriction was permissible. The Court upheld the material support statute to combat terrorism, citing Congress's compelling interest in national security. Providing support to foreign terrorist organizations, even unintentionally, can aid terrorist activities and strain diplomatic relationships. The Court upheld the material support statute to combat terrorism, citing the government's interest in national security. Official cooperation with non-governmental entities can legitimize terrorist groups, undermining efforts to combat them. Prohibiting material support to FTOs directly advances the government's compelling interest in fighting terrorism. The statute is narrowly tailored to apply only to support coordinated with FTOs. The Court's decision is specific to the case at hand. The Court upheld the material support statute to combat terrorism, emphasizing the government's interest in national security. It stated that the statute applied only to the factual situation before the Court and did not address the constitutionality of more complex cases. Congress's careful crafting of the law to avoid burdening constitutional rights was highlighted, with an emphasis on the significant weight given to Congress's views on national security matters. Some argue for restrictions on terrorism advocacy online under the First Amendment. Advocates argue for restrictions on terrorism advocacy online under the First Amendment, citing concerns about self-radicalization and terrorist groups using social media for propaganda. The Brandenburg precedent suggests that laws criminalizing pure advocacy of terrorism may be deemed unconstitutional. Speech advocating the moral propriety of terrorist acts is likely protected by the First Amendment. Laws restricting independent advocacy of terrorist action online may be unconstitutional under the First Amendment, as per the Brandenburg precedent. The Supreme Court's opinion in Humanitarian Law Project also supports this argument by emphasizing the need for tailored restrictions that do not apply to pure advocacy of terrorism. Some argue that advocating terrorist acts should be banned like child pornography, but this comparison may not be valid. While technology can filter both, the constitutional justification for restricting child pornography does not necessarily apply to terrorism advocacy. The Supreme Court ruled that possession and distribution of child pornography can be prohibited due to the harm it causes to children. However, restrictions do not apply to virtual child pornography as it does not involve actual children. The government's attempt to justify similar restrictions on virtual depictions was unsuccessful. The Supreme Court ruled that restrictions on virtual child pornography cannot be justified by the government, as it does not involve actual children. Similarly, the creation of speech advocating terrorism does not always inherently harm someone, unlike the creation of actual child pornography. Advocacy of terrorism, like virtual child pornography, may create a risk of future crimes, but the government cannot prohibit speech based solely on this risk. Some argue that terrorist advocacy on the Internet should be more easily restricted due to the potential danger it poses in reaching individuals who may act on the messages. The Supreme Court recognizes the unique challenges of different mediums of expression, allowing for more regulation of broadcasted speech. The Supreme Court has not yet addressed whether advocating violence on the Internet should be treated differently than other mediums. In Reno v. American Civil Liberties Union, the Court ruled that content-based restrictions on Internet speech should be subject to strict scrutiny, rejecting the idea that the Internet justifies greater government control over speech. The Supreme Court accorded the highest degree of protection to speech on the Internet, stating that the interest in freedom of expression outweighs any theoretical benefit of censorship. The Court explained that the risk of children being exposed to indecent speech on the Internet was far lower than on broadcasted speech, therefore justifying the general rules regarding content-based restrictions on speech. Under current law, federal statutes criminalize material support for terrorism or foreign terrorist organizations, potentially covering non-tangible forms of support for terrorist activities. The material support statutes have been the most often prosecuted anti-terrorism offenses. Section 2339A of Title 18 of the United States Code prohibits the advocacy of terrorism. Section 2339A and 2339B of Title 18 of the United States Code prohibit the provision of material support for terrorist activities and foreign terrorist organizations. The Supreme Court has ruled that providing material support, including certain types of speech, to these organizations can be punished even if the support is for purposes other than advancing terrorist activities. The material support statutes in Title 18 of the United States Code prohibit providing resources for terrorist activities, including training and expert advice. This support can be punished even if it is not directly related to advancing terrorist activities. The material support statutes in Title 18 of the United States Code prohibit providing resources for terrorist activities, including training and expert advice derived from specialized knowledge. Unlike the material support statute in Humanitarian Law Project, Section 2339A requires that support be given with the knowledge or intention that it will facilitate a terrorist crime. The provision of speech in the form of expert advice or assistance with the intent to support terrorism can be constitutionally punished, even if it involves speech. The Supreme Court has ruled that the Constitution does not necessarily prevent punishment for agreements to violate the law. Section 2339B of Title 18 of the United States Code prohibits providing material support to designated terrorist organizations, raising constitutional questions when applied to speech. The statute outlaws attempting, conspiring, or actually providing material support to a foreign terrorist organization with knowledge of its designation or terrorist activities. Section 2339B of Title 18 prohibits providing material support to designated terrorist organizations, including property, services, training, and advice. Advocacy can be considered material support if it is connected to a terrorist organization. Knowledge of the organization's terrorist activities is enough to violate the statute. The primary question regarding the \"material support\" proscribed by Section 2339B is whether speech constitutes advocacy \"directed to, coordinated with or controlled by\" a foreign terrorist organization. The statute prohibits providing a service \"to a foreign terrorist organization,\" indicating a connection between the service and the group. The distinction between independently advocating for a cause and providing a service to a group advocating for that cause is crucial. The Court left open questions on the level of direction or coordination needed for an activity to be considered a 'service' to a foreign terrorist organization. A 2013 case involving Tarek Mehanna showed a broad interpretation of directing speech or acting under the direction of a designated FTO. Mehanna was convicted of supporting Al Qaeda by translating their propaganda and attempting to join them in Yemen. Tarek Mehanna translated Al Qaeda propaganda into English and posted it on a sympathetic website. He argued that his translations were protected by the First Amendment, but the First Circuit upheld his convictions, stating that individuals acting independently to advance an FTO's goals are not considered to be working under the FTO's direction. The appeals court stated that a direct connection between a defendant and a Foreign Terrorist Organization (FTO) is not required for a violation to occur. While Mehanna's translational activities were not explicitly deemed sufficient for his conviction, evidence of his attempt to join Al Qaeda in Yemen supported his convictions. The case does not provide clear answers on when speech activity benefiting an FTO is considered material support. The possibility that social media sites providing accounts to Foreign Terrorist Organizations (FTOs) could constitute material support in violation of Section 2339B has been suggested. Some FTOs have obtained social media accounts from companies, raising questions about where the line is drawn between independent advocacy of terrorism and support for FTOs. The acquisition of social media accounts by terrorist groups like the Islamic State on platforms like Twitter has raised concerns about whether providing such accounts constitutes material support. Despite the presence of terrorist groups on social media, the Department of Justice has not taken legal action against social media companies for this issue. The application of Section 2339B to social media companies remains unclear, with questions about their knowledge and liability in supporting FTOs through their services. The level of coordination necessary for a social media site to be considered providing a service to a Foreign Terrorist Organization (FTO) remains unclear. Websites do not conduct background checks on users, making it difficult to verify affiliations with FTOs. The burden of performing background checks on every user may be too high for social media companies. Providing an account to a user affiliated with an FTO may not be sufficient to constitute support under the statute. The level of coordination required for a social media site to be considered providing a service to a Foreign Terrorist Organization (FTO) is unclear. Social media sites have policies to remove terrorist content, but the government could argue that failure to suspend accounts associated with FTOs shows coordination. It is uncertain if the ability of terrorist groups to use social media accounts establishes enough connection for liability under Section 2339B. The government must prove material support for an FTO to hold a social media company liable. Social media companies like Facebook and Twitter may argue that they lack sufficient knowledge of a new user's affiliation with a Foreign Terrorist Organization (FTO) upon account activation. While they disable accounts that violate their terms of service, they may not be able to determine with certainty if users are terrorist affiliates beforehand. Despite being aware that some subscribers use their services for terrorist advocacy, social media sites do not actively seek out FTO connections. Social media sites like Twitter and Facebook disable accounts promoting terrorism. They have increased efforts to remove such content. However, they may not always be certain if an account belongs to a terrorist organization. Courts have ruled that social media websites can be held liable for providing material support to terrorist groups under Section 2339B of Title 18 of the United States Code. Lawsuits have been filed against platforms like Twitter, alleging that their dissemination of propaganda by terrorist organizations led to terrorist attacks. The death of three government contractors in Jordan and a lawsuit accusing Twitter, Google, and Facebook of providing material support to ISIS. Private civil lawsuits may face hurdles in holding social media companies accountable for allowing terrorist organizations to use their platforms due to Section 230(c) of the Communications Decency Act. The U.S. Court of Appeals for the First Circuit recently ruled that Section 230 of the Communications Decency Act may shield social media service providers from civil liability, even in cases involving violations of federal criminal law. This shield protects providers from being treated as publishers of content provided by third parties. Section 230 of the Communications Decency Act provides immunity from civil liability to interactive computer service providers and users for content provided by third parties. The liability shield applies if the lawsuit is brought against a provider or user based on information from another content provider and seeks to hold them liable as a publisher or speaker of that content. The court ruled in Fields v. Twitter that Section 230's liability shield does not apply if a computer service provider contributes to the development of illegal content. The plaintiffs alleged that Twitter knowingly allowed the Islamic State to use its platform for propaganda, fundraising, and recruitment, leading to their injuries. However, they did not specifically claim that Twitter was used to plan the terrorist attack that caused their harm. The plaintiffs in Fields v. Twitter alleged that Twitter allowed the Islamic State to use its platform for propaganda, fundraising, and recruitment, leading to their injuries. The court dismissed the lawsuit based on Section 230 of the CDA shielding Twitter from liability, as the lawsuit did not target Twitter as a publisher. The plaintiffs alleged that Twitter provided services to the Islamic State organization, specifically through Twitter accounts and Direct Messaging services. The district court rejected these arguments, stating that Section 230's liability shield includes decisions related to third-party content on a site. The district court viewed Twitter's decisions on allowing access to its platform as publishing decisions, whether it involved offensive content or granting permission to specific individuals. Twitter's choices in structuring its platform, including allowing ISIS to sign up for accounts, were seen as quintessential publishing decisions by the court. The court considered Twitter's decisions on platform access as publishing decisions, with Section 230's liability shield applying. The court determined that content does not need to be publicly available to be considered published under Section 230. The court's decision in Fields v. Twitter suggests that Section 230's liability shield also applies to content communicated through Twitter's Direct Messaging service. This could set a precedent for similar cases involving social media platforms like Facebook and Google, providing a barrier to attempts to curb terrorism advocacy online through civil litigation."
}