{
    "title": "Hkbd5xZRb",
    "content": "Convolutional Neural Networks (CNNs) are commonly used for 2D planar images, but there is a growing need for models that can analyze spherical images. This is important for applications such as omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modeling. Simply applying CNNs to a planar projection of spherical signals will not work due to space-varying distortions that make translational weight sharing ineffective. In this paper, the building blocks for constructing spherical CNNs are introduced. A definition for spherical cross-correlation is proposed, which is rotation-equivariant and computationally efficient. Spherical CNNs are shown to be effective for 3D model recognition and atomization energy regression. Unlike planar CNNs, spherical CNNs can detect local patterns through 3D rotations instead of translations. The text introduces the concept of spherical CNNs, which can detect patterns through 3D rotations instead of translations. It discusses the need to change the definition of crosscorrelation to account for rotations on the sphere, represented by the three-dimensional manifold SO(3). The output feature map is considered a signal on SO(3), not on the sphere S2. Deploying SO(3) group correlation in higher layers is crucial for spherical CNNs. The implementation of a spherical CNN (S2-CNN) faces challenges due to the lack of perfectly symmetrical grids for the sphere and the computational inefficiency of SO(3) correlation. Techniques from non-commutative harmonic analysis are used to address these issues, providing a generalization of the Fourier transform applicable to signals on the sphere and the rotation group. The S2 and SO(3) correlation can be efficiently implemented using generalized FFT algorithms in a spherical CNN. The mathematical properties predicted by the continuous theory are rigorously evaluated in practice for the discretized implementation. Spherical CNNs are shown to be superior for rotation invariant classification and regression tasks through experiments on various datasets. The main contributions of this work include the theory of spherical CNNs, the first automatically differentiable implementation of the generalized Fourier transform for S2 and SO(3), and empirical support for the utility of spherical CNNs for rotation-invariant learning problems. Our work introduces SO(2)-steerable networks that achieve equivariance to a continuous, non-commutative group (SO(3)) and utilize generalized Fourier transform for fast group correlation. Generalized FFT algorithms are used for efficient cross-correlations on the sphere and rotation group. The text covers generalized FFT algorithms and important works related to SO(2)-steerable networks achieving equivariance to SO(3). It explains the correlation in S2 and SO(3) using analogies to planar Z2 correlation, discussing the computation of output feature maps through inner products with filters. The output feature map is modeled as a function on SO(3), with further concepts to be defined mathematically. The Unit Sphere S2 is defined as the set of points x \u2208 R3 with norm 1, parameterized by spherical coordinates \u03b1 \u2208 [0, 2\u03c0] and \u03b2 \u2208 [0, \u03c0]. Spherical images and filters are modeled as continuous functions f : S2 \u2192 RK. Rotations in three dimensions are represented by matrices in the special orthogonal group SO(3), preserving distance and orientation. Rotation can be performed on 3D unit vectors x using matrix-vector product Rx. The rotation group SO(3) is a three-dimensional manifold parameterized by... The rotation group SO(3) is a three-dimensional manifold parameterized by ZYZ-Euler angles \u03b1, \u03b2, and \u03b3. The rotation operator L R rotates functions on the sphere. The inner product on spherical signals is defined using a rotation invariant integration measure. This measure ensures that the volume under a spherical heightmap remains unchanged when rotated. The rotation group SO(3) is a three-dimensional manifold parameterized by ZYZ-Euler angles \u03b1, \u03b2, and \u03b3. The rotation operator L R rotates functions on the sphere. The inner product on spherical signals is defined using a rotation invariant integration measure. A spherical heightmap does not change when rotated. The correlation of spherical signals f and \u03c8 is defined mathematically as a function on SO(3), allowing for greater expressive capacity in the network. The rotation operator can act on signals defined on SO(3) by reusing eq. 1. The correlation of signals on the rotation group is defined using an invariant measure on SO(3). The justification for using the rotation operator in the network's layers is provided. The justification for using the rotation operator in network layers is based on equivariance, a property shared by convolution and correlation. Correlations and convolutions can be efficiently computed using the Fast Fourier Transform (FFT) due to the Fourier theorem. Implementing correlation using FFTs is faster than spatial implementation, especially for functions on the sphere and rotation group. This is facilitated by the generalized Fourier transform (GFT) and corresponding fast algorithm (GFFT). The GFT is a linear projection of a function onto orthogonal basis functions, with roots in group representation theory. It can be efficiently computed using a GFFT algorithm. S2 is a quotient of groups SO(3)/SO(2), and the GFT is related to this. The integral can be computed efficiently using a GFFT algorithm. The inverse SO(3) Fourier transform is defined, and the maximum frequency b is known as the bandwidth. The signal f and the locally-supported filter \u03c8 are Fourier transformed, block-wise tensored, summed over input channels, and finally inverse transformed. The sphere is parameterized using spherical coordinates \u03b1, \u03b2, and SO(3) with ZYZ-Euler angles \u03b1, \u03b2, \u03b3. The implementation of GFFTs is sketched here. The SO(3) FFT involves performing a 2D translational FFT over the \u03b1 and \u03b3 axes, followed by a linear contraction with a precomputed array. The output consists of Fourier coefficients for specific ranges of l, m, and n. The S2-FFTs are similar but involve FFT over the \u03b1 axis and a linear contraction with Legendre functions over the \u03b2 axis. The code for these operations is available on GitHub. In a series of experiments, the algorithm's stability and accuracy were evaluated. New cross-correlation layers were introduced for a group equivariant CNN on a continuous, non-commutative group. Testing was done to assess equivariance at various resolutions, questioning the impact of discretization artifacts on network properties. In testing the equivariance of the SO(3) correlation at different resolutions, n random rotations and feature maps were sampled. The results show manageable approximation errors with increasing resolution and layers. Repeating the experiment with ReLU activation function reveals higher but stable errors, attributed to feature map rotation accuracy. Generalization performance with input rotations was evaluated using a version of MNIST. For testing, a version of the MNIST dataset is projected on the sphere. Two instances are created: one with digits on the northern hemisphere and one with randomly rotated digits. A baseline CNN model is compared to a spherical CNN model. Results show the spherical CNN performs better with rotations in the test set. The S2 CNN model performs well on the rotated MNIST dataset, while the NR/NR regime shows worse performance. The model is then applied to 3D shape classification using the SHREC17 task BID31 dataset, focusing on randomly perturbed models to test rotation equivariant representations. The 3D meshes are projected onto a sphere for analysis. For 3D shape classification, a network is used with ray casting information for the convex hull of the model. The network architecture includes S2 conv-BN-ReLU blocks and SO(3)conv-BN-ReLU blocks, followed by max pooling over the group SO(3) for final classification. The network architecture for 3D shape classification includes S2 and SO(3) conv-BN-ReLU blocks with max pooling over the group SO(3) for final classification. The final network has 1.4M parameters, uses 50, 70, and 350 features for different layers, and takes 50 hours to train. The model ranks third in precision and F1@N but is the runner up in other metrics compared to top competitors. The models Tatsuma_ReVGG and Furuya_DLAN are specialized for the SHREC17 task, while our model shows strong support for Spherical CNNs. Additionally, S2 CNN is applied to molecular energy regression, specifically in predicting atomization energy using a rotation and translation invariant representation of molecules. BID30 proposes a distance measure for Coulomb matrices in Gaussian kernels, while Montavon et al. suggest sorting or random sampling index permutations. Utilizing spherical symmetries, a spherical signal is defined around each atom in the molecule, producing a T channel spherical signal that is invariant to translations and equivariant to rotations. The signal in the molecule is discretized using a Driscoll-Healy BID10 grid with bandwidth b = 10, represented as a sparse N \u00d7 T \u00d7 2b \u00d7 2b tensor. A deep ResNet style S 2 CNN is used, with ResNet blocks consisting of S 2 /SO(3)conv-BN-ReLU-SO(3)conv-BN layers. We achieve permutation invariance by sharing weights among atoms and embedding resulting feature vectors into a latent space using MLPs \u03c6 and summing them over the atom dimension to get the final regression value with another MLP \u03c8. The final architecture for the molecule involves training a S2 CNN on the residual, resulting in improved convergence speed and stability. The model has 1.4M parameters, requires 7GB of memory, and takes 3 hours to train. Evaluation shows that the learned representation outperforms kernel-based approaches and a MLP trained on sorted Coulomb matrices. However, the method of training on randomly permuted Coulomb matrices may not scale well to large molecules due to the exponential growth in permutations with size. In this paper, the theory of Spherical CNNs is presented and evaluated on important learning problems. Spherical CNNs can generalize across rotations and achieve near state-of-the-art results on 3D Model Recognition and Molecular Energy Regression challenges. Further improvements can be made by generalizing to the roto-translation group SE(3). The development of Spherical CNNs is a crucial step in this direction. The development of a Steerable CNN for the sphere allows analysis of vector fields like global wind directions and other vector bundles. The future application of Spherical CNNs in omnidirectional vision is promising due to the increasing use of omnidirectional sensors in drones, robots, and autonomous cars. The ZYZ Euler parameterization for SO(3) is used, with R \u2208 SO(3) written as DISPLAYFORM0 where \u03b1 \u2208 [0, 2\u03c0], \u03b2 \u2208 [0, \u03c0], and \u03b3 \u2208 [0, 2\u03c0]. The normalized Haar measure is DISPLAYFORM1 with SO(3) dR = 1. The Haar measure for the sphere and SO(2) allows for useful substitutions and parameterizations. The sphere is represented as a quotient S2 = SO(3)/SO(2), where rotations around the Z axis form the subgroup H = SO(2). The normalized Haar measure for the sphere is dx dh, reflecting the invariance property of SO(3). The normalized Haar measure for SO(2) is dx dh, reflecting the quotient structure. A function on S2 can be seen as a \u03b3-invariant function on SO(3). The Fourier transform on S2 can be defined from the Fourier transform on SO(3) using normalized Haar measures. The S2 correlation is defined without loss of generality for the single-channel case K = 1. The spherical convolution defined by BID10 is where n is the north pole. The output of the spherical convolution is a function on the sphere. The spherical convolution involves an integral over SO(3) and integrates over \u03b3 in only one factor, making it invariant wrt \u03b3 rotation. This definition implicitly averages the filter before combining it with f, which is considered too limited for pattern matching in spherical CNNs. Each compact topological group is associated with a discrete set of orthogonal functions arising from irreducible unitary representations of these groups. The Wigner D-functions are matrix-valued functions parameterized by degree l and order parameters m, n in the group SO(3). The Fourier transform of a right invariant function on SO(3) equals the S 2 Fourier transform of a function on S 2. This relationship has not been previously referenced but is likely observed before."
}