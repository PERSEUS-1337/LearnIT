{
    "title": "r1lrAiA5Ym",
    "content": "The brain's lifelong learning is facilitated by synaptic plasticity controlled by neuromodulation, enhancing self-modifying abilities crucial for learning and adaptation. Artificial neural networks with neuromodulated plasticity can be trained using gradient descent, improving performance on reinforcement and supervised learning tasks. Neuromodulated plastic LSTMs outperform standard LSTMs on language modeling tasks. Differentiable neuromodulation of plasticity enhances neural network training, allowing for better performance on language modeling tasks compared to standard LSTMs. Plasticity, based on synaptic modification, is crucial for long-term learning and memory in the brain, enabling the storage of information about the environment. The brain actively modulates its own connectivity through neuromodulation of plasticity, involving chemicals like dopamine, to filter out irrelevant events and incorporate important information for learning and adaptation. This process helps prevent catastrophic forgetting and implements a self-contained reinforcement learning algorithm. The brain's neuromodulated plasticity is a result of evolutionary optimization, enabling efficient lifelong learning through self-modifying abilities. This coupling of evolution and plasticity is a meta-learning process, inspired by nature's optimization for producing efficient learning agents. The text discusses the potential of making neuromodulated networks compatible with gradient descent to enhance deep learning architectures with self-modifying abilities. It builds on the differentiable plasticity framework to implement differentiable neuromodulated plasticity. The text introduces the backpropamine framework, which enables training neuromodulated plastic networks with gradient descent. Experimental results show that these networks outperform non-plastic and non-modulated networks on various tasks, indicating potential for more powerful neural networks in different domains. Neuromodulated plasticity in evolved networks helps mitigate catastrophic forgetting by activating plasticity only in relevant neural weights for the current task, preserving knowledge in other weights. The differentiable plasticity framework allows optimization of individual synaptic connections for improved performance. The differentiable neuromodulated plasticity framework extends the ability of networks to modulate synaptic connections moment-to-moment, allowing for true self-modifying abilities. This approach contrasts with passive plasticity methods and offers the network the autonomy to decide when and where to be plastic. Other complex methods exist for training self-modifying networks, such as using neural networks to compute weight modifications. The present work extends the differentiable plasticity framework by optimizing neuromodulation of plasticity within a single network through gradient descent. Each connection in the network contains a fixed and plastic component that automatically adjusts based on ongoing activity. The plasticity coefficient \u03b1 i,j scales the plastic component between neurons i and j, represented by the Hebbian trace Hebb i,j. Hebb i,j is episodic and updated within episodes, while w i,j, \u03b1 i,j, and \u03b7 are structural components optimized between episodes to minimize loss. The function Clip(x) constrains Hebb i,j to [-1, 1] range for stability in Hebbian learning. In this paper, a simple hard clip operation is used for normalization, showing equal or superior performance compared to previous methods. The parameters \u03b7 and \u03b1 i,j control the learning rate and magnitude of plastic connections, allowing for trainable plasticity in each connection. This approach differs from others by enabling the meta-optimizer to design complex learning strategies. Differentiable plasticity allows for easy implementation of plastic recurrent networks with minimal additional code. Two methods are proposed to introduce neuromodulated plasticity within this framework, modulating plasticity based on a network-controlled neuromodulatory signal. The introduction of neuromodulation in differentiable plasticity allows for network-controlled plastic changes, with the neuromodulatory signal influencing the rate of plasticity. This modification enables the network to determine the plastic connections at any given time. Incorporating an alternative neuromodulation scheme inspired by dopamine's retroactive effects on Hebbian plasticity in animal brains. Dopamine gates plasticity induced by past activity within a short time window, creating eligibility traces that modulate actual plastic changes in synapses. The dopamine signal modulates the transformation of eligibility traces into plastic changes in synapses. This refined model of dopamine effects on plasticity involves exponential averages of Hebbian products and gated accumulation of traces based on dopamine levels. The first test task involves a meta-learning problem simulating an animal behavioral learning task. The agent is shown two cues in succession, then a Response cue where it must respond 1 if the Target cue was part of the pair, or 0 otherwise. Rewards are given for correct responses. The cues are binary vectors of 20 bits, and zero-input time steps are randomly inserted to prevent time-locked strategies. The architecture used for the meta-learning problem involves a simple recurrent network with 200 neurons in the hidden recurrent layer. The plasticity is only in the recurrent layer, with non-plastic input and output weights. There are 24 inputs, including cues, time elapsed, previous response, and reward, with four outputs for response and predicting future rewards. The architecture for meta-learning involves a simple recurrent network with 200 neurons in the hidden layer. The network predicts future rewards and uses a neuromodulatory signal for learning. Training curves show successful learning with neuromodulatory approaches, while non-neuromodulatory networks and non-plastic networks fail. The high dimensionality of input cues may explain the difference in performance. Neuromodulation enhances memorization of reward associations with high-dimensional stimuli and reacts to rewards in a time-dependent manner. The approach was tested on a grid maze exploration task, showing successful performance in navigating the maze. The maze has a fixed shape and one random reward location per episode. The agent must accumulate rewards within 200 time steps. The reward is invisible, and the agent detects it through reward input activation or teleportation. The architecture has 100 recurrent neurons and 4 action channels. The agent's inputs include a binary vector describing the maze layout, previous action taken, and previous reward received. The maze navigation task involves exploring a maze to accumulate rewards within 200 time steps. The architecture consists of 100 recurrent neurons and 4 action channels. The experiment aims to study the benefits of adding plasticity and neuromodulation to LSTMs for word-level language modeling using the Penn Tree Bank corpus as a benchmark. The dataset includes 929k training words, 73k validation words, and 82k test words with a vocabulary of 10k words. Neuromodulated plasticity is implemented in recurrent weights for improved performance. The experiment implemented neuromodulated plasticity in two models: a basic model with 4.8 million parameters and a larger model with 24.2 million parameters. The basic model consisted of an embedding layer and two LSTM layers, while the larger model showcased the results of neuromodulation on a complex model with state-of-the-art performance. The experiment involved implementing neuromodulated plasticity in two models: a basic model with 4.8 million parameters and a larger model with 24.2 million parameters. The final layer is a softmax layer of size 10k, with the network unrolled for 20 time steps during backpropagation through time. An extra L2 penalty is added to the weights of the network, and recurrent dropout is not implemented. The Baseline LSTM model and LSTM with Differentiable Plasticity are evaluated in four versions of the smaller model. In LSTM nodes, plasticity is added to one of the recurrent connections, with each plastic connection having its own individual \u03b7 for tuning. Three variations are explored: LSTM with Simple Neuromodulation, LSTM with Retroactive Neuromodulation, and LSTM with Differentiable Plasticity. Each model is described in detail in the Appendix. The study explores different plastic LSTMs models with varying hyperparameters. Results show that adding differentiable plasticity to LSTM improves results significantly compared to the Baseline LSTM. Additionally, adding neuromodulation further reduces perplexity. Retroactive neuromodulation provides a 1.7 perplexity improvement over the Baseline LSTM. The study compares different plastic LSTM models with varying hyperparameters. The improvement in results with neuromodulation is not statistically significant at p = 0.066. The larger model includes neuromodulated plastic connections, while the baseline model does not have plasticity and modulation. Plasticity coefficients are attributed per neuron to limit the total number of parameters. The paper introduces a biologically-inspired method for training networks to self-modify their weights using neuromodulated plasticity. This allows networks to control their own weight changes and be trained with gradient descent, leading to improved performance in large-scale self-modifying neural networks. Our study shows that plastic and neuromodulated LSTMs outperform standard LSTMs in language modeling tasks, which could have significant implications due to the widespread use of LSTMs in real-world applications. We plan to further investigate the impact of plasticity and neuromodulation on LSTM performance in other common applications like forecasting. Comparing our approach to the \"Learning to Reinforcement Learn\" framework, where weights remain constant during episodes, provides valuable insights. The framework described in BID40 involves the slow sculpting of the prefrontal cortex by the reward-based dopamine system. It adds flexibility by allowing the system to store state information with weight changes. The network can update its own connectivity, potentially extending the model to determine its own weight-modification scheme based on various signals. The emergent weight-modifying algorithm, designed by the \"outer loop\" meta-training algorithm, sculpts network connectivity to implement meta-learning. This additional level of learning, known as meta-meta-learning, has evolved in humans and other animals, potentially key to advanced mental functions. The framework allows for the study of this process, replacing evolution with gradient-based methods in the optimization loop. The framework described above aims to enhance the potential of the approach by implementing multiple neuromodulatory signals, introducing more complex tasks, and addressing pitfalls in reinforcement learning with reward-modulated Hebbian plasticity. This would facilitate the automatic design of efficient reinforcement learning systems. The framework for neuromodulated plastic networks introduces plasticity in LSTM control paths and individual plastic connections with learned coefficients. This approach aims to enhance reinforcement learning systems by allowing the meta-training algorithm to design the system's architecture. The plasticity coefficients (\u03b1 i,j ) are used in backpropagation for neuromodulated LSTMs. Each LSTM layer has a dedicated neuromodulatory neuron, with variations including one neuron per node or one for the whole network. Four models in TAB0 are trained using SGD with an initial learning rate of 1.0 for 13 epochs. The hidden states of LSTM are initialized to zero. The Backpropamine framework was applied to a larger model with three stacked LSTMs. The model uses various optimization and regularization techniques, including variational dropout and a variable horizon for backpropagation through time. The optimizer switches from SGD to Averaged-SGD after 45 epochs. The model switches from SGD to Averaged-SGD after 45 epochs, implementing neuromodulation and plasticity coefficients per neuron. This reduces trainable parameters and simplifies the model. The model implements neuromodulation with a single neuromodulator neuron and different \u03b7 i values for each neuron, reducing the total number of trainable parameters. The model implements neuromodulation with a single neuromodulator neuron and different \u03b7 i values for each neuron, reducing the total number of trainable parameters to 24 198 893. The behavior of the neuromodulator neuron is illustrated by plotting its output for random trials from well-trained networks in Task 1, showing rich and complex dynamics varying between runs. The neuromodulator neuron reacts to reward in complex, time-dependent ways, with varying dynamics between runs. Different patterns of neuromodulation are observed, including negative modulation following reward perception. Understanding these dynamics is crucial for efficient within-episode learning. Neuromodulated plasticity successfully learns cue-reward associations in the task described. In a previous experiment, a simplified version of the association learning task was conducted using fixed 4-bit binary cues. Non-modulated plasticity was able to learn the task, albeit slower than neuromodulated plasticity. This suggests that neuromodulated plasticity may have a stronger advantage in learning tasks with arbitrary cues. Neuromodulated plasticity may have a stronger advantage in learning tasks with arbitrary high-dimensional cues, as shown in previous experiments. Further research is needed to determine which problems benefit most from this type of plasticity. The curr_chunk shows training curves for a cue-reward association task with fixed, binary four-bit cues. The curves display the diversity of dynamics, with success achieved by non-modulated plastic networks. The modulator output values are indicated by blue curves at different time steps."
}