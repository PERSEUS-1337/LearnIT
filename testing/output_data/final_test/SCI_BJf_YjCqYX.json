{
    "title": "BJf_YjCqYX",
    "content": "Machine learned models exhibit bias due to biased training datasets, posing challenges for technology deployment. A framework using high-fidelity simulations and Bayesian parameter search can efficiently identify biases in ML classifiers. This approach was applied to face detection, revealing demographic biases in commercial face APIs. Machine learned models, like deep neural networks, may have unknown biases that need to be identified. Biases can arise from limited training data or reflect human biases. Researchers struggle to collect diverse datasets to address these biases efficiently. Facial analysis in computer vision systems can exhibit systematic biases, with error rates significantly higher for women and certain demographics. This poses challenges when deploying these algorithms in real-world scenarios. Facial analysis in computer vision systems can exhibit biases, with higher error rates for women and certain demographics. This can lead to increased false positives or false negatives, impacting tasks like face detection. Training data may not be evenly distributed across demographic groups, resulting in less accurate performance for certain groups. Facial analysis in computer vision systems can exhibit biases, with higher error rates for women and certain demographics. A longitudinal study of police departments found that African-American individuals were more likely to be subject to face recognition searches. Even with balanced datasets, characteristics like lighting and pose can still lead to flawed results. The concept of fairness through awareness suggests being aware of biases to combat them. This has inspired proposals for standards to characterize training datasets. Standards for characterizing training datasets to inform consumers of their properties are valuable, but transparency alone cannot address biases caused by poor representation. Improving facial attribute detection by including gender and racial diversity has shown some success, but data collection and cleaning remain time-consuming tasks. To address bias in real-world datasets, high-fidelity simulations like generative adversarial networks (GANs) can be used to generate diverse training examples and test different parameter combinations systematically. GANs are popular for synthesizing data, such as creating images of faces at different ages, but may still contain biases present in the training data. The text discusses the use of parameterized graphics models as an alternative for training and testing vision models, specifically for detecting demographic biases. It presents a simulated model for generating synthetic facial data to identify limitations in face detection algorithms and proposes a sample efficient approach to reduce the number of simulations needed. The paper introduces a sample efficient approach to reduce simulations needed for predictive models. It addresses concerns about discrimination in machine learning algorithms and discusses known unknowns and unknown unknowns in model performance. Lakkaraju et al. BID23 proposed a method to discover unknowns in predictive models by partitioning the search-space and using an explore-exploit strategy. In the context of reducing simulations for predictive models and addressing discrimination in machine learning algorithms, an explore-exploit strategy is utilized to navigate through groups systematically. While biases in automated systems have been identified in various domains, further research is needed to address bias in machine learned systems. Numerous papers have highlighted biases within data typically used for machine learning and machine learned classifiers. Biases in datasets used for machine learning and machine learned classifiers can be caused by selection bias, capture bias, and negative set bias. Selection bias involves certain types of images being included in datasets, capture bias is influenced by how data is acquired, and negative set bias affects the representation of the \"rest of the world\" in the dataset. These biases can lead to skewed representations and impact the performance of the model. The model may learn a distorted representation due to biases in data collected from the internet and crowdsourcing. Human bias, selection bias, capture bias, and negative set bias can all contribute to skewed datasets, impacting the performance of machine learning classifiers. Powerful feature descriptors like deep convolutional neural networks may worsen bias issues. In the context of biased data affecting machine learning classifiers, using high-fidelity simulations can efficiently diagnose biases in machine vision classifiers. Early face detection algorithms relied on hand-crafted features like Haar features, local binary patterns, and histograms of gradients, with the Viola-Jones BID39 classifier being a significant landmark in this field. The Viola-Jones BID39 classifier, based on Haar features, was a significant advancement in face detection algorithms. Deep convolutional neural networks have since surpassed previous methods and are now widely used for face detection and attribute classification. Companies are deploying face detection technology in various real-world applications, including safety critical contexts. APIs and SDKs are used to expose these models to businesses and consumers. Identifying biases in these models, which all use convolutional neural networks, can be challenging. The approach presented for bias identification is algorithm independent. The approach presented for identifying biases in face detection models is algorithm independent and particularly suited for models trained on large datasets. Biases in face detection can lead to biased datasets, as seen in the Labeled Faces in the Wild dataset. A simulation-based approach using an artificial human could help characterize biases and allow researchers to account for them in their datasets. The approach presented involves synthesizing examples to break machine learned classifiers and diagnose biases. Computer graphics are used to create realistic inputs for testing face detection algorithms, allowing for exploration of various parameter combinations quickly and systematically. In this work, Bayesian Optimization BID4 is proposed for efficiently searching parameter combinations in simulations. Parameters spawn simulation instances fed into a machine intelligence system to check for correct identification. A composite function Loss(s(\u03b8)) evaluates how well the AI system handles the simulation instance. Bayesian Optimization models the composite function Loss(s(\u03b8)) as a Gaussian Process to efficiently explore parameter space and identify optimal spots that meet search criteria. The function evaluates how well the AI system handles simulation instances, aiming to find diverse instances of \u03b8 with composite loss values above a set threshold. In this work, the parameter space is explored to identify spots that meet the search criterion using a Gaussian Process with a Radial Basis Function kernel and Expected Improvement as an acquisition function. An agent torso is created in the AirSim environment with customizable skin type, aging, facial position, and actions. The goal is to illustrate the customization possibilities. The study focused on using simulated data to identify biases in classifiers for face detection algorithms. Parameters like facial expressions and lighting were manipulated to evaluate algorithm success. Four facial analysis APIs from Microsoft, Google, IBM, and Face++ were compared in the experiments. The APIs for facial analysis accept HTTP POST requests with image URLs or binary data. They use deep convolutional neural network architectures and are trained on millions of images. The models can detect faces ranging from 36 \u00d7 36 to 4096 \u00d7 4096 pixels, with up to 64 faces per image. Google's documentation lacks minimum size or resolution requirements, while IBM specifies a minimum pixel density of 32 \u00d7 32 pixels per inch and a maximum image size of 10 MB. The response to Buolamwini and Gebru's article further characterizes the performance of the face detection algorithm. The algorithm can detect faces ranging from 48 \u00d7 48 to 4096 \u00d7 4096 pixels, with specific requirements for face size. The distribution of simulation parameters shows differences in skin types and ages between false negatives and true positives. Bayesian optimization reveals these differences with fewer simulations compared to random sampling. The skin tone ranges from light (0) to dark (1) and age ranges from young (0) to old (1). Two approaches were used to search the space of simulated faces. The study compared random sampling and Bayesian optimization for searching simulated faces to identify face detection failures. Demographic parameters like skin type and age were analyzed for different face detection APIs. Results showed differences in performance for Microsoft, Face++, Google, and IBM classifiers. The cumulative number of failure cases identified with increasing simulations was also shown. The study compared random sampling and Bayesian optimization for identifying face detection failures in simulated faces. Results showed that Bayesian optimization was more efficient, with 44% more failures found after 800 samples. Face detectors performed worse on darker skin types and older faces, with IBM showing the least extreme skew. The study found that improving detectors following biases identified in previous versions significantly reduced biases in resulting models. Results support prior work and suggest the need for diverse models to generalize findings. Limitations include constrained age manipulation and the need for more realistic approaches in future research. Using naive sampling techniques like random sampling or grid search, the cost of search is exponential with the number of parameters. Bayesian optimization can significantly reduce the number of simulations needed to find failure cases, leading to over 40% improvement in efficiency in a simple experiment with six parameters. This improvement can be much more dramatic with a larger number of parameters. The sample efficiency improvement was over 500% for the classifier with the fewest missed detections overall. Using data generated via a realistic synthetic environment, demographic biases were identified in commercially available face detection classifiers. These biases were consistent with previous results on photo datasets. Leveraging highly-realistic computer simulations and Bayesian optimization can help intelligently search the parameter space to improve efficiency in identifying failures. The study utilized simulated data and Bayesian optimization to uncover biases in commercial face detection systems, particularly in their performance on darker skin types and older skin textures. The approach is flexible due to the various parameters that can be systematically adjusted in simulations. However, the use of only one base facial model limits the generalizability of the findings, necessitating the creation of synthetic faces with different bone structures for further testing. Improved age modeling in face images can be achieved using GAN or enhanced parametric synthetic models. While the initial cost of creating these models is high, they can generate large volumes of data, making them cost-effective in the long run. Future work will explore GAN-based approaches for synthesis and compare them to parametric synthesis. A hybrid of parametric and statistical models could be used to create a more diverse set of synthesized faces. Retraining the models using synthetic data may help combat model bias."
}