{
    "title": "rJxok1BYPr",
    "content": "Machine learning algorithms for molecular structure generation in drug discovery are promising. Molecular optimization is seen as a translation problem, where compounds are mapped to target compounds with improved properties. The Black Box Recursive Translation (BBRT) method improves compound attributes with each iteration, regardless of the translation model used. This technique shows significant performance improvements in molecular property optimization tasks. Automated molecular design using generative models offers rapid discovery of new compounds with desirable properties. Chemical space presents challenges due to its large, discrete, and unstructured nature. New methods for intelligent search are crucial in molecular optimization campaigns. The BBRT method significantly boosts performance in molecular property optimization tasks and is highly interpretable for mapping compound evolution. The framework for molecular optimization presented impressive results for constrained property optimization. It can generate structurally similar compounds and can be extended to unconstrained optimization by treating inference as a priority. The model can repeatedly generate better compounds, regardless of the translation model used, making it a \"black box\" algorithm. This method can leverage new molecular representations effectively. Black Box Recursive Translation (BBRT) is a new inference method for molecular property optimization that has shown to produce state-of-the-art results on benchmark tasks. Through various decoding strategies and ranking methods, BBRT proves to be beneficial for secondary property optimization and user-centric molecular design applications. Recent work in molecular design has focused on learning new representations such as graphs, grammars, trees, and sequences. Latent variable models, Markov chains, and autoregressive models have been developed to learn distributions over molecular data. Molecular optimization has been approached with reinforcement learning and optimization in continuous latent spaces. A third paradigm for design is introduced, focusing on molecular optimization. In molecular design, a new paradigm focuses on molecular optimization as a translation problem, where molecules are optimized by translating from a source graph to a target graph. The translation framework extends to finding the best scoring molecules based on a given biochemical property. The inference method restricts the framework's application to more general problems, despite the translation model not being fundamentally limited to constrained optimization. MMP analysis is a cheminformatics framework for analyzing structure-property relationships by identifying pairs of chemical structures that share the same core and differ by a small structural difference. This approach interprets structure-activity relationships through simple perturbations that can be transferred across drug design projects. The curr_chunk discusses the application of molecular translation as a learned MMP analysis, extending the framework to infer a sequence of MMPs for problems beyond constrained optimization. It also mentions the success of machine translation models in various applications, focusing on molecular optimization as a recent application. The curr_chunk introduces Black Box Recursive Translation (BBRT) as a method for molecular optimization, showing improved molecular properties compared to non-recursive approaches. It discusses diverse beam search, sampling methods, and reinforcement learning for optimizing translation tasks. The curr_chunk discusses optimizing chemical properties of molecules using a sequence-based molecular representation. Training pairs have high chemical similarity, aiding in learning local edits. The inference method is a black box, invariant to specific architectural choices. The curr_chunk discusses using a Seq2Seq model to optimize chemical properties of molecules. The model learns parameters to estimate conditional probabilities and uses an encoder-decoder architecture with RNNs. The attention mechanism is also utilized in the model. The attention mechanism in Seq2Seq models helps with token generation by focusing on token-specific source representations. Decoding methods for translation models can be deterministic or stochastic, with popular deterministic methods including greedy search and beam search. Greedy search selects the most likely token at each time step, while beam search explores multiple likely sequences within a fixed computational budget. Beam search is a method that maintains a set of hypotheses at each timestep, but it can lead to suboptimal generation. Recent work has explored diverse beam search methods to reduce duplicate sequences and increase the diversity of generated sequences. Stochastic decoding, another class of methods, samples from the model at generation time and has shown effectiveness in generating diverse samples. The method discussed involves using a top-k sampler to generate diverse samples in a target design space. It focuses on recursively inferring new sequences using a scoring function to select the best outputs. This process is repeated for multiple iterations. The method involves using a top-k sampler to generate diverse samples in a target design space by recursively inferring new sequences with a scoring function. This process scales exponentially with the number of iterations, so simple ranking strategies are introduced to select the best outputs for the next iteration. Scoring functions help calibrate the distributional statistics of generated sequences and aid in multi-property optimization. After n recursive iterations, the generated outputs are ensembled and scored on a desired objective, returning the arg max for property optimization. BBRT is a method that can aggregate results from different modeling choices and molecular representations to optimize properties. It is applied to solve unconstrained and multi-property optimization problems, generating state-of-the-art results in molecular property optimization. Recursive inference in BBRT also allows for interpretability by mapping the evolution of compounds through structural changes. BBRT is a method used for optimizing properties of compounds by making structural changes. It involves introducing \"break points\" to explore alternative translations and evaluate design objectives. The method is applied to secondary property optimization by ranking models, using SELFIES molecular representation for sequences and graphs. A Seq2Seq model with LSTM cells is developed for this purpose. The encoder-decoder model uses LSTM cells and attention for decoding. Hidden representations are optimized with cross-entropy loss. Decoding strategies include deterministic and stochastic methods. A tree-based molecular representation is used for graphs. Training data is constructed with molecular pairs that have similarity and property improvement constraints. The training pairs are constructed with a similarity constraint to avoid degenerate mappings. Molecular similarity is measured using Tanimoto similarity with Morgan fingerprints. Models are trained on the ZINC dataset and focus on optimizing drug properties, specifically the water-octanol partition coefficient (logP). The model is evaluated for unconstrained optimization using a training set of 88K molecule pairs. The training set consists of 88K molecule pairs, with details on property computation provided in Appendix A. Scoring functions are described for ranking outputs in recursive iterations, including Penalized logP, QED, Max Delta Sim, Max Init Sim, and Min Mol Wt for compound selection based on specific properties or similarities. For input-constrained optimization, choose compounds with minimum molecular weight to rectify generation artifacts. Tanimoto similarity is computed on Morgan fingerprints. Goal is to generate compounds with high penalized logP and QED values. BBRT-JTNN and BBRT-Seq2Seq are considered under different strategies and scoring functions. Seed translations with diverse compounds using MaxMin algorithm on Morgan fingerprints. The MaxMin algorithm was used to compute compounds on Morgan fingerprints, aiding BBRT in generating higher scoring compounds. Baselines compared include Junction Tree VAE, which outperforms other methods in molecular graph generation and optimization. In this study, various molecular generation methods are compared, including Syntax-Directed-VAE and Objective-Reinforced Generative Adversarial Networks (ORGAN). Baselines like Seq2Seq and Variational Junction-Tree Encoder-Decoder (JTNN) are also included, with different decoding strategies for fair comparison. The GitHub implementation of JTNN from Jin et al. (2019b) is used for evaluation. In this study, molecular generation methods are compared, including JTNN. The evaluation uses the GitHub implementation from Jin et al. (2019b). Comparisons are made with a fair computational budget by sampling from the prior distribution. Results show BBRT-JTNN outperforms baseline models for logP optimization, while BBRT-Seq2Seq outperforms Seq2Seq for QED property optimization. In Figure 2, the top 100 logP compounds generated by BBRT show significant improvements in logP compared to non-recursive models. The JTNN variant produces more diverse compounds, while Seq2Seq generates less diverse ones. Figure 3 visualizes the top 2 compounds discovered by BBRT-JTNN and BBRT-Seq2Seq for both properties, with BBRT-JTNN having higher property values and BBRT-Seq2Seq showing a richer molecular vocabulary. The top 2 compounds generated by BBRT-JTNN and BBRT-Seq2Seq have different molecular vocabularies, with BBRT-JTNN producing compounds with higher property values and BBRT-Seq2Seq showcasing a richer vocabulary. The differences in compound generation highlight the importance of using flexible frameworks that can combine results across different molecular representations. Additionally, BBRT shows a 27% improvement in logP optimization compared to state-of-the-art methods, while for QED values, non-recursive techniques perform similarly to recursive methods, suggesting a potential upper bound for QED values. The study highlights the importance of new metrics for evaluating models, particularly in terms of QED values. Ablation experiments were conducted to analyze the impact of different design choices on performance. Stochastic decoding methods were found to outperform deterministic methods in terms of average logP scores and compound diversity. Non-greedy search strategies are not commonly used in molecular design. Recent research focuses on novel network architectures and generating diverse compounds. In molecular design, the importance of well-informed search techniques is highlighted, with improvements in mean logP observed with iterations when using BBRT. A logP scoring function quickly discovers the best compounds, while secondary scoring functions improve logP at a slower rate. The trade-off between conflicting molecular design objectives is emphasized, with the standard deviation typically decreasing with iteration number. In Figure 4A, standard deviation decreases with iteration number n, indicating property values concentrate within a certain range. The average pairwise diversity of translated outputs per recursive iteration across 3 decoding strategies shows a decay in diversity for logP in Figure 4B. The top-5 sampler strategy exhibits a decay in diversity from 0.86 to 0.78 after n = 25 recursive translations. Differences in decay rate for QED suggest task variability between explorative and interpolative tasks in drug design. The number of generated suggestions can pose a practical challenge for project teams. BBRT generates molecular traces to optimize compounds with minimal structural changes while improving logP. These traces are likened to Free-Wilson analysis steps towards optimal molecules, each step representing a local model using molecular subgraphs. The biological activity of molecules is described by linear summations of activity contributions. The method allows users to \"debug\" the translation process and consider alternative steps, similar to breakpoints in computer programs. It provides interpretability within the chemical space spanned by subgraphs, allowing for molecular design with conflicting objectives. For example, increasing logP may lead to poor oral drug-like properties, while increasing QED could result in structurally dissimilar compounds. The approach involves molecular breakpoints and considering alternative steps in the translation process. The translation process in Figure 5A involves evaluating trade-offs between logP, QED, molecular weight, rotational bonds, and chemical similarity. Secondary property optimization ranks recursive outputs using a scoring function to determine the next compound. BBRT-Seq2Seq is applied with a trained QED translator to optimize QED and logP. Scoring outputs based on QED and logP are compared in Figure 6A. The study compares the use of logP and QED as scoring functions for optimizing compound generation. Results show that optimizing logP leads to higher average logP values compared to QED. However, after 15 recursive iterations, compounds scored by logP converge to lower average QED values. Similar effects are observed with JTNN. Secondary property optimization by ranking extends to variables that are loosely positively correlated. BBRT is a simple algorithm for molecular optimization that feeds the output of translation models back into the same model for additional optimization. It has been applied to well-known models in the literature, producing new state-of-the-art results for property optimization tasks. The algorithm also allows for multi-property optimization and can be extended to consider multiple translation paths simultaneously in future work. In future work, BBRT will be extended to consider multiple translation paths simultaneously and to low-resource settings. The Seq2Seq model used a 2-layer bidirectional RNN encoder and 1-layer unidirectional decoder with attention. The model was trained for 20 epochs with an Adam optimizer. The graph-based model implementation was from Jin et al. (2019b). Penalized logP and QED scores were calculated using RDKit."
}