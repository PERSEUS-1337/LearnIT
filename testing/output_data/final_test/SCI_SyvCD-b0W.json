{
    "title": "SyvCD-b0W",
    "content": "Autostacker is an automatic machine learning architecture that improves prediction accuracy without requiring domain knowledge or feature preprocessing. It utilizes a hierarchical stacking architecture and an efficient parameter search algorithm, reducing AutoML time with Parallel Hill Climbing. Autostacker breaks tradition by exploring innovative combinations and structures in the modelling process, providing pipelines with high prediction accuracy quickly. Autostacker achieves superior performance in test accuracy and time cost compared to human initial trials and other AutoML systems. Machine Learning is widely used to solve prediction problems by leveraging data and algorithms. Different models are proposed to address various problems based on specific characteristics. Data scientists need to understand model advantages, manually tune hyperparameters, and run experiments, which is time-consuming and costly. Automating the modeling process is highly desired in academia and industry, with AutoML systems aiming to streamline this procedure. An AutoML system aims to provide automatically generated baselines for data scientists to solve machine learning problems with less effort. While some efforts have been made to automate the process of finding appropriate configurations of modelling pipelines, these often rely on fixed order pipelines mimicking human experts, limiting the potential for the machine to find better pipelines. Autostacker is an architecture that generates pipelines using ensemble learning methods, allowing for the discovery of innovative combinations of models. It aims to provide better starting points compared to human expert trials, but faces challenges due to data quality issues. The system addresses this by using raw datasets in all stacking layers. Autostacker pipelines consist of multiple layers and nodes, with each node representing a machine learning model. The raw dataset is used as input in the first layer, and prediction results from each node are added as synthetic features in subsequent layers. This approach aims to fully utilize the information in the dataset by adding synthetic features in each stacking layer. The AutoML framework allows for dynamic generation of pipelines with varying numbers of primitive models based on computational and time costs. This flexibility enables pipelines ranging from a single model to hundreds of primitive models. The variables in the framework include types of machine learning models, configuration settings, and the number of primitive models in each stacking layer. The paper proposes using Parallel Hill Climbing (PHC) as a search algorithm to find suitable candidate pipelines in the AutoML framework. It defines primitives as single machine learning models and pipelines as combinations of primitives in Autostacker. Autostacker consists of multiple stacking layers and nodes. Autostacker architecture consists of multiple stacking layers with nodes representing machine learning models. Recent focus in AutoML includes machine learning pipeline building and model hyperparameter search. TPOT framework allows for parallel feature engineering before model prediction and uses Evolutionary Algorithms for parameter configuration. In this work, Autostacker aims to discover innovative machine learning pipelines by generating models with new combinations and architectures. They utilize Parallel Hill Climbing for optimization in a large search space, proving its effectiveness in large scale AutoML. Autostacker utilizes Parallel Hill Climbing for optimization in a large search space, proving its effectiveness in large scale AutoML. The pipeline architecture consists of multiple layers with primitive machine learning models, where each layer adds synthetic features to the dataset for the next layer. The final output is generated by the last layer's single node. The Autostacker model utilizes Parallel Hill Climbing for optimization in a large search space. The final output is determined by the last layer's single node, which retains information directly from the raw dataset. The model pipelines are built with dynamic configurations of architecture and hyperparameters, feeding into the PHC algorithm for iterative improvement. The Autostacker model uses Parallel Hill Climbing for optimization in a large search space, generating winning pipelines for data scientists. The dataset size can impact prediction results, and combining new synthetic features with the raw dataset can improve prediction accuracy without fully trusting individual primitives. The Autostacker model uses Parallel Hill Climbing for optimization in a large search space to generate winning pipelines for data scientists. It does not fully trust individual primitives in layers to reduce bias and noise from the raw dataset. The architecture includes hyperparameters like I and J for layers and nodes, H for primitive hyperparameters, and types of primitives in a dictionary for search space. Autostacker offers two specifications for I and J, allowing users to explore different configurations easily and speed up the process significantly. The Autostacker model uses Parallel Hill Climbing for optimization in a large search space to generate winning pipelines for data scientists. It offers two specifications for I and J to speed up the process significantly. The search algorithm for finding hyperparameters is described, with the Parallel Hill Climber Algorithm chosen for better baseline model pipelines. The Autostacker model utilizes Parallel Hill Climbing for optimizing pipelines in a large search space. N pipelines are initially generated with random hyperparameters, followed by a one-step Hill Climber to create another set of pipelines. The top N pipelines based on validation accuracies are then chosen as seed pipelines for the next generation. This process continues iteratively until the specified number of iterations M is reached. The training and testing procedure in Autostacker involves training pipelines layer by layer, with each primitive trained independently within each layer. Validation and testing processes follow a similar mechanism using validation and test sets. The top 10 pipelines with the highest validation accuracies are selected as the final output. The Autostacker system selects the top 10 pipelines based on validation accuracies to provide better baselines for human experts. This approach ensures better performance on average and allows for flexibility in scaling up and parallelizing the system. Each pipeline runs independently from generation to evaluation. The Autostacker system utilizes one-step hill climbing for training, validation, and evaluation. Each pipeline runs independently, with no communication or sequential decision making among workers. Validation results are shared for ranking, and a one-shot selection based on accuracy is applied. The system's performance was tested on 15 datasets from BID9, showing promising results. Autostacker utilizes one-step hill climbing for training, validation, and evaluation on 15 datasets from various problem domains. The data is cleaned by filling missing values with large negative values or deleting data points with missing values. Autostacker is compatible with regression problems and does not involve additional data preprocessing or feature preprocessing. More benchmark dataset results and code base will be released in the future. In this paper, Autostacker focuses on the modelling process to showcase its contribution to architecture and automation. Before each experiment round, the dataset is shuffled and split into 80%/20% for training/testing. The goal is to offer a better baseline pipeline for data scientists automatically. The baseline compared is the Random Forest Classifier/Regressor with 500 estimators, known for its effectiveness in practice. Autostacker allows users to customize primitives from scikit-learn and XGboost libraries for model predictions. The default mode includes dynamic configurations with a maximum of 5 layers and 3 nodes per layer. Test accuracy results are shown for the candidate pipelines. The test accuracy and time cost of Autostacker are compared with Random Forest and TPOT baselines. 10 rounds of experiments were run for Random Forest Classifier and 3 to 10 rounds for TPOT. Autostacker executed 3 rounds of experiments on each dataset, with datasets shuffled before each round. The figure contains 30 test results in total, with notches in the box plot representing 95% confidence intervals of median values. Test accuracy comparisons on 15 sample datasets are shown in FIG5. Autostacker achieves significantly better test accuracy compared to Random Forest and TPOT on 15 sample datasets. It is more robust and consistently provides better baselines, thanks to its innovative stacking architecture utilizing predictions from different models. Autostacker significantly improves test accuracy compared to Random Forest and TPOT on sample datasets by utilizing predictions from different models and reducing time usage up to 6 times. Despite its success, Autostacker still has limitations that need to be addressed for future improvements. The limitations of Autostacker include the need for automation of machine learning processes for large datasets and the potential for increased efficiency with better search algorithms. Incorporating advanced primitives and utilizing modern evolutionary algorithms could enhance Autostacker's performance. Autostacker is a machine learning system with an innovative architecture for automatic modeling and an efficient search algorithm. It automates the machine learning modeling process, providing a flexible and well-behaved system that can be integrated with data processing modules. The system's performance is compared with human trials and other techniques, showcasing its scaling and parallelization abilities."
}