{
    "title": "SkMON20ctX",
    "content": "The evolution of information theoretic quantities during Stochastic Gradient Descent (SGD) learning of Artificial Neural Networks (ANNs) is a popular research topic. The framework proposed in this work aims to understand SGD learning in the information plane by observing entropy and conditional entropy of ANN output labels. Experimental results and theoretical justifications suggest that SGD learning trajectories are similar for different ANN architectures. The SGD learning is modeled as a Hidden Markov Process with increasing entropy towards the maximum. The trajectory appears to move towards the shortest path between initial and final joint distributions in the space of probability measures. This approach offers an alternative for observing the learning process. The information plane offers a new perspective on learning processes in artificial neural networks. Shwartz-Ziv & Tishby (2017) explored information theoretic quantities during training, using the information bottleneck method to explain SGD learning. They found that compression plays a significant role in learning, leading to further research in this area. The initial paper inspired further research in the field, focusing on estimating mutual information between high-dimensional continuous random variables. This becomes challenging with large datasets like CIFAR-100, where large artificial neural networks are used. Previous works have shown that generalization error can be bounded by mutual information, but experimentally verifying these results is difficult. In previous work, a 2D information plane was defined that only requires estimating information between correct and estimated values. In this work, a 2D-information plane is defined to study the behavior of artificial neural networks during learning. The main focus is on the entropy of output labels and conditional entropy given true labels. It is shown that under perfect learning conditions, the entropy tends to increase. The entropy tends to increase under perfect learning conditions. SGD learning trajectory follows the shortest path in the space of probability measures. Experimental justifications for constructing a Markovian model for learning are provided and compared with SGD through experiments using various datasets and ANN architectures. The trajectory of SGD learning differs significantly for different learning scenarios. The paper discusses how SGD learning trajectories vary based on different learning scenarios, noisy labels, overfitting, and underfitting. It introduces notation, formulates learning as a trajectory on probability measures, and constructs a Markov chain model for gradient-based learning. An empirical evaluation of the model is also performed. The paper introduces the concept of an oracle mapping inputs to classes, with the assumption of uniformly distributed classes. It discusses the impact of error-prone labels on data by introducing random noise. The classifier aims to approximate the mapping function with tunable parameters in the hypothesis space. The classifier is a deterministic function that approximates the oracle mapping with tunable parameters. It defines three types of errors: dataset error, test error, and true error. Information theory concepts like entropy and mutual information are used to quantify uncertainty and information between random variables. The concept of mutual information measures the information one random variable carries about another. Fano's inequality relates test error to conditional entropy, providing an upper bound on conditional entropy in terms of expected error. The minimal error between variables y and \u0177 is minimized when mutual information is maximized, modeling learning as finding parameters that maximize mutual information. In our previous work, we focused on characterizing the trajectory in the 2D information plane of artificial neural networks during the learning process. We analyzed the learning trajectory of a DenseNet architecture with 100 layers classifying data from the CIFAR-100 dataset. Maximizing H(\u0177) is related to unsupervised learning, while keeping H(\u0177|y) low is related to supervised learning. It would be interesting to identify the inflection point where H(\u0177|y) starts decreasing, indicating when SGD prioritizes assigning labels correctly over learning the input distribution. In previous work, the trajectory of artificial neural networks during learning was analyzed. The behavior of SGD in assigning labels correctly over learning input distribution was studied across different datasets and activation functions. The tunable parameters of networks are adjusted over time to minimize learning error. See Appendix A for more on error and entropy relations with noisy labels. The tunable parameters of an artificial neural network (ANN) are adjusted during training to minimize learning error. The outcome of the learning algorithm is captured by random variables modulated by the network function applied to input data. As training progresses, the random variables converge to true labels, which follow a joint distribution with the input data. The random variables are coupled through the input data and parameter updates. During training, the parameters of an artificial neural network are adjusted to minimize learning error. The outcome is captured by random variables modulated by the network function. The trajectory of the probability distribution and conditional entropy of the random variables are studied in relation to the training samples and parameter updates. The parameters of an artificial neural network are adjusted during training to minimize learning error. The SGD updates depend on the parameters in the last step and the current training set. The sequence of random variables {\u03b8 n} forms a Markov chain with transition probability obtained from the update rule of SGD and T 1. The Markov chain is assumed to have a stationary distribution. The Markov chain {\u03b8 n} has a stationary distribution corresponding to the learned ANN. SGD updates induce Markov property for weights of an ANN. The sequence \u0177 n = g(\u03b8 n, x) is not a Markov chain due to coupling through x. Decoupling random variables g(\u03b8 n, x n) with i.i.d. x n preserves entropy function. The resulting sequence is a function of a Markov chain and i.i.d. random variables, but \u0177 n is not a Markov chain unless certain conditions are met by the function g(\u00b7). The random process {g(\u03b8 n , x n)} is a Hidden Markov Process (HMP) where the observation of the Markov process {\u03b8 n} is through a noisy memoryless channel. If learning is perfect, the HMP converges to a uniform distribution of correct labels. The entropy of the correct labels approaches its maximum as they become uniformly distributed. The instantaneous entropy would converge to the entropy of the stationary distribution if the sequence were a Markov chain. The entropy of the correct labels approaches its maximum as they become uniformly distributed in a Hidden Markov Process (HMP). The entropy is lower-bounded by an increasing function in the case of a Markov process. The network output is modeled as an HMP, and the convergence of true labels is discussed. The task of learning involves tuning parameters to approach the distribution of the true labels. Gradient descent steps correspond to a sequence of joint distributions on the space of probability measures. The trajectory of conditional entropy is examined, but characterizing this path precisely is challenging. The focus is on comparing the gradient descent trajectory with a natural path on the space of probability measures. To compare the gradient descent trajectory with a natural path on the space of probability measures, we need to define curves and lengths on the metric space of probability measures. The space of probability distributions on the discrete space Y \u00d7 Y is denoted by P(Y \u00d7 Y) with the total variation metric d T V (\u00b7, \u00b7) being a simplex in a finite dimensional Euclidean space. A curve in this space is defined by a continuous function \u03c3 : [0, 1] \u2192 P(Y \u00d7 Y), and the shortest path is the curve with minimal length measured using the L 1 -norm. The space of probability distributions on the discrete space Y \u00d7 Y, denoted by P(Y \u00d7 Y), can be traversed by a Markov chain following a shortest path between two probability measures \u00b5 and \u03bd. This path is given by t\u00b5 + (1 \u2212 t)\u03bd for t \u2208 [0, 1], with \u00b5 n = \u00b5\u03a0 n approaching \u03bd as n approaches infinity. The existence of this shortest path is guaranteed by the space being a bounded compact metric space with points connected by rectifiable curves. The transition matrix \u03a0 is defined by DISPLAYFORM0 where 1 = (1, 1, . . . , 1). The previous paragraph discusses the traversal of probability distributions on a discrete space by a Markov chain. The current paragraph focuses on the implications of a theorem regarding conditional distributions and the convergence of a distribution matrix in a learning algorithm. The initialization of the distribution matrix and its convergence to an optimal distribution as n approaches infinity are key points discussed. The current paragraph introduces the concept of \u03b1-Simple Markov Learning Chain (\u03b1-SMLC) and its transition matrix for passing from initial to stationary distribution. Theorem 2 describes how an \u03b1-SMLC moves in the space of stochastic matrices, leading to points on the shortest path between measures. This construction ensures that the distribution matrix belongs to a continuous curve, regardless of the choice of \u03b1. Proposition 4 states that if {(\u0177 n ,\u1ef9 n )} is an \u03b1-SMLC and z follows a certain distribution, then H(\u0177(t)|y) has one maximum at t = 0. This result helps characterize the shape of 2D curves for the construction. Proposition 5 discusses a stationary Markov Chain converging to a distribution p * = e. In this section, we compare gradient-based learning to the \u03b1-SMLC model through empirical simulations using datasets where SGD is successful at classification tasks like the MNIST dataset and the spirals dataset. The spirals dataset is a 2D-spiral classification task with independent uniformly distributed random variables. It is divided into a training set of 50,000 samples and a test set of 2,000. The dataset includes MNIST and spirals, with FCNN and LetNet-5 achieving over 99% accuracy. DenseNet is used for CIFAR-10 and CIFAR-100. Different optimizers are used for training. Entropy estimation is done using a naive method with an approximation error. More sophisticated methods can be used for larger K values. In experiments, i.i.d. noise is added to dataset labels before training. The similarity between the \u03b1-SMLC model and ANNs is shown on spirals and MNIST datasets. ANNs and the \u03b1-SMLC model move similarly along the information plane, converging to the optimal distribution. The inflection point of the \u03b1-SMLC model for different noise levels suggests that as labels get noisier, a learning algorithm needs more information about the input. The experiment investigates the impact of noisy labels on learning algorithms. Results show that a good algorithm should converge to a point on the upper bound provided by Fano's inequality. The trajectory of SGD oscillates depending on factors like learning rate and dataset structure. An experiment on underfitting and overfitting effects on SGD trajectory is also conducted. Incorporating 1 norm regularization with parameter \u03bb into the loss function in FIG8 (a) leads to minimum error for small \u03bb values. Increasing the regularization coefficient induces underfitting, causing models to deviate from Fano's bound and increase error. Conversely, increasing the number of parameters in FCNN and reducing dataset size induces overfitting, distinguishable by its trajectory in the entropy-error plane. This experiment reveals insights beyond train and test error, providing a richer view of model behavior. Further understanding about desired trajectories may allow practitioners to monitor models during training, spot undesired behaviors, and tune hyperparameters accordingly. The bound for independent noise z is shown to be sharp when distributed such that \u03a6(H(z)) = p, with p \u2264 \u03b5. This result is generalized for an arbitrary distribution of z, showing that p \u2264 \u03b5 is a sharp lower bound. The minimum expected error \u03b5 can only be achieved if g(\u03b8, \u00b7) denoises the labels, leading to \u03b5 = 0. The theorem provides bounds for \u03b5 given \u03b5 and p. Theorem 4 provides bounds for \u03b5 given p, while Corollary 3 states conditions for \u03b5. Mrs. Gerber's Lemma (MGL) gives an upper bound on H(\u1ef9|\u0177) for K = 2. Generalizing MGL for arbitrary K remains an open question, but BID12 proved it for K as a power of 2. Proposition 7 presents Generalized Mrs. Gerber's Lemma for K = 2. Inequalities linking entropies and error values are derived, showing that the best way to minimize \u03b5 in the presence of corrupted labels is to learn c. Theorem 5 establishes the relationship between HMP {y_n} and Markov process {x_n} through a stationary memoryless channel. The joint distribution of x n and y n is denoted by \u00b5 n and defined on X \u00d7 Y. The stationary joint distribution \u00b5 is defined by q \u00d7 r. A fully connected ANN with four hidden layers is trained on the spirals dataset, while the LeNet-5 convolutional network is used for the MNIST dataset. The LeNet-5 network is used for training, with the learning rate starting at \u03b3 max and decaying by 40% per epoch until reaching \u03b3 min. A 100 layer DenseNet architecture is trained on the CIFAR-10 dataset for 10 epochs. Different configurations are summarized in TAB1. Figure 8 shows oscillating trajectories for DenseNet on CIFAR-10. The trajectories follow a similar behavior as the \u03b1-SMLC model. In FIG8 (a), an additional regularization term \u03bb w 1 is added to the loss function of the model. In FIG8 (b), a FCNN with a single hidden layer of size 100 and tanh activations is used, with reduced dataset sizes. Other parameters include \u03b3 max = 10 \u22121, \u03b3 max = 10 \u22122, and 10,000 epochs."
}