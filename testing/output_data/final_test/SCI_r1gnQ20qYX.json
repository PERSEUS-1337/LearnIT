{
    "title": "r1gnQ20qYX",
    "content": "Deep neural networks have shown strong performance in healthcare applications, but lack interpretability. PEARL, Prototype lEArning via Rule Lists, combines rule lists with neural networks to improve interpretability and accuracy in predicting electronic healthcare records. PEARL outperforms baselines on electronic healthcare records datasets, showing up to 28% improvement over rule learning and 3% over prototype learning. It provides simpler interpretations than standard rule learning, addressing the lack of interpretability in deep learning models used for diagnostics, disease detection, medication prediction, risk prediction, and patient subtyping in electronic health records. Recently, efforts have been made to explain black-box deep models in medical decision making through attention mechanisms, visualization, and explanation by examples. Clinicians need to understand how deep models generate outputs for given inputs to bring them into real clinical practice. Rule learning and prototype learning are promising for achieving clinical model interpretability, with rule learning generating interpretable rule lists expressed in simple logical forms. Rule-based models are interpretable to domain experts but have lower accuracy compared to deep neural networks. The interpretability of rules can be compromised when the depth of rules becomes too large. Prototype learning, inspired by case-based reasoning, classifies observations based on their proximity to a prototype point in the dataset. However, prototypes alone may not lead to interpretable models without an intuitive way to explain them. In healthcare applications, a new approach called Prototype lEArning via Rule List (PEARL) combines rule learning and prototype learning on deep neural networks to create an accurate and interpretable prediction model. This method aims to address challenges in constructing simple rules with accurate prediction and classification performance, as well as producing intuitive definitions of prototypes. PEARL combines rule list and prototype learning on neural networks to create accurate and interpretable prediction models. It automatically learns prototypes corresponding to rules, providing concise and explainable results. On real-world health record datasets, PEARL shows accurate predictions and simple interpretations. Prototype learning is a type of case-based reasoning that aims to find representative objects from a set of similar instances. Prototypes can be seen as an alternative approach to learning centroids of clusters and have been applied to few shot learning. In this work, a general representation of prototypes is used, where they are automatically learned via deep neural networks. In this work, prototype learning is guided iteratively through neural networks using rule lists with logic statements over original features. Each rule in the list depends on previous rules with \"else-if\" logics, enhancing the understanding of the reasoning process in diagnosis. The interpretability of rule lists in prototype learning is crucial for understanding the reasoning process in diagnosis. It is defined by four aspects: size (number of rules), length (number of clauses in each rule), cover (set of data points satisfied by each rule), and overlap (discriminative power between rules). In this paper, new methods are proposed to reduce the size and length of rule list classifiers while improving accuracy. The cover of each rule is used to re-weight data, focusing on more discriminative points and reducing overlap among rules. The methodology involves representing data samples as sequences of discrete event labels, with each sample having a class label. The PEARL method aims to accurately predict class labels y for categorical variables X using a deep neural network with interpretable prototypes. The network outputs class labels and rule lists to guide accurate classification. The overall objective is to provide explanations for predictions by learning representations of X. The PEARL method uses a deep neural network with interpretable prototypes to predict class labels for categorical variables. The prototypes serve as representations of the data, and a distance measure is used to determine their similarity to learned rules. The Cross Entropy loss is used for final prediction targets, with model parameters for data representation learning and classification. Minimizing the loss encourages training examples to be closer together. The PEARL method integrates rule learning and rule-guided prototype learning by using interpretable prototypes closely related to learned rules. The framework emphasizes classification performance by choosing appropriate relative weights through hyperparameter tuning. The goal is to create prototypes that serve as surrogates for clauses in rules, transforming them into a one-to-one or many-to-one rule-prototype mapping. The PEARL method combines rule learning and prototype learning, with interpretable prototypes linked to learned rules. The network architecture includes an interpretable module for rule list learning and a prediction module for prototype learning. The PEARL method combines rule learning and prototype learning in two modules: an interpretable module for rule list learning and a prediction module for prototype learning. The prediction module includes a representation network and a prototype learning network that iteratively improve each other during training. The interpretable module employs a rule list classifier to provide interpretable prototype definitions. It uses a known rule list learning algorithm to generate a rule list, which is then used to help the prediction module define and interpret prototypes. Feature selection algorithms were tested in experiments but did not significantly impact performance. The prediction module in our experiments utilizes patient representation learning and prototype learning networks, employing recurrent convolution neural networks (RCNN) BID18 for event sequence embedding. The patient representation learning procedure is denoted as Eq. 2, incorporating time differences between consecutive events. The patient representation learning procedure incorporates time information into patient representation by using highway networks to alleviate the vanishing gradient issue in network training. Highway networks are essential for prototype qualities in data representation learning. The highway networks are crucial for prototype qualities in data representation learning. The embedded clinical events are used in an iterative prototype learning procedure, generating prototype vectors from the data samples. The output of the prototype learning network is the distance of a training subject to all prototypes. The dimension of o(X) depends on the number of rules. Rule-prototypes are used as guidance for prototypes in the feature space h(X). A fully-connected layer and softmax activation are used for classification, with estimated probability s_R(X_n). Cross-entropy loss is used for training, with data re-weighting based on prediction results for iterative learning. By utilizing data samples from the new feature space h(X), prototypes become more discriminative and reveal underlying data similarity relationships. This leads to easier separability of data samples, especially for difficult or noisy examples with low probability. Weighting simpler, more separable samples in rule-list learning facilitates easier training and better separation later on. Empirical study on data separation will be conducted. The iterative learning and re-weighing procedure is based on the similarity between data samples and prototypes. Cosine similarity is measured to boost prototypes that are far away from other subjects, making them more discriminative. Prototypes with fewer subjects nearby are prioritized, and those below a certain similarity threshold are selected for further analysis. The iterative learning and re-weighing procedure in PEARL involves optimizing rule list R and neural networks until convergence. Data augmentation is used when the rule list cannot handle data weights directly. For new samples, PEARL generates predicted probabilities for classification and outputs from the prototype layer to indicate similarity. The PEARL model involves optimizing rule list R and neural networks iteratively until convergence. Data reweighing is done based on similarity between data and prototypes. Evaluation is done on heart failure detection and mortality prediction tasks using PyTorch BID25. The PEARL model optimizes rule list R and neural networks iteratively. Data reweighing is based on data-prototype similarity. Evaluation is on heart failure detection and mortality prediction using PyTorch BID25. Methods are implemented in PyTorch BID25 and trained on a laptop with 8GB memory. Real world datasets are used for experiments, including a Heart Failure dataset with 2,268 case patients and 14,526 controls. Baseline algorithms include Rule learning, Decision Tree, and Prototype Learning. The scikit BID26 package in Python includes Prototype Learning (without rules) using RCNN+prototype and RNN (Doctor-AI) with RNN+softmax. Evaluation involves randomly splitting the dataset, training, validation, and testing sets, and measuring prediction accuracy using ROC-AUC. After tuning, specific parameters are set for the models. For prototype learning and model training, specific parameters are set such as \u03bb values, embedding initialization, number of prototypes, hidden layer size, number of filters, stride, window size, pooling layer, highway network layers, optimization through Adam, batch size, data weighting threshold, convergence criteria, and early stopping within 5 epochs. The study compares the performance of different models using a criteria of 0.001. PEARL outperforms all other methods in terms of AUC. Prototype learning is better than rule learning and RNN models but worse than PEARL. The proposed PEARL model achieves better accuracy with fewer prototypes compared to rule list learning. The study compares the performance of different models using a criteria of 0.001. PEARL outperforms all other methods in terms of AUC. Prototype learning is better than rule learning and RNN models but worse than PEARL. The proposed PEARL model achieves better accuracy with fewer prototypes compared to rule list learning. PEARL can explain more samples than rule lists with over 50 rules, and data reweighing leads to more separable prototypes. The mean distances between prototypes and data decrease over training iterations, resulting in lower training loss. Data augmentation improves rule list accuracy, along with hyper-parameter tuning. The prototypes learned in PEARL provide more interpretable diagnosis compared to conventional rule learning. The prototypes learned in PEARL for sets of patients involve rule-prototypes with high frequent events, discarding events that occur to only one or two patients. PEARL uses around 10 rules for correct diagnosis, contrasting with complex rule lists from rule learning. An example of a prototype-rule from PEARL includes events like chronic airways obstruction, malignant neoplasm of trachea, lung and bronchus, and others. The PEARL model combines rule learning and prototype learning to diagnose patients with heart failure based on specific clinical events and medications. It simplifies the diagnosis process by using around 10 rules compared to traditional methods that require over 40 clinical events. This approach focuses on common symptoms and comorbidities of heart failure patients. The PEARL model combines rule learning and prototype learning on deep neural networks for accurate and interpretable diagnostic decisions in heart failure patients. In future research, the model will be extended to other interpretable models. The inclusion criteria for heart failure data involve ICD-9 diagnosis consistency and medication prescription validation. The study evaluated the accuracy of rules in different epochs using Algorithm 1. Five independent trials were conducted with varying hyperparameters, showing an increase in accuracy with iterative learning. Data augmentation improved rule list learning accuracy. Comparison between non-rule prototypes and rule prototypes demonstrated that more rule-prototypes yielded better performance, as shown in FIG6. In the study, it was found that more rule-prototypes led to better accuracy compared to non-rule prototypes. The evaluation included data reweighing threshold \u03b7 in Algorithm 1, showing that a higher threshold generally resulted in improved accuracy. Additional evaluation using \"cars\" and \"breast\" datasets from UCI data repository showed varying classification accuracies for different methods. The maximal number of rules from rule learning is not predetermined but determined by the data. The study found that more rule-prototypes improved accuracy. Evaluation with different thresholds in Algorithm 1 showed higher thresholds led to better accuracy. Experiment results showed PEARL had better clustering properties than random prototype."
}