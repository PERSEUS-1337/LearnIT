{
    "title": "SJlDDnVKwS",
    "content": "Evolutionary Strategies (ES) are optimization algorithms that use search distributions to optimize objective functions. This paper explores the benefits of using flexible search distributions modeled by Generative Neural Networks (GNNs) in ES algorithms. A new ES algorithm is introduced that leverages these distributions to accelerate stochastic search, allowing for augmentation of standard ES algorithms. Empirical results show advantages in optimizing various objective functions with expensive evaluations. Bayesian Optimization is used for problems with high evaluation costs and aims to discover the global minimum after a few hundred function evaluations. It requires a balance between exploitation and exploration of the optimization landscape. Evolutionary Strategies (ES) algorithms, such as Covariance Matrix Adaptation Evolution Strategies (CMA-ES) and Natural Evolution Strategies (NES), use a multivariate Gaussian search distribution for proposing queries in optimization tasks. These algorithms have shown success in hyper-parameter tuning and direct policy search in Reinforcement Learning, competing with state-of-the-art techniques. In ES algorithms, the choice of standard parametric search distributions like Gaussian or Cauchy can be limiting for finding a global minimum. To address this, flexible distributions generated by bijective Generative Neural Networks (GNNs) with computable and differentiable log-probabilities are proposed. A tailored algorithm is designed to efficiently train GNNs for an ES objective, allowing for the incorporation of existing optimization methods. The new algorithm efficiently trains GNNs for an ES objective, incorporating existing ES algorithms that operate on simple search distributions like Gaussian. This extension accelerates ES algorithms on various objective functions. The process involves sampling, evaluating, and updating the search distribution until convergence. Experimental results are reported in Section 5. The new algorithm efficiently trains GNNs for an ES objective, incorporating existing ES algorithms that operate on simple search distributions like Gaussian. This extension accelerates ES algorithms on various objective functions. The generic procedure followed by ES algorithms is presented in Algorithm 1, where the search distribution is tied to a parameter vector \u03b8 and updated by minimizing the expected objective value over samples drawn from the distribution. This update step is a key difference in ES algorithms and can be differentiated with respect to \u03b8 using the log-trick. The authors propose a trust-region optimization scheme to improve the Plain Gradient Evolutionary Strategies (PGES) algorithm for training GNNs. This scheme minimizes a linear approximation of the objective function under a KL divergence constraint, using the Fischer Information Matrix (FIM) of the search distribution. The Fischer Information Matrix (FIM) is used to update the parameter \u03b8 along the natural gradient in Exponential Natural Evolutionary Strategies (xNES). This algorithm has shown state-of-the-art performance in ES benchmarks. CMA-ES is another strategy that updates the search distribution using heuristic mechanisms like covariance matrix adaptation. CMA-ES relies on heuristic mechanisms like covariance matrix adaptation and evolution paths, defined for a multivariate Gaussian distribution. ES balances exploration and exploitation in optimization. The search distribution plays a key role in adapting to the landscape's structure for improved samples. The choice of a parametric distribution, like the multivariate Gaussian, can be a constraint in ES algorithms. The search distribution in ES algorithms, like CMA-ES, can be a constraint due to its lack of flexibility in navigating complex landscapes and exploring multiple local minima simultaneously. Introducing more flexible search distributions is essential for enhancing the exploration abilities of the algorithm. In order to enhance exploration abilities in ES algorithms like CMA-ES, more flexible search distributions are needed. These distributions should be easily trainable and carefully designed to balance exploration and exploitation. Generative Neural Networks (GNNs) are being investigated as a parametric class of distributions that meet these criteria. Generative Neural Networks (GNNs) are proposed to enhance exploration abilities in ES algorithms like CMA-ES by modeling complex distributions. GNNs map latent variables to output variables using neural networks, but computing the density of the output variable for GNN samples is challenging. Generative Neural Networks (GNNs) are often trained with adversarial methods or variational auto-encoders for sample generation. An alternative method is using Normalizing Flows (NF) to compute the distribution's density exactly by restricting architectures to build bijective GNNs. This allows for tractable density computation by ensuring the determinant of the Jacobian is easily computed. Normalizing Flows (NF) models, such as the Non-Linear Independent Component Estimation (NICE) model, offer flexibility and ease of training for density estimation. NICE utilizes additive coupling layers to create complex yet invertible transformations, ensuring numerical stability and volume preservation. The NICE model utilizes additive coupling layers to create complex yet invertible transformations with unit Jacobian determinant, easily invertible through a Multi-Layer Perceptron (MLP). The resulting distribution's density is computable thanks to the inverse transform theorem, making it volume preserving and desirable for density estimation. The NICE model uses additive coupling layers to introduce non-linearities in the inverse transform, making the distribution better suited for optimization. This volume-preserving fit encourages the search distribution to align its tails with regions of small optimization landscape values, improving exploration quality. The NICE model provides a flexible search distribution that is easy to train and offers control over exploration/exploitation trade-off. The NICE model introduces non-linearities in the inverse transform to improve optimization. However, existing training strategies are not sufficient for leveraging the flexibility of GNNs for ES. A new algorithm tailored for this task is introduced to address limitations in locating precise solutions. The NICE model introduces non-linearities in the inverse transform to enhance optimization for GNNs in ES. However, training the NICE distribution for ES requires more advanced algorithms like NES due to limitations in locating precise solutions. The natural gradient for GNNs distributions is challenging as the Fischer Information Matrix must be estimated via Monte-Carlo sampling, leading to approximation errors. The approximations for following the descent direction provided by the natural gradient are not suitable for NICE distribution due to its highly non-linear nature, resulting in spurious updates. The NICE model introduces non-linearities in the inverse transform to enhance optimization for GNNs in ES. However, high damping of the latent space parameters prevents the distribution from quickly concentrating when a minimum is found, hindering state-of-the-art performances. The text discusses adapting the damping parameter to avoid spurious updates in GNN distributions in an ES context. An alternated minimization scheme is proposed to address issues with natural gradient training. The roles of parameters \u03c9 and \u03b7 are separated to rewrite the objective function, focusing on the expected value of samples drawn from the latent distribution. The text introduces a new training algorithm that optimizes parameters \u03c9 and \u03b7 separately using alternating minimization. Samples are drawn from the NICE distribution with parameters \u03c9 and \u03b7 to optimize the latent space distribution parameters first, followed by the additive coupling layers parameters. The algorithm optimizes parameters \u03c9 and \u03b7 separately using alternating minimization. Samples are drawn from the NICE distribution to optimize latent space distribution parameters first, followed by the additive coupling layers parameters. The update of the latent space parameters is derived from the new representation of the initial objective. The coupling layers parameters are then optimized based on the available samples. Importance propensity scores are used to estimate expectations under the new parameters. The algorithm optimizes parameters separately using alternating minimization. The latent space is optimized by natural gradient descent, and the coupling layers via an off-policy objective with clipped propensity weights. The algorithm is named GNN-ES for Generative. The GNN-ES algorithm optimizes latent space using natural gradient descent and incorporates existing ES algorithms like xNES or CMA-ES. It improves ES algorithms by learning complex transformations on standard search distributions like the Gaussian. The GNN-ES algorithm enhances existing ES algorithms by incorporating a plug-in approach with a general algorithm. It addresses the issue of small sample sizes by augmenting the program with samples from past generations using the fused importance sampling estimator. This technique, common in reinforcement learning, is crucial for the problem at hand. Storing samples and their scores in a buffer allows for a meaningful transformation to be built by the GNN. The GNN-ES algorithm utilizes past samples to increase data exposure and reduce variance in the off-line estimator. To align the search distribution with the objective function's level sets, a mode-preserving property is imposed on the GNN's update step. The NICE model uses a mode-preserving property to ensure the GNN impacts only the tails of the search distribution, essential for evolutionary strategies. It employs three coupling layers with nonlinear mappings. The NICE model utilizes three coupling layers with nonlinear mappings, employing a one hidden layer MLP with 128 neurons and leaky ReLU activation functions. GNN-xNES trains a Gaussian latent distribution, enabling better exploration with curved density isolines. Visualizations on the Rastrigin function show the GNN's ability to lower barriers between local minima, facilitating escape to the global minimum. Experimental set-up includes experiments on unimodal and multimodal objectives for xNES and GNN-xNES using default hyper-parameters. The COCO platform is used for benchmarking black-box optimization algorithms, comparing xNES and GNN-xNES on functions from the BBOB suite with close initial search distributions for a fair comparison. The xNES algorithm configuration remains the same for standalone use or as an inner-optimization algorithm for GNN-xNES. Experimental details and additional hyper-parameters for GNN-xNES are provided. Performance is evaluated on two unimodal landscapes, the Rotated Rosenbrock function and the Bent Cigar function. Additional results on unimodal functions can be found in the appendix. Performance is measured using Empirical Cumulative Distribution Functions (ECDFs) of the runtime. We compare the performances of different algorithms on multimodal objectives using ES algorithms and restart strategies. Results are presented for benchmark functions in dimensions 2, 5, and 10. The Rastrigin, Griewank-Rosenbrock, and Schwefel functions are evaluated. Performance is measured through Empirical Cumulative Distribution Functions (ECDFs) of the runtime. ES algorithms for optimizing multimodal functions are often augmented with restart strategies to explore different parts of the landscape. A variety of restart strategies exist, and in the absence of a default one in the xNES implementation, a restart is triggered when no progress is made for more than 30 \u00d7 d iterations. This restart resets the search distribution's standard deviation to 1 and samples its mean uniformly within the defined X of interest. Additionally, the population size is doubled at each restart, following the approach of Auger & Hansen (2005). The algorithm size is doubled with a restart strategy used for xNES and GNN-xNES. Performance is measured by the number of function evaluations to find an objective value smaller than f(x*) + 10^-5 within a budget of d*10^5 evaluations. GNN-xNES outperforms xNES in discovering the global minimum faster on all objectives and dimensions. Additional results on multimodal functions are in Appendix E. ES algorithms have been used for direct policy search in Reinforcement Learning, achieving performances comparable to MDP-based techniques. The search for the optimal policy is done directly in parameter space to maximize the average reward per trajectory. The objective can be approximated from samples by rolling out M trajectories and optimized using ES. In experiments, deterministic linear policies were optimized, and results of GNN-xNES are reported. In this work, GNN-xNES algorithm outperforms xNES in Mujoco locomotion tasks Swimmer and InvertedDoublePendulum from OpenAI Gym. Results show GNN-xNES discovers high reward behaviors faster, leveraging bijective GNNs for improved Evolutionary Strategies. The algorithm proposed in this work, utilizing bijective GNNs with an ES objective, shows empirical advantages across various synthetic and RL objective functions. The role of expressiveness in exploration for optimization tasks is emphasized, with potential applications in MDP-based policy search methods. Future work could focus on optimizing GNN-based conditional distributions for RL tasks and investigating first-order and mixed oracles. The algorithm proposed in this work utilizes bijective GNNs with an ES objective, showing empirical advantages across various synthetic and RL objective functions. The pseudo-code for the generic algorithm GNN-A-ES is provided, with additional hyper-parameters including the horizon T and clipping constant \u03b5. The function clip(x, lb, ub) is used to clip input x between lower-bound lb and upper-bound ub. The algorithm utilizes bijective GNNs with an ES objective, with hyper-parameters such as horizon T and clipping constant \u03b5. The function clip(x, lb, ub) is used to constrain input x within bounds. The algorithm involves ES-based optimization of the latent space and gradient-based optimization of the GNN. Additional details on mode-preserving addition are provided, involving the mode of the latent distribution and a push-forward map on the NICE model. The algorithm utilizes bijective GNNs with an ES objective, involving ES-based optimization of the latent space and gradient-based optimization of the GNN. The push-forward map on the NICE model is used to update the latent space, ensuring the mode of the search distribution remains unaffected by the GNN update. Experimental details include the use of xNES with default hyper-parameters for baselines in GNN-xNES. The algorithm uses bijective GNNs with an ES objective and rank-based fitness shaping. Hyper-parameters for GNN-xNES are consistent across experiments. The history size is determined empirically. Synthetic objectives are taken from the BBOB2019 benchmark dataset. The algorithm uses bijective GNNs with an ES objective and rank-based fitness shaping. Hyper-parameters for GNN-xNES are consistent across experiments, with synthetic objectives from the BBOB2019 benchmark dataset. Details on RL environments used for comparison are provided in Table 1, including dimensions of state and action spaces, policy degrees of freedom, and maximum trajectory steps. Gaussian search and latent distributions are set to standard normal at the start of each experiment for xNES and GNN-xNES. The xNES algorithm's default population size is compared to GNN-xNES in discovering global minima on various synthetic functions. GNN-xNES accelerates xNES on some functions in lower dimensions but not in higher dimensions. Results are shown for the Attractive Sector, Rosenbrock, and multimodal Gallagher's Gaussian functions. In multimodal experiments, GNN-xNES outperforms xNES in discovering global minima with fewer restarts on the Rastrigin function. This demonstrates the effectiveness of GNN-xNES in leveraging the flexibility of the GNN to detect global minima missed by xNES. GNN-xNES consistently finds the global minimum with fewer restarts compared to xNES. Algorithm 2 can be applied to any ES method. Evaluations comparing GNN-CMA-ES and CMA-ES on the Rosenbrock function show improvement with GNN-CMA-ES, although the performance boost is less pronounced than with GNN-xNES. The use of evolution paths in CMA-ES for optimizing the latent distribution may conflict with GNN optimization, hindering its benefits. Future work could focus on designing a GNN update strategy that aligns with evolution paths. An ablation study was conducted on two additional tools introduced after the alternating optimization view. ECDFs curves were presented on various functions. Figure 13 shows ECDFs curves on the Rosenbrock, Rotated Rosenbrock, and Bent Cigar functions in 2D using a version of GNN-xNES that only considers the current population, while Figure 14 compares results with and without mode-preserving property in GNN-xNES. It is crucial to ensure that the GNN training does not impact the mode of the search distribution for optimization improvement."
}