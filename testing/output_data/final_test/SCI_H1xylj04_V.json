{
    "title": "H1xylj04_V",
    "content": "Capsule Networks have shown promising results on benchmark computer vision datasets like MNIST, CIFAR, and smallNORB. This paper introduces Siamese Capsule Networks for face verification tasks in controlled and uncontrolled settings, addressing challenges such as complex internal representations, few instances per class, and unsuitable point-wise classification. The model outperforms baselines in few-shot learning, indicating efficiency in learning discriminative representations with limited samples. Siamese Capsule Networks outperform strong baselines on pairwise learning datasets using contrastive loss with $\\ell_2$-normalized capsule encoded pose features. CNNs are effective at detecting local features but lose spatial relationships with pooling operations, leading to viewpoint invariance and loss of internal properties and relationships in images. The issue of preserving reference frames in human perception is addressed by Spatial Transformer Networks (STN) through dynamic spatial transformations on feature mappings to enhance geometric invariance. This approach aims to combat the loss of viewpoint information caused by pooling operations in CNNs. Capsule Networks address changes in viewpoint by removing rotational and scale variance, achieving translation equivariance. They have shown promising results in addressing these challenges and have been extended to pairwise learning for few-shot learning. Siamese Capsule Networks are trained using a contrastive loss. The Siamese Capsule Network uses whole vectors to represent internal properties of entities in images, with a dynamic routing scheme replacing pooling for preserving information and achieving equivariance. The Siamese Capsule Network utilizes dynamic routing to represent internal properties of entities in images through vectors, achieving translation equivariance and untangling coordinate frames. The architecture includes convolutional layers for initial input representations before routing to a final class capsule layer. The Siamese Capsule Network uses dynamic routing to represent internal properties of entities in images through vectors. Capsule inputs are determined using Iterative Dynamic Routing, with a transformation made to output vector u i of capsule C L i. The length of vector u i represents the probability that a lower-level capsule detected an object, and the direction corresponds to the object's state. The output vector u i is transformed into a prediction vector \u00fb j|i, weighted by a coupling coefficient c ij to obtain s j = i c ij \u00fb j|i. Coupling coefficients are determined by log prior probabilities from a sigmoid function and softmax. If \u00fb L j|i has high scalar magnitude when multiplied by u L+1 j, then the coupling occurs. The Siamese Capsule Network uses dynamic routing to represent internal properties of entities in images through vectors. Routing By Agreement is then performed using coincidence filtering to find tight clusters of nearby predictions, with the entities output vector length representing the probability of an entity being present. The capsule is assigned a high log-likelihood if densely connected clusters of predictions are found, and the centroid of the dense cluster is output as the entities generalized pose. This coincidence filtering step can also be achieved by traditional outlier detection methods such as Random sample consensus (RANSAC) and classical Hough Transforms. In this paper, a reconstruction loss on images was used for regularization to better encode entities, without using an autoencoding scheme. BID7 introduced matrix capsules for routing by agreement using the EM algorithm, inspired by computer graphics for handling viewpoint changes. Each parent capsule is treated as a Gaussian, with child capsules' pose matrices as data samples. The network uses a Gaussian model for capsules, with pose matrices as data samples. Capsules in a layer contain pose matrices and activations as outputs. Votes are made based on learned transformation matrices. Costs are calculated based on negative log-probability density and assignment probabilities. Inverse temperature affects assignment probabilities. The matrix capsule network outperformed CNNs on the SmallNORB dataset. SegCaps uses dynamic routing to reduce parameters and deconvolutional capsules for segmenting pathological lungs. Spectral Capsule Networks show faster convergence for medical diagnosis using spatial coincidence filters. Spatial coincidence filters align features on a 1-d linear subspace in the architecture, which includes a 1d convolution and 3 residual layers with dilation. Residual blocks are used for nonlinear transformations in healthcare imaging. Weighted votes are obtained and decomposed using SVD to capture variance. The model is trained by maximizing log-likelihood, showing better performance than spread loss used with matrix capsules. The proposed capsule routing strategy in BID31 improves performance by optimizing a clustering loss and KL regularization term. It outperforms the original routing scheme as routing iterations increase. The novelty lies in the pairwise learning capsule network scheme, introducing a different loss function and architecture for comparing and aligning images while measuring similarity. The current state of the art work in face verification involves Siamese Networks that learn relationships between encoded representations of instance pairs on a low dimensional manifold. BID27 presented a joint identification-verification approach for face verification and recognition using contrastive and cross-entropy loss functions to balance signals for both tasks. The study investigates the effects of varying weights controlled by \u03bb on intra-personal and inter-personal variations in face recognition. Optimal results are found when \u03bb = 0.05, maximizing intra personal variation while distinguishing between classes. BID32 proposes a center loss function to improve discriminative feature learning in face recognition by minimizing intra-class variation and keeping features separable. BID18 introduced Sphereface, a hypersphere embedding with an angular softmax loss for face recognition. Achieving high accuracy on the LFW dataset, it also showed competitive results on YTF and MegaFace. BID25 proposed a triplet similarity embedding using a triple loss function for face verification. BID9 utilized deep metric learning with a specific loss function for face verification. The loss function in face recognition involves logistic loss and regularization on parameters. SIFT descriptors, dense SIFT, and LBP achieve high accuracy on the LFW dataset. BID21 and this work use a 2-constraint on face features for improved performance. FaceNet BID26 utilizes a triplet network combining Inception and a 8-layer convolutional model for face verification, recognition, and clustering. The method trains a network on triplets for face verification, recognition, and clustering, using a Siamese Inception Network. Siamese Networks like DeepFace achieve human-level performance on the LFW dataset, utilizing transfer learning from a large dataset. Manual steps are taken for detecting, aligning, and cropping faces, with normalization to avoid illumination differences. The 3D model creation process involves identifying fiducial points in the image, cropping faces, and applying a piecewise affine transformation. The cropped image is then passed through 3 CNN layers without max pooling. The proposed SCNs only require pixel normalization and image resizing as preprocessing steps. Various CNN models achieve state-of-the-art results for face verification, some pretrained on related datasets. The Capsule Network for face verification aims to improve similarity measures by identifying part-whole relationships of facial features and poses. It consists of a 5-hidden layer network with tied weights, including 2 capsule layers. The first layer is a convolutional filter with 256 channels and the second layer is the primary capsule layer. The Capsule Network for face verification consists of 5 hidden layers with tied weights, including a primary capsule layer for facial feature routing. Different distance measures are used for capsule image encodings, and the architecture varies for different datasets. The Capsule Network for face verification uses different routing iterations for different datasets. Paired images are encoded into vector pairs using capsule pose vectors. A fully connected layer with 20 activation units is used to create a 20-dimensional representation. Dropout probability rates are learned for each capsule to keep them active. The logit function learns the dropout rate of the final capsule layer using Concrete Dropout. The Capsule Network for face verification uses different routing iterations for different datasets. Dropout probability rates are learned for each capsule to keep them active. The sigmoid function computes relaxation on the Bernoulli variable for dropout, with temperature values forcing probabilities at the extremum when small. Weight regularization and dropout entropy terms are used for regularization in the final layer. Weight regularization of 0.1 is chosen based on experiments. In experiments, weight regularization of 0.1 is chosen based on grid search. A straight-through pathwise derivative estimator is used to optimize dropout probability. Capsule encoding similarity function outputs a predicted similarity score for contrastive margin loss. This ensures similar pose encodings are drawn together and dissimilar poses are separated. Loss L c ensures similar pose encodings are drawn together and dissimilar poses repulse. Equation 4 shows a pair of images passed to the SCN model where Euclidean distance is computed between encodings with a margin m. A double-margin contrastive loss is used to separate matching and non-matching pairs, with positive margin m p and negative margin m n. This loss is specifically used for LFW dataset due to limited instances in AT&T. In experimentation, overlap between pairs is less severe. The original reconstruction loss is not used in pairwise learning, relying on dropout for regularization. The SCN model uses concrete dropout on the final layer. Optimization convergence can be slow for face verification tasks, but AMSGrad improves adaptive learning rates over ADAM in some cases. AMSGrad improves adaptive learning rates over ADAM by utilizing a maximum instead of an exponential average of squared gradients, maintaining long-term memory of past gradients. This prevents divergent or vanishing step sizes over time. The AT&T dataset for face recognition consists of 40 subjects with 10 images each, allowing testing with limited data. LFW dataset contains 13,000 colored faces for further evaluation. The LFW dataset contains 13,000 colored faces from the web, with 1680 subjects and images resized to 100x100. Two versions of the dataset align images using different methods, showing improvements in face verification tasks. This addresses issues with pose, orientation, and Capsule Networks. The AT&T dataset is used for few-shot learning in face verification with limited instances and grey-pixel images. LFW dataset has colored images in an unconstrained setting with imbalanced classes. SCNs are compared against AlexNet, ResNet-34, and InceptionV3 for image recognition and verification tasks. Best results are obtained using contrastive loss with Euclidean distance between encodings. The AT&T dataset is used for few-shot learning in face verification with limited instances and grey-pixel images. LFW dataset has colored images in an unconstrained setting with imbalanced classes. SCNs outperform baselines on the AT&T dataset after training for 100 epochs, with adapted dropout rates and additional reconstruction loss affecting performance. The SCN and AlexNet show the best results on the LFW dataset, with SCN having 25% fewer parameters. The LeNet SCN performs better with a double margin but slightly worse with concrete dropout on the final layer. SCN demonstrates faster convergence on the AT&T dataset with Manhattan distance, while Euclidean distance shows improved overall performance. Batch normalized convolutional layers enhance SCN performance. Batch normalization in the SCN model allows the network to adjust input range diffusion. It reduces variance in loss during training on AT&T and LFW datasets. The SCN model takes longer to converge compared to AlexNet, especially in early training stages. Accuracy is computed using margins to separate positive and negative instance pairs, with lower prediction variance and higher precision than other models. The Siamese Capsule Network model has lower prediction variance and higher precision compared to other models, particularly for Manhattan distance. It has fewer parameters than AlexNet, Resnet-34, and LeNet baseline. However, Capsule Networks are limited in speed due to routing iterations. The model introduces a novel architecture for pairwise learning with a contrastive loss function that maximizes inter-class variance and minimizes intra-class variance. Capsule Networks perform better at few-shot learning with a contrastive loss that maximizes inter-class variance and minimizes intra-class variance. Siamese Capsule Networks excel on the AT&T dataset for unseen classes, while remaining competitive on the Labeled Faces In The Wild dataset."
}