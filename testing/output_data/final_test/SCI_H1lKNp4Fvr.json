{
    "title": "H1lKNp4Fvr",
    "content": "Stereo matching is a crucial task in computer vision, with recent advancements in deep learning algorithms showing great performance. This paper introduces a shallow feature extraction network with a large receptive field, focusing on retaining detailed spatial structure information. The network includes a primary feature extraction module, an atrous spatial pyramid pooling (ASPP) module, and a feature fusion module, utilizing only three convolution layers to extract and preserve spatial details effectively. The paper introduces a shallow feature extraction network with dilated convolution and ASPP module to increase the receptive field size. A feature fusion module integrates multiscale receptive fields for improved feature information. State-of-the-art performance on the KITTI 2015 dataset was achieved with 42% fewer parameters and 1.9% higher matching accuracy compared to the reference network. Increasing network depth is crucial for improving feature extraction ability in computer vision tasks. Increasing network depth is crucial for improving feature extraction ability in computer vision tasks. Deep networks like AlexNet, VGG, and ResNet constantly improve classification accuracy by extracting more abstract features important for tasks like object detection and classification. The deep feature extraction network can extract abstract semantic information and obtain a larger receptive field to learn more. Stereo matching, a basic vision task, relies on basic feature information rather than high-level abstract features. Traditional stereo matching algorithms use color similarity metrics to calculate matching costs. The deep feature extraction network increases the receptive field to learn more context information, with the ability to extract primary features in lower layers and abstract semantic information in higher layers. In stereo matching, deep learning has improved feature extraction for better performance. Algorithms like GC-Net, PSMNet, and GwcNet follow similar processes including feature extraction, matching cost volume construction, 3D convolution, and disparity regression. The focus is on enlarging the receptive field to obtain more context information critical for the task. The focus in stereo matching is on enlarging the receptive field to obtain more context information critical for solving mismatching problems in discontinuous disparity areas. Maintaining more details of the spatial structure can improve matching accuracy for small structures like railings, chains, and traffic signs. Existing feature extraction networks use deep convolutional neural networks to extract abstract semantic information, but this process may lead to loss of substantial detailed spatial information. This paper proposes a shallow feature extraction network with 3 convolution layers to preserve detailed spatial structure for improving stereo matching accuracy. The network focuses on primary features like edges and corners while sacrificing abstract semantic information. The paper introduces the atrous spatial pyramid pooling (ASPP) module to increase the receptive field size without adding parameters. It uses dilated convolution for multiscale receptive fields, addressing context information and stereo matching accuracy. The feature fusion module integrates these feature maps with different dilation rates. The paper introduces a feature extraction network with different dilation rates in channel dimensions to improve stereo matching accuracy. The network retains spatial structure details while reducing parameters and training difficulties. It outperforms existing networks on the KITTI2015 dataset. The paper proposes a shallow feature extraction network to improve stereo matching accuracy on the KITTI2015 dataset. It introduces dilated convolution and ASPP module to enlarge the receptive field and a feature fusion module for integrating feature maps with multiscale receptive fields. Deep learning methods have become the mainstream in stereo matching algorithms. The GC-Net introduced a new stereo matching algorithm process based on deep learning, including feature extraction, matching cost volume construction, 3D convolution, and disparity regression. Most stereo matching algorithms now follow the process of GC-Net, with improved schemes for feature extraction networks. In recent years, improved schemes for feature extraction networks have been introduced. PSMNet deepened the network structure using ResNet-50 and SPP module. GwcNet retained the structure but introduced a new method for matching cost volume. MCUA incorporated DenseNet's densely connected structure. Stereo-DRNet introduced the vortex pooling structure. In 2019, a new feature extraction network called CFPNet was proposed, incorporating a cross form spatial pyramid pooling module. This network combines SPP and ASPP structures to extract feature information at different scales. Unlike existing stereo matching networks using ResNet-50, a shallow feature extraction network called SWNet was introduced with a larger receptive field and fewer parameters, achieving higher matching accuracy. The SWNet is a shallow feature extraction network with a large receptive field, consisting of the primary feature extraction module (PFE), atrous spatial pyramid pooling (ASPP) module, and feature fusion module (FFM). The network architecture includes three convolution layers with a kernel size of 3*3, followed by batch normalization and ReLU layers. The ASPP module is added to the PFE module to increase the receptive field size. The ASPP module, inspired by Deeplab v2, incorporates dilated convolution layers with different dilation rates to form four parallel branches with varying receptive fields. The outputs from these branches are fused using a feature fusion module, assigning specific weights to each feature map. This process enhances the network's ability to capture multiscale information. The feature map group is converted into a 1D feature vector by global average pooling and a bottleneck structure is used to limit parameters. Weight coefficients for each channel are obtained using a sigmoid function. The bottleneck structure consists of two 1*1 convolution layers and a ReLU activation layer. The PFE module generates feature maps which are concatenated with weighted feature maps through skip connections. Finally, fusion feature maps are obtained by compressing the number of channels to 32 using two 3*3 convolution layers. In this paper, a feature extraction network is designed to replace the feature extraction part of stereo matching algorithms PSMNet and GwcNet. The network, SWNet-P and SWNet-G, utilize shift and concatenation operations for matching cost volume construction. Experiments focus on the depth of the feature extraction network, receptive field size, and multiscale receptive fields' impact on stereo matching. The implementation details of the feature extraction network SWNet are discussed in different sections, including comparing shallow and deep networks, testing receptive field size, evaluating the ASPP module parameters, and comparing stereo matching results with other algorithms on the KITTI dataset using Pytroch for implementation. The Adam method with specific parameters is used for end-to-end training. The model is trained using the Adam method with specific parameters for end-to-end training. Training images are cropped to 512x256 and normalized to [-1,1]. Maximum disparity is set to 192. Training is done for 10 epochs on SceneFlow dataset and 300 epochs on KITTI 2015 dataset with a pretrained model. Evaluation is based on EPE for SceneFlow and 3-pix error for KITTI 2015. Model training is done on an NVIDIA 1080Ti GPU with a batch size of 3. This paper uses two open datasets for network training and testing. SceneFlow dataset contains 35454 training images and 4370 test images with dense disparity maps as ground truth. Another stereo dataset contains 200 training images and 200 test images with sparse disparity maps provided for training. The paper explores the impact of varying the depth of the feature extraction network on stereo matching accuracy by modifying the backbone of reference networks. Different structures like PSMNet and GwcNet were compared with the proposed feature extraction network. Results show that increasing the backbone from 34 layers to 50 layers improves performance. Increasing the depth of the feature extraction network from 34 to 50 layers improved the performance on the SceneFlow dataset, reducing End-point-error (EPE). However, adopting the ResNet-101 structure led to a decrease in stereo matching accuracy for GwcNet. SWNet showed comparable or better matching accuracy with fewer parameters than the default structure. The shallow feature extraction network with fewer parameters is more suitable for stereo matching tasks. Dilated convolution enlarges the receptive field but may lead to some input neurons failing. The concepts of theoretical receptive field (TRF) and effective receptive field (ERF) are proposed to address this issue. The effective receptive field in a neural network excludes invalid neurons and is calculated based on kernel size, dilation rate, and stride. Mathematical methods for both theoretical and effective receptive fields are provided, along with a visualization experiment to demonstrate the impact of dilated convolution. The concept of the density of the receptive field is introduced to describe the relationship between theoretical and effective receptive fields in a neural network. The size of the theoretical receptive field increases with the dilation rate, reaching 16 times the size of ordinary convolution at a dilation rate of 12. The effective receptive field size reaches 33*33 before stabilizing, with a rapid decrease in the density of the receptive field. The dilation rate affects the size of the receptive field in a neural network. An experiment demonstrates this visually. Neurons in different network levels are compared to receptors and nerve centers. Stimuli are applied to pixels to detect changes in high-level neurons, determining their relationship to input neurons. The dilation rate affects the size of the receptive field in a neural network. The experiment visually shows the correlation between input neurons and high-level neurons. The receptive field size increases with the dilation rate, but cavities appear when the rate exceeds 6, growing rapidly with further increases. The ASPP module and feature fusion module are used to compensate for cavities in the receptive field by fusing convolution layers with different dilation rates. Ablation experiments show that introducing dilated convolution and ASPP module effectively enlarges the receptive field, improving stereo matching performance. The ASPP module and feature fusion module effectively enlarge the receptive field and improve stereo matching accuracy. The EPE of SceneFlow dataset decreases from 0.931 to 0.859. Dilated convolution enlarges the theoretical receptive field but may lead to information loss. ASPP and feature fusion modules solve this issue by fusing feature maps with multiscale receptive fields, providing more context information and improving matching accuracy in ill-posed regions. The ASPP module experiments focused on dilation rate and number of branches. Results showed improved stereo matching accuracy with more branches. Dilation rate of base 3 outperformed base 2. In experiments with the ASPP module, a dilation rate of [2, 4, 6, 8] in the KITTI 2015 dataset achieved the best performance with a 3-pixel error of 1.58%. Adding branches to the ASPP module allows for more receptive fields with different scales, extracting detailed structural information and context information. SWNet results were uploaded to KITTI and showed the lowest matching error compared to other stereo matching algorithms on the leaderboard. SWNet achieved the lowest matching error among stereo matching algorithms on the KITTI 2015 leaderboard, reducing error rates compared to PSMNet and GwcNet. The shallow feature extraction network with a large receptive field improved accuracy while reducing network parameters, making training and deployment easier. The network's processing speed is dependent on the computing platform used. The improved stereo matching algorithm SWNet achieved the lowest matching error on the KITTI 2015 leaderboard, outperforming PSMNet and GwcNet. It retains detailed structural information for better matching in specific areas and maintains high accuracy on large-scale objects. The processing speed is slightly slower compared to the reference network. The paper proposes a novel network structure for stereo matching, utilizing a shallow network with ASPP module for multiscale receptive fields. Feature fusion resolves information loss from dilated convolution, resulting in a large receptive field for better feature extraction with fewer parameters. The SWNet improves stereo matching accuracy by replacing the feature extraction part of the network. A simplified 1D neural network is used to explain the calculation process of receptive fields. In layer 2, the receptive field size is calculated accounting for overlaps between neurons. The number of neurons in the overlapping part is determined by kernel size and convolution stride. As the number of convolution layers increases, the impact of convolution stride accumulates. For dilated convolution, the receptive field size is adjusted accordingly. The theoretical receptive field size of a neuron in layer n is calculated for dilated convolution by modifying the kernel size. The paper focuses on cases where the convolution stride is smaller than the kernel size. Invalid neurons, which do not transmit information from low-level neurons, are identified in layer 3. The maximum number of continuous invalid neurons in layer 2 is determined by the dilation rate of layer 3. The connection relationship between network layers introduces the concept of exclusive neurons in layers 0-1. The paper introduces the concepts of exclusive subneurons and shared subneurons in network layers. Exclusive subneurons are the only sub-neurons connected to a neuron in the next layer. The number of exclusive subneurons of a neuron in layer n can be calculated. A non-negative constraint is added to the formula to ensure a minimum value of 0. If a neuron in layer n fails, it directly leads to the failure. If one neuron in layer n fails, it will lead to the failure of N n subneurons in layer (n-1). Shared subneurons are connected to multiple neurons in higher layers. The calculation method for the number of invalid neurons in layer (n-1) is provided. The number of invalid neurons in layer n can be directly caused by dilated convolution. Neurons in layer n are calculated as p n = d n+1 \u2212 1. The number of invalid neurons in layer 2 is p 2 = d 3 \u2212 1 = 5 \u2212 1 = 4. The sizes of invalid neurons in layer 1 and 0 are p 1 = 4 \u00d7 (0 + 1) \u2212 3 + 1 = 2 and p 0 = 2 \u00d7 (1 + 1) \u2212 2 + 1 = 3. The effective receptive field size is the theoretical receptive field size minus the number of invalid neurons in layer 0. Calculation method is shown in formula (17) r n = r n \u2212 p 0 (k n \u2212 1) B. ReLU denotes the activation layer, H denotes the height of the image, W denotes the width of the image. Concat stands for the concatenation operation of feature maps, and SElayer stands for assigning weights to each feature map."
}