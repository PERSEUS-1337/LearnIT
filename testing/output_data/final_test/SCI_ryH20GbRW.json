{
    "title": "ryH20GbRW",
    "content": "Common-sense physical reasoning is crucial for intelligent agents in the real world, enabling them to simulate environments and infer unobserved states. A novel unsupervised method learns to discover objects and model their interactions from raw visual images efficiently by incorporating prior knowledge of human perception. This approach outperforms other unsupervised neural methods on videos of bouncing balls, demonstrating superior modeling capabilities, handling occlusion, and extrapolating knowledge to scenes with varying object numbers. Common-sense physical reasoning is essential for intelligent agents to understand and interact with the world. Humans rely on this reasoning to predict outcomes, infer unobserved states, and decompose visual scenes into objects for reasoning about their interactions and dynamics. Intelligent agents can benefit from incorporating prior knowledge of objects as primitives in a compositional system for common-sense physical reasoning. Machine learning approaches to common-sense physical reasoning incorporate prior knowledge by maintaining explicit object representations for learning general physical dynamics between object pairs. While supervised approaches rely on external object representations, unsupervised neural approaches model motion or physical interactions in pixel space. However, these methods lack compositionality at the object representational level, hindering efficient learning of functions operating on multiple entities in a human-like way. In this work, we introduce Relational N-EM (R-NEM), a novel approach to common-sense physical reasoning that learns interactions between objects from visual images in an unsupervised manner. By combining Neural Expectation Maximization (N-EM) with a relational mechanism, R-NEM can model interactions between object pairs, generalize to scenes with varying objects, and learn common-sense reasoning directly from visual observations. The structure of a visual scene can be represented using Neural Expectation Maximization (N-EM) and its extension, Relational N-EM (R-NEM), which learns separate distributed representations for each object in an unsupervised manner. This approach allows for modeling interactions between object pairs and enables common-sense reasoning directly from visual observations. Neural Expectation Maximization (N-EM) is a clustering method that learns representations of objects in a visual scene. These representations are used as primitives in a compositional system and form a representation of the visual scene in an unsupervised manner. Neural Expectation Maximization (N-EM) aims to group pixels belonging to the same object efficiently in a distributed representation. It utilizes Expectation Maximization to compute a Maximum Likelihood Estimate of object parameters, learning a statistical model of images through a neural network. Neural Expectation Maximization (N-EM) groups pixels into object representations using a spatial mixture model parameterized by vectors. A neural network transforms these representations into pixel-wise distributions. Binary latent variables encode pixel assignments, and a function computes interactions between object representations. The function R-NEM computes pair-wise interactions between object representations using generalized EM, which consists of E-step and M-step iterations to update object representations. The unrolled computational graph of the generalized EM steps is differentiable, allowing for training f \u03c6 to model images based on object representations. Back-propagation through time is used to minimize a loss function, with intra-cluster and inter-cluster terms ensuring accurate pixel representation. RNN-EM enhances N-EM by using a recurrent neural network with hidden state \u03b8 k. The learning objective may lead to trivial solutions. The learning objective in (3) can lead to trivial solutions in overcapacity situations, hindering the network from capturing statistical regularities in data related to objects. Adding noise to input images or reducing dimensionality can help guide learning to avoid this issue. RNN-EM, unlike N-EM, can capture individual object dynamics through a recurrent connection operating on object representations across time-steps. Using denoising or next-step prediction in training objectives helps the network learn essential object properties, such as those related to Gestalt Principles like pr\u00e4gnanz and common fate. Relational N-EM (R-NEM) adds relational structure to the recurrence of RNN-EM to model interactions between objects without violating key properties of object representations. It computes the object representation at time t as a function of all object representations at the previous time-step through an interaction function. This dynamics model can recover the original RNN-EM update rule. The dynamics model in R-NEM incorporates an inductive bias in \u03a5 to reflect assumptions about object interactions. Depending on the assumptions made, the \u03b8 k 's can be fully independent or interdependent. If interactions are assumed but little is known about the interdependence structure, useful properties like compositionality may be lost. Efficient use of compositionality among learned object representations can guide constraints on how they are incorporated. The proposed model incorporates constraints on learned object representations to capture interdependence between objects in a compositional manner. A parametrized interaction function is used to update the representations based on pairwise effects, enabling efficient learning of physical dynamics and extrapolation to a variable number of objects. The proposed model uses a shared embedding to encode interactions between objects, computes the effect of one object on another, and uses attention coefficients to select relevant context objects. This approach allows for efficient learning of physical dynamics and can be seen as a more flexible unsupervised method compared to previous distance-based heuristics. The former group uses symbolic approaches with a physics engine in synthetic environments, while the latter group employs machine learning for state-to-state predictions. Incorporating object information has led to excellent generalization and simulation capabilities. Unsupervised approaches using raw visual inputs have not matched these capabilities yet. Our method is an unsupervised state-to-state prediction in pixel space, a step towards common-sense unsupervised learning. The proposed interaction function R-NEM is a type of Message Passing Neural Network that incorporates neighborhood attention. It relies on N-EM to discover object representations from raw visual inputs. TAG framework is a related approach that performs inference over group representations. The proposed R-NEM interaction function is a Message Passing Neural Network that uses neighborhood attention to discover object representations from visual inputs. It is evaluated on physical reasoning tasks involving bouncing balls with variable mass, invisible curtains, and the Arcade Learning Environment, compared to other approaches. R-NEM is compared to other unsupervised neural methods in physical reasoning tasks involving bouncing balls with variable mass, invisible curtains, and the Arcade Learning Environment. Experiments use ADAM with default parameters on train, validation, and test sequences. Neural networks with specific architectures are used for different components. A detailed experimental setup is provided in the appendix. R-NEM computes new representations and group reconstructions to predict the environment state at each time-step. Attention coefficients are visualized to compute new soft-assignments for prediction accuracy. Performance on the bouncing balls task is compared with other methods. Performance of different methods on the bouncing balls task is evaluated using ARI score. R-NEM is trained on sequences of 64x64 binary images with four bouncing balls, showcasing physical reasoning capabilities. After training on sequences of 64x64 binary images with bouncing balls, R-NEM demonstrates physical reasoning capabilities by accurately reconstructing the input sequence at the next time-step. The representation \u03b8 k ensures that each component contains information about a unique object, resulting in a compositional object representation of the scene. R-NEM shows physical reasoning by accurately reconstructing input sequences of bouncing balls. It outperforms other methods in terms of loss and compositionality, as validated by the Adjusted Rand Index score. R-NEM achieves an ARI score of 0.8, indicating that each ball is modeled by a single component in 80% of cases. Increasing the number of components during training improves grouping quality and reduces loss, supporting the hypothesis of compositional object representations. Extrapolating learned knowledge from physical interactions between four balls to environments with more balls, R-NEM outperforms all other methods when evaluated on a test-set with 6-8 balls. LSTM shows worse performance relative to the baseline when tested with extra balls, indicating the importance of compositional object representations. The LSTM's gating mechanism allows it to learn a specialized solution for sequences with four balls, but it does not generalize well to datasets with 6-8 balls. R-NEM and RNN-EM scale better to datasets with more balls than LSTM, with RNN also showing some overfitting. The superior extrapolation capabilities of RNN-EM and R-NEM are attributed to their ability to factor scenes in terms of permutation invariant object representations. Visualizing attention coefficients provides further insight into the role of the attention mechanism. The attention mechanism in R-NEM is visualized by drawing \u03b1 k,i * \u03c8 i on top of the reconstruction \u03c8 k, colored according to the component i. The attention coefficient becomes non-zero during collisions, lighting up colored balls in subsequent time-steps. Comparing R-NEM to a variant without attention shows similar performance on the regular test set. The attention mechanism in R-NEM is visualized by drawing \u03b1 k,i * \u03c8 i on top of the reconstruction \u03c8 k, colored according to the component i. Comparing R-NEM to a variant without attention shows similar performance on the regular test set. Both methods perform equally well on the regular test set (4 balls), but R-NEM performs worse at extrapolating from its learned knowledge (6-8 balls) due to changes in the sum range with K. Simulation capabilities of R-NEM are compared to RNN-EM and an RNN on the bouncing balls environment, showing accurate simulation by R-NEM. The R-NEM model accurately simulates the environment, preserving the shape and position of balls. In contrast, the RNN model deviates from the ground-truth position and increases the size of the balls. R-NEM consistently outperforms the RNN in simulation performance, especially when handling cases where a single component models multiple balls. The ability of R-NEM to handle hidden factors is crucial for physical reasoning systems. The R-NEM model demonstrates superior simulation performance, accurately modeling object states even in the presence of occlusion. It shows object permanence by predicting the re-appearance of occluded objects correctly. This implies a deeper understanding of scenes beyond pixels, assigning persistence and identity to objects. The R-NEM model accurately models object states, including interactions and occlusions. It demonstrates object permanence by predicting occluded objects' re-appearance, showing a deeper understanding of scenes beyond pixels. R-NEM accurately models sequences of frames from Space Invaders, showing high-level entities with similar movement patterns. It outperforms RNN and LSTM in test-set performance. When tested on visually challenging environments, R-NEM trained on 84x84 binarized images over 25 time-steps of gameplay accurately models the environment, even with increased visual complexity. R-NEM, trained with four components, groups pixels based on movement in Space Invaders. It assigns different groups to columns of aliens and shields, while bullets and the spaceship are grouped less frequently due to environmental noise and small size. The ability to perceive objects and their interactions is crucial for common-sense physical reasoning, supported by evidence from cognitive science and developmental psychology. R-NEM incorporates inductive biases about objects and interactions, allowing for efficient learning from visual observations. R-NEM captures physical dynamics accurately and generalizes well to environments with different object numbers. It can simulate environments, predict object movement and collisions even when objects are occluded, demonstrating object permanence. The behavior of R-NEM aligns with infants' expectations of object interactions, showing a step towards a more human-like model of the world. Our method aims to create a more human-like model of the world through unsupervised learning. Limitations include the variability in how humans group aspects of a scene based on the task at hand, the need for top-down feedback to facilitate dynamic grouping, incentivizing useful groupings in R-NEM, and the difficulty in increasing the number of components above ten in the grouping procedure. The E-step in R-NEM and RNN-EM is challenging due to the multitude of interactions and objectives, making training difficult. Objects behaving unpredictably pose a challenge, but masking input helps components adapt. A limitation is the hindrance in modeling complex backgrounds due to the second loss term in the training objective. The ability to engage in physical reasoning benefits intelligent agents operating in physical environments, leading to future research opportunities. Future work will explore incorporating top-down feedback in R-NEM for dynamic groupings and how compositional representations can aid reinforcement learning. Training networks using ADAM with default parameters and batch size of 64. The quality of learned groupings is evaluated using the Adjusted Rand Index (ARI) with default parameters and a batch size of 64. The bouncing balls data consists of sequences of binary images with two types of balls, one heavier and larger than the other. A convolutional encoder-decoder architecture with a recurrent neural network is used for processing the data."
}