{
    "title": "Hkem-lrtvH",
    "content": "Black-box adversarial attacks often require many attempts to find visually indistinguishable adversarial examples. A new query-efficient black-box attack using Bayesian optimization and model selection achieves comparable success rates with fewer queries compared to previous methods. This approach is suitable for real-world systems with limited query capabilities. In real-world scenarios, black-box adversarial attacks are a growing concern due to the potential for model failures. This paper focuses on practical attacks that are designed for black-box settings and prioritize query efficiency. The goal is to assess the robustness of deep learning models against such attacks and their ability to detect them. In practical cases, query efficiency is crucial for adversarial attacks. Many attacks assume full access to the target model, while black-box attacks use techniques that do not require access to the model architecture. One approach involves training a white-box substitute model to fool the target model with adversarial examples. Black-box attacks on target models involve estimating gradients numerically through repeated queries, showing better empirical performance than substitute model approaches. These attacks require a large query budget for successful execution. Another approach uses decision-based techniques or genetic algorithms to bypass gradient estimation. The text discusses the need for gradient estimation in black-box attacks and the use of decision-based techniques or genetic algorithms to generate adversarial examples. A popular technique is to search for adversarial perturbations in a low-dimensional latent space to improve query efficiency. The proposed BayesOpt attack is a novel gradient-free black-box attack method that optimizes over both the adversarial perturbation and the effective dimensionality of the latent search space. The BayesOpt attack is a novel gradient-free black-box attack method that uses Bayesian optimization with Gaussian process surrogate models to find effective adversarial examples in high-dimensional image inputs. It incorporates a Bayesian technique to learn the optimal degree of search dimensionality reduction, leading to efficient optimization over both adversarial perturbation and latent search space dimension. Empirical results show that this attack method achieves comparable success rates with fewer model queries compared to current state-of-the-art query-efficient black-box attack methods. In black-box settings, attackers have no knowledge of the target model and can only observe input-output correspondences. One approach is to train a substitute model using data acquired from querying the target model, mimicking its behavior. This substitute model can then be attacked using white-box methods, and the successful adversarial examples can be applied to the target model. In black-box settings, attackers train a substitute model using data from the target model to mimic its behavior. Adversarial examples effective on the substitute model can then be applied to the target model. Gradient estimation can be used as an alternative to training a substitute model for producing attacks. The naive coordinate-wise gradient estimation for producing attacks is not feasible for high-dimensional input models. Chen et al. (2017) introduced the state-of-the-art zeroth-order attack, ZOO, which uses stochastic coordinate gradient descent and importance sampling. While ZOO makes black-box attacks on high-dimensional image data computationally tractable, it still requires millions of queries to generate successful adversarial examples. AutoZOOM (Tu et al., 2018) improves on ZOO significantly. AutoZOOM enhances query efficiency by using random vectors to estimate the gradient and adjusting the estimation parameter adaptively. It employs dimension reduction techniques to accelerate attacks by searching for adversarial perturbations in a low-dimensional space. Ilyas et al. use a modified natural evolution strategy to estimate the gradient and generate adversarial examples using projected gradient descent. Gradient-free optimization methods are discussed as alternatives to gradient-estimation approaches. Gradient-estimation approaches require many queries and are less robust to defenses. GenAttack is a gradient-free method that uses genetic algorithms for query efficiency. Boundary Attack is a decision-based attack that starts with a large perturbation and iteratively reduces it. Boundary Attack is a method that reduces perturbation iteratively through a random walk along the decision boundary. It requires significantly more queries than GenAttack to fool an undefended ImageNet model. Other recent approaches focus on discrete domain search and combinatorial optimization for successful attacks, while prior works using Bayesian optimization are limited in performance. In comparison to random search, Bayesian optimisation is evaluated for a low-dimensional email attack task. BO-ADMM, proposed in Zhao et al. (2019), applies Bayesian optimisation directly on image data to minimize attack and distortion losses. Despite query efficiency, BO-ADMM results in poor-quality adversarial examples with large distortion loss. The focus is on black-box attacks, where the adversary has no knowledge of the target model's architecture, weights, or training data, only querying the model for prediction scores. Targeted attacks are performed subject to a constraint on maximum coordinate changes. In targeted adversarial attacks, the goal is to find an adversarial input close to the original input according to a specified norm. Untargeted attacks aim to find an input that is classified differently from the original input. The problem is formulated as optimizing over the perturbation instead of the adversarial example directly. Bayesian optimization is a query-efficient approach for global optimization problems. Bayesian optimization is a query-efficient approach for global optimization problems, particularly useful for black-box objective functions. It involves a statistical surrogate like a Gaussian process or Bayesian neural network, along with an acquisition function for recommending the next query location. Reducing the dimensionality of the search space has been shown to increase query efficiency significantly. In Bayesian optimization, dimensionality reduction using bilinear resizing is adopted to optimize over a low-dimensional input space. The objective function is smoothed to improve optimization, leading to a blackbox objective problem for Bayesian optimization. A Gaussian process is used as a surrogate to solve the black-box attack objective in the reduced input dimension. In Bayesian optimization, dimensionality reduction is used with bilinear resizing to optimize over a low-dimensional input space. The objective function is smoothed for a blackbox problem, and a Gaussian process is used as a surrogate to solve the objective in the reduced input dimension. The Matern-5/2 kernel is utilized, and the predictive posterior distribution is used to construct an acquisition function for selecting the next query point. The optimal GP hyper-parameters can be learned by maximizing the marginal likelihood. The use of BayesOpt with a GP surrogate for attacking the target model is described in Algorithm 1. Despite reducing the input dimension with techniques like bilinear resizing, the search space for the adversarial attack remains high dimensional, posing challenges for GP-based BayesOpt due to the curse of dimensionality in modelling the objective function. The computational challenges in optimizing the acquisition function for adversarial perturbation in high-dimensional spaces are addressed by adopting the additive-GP model. The key assumption is decomposing the objective into low-dimensional composite functions, utilizing GP priors for each subspace to learn the exact decomposition. The acquisition function for adversarial perturbation is optimized by learning input dimension subspace relationships. The perturbations in subspaces are combined to find the next query point efficiently. The practice of generating successful adversarial examples in reduced dimensions has shown significant query efficiency improvement. However, determining the optimal reduced dimension and how to decide it efficiently remains unexplored in previous work. The optimal reduced dimension for adversarial attacks is crucial for query efficiency and attack success. A method is proposed to learn the optimal dimension by maximizing the posterior using a statistical surrogate model. This approach considers prior knowledge on dimension choices and explains observed query data effectively. The approach proposed involves maximizing the posterior using a statistical surrogate model to learn the optimal reduced dimension for adversarial attacks. The method considers prior knowledge on dimension choices and effectively explains observed query data. The procedure includes projecting perturbation query data into different latent spaces to train separate GP models for query efficiency. The use of the statistical surrogate enables the application of Bayesian model selection techniques to automatically determine the optimal dimension, balancing data-fit quality and model performance. The proposed approach involves maximizing the posterior using a statistical surrogate model to learn the optimal reduced dimension for adversarial attacks. By automating the learning of the optimal dimension, higher success rates and query efficiency can be achieved. Empirical comparisons with state-of-the-art blackbox methods show the effectiveness of the BayesOpt attacks on image classifiers for MNIST and CIFAR10 datasets. In an experiment following a design from Tu et al. (2018), targeted attacks were performed on 50 correctly classified CIFAR10 images and 7 MNIST images. Each image was attacked 9 times, totaling 450 attacks for CIFAR10 and 63 for MNIST. The attacks used \u03b4 max = 0.3 for MNIST and \u03b4 max = 0.05 for CIFAR10. The effect of reduced dimensionality in the latent space for adversarial perturbation search was empirically investigated using GP-based BayesOpt attacks on the CIFAR10 classifier with reduced dimension d r = {6 \u00d7 6 \u00d7. The GP-based BayesOpt attacks on the CIFAR10 classifier used reduced dimensions for targeted attacks on 5 images, with each image attacked 9 times. The attack success rate varied for different original images, and the study examined how the dimensionality affected query efficiency and attack quality. The study focused on GP-based BayesOpt attacks on CIFAR10 classifier using reduced dimensions for targeted attacks on 5 images. Varying dimensions impacted query efficiency and attack quality, highlighting the importance of finding the optimal dimension. The experiment limited the total query number to 1000 for comparison with GenAttack. AutoZOOM uses reduced search dimensions for successful attacks on MNIST and CIFAR10. The BayesOpt attack limits iterations to 1000 queries and switches to fine-tuning after finding a successful attack. AutoZOOM focuses on attack success rate and perturbation costs measured by L2 norm. Our method and GenAttack limit the search space using L \u221e norm for successful attacks. Results show that our BayesOpt attack achieves comparable success rates with lower query counts compared to GenAttack and AutoZOOM on MNIST. GP-BO-auto-d r and ADDGP-BO achieve high attack success rates on MNIST and CIFAR10 with significantly fewer queries than GenAttack and AutoZOOM. ZOO and AutoZOOM have varying success rates and query counts for attacking MNIST and CIFAR10 datasets. BayesOpt attack shows higher success rates with lower query counts compared to GenAttack. The adversarial examples generated by BayesOpt attack are closer to the original image with lower perturbation. The Bayesian method for learning d r as GP-BO-auto-d r leads to a 15% increase in attack success rate compared to GP-BO, with lower perturbation. BayesOpt attacks converge faster to high success rates with lower query counts compared to other methods. The success rates for adversarial attacks on MNIST and CIFAR10 datasets are compared using AutoZOOM and GenAttack. AutoZOOM is more query efficient than GenAttack, but both have limitations. A new black-box attack leveraging Bayesian optimization is introduced for high query efficiency. Our BayesOpt attacks leverage a statistical surrogate model and query data to reduce dimensions efficiently, achieving high success rates with fewer queries compared to existing methods. This approach can be a competitive alternative for assessing model robustness in real-world applications with limited query budgets. Various BayesOpt methods are used to attack a CIFAR10 image of class label 9. ADDGP-BO and GP-BO-auto-d r show faster convergence and higher attack success rates compared to simple GP-BO. The additive GP surrogate and Bayesian learning of optimal d r lead to faster convergence and higher attack success rates. In the context of attacking a CIFAR10 image of class label 9, the method ADDGP-BO-LD is used to learn the optimal decomposition by maximizing marginal likelihood. A computationally cheaper alternative involves randomly selecting 20 decompositions and choosing the one with the largest marginal likelihood. Another method, ADDGP-BO-FD, groups pixels/dimensions based on the magnitude of average change in their pixel values over past iterations. The attack success rate of ADDGP-BO and GenAttack on ImageNet is compared within a query budget of 1797 queries. ADDGP-BO achieves a 78% success rate, while GenAttack takes 4711 queries to achieve the same success rate, which is 2.6 times that of ADDGP-BO. Additionally, learning decomposition by maximizing marginal likelihood (ADDGP-BO-LD) results in a higher attack success rate. BayesOpt (ADDGP-BO) achieves higher attack success rate on ImageNet images with fewer queries compared to GenAttack. Gaussian processes (GPs) are popular for targeted attacks. Gaussian processes (GPs) are commonly used for regression problems when uncertainty in predictions is important. They are popular in Bayesian optimization for hyperparameter tuning and model selection. The marginal likelihood is key for finding the right hyperparameters in a principled way. In Bayesian optimization, Gaussian processes are used for regression problems to find the right hyperparameters. A maximum likelihood approach is often used to maximize the likelihood of the data with respect to the hyperparameters, instead of fully Bayesian methods like MCMC sampling. Gradient-based search is then employed to find the optimal hyperparameters by maximizing the logarithm of the likelihood. In Bayesian optimization, Gaussian processes are used for regression problems to find optimal hyperparameters. The gradient-based search is used to maximize the likelihood of the data with respect to the hyperparameters. Once the optimal hyperparameters are found, they can be used to choose among different models based on the reduced dimensionality."
}