{
    "title": "SyxhapVYvH",
    "content": "This paper introduces an unsupervised few-shot object recognition approach using a GAN-like deep architecture for image representation learning. The method combines adversarial training, self-supervision, and deep metric learning to generalize well to unseen classes. The model extends GAN with reconstruction loss and utilizes triplet image examples for metric learning, focusing on identifying latent object parts. Our new deep architecture for unsupervised few-shot object recognition combines adversarial training, self-supervision, and deep metric learning to generalize well to unseen classes. The model focuses on identifying latent object parts and outperforms the state of the art in few-shot learning tasks. The N-way K-shot recognition problem aims to learn a deep image representation on unlabeled data for accurate distance estimation between query and support images. This unsupervised few-shot recognition problem differs from standard few-shot learning and semi-supervised learning approaches. Our approach focuses on unsupervised few-shot recognition by learning an image representation from unlabeled data to capture latent object parts. Using a GAN-like deep architecture, we aim to create an image encoding suitable for few-shot recognition in testing. Our unsupervised training approach integrates adversarial, self-supervision, and metric learning to create an image representation suitable for few-shot recognition. The method extends the vanilla GAN with regularization to ensure similarity between encoded \"fake\" images and randomly sampled codes. Additionally, self-supervision involves predicting rotation angles of real training images, while deep metric learning aids in recognizing unseen classes. The approach aims to capture common parts shared among object classes in both training and test image sets. In unsupervised training, adversarial, self-supervision, and deep metric learning are integrated to create an image representation for few-shot recognition. A GAN-like architecture is used to train a discriminator network for encoding real images, with a focus on binary encoding for better performance. The discriminator also has outputs for adversarial and self-supervised learning. In unsupervised training, a GAN-like architecture integrates adversarial and self-supervised learning for image representation. The discriminator is trained to distinguish real from \"fake\" images generated by a network, with a focus on reconstruction loss to improve image quality. In unsupervised training, a GAN-like architecture combines adversarial and self-supervised learning for image representation. The training set is augmented with rotated versions of real images to predict rotation angles, strengthening unsupervised training and improving few-shot recognition. Deep metric learning is used to encode latent parts of images for better capturing similarity of object classes in few-shot recognition. To improve few-shot recognition, metric learning is used to encode latent parts of images. Triplet training examples are formed using image masking to ensure that images showing similar object classes have a small distance in their encodings. The triplet consists of an anchor image, a positive image with masked patches at the periphery, and a negative image with centrally masked patches, emphasizing the importance of object parts in deep representations. Our metric learning approach uses triplet training examples with masked patches to ensure deep representations capture similarity of object classes. This method significantly improves few-shot recognition, outperforming state-of-the-art approaches and achieving performance comparable to fully-supervised few-shot learning on various datasets. The paper introduces a novel approach to few-shot learning using a GAN with a reconstruction loss and a masking procedure for triplet image examples. It reviews related work on few-shot learning and presents implementation details and experimental results. Few-shot learning models can recognize new classes with a few examples. Approaches include metric learning, meta-learning, and hallucination. Metric-learning methods focus on learning embeddings for same-class examples. Meta-learning uses a meta-learner to adapt to new classes. Hallucination-based learning identifies data augmentation rules from the training set. Representative methods include Matching networks, Prototypical networks, Relation networks, MAML, and Reptile. Few-shot learning models utilize various approaches such as metric learning, meta-learning, and hallucination to recognize new classes with minimal examples. Hallucination-based learning involves identifying data augmentation rules from the training set, with methods like Imaginary network, f-VEAGAN-D2, and Delta-encoder. Semi-supervised few-shot learning and unsupervised few-shot learning have also been explored in the literature. In few-shot learning, the approach differs from episodic training and focuses on preserving distance relationships between dissimilar images. The training set includes unlabeled examples with hidden classes, while testing involves support images from unseen classes for N-way K-shot classification tasks. Deep image representations are computed for query and support images, and prototypes are generated for each unseen class. Our deep architecture for few-shot recognition involves a generator G and a discriminator D networks, utilizing adversarial, self-supervision, and metric learning. The discriminator D has three output heads: image encoding head Dz, rotation prediction head Drot for self-supervision, and discriminating head Dr/f for adversarial training. Adversarial loss functions for training D and G are specified as L, with distributions of unlabeled training images and image encodings. In experiments, different distributions for latent codes were studied for generating images, with similar performance. Optimizing objectives in equations 3 and 4 minimizes reverse KL divergence. Self-supervision involves rotating real images for training D to predict rotation angles. Other self-supervision methods like \"jigsaw solver\" can also be used. We use image rotation as a form of self-supervision in training the GAN model. The latent code z is reconstructed by D and used as a \"free\" label for training D and G. The reconstruction loss is calculated using binary cross-entropy, and D is trained to output image representations that respect distance relationships between latent parts. The training set consists of triplets anchor, positive, negative, where the anchor represents an original image and positives are obtained by masking corners. The training integrates adversarial, self-supervision, and deep metric learning in two stages for easier training of D and G. The training process involves two stages: in the first stage, the standard GAN training is followed with optimization of G and D over multiple iterations. After convergence, the resulting discriminator is saved as D(1). In the second stage, metric learning of D is continued over triplet image examples while ensuring that updates do not deviate significantly from D(1). In the second stage of training, 3 iterations focus on metric learning with hyperparameters \u03b2, \u03b3, \u03b4, \u03bb. Images are sampled for anchor, positive, and negative examples to form triplets. Evaluation is done on Mini-Imagenet and Tiered-Imagenet datasets, with details on class distribution and image sizes provided. The Tiered-Imagenet dataset consists of classes grouped into 34 high-level categories, with 20, 6, and 8 categories for meta-training, meta-validation, and meta-testing. The dataset aims to minimize semantic similarity between splits like Mini-Imagenet, with all images sized at 84 \u00d7 84. Unsupervised few-shot recognition results are reported for the first time on this dataset, where ground-truth labeling information is ignored in training and validation sets. Images are resized to 64 \u00d7 64 for GAN input, and hyper-parameter tuning is based on validation loss. Evaluation involves randomly sampling N classes and K examples for classification. The implementation details of the approach involve sampling N classes and K examples for classification, using Pytorch for experiments, SN-GAN with self-modulated batch normalization as the backbone, and specific settings for optimization and training stages. The implementation involves sampling N classes and K examples for classification using Pytorch and SN-GAN with self-modulated batch normalization. Image masking is done by placing a 16x16 patch centered at 4x4 grid locations in the original image. Convergence is observed after 50000 and 20000 iterations for the first and second training stages. Parameters \u03b3=1, \u03b2=1, \u03b4=1, \u03bb=0.2, \u03c1=0.5 are set empirically. Data augmentation techniques are not used. Variants of the approach are defined for testing individual components' impact on performance. The study involves testing different variants of GAN models to improve performance, including SN-GAN with self-modulated batch normalization, GAN + BCE with reconstruction loss, GAN + BCE + ROT with rotation prediction loss, and GAN + BCE + ROT + METRIC with triplet loss. Results show the importance of the reconstruction loss in enhancing performance. Our reconstruction loss significantly boosts the performance of GAN + BCE by 9% compared to GAN alone. The addition of rotation loss and triplet loss in GAN + BCE + ROT + METRIC further improves performance, surpassing the state-of-the-art results. Additionally, the masking procedure for generating negative images in the triplets for metric learning is illustrated in Fig. 4. The image representation in Fig. 4 shows the importance of object parts in our metric learning approach. We focus on unsupervised few-shot object recognition using a new deep architecture. Various methods are compared based on their performance metrics. Our approach for unsupervised few-shot object recognition utilizes image masking with rectangular patches for Mini-Imagenet. By extending the vanilla GAN with reconstruction loss and integrating deep metric learning, we outperform the state of the art by more than 8% in 1-shot and 5-shot recognition tasks on Mini-Imagenet. Additionally, we report the first results of unsupervised few-shot recognition on the Tiered-Imagenet dataset. Our approach for unsupervised few-shot object recognition using image masking with rectangular patches for Mini-Imagenet outperforms the state of the art by more than 8% in 1-shot and 5-shot recognition tasks. The addition of a second contribution further improves recognition by 3% and outperforms a recent fully-supervised approach on the same datasets."
}