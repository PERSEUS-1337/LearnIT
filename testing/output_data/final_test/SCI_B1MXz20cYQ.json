{
    "title": "B1MXz20cYQ",
    "content": "When an image classifier makes a prediction, which parts of the image are relevant and why? Our approach involves conditioning a generative model on the rest of the image to find the regions that most influence the classifier's decision. This method produces more compact and relevant saliency maps compared to traditional approaches. Saliency maps help interpret the decisions of powerful image classifiers. Saliency maps are used to interpret classifiers by computing sensitivity to input dimensions. BID3 and BID2 optimize saliency computation by changing input values, but may produce unnatural images. Modifying the question to focus on data distribution helps generate more consistent explanations. In this paper, a new model-agnostic framework is introduced for computing and visualizing feature importance of classifiers. The framework, based on variational Bernoulli dropout, marginalizes out masked regions to sample counterfactual inputs that either change or preserve classifier behavior. Saliency maps are produced on ImageNet using a conditional generative model to identify relevant pixels better than existing methods. Gradient-based approaches derive saliency maps by computing the gradient of the classifier output with respect to each input component. The reliance on local gradient information in DNN activations can induce bias. Gradient-based saliency computation reflects an inductive bias from the convolutional architecture. To explain classifier response, input is partitioned into masked and unmasked regions, with the masked region replaced by a reference value to determine importance. Efficient sampling from a conditional generative model is used to respect data distribution. BID11 and BID18 are reference-based approaches for analyzing classifier sensitivity to input changes. BID11 approximates output changes linearly but ignores nonlinear interactions, while BID18 computes pixel saliency by marginalizing it out. These methods are limited to simple image domains like MNIST. The proposed method leverages a variational Bernoulli distribution to efficiently search for optimal solutions while encouraging sparsity, reducing computational complexity. It models the interaction between disjoint regions of input space and computes saliency by optimizing the change in classifier outputs with respect to a perturbed input. The method offers three heuristics for choosing the reference image. Gal (2017) proposes two objectives for computing the saliency map: Smallest Deletion Region (SDR) focuses on the smallest input region that could be removed to minimize the classification score, while Smallest Supporting Region (SSR) looks at the smallest input region that could be substituted to maximize the classification score. Solving these optimization problems involves searching over input masks and using a strong conditional generative model to efficiently marginalize unobserved variables. Our approach involves sampling from a generative model to efficiently marginalize unobserved input pixels in an image application. The method is applicable to any domain with a differentiable classifier. The classifier output is approximated using a generative model with distribution p G (x r |x \\r ), where x r represents a region of unobserved pixels. A binary mask z and the original image x are used to define an infilling function \u03c6 as a convex mixture of input and reference with binary weights. The method involves using a generative model to marginalize unobserved input pixels in an image application. A binary mask z and the original image x are used to define an infilling function \u03c6 as a convex mixture of input and reference with binary weights. The classification score function represents the confidence of the classifier on a class, and SDR seeks a mask yielding low classification score when reference pixels are mixed in. FIDO-CA finds a minimal pixel region preserving the classifier score, while SSR aims to find a masked region. FIDO is a method that uses a generative model to Fill-In DropOut regions in images by optimizing a saliency map \u03b8 through a discrete random mask z. The method aims to minimize a classification score while penalizing the size of the mask, using biased gradients computed via the Concrete distribution. The method optimizes a saliency map through a discrete random mask using biased gradients computed via the Concrete distribution. Dropout rates are initialized to 0.5 for faster convergence. Adam optimizer with a learning rate of 0.05 is used, and the learning rate is decayed linearly. PyTorch implementation takes about one minute on a single GPU per image. The approach differs from Fong & Vedaldi (2017) by optimizing parameters of a Bernoulli dropout distribution for sampling reference values from a generative model. Mini-batches of samples efficiently explore the space of binary masks for uncertainty estimates. The method optimizes saliency maps using biased gradients computed via the Concrete distribution. Dropout rates are initialized at 0.5 for faster convergence. Adam optimizer with a learning rate of 0.05 is used, and the learning rate is decayed linearly. PyTorch implementation takes about one minute on a single GPU per image. BID3 and BID2 include regularization techniques like upsampling and total variation penalization to avoid unnatural artifacts in the saliency maps. Upsampling optimizes a coarser \u03b8, which is then upsampled to the full dimensionality using bilinear interpolation. Total variation penalty smoothens \u03b8 with a regularization penalty between spatially adjacent \u03b8. The method optimizes saliency maps using biased gradients computed via the Concrete distribution. Dropout rates are initialized at 0.5 for faster convergence. Adam optimizer with a learning rate of 0.05 is used, and the learning rate is decayed linearly. PyTorch implementation takes about one minute on a single GPU per image. Regularization techniques like upsampling and total variation penalization are used to avoid unnatural artifacts in the saliency maps. FIDO outperforms BBMP BID3 and BID2 in various tasks, including a pixel removal task and the Saliency Metric on ImageNet. Appendices provide further analysis on regularization effects and infilling strategies. The proposed generative approaches for saliency computation include heuristics like Mean, Blur, and Random sampling, as well as Generative Models like Local, VAE, and CA. The choice of objective function between L SDR and L SSR affects the quality of saliency maps, with L SDR showing more artifacts, especially with weak in-filling methods. The choice of objective function between L SDR and L SSR affects the quality of saliency maps, with L SDR showing more artifacts, especially with weak in-filling methods like Mean. L SSR encourages finding explanations consistent with the classifier's training distribution. To improve saliency maps, L SSR is used to reduce artifacts. Generative approaches produce focused explanations, while heuristic methods tend to create more artifacts. Using a strong generative model results in fewer artifacts and concentrated saliency maps. Generative in-filling methods are less susceptible to artifacts compared to heuristic methods. Filters in the low level of the network can cause artifacts in saliency maps, but generative in-filling methods like FIDO-CA help mitigate this issue. FIDO-CA produces the fewest artifacts compared to other methods. Different classifier architectures prioritize different input regions in the saliency maps. In the context of saliency maps, the study evaluates the classifier's sensitivity by altering pixels based on their saliency scores. Instead of flipping or zeroing out salient pixels, they use a generative model to infill pixel values. The evaluation is done on ResNet using 1,533 ImageNet validation images, measuring the number of pixels needed to reduce the log-odds score by a certain percentage. Various in-filling strategies are compared under the FIDO framework. The study evaluates FIDO and BBMP algorithms under different in-filling strategies to reduce log-odds scores. Strong generative in-filling methods yield more parsimonious saliency maps, with FIDO-CA requiring fewer pixels for log-odds score suppression. FIDO outperforms heuristic in-filling approaches when evaluated with CA-CAN. The algorithm is compared to strong baselines on established metrics for weakly supervised localization. After evaluating FIDO and BBMP algorithms with various in-filling methods to reduce log-odds scores, the study focuses on the BID2 model. By thresholding the saliency map above 0.5, the smallest bounding box containing all salient pixels is computed. The prediction is considered \"correct\" if it has an IoU ratio over 0.5 with any ground truth bounding boxes. The authors' pre-trained model of BID2 is compared to five baselines using mean thresholding and normalization techniques. The study evaluates the FIDO and BBMP algorithms, focusing on the BID2 model. The smallest bounding box containing salient pixels is computed by thresholding the saliency map. Evaluation is done using the Saliency Metric proposed by BID2, which avoids human-labeled bounding boxes. The metric calculates the log ratio between the bounding box area and the in-class classifier probability after upscaling. The study compares FIDO-CA with BBMP methods, showing superior performance of FIDO-CA in generating compact saliency maps that retain class information. The use of strong generative in-filling with CA-GAN is essential for this purpose. Examples from the ablation study demonstrate the effectiveness of FIDO and generative in-filling compared to previous methods. The study compares FIDO-CA with BBMP methods, demonstrating FIDO-CA's superior performance in generating compact saliency maps that retain class information. An ablation study was conducted to compare FIDO with different in-filling methods, showing the importance of using a strong generative model like CA-GAN. The study compared FIDO-CA with BBMP methods, showing FIDO-CA's superior performance in generating concentrated saliency maps. FIDO-Blur and FIDO-Random produced more focused maps with fewer artifacts. BBMP-CA underperformed compared to FIDO-CA. Modeling input distribution with a generative model can improve explanations. FIDO is a new framework for explaining differentiable classifiers using adaptive Bernoulli dropout and generative modeling. It provides more concise explanations compared to existing methods by highlighting relevant contextual information. The code is available in PyTorch. Comparisons with other methods show FIDO's effectiveness in generating saliency maps. In comparing different methods for generating saliency maps, BBMP with Blur and Random in-filling strategies show varying sensitivity to the sparsity parameter \u03bb. BBMP requires a higher sparsity penalty compared to other methods. The selection of \u03bb is crucial as all methods exhibit artifacts at low values. BBMP Blur and Random find different types of artifacts, while FIDO with CA produces the best saliency maps with fewer artifacts and focused saliency on small regions in images. In comparing different methods for generating saliency maps, BBMP with Blur and Random in-filling strategies show varying sensitivity to the sparsity parameter \u03bb. BBMP requires a higher sparsity penalty compared to other methods. The selection of \u03bb is crucial as all methods exhibit artifacts at low values. BBMP Blur and Random find different types of artifacts, while FIDO with CA produces the best saliency maps with fewer artifacts and focused saliency on small regions in images. The effect of learning a reduced dimensionality \u03b8 that upsampled to the full image size during optimization is examined, with a choice of 56 for experiments to balance between details and removal of artifacts. The upsampling regularization method removes artifacts, especially in the Mean infilling method. The stability of the method is tested with different random seeds, showing similar results. Total variation prior regularization can further reduce adversarial artifacts, but may risk losing signals if too strong. Generative approaches produce visually sharper images compared to other baselines. Classification probability of ResNet is used to measure the effectiveness of the removal of target information. The effectiveness of different infilling methods is measured using ResNet's classification probability. VAE and CA outperform other methods, while heuristic baselines perform poorly due to generating images outside the distribution of natural images. Generative models show better classifier probability. The effect of batch size on saliency maps is shown, with batch sizes less than 4 yielding unsatisfactory results. The performance of BBMP-CA with various thresholds \u03c4 on both WSL and SM on a subset of 1,000 images is shown in TAB3 and qualitative examples in FIG14. BBMP-CA is relatively brittle across different thresholds of \u03c4, performing slightly better than BBMP and FIDO with heuristics infilling at \u03c4 = 0.3, but still inferior to FIDO-CA. Flipping experiments in FIG0 demonstrate that FIDO-CA outperforms BBMP-CA with varying thresholds. Additional examples of infilled counterfactual images are shown in FIG0 and comparisons of FIDO infilling approaches in FIG12 and 21. FIDO-CA, a method with CA-GAN infilling, highlights compact pixel areas of contextual information in images. This contextual information is missing from Realtime saliency maps but is relevant to the classifier's prediction. Examples include bulbul, tench, junco, and ptarmigan."
}