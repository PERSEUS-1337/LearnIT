{
    "title": "H1bM1fZCW",
    "content": "Deep multitask networks are more scalable and better regularized than single-task networks. A novel gradient normalization technique called GradNorm balances the multitask loss function by tuning gradients to equalize task training rates. GradNorm improves accuracy, reduces overfitting, and matches or surpasses the performance of exhaustive grid search methods with just one asymmetry hyperparameter. Multitask learning in computer vision aims to perform multiple perceptual tasks simultaneously, requiring efficient training dynamics. Gradient manipulation through techniques like GradNorm can balance task training rates and improve accuracy, reducing overfitting. This approach offers control over multitask network training and has the potential to enhance performance in diverse tasks within limited compute environments. Multitask learning in embedded systems like smartphones, wearables, and robots/drones involves sharing weights among tasks in a model for efficient predictions. The challenge lies in balancing tasks by choosing the right joint loss function, typically assumed to be linear in single task losses. Finding the optimal values for each task's contribution is crucial for performance optimization. Our proposed adaptive method adjusts task weights during training to control gradient norms directly, ensuring balanced training dynamics in multitask networks. This approach penalizes large or small gradients to maintain optimal training rates for all tasks. Our proposed method addresses imbalances in gradient norms within a multitask network by implementing a novel gradient loss function. This approach aims to equalize gradient norms among tasks for optimal task balancing, leading to improved accuracy and reduced overfitting. The field of multitask learning involves a heuristic for multitask loss balancing, simplification of grid search, and direct interaction with gradients for reasoning. Deep learning has sparked renewed interest in multitask learning, with applications in various fields such as computer vision, natural language processing, speech synthesis, traffic prediction, and cross-domain work. Multitask learning in computer vision involves solving multiple vision tasks with deep networks, from 3-task networks to larger subsets like UberNet. Single vision problems can also be framed as multitask problems, such as Mask R-CNN for instance segmentation or YOLO-9000 for object detection. Researchers explore optimal ways to relate tasks in a multitask model, using clustering methods, deep relationship networks, and cross-stitch networks to find meaningful relationships between tasks. Researchers in computer vision explore optimal ways to relate tasks in a multitask model using various methods like clustering, deep relationship networks, and cross-stitch networks. One relevant approach involves using a joint likelihood formulation to derive task weights based on the uncertainty in each task. The goal is to learn task weights by considering the norms of gradients from each task backpropagated into the network. Researchers in computer vision are exploring optimal ways to relate tasks in a multitask model. One approach involves using a joint likelihood formulation to derive task weights based on gradient norms. The method of gradient normalization, known as GradNorm, scales all gradient norms to an equal value as a starting point and modifies them with a rate balancing term to ensure no task trains too slowly. This adjustment boosts more sluggish tasks by increasing gradient norms as a function of the relative inverse training rate for each task. The relative inverse training rate is calculated using a simple loss ratio metric, valid for regression squared loss and classification cross-entropy loss. The desired gradient norms are determined by an additional hyperparameter alpha, which balances the training rates between tasks. A higher alpha value is used for tasks with different complexities to align their learning dynamics, while a lower alpha is suitable for more symmetric tasks. An alpha value of 0 aims to equalize the backpropped gradient norms from each task. The gradient norms are controlled by setting a target using equation 1, with a loss function L grad implemented as the L1 distance between actual and target norms. This loss is applied to update loss weights w i (t) to move gradient norms towards the target. The full loss is the mean of individual task losses, differentiated with respect to each w i (t) and updated using standard rules. After setting target gradient norms using equation 1, the weights are updated to move gradient norms towards the target. The weights can be any subset within network layers, with a preference for the last layer to save on compute overhead. GradNorm adds minimal additional compute time and renormalizes weights after each update step to decouple gradient normalization from the global learning rate. This method is illustrated on T regression tasks. To illustrate GradNorm on regression tasks, matrices B and i are generated with specific elements. The goal is to perform regression on multiple tasks with shared information B and task-specific information i. Higher variance tasks induce higher squared loss but also backpropagate larger gradients. A common trunk network is used with a final affine transformation per task. In regression tasks, a common trunk network with 100 neurons per layer is used for multiple tasks with shared and task-specific information. A final affine transformation per task yields T predictions. Inputs are in R 250 and outputs in R 100. The asymmetry \u03b1 is set low at 0.12, and task-normalized test-time loss is measured. The toy problems are statistically identical except for their loss scales \u03c3 i, allowing for a clear measure of overall network performance. In regression tasks with a common trunk network, multiple tasks are performed with shared and task-specific information. The loss scales \u03c3 i are varied to measure overall network performance. Gradient normalization improves task balance and test-time performance, especially with a higher number of tasks. GradNorm improves task balance and outperforms uncertainty weighting for tasks with smaller loss scales. Uncertainty weighting leads to unstable training and quick crashes due to growing weights. GradNorm ensures stable and convergent training with time-averaged weights close to optimal static weights. GradNorm simplifies grid search by keeping weights close to optimal static weights. NYUv2 dataset is used for testing, which includes depth, surface normals, and semantic segmentation labels. NYUv2 dataset is small but contains regression and classification labels, making it suitable for testing GradNorm's robustness. Additionally, NYUv2 dataset is expanded to 40,000 images with pixel-wise depth, surface normals, and room keypoint labels for large-scale multitask testing. The curr_chunk discusses the use of two different models for room layout prediction, one using a SegNet network with a VGG16 encoder/decoder and the other using an FCN network with a modified ResNet-50 encoder and shallow ResNet decoder. The ResNet architecture is thinned to contrast with the VGG SegNet, with different approaches to upsampling. The VGG SegNet has 29M parameters compared to 15M for the thin ResNet. Standard pixel-wise loss functions are used for segmentation, depth, and normals prediction tasks. Regression tasks use quadratic losses, with room layout predictions generated using Gaussian heatmaps and a pixel-wise squared loss. GradNorm improves performance on NYUv2 dataset tasks compared to equal-weights baseline. GradNorm Converged Weights network uses time-averaged weights for each task. Good values for static weights can be extracted using GradNorm. GradNorm networks outperform other multitask methods on the expanded NYUv2 dataset, showing improved test-time depth error by approximately 5%. This is achieved by aggressively rate balancing the network with a high asymmetry alpha value of 1.5, ultimately suppressing the depth weight to lower than 0.10. The depth weight is suppressed to below 0.10 for network regularization. Results for VGG SegNet and Thin ResNet FCN are consistent. Training 100 networks with random task weights on expanded NYUv2, comparing GradNorm to uncertainty weighting BID13 at 15000 iterations. Results are shown in FIG1. After training 100 networks with random task weights on expanded NYUv2, comparing GradNorm to uncertainty weighting BID13 at 15000 iterations, a strong negative correlation was found between network performance and task weight distance to time-averaged GradNorm weights. GradNorm simplifies the process by immediately finding optimal grid search weights without actually performing grid search. Visualizations at inference time are shown in Figure 5. The GradNorm network shows incremental qualitative improvements in pixel map predictions compared to other baselines, with smoother and more detailed outputs. It acts as a model regularizer in multitask networks by balancing gradients and accommodating varying complexities with a single hyperparameter. The GradNorm network introduces a new methodology for balancing multitask networks by manipulating gradients to optimize task weights efficiently. Training characteristics include batch size, GPU specifications, learning rates, and steps for NYUv2 runs. The GradNorm technique introduces an asymmetry parameter \u03b1 to balance multitask networks efficiently. Tuning \u03b1 leads to performance gains, with values between 0 and 3 improving network performance. Higher values of \u03b1 push task weights further apart, reducing the influence of tasks that overfit or learn too quickly. At \u03b1 = 1.75, the depth task weight is suppressed to below 0.02 without detriment to network performance."
}