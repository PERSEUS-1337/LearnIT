{
    "title": "B1GMDsR5tm",
    "content": "Equilibrium Propagation is a method for training neural networks without backpropagation. However, it has a limitation of requiring iterative optimization during inference. Initialized Equilibrium Propagation addresses this issue by training a feedforward network to initialize the iterative inference process. Propagation trains a feedforward network to initialize Equilibrium propagation, approximating the fixed-point state with a local learning rule. The learned feedforward network performs as well as the original Equilibrium propagation, offering a way to train deep networks without backpropagation. This is significant for understanding the brain's one-way signaling process in biological neurons. Neurons communicate through axons in a one-way signaling pathway. Backpropagation is not observed in biological neurons, leading researchers to explore alternative methods for neural credit assignment. Equilibrium Propagation is a novel algorithm proposed as an alternative to backpropagation for efficient learning in hardware. Equilibrium Propagation is an algorithm that computes parameter gradients in a neural network without backpropagation. It defines the network as a dynamical system following the negative-gradient of an energy function. The network's prediction is the fixed point where the system settles to a local minimum energy. However, it is slow for large networks as it iteratively converges to a fixed point at every training iteration. To address this, knowledge from a slow equilibrating network is distilled into a fast feedforward network by training it to predict the fixed points of the equilibrating network with a local loss. Equilibrium Propagation is a method for training an Energy-Based Model for classification without backpropagation. It involves a feedforward network producing a network state evaluated by an equilibrating network. The network converges to a fixed point based on input data, with the output neurons' state at the fixed point serving as the network's output. The network's dynamics are defined by an energy function over neuron states and parameters. Equilibrium Propagation is a method for training an Energy-Based Model for classification without backpropagation. The network is trained using a two-phase procedure, with a negative and then a positive phase. In the negative phase, the network settles to an energy minimum conditioned on input data. In the positive phase, a target is introduced to perturb the fixed-point of the state towards the target. Equilibrium Propagation trains an Energy-Based Model using a two-phase procedure without backpropagation. The network settles to an energy minimum in the negative phase and perturbs towards a target in the positive phase to minimize output loss through local learning rules. Equilibrium Propagation trains an Energy-Based Model using a two-phase procedure without backpropagation. In inference, a fast scheme is needed due to the slow settling process. A feedforward network is proposed to predict the fixed-point of the equilibrating network, allowing for initialization and inference at test-time. Equilibrium Propagation trains an Energy-Based Model using a two-phase procedure without backpropagation. A feedforward network predicts the fixed-point of the equilibrating network for initialization and inference at test-time. The parameters are trained to approximate the minimal energy state of the equilibrating network. The derivative of the forward parameters of the neuron can be expanded. Minimizing the distance with the minimal energy state works better than with a different state. Equilibrium propagation relies on initializing the negative phase close to the true minimum of the energy function for better gradient computations. Optimizing only the local term does not significantly affect performance. Parameters will learn during training until the feedforward network accurately predicts the minimal-energy state of the equilibrating network, allowing for inference. Equilibrium propagation relies on initializing the negative phase close to the true minimum of the energy function for better gradient computations. The training procedure involves using the output neurons to predict the target data. Inference can be done through the forward pass of the inference network or by iteratively minimizing the energy. Experiments show that the forward pass performs equally well as full energy minimization. The equilibrating network's fixed point is computed iteratively using all parameters, while the initial state is generated in a single forward pass. Equilibrium propagation involves initializing the negative phase close to the true energy minimum for better gradient computations. The equilibrating network creates targets that may not be achievable by the feedforward network. Neurons in the feedforward network learn a linear mapping from previous activations to equilibrating network targets. Adding a loss can encourage the equilibrating network to stay within the reachable regime of the forward network. A hyperparameter \u03bb helps bring equilibrating network fixed points closer to forward pass states, optimizing the energy landscape. The trick of using a hyperparameter \u03bb in equilibrium propagation optimizes the energy landscape by pulling the minimum of the loss function closer to the feedforward prediction, allowing faster convergence. Different values of \u03bb are investigated for their effects on convergence. Ignoring the global loss and focusing on the local loss still leads to good convergence, as shown empirically. In a two-layer network, when the parameters are close to ideal, the cosine similarity between local and distant gradients is usually positive, indicating alignment. This alignment helps the local loss guide in the right direction, as shown by the gradient expression when parameters are near ideal. In a two-layer network, the alignment between local and distant gradients is positive when parameters are close to ideal. This alignment aids in guiding the local loss in the right direction, even with nonlinear activations. The gradient-alignment tends to increase as the network trains to approximate targets, showing that optimizing the local loss does not slow down convergence. In a 6-layer network, training the local loss leads to faster convergence compared to training directly on the global loss. The distant-gradient signals from higher layers can be confusing, making optimization easier when focusing on local losses. As training progresses, the local and distant gradients align as parameters approach the ideal values. Training the local loss in a 6-layer network can lead to faster convergence compared to training on the global loss. Aligning the local and distant gradients optimizes the loss of later layers from the beginning of training. Providing local targets by the equilibrating network may not always result in perfect alignment, but the forward network can still learn to classify effectively. Using the hard sigmoid function as nonlinearity and clipping the state of s i to the range (0, 1) are key aspects of the experiments based on BID19. Resolving issues with more complex datasets may require future work on annealing \u03bb up to infinity while maintaining stable training. The text discusses techniques such as clipping the state of s i to the range (0, 1) and randomly sampling \u03b2 to avoid instability problems. Unlike BID19, caching and reusing converged states for each data point between epochs is not used. The activation function of the feedforward network is modified to prevent neurons from getting stuck in saturated regions. The text discusses techniques to prevent feed-forward neurons from getting stuck in saturated regions. A regularizing parameter \u03bb = 0.1 is used, and the algorithm is verified on the MNIST dataset. Results show that the network performs similarly to Equilibrium Propagation. The approach stabilizes Equilibrium-Prop learning and avoids instability by scaling the learning rate when \u03b2 is negative. The text discusses stabilizing Equilibrium Propagation by scaling the learning rate when \u03b2 is negative. Training with a small number of negative-phase steps shows that feedforward initialization improves stability. Increasing negative-phase steps allows Equilibrium Propagation to perform comparably with feedforward networks. The performance of Initialized Equilibrium Propagation is compared when trained with local losses versus global loss (backpropagation). No disadvantage is observed with only using local losses. Initializing the negative phase close to optimal regime allows the network to learn with fewer steps. Increasing negative-phase iterations does not improve error when convergence is achieved. In Figure 3, it is shown that using only local losses to update the feedforward network has no apparent disadvantage. Local loss gradients align with gradients from higher layers, indicating that using local gradients alone may be sufficient. Another related work initializes an iterative settling process with a forward pass, where the Equilibriating network parameters are used for a good approximation of the energy-minimizing state. Their model differs from ours as the forward model parameters are tied to the energy-based model parameters. The authors were inspired by the idea of distilling knowledge from a slow equilibrating network into a fast feedforward network. Several authors have noted the connection between Energy Based Models and Generative Adversarial Networks (GANs), where a feedforward generator network proposes synthetic samples to be evaluated by an energy-based discriminator. Both the generator and discriminator are deep feedforward networks trained with specific algorithms. In their approach, the inference network acts as a conditional generator producing a network state given input data. The Energy-Based network evaluates the minimizing state produced after energy-minimization steps. Parameters are trained based on a contrastive loss to adjust the energy levels of synthetic and real states. The goal is to estimate a posterior distribution in variational inference. In variational inference, the goal is to estimate a posterior distribution p(z|x) using an approximate posterior q(z). Amortized inference involves learning a global set of parameters \u03c6 to map a sample x to a posterior estimate z. BID3 proposed using a \"recognition network\" for this purpose, and BID11 demonstrated efficient training using the reparameterization trick. However, there is an \"amortization gap\" where the sharing of posterior estimation parameters across data samples can lead to a loss in accuracy. Recent works have introduced a \"teacher-student\" framework to address this issue. In the \"teacher-student\" framework, an amortized network provides an initial guess for the posterior, refined by a non-amortized network in several steps. The \"student\" learns to refine its posterior estimate using the final result of iterative inference. This approach is used in training Deep Boltzmann Machines, where a feedforward network initializes variational parameters for estimating the posterior over latent variables. Initialized Equilibrium Propagation is a zero-temperature analog of amortized variational inference, reducing mean-field updates to coordinate ascent on variational parameters. The function of the amortized student network is analogous to the initializing network, and the negative phase corresponds to iterative optimization. Equilibrium propagation involves optimizing variational parameters through iterative passes in a feedforward network. A model proposed by BID12 includes reprojecting the output back to the input layer to shorten convergence time. Initialized Equilibrium Propagation shows similarities to the Method of Auxiliary Coordinates in optimizing a layered feedforward network. The method involves optimizing a layered feedforward network by alternating optimization of neural activations and parameters. The objective includes a layerwise cost to ensure that layer activations remain close to what the network can compute. Unlike Equilibrium Prop, other methods backpropagate gradients across one layer or use the Alternating Direction Method of Multipliers. Other approaches to backprop-free credit assignment have been explored, such as DifferenceTarget propagation, Feedback-Alignment, and a unique approach by BID8 where each layer predicts its own \"pseudogradient\". These methods aim to optimize targets locally or align forward and backward pass parameters for training. In this paper, a recurrent, energy-based model is used to provide layerwise targets for training a feedforward network without backpropagation. Neurons in the inference network learn to predict local targets corresponding to minimal energy states, achieved through iterative settling of a recurrently connected equilibrating network. This approach could lead to efficient analog neural network designs in hardware. In this paper, a recurrent, energy-based model is used to provide layerwise targets for training a feedforward network without backpropagation. A hybrid circuit could be used to train a digital, copy-able feedforward network updated by gradients computed in analog hardware, simplifying designs and avoiding dependencies on specific analog hardware. Symbols used in the paper are listed in alphabetical order. The paper presents a recurrent, energy-based model for training a feedforward network without backpropagation. It introduces symbols in alphabetical order and discusses the gradient alignment phenomenon at random initialization. The paper introduces a new parameter \u03bb to encourage the equilibrating network state to be close to the forward pass state. A parameter sweep is conducted to evaluate the effect of \u03bb, showing that it can improve performance, especially with a small number of negative-phase convergence steps. Introducing \u03bb can lead to more stable training with fewer steps of iteration needed to reach the minimizing state. However, training fails when \u03bb is too high due to instability in optimizing sharp loss surfaces. Adaptive \u03bb or Euler-integration step-size could address this issue in future work."
}