{
    "title": "HylUPnVKvH",
    "content": "Convolutional neural networks (CNNs) can be adjusted to evaluate a wide range of image sizes at test time. A novel mixed-size training regime is described and evaluated in this work, showing that models trained using this method are more resilient to image size changes and generalize well even on small images. This allows for faster inference using smaller images at test time, achieving a 76.43% top-1 accuracy with ResNet50 at an image size of 160, matching the accuracy of the baseline model with 2x fewer computations. Convolutional neural networks can be adjusted to evaluate a wide range of image sizes at test time. This method can accelerate training or improve final test accuracy, as shown by reaching a 79.27% accuracy with a model evaluated at a 288 spatial size for a 14% improvement over the baseline. CNNs are used in various domains like visual, audio, language, and speech tasks. However, CNNs are not scale invariant with respect to image input resolution, leading to non-linear changes in output with image dimension alterations. CNNs are sensitive to image size, limiting practical use cases. Networks trained on specific image sizes perform poorly on others. Data augmentation can increase network robustness to inputs of different scales. In this work, a novel training regime called \"MixSize\" for convolutional networks is introduced to reduce image size sensitivity and improve model performance on a wide range of sizes used at evaluation. The regime also allows for faster inference by evaluating mixed-size models at smaller image sizes, resulting in up to 2\u00d7 reduction in computations required at inference to reach the same accuracy as the baseline model. The text discusses the trade-off between training time and accuracy when reducing the average image size during training of convolutional networks. It mentions how modifying the spatial size of an input to a convolutional layer affects the output size. The modification of input size in convolutional layers can scale the output size by a factor \u03b3 without changing parameters. Practitioners have noted that using a modified image size during inference can still be effective. However, increasing image size beyond training dimensions can improve accuracy up to a point before deteriorating. Recent studies show a trade-off between computational cost and accuracy when scaling image size for training and evaluation with convolutional networks. In previous studies, it was found that training with larger image sizes can lead to increased classification errors. Progressive resizing, where image size is increased during training, has been explored to improve model performance. Recent research has shown that CNNs can be trained with a small image size and fine-tuned post-training to a larger size for evaluation, reducing train-test discrepancies. This approach allows for faster training and improved accuracy, albeit with additional fine-tuning and computational costs at inference time. The current work aims to investigate using multiple image sizes during training to enhance CNN performance resilience to changes in image size at test time. Deep neural network training can be distributed across multiple computational units using data-parallelism. Large batch training can affect network generalization capabilities, but recent studies suggest that the generalization gap can be mitigated through hyper-parameter tuning. Recent studies propose modifications to the optimization procedure to cope with changes in training dynamics, such as scaling learning rate with batch size growth and per-layer gradient scaling schemes. Incremented batch-sizes and Batch Augmentation (BA) have been explored to reduce training iterations and improve generalization across models and tasks, albeit with increased computational effort. The Repeated Augmentation (RA) method, similar to Batch Augmentation (BA), aims to decrease training steps and mitigate I/O bottlenecks. The utility of varying batch sizes is still an open question, prompting exploration of a new optimizer modification for training with multiple batch sizes. Training CNNs with fixed-size images has limitations, as evaluation often uses different sizes. The impact of image size on CNN training progress was evaluated by examining gradient statistics. Gradients across different scales of the same image showed strong correlation, especially in the early stages of training. This suggests that small image gradients can approximate full image gradients, aiding in training efficiency. Using small image gradients as an approximation of full image gradients can improve computational efficiency during training. The \"MixSize\" training regime suggests varying input sizes and batch sizes to optimize resource utilization. In the MixSize regime, training on square images with shared size distribution can improve network resiliency and accuracy across various image sizes, leading to computational savings during inference. In the MixSize regime, training with varying batch and spatial sizes can lead to computational savings during inference. Two trade-offs are explored: decreasing iterations per epoch by enlarging batch size at the expense of spatial size, and improving generalization per epoch by enlarging image size at the expense of spatial size. This behavior may require hyper-parameter tuning and can affect size-dependent layers like batch normalization. Gradient Smoothing and Batch-norm calibration are described as useful methods to adapt training regimes and improve performance. Training with varying batch and spatial sizes can affect the variance of accumulated gradients. Optimization regimes may need to be adjusted for smaller spatial sizes, similar to learning-rate adaptations for large-batch training. Previous works have suggested modifications like square-root scaling, linear scaling, or fixed norm ratio to compensate for variance reduction in larger batch sizes. Changing both spatial size and batch size is proposed to modify gradient variance. Gradient smoothing is proposed as an alternative solution to controlling gradient norm variability when training with changing image sizes. It involves using an exponentially moving weighted average of the gradients' norm to mitigate variations in gradient statistics. This method aims to address the challenges posed by varying batch and spatial sizes on gradient variance. Gradient smoothing is a method designed to adapt globally to changes in batch and spatial sizes during training, aiming to reduce variations in gradient statistics. It has been found beneficial in scenarios with multiple batch sizes, showing a slight advantage in test error compared to traditional methods. Using different image sizes at evaluation can lead to discrepancies between training and evaluation protocols due to varying data pre-processing. Touvron et al. (2019) proposed fine-tuning a network trained on a fixed size for evaluation, requiring multiple training epochs and computations. Discrepancy issues in networks trained with mixed-regimes are mainly attributed to batch-norm layers, which introduce differences between training and test evaluations by using running estimates instead of actual mean and variance values. Targeting batch-norm layers specifically can help resolve these discrepancies. When using varying image sizes for evaluation, discrepancies can arise in models trained with mixed-regimes due to batch-norm layers using running estimates instead of actual mean and variance values. To address this, a calibration method is proposed to adjust mean and variance estimates for each evaluated size, improving performance on a wide range of image sizes with minimal computational cost. The study examines the method using CIFAR10/100 datasets with modified mixed-size regimes to increase batch size and number of duplicates for each training step. The sampling strategy is used to compare the regime to baseline results, maintaining original hyper-parameters. Gradient smoothing method is applied for the increased effective batch-size regime. Test accuracy is measured on the original 32 \u00d7 32 image size for each result. The study measures final test accuracy on original 32 \u00d7 32 image size for each result and performs batch-norm calibration. Results show improvements in training steps and test accuracy with MixSize regimes on CIFAR datasets. Training progress on CIFAR10 using ResNet44 is illustrated. Large scale experiments on ImageNet dataset using ResNet-50 confirm findings. The study utilized ResNet-50 and EfficientNet-B0 models with specific training regimes and data augmentation techniques. For ResNet-50, a base learning rate of 0.1 was used, decreased at epochs 30, 60, 80, stopping at epoch 90, with a batch size of 256 over 4 devices and L2 regularization. EfficientNet-B0 employed a shorter training regime with a momentum-SGD optimizer and a cosine-annealed learning rate over 200 epochs. The ImageNet dataset training regime was determined through cross-validation. The proposed training regime involves reducing image size to 144x144 to increase batch size or number of duplicates. Batch size is scaled by a factor of S^2, with learning rate adjusted accordingly. No warm-up is needed due to gradient smoothing. Regime B+ allows training with 2.7x less time. Regime B+ enables training with 2.7x less time, achieving a better-than-baseline accuracy of 76.61%. Increasing batch-augmentation in D+ regime improves test accuracy to 78.04%. MixSize is examined for model resiliency to image size changes during test-time. MixSize evaluates model resiliency to changes in image size during test-time by varying test-time image sizes around the original 224 spatial size. Models trained with a mixed regime were calibrated to a specific evaluation size by measuring batch-norm statistics for 200 batches of training samples. The calibration procedure resulted in degraded results for models trained with original fixed-size regimes. No fine-tuning procedure was used post training for any of the models. The baseline model trained at a fixed size of 224 achieves 76.8% accuracy, but degrades quickly at smaller sizes. In comparison, the D+ regime with an average size of 144 improves accuracy to 77.14% at size 224 and performs better at smaller sizes as well. The model trained with the S (208) regime offers improved accuracy at a larger spatial size of 208 \u00d7 208 compared to the baseline fixed-size regime. Mixed-size regimes show superior accuracy across a range of evaluation sizes, with S = 208 outperforming the baseline at all sizes. In this study, mixed-regime models trained with an equal computational budget outperform fixed-size models at all sizes. The use of a mixed regime significantly improves accuracy per compute at evaluation, with the S (224) model reaching a top accuracy of 79.27% at a 288 \u00d7 288 evaluation size. The research introduces a performance trade-off between computational load and classification accuracy based on the input's spatial size, suggesting stochastic image size regimes. The study suggests using stochastic image size regimes to improve model accuracy and robustness. This approach can lead to faster training, better results, and the ability to target specific image sizes for testing. Mixed regimes can create networks with better performance across various use cases. The study recommends using stochastic image size regimes to enhance model accuracy and robustness. This method can result in quicker training, improved outcomes, and the capability to target specific image sizes for testing. Mixed regimes can produce networks with superior performance across different designated use cases, with two batch sizes created by the regime: 256 and 2,048. Gradient smoothing reduces the gap between gradient norms at different batch sizes, enhancing final accuracy. Various alternatives for image size variations are considered, with random sampling regimes proving more effective than scaling image size from small to large. The study suggests using stochastic image size regimes for improved model accuracy and robustness. Sampling image sizes per training step showed faster convergence and less noise in test accuracy measurements. The use of batch-normalization and hyper-parameter tuning are factors influencing these results. The experiments were conducted using the third regime - sampling image size per training step, with alternative size regimes named S (208) and S (224)."
}