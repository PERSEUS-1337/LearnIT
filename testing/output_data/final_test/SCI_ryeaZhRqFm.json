{
    "title": "ryeaZhRqFm",
    "content": "Link prediction in simple graphs involves predicting new links between nodes based on the graph's structure. In real-world applications, relationships among nodes can be more complex than pairwise associations, such as in chemical reactions. Hypergraphs offer a way to represent higher-order relationships, including directionality. While Graph Convolutional Networks (GCN) are effective for link prediction in simple graphs, their applicability to hypergraphs is unexplored. This paper introduces Neural Hyperlink Predictor (NHP), which adapts GCNs for link prediction in hypergraphs with two variants: NHP-U and NHP-D. The Neural Hyperlink Predictor (NHP) introduces two variants, NHP-U and NHP-D, for link prediction in undirected and directed hypergraphs. NHP-D is the first method for link prediction in directed hypergraphs. Hypergraphs model higher-order relationships, beyond pairwise associations, in various fields like social network analysis, knowledge bases, and bioinformatics. Link prediction in hypergraphs involves predicting missing higher-order relationships. Hyperlink prediction involves predicting missing higher-order relationships in hypergraphs. Modeling direction information in these relationships is important in practical applications, such as chemical reactions data. Directed hypergraphs provide a way to represent direction information. Previous work focused on undirected hypergraphs, but predicting missing hyperlinks in directed hypergraphs is also valuable. In this work, the focus is on both undirected and directed hypergraphs for hyperlink prediction using a GCN-based framework. The success of GCNs in link prediction on graphs has inspired this approach, with a contribution being the illustration of modeling chemical reactions data using both types of hypergraphs. The Neural Hyperlink Predictor (NHP) is a Graph Convolutional Networks (GCN)-based framework for hyperlink prediction in directed hypergraphs. It is the first deep learning approach for this problem and has shown effectiveness in link prediction through experiments on real-world datasets. The NHP's source code is available at an anonymous location. In this section, we review advancements in deep learning on graphs and link prediction on hypergraphs. Geometric deep learning aims to generalize deep neural network models to non-Euclidean domains like graphs and manifolds. Various methods such as matrix factorization, random-walk algorithms, and CNN-like neural networks on graphs have been developed for learning low-dimensional node representations. In a pioneering work, a mathematically sound definition of convolution on a graph was introduced, employing the analogy with classical Fourier transforms and projections onto the eigen basis of the graph Laplacian operator. The ChebNet framework learns Chebyshev polynomials of the graph Laplacian to resolve computational bottlenecks. The graph convolutional network (GCN) is a simplified version of ChebNet that uses simple filters on 1-hop local neighborhoods of the graph. Another formulation of convolution on a graph is in the spatial domain, providing a localisation property by construction. The first formulations of a spatial CNN-like neural network on graph generalized standard molecular feature extraction methods based on circular fingerprints. Different types of neural networks were unified into a message passing neural network (MPNN) framework, achieving state-of-the-art results on molecular property prediction. Related research includes link prediction on hypergraphs, where relationships go beyond pairwise interactions. Machine learning on hypergraphs was introduced in a seminal work that generalized spectral clustering to hypergraphs. The methodology of spectral clustering was extended to hypergraphs, leading to algorithms for hypergraph embedding and semi-supervised classification. Link prediction on hypergraphs, especially in social networks, involves predicting higher-order links and metadata information. Techniques include ranking for link proximity and matrix completion on the incidence matrix. Hyperlink prediction has also been used for multi-actor collaborations. Additionally, a dual hypergraph approach has been proposed for hyperlink prediction, treating it as a vertex classification problem on the dual hypergraph. The problem of link prediction in an incomplete undirected hypergraph involves predicting missing hyperlinks based on the current set of observed hyperlinks. The variable cardinality of hyperlinks makes traditional graph-based link prediction methods infeasible. Traditional graph-based link prediction methods are hindered by the variable cardinality problem in hyperlinks, leading to an exponentially large inference space. However, in practical cases, filtering out infeasible hyperlinks makes prediction feasible, such as restricting predictions to feasible reactions in missing metabolic reactions or collaborations with a small number of authors in academic/technical papers. Hyperlink prediction on a restricted set of hyperlinks is a feasible problem. A hyperlink prediction problem involves finding the most likely hyperlinks missing in a given incomplete hypergraph. Directed hypergraph BID12 is a model that captures chemical reactions using directed hyperlinks. This model is general enough to include previous graph models. The directed hyperlink prediction problem involves finding missing hyperlinks in an incomplete hypergraph. The proposed NHP method can predict both undirected and directed hyperlinks in a hypergraph by constructing a dual hypergraph. The problem of link prediction in a hypergraph can be addressed as a binary node classification task in its dual hypergraph. Graph Convolutional Networks (GCN) are used for semi-supervised node classification on the dual hypergraph obtained from the clique expansion of the original hypergraph. The data matrix contains real-valued vector representations for nodes in the graph. A two-layer GCN model is used for semi-supervised multi-class classification, minimizing cross-entropy error. The weights of the GCN are trained using gradient descent. This approach is deep learning-based and includes node classification but does not perform link prediction in directed hypergraphs. The proposed NHP framework converts hypergraphs into their dual form, uses positive unlabelled learning to classify hypernodes, and employs GCN for classification. The cross-entropy objective of GCN is not directly applicable to positive unlabelled settings, presenting a challenge in semi-supervised learning. In positive unlabelled learning, a variant of semi-supervised learning, a plausible negative sampling set is constructed based on data similarity. Unlabelled points are ranked by their average similarity to positive examples, and the top ones are selected as plausible negative examples. This approach helps in scenarios where only a limited amount of positive examples are available. The GCN on the hypergraph can be run by minimizing the objective over positive examples in E and plausible negative examples in F. Link prediction in directed hypergraphs involves predicting directing links and missing tail and head sets of nodes. Predicting undirected hyperlinks first is a straightforward approach for this problem. The proposed joint learning scheme involves separate hypernodes for tail and head hyperlinks in the dual hypergraph, forming directed hyperlinks in the primal. Positive hypernodes are sampled from unlabelled data to create negative pairs for training. The proposed joint learning scheme involves separate hypernodes for tail and head hyperlinks in the dual hypergraph, forming directed hyperlinks in the primal. Negative pairs are created from unlabelled data to train the model using a simple neural network. The experiments evaluate NHP on hyperlink prediction in undirected hypergraphs, including predicting reactions of metabolic networks for various applications. The study focuses on predicting reactions in metabolic networks using NHP, which outperforms baselines across all datasets. Fake reactions were generated to supplement existing ones, with NHP consistently achieving superior performance. The study demonstrates NHP's superior performance in predicting hyperlinks in coauthorship networks, outperforming baselines across all datasets. Coauthorship data from cora and dblp were analyzed to understand research collaborations in the scientific community. The study analyzed coauthorship networks using a coauthorship hypergraph model. It involved predicting collaborations among authors using a small number of known collaborations. Random sampling was done to create a feature matrix for the datasets, including metabolic networks and coauthorship data. Node2vec was used for the analysis, showing superior performance in predicting hyperlinks. In the study, fake papers were generated with random Gaussian bag-of-word features. Node2vec was used to learn low-dimensional embeddings, and the clique expansion of the dual hypergraph was used as input. NHP was compared against state-of-the-art baselines, including Spectral hypergraph Clustering and node2vec. Node2vec was found to be superior to DeepWalk and LINE. MLP on embeddings with semi-supervised objective in positive unlabelled setting. CMM uses EM algorithm for matrix factorisation to determine presence of candidate hyperlinks. GCN on star expansion BID40 for Pinterest graph. Comparison of NHP against star expansion, running GCN over hypergraph's star expansion. Mean AUC and mean number of hyperlinks recovered reported. In 10 trials, the proposed models consistently outperform baselines in metrics due to GCNs' powerful non-linear feature extraction capability. Mean AUC over 10 trials for all datasets is reported in Table 6, showing similar results for both models. Table 7 displays the mean number of hyperlinks recovered over 10 trials, with both models achieving similar results. The proposed models achieve similar results in recovering hyperlinks, using the same metabolic networks and stoichiometric matrices. NHP-D (joint) and NHP-D (sequential) are the two models compared, with the latter treating undirected hyperlink prediction and direction prediction separately. The study runs a GCN on the clique expansion of the undirected hypergraph to obtain node embeddings and then uses a multi-layer perceptron to predict directions. Positive unlabeled learning outperforms random negative sampling in terms of standard deviations. Baselines compared include node2vec + MLP and Co-ordinated Matrix Maximisation + MLP for hyperlink prediction and direction prediction. The CMM technique uses the EM algorithm to determine candidate hyperlinks. A 2-layer perceptron is used to predict directions between hyperlinks. NHP-D (joint) and NHP-D (sequential) perform similarly due to sparse training data. The hypernode representations of both models are similar. NHP-D outperforms baselines on 3 out of 4 datasets, with iHN637 being particularly challenging. Positive-unlabeled learning of equation 3 is justified by comparing NHP-U to negative samples chosen uniformly at random. Results for undirected hypergraph datasets are shown in tables 8 and 9. In addition to positive unlabeled learning, a mixed technique was used to sort hyperedges based on similarities and select randomly from the least similar ones. The technique, named mixed, combines benefits of positive unlabeled learning and random negative sampling. Results show that mixed outperforms random negative sampling in terms of AUC values. The study introduces NHP, a novel neural approach for hyperlink prediction in undirected and directed hypergraphs, demonstrating its effectiveness over existing methods through extensive experiments on real-world datasets. NHP combines the benefits of positive unlabeled learning and random negative sampling, with lower standard deviations compared to the latter. The NHP framework incorporates self-training, co-training with random walks, and edge-feature learning for improved performance in graph-based semi-supervised learning tasks. Future work includes predicting hyperlinks in partial-order hypergraphs. Hyperparameters for GCN used in all datasets are specified, and the DBLP database was filtered to include 540532 papers for analysis. After filtering the DBLP database to include 540532 papers, the top 1000 authors were selected based on the number of papers authored. From these authors, 1590 papers by 685 authors were identified. Word features were extracted from the abstracts with a frequency greater than 50, resulting in a 602-dimensional bag-of-words representation. Fake papers were generated with Gaussian p dimensional features based on the author distribution of existing non-fake papers."
}