{
    "title": "SJgEl3A5tm",
    "content": "In an experimental study, a camouflage pattern is learned to hide vehicles from state-of-the-art object detectors. The approach involves training a neural function to imitate camouflage application and minimizing detection scores to find optimal camouflage. Results show the camouflage can effectively hide vehicles from detectors in various environments and generalize to different scenarios. The study raises the question of whether painting a unique pattern on a vehicle can hide it from surveillance cameras. The use of deep neural networks in surveillance and autonomous driving systems makes them vulnerable to adversarial attacks, where imperceptible perturbations can fool the neural networks. This has led to the development of defense techniques and powerful attack methods to defeat these defenses in various tasks such as image classification, semantic segmentation, object detection, and image captioning. In the context of adversarial attacks on deep neural networks, researchers aim to create physical camouflage for 3D objects like cars to evade detection by deep learning based vehicle detectors. Despite challenges in real-world experiments, promising results have been shown using simulation engines. Using a simulation engine, researchers demonstrate the effectiveness of physical adversarial attacks on 3D vehicles, showing that even camouflaged vehicles can be detected by deep learning detectors. The simulation allows for testing under various environmental conditions, unlike existing experiments in simplified scenarios. In this paper, researchers focus on 3D vehicles and use a neural approximation function to synthesize adversarial objects like baseballs and turtles. They aim to create effective camouflage for 3D vehicle models by considering various transformations to hide them from neural detectors. The challenge lies in the non-differentiable image generation process of the simulator, suggesting the use of a neural network for training. The researchers aim to create effective camouflage for 3D vehicle models by using a neural network to approximate the non-differentiable image generation process of the simulator. They propose learning a substitute neural network to mimic the behavior of the object detector and imaging procedure, which is more feasible than training an image generation neural network. The researchers aim to create effective camouflage for 3D vehicle models by using a substitute neural network to mimic the behavior of the object detector and imaging procedure. This approach allows for running the EoT algorithm to infer adversarial camouflage for vehicles, with potential significant impact in various industrial applications. Adversarial attacks on autonomous driving systems are a significant threat, with the ability to legally perturb public machine learning systems by painting cars. The focus is on camouflaging cars within legally paintable body parts, leaving key visual cues unaltered for detectors. Adversarial attacks are powerful across various domains, including image classification, object detection, and audio recognition, bypassing defense mechanisms. Mainstream research typically focuses on in silico perturbations, which are not practical in the real world. In experiments, various perturbation methods failed to prevent detectors from detecting real stop signs. Physical world adversarial attacks were effective on printed paper, but not on object detectors YOLO9000 and Faster RCNN. Different perturbations were trained to attack classifiers on real stop signs and 3D-printed objects. Lu et al. (2017a) and BID11's work can be applied to attack stop sign detectors more effectively in the physical world. Blackbox attacks, such as BID29's target model substitution, rely on the availability of gradients between images and perturbations. However, due to the non-differentiable nature of simulations, coordinate descent methods are time-consuming, noisy, and non-convex, making them impractical for extensive evaluations. Deep learning models rely on data collection for performance. Some researchers use synthetic data due to high annotation costs. Various synthetic datasets have been proposed for different applications like semantic segmentation, tracking, and human action learning. Researchers have also adapted models from synthetic to real environments. Physical adversarial attacks on state-of-the-art models are being investigated. In this paper, physical adversarial attacks are investigated on neural network object detectors. The goal is to create a camouflage pattern that can make vehicles undetectable by Mask R-CNN BID18 and YOLO BID32 detectors under various conditions. The attack is conducted in a black-box manner using the Expectation-over-transformation (EoT) framework. The physical adversarial attack problem involves transforming a camouflage pattern onto a vehicle to minimize its detection score by neural network object detectors. The transformation process includes painting the pattern on the vehicle, driving it to a location, setting up a camera, and taking a picture. The study is conducted using the Unreal 4 game engine due to financial and time constraints. The study utilizes the Unreal 4 game engine for transforming a camouflage pattern onto a vehicle to reduce its detection score by neural network object detectors. Key techniques involve estimating expectations through empirical means and training a neural network to mimic joint behavior of detectors and simulators. The simulation engine uses a transformation procedure to apply camouflage to a vehicle and capture images with cameras. The camouflage is programmed as textures and warped onto a 3D model. The simulator can move the object to different locations and take photos from various angles. Key factors include the vehicle, location, camera distance, and viewing angle, leading to variations like lighting changes and occlusion levels. Multiple transformations are sampled for learning the camouflage. The simulation engine uses transformations to apply camouflage to a vehicle and capture images with cameras placed at different positions. Cameras are randomly arranged in heights and distances for variation. The detection score consists of rendering the camouflage image and using a vehicle detector like Mask-RCNN. The first component is non-differentiable while the second is a black box in practice. The simulation engine uses transformations to apply camouflage to a vehicle and capture images with cameras placed at different positions. Cameras are randomly arranged in heights and distances for variation. The detection score consists of rendering the camouflage image and using a vehicle detector like Mask-RCNN. To solve the problem, a neural network is trained to imitate the input-output behavior of the extended black box, taking as input a camouflage pattern, background image, and cropped foreground of the vehicle. The network approximates the detection score and allows for solving the problem using standard gradient descent. The fidelity of the problem depends on the size and diversity of the sampled set of transformations and the quality of the clone network. To address discrepancies, an alternative learning algorithm is used to learn the clone network and solve the problem alternatively. This helps in finding new camouflage patterns and optimizing problem (2). The iterative camouflage optimization framework involves converting the problem to multiple images for training. Detection scores are obtained for each image using a detector, and the scores are added to the training set for learning the clone network. The cross-entropy loss is used in solving two alternating problems, with regularization over the clone network's weights to prevent oscillations or degeneration of solutions. In the experiments, the clone network's approximation accuracy near optimal camouflage is emphasized by weighing newly added samples 10 times higher than old ones. Two baseline camouflage patterns are introduced: 6 popular car colors and 800 random camouflages. The resolution of the camouflage and its impact on detection performance are analyzed using 3D models of a 2015 Toyota Camry and a virtual SUV. Transferability of the learned camouflage across different car models, environments, camera positions, and object detectors is also tested. The experimental setup includes using the Unreal engine to create a simulation environment resembling downtown Manhattan. 32 locations with 8 cameras each are used for training and testing, with an additional 16 cameras for generalization testing. The relative position of cameras is indexed by viewing angle and camera-to-object distance. The study used 18 locations for training and testing vehicles in two different environments. One environment is a downtown scene, while the other is a countryside scene with mountains, bridges, forests, snow, and a lake. The vehicles used in the experiments are a 2015 Toyota Camry XLE and another vehicle. The study used a 2015 Toyota Camry XLE and a virtual SUV for object detection experiments. Two state-of-the-art detectors, Mask R-CNN and YOLOv3-SPP, were used, with Mask R-CNN ranking 4th in the MS COCO detection leaderboard. Detection performance was evaluated using two metrics. The study evaluated detection performance using two metrics: a modified Intersection over Union (IoU) and precision at 0.5 (P@0.5). The IoU was adjusted to focus on single vehicle detection, while P@0.5 measured the percentage of hit detections. Additionally, the study reported the relative precision drop of camouflage compared to baseline colors. The study evaluated detection performance using modified IoU and P@0.5 metrics. It also reported the relative precision drop of camouflage against baseline colors. Camouflages with strong contrasts were found to work better, generated using different RGB values. These camouflages were used to initialize the training set for the clone network V \u03b8 (c, t). Results show that camouflages exploit the domain gap between real and simulated data to successfully hide from detectors. Random camouflages visually differ from conventional car paintings but are still detected by the Mask R-CNN detector. Detector performance does not always decrease with camouflage resolution. The detector's performance may not decrease as camouflage resolutions increase, possibly due to fine-grained patterns being harder to observe from a distance. Camouflages of size 16x16 are used in experiments, with results showing Mask R-CNN's robustness against random camouflages in detecting the Camry in urban environments. Random camouflages have detection scores close to baseline colors, with low standard deviation indicating minimal impact on the detector's performance. The learned camouflage reduces the precision of detectors by around 30% in urban environments. Results show that the camouflage can defeat both Mask R-CNN and YOLOv3 to a certain degree. The study demonstrates the effectiveness of learned camouflage in reducing detector precision by around 30% in urban environments. Results in Table 2 show transferabilities across different environments, vehicles, camera angles, and distances. Detection results on baseline colors, random camouflages, and learned camouflages for the Camry are presented in Fig. 11, revealing successful attacks on objectiveness and misclassification of car regions. The study investigates the impact of learned camouflage on reducing detector precision in urban environments. Results show successful attacks on objectiveness and misclassification of car regions, highlighting the importance of context in object detection. The detector's performance differs from human vision, with some camouflaged vehicles still undetected. The research explores the possibility of physically camouflaging 3D objects like vehicles to hide them effectively. The study explores using learned camouflage to hide 3D objects like vehicles from object detectors. A clone network is used to create effective camouflage, reducing detectability of vehicles in different environments. Future work aims to improve the camouflage process. The study demonstrates the effectiveness of using pretrained camouflage on vehicles in urban environments. The Mask R-CNN detector shows high detection scores for baseline colors and random camouflage on a newly modeled SUV, despite not being trained on it. However, the detector is more susceptible to camouflage effects due to lack of training on the specific vehicle, resulting in lower detection precision. The experiment shows that Mask R-CNN performs well on unseen vehicles but is vulnerable to attacks. Transferring camouflage to a different environment, such as a barren landscape, improves detection due to fewer distractions. The detector detects the car better in this environment for both baseline colors and random camouflages. Our directly transferred camouflage outperforms baseline colors and random camouflages by more than 46% in detection mIoU and precision without fine-tuning. The Camry with grey color blends well with the background but is still detectable. Swapping camouflages between vehicles shows potential transferability in urban environments. The testing precision after swapping camouflages between vehicles shows potential transferability in urban environments. The SUV learned camouflage outperforms the Camry learned camouflage, possibly due to the SUV's more generic features. Testing the learned camouflage on new cameras around the vehicle shows a slight performance drop of 5%. The performance drop in camouflage is beyond the standard deviation of random camouflages' scores. The new camera views cover more perspectives, impacting the clone network's quality and necessitating alternative optimization. Without iterative optimization, the clone network can only find camouflages with mIoU around 70%. The clone network's global minima are calibrated by new samples, improving camouflage generation. The classification score is minimized to enhance performance, with spikes in the graph due to parameter re-initialization. Visualizing Mask-RCNN's detection attention on camouflaged objects provides insight into camouflage effectiveness against detectors. The Mask-RCNN implementation focuses on visualizing detection attention on camouflaged objects using Grad-CAM and saliency approaches. Grad-CAM is preferred for its abstracted semantic information in the last convolutional layer, despite challenges in defining a single \"penultimate layer\" in Mask-RCNN due to multiple layers tracing back to different network stages. In the context of visualizing detection attention on camouflaged objects using Grad-CAM and saliency approaches, the study focuses on defining attention in image classification scenarios and visualizing the gradient of the best bounding-box's classification score w.r.t. the input image. The visualizations reveal the predominant role of window, roof, and upper bodies in car detection, even when the upper body is not included in the detection bounding box. The study visualizes detection attention on camouflaged objects using Grad-CAM and saliency approaches. The detection stage makes classification decisions based on the proposed feature map box region. Front-view and rear-view detectors focus on the hood and trunk, making them easier to fail with camouflage patterns. Side-view detectors are harder to attack as they place less attention on the car body. The iterative optimization framework works on two Nvidia GTX 1080 Ti. The iterative optimization framework utilizes two Nvidia GTX 1080 Ti for running the detector, simulation, and training/prediction of evaluation network. The simulation is implemented using AirSim and UnrealEnginePython, with asynchronous submodules communicating via RPC/RPyC. Evaluation in the simulation takes 15 to 20 seconds, with V t (c) showing a standard deviation of 0.008 due to random processes in rendering. Repeat sampling V t (c) 5 times helps reduce this error. The blackbox optimization problem involves examining the convexity of E t V t (\u00b7) by testing the convexity of subsampled correspondence. Sampling random camouflages shows that half of them do not meet the equation, indicating non-linearity."
}