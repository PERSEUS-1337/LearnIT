{
    "title": "BJelsDvo84",
    "content": "EDA is a set of easy data augmentation techniques for text classification tasks, including synonym replacement, random insertion, swap, and deletion. It improves performance for convolutional and recurrent neural networks, especially on smaller datasets. Training with EDA using only 50% of the data achieves the same accuracy as normal training with all data. Ablation studies were conducted, and parameters for practical use were suggested. Automatic data augmentation is commonly used in vision and speech to train more robust models, especially with smaller datasets. While previous work in NLP has proposed techniques like translating sentences and using predictive language models for data augmentation, these methods are not widely implemented due to high costs relative to performance gains. This paper introduces a simple set of universal data augmentation techniques for NLP tasks. In this paper, a simple set of universal data augmentation techniques for NLP called EDA (easy data augmentation) is presented. The techniques are evaluated on five benchmark classification tasks, showing substantial improvements, especially for smaller datasets. Code will be publicly available. The EDA technique involves four operations: Synonym Replacement, Random Insertion, Random Swap, and Random Deletion, to improve the performance of text classifiers trained on small datasets. These operations help train more robust models by introducing noise into sentences while maintaining their original class. The EDA technique involves operations like Synonym Replacement, Random Insertion, Random Swap, and Random Deletion to enhance text classifier performance on small datasets by introducing noise into sentences while preserving their original class label. Varying the number of words changed based on sentence length is explored, and experiments are conducted on five benchmark text classification tasks. The study explores the effectiveness of EDA technique on text classification tasks using CNN and RNN models with varying training set sizes. Results show an average improvement of 0.8% for full datasets and 3.0% for N train =500 when using EDA. EDA was found to have significant improvements for smaller training sets in text classification tasks. Models trained with EDA achieved an average accuracy of 88.6% using only 50% of the available training data, surpassing the 88.3% accuracy achieved without augmentation. Individual dataset results are displayed in FIG3. The study examines the impact of EDA operations on sentence meanings while maintaining class labels. A visualization approach is used to analyze the changes in augmented sentences compared to original ones. Results show that augmented sentences closely resemble original ones in the latent space representations. Ablation studies are conducted to explore the effects of each component in EDA, with a focus on synonym replacement. The study conducted ablation studies to explore the effects of each component in EDA, focusing on synonym replacement. All four EDA operations were isolated to determine their individual ability to boost performance. Results showed that all four operations contribute to performance gain, with varying effects based on the augmentation parameter \u03b1 values. The study analyzed the effects of different EDA operations on performance. RS showed high gains at \u03b1\u22640.2 but declined at \u03b1\u22650.3. RD had the highest gains for low \u03b1 but hurt performance at high \u03b1. Improvements were more significant on smaller datasets, with \u03b1=0.1 being optimal. Overfitting was more likely on smaller training sets, so generating many augmented sentences boosted performance. Adding more than four augmented sentences per original sentence on larger training sets was unhelpful. The study recommends parameters for practical use in machine translation. Various approaches like back-translation, translational data augmentation, and synonym replacement have shown improvements in performance. Some studies have reported mixed results for using synonym replacement in text classification tasks. Most studies explore data augmentation techniques for improving model performance. EDA is compared to previous literature on data augmentation. BID4 and BID8 studies evaluated augmentation techniques on multiple datasets, showing gains in accuracy. EDA yields similar results but is easier to use as it does not require training a language model or external datasets. In comparison to previous studies on data augmentation, EDA is easier to use and does not rely on external datasets. It has been shown that simple data augmentation techniques can improve performance on text classification tasks, particularly on smaller datasets. Further research could explore the theoretical basis of EDA operations, with the hope that its simplicity will encourage widespread adoption in NLP. The implementation details for EDA include the use of a synonym thesaurus and word embeddings. The implementation details for EDA involve using WordNet for a synonym thesaurus and 300-dimensional Common-Crawl word embeddings trained with GloVe. The CNN architecture includes input, convolutional, max pool, dense, and softmax layers, while the RNN architecture consists of input, bi-directional LSTM layers, dropout layers, and dense layers. Both networks are initialized with random normal weights and trained using categorical cross-entropy loss with early stopping. Using EDA in text classification improves performance by introducing noise to prevent overfitting and adding new vocabulary through operations like synonym replacement and random insertion. Using EDA for data augmentation in NLP tasks introduces new vocabulary and helps models generalize to words not in the training set. While other techniques like contextual augmentation, noising, GAN, or back-translation are valid, EDA offers simple and generalizable methods with lower implementation costs. There is a slight chance that EDA may not improve performance, but results across multiple classification tasks suggest otherwise. Data augmentation operations in NLP tasks should not change the true label of a sentence to avoid introducing unnecessary noise. Inserting synonyms of words in sentences, rather than random words, is more likely to be contextually relevant and retain the original label."
}