{
    "title": "SylyHkHYDB",
    "content": "Knossos is a compiler that optimizes machine learning models without the need for custom back-ends, making it practical to train models on different hardware. It uses a rewriting approach driven by the $A^\\star$ search algorithm and a learn value function to automatically learn optimizations that past compilers had to implement manually. Knossos compiler automates optimizations previously done manually by compilers, achieving time reduction on machine learning programs like linear algebra and convolutional networks. It has few dependencies and works on any architecture supporting a \\Cpp toolchain. The proposed algorithm optimizes cost models tailored to hardware architectures, benefiting software development by producing fast code, especially crucial for modern machine learning models that can take weeks to train. Compiler optimizations for execution speed-ups are valuable as machine learning is deployed on diverse devices with varying performance profiles, requiring different code optimizations. The need for custom back-ends in machine learning frameworks is costly and error-prone. New tools are emerging to transform machine learning code using traditional software compiling techniques, eliminating the need for separate front-end APIs. Automatic differentiation is integrated as a key feature in the compiled language. Modern machine learning compilers integrate automatic differentiation as a core feature and use an intermediate representation for code optimization. Program optimization is treated as a machine learning task, with compilers learning to perform rewrites. Knossos rewrites programs in an intermediate representation to generate fast, customized code without relying on hand-written libraries. Knossos rewrites programs in an intermediate representation to enable seamless deployment on various platforms supporting a C++ toolchain, without manual tuning. It combines RL-based program optimization, deep learning support, and can target any architecture with C++ toolchain support. In Section 5, Knossos demonstrates the benefits of its program optimization by automatically learning loop fusion, a compiler optimization previously done manually. Code optimization is modeled as a finite-horizon Markov Decision Process (MDP), with detailed descriptions of states, transitions, and rewards provided later in the section. The Knossos program optimization involves a finite-horizon Markov Decision Process (MDP) with states, actions, and transition functions. The action set A allows for rewriting expressions using over 50 generic rules that do not change the program's meaning. The RL agent in the Knossos program optimization uses a policy \u03c0 to determine actions in states with a time budget. It aims to find an optimal policy \u03c0 that maximizes return, defined as R(s t , s t+1 ). The value function V (s) calculates expected returns based on the remaining time budget. The optimal value function V is defined as the value function of an optimal policy \u03c0, where the remaining time budget at state s is denoted by t s. A function c(s) provides the cost model for running the expression represented by state s. While perfect cost models are theoretically impossible, good cost models exist for programs that compilers optimize. The ideal cost model c B corresponds to the run-time of the program on typical inputs, but evaluating costs through benchmarking is computationally intensive. Surrogate cost functions can often approximate the ideal cost function for most initial programs. Knossos has a modular architecture, allowing for easy changes to the cost function and quick optimization for different hardware targets. The reward function is based on a cost model, with rewards corresponding to the reduction in cost when rewriting expressions. This formulation enables finding optimizations even if intermediate programs of higher cost are needed. The reward function in Knossos is based on a cost model, with rewards linked to cost reduction when rewriting expressions. The value function corresponds to expected cost reduction under the current policy, and the optimal value function is monotonic. Rewriting expressions poses challenges in exploration due to the growing set of actions and varying graph representations of states in the MDP. Knossos uses a custom RL algorithm for rewriting tasks, with deterministic MDP transitions and a large degree of locality. State transitions can be generated in any order convenient, unlike traditional RL settings. The algorithm is based on A* search supported by a value function learned with a focus on generalization for competitive solutions. Knossos uses a custom RL algorithm based on A* search supported by a value function learned with graph neural networks. The algorithm maintains two priority queues to explore states efficiently. The heuristic is obtained from previous iterations and guides the exploration process by estimating future cost reduction. The algorithm in Knossos uses A* search with a value function learned through graph neural networks to estimate cost reduction in states within a certain number of timesteps. The algorithm stops after evaluating the value function a set number of times. The Knossos algorithm utilizes A* search with a learned value function from graph neural networks to estimate cost reduction in states within a specified number of timesteps. It exploits determinism, reset availability, and locality to optimize re-writes based on a heuristic function. Additionally, deep RL is applied to computation graphs using Graph Neural Networks with Gated Recurrent Units for constructing differentiable embeddings. The process involves encoding the edge structure of a graph using a gated recurrent unit (GRU). Knossos expressions are represented as graphs with nodes representing subexpressions. Different types of edges connect nodes with their parents and indicate identical subexpressions. Initial node embeddings are computed using a one-hot encoding of node types. The initial node embedding consists of a one-hot encoding of the node type followed by zero padding. The message function is a single dense layer for each edge type, and the aggregation operator is the sum of all incoming messages. The GRU cell is used as the recurrent unit. The final node embedding is used to compute the value of the expression by taking a weighted sum and passing through a dense layer. The GNN is trained to approximate the optimal value function V. The value function V is computed for expression e and time budget t. To approximate the lower bound of V, the loss function l is minimized in Algorithm 2. Normalization by t is done to ensure target values for all outputs of V are in a similar magnitude. The value function estimate V(s) is obtained from per-step value estimate V(s) as V(s) = t * V(s). The Huber loss is used for the loss function. The optimization process is represented by the function FIT in Algorithm 1. Knossos is based on compiler technology, similar to traditional compilers and recent deep learning compilers like Myia and DLVM. Knossos, a compiler, differs from other deep learning compilers by learning the algorithm to optimize programs. It utilizes a Reinforcement Learning-driven optimizer, giving it an edge over existing approaches. Unlike benchmark-driven optimization approaches, Knossos is a fully-fledged compiler capable of optimizing arbitrary programs. Knossos, a compiler, utilizes a Reinforcement Learning-driven optimizer to optimize programs, outperforming other approaches like REGAL, TVM compiler, LIFT, and JAX. It differs from JAX by using efficient RL code. Knossos, a compiler, utilizes efficient RL code optimization and supports a broader variety of target architectures by generating C++ code. Unlike JAX, Knossos benefits from statically typed languages and uses an RL-driven code optimizer for automatic differentiation. Unlike established deep learning frameworks, Knossos learns to optimize code instead of relying on manually-prepared back-ends. The Knossos language allows direct usage without manual computation graph specification or language subset restrictions. Automated rewriting for achieving objectives has been explored in theorem provers, with recent work focusing on refutational proofs in first-order logic using hardcoded features. The algorithm for Reinforcement Learning in Knossos differs from standard techniques due to its larger action and state space, making traditional RL algorithms ineffective. AlphaGo, which also deals with a large state space, differs in its use of pixel observations and a bounded action space. RL has been applied to expression rewriting and scheduling problems using actor-critic RL, but it is less suited for Knossos. Knossos uses actor-critic RL for optimization tasks on arithmetic expressions and linear algebraic operations. The text discusses the implementation of a matrix multiplication function using Knossos IL and compares its performance to a hand-written rule-based transpiler called ksc. The cost of the function is evaluated and compared to the output of ksc, which both generate C++ code for compilation. The text compares the performance of Knossos IL and ksc in optimizing arithmetic expressions. Different strategies are needed to optimize similar expressions, making it challenging for rule-based compilers. Knossos was tested on 36 arithmetic expressions with a training set and 12 different ones with a test set. The experimental setup details are provided in Appendix B. In the experimental setup, 6 expressions are randomly picked from a training set to train in each epoch. Training is done for 30 epochs with 10 repetitions for each experiment. Knossos achieved the oracle cost for all expressions, compared to NoGNN algorithm and greedy best-first search. Results are shown in Figure 5a. Knossos achieved the best possible cost for all expressions in the experimental setup, including linear algebra primitives like vector multiplication and matrix multiplications. Knossos was evaluated on linear algebra primitives, including General Matrix Multiplication (GEMM). Training involved 5 epochs optimizing the cost of 6 primitives each. Search depth was limited to 30 with termination at 5000 evaluations. Results from 10 runs of Knossos optimizer on the same input file showed the cost of GEMM. Training included vector operations and was split into two phases with different sets of allowed rules. In the first phase, only rules resulting in large cost changes were allowed. Knossos produced code with lower cost compared to the traditional ksc compiler, as shown in Table 4. The output of Knossos also showed improvements in wall clock time, as depicted in Fig. 7a. Additionally, Knossos eliminated temporary variables in the output, indicating a form of loop fusion optimization. This optimization was previously a manual process in compilers. The evaluation of Knossos was performed on workloads, including Convolutional Networks. Knossos optimized code for training a convolutional deep network on the MNIST dataset, showing improvements in cost and wall clock time compared to traditional methods. The output also eliminated temporary variables, a manual process in compilers. The code snippet involves defining a function rev$conv1d for convolutional deep network training on the MNIST dataset, optimizing cost and wall clock time. It eliminates temporary variables and uses tuples and vectors for computations. The function rev$conv1d is defined for convolutional deep network training on the MNIST dataset, optimizing cost and wall clock time by using tuples and vectors for computations. The function rev$conv1d is defined for convolutional deep network training on the MNIST dataset, optimizing cost and wall clock time using tuples and vectors for computations. The implementation provided represents a typical deep learning algorithm. The Knossos optimizer focused on code optimization for a deep learning algorithm, using dense layers, convolutional layers, and pooling layers. Training was done on 5 expressions and evaluated on a reverse mode of a convolutional layer. The search depth was fixed at 40, with a termination condition of 30000 evaluations. Results showed improved performance in cost and wall clock time. Knossos optimizer produces code that outperforms traditional compilers by automatically discovering optimization strategies like loop fusion. It can run on any hardware supporting the C++ toolchain and is ideal for machine learning and numerical computation tasks. Knossos, with its automatic code optimization, generates binaries that outperform traditional compilers. It can handle complex code from automatic differentiation and discover optimizations without manual compiler design. Knossos has a LISP-like syntax and plans to offer transpilers for code conversion. The Knossos IL supports automatic differentiation for Machine Learning tasks. Knossos uses a type system and consistent rewrite rules for automatic differentiation, optimizing the cost of execution. Unlike PyTorch, Knossos generates tailor-made AD algorithms for specific use cases, making the process transparent to the user. The important feature of automatic differentiation (AD) in Knossos is its transformation of the abstract syntax tree, allowing for optimization of the resulting AST. Parameters for experiments and hyper-parameters for value network training are detailed. Graph Neural Network uses one-hot vectors for initial node features representing various node types and auxiliary edge types like \"is-identical\" to identify identical subexpressions for easier learning of re-writes. The GNN was implemented using a sparse adjacency matrix to conserve GPU memory. GNN recursion was run 10 times with Adam optimizer and specific dropout rates. Basic rule sets for arithmetic expressions and additional rewrite rules for linear algebra and CNN were listed. Monte Carlo Tree Search with UCT formula was compared to A search. MCTS iteration consists of four steps. Monte Carlo Tree Search (MCTS) involves four steps: Selection, Expansion, Simulation, and Back-up. The tree policy and rollout policy are defined to guide the search process. Evaluation of A search and MCTS performance was conducted for training and testing, following the experimental setup outlined in the previous section. The experimental setup for evaluating search algorithms involved using MCTS with \u03b1 = 5.0 and \u03b2 = 0.5 for training and testing. Results showed that using algorithm A for both training and testing achieved the best performance, outperforming MCTS in terms of total minimum cost. Various combinations of algorithms were tested, with A consistently performing better than MCTS. List of expressions in training set for Linear Algebra Primitives."
}