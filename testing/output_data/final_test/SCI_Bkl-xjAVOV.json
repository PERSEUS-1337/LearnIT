{
    "title": "Bkl-xjAVOV",
    "content": "The visual world can be divided into structured and unstructured factors. Structured factors like scale and orientation have clear theories, while unstructured factors like recognizing a cat require free-form representation learning. By combining structured Gaussian filters and free-form filters, optimized end-to-end, we can efficiently learn representations. Experiments show that dynamic structure with structured filters varying with input can match dynamic inference accuracy with improved efficiency. In this work, the authors propose a semi-structured composition of Gaussian and free-form filters to blur the line between free-form and structured representations. They emphasize that strongly structured representations must encompass the true structure of the data to be effective, as substituting structure for learning can lead to limitations and errors. The approach involves composing structured and free-form filters and learning both end-to-end. The authors propose a semi-structured composition of Gaussian and free-form filters to blur the line between free-form and structured representations. They combine structured and free-form filters to learn end-to-end, optimizing structured covariance parameters for efficient computation. The composition factorizes the representation into spatial Gaussian receptive fields and free-form features, making receptive field shape differentiable and decoupled from the number of parameters. The authors propose a semi-structured composition of Gaussian and free-form filters to blur the line between free-form and structured representations. The structure of a Gaussian is controlled by its covariance \u03a3, which for a spatial 2D Gaussian is Covariances come in families with progressively richer structure: spherical has one parameter for scale, diagonal has two parameters for scale and aspect, and full has three parameters for scale, aspect, and orientation/slant. Composing free-form filters f \u03b8 and structured Gaussian filters g \u03a3 by convolution * defines a more general family of semi-structured filters. The composition makes receptive field scale, aspect, and orientation differentiable in a low-dimensional parameterization for efficient end-to-end learning. The computation of the composition reduces to convolution, inheriting efficiency from tuned implementations. Gaussian step benefits from specialized filtering for memory efficiency. Each compositional filter can be explicitly formed for visualization or analysis. Dynamic Gaussian structure allows for a rich family of filters to be learned. Dynamic Gaussian Structure allows for the learning of a rich family of receptive fields that can adapt to variations in scale and orientation within an image. This dynamic inference replaces static, global parameters with local parameters inferred from the input, making the composition efficient by decoupling low-dimensional Gaussian structure from high-dimensional filters. There are two approaches to dynamic Gaussian structure: local filtering and deformable sampling. Dynamic Gaussian Structure involves two approaches: local filtering and deformable sampling. Local filtering uses a different filter kernel for each position, ensuring exact filtering for dynamic Gaussians. Deformable sampling adjusts the position of filter taps by arbitrary offsets to form sparse approximations of Gaussians. Sampling points are set through covariance, with Gaussian deformations illustrated in FIG3. The progression includes spherical, diagonal, and full covariance for dynamic structure. Our semi-structured composition requires a small number of covariance parameters independent of sampling resolution and kernel size. To infer local covariances, we use a convolutional regressor for each dynamic filtering step, making the regression more efficient than free-form deformation. Our composition uses a convolutional regressor for dynamic filtering, making regression more efficient than free-form deformation. We experiment on semantic segmentation of CityScapes BID2 dataset using fully convolutional DRN-A BID9 as our base architecture and deformable convolution BID3 as a strong baseline. The backbone is aggressively-tuned, but our composition delivers improvement through learning without further engineering. Dynamic Gaussian deformation reduces parameters, improves computational efficiency, and rivals the accuracy of free-form deformation. Even restricting the deformation to scale by spherical covariance suffices to equal the free-form accuracy. Deformable convolution by Gaussian structure improves efficiency while preserving accuracy. Free-form deformations are more general but less efficient in practice. Our results show that making scale dynamic is beneficial. Convolution requires 2k^2 parameters for a k \u00d7 k filter. Scale modeling through spherical covariance can achieve equal accuracy with fewer parameters. Our low-dimensional parameterization only needs one scale parameter, making it efficient for optimization on limited data."
}