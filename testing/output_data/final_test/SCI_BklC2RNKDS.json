{
    "title": "BklC2RNKDS",
    "content": "Formal verification of machine learning models has made progress in proving robustness to input perturbations. Folding verification into training makes it easier to train verifiably robust models. This paper extends verified training to recurrent neural networks and complex specifications beyond adversarial robustness, such as temporal properties. Experiments show that verified training produces models that perform well and meet desired specifications. Deep neural networks (DNNs) have shown significant progress on various tasks but lack formal guarantees of correctness. Researchers are exploring formal verification techniques for DNNs, focusing on feedforward networks and robustness to adversarial perturbations. Temporal logic, specifically Signal Temporal Logic (STL), is used to provide guarantees with respect to temporal specifications for DNNs with sequential outputs. This approach integrates a verification procedure into training to ensure properties like absence of repetitions or appropriate sequence halting. Our approach extends verified training for DNNs to include specifications beyond adversarial robustness, focusing on certifiably satisfying temporal specifications. We propose extensions to train auto-regressive GRUs/RNNs and demonstrate applicability in ensuring verifiable consistency with temporal specifications while maintaining high accuracy. Verified training on neural networks ensures high accuracy across domains and provides verification guarantees for unseen test data. This results in robust DNNs with easier specification conformance. Recent progress in neural network verification includes the development of solvers for verifying properties in deep neural networks. Recent advancements in neural network verification, such as using incomplete over-approximations and propagating bounds through the network, have led to more scalable techniques. Verified training, which integrates the verification process into the training loop, has shown promise in obtaining stronger guarantees. However, existing works focus mainly on adversarial robustness and feedforward networks with monotonic activation functions. This study aims to expand on these concepts by considering richer specifications for improved verifiability. In this work, the focus is on developing novel architectures with non-differentiable components and considering complex temporal specifications for verified training. Jia et al. also work on verifying LSTMs, CNNs, and networks with attention mechanisms, focusing on robustness to misclassification. The main difference is that this study emphasizes auto-regressive architectures and satisfying temporal logic specifications. The study focuses on training DNNs to satisfy rich temporal specifications over large sets of inputs, contrasting with previous work that enforces specifications on specific inputs. The emphasis is on verified training rather than falsifying specifications using stochastic optimization. The study emphasizes verified training of DNNs to satisfy rich temporal specifications, incorporating temporal logic objectives into training to achieve this goal. This approach contrasts with previous methods that enforce specifications on specific inputs. The study demonstrates the generality of their approach on image captioning and language generation tasks using Signal Temporal Logic (STL) for verification. STl extends Linear Temporal Logic (LTL) to reason about real-valued signals with specific syntax and qualitative semantics. Signal Temporal Logic (STL) extends Linear Temporal Logic (LTL) to reason about real-valued signals with specific syntax and qualitative semantics. STL formulae are interpreted over a discrete-time, vector-valued signal trace \u03c3. The until formula \u03d51 U I \u03d52 holds at a time instance t if \u03d52 holds for some time in the interval [t + a, t + b] and \u03d51 holds for all times in [t, t]. The paper restricts I to bounded-intervals of time and refers to Donz\u00e9 & Maler (2010) for detailed semantics of STL specifications. Bounded-time STL properties can be unrolled into logical properties using Boolean conjunction. Signal Temporal Logic (STL) extends Linear Temporal Logic (LTL) to reason about real-valued signals with specific syntax and qualitative semantics. STL provides a succinct notation for expressing temporal properties over input-output behaviors of neural networks. Examples of relevant properties that can be expressed in bounded-time STL are listed in Section 3.2. Multi-MNIST images consist of non-overlapping MNIST digits on a canvas of fixed size, with the task being to label the sequence of digits in the image. In the task of training a DNN to not output sequences longer than the desired length, a termination specification is enforced to ensure the end of sequence token is output no later than after the true number of digits have been output by the RNN. This approach is demonstrated in the RL setting. In the RL setting, a vacuum cleaning robot operates in a continuous domain divided into discrete cells. The robot receives rewards for visiting dirty cells and must recharge every T time-steps to avoid termination. The policy maps observations to velocity controls, aiming to verify the agent's location in recharge cells. The text discusses the specification for a vacuum cleaning robot in a continuous domain, ensuring it recharges within a set time frame. It also mentions the challenge of language models repeating words and how to formalize the property of non-repeating bigrams in output sequences. The verification is done over a large set of possible inputs for the generative model. The text discusses the formal specification for a language model to avoid repeating bigrams in output sequences. It involves evaluating the model output against a set of prefixes generated from a syntactic template. The goal is to learn a function that satisfies the specification for a given input set. The problem statement involves training the parameters of a function to satisfy a bounded-time STL specification. The verification task is to find inputs that result in the strongest violation of the specification. Equation 4 being negative leads to a violation of \u03d5. The optimization problem in equation 4 is often intractable, especially when robustness against perturbations in a classification task is considered. Tractable approaches exist to bound the problem in equation 4, but the bounds may be too loose. Interval bound propagation can be used for verified training to obtain tighter bounds on robustness under perturbations. Standard interval arithmetic is used for bound propagation on the function f, extending it to a richer set of specifications and architectures. Bound propagation is extended to richer temporal specifications and architectures, including auto-regressive RNNs/GRUs and STL specifications. Computing bounds across GRU cells involves interval arithmetic for handling multiplication operations. For auto-regressive RNNs, differentiable bounds are computed using a softmax operator during training to overcome non-differentiable operations like greedy decoding. The softmax operator converges to one-hot(argmax(\u00b7)) at low temperatures. Bounds propagation through the softmax operator leverages monotonicity in individual inputs. Lower and upper bounds on the output can be computed based on bounds on the input. Bound propagation for discrete inputs is discussed. Quantitative semantics for STL specifications are extended to reason over sets of inputs. The lower bounds for the quantitative semantics of a STL specification in negation normal form (NNF) over a set S are defined assuming lower bounds on all atoms in the specification. These bounds can be computed by first determining bounds on the outputs at each time step, and then propagating bounds on the input atoms. Training a network to satisfy an STL specification involves computing lower bounds on the atoms in the specification at each time step. By optimizing these bounds to be non-negative, we ensure that the specification holds. Balancing the loss objective for the base task with the positivity of the bounds is crucial during training. During training, optimizing the joint loss involves ensuring the positivity of bounds for the STL specification. Curriculum training is effective for optimizing the specification loss, gradually enforcing it over the entire dataset. Verified training is used to enforce termination specifications on the training data. After optimizing the joint loss during training, verified training is used to enforce termination specifications on the training data. Post training, for unseen test-set images, the quantitative specification loss is evaluated. If the loss is positive, it guarantees that no input within a certain radius can cause the RNN to generate a longer sequence than the true digits in the image. Verified training outperforms adversarial and nominal training in both termination accuracy metrics. The DNN remains robust to large perturbations, predicting single digits with high accuracy. Adversarial accuracy is evaluated using an iterative attack method. ReLU RNNs are used for verified termination accuracies, outperforming adversarial and nominal training. In this study, ReLU RNNs are used for verified training to certify specification conformance for larger perturbations. The recharging specification \u03d5 recharge is considered over a time-horizon of T = 10. The DNN is regularized to be verifiable with regard to \u03d5 recharge by rolling out the current policy through time. Comparison is made with vanilla RL and reward shaping trained agents, all achieving similar rewards without specification violations. Agents trained with verified training are more verifiable than agents trained otherwise, with little performance degradation. The language model used consists of a 2-layer GRU with 64 hidden nodes per layer, trained on the tiny Shakespeare corpus. The study evaluates different training methods for a language model on the Shakespeare corpus. Standard training achieves the best perplexity results but has many specification failures. Sampling prefixes and regularization can eliminate failures but at a high computational cost. Verifiable training with bound propagation offers a constant computational cost with good performance. Verification with propagating bounds through a layer of the form y = \u03c3(W x + b) can be done at a constant computational cost of \u2248 2 forward passes. This method is efficient, taking under 0.4 seconds for verification, compared to over 50 minutes for exhaustive search over 25M prefixes. Additionally, as word substitutions increase, the cost for exhaustive search grows exponentially while that for bound propagation remains constant. This approach extends verified training to tasks requiring temporal properties in DNNs with sequential outputs. Our experiments show that verified training improves the verifiability of DNNs, with fewer failures. Future work involves extending verification to unbounded temporal properties and developing better bound propagation techniques. In the RL setting, data-driven verification is important without a known environment model. STL formulae have quantitative semantics defined by a function \u03c1 for a given trace \u03c3. The qualitative semantics of STL formulae can be obtained from the sign of the quantitative semantics. The formulae can be converted to their equivalent negation normal form by a standard procedure. The normal form for \u00ac(\u03d51 U \u03d52) is obtained by pushing the negation into the subformulae and swapping min with max. The verification process involves induction on \u03d5, with base cases, conjunction, and atom cases being straightforward. The disjunction case requires applying the max-min inequality. Tasks with discrete inputs, like language generation, involve encoding a prefix sentence before decoding a follow-up word sequence. Perturbations in the prefix can be propagated by projecting tokens through an embedding layer and considering max and min values along each dimension. For the MMNIST dataset, a 2 layer-convolution network with 32 filters in each layer is trained for the GRU decoder. For the GRU decoder, a 2 layer-convolution network with 32 filters in each layer is trained, and the decoder has 2 cells with a latent space of 64 dimensions. The weights in the linear-layers of the GRU are normalized with the l1 norm for stabilization. Curriculum training involves initial training on the original task for 5000 steps, followed by training with specification loss for 300000 steps to meet the specification. Perturbation radius and coefficient \u03bb are gradually increased during training. Adversarial training includes a 7-step PGD attack. Adversarial training with a curriculum approach helps stabilize training, unlike using the largest perturbation radius. The set S defines feasible initial states for verification in the task. The agent's observation includes its coordinates, time until cells are dirty, and recharge locations. A policy is learned for continuous control actions. Verification is done in an environment with specific recharge and dirt accumulation times. The initial cell may have uncertainty in dust accumulation. The robot starts in an initial cell with up to 0.1% uncertainty in dirt, charge, and battery. If it leaves the domain, it is clipped back. The agent has 4 discrete actions and is trained using Deep-Q learning methods. For verifiable training, the agent is trained with a temporal specification and verification losses are optimized using the Adam optimizer. The model is trained for verifiability in regions outside the trained area, using a linear annealing weight approach. For text generation, a \"seq2seq\" model is trained with a GRU core. The Adam optimizer is used for optimization, with a decaying learning rate. The verification loss weight varies linearly and is clipped below 10. The Language Model prefixes are generated using specific syntax with defined pronouns, persons, and action verbs. Gradients during optimization are clipped at 0.1 to prevent exploding gradients. The language model generation is conditioned upon 25779600 possibilities in the space of combinations. An example prefix is: 'Our lord yielded and their king left'."
}