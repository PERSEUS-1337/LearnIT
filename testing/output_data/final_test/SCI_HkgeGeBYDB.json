{
    "title": "HkgeGeBYDB",
    "content": "RaPP is a new methodology for novelty detection using hidden space activation values from a deep autoencoder. It compares input and its reconstruction in both input and hidden spaces. By aggregating hidden space activation values with two metrics, RaPP enhances novelty detection performance. Extensive experiments show that RaPP improves detection compared to other methods on popular benchmarks. Novelty detection is crucial for identifying outliers in data samples compared to training data. It is especially useful in detecting fraudulent transactions, intrusion, video surveillance, medical diagnosis, and equipment failure. Deep autoencoders have shown great performance in compact data representation, with reconstruction error being a popular metric for novelty detection. In this paper, a new method called RAPP is proposed for detecting novelty samples using hidden activation values in addition to input values and their autoencoder reconstruction values. Unlike traditional methods that only measure reconstruction quality in the input space, RAPP extends comparisons to hidden spaces without requiring additional training of the autoencoder. The RAPP method quantifies input novelty by aggregating hidden activation values without additional autoencoder training. Two metrics measure reconstruction errors in input and hidden spaces, with a normalization step. RAPP extends comparisons to hidden spaces, showing equivalence between hidden space activation values and original input reconstruction. The RAPP method introduces a new approach to novelty detection by utilizing hidden activation values of an autoencoder. It incorporates hidden reconstruction errors along with ordinary reconstruction errors to improve detection accuracy. Extensive experiments demonstrate the effectiveness of RAPP compared to other methods, outperforming recent developments on benchmark datasets. The proposed novelty detection method, RAPP, utilizes hidden activation values of an input and its autoencoder reconstruction to quantify novelty. It extends the reconstruction concept into hidden spaces and improves detection accuracy in diverse datasets, outperforming recent methods on benchmark datasets. Variational Autoencoders (VAE) are effective for novelty detection in highly class-imbalanced data. By training an autoencoder with only normal data, the reconstruction error can be used to detect samples out of the normality. A higher reconstruction error indicates that the input value cannot be encoded onto the lower-dimensional space. Reconstruction error signifies the inability to encode input onto a lower-dimensional space, marking it as a novelty if it exceeds a threshold. Generative Adversarial Networks (GAN) are also used for modeling normal data distribution. Combining autoencoders and adversarial learning aims to achieve both dimension reduction and data generation criteria. Limitation of methods based on reconstruction error is the failure to utilize all available information. In the context of novelty detection, the reconstruction error in deep autoencoders fails to utilize all available information along the projection pathway. Two cases in novelty detection involve a small fraction or a majority of classes being normal, each requiring different approaches for evaluation and training data organization. In this paper, the proposed novelty detection method RAPP is evaluated along with other methods using experiments on datasets with a large number of normal classes. The method is based on an autoencoder and compares hidden activations of inputs and their reconstructions to quantify novelty. Two metrics are presented to measure the difference within each pair of activation values. An autoencoder is a neural network with an encoder and decoder for dimension reduction. The encoder creates a latent space for more concise data representation. It is used for novelty detection by measuring reconstruction error, where larger errors indicate a more novel test sample. However, relying solely on reconstruction error may not fully utilize the autoencoder's potential. The reconstruction error in novelty detection with autoencoders may not fully utilize the deep architecture's hierarchical information. To address this, exploiting hidden spaces can capture differences between normal and novel samples more effectively. Hidden spaces along a projection pathway of A are examined to quantify the novelty of samples x and x in RAPP. The algorithm aggregates hidden representations (h i , \u0125 i ) and is a generalization of the ordinary reconstruction method. The hidden activation of the reconstruction input is computed, equivalent to the hidden reconstruction of the input. The algorithm RAPP computes a novelty score using two metrics, SAP and NAP, which utilize hidden spaces more extensively than ordinary methods. These metrics are useful when no prior knowledge is available for selecting layers in deep neural networks. SAP sums the square of Euclidean distances for all pairs in the hidden space H, but does not consider properties of the hidden spaces. To capture clearer patterns in hidden spaces, the distances are normalized via orthogonalization and scaling. The normalization involves computing the SVD of a matrix D, obtaining its singular values and right singular vectors. The Mahalanobis distance with the covariance matrix V \u03a3\u03a3V is used to define a new distance metric sNAP for data samples x. Despite the quadratic computation time of SVD, its impact is relatively significant. In practical setups, the impact of the quadratic computation time of SVD on the target matrix is relatively small. The reconstruction error in hidden spaces is not extensively employed due to differences in encoding and decoding layers. The autoencoder objective lacks terms involving activations from intermediate hidden layers, making direct reconstruction challenging. However, there is an indirect way to compute hidden space reconstructions. In practical setups, the impact of SVD's quadratic computation time on the target matrix is minimal. The autoencoder objective lacks terms involving activations from intermediate hidden layers, making direct reconstruction challenging. However, an indirect method to compute hidden space reconstructions is possible. This involves defining low dimensional manifolds and using decoders to enable hidden reconstructions without the need for certain computations. The indirect method to compute hidden space reconstructions involves defining low dimensional manifolds and using decoders to enable hidden reconstructions without the need for certain computations. Neural networks are highly flexible, but using the symmetric architecture for f i may hinder learning f i = g \u22121 i. Neural networks are flexible frameworks that can represent complex functions by adjusting network architecture. This allows for the approximation of functions like f i even with multiple layers. RAPP is evaluated against existing methods using datasets from Kaggle and the UCI repository for novelty detection. MI-F and MI-V share the same feature matrix but are considered different. In comparing RAPP with standard autoencoder-based methods, MI-F and MI-V datasets are used, where labels are assigned differently. Benchmark datasets like MNIST and F-MNIST are also utilized. Novelty detection focuses on deviations from normal patterns, with training sets containing only normal samples and test sets containing both normal and anomaly samples. In anomaly detection setups, datasets with anomaly labels assign samples to the test set for detection. Two setups are considered: Multimodal Normality where one class is novelty and the rest are normal, and Unimodal Normality where one class is normal and the rest are novelty. These setups were applied to various datasets like STL, OTTO, SNSR, MNIST, and F-MNIST for comparison using AUROC. Thresholding-based metrics like F1 score were not used. In anomaly detection, the focus is on the separability of models for novelty using AUROC. Different models like Autoencoder, Variational Autoencoder, and Adversarial Autoencoder are compared for effectiveness. Benchmark datasets and recent approaches are also evaluated. Test sets are created with specific novelty ratios for different setups. The study compares Autoencoder (AE), Variational Autoencoder (VAE), and Adversarial Autoencoder (AAE) models for anomaly detection using AUROC. Symmetric architecture with fully-connected layers is used for the three base models. PCA is performed on Kaggle and UCI datasets to determine bottleneck size. Leaky-ReLU activation and batch normalization layers are added to all layers except the last layer. Models are trained with Adam optimizer and the best model is selected based on validation loss. VAE training stability is ensured by averaging 10 Monte Carlo samples in the reparameterization trick. Carlo samples were averaged in the reparameterization trick to obtain reconstructions from the decoder. SAP and NAP calculations excluded reconstructions in the input space for MNIST and F-MNIST. AUROC scores were averaged from five trials to reduce random errors. Additional results are provided in the Appendix, including standard deviations, comparisons to baselines, and the effect of varying hidden layers in RAPP computation. Table 2 summarizes the performance evaluation, highlighting the best scores for each model and dataset. Anomaly labels were not available for STL, OTTO, SNSR, MNIST, and F-MNIST, so scores were averaged over all possible anomaly class assignments. In the unimodal normality setup, RAPP shows the highest AUROC scores for most cases, achieving the best performance in 13 out of 15 datasets. NAP outperforms all competing methods in most cases, especially when combined with VAE. The proposed novelty detection method utilizes hidden reconstructions along a projection pathway of deep autoencoders. The proposed novelty detection method utilizes hidden reconstructions along a projection pathway of deep autoencoders, outperforming other methods in terms of AUROC for diverse datasets. Experimental results show superior performance compared to competing methods. Comparisons are made in terms of computation time between training an autoencoder and computing SVD for NAP, with varying input matrix sizes. The experiment varied the depth and bottleneck size of autoencoders, showing that Pytorch SVD on GPU is 47x faster than training neural networks. Even fbpca on CPU achieves a 2.4x speedup. Standard deviations of results are provided. Performance of NAP is investigated by increasing hidden layers. Adding hidden layers incrementally can be done in two ways: forward addition from the input layer or backward addition from the bottleneck layer. Experimental results on two datasets show that more hidden layers generally lead to better performance. The values presented are from a single trial, not averaged over multiple trials as in Section 5."
}