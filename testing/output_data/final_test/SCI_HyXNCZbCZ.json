{
    "title": "HyXNCZbCZ",
    "content": "We propose a novel hierarchical generative model trained using adversarial learning, supporting the learning of abstract representations and providing meaningful reconstructions. By minimizing the Jensen-Shanon divergence, we achieve semantically meaningful latent structure discovery on the CelebA dataset, outperforming handcrafted features and remaining competitive with recent deep supervised approaches on attribute prediction tasks. Recent research has focused on deep generative modeling strategies, including Variational Autoencoders (VAE), autoregressive models, and Generative Adversarial Networks (GANs). GANs have become popular for various tasks, especially in computer vision, simulation, and robotics. They involve a game between generative and discriminator networks to generate realistic examples. The discriminator in GANs is trained to distinguish between true and generated examples, while the generative model aims to fool the discriminator. This approach eliminates the need for a reconstruction-based loss function, allowing for visually sharper image generation compared to VAEs and faster sampling than autoregressive models. Recent advancements in GANs, such as ALI or BiGAN, have incorporated the learning of an inference network, where the encoder maps training examples to a latent space variable and the decoder acts as the generator. In ALI, the discriminator distinguishes between the encoder and decoder, while they work together to deceive the discriminator. In ALI, the encoder and decoder conspire together to fool the discriminator using a purely adversarial approach. This adversarial-only formalism results in high-quality generated samples and allows for inferring the latent code associated with true data examples. Despite not being explicitly trained for reconstruction, the encoder and decoder can easily reconstruct data samples by projecting them into the latent space and back to the data space, preserving some semantic features. The discrepancy between data samples and their ALI reconstructions is explored in this paper. Improvements in reconstructions are achievable by adding terms that minimize reconstruction error in the data space to the training objective. Non-identifiability issues in bidirectional adversarial training are addressed by augmenting the generator's loss with an adversarial cycle consistency loss. The paper delves into issues surrounding the representation of complex, richly-structured data. In this paper, a novel hierarchical generative model called HALI is introduced, which extends ALI to represent complex data like natural images. The hierarchical structure of HALI allows for modulation of perceptual fidelity in reconstructions through adversarial training. The theoretical arguments and empirical evidence presented support HALI's effectiveness in minimizing reconstruction cost. The learned representations are evaluated on tasks using MNIST and CelebA datasets, showcasing the hybrid approach of combining VAEs and GANs in generative modeling. Research has explored various aspects of VAEs and GANs, such as replacing the Kullback-Leibler divergence in VAEs with an adversarial discriminator in Adversarial Autoencoders. Another direction involves combining GAN generators with VAE decoders and using auxiliary losses like pre-trained classifiers. Additionally, there is a focus on augmenting GANs with inference machinery, including joint training of inference networks with GAN discriminator and generator. Generative modeling aims to capture complex data-generating processes with probabilistic models. Various approaches have been explored, such as leveraging multiple discriminators in directed acyclic graphs (BID15) and decomposing data generation into subtasks with stacked discriminators (BID12). The idea of stacking discriminators can be traced back to previous works like BID4, which used convolutional networks in a Laplacian pyramid framework to enhance image resolution. Generative Adversarial Networks (GANs) model complex data-generating distributions by transforming a fixed distribution over latent variables. The adversarial loss in GANs forces the generator network to produce samples close to the data distribution. Adversarially Learned Inference (ALI) extends GANs by including an inference network for encoding data into the latent space, allowing for inference on latent variables. The ALI objective aims to match joint distributions of data and latent causes from the generator and inference network, enabling inference on latent variables. Improvements sought include better perceptual matching in reconstructions and compressing observables into a hierarchy of stochastic latent representations. In information-theoretic terms, the conditional entropy decreases as we move up the hierarchy, impacting perceptual fidelity in ALI reconstructions. The goal is to maintain high fidelity while compressing the latent space. HALI, a novel model, achieves this by using a hierarchical Markovian inference network trained adversarially with a generator network. The hierarchical inference network induces a hierarchy of reconstructions, minimizing errors during training. During adversarial training, errors are minimized. HALI's hierarchical inference network is used for semi-supervised learning in generative adversarial models. Markov kernels are defined and composed to construct a hierarchy of feature transitions with adjoint feature transitions for generative mechanisms of latent variables. The HALI model uses a hierarchical inference network for semi-supervised learning in generative adversarial models. Markov kernels are composed to create a hierarchy of feature transitions for generative mechanisms of latent variables, with an encoder and decoder structure. The training procedure involves sampling from the prior and encoder hierarchy levels. The encoder and decoder distributions are visualized graphically, and adversarial training is used to match these distributions. The training procedure involves minimizing the Jensen-Shanon divergence between joint distributions. The Markovian character of both encoder and decoder implies a hierarchy of reconstructions in the decoder. The model in question yields multiple reconstructions for a given observation x, with each reconstruction corresponding to a different level of the hierarchy. Unlike other models, HALI does not require additional terms in its loss function to minimize reconstruction errors. Training in HALI aims to minimize the Jensen-Shanon divergence between distributions as training progresses. Training in HALI aims to minimize the Jensen-Shanon divergence between distributions to learn hierarchical representations and reduce reconstruction errors. Propositions 1 and 2 establish the dynamics between the learned representations, reconstruction errors, and adversarial matching of joint distributions. Theoretical propositions in HALI establish the relationship between reconstruction errors, adversarial matching of joint distributions, and hierarchical representations. Empirical evaluation of HALI focuses on improving perceptual reconstructions, creating semantically meaningful representations, and usefulness for downstream classification tasks on various datasets. Markov kernels parametrized by conditional isotropic Gaussians are used for different datasets with varying resolutions of latent variables. Residual blocks with skip connections and batch normalization are utilized in the encoder and decoder. Downsampling is done with convolution and upsampling with bilinear interpolation. The discriminator includes stride convolutions, weight normalization, and dropout regularization. Gaussian noise is added to inputs. HALI aims to improve perceptual reconstructions in generative models. HALI offers improved perceptual reconstructions compared to ALI model, shown through reconstructions on ImageNet, SVHN, and CIFAR10. HALI's reconstructions exhibit local and global changes in natural images, with higher conditional reconstructions often being a different member of the same class. The increase in reconstruction fidelity does not affect the quality of generative samples. Quantitative assessment confirms preservation of perceptual features in input samples. HALI's reconstructions outperform VAE and ALI models in preserving identifiable attributes, as shown by a quantitative assessment on the CelebA dataset. The encoder-decoder relationship of HALI better preserves perceptual features compared to other models. HALI's reconstructions preserve identifiable attributes better than other models. A metric is constructed by computing the Euclidean distance between input images and their reconstructions in the discriminator's feature space. The average reconstruction errors decrease steadily as training progresses, with reconstructions from the first level of the hierarchy having uniformly bounded errors compared to the second level. The VAEGAN model of BID20 minimizes perceptual reconstruction error explicitly, while HALI minimizes it implicitly during adversarial training. Comparison of reconstruction errors using Euclidean and discriminator embedded distances shows that errors for x \u223c T x|z 1 are consistently lower than x \u223c T x|z 2. Euclidean distance poorly approximates natural image manifold. Quality of learned representation is assessed through inpainting and visualizing hierarchy and innovation vectors. Our model utilizes HALI adversarial loss for inpainting, predicting missing portions from higher level reconstructions and iteratively using lower level reconstructions for pixel-wise accuracy. The effectiveness lies in extracting semantically consistent reconstructions from higher levels and leveraging pixel-wise reconstructions from lower levels. This approach is demonstrated on SVHN, CelebA, and MS-COCO datasets without blending or explicit supervision. The model utilizes HALI adversarial loss for inpainting, leveraging higher level reconstructions for semantic consistency and lower level reconstructions for pixel-wise accuracy. By varying latent variables, it is shown that higher levels encode abstract representations, while lower levels capture local details. The approach is demonstrated on various datasets without blending or explicit supervision. The HALI model uses latent variables to modify data samples by manipulating their codes, resulting in latent semantic innovations. This process involves encoding data samples, modifying specific entries in the latent codes, and decoding the modified vectors to generate innovations. The HALI model utilizes latent variables to manipulate data samples by modifying their codes, resulting in latent semantic innovations. This method allows for explicit control over variations on real samples in an unsupervised manner. The results of this approach, evaluated on the CelebA validation set, demonstrate its usefulness for downstream tasks such as attribute classification. Performance is measured using linear SVMs on the HALI encoder representations, with balanced accuracy reported for attribute prediction evaluation. The HALI model, trained on unsupervised data, outperforms VAE, ALI, and handcrafted features in attribute prediction. Results show superiority over various supervised and deeply supervised features. HALI achieves a balanced accuracy of 73, surpassing other models in the comparison. The HALI model outperforms VAE, ALI, and handcrafted features in attribute prediction with a balanced accuracy of 73. It can be used in a semi-supervised setting where the encoder receives a training signal from the supervised objective. The approach leverages the Markovian hierarchical inference network provided by HALI. HALI is a generative model that learns a hierarchy of latent variables with a simple Markovian structure. It achieves state-of-the-art results in a semi-supervised MNIST digit classification task with 100 labeled examples. The model extends the ALI framework to a hierarchy, showcasing both theoretical and empirical advantages. Extending the ALI framework to a hierarchy in HALI shows theoretical and empirical advantages. Future research should focus on stabilizing and simplifying the training process, especially with the added complexity of a hierarchy of latent variables. The text discusses Kullback-Leibler's upper bound by Jensen-Shannon for two probability distributions p and q. It establishes the existence of a positive scalar K and bounds the Kullback-Leibler divergence by the \u03c7 2 -distance using Jensen's inequality and Taylor expansion. The \u03c7 2 -distance and Jensen-Shannon divergences are f-divergences with specific generators. The function h(t) = f \u03c7 2 (t) / f JS (t) is strictly increasing on [0, \u221e) due to q being bounded away from zero. The text discusses the upper bound of Kullback-Leibler divergence by Jensen-Shannon for probability distributions p and q. It establishes a positive scalar K and bounds the divergence using Jensen's inequality and Taylor expansion. The Jensen-Shannon divergence is an f-divergence with a specific generator, and the function h(t) = f \u03c7 2 (t) / f JS (t) is strictly increasing on [0, \u221e) due to q being bounded away from zero. Integrating over the marginal and applying Fubini's theorem yields DISPLAYFORM16 where the conditional entropy H(x | z l ) is computed under the encoder distribution."
}