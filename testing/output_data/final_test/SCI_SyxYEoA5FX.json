{
    "title": "SyxYEoA5FX",
    "content": "We study the invariance and robustness of neural networks by examining the non-uniqueness and instability of the inverse mapping, focusing on ReLU-layers. Theoretical and numerical results are provided, including a necessary condition for invariance and analysis of local effects on the inverse for robustness. This reverse perspective offers insights into key effects and alternative views on adversarial examples, crucial for addressing the growing demand for robustness in deep learning applications. Invariance and stability are key mechanisms in dealing with uninformative properties of input BID0 BID6, studied from an information theoretical perspective. They are linked to robustness against adversarial attacks and training of Generative Adversarial Networks. Stability is studied locally via a norm of the Jacobian and globally via the Lipschitz constant. Unlike other approaches, we aim to broaden our understanding by analyzing upper bounds on stability. Our analysis focuses on studying perturbations that minimally affect the outcome of a network F, considering small changes under a perturbation \u2206x with a given \u03b5 > 0. This perspective contrasts with adversarial examples, as we examine the instabilities of the inverse mapping rather than the stabilities of the forward mapping. The study focuses on the instability of the inverse mapping of a network F when subjected to perturbations \u2206x. It discusses how robustness to large perturbations can lead to an unstable inverse mapping, particularly in ReLU networks. The preimage of ReLU-activations is characterized as single point, finite, or infinite. The stability of linearization in rectifier networks is analyzed through singular values. Visualizations on a synthetic problem illustrate these properties. The local behavior in ReLU-layers is constant on polytopes, with regions of infinite/finite preimages corresponding to condition numbers of one or zero. Singleton preimages are linked to larger condition numbers. Our contributions include deriving conditions for the preimage of an output of a ReLU-layer, developing an algorithm to check these conditions, and studying the stability of the inverse mapping by analyzing the linearization at a point in input space. We provide upper bounds on the smallest singular value of a linearization and demonstrate how singular values evolve over different layers in rectifier networks. The text discusses the evolution of singular values in rectifier networks and introduces a reverse view on adversarial examples connected to invariance and robustness through the analysis of preimages. It explores mechanisms affecting invertibility and the shape of preimages of outputs from ReLU layers. The text explores the reconstruction property of cReLU and the preimage of ReLU-activations without assumptions on weights. It also mentions the development of reversible network structures and the challenges of invariance and robustness in network design, particularly in relation to adversarial examples. The text discusses stability in rectifier networks, focusing on global injectivity and stability bounds for single layers with ReLU and pooling. It also mentions applications like inverse problems and parameter estimation, which often require network inversion. In this section, the notation for rectifier networks is briefly explained, including pre-activations, activations, number of layers, and matrix operations. Key definitions such as null space, Euclidean inner product, and matrix association with finite sets are also provided. In this section, the analysis focuses on different preimages of a ReLU-layer to determine conditions for the inverse image of a point being a singleton or having finite/infinite volume. This analysis leads to a simple algorithm distinguishing between these preimages, crucial for studying single layers in rectifier networks. The study focuses on investigating the image space of a ReLU layer and the non-injectivity feature of the ReLU activation function. Other activation functions like ELU and Leaky ReLU are injective but trade invariance for robustness, leading to unstable inverses. The concept of omnidirectionality is introduced as a key tool for analysis. The concept of omnidirectionality is introduced as a key tool for analysis in investigating the image space of a ReLU layer. An omnidirectional matrix A in R m\u00d7n is such that for every direction of a hyperplane through the origin forming two halfspaces, there is a vector from the rows of A inside each open halfspace. This property is illustrated in FIG1 and is related to cReLU BID13. The concept of omnidirectionality is crucial for analyzing the image space of a ReLU layer. It is directly linked to the ReLU-layer preimages and helps characterize their volume. By considering a mixed linear system involving A, b, and y, we can analyze inverse images efficiently. Additionally, the mixed system can be enhanced by incorporating conditions or priors on x. The preimage of a point y under a ReLU-layer is a singleton for k = 0, a singleton if there exists an index set I for the rows of A and b that is omnidirectional, and a compact polytope with finite volume if A is omnidirectional. The matrix must contain a simplex in order to be omnidirectional, as the convex hull of the matrix A \u2208 R m\u00d7n has to have an interior. The convex hull of matrix A \u2208 R m\u00d7n must have an interior for omnidirectionality. A tuple (A \u2208 R m\u00d7n, b \u2208 R m) is omnidirectional for a point p \u2208 R n if m hyperplanes generated by rows of A with bias b intersect at p and their normal vectors form an omnidirectional set. Singleton preimages of ReLU layers are unlikely without sufficient linear equalities in the mixed linear system. An algorithm can be derived to check if a preimage is finite, infinite, or a singleton. In the context of omnidirectionality, a linear programming problem can determine if the preimage of a layer is finite, infinite, or a singleton. This was demonstrated using a MLP model with two hidden ReLU layers on the MNIST dataset. The preimage can vary based on the given point, with the possibility of being a singleton, infinite, or finite. In Figure 4, the number of samples in the test set with infinite or finite preimages over positive outputs is plotted. Samples with 784 or more positive outputs are assumed to have a singleton preimage. The analysis focuses on the robustness of rectifier MLPs against perturbations by studying the stability of the inverse mapping, particularly the effect of ReLU on the singular values of the linearization of the network. The linearization of ReLU networks is exact in some neighborhood due to its piecewise-linear nature. The input space of a rectifier network is partitioned into convex polytopes, simplifying the network into linearized matrices through weight matrix multiplications that incorporate the effect of ReLU. Admissible index sets formalize local behaviors and diagonal matrices model the effect of ReLU. The linearization of ReLU networks involves weight matrix multiplications to incorporate the effect of ReLU, with admissible index sets formalizing local behaviors and diagonal matrices modeling this effect. The mapping of pre-activation z under ReLU can be written as a matrix chain, with a global upper bound for the largest and smallest singular values of DIA. The smallest non-zero singular value of DIA is upper bounded by \u03c3k, where k = N - |I| and \u03c31 \u2265 ... \u2265 \u03c3N > 0 are the non-zero singular values of A. The largest singular value is upper bounded by \u03c31. Lemma 8 analyzes the best case scenario for the smallest singular value, but reaching this bound is unlikely due to the alignment of singular vectors. Effects of ReLU on input polytopes are studied, with an example shown in Figure 3. The effect of ReLU on input polytopes is analyzed, showing that removing weakly correlated features can lead to ill-conditioned singular vectors. Modern deep networks often face redundant situations vulnerable to this phenomenon, with proposed regularizers to mitigate it. Lemma 9 formalizes the removal of weakly correlated rows in a matrix A. The effect of ReLU on input polytopes is analyzed, showing that removing weakly correlated features can lead to ill-conditioned singular vectors. In a highly redundant setting, a large correlation is needed to fulfill a condition for the upper bound on the smallest singular value. The impact of ReLU on multiple layers is also discussed, including questions about pre-conditioning effects and the composition of orthogonal matrices with stable inverses. The nonlinear nature of ReLU can destabilize matrix products in neural networks, especially when considering different input polytopes. Applying ReLU can remove orthogonality properties in the rows of matrices, leading to non-orthogonal columns. This can affect the stability of matrices with stable inverses in the network layers. The nonlinear nature of ReLU can destabilize matrix products in neural networks, affecting the orthogonality properties of matrices and leading to decaying singular values. This instability can arise even when designing the network with orthogonal matrices. The analysis showcases qualitative effects of ReLU on singular values, valid for any MLP. Experimental studies on CIFAR10 using baseline CNNs further examine the stability properties of the network. Our CNN architectures in 2009 use only strides, no pooling, residual connections, or normalization layers. The evolution of singular values over multiple layers is shown in Figure 6, where the largest singular value grows while smaller ones decrease. This growth aligns with observations for adversarial examples. Defense strategies by Cisse et al. (2017) and Jia (2017) focus on the largest singular values. In the study, the behavior of smaller singular values in defense strategies is often overlooked. A numerical analysis in Appendix A5 explores the effects of ReLU on singular values. The relationship between stability and invariance is investigated, showing a tight relationship between output size, condition number, and non-zero singular values for different CNN architectures. ReLU has a different effect on ThinCIFAR, reducing the number of singular values in layer 5 and lowering the condition number. However, there are more invariance directions within the linear region. Computational costs for linearizing a network F and computing the full SVD scale cubically, especially for early CNN layers with high-dimensional outputs. To address memory issues, a small CNN trained on CIFAR10 is chosen for analysis. Scaling up to larger networks like VGG on ImageNet requires restricting the analysis to input image windows to simplify the full SVD complexity. See BID2 for singular values restricted to input windows. The analysis focuses on the characterization of preimages over multiple layers in a ReLU-layer neural network. The approach is currently limited to a layer-by-layer study due to computational constraints. The study aims to identify specific layers where information is expressed in non-singleton form. The analysis focuses on characterizing preimages in a ReLU-layer neural network, specifically looking at convolutional layers and their sparse structure. Inverse stability is considered by linearizing input polytopes, with a focus on the impact of ReLU on the shared structure of matrix chains in convolutional networks. In the stability analysis of ReLU-layer neural networks, the focus is on characterizing preimages in convolutional layers. The analysis employs a piecewise-linear viewpoint to characterize stability via singular values of the linearization within an input polytope. Questions arise regarding the reachability of points in an \u03b5-ball around a point y, leading to the need for nonlinear considerations to model movements between piecewise-linear regions. The analysis focuses on the effects of ReLU on network design and regularization, emphasizing the importance of controlling omnidirectionality and correlation between feature maps through architecture design and regularization techniques. The analysis highlights the challenge of controlling network properties like omnidirectionality and correlation through regularization or architecture design. Incorporating additional structure in reversible networks can help ensure a singleton preimage. The analysis is linked to mutual information loss and the impact of invariance on information bottleneck. Instable inverses can lead to information loss due to quantization of activations. Invariance and robustness can affect space contraction along uninformative directions, with implications for adversarial examples. Invariance and robustness can lead to vulnerabilities for adversarial examples by contracting space along uninformative directions. Adversarial examples are small perturbations causing large changes in network outputs, but if input changes semantically and the output remains robust, the model may still be flawed. Addressing invariance and robustness through invertibility can help mitigate these issues. Invariance and robustness can lead to vulnerabilities for adversarial examples by contracting space along uninformative directions. Addressing invariance and robustness through invertibility can help mitigate these issues. The preimage of the output can indicate the stability of the inverse mapping in ReLU networks, with conditions determining if it is a point, finite, or infinite. The study also explores how ReLU affects the stability of the linearization in the inverse mapping. The study examines the effects of ReLU on the stability of the linearization and the preimage properties in neural networks. It highlights the importance of controlling these properties, especially in the context of adversarial examples. The research suggests exploring theoretical directions to incorporate nonlinear effects and strengthen the link between omnidirectionality and singular values. The text discusses the equivalence of omnidirectionality in matrices and the convex hull definition. Stiemke's theorem is also mentioned, showing the equivalence of two expressions involving matrices. The proof of Singleton solutions of inequality systems is provided as well. The text discusses the equivalence of omnidirectionality in matrices and the convex hull definition. Stiemke's theorem is also mentioned, showing the equivalence of two expressions involving matrices. The proof of Singleton solutions of inequality systems is provided as well. Here we prove that if A| I is not omnidirectional, then the solution for the inequality system Ax + b 0 is non-unique. The text discusses the uniqueness of solutions for the inequality system Ax + b 0 when x * = 0. The proof shows that x 0 is a non-unique solution in this case. The ReLU-layer equation is considered as a mixed linear system, leading to two cases where x can be calculated uniquely or only if certain conditions are met. The text discusses the upper bound for singular values in the context of ReLU being contractive. It also formulates an algorithm to determine the finiteness of the preimage of y. This involves checking if matrix A is omnidirectional, which can be done through linear programming with side-conditions. The text discusses linear programming with side-conditions to determine the finiteness of the preimage of y. Training details for MLP on MNIST and WideCIFAR/ThinCIFAR are provided. Numerical analysis is conducted to understand the bound on the smallest singular value after ReLU. The text discusses the bound on the smallest singular value after ReLU in linear programming with side-conditions. It involves choosing suitable interval endpoints, computing values for a k, and counting the number of a i satisfying a condition. The example is from layer 4 of WideCIFAR, showing the correlation condition for different choices of c. The text describes how the results in FIG4 were obtained, showing the process of selecting input images with fewest positive activations in the first layer and searching for examples resembling images from a different class. It highlights that the bound given by Lemma 9 is far off due to the large volume of preimages in the MLP. The preimages of the MLP may have large volume, leading to network invariance to certain semantic changes. Studying preimages can unveil previously unknown properties."
}