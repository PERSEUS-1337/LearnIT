{
    "title": "Byg9KJn4Fr",
    "content": "Particle-based inference algorithm, such as Stein Variational Gradient Descent (SVGD), efficiently generates samples for intractable target distributions. SVGD is known to underestimate variance in high dimensions due to a combination of high variance and deterministic bias. By comparing SVGD with MMD-based inference algorithms, the source of bias in SVGD is identified. Analytically, only SVGD suffers from the \"curse of dimensionality\" when learning high-dimensional Gaussian targets. The Stein Variational Gradient Descent (SVGD) algorithm suffers from the \"curse of dimensionality\" and underestimates variance in high dimensions. This poses challenges in explaining uncertainty in model predictions, especially in high-dimensional Bayesian neural network problems. The algorithmic bias of SVGD leads to variance underestimation in high dimensions. A new algorithm, MMDdescent, accurately estimates variance by addressing the causes of variance collapse in SVGD. Removing high variance and deterministic bias improves variance estimation, confirmed through empirical verification. Equilibrium variance of SVGD and MMD-descent in high-dimensional Gaussians is derived, showing SVGD's variance scales inversely with dimensionality. Particle variational inference approximates intractable problems. Particle variational inference approximates an intractable distribution with a set of particles. SVGD optimizes particles iteratively with a driving force and repulsive force defined by a positive definite kernel. MMD-descent is a particle inference algorithm that jointly optimizes all particles to minimize the mean maximum discrepancy with the target distribution. In particle variational inference, SVGD optimizes particles iteratively using a positive definite kernel. MMD-descent jointly optimizes particles to minimize mean maximum discrepancy with the target distribution. The two algorithms converge to similar stationary points under finite samples but may not reliably approximate the target distribution in high dimensions. SVGD and MMD-descent converge to different stationary points in high dimensions. SVGD underestimates marginal variance, while MMD-descent accurately approximates it. The variance of SVGD crucially depends on integration by parts. The variance of SVGD crucially depends on integration by parts, leading to convergence issues under finite particles. In contrast, MMD-descent accurately approximates marginal variance without involving high variance terms. High variance of S1 requires more samples for accurate estimation, impacting the approximation quality of SVGD. The modified update in SVGD involves estimating repulsive force with n particles and driving force with rn particles. This correction addresses the variance collapse issue but is impractical due to scaling with dimensionality. High variance of the driving force S1 in SVGD leads to slower convergence, unlike in MMD-descent. In SVGD, deterministic bias combined with high variance estimators can lead to biased convergence or divergence. MMD-descent shows higher variance with \u2206 MMD 1 due to S 1. Resampling target samples helps maintain unbiased variance in the estimation. The deterministic bias in SVGD arises from the algorithm's inability to resample from q. An algorithm is designed to achieve random \"resampling\" by drawing new samples from a continuous distribution q0 and updating particles using \u2206 SVGD. The algorithm in SVGD uses resampling from the same distribution as q to update particles without bias. This resampling scheme accurately estimates target variance with few particles but becomes impractical due to quadratic scaling. Variance collapse in SVGD is quantitatively characterized by deriving higher order moments. Deriving the Variance. The variance collapse in SVGD is characterized by deriving the variance of converged particles in learning a unit Gaussian in high dimensions. As n, d tend to infinity at the same rate, the kernel matrix can be decomposed into a weighted sum of the data covariance matrix and a scaled identity. Under certain conditions, particles driven by SVGD equilibrate at the marginal variance v SVGD \u2192 1 e\u22121 \u03b3, while MMD-descent leads to v MMD \u2192 1. When comparing SVGD and MMD-descent, the equilibrium variance of SVGD scales linearly with n but inversely with d. More particles are needed as dimensionality increases to estimate the true variance reliably. The integral probability metric (IPM) measures how well a set of samples approximates a target distribution, with the maximum mean discrepancy (MMD) being a key metric. The maximum mean discrepancy (MMD) is a key metric for measuring how well a set of samples approximates a target distribution. MMD defines a proper metric using the Euclidean distance kernel, which includes Gaussian and IMQ kernels. Stein's method can be used for constructing zero-mean test functions when integration under p is difficult. The Stein's discrepancy, derived from the Langevin Stein operator, is used to approximate distributions efficiently. Kernel herding minimizes the MMD between particles and the target distribution. The herding algorithm, introduced by Welling in 2009, minimizes the MMD between particles and the target distribution. It selects particles greedily to reduce the MMD at a rate O(1/N) in finite-dimensional Hilbert spaces. The algorithm adds particles one at a time and can jointly optimize all particles to decrease distance. SVGD constructs the update direction to decrease the KL divergence by constraining it in terms of RKHS norm. Stein's lemma provides tools for approximating probability distributions and convergence rates. SVGD derives a particle updating formula by minimizing KL divergence with unnormalized targets. Stein's lemma also supports score estimation methods using random samples from implicit distributions. The curse of dimensionality in Stein's lemma-based kernel algorithms has been studied. Proposition 4 discusses the convergence of SVGD with a resampling scheme using random samples from the target distribution. The proof involves bounding the kernel and utilizing Markov's Inequality. In this section, we aim to calculate the variance of SVGD and MMD-Descent in learning a unit Gaussian target under the scaling of n, d \u2192 \u221e with lim d,n\u2192\u221e n/d = \u03b3 \u2208 (0, \u221e). Assuming particles spread evenly in space, have concentrated norm, and weak correlation, we compute the asymptotic variance of both algorithms under specific assumptions. In this subsection, we analyze the asymptotic scaling of n and d as they approach infinity with n/d converging to a constant \u03b3. By solving the stationary point of the SVGD update equation, we derive a matrix equation involving a Euclidean random kernel matrix K. The empirical spectrum density of the resulting matrix converges weakly to a certain value. The empirical spectrum density of a random matrix A converges weakly to a certain value, denoted as \u00b5. The Hoffman-Wielandt inequality is used to show convergence, with the 2-Wasserstein distance involved. The stationary point of MMD-descent satisfies certain conditions, and under assumption A1, a matrix form of equilibrium particles is derived."
}