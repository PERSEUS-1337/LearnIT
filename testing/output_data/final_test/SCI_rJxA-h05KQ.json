{
    "title": "rJxA-h05KQ",
    "content": "We present a new method for uncertainty estimation and out-of-distribution detection in neural networks with softmax output. By extending the softmax layer with an additional constant input, the method can represent network uncertainty without the need for extra parameters or multiple forward passes. The proposed method performs comparably to more computationally expensive methods and outperforms baselines in image recognition and sentiment analysis experiments. Misclassifications due to model overconfidence are highlighted, such as misclassified traffic signs and mislabeling African Americans as gorillas. The text discusses the importance of estimating uncertainty in machine learning systems to prevent malfunctions caused by overconfidence in models. A method using an Inhibited Softmax layer is proposed to measure uncertainty in neural networks with a softmax output layer, aiming to provide a simple and efficient solution for quick training and inference. The text introduces the Inhibited Softmax layer as a method to measure uncertainty in neural networks, outperforming baselines and comparable to more computationally expensive methods. It provides a mathematical explanation for interpreting the additional output as an uncertainty measure and benchmarks comparing it with other methods. In the nineties, Monte Carlo dropout, a technique for approximate Bayesian inference in Bayesian Neural Networks, has been used in real-life scenarios. Other methods to measure uncertainty in neural networks include non-Bayesian ensemble, student network, GAN modeling, Monte Carlo Batch Normalization, and nearest neighbour analysis. Some authors distinguish uncertainties in machine learning models: epistemic uncertainty (lack of knowledge about data distribution) and aleatoric uncertainty (arising from noise). Another type is distributional uncertainty, when test data differs from training data. Benchmarking models for distributional uncertainty involves distinguishing original test set from out-of-distribution dataset. Our method, utilizing Inhibited Softmax, improves upon existing techniques by meeting criteria such as no additional parameters, single forward pass, no preprocessing, and no need for out-of-distribution data. Inhibited Softmax is used for predicting background class in aerial imagery extraction tasks. The function provides uncertainty estimation in machine learning models and can be applied to multilayer neural networks. The function IS c maps R n to R n, with the i-th output determined by a specific equation. The \"certainty factor\" P c (x) is derived from the standard softmax function S(x). The certainty factor P c (x) is maximized during the optimization process in Inhibited Softmax, serving as an uncertainty estimator for cases within the training distribution. To provide a valid uncertainty score, a function is introduced and minimized during optimization, acting as an artificial softmax output. The network adjustments were made to ensure that low values of P u are obtained solely due to the training process, not trivial solutions or accidental network structure. This included removing bias terms from the inhibited softmax layer and changing the activation function to a kernel function in the penultimate layer to make activations greater from 0 only for a narrow, learnable region. To combat network overconfidence, activity regularization and l2 regularization on output layer weights were introduced. The former ensures gradient optimization methods do not increase values boundlessly, while the latter indirectly limits activation values. The adjustments made to the model architecture significantly improved the certainty estimation properties of Inhibited Softmax. Various methods for estimating uncertainty in neural networks were compared, with experiments conducted to assess their quality, including out-of-distribution examples detection and predictive performance evaluation. The experiments conducted evaluate the predictive performance and wrong prediction detection of a model on small datasets. The experiments aim to measure the model's ability to estimate uncertainty effectively. The experiments evaluate predictive performance and wrong prediction detection on small datasets by measuring uncertainty using various methods like Inhibited Softmax and Monte Carlo Dropout. Two baselines are established, measuring uncertainty through maximum probabilities or entropy. The suggested method is IS for benchmarking. The experiments evaluate predictive performance and wrong prediction detection on small datasets using methods like Inhibited Softmax and Monte Carlo Dropout. Inhibited Softmax is chosen for benchmarking, with specific parameters set. The base neural network for CIFAR-10 includes 3 convolutional layers with batch norm and dropout, followed by fully-connected layers. In computer vision OOD tasks, Inhibited Softmax improves detection performance on various datasets compared to baselines. It outperforms on tasks like discriminating MNIST from black and white CIFAR-10, NOTMNIST, Omniglot, and CIFAR-10/LFW-A. IS achieves high ROC AUC scores on different datasets and sentiment analysis. In sentiment analysis, Inhibited Softmax (IS) outperforms other methods, showing significant improvements on tasks like Movie Reviews dataset. IS achieves higher ROC AUC scores compared to baselines like MCD and BBP. It also performs best on tests against Reuters-21578 and Customer reviews datasets. The results do not align with the baseline publication BID10, as the detection task is more challenging when considering full reviews rather than single lines. The results show that Inhibited Softmax (IS) outperforms other methods in sentiment analysis tasks. The improved baseline achieved higher ROC AUC scores on IMDB/Movie Reviews and IMDB/Reuters-21578 datasets. However, it did not improve on IMDB/Customer Reviews. Inhibited Softmax did not affect the predictive performance of the neural network and ensembling the networks yielded the best results. Ensembling neural networks improves predictive performance, especially in sentiment analysis tasks. Inhibited Softmax (IS) stands out in detecting misclassified observations better than random classifiers. Comparison with Bayesian methods shows a surprisingly large overlap in correctly detected out-of-distribution observations. The uncertainty estimation of IS is demonstrated through an experiment using a fully connected variational autoencoder on the MNIST dataset. The uncertainty estimation of two methods is compared using generated samples from points in a 2D latent space. Both methods struggle to detect out-of-distribution samples and areas where different classes intersect. It is suggested that constructing challenging samples could improve uncertainty sampling performance. Enhancing uncertainty estimation could involve developing a method similar to IS for regression and limiting the number of required samples. The text discusses the development of an analogous method to IS for regression, limiting hyperparameters for Inhibited Softmax, and expanding the method to hidden layers. It highlights the potential of Inhibited Softmax in sentiment analysis but acknowledges the need for a mathematical explanation of its influence on model behavior. The method offers uncertainty estimation and can be applied to various neural network architectures without additional requirements. The method offers uncertainty estimation and can be easily applied to various neural network architectures without additional requirements. It outperforms baseline methods and does not deteriorate classifier performance. Results from experiments on IMDB/Movie Reviews and CIFAR-10/MNIST datasets show the effectiveness of the method. The results of experiments show that without l2 penalty or with too strong a penalty, performance in terms of accuracy on CIFAR-10, wrong prediction detection, and out-of-distribution detection deteriorates. The activity regularizer penalty is also important, as networks without it perform worse on all tasks except OOD detection on CIFAR-10/SVHN. Too much regularization leads to poor data fitting and a sharp drop in results on CIFAR-10. Additionally, it is possible to replace the rescaled Cauchy PDF function with other kernel functions. The text discusses the impact of different parameters on performance in various tasks, such as out-of-distribution detection and sentiment analysis. Preprocessing steps like removing stopwords and using pretrained embeddings are mentioned. The results of experiments show the importance of l2 penalty, activation function, and activity regularization penalty. The text discusses the impact of different parameters on performance in various tasks, such as out-of-distribution detection and sentiment analysis. Preprocessing steps like removing stopwords and using pretrained embeddings are mentioned. The results of experiments show the importance of l2 penalty, activation function, and activity regularization penalty. In a separate experiment, the model trained on full reviews from IMDB was found to have invalid results due to the use of average pooling after the embedding, which skewed the uncertainty estimation method. The input padding with zeros to 400 words also affected the true average of the embedded words. In the ensemble approach, different dropout probabilities were used for various tasks, with a trade-off between accuracy and out-of-distribution detection performance. The initialization of variance played a crucial role in achieving the best combination of accuracy and OOD detection. The number of networks and inferences were based on the original descriptions of the algorithms. In the visualisation section, uncertainties were normalised for comparison. Uncertainties were ranked and split into 400 bins, with white representing most uncertainty and black the least. Images decoded from the latent space were visualised for better understanding."
}