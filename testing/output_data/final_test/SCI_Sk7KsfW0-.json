{
    "title": "Sk7KsfW0-",
    "content": "We propose a novel deep network architecture called Dynamically Expandable Network (DEN) for lifelong learning. DEN can adjust its network capacity as it learns on a sequence of tasks, creating a compact knowledge sharing structure. It is trained online through selective retraining, dynamically expanding its capacity for each task, and preventing semantic drift. DEN outperforms existing methods in lifelong learning scenarios and achieves similar performance to batch models with fewer parameters. The primary goal of lifelong learning in deep learning is to leverage knowledge from earlier tasks for better performance on later tasks. Storing and transferring knowledge can be done through learned network weights, allowing new tasks to share these weights. Lifelong learning is considered a special case of online or incremental learning for deep neural networks. Multiple ways exist to perform incremental learning. Incremental learning in deep learning involves fine-tuning the network for new tasks, but this can lead to performance degradation. If the new task is significantly different from previous ones, the learned features may not be useful. Retrained representations for new tasks could also negatively impact old tasks. For example, a feature describing a zebra's stripe pattern may change meaning for later tasks like classifying striped t-shirts or fences. Recent work suggests different approaches to ensure beneficial knowledge sharing through the network in online/incremental learning of deep neural networks. One approach involves using a regularizer to prevent drastic changes in parameters while still finding a good solution for new tasks. Another approach involves either retraining the entire network learned on previous tasks with regularization to prevent large deviations from the original model or using non-retraining models that expand the network for new tasks without modifying network weights for previous tasks. Our DEN selectively retrains the old network, expanding its capacity when necessary. Our strategy involves selectively retraining the network at each task to utilize and change only the relevant part of the previous trained network, allowing for dynamic layer expansion. This approach ensures each task uses a different subnetwork while still sharing a considerable part with previous tasks. Challenges include achieving scalability and efficiency in training as the network grows in capacity. To maintain efficiency in training as the network expands in capacity, it is crucial to decide when to add neurons based on task similarity. Preventing semantic drift is essential to avoid performance degradation on earlier tasks. This involves retraining the network selectively and adding new neurons only when necessary. To prevent semantic drift and maintain efficiency in training, a novel deep network model called Dynamically Expandable Networks (DEN) is proposed. DEN maximizes the use of previous task knowledge while dynamically increasing network capacity by adding or splitting neurons. This incremental learning algorithm achieves similar or better performance than training separate networks for each task, using only a fraction of parameters. Our model, Dynamically Expandable Networks (DEN), maximizes previous task knowledge while dynamically increasing network capacity. It achieves similar or better performance than training separate networks for each task, using only a fraction of parameters. Lifelong learning, a continual learning paradigm, transfers knowledge from earlier tasks to later ones, making it practical for scenarios like autonomous driving or robotic agents. BID3 proposes an online lifelong learning framework. BID3 proposes an online lifelong learning framework (ELLA) based on multi-task learning to efficiently update latent parameter bases for a sequence of tasks, preventing retraining of previous task predictors. Lifelong learning in deep networks focuses on overcoming catastrophic forgetting, where retraining for new tasks causes the network to forget previous learnings. Regularizers can help prevent this issue. Elastic Weight Consolidation (EWC) and other methods like per-synapse consolidation and blocking modifications to previous networks are proposed to prevent catastrophic forgetting in lifelong learning frameworks. These methods aim to regularize model parameters to retain previous knowledge while learning new tasks efficiently. Dynamic network expansion is a method explored in neural networks to increase capacity during training. Various approaches have been proposed, such as incrementally training a denoising autoencoder by adding new neurons for difficult examples and merging them later to prevent redundancy. Nonparametric neural network models have also been suggested to minimize loss and determine the minimum dimensionality of each layer. Additionally, adaptive networks have been proposed to learn both structure and weights to minimize loss based on boosting theory. Our method for incremental training of deep neural networks in a lifelong learning scenario involves training the network once for each task to determine how many neurons to add at any layer. This is in contrast to BID15's method, which incrementally trains a network for multi-class classification by growing and branching only the topmost layers. Our goal is to learn models for a sequence of tasks with unknown distributions of training data arriving at the model in sequence. The lifelong learning agent aims to learn model parameters for a sequence of tasks, with the main challenge being the unavailability of previous training datasets. The agent incrementally learns by solving a problem to determine how many neurons to add at any layer in the network. The lifelong learning agent incrementally learns by selectively retraining network parameters and dynamically expanding network capacity when necessary. It utilizes knowledge from previous tasks and can add neurons as needed. The lifelong learning agent incrementally learns by selectively retraining network parameters and dynamically expanding network capacity when necessary. The incremental learning process involves selective retraining, dynamic network expansion, and network split/duplication. Selective retraining focuses on retraining only the weights affected by the new task, promoting sparsity in the weights to reduce computational cost. When a new task arrives, a sparse linear model is fitted using top hidden units to predict the task. This optimization helps identify connections between output unit and hidden units at a specific layer, reducing computation overheads by focusing on the subnetwork connected to the new task. Selective retraining involves identifying affected units and weights in the network connected to a new task, training only the selected subnetwork to reduce computational overhead and prevent negative transfer. This process is described in Algorithm 2, where neurons are added to the subnetwork based on non-zero weights or connections with other selected neurons. Dynamic Network Expansion is achieved through solving equations to obtain the updated weights for the selected subnetwork. Dynamic Network Expansion involves solving equations to update weights for selected subnetworks. When learned features cannot represent a new task accurately, additional neurons are introduced. Group sparse regularization is used to dynamically determine the number of neurons needed. This approach overcomes limitations of existing methods by efficiently adapting network capacity based on task difficulty. The proposed method uses group sparse regularization to dynamically decide the number of neurons to add at each layer for different tasks without retraining the network. Group sparsity regularization is applied to the added parameters based on the relatedness between tasks, with each group defined on the incoming weights for each neuron. This approach was previously used to determine the right number of neurons for a full network and is now applied to partial networks. The proposed method uses group sparse regularization to dynamically decide the number of neurons to add at each layer for different tasks without retraining the network. Algorithm 3 describes the process of network expansion after selective retraining, dropping unnecessary hidden units or convolutional filters. The model aims to capture new features while maximizing network capacity. The proposed method uses group sparse regularization to dynamically decide the number of neurons to add at each layer for different tasks without retraining the network. In lifelong learning, preventing semantic drift is crucial to avoid catastrophic forgetting. Regularizing the parameters with 2-regularization helps maintain the original values, with \u03bb controlling the degree of deviation. This approach balances learning new tasks while preserving knowledge from previous tasks. In lifelong learning, preventing semantic drift is crucial to avoid catastrophic forgetting. The proposed method uses group sparse regularization to dynamically decide the number of neurons to add at each layer for different tasks without retraining the network. If the number of tasks is large or if tasks are semantically disparate, it may be difficult to find a good solution for both previous and new tasks. To address this, neurons can be split to optimize features for different tasks based on the amount of semantic drift measured between incoming weights at different time points. In lifelong learning, preventing semantic drift is crucial to avoid catastrophic forgetting. Neurons can be split to optimize features for different tasks based on the amount of semantic drift measured between incoming weights at different time points. The network duplicates hidden units and trains the weights again, converging fast due to reasonable parameter initialization. Newly added units are timestamped to record the training stage, preventing semantic drift. In lifelong learning, preventing semantic drift is crucial to avoid catastrophic forgetting. At inference time, tasks only use parameters introduced up to stage t to prevent old tasks from using new hidden units. This strategy is more flexible than fixing weights learned at each learning stage. Different models are compared, including DNN-STL, DNN-MTL, DNN, DNN-L2, and DNN-Progressive, all using 2-regularizations. Weight consolidation BID4 regularization is used in the DNN-Progressive network implementation, with fixed network weights for each task. Base network settings include two-layer feedforward networks and a modified version of AlexNet with specific layer configurations. All models and algorithms are implemented using the Tensorflow library. The MNIST-Variation dataset contains rotated handwritten digits with background noise for a more challenging prediction task. The dataset CIFAR-100 consists of 60,000 images of 100 object classes with 500 training images and 100 test images per class. A CNN was used for experiments on this dataset, treating each task as a set of 10 subtasks. The AWA dataset includes 30,475 images of 50 animals with DECAF features reduced to 500 dimensions. Random splits of 30 images were used for training, validation, and testing. Models were validated for prediction accuracy and efficiency. Our models are validated for prediction accuracy and efficiency, measured by network size and training time. DNN-STL performs best on AWA and CIFAR-100 datasets due to task optimization. MTL is effective with few tasks for knowledge sharing, while STL is better with many tasks due to larger learning capacity. Our model DEN performs similarly to batch models and outperforms them on MNIST-Variation dataset. Retraining models with regularization like L2 and EWC do not perform well, with EWC slightly outperforming L2. The Progressive network outperforms DNN-STL and MTL, but underperforms DEN on all datasets. The performance gap is most significant on AWA due to network capacity issues. DEN achieves better performance with fewer parameters compared to Progressive network. DEN also matches the performance of STL. DEN outperforms Progressive network, DNN-STL, and MTL with fewer parameters. It dynamically adjusts its capacity for optimal performance on different datasets. DEN-Finetune achieves the best results on all datasets. Selective retraining is efficient and effective, as shown on the MNIST-Variation dataset. The study compares different models on the MNIST-Variation dataset, showing that selective retraining is more efficient than full retraining. DNN-Selective improves accuracy by 2% compared to the base network, possibly due to avoiding catastrophic forgetting. The study compares different models on the MNIST-Variation dataset, showing that selective retraining is more efficient than full retraining. DNN-Selective improves accuracy by 2% compared to the base network, possibly due to the suppression of catastrophic forgetting. DNN-Dynamic, a variant of the model with selective retraining and layer expansion, outperforms all models in terms of mean AU-ROC. DNN-Dynamic achieves the best mean AU-ROC, outperforming all models including DNN-Constant, with a smaller increase in network size. This is attributed to the benefits of fewer parameters in terms of training efficiency and preventing overfitting. The study also examines the impact of network split/duplication and timestamped inference on preventing semantic drift and achieving good performance on later tasks. The study examines the impact of network split/duplication and timestamped inference on preventing semantic drift and achieving good performance on later tasks. DNN-L2 prevents semantic drift at early stages but performs worse on later tasks. DNN-EWC has better performance on later tasks but lower than DNN-Progressive. DEN w/o Timestamping works better than DNN-Progressive on later tasks. DEN with timestamped inference shows no noticeable performance degradation. The study introduces Dynamically Expandable Network (DEN) for lifelong learning, which prevents semantic drift by partially retraining the network on old tasks and increasing capacity for new tasks. DEN with timestamped inference shows no performance degradation, outperforming existing methods in preventing semantic drift. The study introduces Dynamically Expandable Network (DEN) for lifelong learning, which prevents semantic drift by partially retraining the network on old tasks and increasing capacity for new tasks. DEN outperforms existing methods in preventing semantic drift and achieves better performance on Permuted MNIST dataset."
}