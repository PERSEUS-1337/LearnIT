{
    "title": "RL31798",
    "content": "Data mining involves using data analysis tools to discover patterns and relationships in large data sets. This includes statistical models, algorithms, and machine learning methods. Data mining goes beyond data collection and management to include analysis and prediction. It can be done on quantitative, textual, or multimedia data and can involve parameters like association, sequence analysis, and classification. Data mining involves using data analysis tools to discover patterns and relationships in large data sets. It includes classification, clustering, and forecasting to make predictions about future activities. Compared to other analytical tools, data mining represents a different approach, focusing on finding new patterns rather than verifying hypotheses. Data mining utilizes algorithms to examine multidimensional data relationships, identifying unique patterns. It requires a clear problem formulation and access to relevant data for success. Data mining is part of the larger process of knowledge discovery in databases (KDD), which includes steps like data cleaning, integration, selection, transformation, pattern evaluation, and knowledge presentation. Advances in technology and business processes have increased interest in data mining, with improvements in data management tools and the ability to combine data from different sources. The increased availability of information and decreasing costs of data storage have led to a rapid growth in the volume of data collected. Data mining is now widely used in both public and private sectors for various purposes such as customer surveys, fraud detection, and medical research. However, the proliferation of data mining has raised concerns about implementation and oversight. Data mining implementation and oversight issues include concerns about data quality, database interoperability, privacy infringements, and overlooking limitations. Skilled specialists are needed for successful data mining, as it can reveal patterns but not their value or significance. Limitations are primarily data or personnel-related, rather than technology-related. Data mining can reveal patterns but not their value or significance. Validity of patterns discovered depends on real-world circumstances. Limitations include identifying connections between behaviors/variables but not causal relationships. Data mining can reveal patterns in behaviors and variables, but not causal relationships. Predictive data mining for identifying potential terrorists before an activity occurs is limited by the lack of known instances. Factors like income, education level, and Internet use may influence ticket purchasing behavior, but other variables like occupation, family status, or hobbies can also play a role. Data mining is used in various industries like banking, insurance, medicine, and retailing to reduce costs, enhance research, and increase sales. It can predict consumer behavior and detect fraud, but creating valid predictive models for rare events like terrorist incidents is challenging. Data mining is utilized in various industries such as banking, insurance, medicine, and retailing to reduce costs, enhance research, and increase sales. Companies can develop predictive models to assess credit risk, detect fraud, predict medical procedure effectiveness, guide pharmaceutical research, and analyze customer behavior through affinity programs. Phone service providers and music clubs use data mining for churn analysis to determine subscriber retention. Data mining is used in the public sector to detect fraud, improve program performance, and predict demographic changes. Examples include recovering fraudulent Medicare payments, assessing crime patterns, predicting budgetary needs, reviewing plane crash data for common defects, and recommending precautionary measures. Data mining is increasingly important for homeland security efforts, with initiatives like Terrorism Information Awareness (TIA) and Computer-Assisted Passenger Prescreening System II (CAPPS II) attracting attention. CAPPS II has been replaced by Secure Flight, while other programs like Able Danger have also garnered congressional interest. The creation of the Information Awareness Office (IAO) at DARPA in response to intelligence concerns post-9/11 aimed to utilize technology for combating terrorist threats through total information awareness. The TIA project focused on developing technologies for detecting terrorist groups planning attacks against American interests, including language translation, data search with pattern recognition, and privacy protection, and advanced decision support tools. The TIA project aimed to develop technologies for detecting terrorist activity by allowing analysts to search data for patterns while controlling access and ensuring misuse detection. Collaborative reasoning and decision support tools would enable data sharing among agencies, improving data mining capabilities. Automated language translation and improved search technologies could enhance monitoring of foreign language documents and transactional data. The TIA program aimed to develop collaboration and decision support tools for coordinating activities among different government agencies. DARPA emphasized using legally available data for research and development, with the potential for other agencies to adopt the tools. Some technology projects under TIA did not involve data mining, but the program faced opposition for its focus on collecting and analyzing individual data trails. The TIA program faced significant opposition after John Poindexter presented it at the DARPATech 2002 Conference. Critics were concerned about Poindexter's involvement and the program's controversial logo. DARPA eventually removed the logo, but the negative publicity persisted. The negative publicity surrounding the TIA program led to the introduction of bills in Congress, including S. 188, the Data-Mining Moratorium Act of 2003. An amendment in the Omnibus Appropriations Act required a joint report on the TIA program. Funding for TIA was prohibited with the FY2004 Department of Defense Appropriations Act. The CAPPS II project, a response to the 9/11 attacks, aimed to replace the existing CAPPS system for air travel security. Developed in response to airplane bombings, the original CAPPS was funded by the FAA and tested by Northwest Airlines in 1996. In 1997, major carriers began implementing CAPS for airport security, following the White House Commission's recommendation for automated passenger profiling. The FAA issued a notice in 1999 for the security of checked baggage on domestic flights, requiring the use of the CAPS system. The CAPPS system is used for passenger screening to identify those needing additional security measures. CAPPS II was meant to enhance this by confirming passenger identities and identifying potential threats before boarding. It would have compared passenger information to commercial data for authentication. The TSA planned to use commercial data to assign risk levels to passengers for security screening. Passengers with a \"green\" score would undergo normal screening, \"yellow\" would have additional screening, and \"red\" would not be allowed to board. TSA would not see the actual data used for scoring and planned to test the system in 2004. However, CAPPS II faced obstacles in obtaining necessary data for testing due to airline concerns. In early 2003, Delta Airlines planned to test CAPPS II using passenger data but faced a boycott campaign. JetBlue shared passenger information with a defense contractor in 2002, while Northwest Airlines provided data to NASA in 2001 for security experiments. In October to December 2001, an airline security-related data mining experiment took place. American Airlines provided passenger data to TSA in June 2002, which was sent to competing companies instead. Delta, Continental, America West, and Frontier airlines, along with Galileo International and Sabre Holdings, also provided passenger records for testing CAPPS II. The European Union initially refused to provide data but later signed an agreement in May 2004. In May 2004, the EU signed an agreement with the United States to allow PNR data for flights from the EU to be used in testing CAPPS II. The agreement included restrictions on data retention, limited access to PNR elements, and required yearly reviews. There were concerns about mission creep as CAPPS II expanded its scope beyond screening high-risk passengers to identifying individuals with arrest warrants and terrorists. CAPPS II could be linked with the US-VISIT program to identify individuals in the country illegally. TSA claimed the suggested uses were consistent with improving aviation security, despite concerns about data retention, access, accuracy of commercial data, and identity theft detection. In August 2004, TSA announced the cancellation of the CAPPS II program and its replacement with Secure Flight. Congress included a provision in the Department of Homeland Security Appropriations Act, 2005, prohibiting the deployment of CAPPS II or Secure Flight until GAO certifies that the system meets privacy requirements and can accommodate air transportation needs. GAO's certification report was delivered to Congress in March 2005, stating that TSA is making progress in implementing the new system. In March 2005, GAO reported that TSA was making progress in addressing congressional concerns with the Secure Flight program, but had not fully completed these efforts due to development stage. Despite continued progress in 2006, the program still faced issues with systems development and program management, leading to privacy requirement challenges. TSA suspended development in early 2006 to reassess the program, and in December 2006, the DHS Privacy Office found discrepancies in TSA's privacy practices related to data testing and retention. The report highlighted discrepancies in TSA's privacy practices related to data testing and retention. TSA Administrator Kip Hawley mentioned improvements to Secure Flight, with an anticipated implementation in 2010. TSA published a notice of proposed rulemaking for Secure Flight in August 2007. In August 2007, TSA published a notice of proposed rulemaking for Secure Flight, along with a final rule for the Advance Passenger Information System (APIS) administered by U.S. Customs and Border Protection. The proposal aims to integrate watch list matching for both programs under a single DHS portal. The August 23, 2007 Secure Flight NPRM proposed integrating watch list matching for aviation passengers into a single DHS system. TSA would receive passenger information, conduct watch list matching, and transmit boarding pass instructions to airlines. Passengers would need to provide their full names as on their ID and optional date of birth. The NPRM proposes that passengers may provide optional personal information like date of birth and gender. Aircraft operators may be required to provide this information to TSA if already obtained in the ordinary course of business. Additionally, operators must transmit passport information and certain non-personally identifiable data fields to TSA. The NPRM proposes a tiered data retention schedule for Secure Flight, including itinerary information and certain non-personally identifiable data fields. Records for individuals not identified as potential matches would be retained for seven days, potential matches for seven years, and confirmed matches for 99 years. The purpose is to facilitate a redress process, expedite future travel, and investigate terrorist events. The NPRM for Secure Flight proposes a tiered data retention schedule, with records of confirmed matches to be retained for 99 years. TSA extended the public comment period for an additional 30 days in response to requests. MATRIX, developed after 9/11 by Seisint, aimed to facilitate information sharing and data analysis, including a component called the High Terrorist Factor (HTF). MATRIX's High Terrorist Factor (HTF) component analyzed various data points to generate a list of 120,000 names with high terrorism quotients. This list was shared with multiple law enforcement agencies, leading to several arrests within a week and scores of other arrests. The HTF scoring system attracted the interest of officials. The HTF scoring system in MATRIX attracted officials' interest but was dropped due to concerns about privacy and reliance on intelligence data. Critics questioned the lack of official documentation on this decision. MATRIX was a pilot project involving Seisint, FDLE, and IIR, with FDLE as the Security Agent controlling system access. IIR specialized in law enforcement and criminal justice issues. The MATRIX pilot project involved Seisint, FDLE, and IIR. FDLE controlled system access and IIR provided administrative support. The analytical core was the FACTS application, allowing query-based searches of public records. FACTS combined over 3.9 billion records from various sources, including FAA pilot licenses, property ownership records, and state sexual offenders lists. The data reference repository included information on vessels registered with the Coast Guard, state sexual offenders lists, federal terrorist watch lists, bankruptcy filings, professional licenses, criminal history, driver's license information, and more. Excluded data were telemarketing call lists, airline reservations, credit card numbers, and bank account information. The RISS Program, a data sharing resource used by law enforcement agencies, helps combat various crimes including drug trafficking and cybercrime. It has been operational for nearly 25 years and has member agencies in multiple countries. Critics of the MATRIX system raised concerns about privacy and data security. Some critics of the MATRIX system raised concerns about its similarities to DARPA's TIA program and the founder's questionable past involving drug smuggling cases. Hank Asher resigned from Seisint amid questions about his criminal history, raising doubts about the project's trajectory. Civil liberties organizations also expressed worries about privacy and data security. Some civil liberties organizations raised concerns about law enforcement actions being taken based on algorithms developed by Seisint without public input. The MATRIX pilot project received $12 million in federal funding, facing setbacks in recruiting states to participate. The MATRIX pilot project faced challenges in recruiting states to participate, with only four states remaining at the conclusion of the pilot. Reasons for non-participation included costs, privacy concerns, and duplication of resources. Despite these challenges, the pilot study from July 2003 to April 2005 was deemed successful by the FDLE. The news release highlighted the operational successes of the FACTS application, with statistics showing a high number of queries and law enforcement users. The application assisted in various investigations, with cases involving fraud, robbery, sex crimes, larceny, theft, extortion, burglary, stolen property, terrorism, and other crimes. Although the pilot study was not continued due to lack of federal funding, Florida and other states were negotiating to continue using the FACTS application independently. In summer 2005, reports emerged about a data mining initiative in the U.S. In 1999-2000, the U.S. Army's Land Information Warfare Agency conducted a data mining initiative called Able Danger at the request of the U.S. Special Operations Command to combat terrorism. Able Danger used link analysis on 2.5 terabytes of data to identify connections between individuals. The program was classified, and all data, including information on U.S. persons, was reportedly deleted. The Able Danger data mining initiative conducted by the U.S. Army in 1999-2000 used link analysis on 2.5 terabytes of data to identify connections between individuals, including U.S. persons. The data was reportedly deleted in April 2000 due to Army regulations. Interest in Able Danger was driven by controversy over allegations that it identified Mohammed Atta as a terrorist suspect before 9/11. The Senate Committee on the Judiciary held a hearing in 2005 to consider data sharing and the destruction of the data. The Department of Defense directed individuals involved in Able Danger not to testify at a hearing. Testimony was taken from an attorney and others not directly involved. A joint hearing was held by the House Committee on Armed Services on February 15, 2006. Witnesses included Stephen Cambone, Erik Kleinsmith, Anthony Shaffer, and J.D. Smith. In September 2006, a Department of Defense Inspector General report on Able Danger was released, examining allegations of mismanagement. The Department of Defense Inspector General investigated allegations of mismanagement and reprisals in the Able Danger program. The investigation found procedural oversights in handling LTC Shaffer's office contents but did not support claims that Able Danger identified 9/11 terrorists early or that team members were prohibited from sharing information. Senators Roberts and Rockefeller released a letter in December 2006 regarding the investigation. The Committee on Intelligence, led by Senators Roberts and Rockefeller, released a letter summarizing the findings of a review of Able Danger. The review confirmed by the DoD Inspector General found no evidence supporting Able Danger allegations, closing the matter. Additionally, the Department of Homeland Security posted a System of Records Notice in the Federal Register about the Automated Targeting System (ATS) for screening travelers entering the US. ATS, part of the Treasury Enforcement Communications System (TECS), was originally developed to identify potential cargo threats. The Automated Targeting System (ATS) is part of the Treasury Enforcement Communications System (TECS) and is run by the Bureau of Customs and Border Protection (CPB). It builds a risk assessment for cargo, conveyances, and travelers based on criteria and rules developed by CPB. Information collected may be retained for up to forty years to cover the potentially active lifespan of individuals associated with terrorism or other criminal activities. ATS is composed of six modules: ATS-Inbound, ATS-Outbound, ATS-Passenger (ATS-P), and ATS-Land. The Automated Targeting System (ATS) includes modules for travelers and conveyances arriving by air, ship, and rail (ATS-Passenger), private vehicles arriving by land (ATS-Land), and cargo targeting for collaboration with foreign customs authorities (ATS-International). The disclosure of ATS raised concerns about exemptions from the Privacy Act, opportunities for citizens to correct errors, risk assessment creation, testing, and system effectiveness. The DHS Privacy Office report to Congress stated that only two modules of the Automated Targeting System (ATS) engage in data mining for cargo targeting, while the ATS Passenger module does not meet the data mining definition. The Privacy Office also published a notice of proposed rulemaking in 2007. The Department of Homeland Security proposed Privacy Act exemptions for the Automated Targeting System (ATS) in the Federal Register. The exemptions are necessary to protect information related to law enforcement investigations from disclosure. The ATS-P module records exempt from the Privacy Act would include risk assessment analyses and business confidential information from air and vessel carriers. Additionally, records or information obtained from other systems of records that are exempt from certain provisions of the Privacy Act would retain their exemption in ATS. The August 6, 2007 SORN revises the November 2, 2006 SORN for the Automated Targeting System (ATS), reducing data retention period from 40 to 15 years. Users need supervisory approval to access archived data in the last eight years. Individuals can correct factual inaccuracies in their PNR data. Booking agents are added as authorized users. The August 6, 2007 SORN revised the ATS, reducing data retention period and allowing individuals to correct inaccuracies in their PNR data. Booking agents were added as authorized users, and categories of people covered by ATS were amended. The revised SORN became effective on September 5, 2007. In December 2005, news reports revealed a classified NSA terrorist surveillance program. The classified NSA terrorist surveillance program, dating back to at least 2002, involved domestic collection, analysis, and sharing of telephone call information. Congressional concerns were raised about homeland security data mining and the capacity of intelligence agencies to analyze and share counterterrorism information. President Bush and Administration officials stated that the program focused on international calls to target al Qaeda and related terrorist groups. The NSA terrorist surveillance program, authorized by President Bush, targeted international communications of individuals with links to al Qaeda. The program was regularly reviewed and briefed to key Members of Congress. President Bush emphasized the importance of intercepting communications based on clear links to terrorist networks and stated that the activities were reviewed every 45 days to assess terrorist threats. The NSA program, authorized by President Bush, targets international communications of individuals linked to al Qaeda. It is reviewed regularly and approved by top legal officials. The program focuses on intercepting communications with clear terrorist links and has safeguards to protect civil liberties. It only applies to communications where one party is outside the US. The NSA program, authorized by President Bush, targets communications of individuals linked to Al Qaeda and affiliated groups. It focuses on intercepting communications with clear terrorist links and has safeguards to protect civil liberties. The program is reviewed and reauthorized every 45 days, monitored by the General Counsel and Inspector General of the NSA, and intelligence agents receive extensive training. Attorney General Gonzalez stated in 2006 that the program is aimed at preventing terrorist attacks. In a Senate Judiciary hearing, U.S. Attorney General Gonzalez explained the terrorist surveillance program, which targets communications involving individuals outside the U.S. believed to be linked to al Qaeda or affiliated terrorist groups. The program is periodically reviewed and reauthorized by the President, with Congressional leadership briefed multiple times since 2001. News reports in May 2006 raised concerns about potential unauthorized domestic surveillance under the NSA program. Following the September 11, 2001 attacks, the NSA contracted with AT&T, Verizon, and BellSouth to collect information about domestic telephone calls. The NSA used this data for \"social network analysis\" to map relationships between people based on their communications. It is unclear what information was collected and provided to the NSA, with reports suggesting that personally identifiable information and call content were not included. BellSouth denied providing bulk customer calling records to the NSA. The three largest US telecommunications companies, AT&T, Verizon, and BellSouth, denied providing bulk customer calling records to the NSA. They serve over 200 million customers and handle hundreds of billions of calls annually. Attorney General Gonzalez stated that the Foreign Intelligence Surveillance Court authorized the collection of international communications with probable cause. The Terrorist Surveillance Program, targeting al Qaeda and associated terrorist organizations, will now require approval from the Foreign Intelligence Surveillance Court. The program will not be reauthorized when the current authorization expires. Legal issues surrounding the program and involvement of telecommunications companies have led to lawsuits. In 2008, Congress passed the FISA Amendments Act. The FISA Amendments Act of 2008 provides protection to telecommunications companies assisting in government surveillance activities. NSA supports the development of new technology for data management through grants from ARDA. ARDA is an intelligence community organization focused on high-risk research using cutting-edge technology to solve critical problems. Their research thrusts include Information Exploitation, Quantum Information Science, Global Infosystems Access, Novel Intelligence from Massive Data, and Advanced Information Assurance. The Novel Intelligence from Massive Data program aims to develop data mining tools for analyzing large, challenging datasets. The Novel Intelligence from Massive Data program focuses on developing data mining tools for analyzing large, complex datasets, including those that are one petabyte or larger. The growth of intelligence data sources is increasing rapidly, leading to a need for more sophisticated analysis tools. The NSA is at risk of being overwhelmed by data due to encrypted communications. Congress may need to consider issues like data quality, interoperability, mission creep, and privacy in data mining initiatives. Data quality, accuracy, completeness, structure, consistency, duplicate records, lack of standards, timeliness, and human error are key challenges in data mining. Human error can impact data mining techniques, requiring data cleaning to improve quality by removing duplicates, normalizing values, handling missing data, removing unnecessary fields, identifying anomalies, and standardizing formats. Interoperability of databases and software is crucial for data mining success. Interoperability is essential for data mining projects to work with other systems or data using common standards. It is crucial for improving collaboration and information sharing among agencies. Issues with interoperability may arise when trying to access legacy databases or collaborating with other agencies. Planning for interoperability is necessary for the effectiveness of data mining efforts. Mission creep is a key risk in data mining projects, where data may be used for purposes other than originally intended. Efforts to combat terrorism can create pressure to utilize all available resources, leading to potential misuse of data. Government officials responsible for ensuring safety may feel pressured to use existing databases to identify threats. Accessing information for unintended purposes can lead to misleading results due to inaccurate data. Data collection efforts often have accuracy concerns, and ensuring data accuracy can be costly. In well-managed data mining projects, limitations of the data are accounted for, but this awareness may not be present when data is used for other purposes. The accuracy of data collected through shopper's club cards may suffer due to various reasons, such as lack of identity authentication and multiple card usage. While these inaccuracies may be negligible for marketing purposes, using this information for targeting individuals based on food purchases associated with religious observances could lead to wasted resources and unpleasant experiences for misidentified individuals. The potential wide reuse of data raises concerns about mission creep beyond just privacy protection. The potential for mission creep in data usage extends beyond privacy concerns to civil rights protection, particularly in targeting individuals based on religion or expression. As data mining initiatives expand, there is increased scrutiny on privacy implications and the possibility of data mining applications being used for purposes beyond their original intent. Debate continues on how data mining should be conducted, with differing viewpoints on the tradeoffs involved. Some observers debate tradeoffs between privacy and security in data mining projects. Existing laws may be sufficient, but others call for more oversight. Disagreement exists on how to address privacy concerns, with suggestions for technical solutions or clearer policies and oversight. Congress may need to consider the use of commercial data by government agencies and the potential misuse of data sources. During the 108th Congress, legislative proposals were introduced to restrict federal government data mining activities and increase reporting requirements. Senator Feingold introduced the Data-Mining Moratorium Act of 2003 to halt data mining under the Total Information Awareness program. Senator Wyden also introduced an amendment to the Omnibus Appropriations Act regarding data mining. Introduced S.Amdt. 59 to H.J.Res. 2, the Omnibus Appropriations Act for Fiscal Year 2003, requiring a joint report on the TIA program by key officials within 90 days. Failure to submit the report could result in discontinuation of funding for TIA. Funding for TIA was eventually discontinued in the FY2004 Department of Defense Appropriations Act. Senator Wyden introduced an amendment to the Air Cargo Security Act, requiring a report on the impact of CAPPS II on privacy and civil liberties. The amendment was passed by the Committee on Commerce, Science, and Transportation, and the bill was sent to the full Senate. Funding restrictions on CAPPS II were included in the FY2004 Department of Homeland Security Appropriations Act. The deployment of the Computer-Assisted Passenger Prescreening System (CAPPS II) is pending a GAO report on its efficacy, accuracy, and security, as well as the establishment of an appeals process for potential threats. GAO reported incomplete progress on key issues, attributing it to the early stage of the system's development. The Subcommittee on Technology, Information Policy, Intergovernmental Relations, and the Census held hearings on data mining, discussing its strengths, weaknesses, and challenges. Witnesses emphasized the importance of data integrity, security, and privacy in government applications. Senator Wyden introduced The Citizens' Protection in Federal Databases Act in 2003. Senator Wyden introduced S. 1484, The Citizens' Protection in Federal Databases Act in 2003, requiring various government officials to submit reports before spending funds on commercially available databases. The bill also set restrictions on searches based on hypothetical scenarios. Senator Feingold introduced S. 1544, the Data-Mining Reporting Act of 2003. Feingold introduced S. 1544, the Data-Mining Reporting Act of 2003, requiring departments to report data mining activities to Congress. The reports must include project details, technology description, privacy impact assessment, and procedures for informing individuals. Senator Murkowski introduced S. 1552, the Protecting the Rights of Individuals Act. Senator Murkowski introduced S. 1552, the Protecting the Rights of Individuals Act on July 31, 2003. Section 7 of the bill proposed a moratorium on data mining by federal departments or agencies unless authorized by law. It also required reports to Congress and public disclosure for any data mining activities. On May 5, 2004, Representative McDermott introduced H.R. 4290, the Data-Mining Reporting Act of 2004, which aimed to mandate reporting of data mining activities. H.R. 4290 and S. 2528 required federal departments using data-mining technology to report activities to Congress. Similar provisions were included in other bills like H.R. 4591. Data mining was a topic of interest in the 109th Congress, with H.R. 1502 also addressing civil liberties restoration. Section 402 of H.R. 1502 required federal departments using data-mining technology to submit public reports to Congress detailing the technology, data used, deployment plans, efficacy assessment, privacy impact, and legal analysis. The Federal Agency Data-Mining Reporting Act of 2005 required federal departments to submit reports to Congress on data mining activities, including laws and regulations, privacy protections, notification of individuals, and opt-out options. These reports were due within 90 days of enactment and updated annually with new technologies. S. 1169, the Federal Agency Data-Mining Reporting Act of 2005, introduced by Senator Feingold, required departments engaged in data mining to submit public reports to Congress detailing the project's technology, data, goals, efficacy, privacy impact, laws, regulations, and procedures for informing individuals about their personal information usage. On July 21, 2005, H.Amdt. 497 to H.R. 3199 was passed, requiring the Attorney General to report to Congress on data mining initiatives. H.R. 3199 was also passed by the House and sent to the Senate, which passed an amended version on July 29, 2005. The Senate passed an amended version of H.R. 3199 on July 29, 2005, which did not include a provision on data mining. The bill went to a House-Senate conference in November 2005, and a report on data mining by the Department of Justice was included in the conference report. The Attorney General was required to submit a report on Department of Justice data mining initiatives within one year of the Act's enactment. The bill became law as P.L. 109-177 on March 9, 2006. Additionally, H.R. 4009, the Department of Homeland Security Reform Act of 2005, was introduced on October 6, 2005. On December 6, 2005, H.R. 4437, the Border Protection, Antiterrorism, and Illegal Immigration Control Act of 2005, was introduced by Representative Sensenbrenner. It directed the Chief Intelligence Officer to establish a secure communications and information technology infrastructure for data analysis and dissemination. On December 8, 2005, H.R. 4437 was amended and reported by the Committee on the Judiciary. It was later discharged by the Committee on Homeland Security and referred to other committees. The bill was passed by the House on December 16, 2005, and sent to the Senate for further review. Section 1305 of H.R. 4437 would have granted the Office of Security and Investigations the authority to conduct fraud detection operations and investigate immigration benefits fraud. The curr_chunk discusses the purpose of investigating violations of the Immigration and Nationality Act, sharing information with law enforcement entities, and engaging in collaborative efforts. Senator Feingold introduced an amendment to the Homeland Security Department FY2007 appropriations bill, similar to S. 1169 but applicable only to departments within the Department of Homeland Security. The curr_chunk discusses the inclusion of Section 549 in the Senate-passed version of H.R. 5441 within the Department of Homeland Security. Despite being deleted from the final bill (P.L. 109-295), a statement on data mining was included in the conference report, directing the DHS Privacy Officer to submit a report. Data mining has been a topic of interest in the 110th Congress. S. 236, the Federal Agency Data-Mining Reporting Act of 2007, introduced in the 110th Congress, requires departments and agencies engaged in data mining to submit public reports to Congress detailing the project's technology, data, goals, efficacy, privacy impact, laws, regulations, and procedures for informing individuals about the use of their personal information. The Senate Committee on the Judiciary held a hearing on the privacy implications of government data mining programs. Witnesses discussed the strengths and weaknesses of data mining, as well as the challenge of balancing national security and civil liberties. Senator Reid introduced an amendment to the Improving America's Security Act, addressing the Federal Agency Data Mining Report. The Federal Agency Data Mining Report Act of 2007, part of an amendment to the Improving America's Security Act, underwent several amendments in the Senate, including one introduced by Senator Kyl to protect patents and narrow the definition of data mining. This modification aligned the language with the USA PATRIOT Improvement and Reauthorization Act of 2005. Senator Feingold introduced S.Amdt. 429, similar to S. 236 but with changes including a broader definition of data mining, exclusion of certain initiatives, and a requirement for reports to be coordinated with privacy officers. S.Amdt. 429 includes details on classified annexes for data mining reports, not to be made public. S.Amdt. 441, a technical modification, was agreed to on March 13, 2007. S. 4 passed the Senate with a data mining provision as Section 604. H.R. 1 did not have a similar provision. On March 21, 2007, the House Committee on Appropriations Subcommittee on Homeland Security discussed data mining activities by DHS, including the ADVISE tool, and privacy protections. The Senate Committee on the Judiciary approved a revised version of the Data Mining Act of 2007 on April 12, 2007. The revised version of S. 236 is similar to the data mining provision in S. 4 and P.L. 110-53. It includes penalties for unauthorized disclosure of classified information. H.R. 2638 passed by the House includes language prohibiting funding for the ADVISE data mining program until a privacy impact assessment is completed. ADVISE is a technology framework for analyzing large amounts of data developed by the Directorate for Homeland Security. The ADVISE data mining program, developed by the Directorate for Science and Technology at DHS, faced funding restrictions until a program plan and privacy impact assessment were completed. The Senate and House resolved differences in bills, leading to the signing of the legislation into law in August 2007. The bill was signed into law by the President as P.L. 110-53 after a 371-40 vote on the conference report. Several CRS reports on homeland security, air passenger prescreening, counterterrorism, privacy protection, and Total Information Awareness programs are available from the authors. The curr_chunk provides links to various reports related to the Terrorism Information Awareness Program, data mining activities, and privacy concerns by the Department of Defense and Department of Homeland Security. The curr_chunk includes links to reports by the Department of Homeland Security and the CATO Institute on data mining, counterterrorism, and privacy concerns. The curr_chunk provides a link to the Office of the Director of National Intelligence's Data Mining Report from February 15, 2008."
}