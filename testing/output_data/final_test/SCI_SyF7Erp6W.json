{
    "title": "SyF7Erp6W",
    "content": "Machine learning algorithms for controlling devices need to learn quickly with few trials, drawing from continental philosophy and mathematical theory of categories. This approach is demonstrated on cyberphysical systems like the slot car game and Atari 2600 games. There is a growing need for algorithms to learn with minimal data in partially-known environments. Current reinforcement-learning solutions using neural networks work well but require a lot of training data, prompting the development of alternative approaches for efficient learning. The text discusses an alternative approach to teaching computers to learn quickly with minimal training data, time, and resources. It focuses on reinforcement learning methods for Markov Decision Processes and Partially Observable MDP, inspired by continental philosophy. Two problem-solving approaches are described: the bijective case for imitation learning and the category-based approach for innovative control algorithms. Results are shown from a slot car game and Atari 2600 video games. The development of Artificial Intelligence (AI) in games, particularly slot car games, involves using image-processing and reinforcement learning algorithms. One approach estimates the car's position on the track using a multilayer perceptron with convolutional layers and controls the car with different voltage levels. Another faster solution utilizes acceleration sensors and a microcontroller to map tracks and control the car's velocity using a Phase-Locked Loop algorithm. Training the algorithms takes time, but they offer efficient control strategies for autonomous slot cars. Our system learns to rank with human players in less than a minute, without embedded sensors, for both known and unknown circuits. Video games provide a cyber-physical representation of our environment, focusing on realism for game and character designers. Older video-gaming systems like the Atari 2600 console offer a variety of games such as mazes, action games, and ball-and-paddle games. Video games encompass a variety of genres, from mazes and action games to ball-and-paddle games. These games involve decision-making and are modeled as Markov Decision Processes (MDPs). Different methods like deep Q-networks, searching algorithms, reinforcement learning, and apprenticeship learning are used to guide the agent in selecting the best actions. The success of Neural Networks (NN) in training humanlike agents for video games is attributed to the large amount of data used, despite the challenges of interpreting the learning process and attributing coefficients. NN can learn and generalize effectively, but the exact mechanisms are not fully understood. To address these limitations, an approach is proposed to explicitly explain how AI learns and extracts information. The approach proposed aims to explain how AI learns, extracts features, categorizes, and generalizes by incorporating theoretical elements directly into the method. It suggests that high-level abilities like categorizing and generalizing should be explicitly included in the framework to avoid long training times and to address critiques of AI research. The author critiques AI research in BID8, suggesting a focus on understanding human intelligence beyond computer models. They argue that intelligence involves more than just elementary computations for a reward goal, but also includes categorization and generalization for understanding. The author references continental philosophers like Heidegger and Foucault, contrasting them with analytic philosophers like Russell and Wittgenstein. Analytic philosophy, influenced by mathematical logic, emphasizes logical analysis and empirical verifiability of philosophical statements. In contrast, continental philosophy includes French and German doctrines like existentialism and psychoanalytic theory, which are contrary to analytic principles. Dreyfus criticizes early AI for favoring analytic approaches over continental philosophies. Dreyfus criticizes early AI for favoring analytic philosophy over continental philosophy, which includes existentialism and psychoanalytic theory. He suggests that incorporating elements of continental philosophy into AI design could improve high-level human intelligence abilities. This approach is described in opposition to analytic philosophy and may involve connections with mathematical theories. The AI logic is expressed at the entity level, similar to working at the morpheme level in linguistics. Entities like tracks, cars, and balls are geometrically organized and described by cartesian coordinates. A distance measure between entities is defined, allowing for the construction of a timeline and a cinematic model of the situation. This concept is influenced by developmental psychology. The text discusses the organization of perceptive world entities in space and time, emphasizing properties like consistency, movement, and permanence. This concept is influenced by developmental psychology and aims to organize knowledge at the entity level. The text discusses the organization of perceptive world entities in space and time, emphasizing properties like consistency, movement, and permanence. This concept is influenced by developmental psychology and aims to organize knowledge at the entity level. The AI approach involves looking for rectangular entities with specific characteristics in Atari 2600 games. Critiques against old AI philosophy include the assumption that all activities can be formalized in predictive rules, which may lead to ignoring new objects that have not been seen before. The text discusses the importance of curiosity in AI development, citing the work of developmental psychologists. It argues that AI focusing solely on predictive rules may miss out on the benefits of curiosity. This concept challenges the traditional AI approach of formalizing all activities into predictive rules, especially in fields like psychology and behavior understanding. Dreyfus argues that human problem solving relies on background context and intuition rather than computing all possible combinations of symbols. This approach, similar to asking AI to focus on important features, is more efficient. BID7 references Heidegger's concept of Dasein, emphasizing the importance of being in the world and considering unity in actions. The AI must identify the \"Me\" among entities, driven by life impulses to seek friends and avoid enemies. It distinguishes between entities that bring rewards or avoid harm, crucial for its survival. The AI must quickly differentiate between friends and enemies of the \"Me\" to survive. Making analogies between past experiences helps in understanding new situations. Transposing policies from one problem to another using mathematical tools is a proposed theory by BID3 for PONDP. The theory of category is a powerful tool in modern mathematics that can identify non isomorphic structures. Category theory, which emerged in the mid-20th century, is associated with continental philosophy, providing syntheses and setting higher levels of being. Category theory provides richer descriptions of objects by introducing arrows between them, allowing for new kinds of identifications. An arrow a : A \u2192 B is called an isomorphism if it is invertible, meaning there is an arrow b : B \u2192 A such that ba = Id B and ab = Id A. This framework is like an oriented graph, and objects A and B are considered isomorphic if such arrows exist. The relation of isomorphism in category theory defines an equivalence relation on objects. Equivalence of categories induces a bijection between classes of isomorphic objects. This process is useful in observable problems, where sets of observations define types of states. In category theory, the relation of isomorphism defines an equivalence relation on objects. This induces a bijection between classes of isomorphic objects, useful in observable problems where sets of observations define types of states. The surjection f: C \u2192 O induces a bijection between the set of types and observations, with f being the inverse of DISPLAYFORM0. If sets of observations O and O have the same cardinality via bijection G: O \u2192 O, a bijection F = f DISPLAYFORM1 can be defined between sets of types. In category theory, a bijection F = f DISPLAYFORM1 can be induced by an equivalence of categories F : C \u2192 C, allowing for the identification of states of the \"same\" type. This enables strategies to be transposed between different sets, formalizing various games and situations. For example, a player can easily switch between games like Breakout and Pong, showcasing the versatility of this approach. In category theory, a concrete system like the slot car can be transcribed into categories. Sets are defined for categories, number of sections, and car locations on the track. The player influences voltage and current with a controller to define a policy. The goal is to identify and transpose policies between different configurations. In category theory, the slot car system can be transcribed into categories. By defining arrows using an observable function, an equivalence of categories can be established to transpose policies between different configurations. In category theory, the slot car system can be transcribed into categories by defining arrows using an observable function. An equivalence of categories is established to transfer policies between different configurations. This systematic categorization and generalization focus on types of states rather than individual states. Results are demonstrated for a cyberphysical system, a slot car circuit, and Atari 2600 video games. The slot car experimental setup was chosen to validate the approach on a cyberphysical system with imperfect actuators like a brushed, direct-current (DC) motor. The slot car system was chosen for validation due to its imperfect actuators and contacts, allowing for evaluation with a wide range of signals. The setup is based on a Scalextric MINI Challenge Set C1320T, with a digital Hall effect sensor replacing the mechanical lap counter. Components in signals above 350 Hz were identified through spectrum analysis. The antialiasing filter designed for the slot car system has a cut-off frequency of 31 Hz. A real-pole filter was chosen using a Cauer Resistor Capacitor (RC) ladder network. Values of R and C were selected based on the cut-off frequency. Scaled values of the second RC network were computed to meet specifications for maximum magnitude error. Choosing d = 0.1 resulted in less than 0.5 dB error, with no significant impact on later computations. The antialiasing filter for the slot car system has a cut-off frequency of 31 Hz, implemented with a real-pole Cauer RC ladder network. The algorithms are written in C language and run in real-time on an Arduino Mega 2560 with 8192 bytes of RAM. Analog signals are sampled and quantized by the microcontroller's integrated ADC. The slot car system relies on a three-step imitation procedure for optimal performance. The AI stores currents for replaying the shortest lap and uses an optimization method to minimize lap time differences. The reward module in the analogy-based approach monitors the car to provide rewards based on lap time, car presence on the track, and car movement. The AI uses k-nearest neighbors algorithms to detect crashes and stops based on voltage and current levels. It can successfully pilot the car on new tracks without replaying human driving data. The reward model ensures the car maintains safe speed and motion without triggering crash or stop signals. The algorithm uses an analogy-based approach to determine the safe speed for the car on an unknown circuit, using k-NN as a classifier. It infers in real time whether the car is on a curve or straight path based on current and voltage measurements, choosing the best control signal to avoid crashes or stops. The algorithm uses past knowledge to generalize its strategy and adapt to different circuit configurations, choosing the best control signal based on current and voltage measurements to decrease lap time while staying on track. Experiments on two circuit configurations show results in table 1. The algorithm uses past knowledge to adapt to different circuit configurations and decrease lap time while staying on track. Experiments show that the AI improves lap times without replaying human driving samples, ranking almost best on the longest circuit. The final human lap time is lower than the AI lap time, but the human exhibits a higher standard deviation from the mean. The AI improves lap times without replaying human driving samples, ranking almost best on the longest circuit. It exhibits a higher standard deviation from the mean. Future improvements will optimize speeds and strategies for different circuits. The bijective strategy imitates the best human lap but only works for an identical circuit, providing an empirical lower bound for lap times. The AI improves lap times by reusing knowledge on new circuits without replaying human driving samples. The approach was validated on slot cars and ALE, with concepts of entities and life impulse used for Atari 2600 games. Image processing with Sobel operator is used for entity detection. The AI system uses image processing techniques like the Sobel operator and bounding-box detection to detect entities, including the controllable entity \"Me\". Signals are sent to ALE to identify affected entities and build a dynamic model of \"Me\". The system updates probability functions for entities E and F, inferring friends and enemies to develop a basic survival strategy. The AI system uses image processing techniques to detect entities and build a dynamic model for a survival strategy. Tests are conducted using the DQN as a benchmark, achieving decent scores with fewer training frames compared to standard benchmarks. The AI system achieves decent scores with fewer training frames compared to standard benchmarks. Initially, the algorithm struggles to identify itself, but eventually focuses on controlling the paddle and differentiates between friends (the ball) and enemies. The best scores are around 200 points, corresponding to partially destroyed rows of bricks. The AI system achieves decent scores with fewer training frames compared to standard benchmarks. The movement of the \"me\" under control of the algorithm sometimes never reaches a steady-state, oscillating at a frequency of 5.4 Hz. The control strategy is almost equivalent to a proportional controller, explaining the oscillations in the context of Linear-Time-Invariant (LTI) systems. The input being quantized to only three values generates a signal similar to limit-cycles, responsible for many missed balls by the algorithm. The AI system achieves decent scores with fewer training frames compared to standard benchmarks. The control strategy, similar to a proportional controller, causes oscillations at 5.4 Hz, leading to missed balls. Implementing concepts from Continental philosophy, a mathematical framework was formalized for controlling agents in simulated or real worlds. Results from experiments with a real slot car and Atari games showed promising outcomes using a basic survival approach. Our AI system achieved high scores in Atari games with fewer training frames compared to standard benchmarks. Implementing transposition properties from the slot car experiment could further reduce learning time. To reach higher scores, we will explore Monte-Carlo Tree Search approaches."
}