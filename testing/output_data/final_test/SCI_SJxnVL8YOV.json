{
    "title": "SJxnVL8YOV",
    "content": "In this study, Generative Adversarial Networks (GANs) are trained to generate realistic 3-D protein backbones by representing protein structures with pairwise distances between atoms. Interpolations in the latent space of the generator result in smooth deformations of the output backbones, and test set structures not seen during training can be generated. Sequence design, relaxation, and ab initio folding of generated structures show promising results in recovering the folds. The study explores the use of Generative Adversarial Networks (GANs) to generate realistic 3-D protein backbones using pairwise distances between atoms. Results show smooth deformations in output backbones through latent space interpolations. The ability to recover folds in forward-folding suggests a mechanism for fast protein structure refinement using external energy functions. Deep generative models have shown success in various modalities, including protein backbone generation for potential therapeutic development and protein modification. In the study, Generative Adversarial Networks (GANs) were used to generate matrices representing pairwise distances between alpha-carbons on protein backbones. This method allows for the stable generation of diverse protein structures, but requires iterative optimization for coordinate recovery. The approach aims to speed up and improve de novo protein design for applications in biosensors, enzymes, and therapeutics. In this study, methods were extended from BID10 to generate full-atom pairwise distance matrices for fixed-length fragments and train deep neural networks to recover and refine coordinates. Some fragments can host folding sequences, making them viable starting scaffolds for de novo protein design. The generator G produces a distance matrix, recovered by network V, with further refinement by network R. External energy functions are incorporated to refine the backbones. Proteins are macromolecules made up of amino acid sequences polymerized via condensation reactions. The protein backbone consists of the alpha-carbon and atoms forming the peptide bond, with torsion angles \u03c6, \u03c8, and \u03c9 around specific bonds. The global structure of the protein reflects its chiral nature, leading to specific torsion angle distributions. This results in the formation of right-handed helices at the secondary structure level. In protein design, the challenge lies in constructing new backbones for which sequences can be designed. Deep generative models can approximate real protein backbones, allowing for de novo protein design. Current methods for backbone generation rely on sampling or assembling native structures. This study extends state-of-the-art methods for backbone generation by improving upon the full-atom GAN baseline presented in BID10. It introduces a fast, fully differentiable method for recovering coordinates from a generated matrix, allowing errors to backpropagate to the generator network. Other methods for protein backbone generation include generating torsion angles or coordinates directly, but these often lack reasonable 3-D structure. The study improves upon full-atom GAN baseline by introducing a method to recover coordinates from generated matrices, addressing issues of distorted structures and mode collapse. The experimental pipeline involves generating pairwise distances, recovering 3-D coordinates, and refining them to reduce errors in the backbone. The method includes training a GAN to generate pairwise distance matrices for full-atom protein fragments. The GAN generates pairwise distance matrices for full-atom 64-residue fragments using two deep neural networks - a generator and a discriminator. The generator produces realistic data while the discriminator distinguishes between real and fake samples. The architecture includes convolution transpose operations for upsampling, a noise vector size of 1024 units, and training with the Adam optimizer. The study involves training a deep convolutional neural network to recover protein backbone coordinates from pairwise distance matrices. The network is pre-trained on real maps and fine-tuned on generated maps, showing surprising logic in coordinate placement. The network is trained with a scaled autoencoder loss on the task of recovering coordinates from real input distance maps. The study involves training a deep convolutional neural network to recover protein backbone coordinates from pairwise distance matrices. To ensure correct handedness of the backbone, a rigid body alignment loss is added to the objective function. The network is fine-tuned on generated maps without ground truth coordinates. The study introduces two discriminator networks to ensure correct handedness of recovered protein backbone coordinates: Local block discrimination (D B) operates on diagonal blocks of input map, correcting torsion locally, while Local fragment discrimination (D F) aligns excised fragments along the positive z-axis. The study introduces two discriminator networks, D B and D F, to ensure correct handedness of recovered protein backbone coordinates. D B corrects torsion locally in diagonal blocks of input map, while D F aligns excised fragments along the positive z-axis during training. The network learns to recover coordinates that match input pairwise distances and fool the discriminators, with specific training loss objectives for V on real and generated maps. After introducing discriminator networks D B and D F to ensure correct handedness of protein backbone coordinates, the study focuses on refining recovered structures with a refinement network R. The network learns an additive shift to correct local backbone errors through a recurrence operation unrolled for t steps. Training involves updating R with autoencoder and discriminator fooling losses, while keeping V and G fixed and training D B and D F in a similar manner. The trained coordinate recovery network V is a good \"local minimum\" despite not generalizing to arbitrary maps without errors. Qualitative features of generated maps are preserved after structure recovery, with correct handedness indicated in torsion distribution post-recovery and refinement. Recovery and refinement improve the fragments. The trained coordinate recovery network V can quickly learn to recover coordinates well for a single or small batch of examples by overfitting to new generated maps. The dataset used consists of protein crystal structures from the Protein Data Bank, with full-atom pairwise distances utilized for fragments. Our final dataset includes 800K fragments from the 'A' chain of PDB structures, omitting those with non-ideal atomic bonds. Random full-atom maps generated by our trained GAN closely resemble real maps, with realistic torsion distribution after coordinate recovery. The refinement module and overfitting procedure improve torsion distribution without deviating from original distance constraints. Random 64-residue protein fragments are also rendered after coordinate recovery. The text discusses the generation of protein structures using a generative pipeline and the optimization process for realistic deformations of protein backbones. It aims to refine and fold protein structures efficiently by utilizing heuristic energy functions. The questions raised include whether small steps in the latent space correspond to realistic deformations and if the pipeline can effectively use external energy functions for refinement. The text discusses the generation of protein structures using a generative pipeline and the optimization process for realistic deformations of protein backbones. It aims to refine and fold protein structures efficiently by utilizing heuristic energy functions. The generator's latent space is examined to determine if it can express unseen real structures and if sequences can be designed onto generated backbone fragments for folding. Linear interpolations in the latent space are analyzed to observe smooth structural deformations of the peptide backbone. The text discusses optimizing the latent vector z to match a given pairwise distance matrix x using a pre-trained generator network. The optimization process involves minimizing the L2 distance between the generated map G(z) and the real example x, along with a K-L divergence regularizer term on z. The generator is found to be expressive enough to find structures for input examples. The generator is expressive enough to find real unseen data examples in its image. Only a small fraction of coordinate sets can host an amino acid sequence that folds into a specified structure. 2800 structures are sampled from the generator, with only a few structures being distended. Ab initio folding of candidate low-energy structures is also discussed. Ab initio folding of candidate low RoG generated and refined structures with low Rosetta energy after sequence design is a challenge in protein design. State-of-the-art protocols rely on partial structures from the Protein Data Bank. To test if generated backbones can host foldable sequences, 2800 structures were randomly sampled and underwent iterative sequence design and structural refinement using Rosetta. The generator provides orderings of secondary structure elements encoded. In this application, the generator orders secondary structure elements based on distance constraints, while Rosetta refines their global positioning. Movements during relaxation lead to lower energy structures with internal contacts. Designs with low radii of gyration and negative Rosetta energies were selected for further testing. Low-energy structures were tested for foldability using Rosetta AbInitio. The results from using Rosetta AbInitio for blind structure prediction show that the designed models closely match the generated models, indicating the capability of the generator to provide designable peptide backbones. The proposed pipeline generates fixed-length full-atom protein backbones in a differentiable manner by training a model to generate pairwise distance matrices between atoms, eliminating the need for explicit encoding of structure invariances. The pipeline can encode structure invariances to rotations and translations, model long-range contacts, and train networks to recover and refine coordinates. It shows potential for de novo protein design, with interpolations in the latent space corresponding to smooth deformations of peptide backbones. The generator can produce native unseen structures and some backbones capable of hosting foldable sequences, suggesting a mechanism for fast protein structure refinement and folding using external energy functions. Future plans include optimizing the generative pipeline with the Rosetta energy function BID22 to generate relaxed, low-energy structures. The work involves generating longer backbones and conditioning the generative model on secondary structure to specify backbone topologies for design."
}