{
    "title": "HyzWeVX_jQ",
    "content": "We propose an end-to-end framework for training domain specific models (DSMs) with distillation to achieve high accuracy and efficiency for object detection tasks. By reducing the dataset size and focusing on a limited domain, compact DSMs outperform COCO trained models of the same size. Training on a compact dataset can reduce training time by 93% with only a 3.6% accuracy drop. The framework aims to minimize the accuracy gap between student and teacher models through knowledge distillation. The paper proposes an end-to-end framework for training domain specific models (DSMs) to reduce the accuracy gap between student and teacher models. By using a restricted class of domain-specific images and culling easy-to-classify images, training efficiency is improved. The framework aims to achieve high accuracy and efficiency for object detection tasks by training DSMs with distillation. The proposed framework aims to train compact models with domain-specific data by culling the training dataset to reduce computation resources. Training data with high utility is retained to achieve a 93% reduction in training time with only a 3.6% accuracy loss. To prepare the training data, predictions from a larger teacher model are used as ground truth labels, improving efficiency in model deployment for surveillance tasks. Training a object detection model can be time-consuming, especially for applications requiring frequent retraining. By utilizing a pre-trained large-scale general dataset, the model can already make accurate predictions for a significant portion of domain-specific data. A compact dataset is created by comparing predictions made by the teacher model to those of the model being trained, only retaining data where inconsistencies are found. This helps reduce computational redundancy and improve training efficiency. The L train is used to measure consistency between teacher and DSM models. Results show training the res18 DSM with 3600 images for 10 epochs using stochastic-gradient descent. The aim is to train models with domain-specific data."
}