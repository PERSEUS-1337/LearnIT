{
    "title": "rJeKVt-iaV",
    "content": "In our work, we develop a game-based abstraction method for Partially Observable Markov Decision Processes (POMDPs) to provide safe bounds and tight approximations for important properties. This method addresses the challenges of undecidable or computationally expensive properties in POMDPs, with applications in robotics and motion planning. We discuss theoretical implications and demonstrate the effectiveness of our approach on various benchmarks. In offline motion planning, strategies for agents are found to ensure desired behavior despite dynamical obstacles and uncertainties. Markov decision processes (MDPs) are used to model scenarios with random elements, while partially observable MDPs (POMDPs) are used when full knowledge of the environment is not available. In POMDPs, the agent only has access to observations that can be shared between multiple states. Our aim is to apply abstraction and abstraction refinement techniques to POMDPs in order to get good and safe approximative results for different types of properties. As a case study, we work with a scenario featuring a controllable agent navigating a room with static obstacles and moving opponents in a grid-based environment. The scenario involves a grid-based environment with static obstacles and moving opponents. The agent knows its position, but opponent positions are only known within a certain distance threshold. A POMDP model is used to find a strategy to navigate from an initial to a target location without collision. The number of states in the POMDP is in O(n^4) for a grid size of n x n cells with one opponent. The POMDP model for navigating a grid-based environment with obstacles and opponents has a state space that grows rapidly with increasing grid size. To handle non-trivial grids, a game-based abstraction approach using BID3 is proposed. This abstraction guarantees a certain level of safety and can be mapped to the original POMDP strategy. A simulation relation is established between paths in the probabilistic game and paths in the POMDP. The game-based model checking approach provides a lower bound on safety levels achievable in a POMDP. Results from analyzing game-based models with PRISM-games show the ability to handle larger grids than PRISM-pomdp, while still obtaining close to optimal schedulers. Experiments on a grid without obstacles demonstrate the faster abstraction approach compared to solving the POMDP. The abstraction approach is significantly faster than solving the POMDP directly, with smaller game models for large grids. Strategies yield better values when mapped back to the original POMDP. While sound, the approach targets an undecidable problem, lacking a strategy for maximum success probability. Refining the abstraction by encoding history into the current state improves results but increases computation time. TAB0 implements this one-step history refinement. The implementation showcases a game-based abstraction technique for synthesizing strategies in POMDPs, specifically for grid-based motion planning problems with restricted observability. By refining the abstraction to remember the opponent's last known position, the agent can navigate the grid to reach a goal state while avoiding collisions with obstacles efficiently. Our approach can handle larger state spaces than general-purpose POMDP solvers, achieving goals while avoiding collisions with obstacles efficiently."
}