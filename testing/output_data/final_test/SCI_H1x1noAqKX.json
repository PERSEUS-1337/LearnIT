{
    "title": "H1x1noAqKX",
    "content": "Most classification and segmentation datasets assume a closed-world scenario with predetermined visual classes, leading to failures with out-of-distribution input. To address this, we propose discriminative detection of OOD pixels without making decisions based on the primary model's training dataset. In a dense prediction setup, experiments are conducted on high-resolution natural images using road driving datasets for training and the ILSVRC dataset for background distribution. The approach is evaluated on the WildDash test dataset, the only public test dataset with out-of-distribution images. The proposed approach successfully identifies out-of-distribution pixels, outperforming previous work significantly. Recent advancements in deep convolutional models have greatly improved visual recognition, with semantic segmentation systems achieving over 80% mIoU on challenging datasets like Pascal VOC 2012 and Cityscapes. However, most existing datasets for semantic segmentation assume closed-world evaluation, limiting their real-world applicability, especially in scenarios like road driving. The text discusses challenges in recognizing image regions not covered by the Cityscapes ontology, such as road works, water, and animals. Improving datasets like Vistas with a richer ontology is one approach, but it requires significant computational resources and still may not cover all variations in datasets like WildDash. The need to quantify model prediction uncertainty is crucial for reliable deployment in real-world applications. Uncertainty can be categorized into aleatoric uncertainty, caused by model limitations, and epistemic uncertainty, arising when the model fails to make accurate predictions despite the training dataset. Recent work in image-wide out-of-distribution detection evaluates prediction uncertainty by analyzing model output. Approaches that use GAN discriminators to detect out-of-distribution samples do not scale easily to dense prediction in high resolution images. Total uncertainty can be high even on in-distribution pixels, such as those at semantic borders or very distant objects. In this paper, a new approach is proposed for detecting out-of-distribution samples on the pixel level using a dedicated \"OOD\" model. This model complements the primary model trained for a specific vision task and involves dense binary classification between the training dataset and a larger background dataset. The formulation requires fewer computational resources compared to GAN-generated backgrounds and is insensitive to uncertainty related to semantic segmentation. Detection of out-of-distribution examples has been a focus in recent literature, with many approaches analyzing prediction entropy to estimate uncertainty. The prediction confidence can be expressed as the probability of the winning class or the max-softmax activation. ODIN proposes pre-processing input images with antiadversarial perturbation and increasing softmax temperature. Another approach involves a separate head in the model to learn prediction uncertainty or confidence, which is used to discount data loss and penalize uncertainty. The model is penalized based on uncertainty, encouraging learning from hard examples. Epistemic uncertainty is calculated using mutual information between model parameters and predictions. This approach helps identify out-of-distribution samples. The text discusses the limitations of using MC dropout for out-of-distribution (OOD) detection accuracy. It suggests that using an ensemble of independently trained models may provide more accurate uncertainty estimation, but this approach may not be suitable for real-time dense prediction systems. A proposed solution involves fitting a generative model to the training dataset to evaluate the probability distribution of the data. The text discusses using generative models for out-of-distribution (OOD) detection, where OOD samples are produced by a GAN generator or an autoencoder. These models aim to enhance inliers and distort outliers for better separability. However, current approaches are limited to low-dimensional samples and simple image datasets, not scaling well to complex domains like traffic scenes. The text discusses out-of-distribution pixel detection in complex domains like traffic scenes. Using joint segmentation training on Cityscapes and ScanNet, out-of-distribution samples can be identified based on foreign class predictions. This involves dense binary classification into OOD and ID classes, with training pixels from the semantic segmentation dataset. The paper proposes using the ILSVRC dataset for out-of-distribution (OOD) training pixels in semantic segmentation, as it offers a diverse range of visual content compared to the in-distribution (ID) dataset. This discriminative OOD detection approach aims to improve model performance in complex domains like traffic scenes. The model for out-of-distribution (OOD) images uses a feature extractor pretrained on ImageNet and an OOD detection head. It addresses issues of overlapping classes and background content by training on both ID and OOD pixels. The proposed OOD model is trained on both in-distribution (ID) and out-of-distribution (OOD) pixels to address biases towards the ID dataset. It focuses on class diversity, such as the occurrence of cars, to classify pixels more accurately. The model is discriminative, fully convolutional, and trained with dense cross-entropy loss. Evaluation involves obtaining dense logit maps for two classes to detect epistemic uncertainty in each pixel, followed by OOD detection through probability thresholding. The proposed OOD model is trained on in-distribution and out-of-distribution pixels to address biases. It can be warmed-up with pre-trained parameters from ILSVRC, speeding up training. Experiments evaluate dense OOD detection accuracy in natural images from driving datasets, comparing the approach to previous methods. In this study, the authors compare their approach to previous methods adapted for dense prediction in OOD detection. They discuss three approaches, including max-softmax and ODIN, which involve perturbing input images to improve prediction accuracy at the pixel level. Despite hyperparameter tuning, only a modest improvement was achieved. In this study, a separate convolutional head is introduced for trained confidence predictions to diminish wrong predictions in pixel loss. Cityscapes dataset contains densely annotated images from the driver perspective, while Vistas dataset is larger and more diverse. WildDash dataset provides a benchmark for semantic segmentation and instance detection. The WildDash dataset BID24 focuses on challenging images for semantic and instance segmentation, including negatives with various distortions. It consists of 70 validation and 156 test images, with 15 marked as negatives. These negative images contain noise, indoor scenes, and artificially altered inlier images. WildDash follows Cityscapes labeling policy BID1 but also evaluates performance on negative images, where correct classification is based on Cityscapes labels or void labels for out-of-distribution samples. The ILSVRC dataset includes 1000 ImageNet classes with over 1.2 million images. The Pascal VOC 2007 dataset has 20 classes with 9,963 images. Three models based on DenseNet-121 are experimented with for semantic segmentation. The primary model for semantic segmentation is based on DenseNet-121 architecture, with 120 convolutional layers organized into dense blocks and transition layers. The model concatenates the upsampled output of DB 4 with DB 2, followed by a spatial pyramid pooling layer and a BN-ReLU-Conv block to output 19 feature maps with logits. These logits are normalized with softmax and used in cross-entropy loss. The proposed method introduces a new SPP layer and BN-ReLU-Conv block parallel to the primary model for semantic segmentation. Confidence estimation is blended with a sigmoid activation block, and a discriminative OOD detector is used to classify inliers and outliers. Gradients are prevented from flowing into segmentation maps to focus on segmentation training. The model is trained on Cityscapes data with specific layers to prevent overfitting. It achieves 70.1% mIoU on Cityscapes val and 23.6% mIoU on WildDash val. A separate model is trained on a combination of Cityscapes train data. The model is trained on Cityscapes data with specific layers to prevent overfitting, achieving 70.1% mIoU on Cityscapes val and 23.6% mIoU on WildDash val. Additionally, a model trained on a combination of Cityscapes train and WildDash val reaches 70.2% mIoU on Cityscapes val. Another model, BID3, achieves 71.1% mIoU on Cityscapes val and 25.7% mIoU on WildDash val. Discriminative models for OOD detection are trained using Cityscapes, Cityscapes + WildDash val, and Vistas datasets. A model instance trained on the Vistas dataset, BID16, is also shown to be more diverse than Cityscapes. The dataset for the OOD class involves labeling ILSVRC pixels as OOD and road-driving pixels as ID. Images are resized to 512 pixels, mixed batches are formed, and models are trained using ADAM optimizer with a batch size of 30. Oversampling is done to balance dataset sizes, and training continues until reaching 100% accuracy on WildDash val. Similar accuracies are observed on ILSVRC val (OOD) and Vistas val (ID). After achieving 100% accuracy on WildDash val, similar accuracies were also seen on ILSVRC val (OOD) and Vistas val (ID). The discriminative OOD model was compared with other models like max-softmax, ODIN, trained confidence, and a pretrained runnerup model from the ROB Challenge. Performance was quantified using average precision to evaluate how well the models separate OOD and ID samples on various test datasets. Image-wide ID and OOD labeling was assumed, with WildDash test images #0-#140 labeled as ID and images #141-#155 labeled as OOD. Two AP measures were provided, one evaluating results on all negative images and the other ignoring altered valid images. The second performance metric for OOD detection is based on the max-softmax criterion using two instances of the primary semantic segmentation model trained on Cityscapes data. Evaluation was done on WildDash test images without altered valid images. All pixels in OOD images are considered \"positive\" responses, while pixels in ID images are considered \"negatives\". Such ambiguous pixels are rare and do not affect the conclusions. The evaluation on WildDash test without altered valid images shows poor performance, with training on WildDash val improving results. The precision-recall curve indicates low precision even for small recall values, suggesting poor separation of ID and OOD pixels. OOD responses do not correlate with epistemic uncertainty but occur on semantic borders, small objects, and distant parts of the scene. The study conducted OOD detection in altered valid scenes from WildDash test, achieving better mIoU performance by training with uncertainty to alleviate overfitting. However, the uncertainty estimation was found to be the worst predictor of OOD pixels among all approaches considered. The confidence head in the model must be taught to recognize uncertain pixels as it performed poorly in experiments. OOD detection results are shown for a model trained on various datasets, with interesting findings in detecting animals in WildDash test images. The model trained on WildDash val performs better on distorted images, turning it into a discriminative OOD detector with ScanNet as the outlier dataset. There is a significant improvement in average precision compared to models trained only on road-driving scenes. The model recognizes most pixels in artificially altered negative WildDash test images as ID, but makes errors in some OOD images such as ants and people in OOD contexts. The model, trained on WildDash val, performs well on distorted images, becoming a discriminative OOD detector with ScanNet as the outlier dataset. It shows improvement in average precision compared to models trained solely on road-driving scenes. The model recognizes most pixels in artificially altered negative WildDash test images as ID but struggles with some OOD images like ants and people in OOD contexts. The precision-recall curve for the model is shown in Figure 2, with high precision for low recall values. Using probabilities for OOD detection extends the range of recall values with high precision. The model instance trained on Cityscapes images performs poorly, classifying all WildDash test images as OOD, indicating potential overfitting due to dataset similarities. The ROB model classifies non-indoor images as ID, outperforming other models on the ROB dataset. The model trained on Vistas performs better than Cityscapes, but the best results are achieved with the WildDash validation set. These models struggle with artificially altered images, recognizing them as ID samples. The models trained on Vistas and Cityscapes + WildDash struggle with recognizing ID classes in OOD context, leading to misclassification of people sitting in a room as OOD samples. The precision-recall curves for these models show different behaviors, with the WildDash-trained model dropping suddenly due to altered valid images. Additionally, difficult cases are discussed in FIG1 to highlight areas for improvement in OOD classification. Our discriminative models suspect that some parts of images labeled as inliers are actually out-of-distribution (OOD) due to the presence of certain classes in the training dataset. Future models should consider the overlap between different datasets to improve predictions. Fine-tuning on images containing both in-distribution (ID) and OOD pixels could lead to more accurate results. The proposed OOD-detection models are evaluated on unseen datasets, showing varying performance based on the ID dataset used. Using Vistas as the ID dataset results in fewer OOD detections in Cityscapes. Using Vistas as the ID dataset leads to fewer OOD detections in Cityscapes, indicating that Cityscapes may not represent a wide variety of traffic scenes well. Pascal VOC2007 pixels are mostly classified as OOD, suggesting that using ILSVRC as an outlier dataset can generalize to other outlier datasets. Graceful performance degradation in unforeseen scenery is crucial for real-life computer vision applications to avoid disasters. Our novel approach improves OOD detection by recognizing outliers as more similar to a \"background\" dataset than the primary model's training dataset. Experiment results show significant AP performance improvement compared to previous approaches, especially for dense prediction in high resolution images. ILSVRC is a suitable background dataset candidate, but more comprehensive datasets are needed. Future work will use these results to guide annotation efforts and improve direction. The Wilddash dataset is the only publicly available dataset providing OOD images, but it lacks detailed annotations for testing unfamiliar object detection in familiar settings. To address this, six new datasets are proposed for this purpose. An improved training procedure is also suggested to enhance the discriminative OOD detection model's ability to predict OOD object borders accurately. This new model will be evaluated in future work. In order to evaluate different OOD detection methods with OOD pixels present in ID scenes, six new datasets are created. Three datasets include images with both ID and OOD pixels for evaluation, while the other three are for control experiments. The first two datasets are generated by pasting Pascal VOC 2007 animals onto images from Vistas val, chosen for its densely annotated object instances that are out-of-distribution for road-driving scenes. The final dataset contains a selection of Vistas images with a significant number of pixels labeled as 'ground animal'. Pascal images with segmentation groundtruth containing 7 animal classes are used to select 369 large objects, which are then pasted onto random Vistas val images. After selecting 369 large objects from Pascal images, they were pasted onto random Vistas val images, resulting in 369 combined images. To address potential issues with resizing artifacts, another dataset was created by pasting objects without resizing onto random Vistas val images, resulting in 31 combined images. This dataset is more challenging as the OOD patches are much smaller. Performance on a dataset of 288 images indicates a model's ability to detect out-of-distribution (OOD) pixels due to different imaging conditions. Different OOD detection methods are evaluated, with red denoting high confidence in OOD pixels. The model trained according to a specific method accurately detects borders. The primary model accurately detects borders and OOD shapes. The ROB model detects the position of pasted patches, while a discriminative model trained on whole OOD images fails to do so. The dataset involves pasting objects from Vistas into Cityscapes images to test model performance in detecting different camera characteristics of the patch. The dataset involves pasting objects from Vistas into Cityscapes images to test model performance in detecting different camera characteristics of the patch. The models struggle to accurately detect the pasted patches, with the fourth model reacting to borders of pasted content. The dataset involves pasting objects from Vistas into Cityscapes images to test model performance in detecting objects at unusual locations. This set contains 1873 images and is a subset of Vistas training and validation images. Unlike images with pasted Pascal animals, OOD detection is unable to succeed by recognizing pasting artifacts or different imaging conditions. The training dataset is modified to cope with images containing both ID and OOD pixels. The training dataset is modified by removing Vistas images with 'ground animal' instances and selecting ILSVRC images with bounding box annotations. These images are used for OOD detection, either as single images or combined images with pasted bounding boxes. Models do not detect pasted patches, but only the fourth model detects 'ground animal' instances in Vistas images. The fourth model accurately segments 'ground animal' instances in Vistas images and reacts to animals in other images. The ROB model detects some parts as OOD but they do not correspond to animal locations. The resulting images are resized to 512x512 pixels and labeled as OOD or ID. The fully convolutional discriminative OOD model is trained according to the described procedure. TAB5 shows the average precision performance of all OOD models in the paper. The models evaluated on six test datasets show high uncertainty on object borders. The ROB model and discriminative model trained on entire images struggle to detect OOD patches due to lack of animal training data and border information. The discriminative model trained according to Section A.2 performs the best. The discriminative model trained according to Section A.2 performs the best in detecting OOD patches, even on small pasted objects and genuine animals in Vistas images. However, it occasionally detects borders of ID patches, suggesting optimistic results on PascalToVistas. The model sometimes misclassifies parts of Cityscapes images, but achieves the best performance on VistasAnimals dataset. Average precision for pasted content detection on control datasets is shown in TAB6. The best discriminative model detects differences in imaging conditions and unexpected object locations between ID images and pasted ID patches. It successfully recognizes pasting interventions, such as animals in road-driving images, outperforming previous approaches. These results provide insights for estimating uncertainty in images and strengthen the conclusions of the main article. The proposed dense OOD-detection approach is tested on the UCSD Ped2 dataset, which contains video sequences of pedestrian scenes with annotated anomalies. Unlike UCSD anomaly detection, OOD detection is not solely based on motion anomalies. The dataset presents a unique challenge for discriminative OOD detectors compared to road driving datasets. The UCSD Ped2 dataset contains grayscale video clips of pedestrian walkways with anomalies like bikers, skaters, and small carts in the test subset. The dataset is unique for OOD detection as it provides a different challenge compared to road driving datasets. The model easily detects anomalies like carts and wheels as out-of-distribution (OOD) in the UCSD Ped2 dataset. It also correctly identifies bike riders and skaters as in-distribution (ID). The training dataset includes images from UCSD Ped2 and uses grayscale images for half of the training data. Experimental results show the discriminative model's response on the UCSD Ped2 dataset and its performance on test sequences 1, 4, and 8. The model struggles to detect skaters as out-of-distribution (OOD) due to their similarity with pedestrians. Additionally, cyclists and their bikes are labeled as anomalies in the ground truth annotations, leading to a decrease in average precision (AP). Training on ILSVRC bounding boxes pasted above UCSD images helps in detecting unexpected objects in pedestrian walkways. Training on ILSVRC bounding boxes pasted above UCSD images supports the conclusion that ILSVRC is a good choice as an outlier distribution for various training datasets."
}