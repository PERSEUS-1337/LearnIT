{
    "title": "HJepXaVYDr",
    "content": "Stochastic AUC maximization is gaining interest for imbalanced data classification. This paper focuses on using deep neural networks for this task, presenting a non-convex concave min-max problem formulation. The main contribution is making stochastic AUC maximization practical for deep neural networks and big data, with the exploration of Polyak-\u0141ojasiewicz condition for faster convergence rates and a more practical step size scheme. The proposed algorithms aim to improve convergence rates and step size schemes for deep neural networks in tasks like computer vision, speech recognition, and natural language processing. Deep learning has shown significant success in various domains by minimizing empirical risk through surrogate loss functions. In image classification tasks, the cross entropy is commonly used as the objective function to measure the misclassification rate. However, when dealing with imbalanced data, AUC maximization has been proposed as a new learning paradigm to address this issue. AUC, which stands for Area Under the ROC curve, is defined as the probability that the prediction score of a positive example is higher than that of a negative example. Compared to misclassification rate, AUC provides a more balanced evaluation metric for models. In imbalanced data settings, AUC is more suitable than misclassification rate. Zhao et al. (2011) use reservoir sampling to maintain representative samples for updating the model. Gao et al. (2013) propose an algorithm that computes stochastic gradient without buffer-based storage. Ying et al. (2016) introduce a novel saddle-point reformulation for AUC surrogate loss. In non-convex min-max optimization, recent studies have focused on designing stochastic algorithms with different convergence rates. Ying et al. (2016) achieved O(1/ \u221a t) convergence using primal-dual stochastic gradient, Natole et al. (2018) obtained O(1/t) convergence with a strongly convex regularizer, and Liu et al. (2018) achieved O(1/t) convergence without strong convexity assumptions. These approaches mainly focus on learning linear models with convex objective functions. In non-convex min-max optimization, recent studies have focused on designing stochastic algorithms with different convergence rates. Sanjabi et al., Lu et al., and Jin et al. (2018-2019) propose algorithms for weakly convex and concave objective functions. Rafique et al. (2018) design a proximal guided algorithm solving convex-concave subproblems. Lu et al. (2019) adopt block alternating minimization/maximization strategy. Lin et al. (2018) propose a proximal algorithm for weakly convex and concave objectives. Our work proposes a proximal algorithm for solving a strongly monotone variational inequality, focusing on the PL condition for the outer minimization problem and designing stochastic algorithms for convergence to a stationary point. The PL condition, introduced by Polyak, allows gradient descent to achieve linear convergence to a global minimum. Several non-convex SVRG-style algorithms have been developed for objective functions with a finite-sum structure that satisfy the PL condition, guaranteeing convergence to a global minimum with a linear rate. However, these stochastic algorithms are not applicable to the min-max formulation for stochastic AUC maximization. Liu et al. (2018) is the only work leveraging a quadratic growth condition to develop a stochastic primal-dual algorithm for AUC maximization with a fast rate, but their analysis relies on convexity. The PL condition is crucial in recent works on deep learning, demonstrating the absence of spurious local minima and ensuring global convergence of gradient descent methods. Various studies have shown that the PL condition holds for different types of neural networks, such as deep linear residual networks and networks with Leaky ReLU activation. Various studies (Li & Yuan, 2017; Arora et al., 2018; Allen-Zhu et al., 2018; Du et al., 2018b; Li & Liang, 2018) analyze the trajectory of gradient descent in neural networks, showing the PL condition holds under certain conditions. For instance, Du et al. (2018b) demonstrate that a global optimum lies within a ball centered at the initial solution for sufficiently wide two-layer neural networks. Allen-Zhu et al. (2018) extend this to overparameterized deep neural networks with ReLU activation, showing the PL condition holds for a global minimum around a random initial solution. The AUC maximization problem involves learning a nonlinear model parameterized by w, denoted as h(w; x), which is not necessarily linear or convex in terms of w. Previous works assumed h(x) = w x for simplicity, but this study considers a more general approach. The optimization problem involves a non-linear model parameterized by w, denoted as h(w; x), which is not necessarily linear or convex. The problem is converted into a saddle-point problem, making the min-max formulation more favorable for developing a stochastic algorithm. Careful sampling of positive and negative examples is required for stochastic optimization. The optimization problem involves a non-linear model parameterized by w, denoted as h(w; x). The algorithms discussed are applicable to both batch-learning and online learning settings. The objective function P(w) is minimized using the Proximally Guided Algorithm (PGA). The algorithm aims to find the global minimum of \u03c6, inspired by a PL condition on the objective function P(w) for learning a deep neural network. Lemma 1 states that if the gradient of h(w; x) is bounded by L for all w and x, and if P(w) satisfies the PL condition, then AUC maximization with a one-hidden layer neural network can be achieved. The algorithms discussed in (Rafique et al., 2018) for batch-learning and online learning settings are further analyzed, with a focus on the online learning setting. The algorithm presented in Algorithm 1 is a direct application of Algorithm 2 from (Rafique et al., 2018) to the online setting. The analysis involves adding a ball constraint on the primal and dual variables to ensure boundedness. The convergence result of Algorithm 1 is discussed, highlighting the complexity compared to stochastic gradient descent methods. Designing a stochastic primal-dual algorithm to achieve better complexity remains an open problem. In this section, two primal-dual algorithms are presented for solving a min-max optimization problem with theoretical convergence results. The algorithms follow a proximal point framework and involve solving convex-concave problems iteratively. The proposed methods aim to handle both known and unknown positive ratios, with updates made periodically. The PPD-SG algorithm uses a geometrically decaying step size scheme and updates the dual variable at the end of each outer loop. It achieves lower iteration complexity by using a small number of samples to estimate the optimal \u03b1. The PPD-SG algorithm uses a geometrically decaying step size scheme and updates the dual variable at the end of each outer loop to achieve lower iteration complexity. Theorem 2 introduces the complexity of the Proximal Primal-Dual Adagrad (PPD-Adagrad) algorithm, which improves upon previous methods by enhancing the dependence on \u00b5 and achieving adaptive updates similar to traditional AdaGrad. The PPD-AdaGrad algorithm aims for adaptive convergence by carefully handling primal-dual updates for non-convex min-max problems. The convergence results show that the number of iterations is at most O, with the required number of samples at O, exhibiting adaptive iteration complexity. The setting of parameters like \u03b7 k, T k, m k depends on the growth rate of stochastic gradients. The setting of parameters like \u03b7 k, T k, m k for adaptive convergence depends on unknown parameters. Heuristics include decreasing step size by a constant factor and updating estimators for unknown values like p. The approach for unbiased estimator optimization is described in Algorithm 4, extending to multi-class problems with normalized scoring functions. AUC is defined for c classes with individual last layer connections in deep neural networks. In this section, empirical results are presented to verify the effectiveness of the proposed algorithms (PPD-SG and PPD-AdaGrad) for solving multi-class problems with normalized scoring functions. The algorithms are compared with baseline methods including PGA, Online AUC method, and standard SGD. A residual network with 20 layers is used for implementation. The study focuses on maximizing AUC for imbalanced data using a residual network with 20 layers. Comparisons are conducted on benchmark datasets like Cat&Dog, CIFAR10, CIFAR100, and STL10. Different training/validation splits are used for each dataset, and multiple binary classification tasks are constructed with varying imbalanced ratios. For more details on task construction, refer to Appendix A.8. The study focuses on maximizing AUC for imbalanced data using a residual network with 20 layers. Comparisons are made on benchmark datasets like Cat&Dog, CIFAR10, CIFAR100, and STL10. Results show that SGD performs better in balanced settings, while AUC optimization methods are more advantageous in imbalanced settings. PPD-SG and PPD-AdaGrad outperform other baseline algorithms, with PPD-AdaGrad sometimes being faster. A mixed strategy of pre-training with SGD and then switching to PPD-SG shows even better performance. In this paper, the study focuses on maximizing AUC for imbalanced data using a deep neural network. Two algorithms with state-of-the-art complexities for stochastic AUC maximization problem are proposed, based on saddle point reformulation and Polyak-\u0141ojasiewicz condition in deep learning. Experimental results demonstrate the efficiency of the algorithms on benchmark datasets, showing faster convergence compared to other baselines. The analysis techniques may be extended to other problems with the min-max formulation. The study focuses on maximizing AUC for imbalanced data using a deep neural network. Two algorithms are proposed for stochastic AUC maximization based on saddle point reformulation and Polyak-\u0141ojasiewicz condition in deep learning. Experimental results show faster convergence compared to other baselines on benchmark datasets. The analysis techniques can be extended to other min-max formulation problems. The text discusses the update of parameters and the convexity of functions involved in the algorithms. The study proposes algorithms for stochastic AUC maximization in deep learning, focusing on imbalanced data. Experimental results show faster convergence compared to baselines. The algorithms involve updating parameters and ensuring convexity of functions. The text discusses rearranging terms, bounding values, and employing conditional expectations in the proof of Lemma 3. The proof of Theorem 3 involves showing the convexity and smoothness of a function \u03c6, using a stopping time argument and conditional expectations. The text discusses rearranging terms, bounding values, and utilizing the PL property of \u03c6. The proof involves showing the convexity and smoothness of function \u03c6 using a stopping time argument and conditional expectations. The total iteration complexity is determined by the required number of samples and constructing datasets for different scenarios. Model pretraining is effective in deep learning tasks, leading to improved performance. The method PPD-SG+pretrain shows better convergence and AUC results. Randomly partitioning classes as positive or negative labels also affects performance on CIFAR10 and STL10 datasets. For CIFAR10 and STL10 datasets, classes are randomly divided into positive and negative labels. Negative samples are then reduced by 95% and 90% for training data, maintaining original testing data. AdaGrad is introduced for minimizing cross-entropy loss, with PPD-Adagrad and PPD-SG showing faster convergence compared to other baselines. Classes from CIFAR10 and STL10 datasets are divided into positive and negative labels, with 50 classes randomly selected for each label."
}