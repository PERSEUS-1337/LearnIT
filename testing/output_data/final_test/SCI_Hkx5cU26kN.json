{
    "title": "Hkx5cU26kN",
    "content": "Recent pretrained sentence encoders, including OpenAI Transformer and BERT, are evaluated for their grammatical knowledge using a development set for the Corpus of Linguistic Acceptability. The study finds that while some syntactic structures are easily learned by all models, others require strong overall performance to be effectively learned. Pretrained sentence embeddings show varying effectiveness in understanding natural language. The effectiveness of pretrained sentence embeddings like GPT and BERT has significantly increased in recent years, especially on tasks like the acceptability task with CoLA. These models outperform recurrent models in identifying subtle grammatical features in sentences. In this paper, the goal is to develop an evaluation dataset to identify syntactic features that GPT and BERT excel at compared to recurrent models. The analysis includes expert annotations on CoLA for 63 syntactic features, revealing specific features that impact sentence classification difficulty. Unusual argument structures do not pose a challenge, while long-distance dependencies do. The study compares the ability of transformer models and recurrent models to learn long-distance dependencies in sentences. Pretrained word embeddings like word2vec and GloVe have been widely used in language understanding applications. Recent research focuses on creating reusable sentence embeddings with pretrained weights. The study compares transformer models and recurrent models for learning long-distance dependencies in sentences. Pretrained word embeddings like word2vec and GloVe are commonly used in language understanding applications, while recent research emphasizes creating reusable sentence embeddings with pretrained weights. Current state-of-the-art sentence encoders are pretrained on language modeling tasks with unlabeled data, such as ELMo, GPT, and BERT, each utilizing different architectures like BiLSTM and Transformer. The Transformer architecture, unlike earlier approaches, fine-tunes the encoder on downstream tasks, leading to top performance on the GLUE benchmark. Research on sentence embeddings includes probing tasks to reveal encoded syntactic information. Related work indirectly probes sentence embedding features through language understanding tasks. Linzen et al. (2016) and Ettinger et al. (2018) investigate whether LSTMs and sentence embeddings can identify syntactic dependencies and encode semantic roles. Kann et al. (2019) use acceptability classification to test if embeddings encode information about verbs and their argument structures. The Corpus of Linguistic Acceptability (Warstadt et al., 2018) is a dataset of 10k example sentences with expert annotations for grammatical acceptability, taken from theoretical linguistics publications. Example sentences from theoretical linguistics publications are labeled for acceptability by authors or native speakers. The acceptability classification task has been explored in computational linguistics using RNNs to classify sequences of POS tags or naturally occurring sentences. Lau et al. (2016) predict acceptability from language model probabilities. Lau et al. model gradient crowdsourced acceptability judgments, reflecting a debate on the reliability of binary expert judgments like those in CoLA. Warstadt et al. found that new human annotators outperform neural network models on CoLA. A grammatically annotated version of the CoLA development set is introduced for detailed error analysis. The curr_chunk discusses the manual annotation of 1043 sentences for 63 minor grammatical features organized into 15 major features. Each sentence is labeled with at least one feature, with an average of 4.31 minor features per sentence and 3.22 major features per sentence. The annotations were done by a PhD student with training in formal linguistics. The features were developed in a trial stage by a PhD student with training in formal linguistics. The feature set includes major features such as SIMPLE, Pred(icate), and Adjunct, which mark various optional modifiers in sentences. These constructions are well-studied in syntax. The curr_chunk discusses different types of syntactic features related to argument structure, including modifiers of NPs and VPs, argument types, argument alternations, imperatives, binding features, and question properties. These features help differentiate various syntactic structures in sentences. The curr_chunk discusses various syntactic constructions, including embedded, matrix, and relative clauses, islands, pied-piping, determiners, and violations in unacceptable sentences. These features mark different syntactic structures in sentences. The curr_chunk analyzes the correlation between minor and major features in syntactic constructions of unacceptable sentences using the Matthews Correlation Coefficient (MCC). Results show varying levels of correlation, with some pairs showing positive correlations and none showing significant anti-correlations. The analysis of correlations between minor and major features in syntactic constructions of unacceptable sentences using the Matthews Correlation Coefficient (MCC) revealed varying levels of correlation. Some pairs showed positive correlations, while none showed significant anti-correlations. Possible reasons for these correlations include overlapping feature definitions, grammatical properties of constructions, and the sources sampled in CoLA. The study by Chung et al. (1995) discusses ellipsis/anaphor in sluicing constructions involving embedded interrogatives. Strong anti-correlations were found between the SIMPLE feature and argument structure features in unacceptable sentences. MLP acceptability classifiers were trained on three sentence encoders for CoLA: CoLA baseline with ELMo-style embeddings, OpenAI GPT, and BERT. The CoLA baseline model utilizes a BiLSTM encoder for reading sentences word-by-word in both directions. The curr_chunk discusses the use of a BiLSTM for sentence encoding, trained on a real/fake discrimination task. Acceptability classifiers are trained on CoLA using the CoLA baselines codebase with 20 random restarts. Transformer encoders like GPT and BERT use a self-attention mechanism for sentence representation. The curr_chunk discusses training GPT and BERT sentence encoders on CoLA using the jiant toolkit. Performance is measured using MCC, and results show the best single restart, mean over restarts, and ensembling for each encoder. BERT outperforms GPT, which in turn outperforms the CoLA baseline in sentence classification. Ensemble performance did not surpass the best single model. Results for major and minor features are displayed in FIG1. MCC is measured for each feature, with error bars showing mean \u00b11 standard deviation. VIOLATIONS features have technically undefined MCC, but a single acceptable example is included for comparison. Within major features, performance is highest on SIMPLE sentences, surpassing overall model performance. However, some features show interactions where model performance deviates from the norm. Overall, features mark the presence of unusual characteristics affecting model performance. The performance of models on sentences with marked argument structures is high, indicating that argument structure is relatively easy to learn. Higher performance is observed on sentences with embedded clauses and VPs compared to sentences with embedded interrogatives. However, low performance is seen on sentences without complementizers in complement clauses. The difficulty of sentences with question-like syntax, involving extraction of a wh-word creating long-distance dependencies, poses a challenge for models. Low performance on morphological violations, especially in simple sentences, suggests deficiencies in encoding morphological features due to the models being word level without access to sub-word information. The models struggle with inflectional endings and small sample sizes, leading to unreliable results on certain features like CP SUBJ and IMPERATIVE. BERT excels in DEEP EMBED and long-distance dependencies, while transformer models show better performance than the CoLA baseline on BIND:REFL. The transformer models, including BERT, outperform the CoLA baseline in features like BIND:REFL and DISLOCATION due to their self-attention mechanism. Despite some idiosyncrasies in performance, all models struggle equally with sentences in VIOLATION. The transformer models, including BERT, outperform the CoLA baseline in features like BIND:REFL and DISLOCATION due to their self-attention mechanism. However, all models struggle equally with sentences in VIOLATION, indicating that the advantages of transformer models do not extend to detecting morphological violations or single word anomalies. Performance of BERT and GPT decreases steadily with sentence length, with BERT performing considerably better on the longest sentences. Using a new grammatically annotated analysis set, we identify predictive syntactic phenomena for sentence encoders on CoLA. Our findings suggest that BERT's success may be attributed to transformer models outperforming sequence models. Future work should focus on addressing morphological violations in sentence encoders, possibly by switching to a character-level model. Transformer models excel with long-distance dependencies but struggle with these constructions compared to more local phenomena. Training larger or deeper transformer models on longer or more complex sentences may help bridge this performance gap. Our findings suggest that future experiments can manipulate syntactic features to evaluate encoder performance. Controlled experiments are needed to confirm the causal relation between these features and model performance. Future work should focus on addressing morphological violations in sentence encoders. The text discusses the impact of syntactic features on sentence embeddings, including examples of included and excluded sentences. It also mentions the criteria for exclusion, such as sentences with predicative uses of the verb \"be\" and adjuncts modifying noun phrases. The importance of future experiments to evaluate encoder performance and address morphological violations in sentence encoders is highlighted. Adjuncts of VPs and NPs specify time, tense, aspect, or frequency of an event. They are optional and do not change the expression's category. Prepositional Phrase arguments of NPs or APs are marked by a preposition and are selected for by the head. They are generally not optional, but in some cases, they may be omitted. Prepositional arguments are introduced with \"by\" and are usually the subject of a passive verb. Arguments introduced with \"by\" are usually selected for by the head and are generally not optional. Expletives like \"it\" and \"there\" are semantically inert arguments. The passive voice involves demoting the subject. The passive voice demotes the subject, with the verb in past participle form. It may include an auxiliary be verb. Other cases involve non-reflexive pronouns with their antecedents, interrogative matrix clauses, and relative clauses with a relativizer. See references for more details."
}