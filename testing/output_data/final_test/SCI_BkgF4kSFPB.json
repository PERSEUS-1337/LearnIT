{
    "title": "BkgF4kSFPB",
    "content": "Visual planning (VP) involves an agent learning goal-directed behavior from observations of a dynamical system, such as images from self-supervised robot interaction. The semi-parametric topological memory (SPTM) method treats image samples as nodes in a graph, learned through deep image classification, to represent topological connectivity for planning. However, SPTM requires manual tuning of the connectivity classifier's loss function and struggles to generalize to domain changes due to its direct observation-based graph construction. In this paper, a new approach called Hallucinative Topological Memory (HTM) is proposed to address the limitations of the semi-parametric topological memory (SPTM) method in visual planning. HTM trains an energy function using contrastive predictive coding and a conditional VAE model to generate samples for building a connectivity graph, enabling zero-shot generalization to domain changes. In simulated domains, HTM outperforms SPTM and visual foresight methods in plan quality and long-horizon planning for robots operating in unstructured environments. The text discusses the challenges of using deep reinforcement learning for robotic manipulation in human-centric environments, focusing on the need for interpretability in the robot's decision-making process. The use of data-driven approaches, such as deep RL, has shown promise in handling high-dimensional sensory inputs and solving complex tasks, but the lack of interpretability remains a significant hurdle. Visualizing the robot's planned actions step by step before execution can help ensure safety and allow for human intervention if necessary. The visual planning paradigm aims to learn a model of the environment and generate a visual plan for robot actions. Studies have explored self-supervised interaction to learn what is possible in an environment and use visual servoing to follow the plan. The semi-parametric topological memory method treats images as nodes in a graph to represent system states and connects them with an image classifier. The semi-parametric topological memory (SPTM) method uses an image classifier to connect nodes in a graph representing system states. It generates visual plans by searching the graph, offering interpretable plans for long-horizon behavior. However, SPTM lacks zero-shot generalization and requires recollecting images in new environments. Training the graph connectivity classifier needs extensive manual tuning. The HTM method involves training a CVAE to generate images of objects and obstacles based on context, using a connectivity energy model to score image transitions, and planning paths on a connectivity graph for visual planning. This approach aims to automate visual servoing tasks without the need for manual tuning. In this work, the authors propose to enhance the robustness and generalization of SPTM by using a conditional generative model to hallucinate possible states of the domain based on a context vector. This allows for exploration data generation without actual exploration, improving planning robustness. The connectivity graph is built using these hallucinated images, and an energy-based model with a contrastive loss is used instead of a vanilla classifier, leading to significant improvements in planning performance. The authors propose Hallucinative Topological Memory (HTM) to improve planning robustness and quality by altering the connectivity graph construction and using an energy model with a contrastive loss. This approach leads to smoother plans with minimal hyperparameter tuning. The method is evaluated on simulated visual planning problems, focusing on both task success and interpretability. In simulated visual planning tasks, HTM outperforms visual foresight and SPTM in terms of interpretability and task success. The context-conditional visual planning problem involves deterministic environments described by context vectors, enabling prediction of object movements. Data is collected in a self-supervised manner, with observations and context information available for each environment. At test time, a planner and policy are used to generate a sequence of observations between start and goal points in a new environment. The planner must be capable of zero-shot generalization and the policy transitions the system between the start and goal points. This planning method allows for separate evaluation of the planner and policy performance. Semi-Parametric Topological Memory (SPTM) is a visual planning method that builds a memory-based planner and an inverse-model controller. A classifier is trained to map observation images to a feasibility score, and the policy is trained to map observation pairs to appropriate actions. In unseen environments, new observations are organized in a graph based on their feasibility scores. SPTM uses a graph to connect observations based on their feasibility scores. Dijkstra's algorithm is used to find a path, with waypoints selected to represent feasible observations. The CVAE model is utilized for learning conditional distributions. The CVAE model is trained using the evidence lower bound (ELBO) to maximize the variational lower bound. It assumes Gaussian prior and encoder, allowing for closed-form computation of the D KL term. Monte-Carlo sampling and the reparametrization trick are used for gradient approximation. Contrastive Predictive Coding (CPC) extracts compact representations from sequential data, maximizing causal and predictive aspects. A non-linear encoder encodes observations to latent representations, maximizing mutual information between the latent representation and future. The Contrastive Predictive Coding (CPC) model maximizes mutual information between latent representation and future observations. It uses the CPC loss function to classify positive samples from random samples. While effective for long-horizon planning, SPTM requires substantial exploration data for any changes in the training environment, posing limitations in robotic domains. The proposed Hallucinative Topological Memory (HTM) approach aims to address challenges in training the connectivity classifier by using a CVAE for zero-shot sample generation, contrastive loss for a robust score function, and approximate maximum likelihood formulation for planning. This method enables automatic building of a planning graph using only a context vector of the new environment, leveraging past training data for effective hallucination. The Hallucinative Topological Memory (HTM) approach utilizes a CVAE to generate samples for building a planning graph in a new environment. A Gaussian distribution is learned during training to sample latent vectors for image generation. A connectivity classifier is crucial in determining feasible image transitions to avoid errors in the planning process. The classifier in [22] was trained discriminatively using positive and negative examples based on the number of steps taken. However, this method faces issues with sensitivity to labeling choices, the need for long trajectories for accurate negative sampling, and inconsistent estimates due to random walk-like data. The classifier's predictions may also be unreliable for medium-distance images. To address issues with unreliable predictions for medium-distance images, a connectivity score is proposed using contrastive predictive loss. This method aims to distinguish between positive and negative pairs to determine temporal distance between observations, improving planning accuracy. The proposed method improves planning accuracy by using a connectivity score based on contrastive predictive loss to determine temporal distance between observations. This approach involves sampling negative data from the latent space of a trained CVAE or the replay buffer, leading to smoother distance manifold in the representation space. Additionally, a learned connectivity graph is utilized for efficient visual planning using conventional graph planning methods. The proposed method utilizes a connectivity score based on contrastive predictive loss to improve planning accuracy. It involves training an inverse model for action prediction and utilizing Dijkstra's algorithm for shortest path planning. By casting the planning problem as an inference problem, the method results in an effective planning algorithm. The proposed method uses a connectivity score based on contrastive predictive loss to enhance planning accuracy. It involves training an inverse model for action prediction and utilizing Dijkstra's algorithm for shortest path planning, resulting in a more stable planning approach and feasible plans. Model-based approaches in Reinforcement Learning have been explored to address limitations of model-free RL frameworks. Our method focuses on predicting individual images instead of full trajectories, reducing errors. It can utilize visual MPC as an alternative to visual servoing policy. Unlike other approaches, we use a CVAE-based method for visual planning, which is more stable than GAN-based methods. In classical planning, task and motion planning separates high-level planning from low-level control, requiring domain knowledge for specification. Our approach for visual planning only requires data from self-supervised interaction, unlike other studies that require domain knowledge. While some works bridge classical planning and representation learning, they do not consider zero-shot generalization. Recent work in visual planning focuses on real robotic tasks with visual input, but results can be difficult to reproduce or compare. The text discusses the proposal of simulated tasks with varying difficulty levels for manipulating objects using the PR2 robot. The tasks involve moving a rigid object between obstacles to control planning difficulty, with two domains created: Block wall and Block wall with complex obstacle. The goal is to assess the difficulty of these tasks. The evaluation metrics for assessing the success of Hierarchical Task Model (HTM) compared to state-of-the-art Visual Planning (VP) methods are discussed. The evaluation includes comparing visual plan quality, execution success rate, and generalization to unseen contexts. Baseline comparisons are made with SPTM and Visual Foresight methods. Visual Foresight utilizes a video prediction model for model predictive control (MPC) in planning. The MPC uses a state-of-the-art video predictor and evaluates trajectories with pixel MSE loss and green pixel distance cost functions. The function uses prior knowledge to estimate the position of the moving green block by calculating the center of mass of green pixels. It provides a smooth cost function for estimating the distance between predicted block positions and the goal image. Qualitative metrics are important for planning interpretability, ensuring visually sensible plans that can be approved by humans before execution. In order to evaluate the quality of generated plans, tests were conducted based on human visual perception. Participants scored plans on fidelity, feasibility, and completeness. Mean opinion scores were calculated for each model. Additionally, success in navigating towards a predefined goal was measured using unseen obstacle configurations. The study evaluated the performance of different models in navigating towards predefined goal images with unseen obstacle configurations. HTM outperformed all baselines in both qualitative and quantitative measurements across all domains. Visual Foresight with green pixel distance only succeeded in the block wall domain with additional state information, but failed in the complex obstacle domain compared to HTM. The comparison with SPTM using the same inverse model and CVAE was also conducted. Visual Foresight generates realistic transitions but is limited in creating a visual plan within 15 timesteps. When faced with challenging tasks requiring more timesteps, it fails to construct a reliable plan, lacking completeness. In comparison, SPTM can imagine trajectories to reach the goal state but struggles to select feasible transitions, as confirmed by perceptual scores. Our approach outperforms SPTM in fidelity, feasibility, and completeness. Results show that using contrastive loss and the inverse of the score function for edge weighting are more successful. Qualitative and quantitative evaluation for block wall domains are presented in Table 1, with HTM (1) and (2) denoting different edge weighting methods. Our proposed method, utilizing density ratio and contrastive loss for energy modeling and classification, improves visual planning quality and execution success rate. By combining classical planning with data-driven perception, we bridge the gap between learning and planning. Future work includes integrating HTM with Visual MPC for handling more complex objects. In future work, the plan is to combine HTM with Visual MPC for handling complex objects and use object-oriented planning for multiple objects. Improving planning by hallucinating samples conditioned on start and goal configurations can help reduce the search space. The method involves training a classifier to distinguish positive from negative transitions, which is used to localize the current image and find possible next images for planning. The binary cross entropy loss of the classifier can be written as follows: , where z \u2212 t is a random sample from D. Another form of discriminating positive transitions from negative transitions is through an energy model. Oord et al. learn embeddings of current states predictive of future states. Loss function described as cross entropy loss of predicting correct sample from N + 1 samples containing 1 positive sample and N negative samples. Object can be translated and rotated slightly per timestep in this domain. Data collected from 360 different object shapes with 3 to 7 building blocks. The goal is to plan a manipulation of an unseen object through the narrow gap between obstacles in zero-shot. 360 different object shapes with different number of building blocks between 3 to 7 are randomly initialized 50 times each episode with a length of 30."
}