{
    "title": "HkeGhoA5FX",
    "content": "In this paper, a residual non-local attention network is proposed for high-quality image restoration. The network addresses the issue of uneven information distribution in corrupted images by using local and non-local attention blocks to capture long-range dependencies between pixels. Trunk and (non-)local mask branches are designed in each attention block to extract hierarchical features and adaptively rescale them with mixed attentions. The local mask branch focuses on local structures, while the non-local attention considers long-range dependencies in the entire feature map. Our proposed method utilizes residual local and non-local attention learning to enhance the representation ability of deep networks for image restoration tasks such as denoising, demosaicing, and compression artifacts reduction. Experiments show that our method achieves comparable or superior results compared to leading methods both quantitatively and visually. Image restoration is crucial for recovering high-quality images from low-quality observations and plays a key role in various vision tasks. Deep convolutional neural networks have shown remarkable ability in addressing various vision problems, including image denoising, compression artifacts reduction, and image super-resolution. However, existing CNN-based methods face issues with small receptive field sizes, limiting their ability to capture long-range dependencies in images. A larger receptive field size is crucial for better utilization of training inputs and improved performance in image restoration tasks. The larger receptive field size in deep convolutional neural networks allows for better utilization of training inputs and more context information, especially beneficial for capturing the latent degradation model of low-quality images. Additionally, current networks lack the ability to focus on specific areas of an image, resulting in over-smoothed outputs and loss of textural details. Furthermore, the equal treatment of all channel-wise features limits flexibility in handling different types of information. The proposed very deep residual non-local attention networks (RNAN) address limitations in current image restoration methods by incorporating residual local and non-local attention blocks. These blocks consist of trunk and mask branches for extracting hierarchical features and enlarging receptive field size. The inclusion of non-local blocks in the mask branch allows for residual non-local mixed attention, improving the accuracy of high-quality image restoration. The proposed RNAN utilizes residual non-local mixed attention for image restoration tasks such as denoising, demosaicing, and compression artifacts reduction. Extensive experiments demonstrate that RNAN outperforms other methods, marking the first instance of using residual non-local attention for image restoration. The network's main contributions include very deep networks based on residual local and non-local attention blocks, incorporating non-local blocks in the mask branch for improved learning of local and non-local information from hierarchical features. The proposed RNAN utilizes residual non-local mixed attention for image restoration tasks, achieving superior results over leading methods for denoising, demosaicing, compression artifacts reduction, and super-resolution. The network's main contributions include very deep networks based on residual local and non-local attention blocks, incorporating non-local blocks in the mask branch for improved learning of hierarchical features. In this paper, the focus is on learning nonlocal attention to guide feature extraction in the trunk branch of deep neural networks. Attention mechanisms are used to bias the allocation of processing resources towards informative components of an input, often combined with a gating function like sigmoid. Previous works have incorporated non-local information in trunk pipelines for tasks like image denoising and restoration, while this paper emphasizes the use of non-local attention for better feature guidance. In image restoration tasks, attention mechanisms like residual attention networks and squeeze-and-excitation blocks have been used to guide networks to focus on specific regions of interest. However, there is a lack of research on the impact of attention in image restoration. Different architectures like Stacked denoising auto-encoder and AR-CNN have been proposed for image restoration with techniques like residual learning and batch normalization. Zhang et al. introduced DnCNN for accurate image restoration and denoiser priors. Recently, significant progress has been made in the image restoration community with various methods proposed by different researchers. Wang et al. introduced a progressive image super-resolution approach, but most methods lack the use of non-local information. A new residual non-local attention network (RNAN) is proposed for image restoration tasks, focusing on image denoising. The framework of RNAN includes convolutional layers, residual non-local attention blocks, and residual local attention blocks. The proposed residual non-local attention network (RNAN) focuses on image denoising by using global residual learning in pixel space. It includes residual local and non-local attention blocks to extract hierarchical attention-aware features, concentrating on learning degradation components like noise, blur, and compression artifacts. The network incorporates non-local attention blocks in low-level and high-level feature spaces to address more challenging areas effectively. The RNAN is optimized with loss functions like L2, L1, perceptual, and adversarial losses. The goal is to minimize the L2 loss function using a training set with low-quality inputs and high-quality counterparts. The network includes residual local and non-local attention blocks for image restoration. The residual non-local attention network (RNAN) consists of residual local and non-local attention blocks for image restoration. Each attention block includes trunk and mask branches, with a total of q residual blocks (RBs). The trunk branch contains t RBs, and the mask branch incorporates a non-local block (NLB) for non-local attention. The simplified residual block (RB) used in the residual non-local attention network (RNAN) consists of two convolutional layers and one ReLU, omitting unnecessary components like maxpooling and batch normalization layers. This simplified RB contributes to image super-resolution and enables the construction of very deep networks for various image restoration tasks. The network includes trunk branches with hierarchical features and mask branches for channel and spatial attention. The mask branches, including local and non-local ones, help adaptively rescale hierarchical features. The local mask branch in the residual non-local attention network focuses on grasping information of larger scope by using large-stride convolution and deconvolution to enlarge the receptive field size. This approach aims to achieve more pixel-level accurate results in image restoration, avoiding the loss of details that occurs with maxpooling. Additionally, considering non-local information across the entire input is another strategy discussed for increasing the receptive field size. The local mask branch in the residual non-local attention network utilizes deconvolution to increase receptive field size. A non-local block is incorporated to achieve non-local mixed attention, considering all positions simultaneously for better attention maps. Incorporating non-local block into the mask branch of networks BID35 to obtain non-local mixed attention. Non-local operation defined with pairwise function f(x_i, x_j) and function g(x_j). Embedded Gaussian function used to evaluate pairwise relationship. Output of non-local block calculated using weight matrix W_z. Different versions of f considered, such as Gaussian function and dot product similarity. Linear embedding used for g(x_j) = W_g x_j. The non-local block is incorporated into the mask branch of networks BID35 to achieve non-local mixed attention. The output is calculated using a weight matrix W_z, and a residual non-local attention learning approach is proposed to enhance the network's depth and training efficiency for image restoration. Incorporating non-local mixed attention in deep image restoration networks is a challenge. A new residual attention learning method is proposed to focus on obtaining non-local attention information from input features, emphasizing the importance of low-level features for image restoration tasks. This method introduces input features directly to improve the network's performance. The implementation details of the proposed RNAN include the use of 10 residual local and non-local attention blocks, with specific settings for each block. The model is trained using ADAM optimizer with specific parameters, and 16 low-quality patches are extracted as inputs in each training batch. The RNAN model is trained using ADAM optimizer with specific parameters and implemented using PyTorch with a Titan Xp GPU. It is applied to image restoration tasks like denoising, demosaicing, and compression artifacts reduction. Different settings are used for each task, and results are evaluated using PSNR and/or SSIM. Non-local mixed attention is enabled in some cases. The positive effect of non-local mixed attention and mask branch on performance improvement is demonstrated in image restoration tasks. Non-local blocks contribute to the network's ability by providing informative attention, leading to better representational ability. More non-local blocks result in better performance, but consume more time. Using 2 non-local blocks balances performance and computational efficiency in the RNAN model. Our proposed RNAN model utilizes 2 non-local blocks to incorporate low-and high-level features, improving performance in image denoising tasks. Comparison with state-of-the-art methods shows RNAN achieves the best results across various datasets and noise levels. The non-local attention mechanism covers information from the entire image, proving effective for heavy denoising tasks. Our proposed RNAN model, with a noise level of \u03c3 = 70, achieves significant PSNR gains over the second best method FFDNet, showcasing the effectiveness of our non-local mixed attention. Visual results demonstrate how RNAN treats different image parts distinctively, reducing over-smoothing artifacts. When compared with IRCNN on various datasets, RNAN shows notable improvements in image demosaicing quality despite the initial poor quality of mosaiced images. Our RNAN model achieves high PSNR and SSIM values, surpassing IRCNN with improvements in handling degradation. Visual results show RNAN's ability to recover faithful colors and reduce blocking artifacts. Comparison with other methods like SA-DCT, ARCNN, TNRD, and DnCNN is done using JPEG compression at different quality settings. Focus is on restoring the Y channel for fair comparison. The datasets LIVE1 and Classic5 are used for evaluation. Our RNAN model outperforms ARCNN, TNRD, and DnCNN in removing blocking artifacts and preserving image details. Visual comparisons show RNAN's superior performance under low image quality. Additionally, RNAN+ with self-ensemble strategy achieves the second best performance among benchmark datasets. Our RNAN model achieves third best results in various datasets, with notable improvements despite having a smaller parameter number compared to EDSR and RCAN. The network depth of RNAN is also shallower, indicating better utilization of the main network. Visual comparisons demonstrate RNAN's effectiveness in image super-resolution, especially with non-local mixed attention. Performance metrics in color image denoising further support RNAN's superiority. In TAB6, RNAN achieves the best performance with 10 blocks, which can be reduced to 2 blocks for the second best performance. Running time is reported for reference. Results are based on DIV2K training data. RNAN is retrained on small training sets for 5 tasks in TAB7, using different datasets for each task. FFDNet utilizes various datasets for image denoising and compression artifacts reduction. In TAB7, 'BSD400+' represents 'BSD400+ImageNet400+WED4744'. RNAN achieves better results for 5 tasks with the same or smaller training set. The effectiveness of RNAN for general image restoration tasks is demonstrated through experiments. Color and gray image denoising comparisons show that RNAN recovers sharper edges and maintains more details by treating different image parts distinctively with non-local mixed attention."
}