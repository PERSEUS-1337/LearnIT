{
    "title": "ryx4PJrtvS",
    "content": "Bayesian optimization is commonly used to tune hyperparameters of black-box functions. This work introduces a novel approach for transfer learning across datasets and metrics by regressing the mapping from hyperparameters to metric quantiles with a Gaussian Copula distribution. Two methods are proposed to leverage this estimation: Thompson sampling and a Gaussian Copula process. These strategies can combine the estimation of multiple metrics like runtime and accuracy to guide optimization. Automatic hyperparameter optimization techniques like Bayesian optimization are crucial for tuning complex machine learning models such as deep neural networks. This work introduces a novel approach for transfer learning across datasets and metrics by regressing the mapping from hyperparameters to metric quantiles with a Gaussian Copula distribution. Experiments show significant improvements in optimizing hyperparameters for the same level of accuracy. Recent advancements in hyperparameter optimization (HPO) involve transfer learning to expedite the process by leveraging evaluations from related tasks. A challenge in HPO transfer learning is the varying scales and noise levels across tasks. This study introduces a semi-parametric Gaussian Copula to address scale issues and facilitate information transfer between tasks. Two HPO strategies, Copula Thompson Sampling and Gaussian Copula Process, are proposed to jointly model multiple objectives. The study introduces a Gaussian Copula Process to address scale issues in hyperparameter optimization transfer learning. Two HPO strategies, Copula Thompson Sampling and GP-based approach, are proposed to jointly model multiple objectives. Experimental results show significant speed-ups over baselines. Transfer learning in hyperparameter optimization (HPO) can be induced by modeling tasks jointly or with a conditional independence structure. This can be achieved through various methods such as multi-output GPs, weighted combinations of GPs, and neural networks. Another approach involves updating models online as new tasks come in, fitting surrogate models to residuals relative to previous predictions. This allows for transfer of knowledge without fitting a surrogate model to all past data. Some methods for transfer learning in hyperparameter optimization involve warm-starting Bayesian optimization with solutions from previous problems, addressing challenges of heterogeneous scale and noise levels among different black-boxes. Techniques focus on pruning the search space to regions likely to contain good configurations, such as learning a promising search space using related tasks or restricting the search space to a low-volume hyper-rectangle or hyper-ellipsoid. Rank estimation can help alleviate scale issues in hyperparameter optimization, but feeding back rank information to Gaussian Processes (GPs) can be challenging. Gaussian Copula Process (GCP) can also address scale issues by estimating the Cumulative Distribution Function (CDF) of the data. GCP was proposed for handling non-Gaussian data in HPO, with a focus on non-parametric homoskedastic priors for single-task and single objective cases. In hyperparameter optimization, minimizing the number of evaluations for a new task is crucial. One approach is to use a parametric estimate of the task distribution, fitting it to observed tasks. This can be achieved with a semi-parametric Gaussian Copula by mapping evaluations to quantiles and fitting a parametric Gaussian model. In hyperparameter optimization, minimizing evaluations for a new task is crucial. Evaluations are mapped to quantiles and fitted with a parametric Gaussian distribution using a Gaussian Copula model. The CDF of the mapped quantiles is modeled with a Gaussian Copula, and the marginal distribution is regressed with a Gaussian distribution. Parameters are determined by a multi-layer perceptron (MLP) output and an activation mapping function. The parameters in MLP are learned by minimizing the Gaussian negative log-likelihood on available evaluations with SGD. Errors in quantile function changes have larger gradients. Evaluations of each task can be weighted equally or normalized per number of task evaluations. The transformation \u03c8 requires estimation using empirical CDFF. The Winsorized cut-off estimator addresses issues with infinite values when evaluating \u03c8 at the minimum or maximum of y. It strikes a bias-variance trade-off by choosing a suitable \u03b4 value. This approach combines non-parametric estimation of the CDF with parametric estimation of the Gaussian Copula, allowing for joint learning of parametric estimates across tasks. The experiments demonstrate the effectiveness of leveraging information from related tasks to improve prediction accuracy. The text discusses a novel HPO strategy using Copula Thompson Sampling to leverage predictive distribution for hyperparameter configurations. It highlights the importance of re-using information from previous tasks but also mentions the challenge of independent draws not exploiting current task evaluations. Gaussian Copula regression can be combined with a GP to learn from previous tasks while adapting to the current task. Observations are modeled as a Gaussian Copula Process, allowing for a non-parametric warping of a GP. This transformation ensures that the transformed variable follows a normal distribution, which is advantageous in cases where a Gaussian distribution cannot be used, such as in HPO tasks. The information gained from other tasks can be incorporated as prior mean and variance parameters. By using prior mean and variance parameters from previous tasks, a Gaussian Copula Process can model the residual with a Mat\u00e9rn-5/2 covariance kernel. The GP's predictive distribution of the surrogate can be used to optimize hyperparameters for maximizing Expected Improvement (EI) of the function g(x). When no observations are available, the optimization is warm-started with a set of N0 = 5 samples. To warm-start optimization on a new task, a set of N0 = 5 hyperparameter configurations is sampled via Thompson sampling. The parameters \u03b8 of \u00b5 \u03b8 (x) and \u03c3 \u03b8 (x) are learned on hold-out evaluations D M by minimizing equation 1. The GP surrogate is fitted to observations, and N candidate hyperparameters are sampled from the search space. The hyperparameter x i is computed where i = arg max i EI. In addition to optimizing accuracy, it is desirable to optimize runtime or memory consumption. Runtime and error objectives are averaged in the transformed space. In the transformed space, error and time observations are optimized seamlessly during HPO. Existing multi-objective methods can potentially be combined with Copula transformation. Three algorithms were tuned on multiple datasets: XGBoost, FCNET, and DeepAR. XGBoost was tuned on 9 libsvm datasets to minimize 1\u2212AUC, FCNET on 4 datasets to minimize test mean squared error, and DeepAR for time series prediction. For HPO, datasets from Klein & Hutter (2019) were used to minimize test mean squared error with DeepAR. Evaluations on GluonTS data included datasets from M4-competition and Lai et al. (2017) to minimize quantile loss. Runtime for evaluating hyperparameter configurations was available for DeepAR and FCNET. Comparison was made against baselines like random search and GP-based BO. Transfer learning baseline included warm-start GP. Lookup tables were used as advocated in Eggensperger et al. (2012). In transfer learning for hyperparameter optimization (HPO), warm-start GP methods like WS GP best and WS GP all are compared with ABLR and a search space-based method by Perrone et al. (2019). ABLR uses a shared neural network with Bayesian linear regression per task, while Perrone et al. (2019) fits a bounding box to previous task hyperparameters and applies random search or GP-based BO. Transfer learning capabilities of these methods are assessed. In transfer learning for hyperparameter optimization, various methods like WS GP best, WS GP all, ABLR, and a search space-based method are compared. The transfer learning capabilities of these methods are evaluated by leaving out one dataset at a time and aggregating the results for each algorithm. The performance of each method is averaged over replicates, and relative improvements over random search are computed. Copula-based methods involve learning the mapping to copulas using a 3-layer MLP with 50 units per layer. A detailed ablation study is conducted to investigate the choice of the MLP and compare the copula. In a detailed ablation study, the choice of MLP for copula estimation is compared to other options like linear models and k-nearest neighbor estimators. Results show that MLP performs best in predicting errors of blackbox tasks, indicating potential for transfer learning methods. FCNET demonstrates the lowest RMSE among the algorithms, supporting the effectiveness of transfer learning methods. The proposed Copula estimator (MLP) uses heteroskedastic noise for the prior, showing improvements over homoskedastic versions. Heteroskedasticity tends to help on most datasets, with a two-step transformation process involving Copula and standardization. Results in Table 2 demonstrate the effectiveness of this approach compared to simple standardization. Results in Table 2 show that standardization performs worse than the Copula transformation in addressing varying scale and noise levels across tasks. The relative improvement objective is not lower bounded, leading to arbitrary large scale of relative improvement. Comparisons with other HPO baselines are made using error information and both time and error information. Results in Table 3 indicate that CGP is the top-performing method for most tasks except XGBoost, where methods without transfer learning excel. An ablation study on copula estimators in XGBoost reveals that some tasks have high test errors, making transferred priors ineffective. CGP typically ranks second after standard GP in these cases. Additional results at iterations 10, 50, and 100 are presented in Tables 7, 8, and 9, showing CGP and Box RS as the most effective methods. At iterations 10 and 100, CGP is the best transfer learning method, showing adaptability to the target task. Results from example datasets in Figure 1 indicate high variations in performance, with CTS and CGP outperforming baselines, especially at the beginning of the BO process. Box RS is competitive initially but falls short later on. Results from copula-based approaches show a clear advantage over baselines, especially at the beginning of the optimization process. The ability to leverage training time information gives copula-based methods an edge, as seen in tasks with DeepAR and FCNET. The copula-based methods outperform baselines, particularly at the start of optimization. They utilize a semi-parametric Gaussian Copula prior to accelerate hyperparameter optimization by leveraging evaluations from previous tasks. The approach leverages a semi-parametric Gaussian Copula prior to improve hyperparameter optimization and outperform standard methods. It can handle heterogeneous tasks robustly and combine multiple objectives efficiently. Future work includes combining Copula-based strategies with Hyperband-style optimizers and generalizing the approach for different hyperparameter dimensions across tasks. In this work, the authors propose a method for hyperparameter optimization using a semi-parametric Gaussian Copula prior. They aim to minimize equation 1 by learning the parameters \u03b8 of \u00b5 \u03b8 (x) and \u03c3 \u03b8 (x) on hold-out evaluations D M. To speed up experiments, they use a lookup table approach to limit the number of blackbox evaluations. This approach focuses on selecting the next hyperparameter configurations from a fixed set that has been evaluated in advance to avoid extrapolation errors. The authors propose a method for hyperparameter optimization using a semi-parametric Gaussian Copula prior to minimize equation 1. Evaluations were obtained by querying each algorithm at hyperparameters sampled uniformly at random. Results show that transfer learning methods, especially CGP and Box RS, outperformed GP at the 10th iteration. However, at 50 and 100 iterations, CGP clearly outperformed all other transfer methods due to its improved adaptivity. The MLP used for regression consists of 3 layers with 50 nodes each, with a dropout layer set to 0.5 and a learning rate of 0.01. The authors conducted over 100 gradient updates 3 times, decreasing the learning rate by 10 each time. Table 9 shows the relative improvements over random search at iteration 100."
}