{
    "title": "B17JTOe0-",
    "content": "Decades of research on spatial navigation neural coding have uncovered diverse response properties in the Entorhinal Cortex (EC). Grid cells, border cells, and band-like cells encode space using different patterns. Recurrent neural networks (RNNs) trained for navigation tasks exhibit grid-like spatial response patterns, similar to experimental observations. The emergence order of grid-like and border cells aligns with developmental studies, suggesting a new way to understand neural representations. Our results suggest that grid cells, border cells, and others in the Entorhinal Cortex may efficiently represent space due to recurrent connections in neural circuits. The neural code in the brain is studied using feed-forward architectures like convolutional neural networks, inspired by deep learning. For tasks like spatial navigation, the brain maintains internal representations of relevant variables beyond feature extraction. This includes updating self-location based on movements and landmarks in the environment. Physiological studies in rodents and mammals have identified neural correlates of space in the Hippocampus and Entorhinal Cortex, including place cells, grid cells, border cells, and others. Grid cells fire only when the animal is in specific physical locations forming a lattice. Recurrent neural networks are useful for solving spatial navigation tasks by creating continuous attractor networks. Grid cells and place cells are important neural responses in the Entorhinal Cortex. Existing models focus on grid cells and rely on specific connectivity patterns. However, a unified model that can explain different types of neural responses in the EC is needed. Here, a new modeling approach using a RNN was presented to understand spatial representation in the neural system, specifically in the Entorhinal Cortex. By training the RNN with biologically relevant constraints, grid-like responses similar to those observed in EC were naturally generated. This study suggests that RNNs can be a valuable tool for studying high-level cognitive functions and neural mechanisms related to spatial navigation. The neural mechanisms of high-level cognitive functions were studied using a RNN model in the Entorhinal Cortex. Different types of cells were recorded during animal navigation, including band-like, border, irregular spatially tuned, speed, and heading direction cells. The RNN consisted of 100 recurrently connected units receiving inputs for speed and heading direction, with outputs representing the animal's physical location. Training aimed to accurately map the responses of the output neurons to the animal's location. The RNN model in the Entorhinal Cortex consists of 100 recurrently connected units representing the animal's physical location during navigation. Each unit's activity is governed by a continuous-time RNN equation with inputs from other units and external input. The network includes biases and noise intrinsic to the network. The RNN model in the Entorhinal Cortex consists of 100 recurrently connected units representing the animal's physical location during navigation. The network simulates Gaussian activity with zero mean and constant variance using the Euler method for 500 timesteps. A 2D navigation task is performed by linearly combining firing rates to estimate the animal's location. Inputs are the animal's speed and direction at each time step, inspired by spatial navigation tasks in 2D open environments. The paper discusses the modeling of animal movement in an open environment using modified Brownian motion. The model focuses on the animal's direction and position, with special consideration near boundaries. Future work could involve testing the model with real animal movement trajectories to observe potential changes in results. The model was adjusted to prevent the animal from crossing boundaries by resampling the input angle. Network parameters were optimized to minimize error in a navigation task in various arena shapes. Parameters were updated using the Hessian-free algorithm with minibatches. Regularization was applied to input and output weights, as well as the firing rates of units for metabolic cost. The training process aims to minimize a loss function that includes the error of the animal, metabolic cost, and penalty for large network parameters. Results are insensitive to initialization schemes for the weight matrix. Simulations were conducted in different environments with specific initialization methods for the weight matrix and bias. The trained RNN in different boundary shapes accurately tracks the animal's path. Neurons in the RNN show interesting spatial response profiles that can be classified into distinct functional types. The spatial responses of neurons in the trained RNN exhibit distinct grid-like patterns, with firing fields arranged in a structured lattice depending on the shape of the boundary. The firing patterns show circular or elliptical shapes and are more rectangular in square environments, and more triangular in hexagonal or triangular environments. The medial entorhinal cortex (EC) contains grid cells with multiple firing fields arranged in a grid-like pattern. The simulation shows grid-like responses similar to rodents, but with fewer periods. Grids are influenced by the environment shape, with grids often on the corners of a triangular lattice even in square environments. The rats in experiments had spatial experience in various environments with different boundary shapes. It would be interesting to see if grid cells would lie on a square lattice if rats are raised in a single square environment. Many neurons exhibit selectivity to the boundary, encoding only a portion of it. Border cells mainly fire along one piece of wall, but some fire along multiple borders or the whole boundary. It is unclear how these boundary-like response profiles emerge. The model suggests that border cells may form without tactile cues, possibly related to animal movement statistics. Some neurons exhibit band-like responses, parallel to boundaries, similar to rodent EC firing patterns. However, the band pattern in the model is clearer than reported data. Based on the model, border cells may form without tactile cues, possibly related to animal movement statistics. Most units exhibit stable spatial responses with irregular firing fields. Non-grid spatial cells are prevalent in rodent EC Layer II and III. Model border cells show almost zero speed-tuning. A substantial portion of model neurons exhibit direction tuning with diverse profiles. In the model, neurons exhibit diverse direction tuning profiles, with some showing strong head direction tuning but no clear spatial firing pattern. Neurons with grid-like firing can have varying direction tuning strengths. The relationship between these tuning properties at the population level is complex. Experimental evidence shows head direction tuning in the entorhinal cortex, with both grid and non-grid cells exhibiting this tuning. In the entorhinal cortex, neurons exhibit head direction tuning, with grid and non-grid cells showing this characteristic. The linear speed dependence of model neurons is similar to speed cells in EC. Neurons in EC also exhibit speed tuning. The evolution of spatial response profiles during learning shows that boundary-selective neurons emerge first, followed by grid-like responses with finer spatial tuning patterns. Dimensionality reduction using the t-SNE algorithm is used for visualization during different training phases. During training, model neurons are embedded in a 2D space based on firing rate correlation. Border cell representations emerge early and persist, while grid-like cells undergo changes before settling into their final pattern. Border cells develop earlier than grid cells, with border cells appearing at 2 weeks and grid cells maturing at 4 weeks after birth. Our simulations suggest that border cells emerge earlier in development due to the ease of wiring up a network for their responses. Grid cells initially have tuning profiles similar to border cells but change substantially during learning. Regularizations of the RNN are crucial for the emergence of grid-like representations. Regularizations of the RNN are crucial for the emergence of grid-like representations, as shown in simulations with noise perturbations and metabolic cost penalization. Proper regularization is necessary for grid-like representations to develop, as demonstrated in simulation results with and without metabolic regularization. The importance of injecting noise into RNN units for learning useful representations in neural networks is highlighted. It is suggested that incorporating constraints like noise and metabolic cost may be necessary to model response properties similar to neural systems. The trained RNNs are tested for localization beyond the typical training path length, with error-correction occurring at the boundary by resampling direction to avoid path extension. The boundary interaction serves as the only cue for the RNN about the boundary. The RNN uses boundary interactions to correct errors in prediction based on integrated input. Error decreases with more interactions, stabilizing over a large duration. The network gradually increases error without further interactions. The RNNs use boundary interactions for error correction during training, leading to stable performance even with longer paths. Boundary-related firing helps in error correction by exploiting input statistics around the boundary. The model proposed in this paper develops grid-like responses, boundary responses, and error-correction mechanisms within the same neural network for path integration in 2D arenas. Training RNNs with appropriate regularization results in neurons exhibiting spatial and velocity tuning profiles similar to neurophysiology in EC. The neural population in the entorhinal cortex (EC) may provide an efficient code for representing self-locations based on velocity input, supported by similarities with neurophysiology. There is interest in using recurrent neural networks (RNNs) to understand the neural code, as they can take advantage of the brain's abundant recurrent connections. The finding that metabolic constraints lead to the emergence of grid-like responses in neuroscience questions the efficient coding hypothesis in visual processing. This work is inspired by sparse coding models, but there are differences in interpretation and sparsity constraints between the two approaches. The grid-like patterns in the network are not filters based on raw input but require integration of velocity inputs to encode spatial locations. The study is inspired by efficient coding in explaining grid cell architecture and relates to regularization of RNN models for generating neural activity similar to motor cortex. In contrast to previous studies using place cells as input for generating grid cells, our model takes the animal's velocity as input to address how spatial tuning can be generated. This approach differs from models that rely on dimensionality reduction and raises questions about how place cells acquire spatial tuning. The authors trained a RNN with LSTM units to perform navigation tasks, but did not report grid-like spatial firing patterns. Their model shows a qualitative match to neural responses in the EC but has limitations. They aim to explore biologically plausible learning rules and incorporate a hierarchy of spatial scales in grid-like cells. The authors are investigating modifications to the RNN model to incorporate a hierarchy of spatial scales. They are also examining the connectivity patterns of the trained network and how it supports the generation of representations. Future work will focus on understanding the underlying mechanisms and quantifying the speed selectivity of each unit. The speed, direction, and spatial selectivity of unit activity were quantified in the study. Speed selectivity is determined by the slope of the tuning curve, direction selectivity by the difference between maximum and minimum activity, and spatial selectivity using lifetime sparseness. Each dot in the figures represents the selectivity of a single unit."
}