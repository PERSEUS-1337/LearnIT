{
    "title": "Bkxv90EKPB",
    "content": "Meta learning has been advancing for fast model adaptation, but there is limited work on fast uncertainty adaption for Bayesian modeling. This paper introduces a Bayesian meta sampling framework using a neural-inverse-autoregressive-flow structure for generating meta samples and a sample adapter for task-specific samples. The combination of these components simplifies the learning process. A meta sampler will be developed for efficient optimization through standard back-propagation, showing improved sample quality and faster results in extensive experiments. Meta learning is a key topic in modern machine learning, aiming to learn abstract concepts from related tasks for adaptation to new tasks. Different methods like learning-to-learn and Model Agnostic Meta Learning (MAML) have been developed for this purpose. These methods involve learning a meta optimizer or meta parameter/model from training tasks to quickly adapt to new models. Recent research in meta-learning has led to the development of various models such as the meta network, meta learner, Reptile model, and extensions for hierarchical relations and sequential strategies. These models are designed from an optimization perspective. In addition to optimization, Bayesian modeling has also gained attention in deep learning, with recent research extending meta-learning methods to a Bayesian setting, such as Bayesian MAML (BMAML) using Stein variational gradient descent for posterior sampling. Probabilistic MAML (PMAML) and Amortized Bayesian Meta Learning extend MAML by incorporating parameter distributions and amortized variational inference. VERSA uses an amortization network for posterior predictive distributions, while Meta particle flow implements Bayes's rule with ODE neural operators. These methods lack uncertainty propagation/adaption, potentially affecting model adaption and uncertainty modeling accuracy. The proposed framework, Bayesian meta sampling, aims to efficiently leverage uncertainty in samples to generate samples from complex distributions. By performing meta learning on the space of probability measures, the framework adapts a meta distribution to new tasks instead of adapting parameters. This approach, which utilizes meta samples, allows for well-encoded uncertainty in distribution adaptation algorithms. The Bayesian meta sampling framework utilizes Wasserstein gradient flows to learn a meta sampler for fast adaptation to new tasks. It consists of a meta sampler parameterized by a neural inverse-autoregressive flow (NIAF) and a sample adapter. The NIAF includes a meta-sample generator and an autoregressive conditioner model to output meta samples. The Bayesian meta sampling framework uses optimal-transport Bayesian sampling for fast adaptation to new tasks. It involves a meta sampler generating meta samples from input distributions, which are then adapted to task-specific samples using a sample adapter. This adaptation mechanism ensures efficient and accurate adjustments to new task distributions, allowing for fast uncertainty adaption. The samples are further utilized to encode uncertainty in modeling tasks like Bayesian classification through variational inference optimization of the task network. The proposed meta-sampling framework utilizes Bayesian sampling, Wasserstein gradient flows, and inverse autoregressive flows to optimize task networks based on variational inference. Extensive experiments show improved performance compared to related methods, with applications in k-shot learning in Bayesian neural networks and reinforcement learning. The proposed Bayesian meta sampling framework aims to learn a meta sampler for fast adaptation to new tasks. It decomposes meta sampling into a meta sampler and a sample adapter, with the meta sampler generating common statistics of tasks and the sample adapter adapting samples to task-specific distributions. The meta sampler is a conditional generator, while the sample adapter aggregates local losses for optimization. The sample adapter aggregates local losses of tasks to form a final loss for optimization based on optimal-transport theory. Gradients can be directly backpropagated for meta-sampler updates. Comparisons with related works like meta NNSGHMC and probabilistic MAML show differences in meta representation and model architecture. Our model adopts data/parameter samples for meta representation, while PMAML relies on variational inference. Our model adopts state-of-the-art autoregressive architectures for generating high-quality meta samples. It simplifies the objective function to allow direct gradient flow for meta-sampler optimization. The framework reduces to MAML with one meta sample. Our approach focuses on Bayesian sampling, similar to meta NNSGHMC, while MAML aims for point estimation. Neural process could also be used for few-shot function regression in meta-learning. The section discusses designing a meta sampler efficiently generating meta samples using a nonparametric model. Our approach focuses on Bayesian sampling for generating high-quality meta samples efficiently. We propose learning the meta sampler with a parametric model, either with an explicit or implicit generator. An explicit generator parameterizes the output as samples from a known distribution, limiting representation power. Our approach focuses on Bayesian sampling using an implicit generator based on neural inverse-autoregressive flows (NIAF) for the meta sampler. NIAF efficiently incorporates task-specific information and generates samples in an autoregressive manner. These meta samples are then used in a task network to encode uncertainty for specific tasks like Bayesian classification. The architecture of the meta sampler is similar to using hypernetworks to generate network parameters. Neural inverse-autoregressive flows (NIAF) are proposed for effective meta-sample generation by incorporating task-specific information. NIAF generates samples in an autoregressive manner using an invertible function and an autoregressive conditioner model. The generator G is parameterized by \u03c8 and implemented as a deep sigmoidal flow. Using positive weights and monotonic activation functions ensures the network is invertible. NIAF is designed for sample generation by transforming noise with a flow-based network G. A task network may be needed for specific learning tasks. The task network may be necessary for specific learning tasks, such as classification with uncertainty. Two ways of parameterization to encode uncertainty into the task network are proposed: sample parameterization and multiplicative parameterization. In normalizing flows, an inference network is defined for the weights using a Gaussian variational distribution. The sample parameterization directly generates weights from the meta sampler, while multiplicative parameterization overcomes instability in high-dimensional meta samples. The multiplicative parameterization reduces the dimensionality of meta samples, making it suitable for large-scale problems. Efficient inference methods for these cases will be discussed in Section 2.4. The approach of sampling from a mean-field distribution and transforming it with NAF is challenging for high-dimensional problems. The meta sampler output contains shared information for all tasks, allowing task-specific samples to adapt quickly. The proposed Bayesian sampling framework based on optimal-transport theory allows for efficient adaptation of task-specific samples from meta samples. This approach overcomes the limitations of standard nonparametric samplers like SG-MCMC and SVGD, enabling direct application of back-propagation. The framework is designed to handle a large number of tasks by learning task-wise parametric models for sample adaption. The proposed Bayesian sampling framework based on optimal-transport theory allows for efficient adaptation of task-specific samples from meta samples. This approach overcomes limitations of standard nonparametric samplers, enabling direct application of back-propagation. Samples are evolved as underlying density functions, allowing for training the meta sampler efficiently via standard back-propagation. Task-wise parametric models are learned for sample adaptation. The proposed Bayesian sampling framework utilizes optimal-transport theory for efficient adaptation of task-specific samples from meta samples. The approach allows for training the meta sampler efficiently via standard back-propagation by evolving samples as density functions. Energy functional design is crucial for sample adaptation, with conditions such as convexity and easy calculation of the first variation needing to be satisfied. The f-divergence is a general family of divergence metrics defined by a convex function f. The f-divergence is a family of divergence metrics defined by a convex function f, with properties such as first variation convenience. In experiments, focus is on the KL-divergence with f(r) = r log r. Density \u03c1(z) for evaluating r is not readily available, so methods from Chen et al. (2018b) are used. In experiments, the focus is on using the meta samples {z (i) k } at the k-th step for approximation, with the number of adaptation steps k determined based on the problem. To improve accuracy, equation 5 is combined with the first variation of SVGD, with a hyperparameter \u03bb \u2265 0 to balance the terms. Training the proposed model involves optimizing the conditional model T (\u00b7; \u03c8) in the sample-parameterization setting. The objective is defined over the task distribution p(\u03c4), with parameters \u03c8 in the autoregressive conditioner model. Gradient calculation is done using the chain rule. In the multiplicative-parameterization setting, parameters \u03c8 and W are learned separately. \u03c8 is optimized using the same update equation as in the sample-parameterization setting. In the multiplicative-parameterization setting, parameters \u03c8 and W are learned separately. \u03c8 is optimized using the same update equation as in the sample-parameterization setting. The ELBO is optimized for (\u03b8, \u03c6) while \u03c8 is updated with gradients from samples of the NIAF. In meta learning, the task network is adapted using MAML with the ELBO as the new-task objective. The algorithm for new-task sample generation involves feeding task information and noise to the meta sampler to generate samples efficiently. Experiments compare the model with Bayesian sampling algorithms like SGLD, SVGD, and SGHMC, as well as PMAML for meta learning. The curr_chunk discusses the comparison of meta learning algorithms such as PMAML, ABML, and NNSGHMC, introducing a new algorithm called DAMS. It demonstrates the effectiveness of a NIAF-based sampler in generating samples for Bayesian Logistic Regression on real datasets. In our model, we test the generator with different architectures, including DAMS with MLP, IAF, and NIAF. Gaussian priors are applied for the parameters. DAMS with NIAF achieves the best performance in accuracy. The results show the effectiveness of the NIAF architecture in the OT-Bayesian sampling framework. The experiments aim to demonstrate the adaptability of the meta-sampling framework in different tasks. Additional experiments on meta posterior adaption are presented in the Appendix. The experiments involve testing different architectures for the generator, including DAMS with MLP, IAF, and NIAF, using Gaussian priors for the parameters. DAMS with NIAF shows the best accuracy. The results highlight the effectiveness of the NIAF architecture in the OT-Bayesian sampling framework. The experiments aim to showcase the adaptability of the meta-sampling framework in various tasks. Additional experiments on meta posterior adaption are provided in the Appendix. Our proposed meta sampler DAMS demonstrates faster convergence compared to other sampling algorithms, particularly on complex mixtures like 20-Gaussians. The quick convergence is attributed to the learned meta sampler, which aids in sample adaption. This is supported by the evolution of samples during the adaption process, as shown in Figure 10, 11, and 12 in the Appendix. The DAMS is tested for meta sampling of BNNs on MNIST and CIFAR-10 datasets, focusing on fast adaptation within 200 iterations. To address high-dimensionality, a multiplicative parameterization method is utilized. Five classes are randomly selected for training, while the rest are used for testing. The proposed method involves training a BNN on a subset of classes for meta sample generation, with adaptation based on testing data. Different architectures are used for MNIST and CIFAR-10 datasets, with comparisons made to other methods for adaptation efficiency. Our NIAF structure for adaptive posterior sampling outperforms the simple conditional version of MNF. Using 20 meta samples in training, our DAMS adapts the fastest to new tasks and achieves the highest classification accuracy. Results show faster adaption and higher accuracy compared to NNSGHMC, demonstrating the effectiveness of our proposed architecture. The NIAF architecture demonstrates superior sample efficiency and uncertainty evaluation compared to NNSGHMC and standard Bayesian learning methods on CIFAR10 dataset. Our method achieves higher accuracies and better sample efficiency, showcasing its effectiveness in adaptive posterior sampling. Following Louizos & Welling (2017), uncertainty is evaluated using entropy of predictive distributions. DAMS shows superior uncertainty estimates compared to other methods. The framework is applied to meta sampling for few-shot classification and reinforcement learning tasks. The method is tested on Mini-Imagenet dataset and compared with MAML and its variants with uncertainty modeling. The framework MAML (PMAML) is evaluated through an ablation study with variants MAML-SGLD, MAML-SGHMC, and DAMS-SGLD. The network architecture includes a 4-layer convolutional feature extractor and a meta classifier. Results show significant improvement in classification accuracy early on compared to MAML, with learning curves demonstrating the method's superiority in providing an elegant initialization for the classification network. Our method provides an elegant initialization for the classification network, with both NIAF and WGF components contributing to performance gain. It is adapted for meta reinforcement learning on MuJoCo tasks, using TRPO-RL framework and MAML method. The policy network has two hidden layers with ReLu activation and a linear layer for Gaussian policy mean. Our method, DAMS, utilizes a Bayesian meta-sampling framework for effective uncertainty adaptation in reinforcement learning. It outperforms MAML on tasks, showcasing the importance of uncertainty adaptation. The model is scalable and based on neural autoregressive flows, enabling simple yet effective training. An efficient uncertainty parameterization for the task network is proposed, trained by variational inference. Experiments show DAMS' advantages over other methods in terms of sample efficiency and fast adaptation. The section reviews Bayesian sampling methods like SG-MCMC and SVGD, highlighting their importance in uncertainty modeling, data generation, and reinforcement learning. Traditional algorithms such as Metropolis-Hastings and Gibbs sampling are also discussed, with a focus on the advancements in large-scale Bayesian sampling driven by modern machine learning and deep learning techniques. This paper introduces a framework for Bayesian meta sampling, bridging the gap between Bayesian sampling methods like SG-MCMC and SVGD and the concept of meta learning. The goal is to design meta sampling algorithms that can quickly adapt to new task-specific distributions. In optimal transport, a density function evolves to a target distribution optimally using the 2-Wasserstein distance metric. The trajectory is described by a partial differential equation, ensuring convergence to a target distribution. The framework considers a more general setting beyond the popular KL-divergence. The WGF framework equation 8 allows Bayesian sampling from a density-optimization perspective. Recent works approximate \u03c1 t with samples and evolve them according to equation 8. Our model uses autoregressive flows for meta-sampler design, implementing sample generation through a deep neural network. The autoregressive flow (AF) parameterizes a Gaussian conditional distribution for each z i. Sample generation process involves neural networks g \u00b5i and g \u03b1i. Instances include AF and Masked Autoregressive Flow (MAF). Inverse autoregressive flow (IAF) uses MADE for sample generation. Neural autoregressive flow (NAF) replaces affine transformation with a deep neural network. Autoregressive flow (AF) and Inverse autoregressive flow (IAF) are used for sample generation in neural networks. AF calculates sample density in one pass but requires D sequential passes for sample drawing. IAF can draw samples and estimate densities in one pass, making it more efficient for large dimensions of z. Neural Inverse-Autoregressive Flow (NIAF) is proposed as an extension of the NAF framework for sampling. The algorithm involves updating flow parameters and learning the task network with variational inference. The process includes sampling batches of tasks, computing adapted parameters with gradient descent, and defining the WGF for each task. The WGF is defined in the sense of distributions, with equation 10 reducing to a differential equation for particle evolution. The proof of Proposition 2 involves applying the f-divergence case and using the chain rule. Experimental results demonstrate the effectiveness of the proposed method, with analytic forms of synthetic distributions provided. DAMS is applied for fast adaptive sampling on regression tasks, following previous work by Huang et al. (2018). Huang et al. (2018) applied DAMS to sample the posterior distribution of the frequency parameter of a sine-wave function with only three data points. Meta training data had two modes of f \u2208 {0.0, 5/4}, while meta testing data had three modes for the first setting and four modes for the second setting. The effectiveness of DAMS was compared with re-training results. The DAMS algorithm is compared with re-training from scratch in adapting to different modes of the posterior distribution. DAMS shows faster adaptation to test data with fewer iterations compared to re-training. The DAMS algorithm can adapt the training posterior to the test posterior much faster than re-training from scratch, achieving over 3X speedups. It shows predictive uncertainty compared to other algorithms by exploring neural parameter posteriors and estimating uncertainty for out-of-distribution data samples. The predictive distribution of the trained model is expected to be uniform over unseen classes in the notMNIST dataset. The BNN is a CNN with 16 and 50 filters and kernel sizes of 5 for the two convolutional layers, using samples from unseen classes."
}