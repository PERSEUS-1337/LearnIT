{
    "title": "S1xim8UFuV",
    "content": "Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions. A modification to a GAN algorithm, PC-GAN, is proposed to generate point clouds. It combines hierarchical Bayesian modeling and implicit generative models, training a posterior inference network for hidden variables. PC-GAN defines a generic framework that can incorporate existing GAN algorithms and introduces a sandwiching objective for a tighter Wasserstein distance estimate. This approach is validated on the ModelNet40 benchmark dataset. The PC-GAN algorithm, a modification of GAN, achieves better results on the ModelNet40 dataset. It demonstrates versatility in tasks like generalization, interpolation, classification, and image to point clouds transformation. Deep generative models, particularly GANs, have shown success in learning complex data distributions. Recently, there has been a focus on capturing 3D information, particularly using point clouds which store more information than 2D images. Point clouds can be easily represented as a set of points, offering advantages like permutation invariance. This has led to the development of algorithms that can effectively learn from 3D point cloud data. The paper discusses the challenges of unsupervised generative models for 3D data, proposing a deep generative adversarial network (PC-GAN) for point clouds. The PC-GAN architecture learns a stochastic procedure to generate new point clouds without explicitly modeling the underlying density function. PC-GAN is a versatile algorithm that incorporates various GAN variants and introduces a sandwiching objective to improve Wasserstein distance estimation. Evaluation on ModelNet40 demonstrates its strong generalization capability, including generating new point clouds and meaningful interpolations. The algorithm also shows superior generalization ability in conditional generation tasks and offers interesting studies like classification and point cloud generation from images. A generative model for sets should be able to sample entirely new sets and sample more points from a given set. The probability of sets can be factored using object representations of point clouds. Points in a point cloud are considered as samples from an unknown latent distribution representing the object. One approach is to model the distribution of the point cloud set together. A generative model for sets should be able to sample new sets and more points from a given set. The distribution of the point cloud set together can be modeled using object representations. The traditional GAN approach with DeepSets classifier as the discriminator may not work due to issues with IPM guarantees and 1-Lipschitz functions. In a setup with a generator G using noise sources u and z i to produce a set of n points, fixing u selects a set and ensures coherence among points generated by sampling z i. If an 'oracle' mapping T exists mapping points to their origin, the optimization task changes. By matching the p(\u03b8) component, the lower bound of \u2212 log(4) can be achieved while allowing conditional p(x|\u03b8) to vary. The DeepSets classifier cannot be used in a simple GAN to generate valid models due to constraints in matching the p(\u03b8) component. Learning point cloud generation directly under a GAN formulation is challenging, but learning p(x|\u03b8) is simpler. Different probabilistic divergences can be used to compare point clouds as 3-dimensional distributions. Implicit generative models with a GAN-like objective are preferred over explicit densities for learning complex distributions. The proposed algorithm involves training a generator and a conditional distribution P, denoted as P, with an unobserved latent variable \u03b8 for modeling different objects. The algorithm concurrently learns an inference network Q(X) \u2248 \u03b8 while learning p(x|\u03b8). After training, hierarchical sampling is done using the trained Q to collect inferred Q(X) and train the generator G \u03b8 (u) \u223c p(\u03b8) for higher hierarchical sampling. The proposed algorithm involves training a generator and a conditional distribution P with an unobserved latent variable \u03b8 for modeling different objects. Hierarchical sampling is done using the trained Q to collect inferred Q(X) and train the generator G \u03b8 (u) \u223c p(\u03b8) for higher hierarchical sampling. The full generative process for sampling one point cloud involves z 1 , . . . , z n \u223c p(z), and u \u223c p(u). The algorithm utilizes an IPM-based GANs objective with a discriminator f (\u00b7) to distinguish generated samples and true samples conditioned on \u03b8. When training GANs on images, quality evaluation focuses on coherence of individual images, while in point clouds, outlier points degrade object quality. Generative models for point clouds require a lower distance between true and generated distributions compared to images. Wasserstein GAN optimizes by minimizing the Wasserstein distance between truth and generated distributions. Many GAN works approximate this distance in dual form. Many GAN works approximate the Wasserstein distance in dual form using neural networks to find a lower bound estimate. However, a lower bound may not be ideal for solving the minimization problem. We propose combining a lower bound W L and upper bound estimate W U to sandwich the solution, solving a minimization problem using lagrange multipliers. By solving the sandwiched problem, a tighter estimate of the Wasserstein distance can be obtained by combining an upper bound W U and a lower bound W L. This approach results in a faster approximation without solving linear programming, especially beneficial for low-dimensional data like point clouds. However, for high-dimensional data such as images, accurately estimating the Wasserstein distance in primal form is challenging. Generative Adversarial Network (GAN) aims to learn a generator that can sample data from the data distribution. GAN has shown compelling results on various data types like images, speech, text, video, and 3D voxels. However, GAN on 3D point cloud is still underexplored. Different objectives for training GANs have been studied, including f-divergence, integral probability metrics (IPMs), and approximated primal form of Wasserstein distance. The adversarial autoencoder (AAE) combines a generative model with an autoencoder to constrain the encoded data to follow a normal distribution via GAN loss. This approach is similar to VAE but replaces the KL-divergence on latent space with any GAN loss. AAE has been theoretically connected to the primal form of Wasserstein distance. Another variant of AAE involves training another generative model to learn the distribution of the encoded data instead of enforcing it to be similar to a known distribution. AAE has been explored for point clouds using a specially-designed encoder network for learning a compressed representation before training GAN on the latent space. The proposed PC-GAN utilizes an encoder-decoder formulation, starting from De-Finetti theorem to learn both p(X|\u03b8) and p(\u03b8) with an inference network interpretation of Q. This differs from previous approaches that focus on learning p(\u03b8) without modeling p(X|\u03b8). The decoder in PC-GAN is capable of generating arbitrarily many points by sampling different random noise as input, breaking limitations of previous models. The PC-GAN focuses on learning both p(X|\u03b8) and p(\u03b8) using an encoder-decoder formulation, unlike previous approaches that only focus on p(\u03b8). It aims to generate point clouds efficiently by sampling random noise as input. The conditional GAN has been explored in images, but its application to point clouds is still underexplored. Most works assume conditioning is given without learning the inference during training. Li et al. have worked on learning GAN and unseen latent variables simultaneously, but only on image and video datasets. The PC-GAN combines W L and W U with a 1:20 mixture for experiments. The circles in the point clouds follow a mixture of Gaussians with equal weights. AAE has a decoder output size of 500 x 2 for 500 points and an encoder output size of 20. The latent code for PC-GAN is 20 with 12K parameters. AAE struggles to learn the radius distribution even with a larger latent code and more parameters. PC-GAN's model size is independent of the number of points, unlike AAE which wastes parameters for nearby points. Using a larger model could improve performance, but both models are limited to generating a fixed number of points for each object. ModelNet40 benchmark contains 40 classes of objects with 9,843 training and 2,468 testing instances. Two settings are considered: training on a single class or all objects in the training set. Different latent code sizes and output dimensions are used for AAE and PC-GAN. The focus is on whether G x and Q can model the distribution of unseen test data by inferring latent variables and generating points. We compare the distribution of input point clouds with conditionally generated ones using f-divergence and IPM for evaluation. Estimators for distance estimates are based on nearest neighbor distances. We propose measuring performance based on distance to faces in a mesh. The algorithm measures the distance to faces in a mesh using D2F, similar to Chamfer distance. It focuses on recovering enough support of the distribution by computing the Coverage ratio, indicating the number of faces covered by generated points. Limited sampled points make it difficult to achieve high coverage ratio for AAE or PC-GAN. The proposed method, Ws, aims to balance both D2F and coverage by combining WU and WL to achieve a desirable middle ground. Empirically, Ws shows better coverage than WL and competitive D2F with WU. This difference is crucial for capturing object details, as illustrated in reconstructed point clouds in FIG4. The proposed method, Ws, aims to balance D2F and coverage by combining WU and WL. Ws outperforms others significantly with larger training data. PC-GAN with Ws has lower D2F and fewer parameters. AAE only outperforms PC-GAN in Guitar and Sofa due to low class variety. AAE has worse coverage than PC-GAN due to fixed output points and Chamfer distance objective. Hierarchical sampling process for point cloud generation is proposed, showing smooth and structured results. PC-GAN captures symmetries and patterns in randomly sampled objects. Interpolation between objects in latent space results in smooth changes. Interpolation between objects in latent space results in smooth changes, allowing for the generation of points based on the interpolation. Generalization on unseen classes is studied by training PC-GAN on 30 classes and testing on 10 fully unseen classes, showing the advantage of the proposed PC-GAN in recovering main shape and geometry structure. The proposed PC-GAN enforces point-wise transformation to learn underlying geometry structure and shared building blocks, achieving D2F and coverage results slightly worse than training on whole 40 classes. PC-GAN generalizes well to unseen classes by matching patterns and symmetries. Additional studies include interpolation between rotations, classification, and image to point clouds. In this paper, a GAN modification called PC-GAN is proposed for generating point clouds. The method utilizes hierarchical Bayesian modeling and implicit generative models, achieving competitive results with a smaller network. PC-GAN can generate arbitrary i.i.d. points to form point clouds without pre-specification, capturing delicate details and generalizing well to unseen data. Our method, PC-GAN, uses \"point-wise\" transformations to learn building components of objects instead of copying the whole object. It can interpolate point clouds and convert images to point clouds. The framework can be extended to higher dimensions, where 3D points may have attributes like RGB colors and velocity vectors. The generator G x (z, \u03c8) takes noise source z \u2208 R d1 and descriptor \u03c8 \u2208 R d2 encoding information about distribution of \u03b8.\u03c8 encodes information about distribution \u03b4(\u03b8 \u2212 \u03b8 0 ) for a given \u03b8 0 , and samples generated follow the distribution p(x|\u03b8 0 ).\u03c8 can encode more complex distributions. The inference network Q is constructed using permutation equivariant layers from Deep Sets to handle variable number of input points in arbitrary order, yielding a consistent descriptor \u03c8. This overcomes the challenge of designing Q for the posterior predictive distribution p(\u03b8|X) for a given sample set X, enabling generative modeling of point clouds. The proposed GAN framework for learning to generate point clouds, known as PC-GAN, involves training the generator G and the inference network Q to collect inferred Q(X) for hierarchical sampling. The Wasserstein distance is used for conditional distribution matching in PC-GAN, which can be interpreted as an encoder-decoder formulation. The Wasserstein distance, also known as optimal transport, is defined as DISPLAYFORM0 where \u03b3 is the coupling of P and G. It involves finding the one-to-one matching between samples X and Y to minimize the total pairwise distance. An approximation provided by BID4 uses an iterative auction algorithm to efficiently find this matching. The algorithm for estimating Wasserstein distance is parallelizable and terminates with a valid matching. It provides an approximation of the matching cost and serves as an upper bound. However, estimating Wasserstein distance in primal form is only accurate for low-dimensional data like point clouds, not for high-dimensional data like images. Finding a modified primal form with low sample complexity for high-dimensional data is a future research problem. The dual form of Wasserstein distance is defined as a set of k-Lipschitz functions parameterized by deep neural networks. Weight clipping constraints and other regularization techniques have been proposed to improve empirical performance, but there is no guarantee that the resulting functions are still Lipschitz or that the distances are lower bounds of Wasserstein. Proposed a variation combining weight clipping and regularization to ensure Lipschitz functions and valid lower bound estimates of Wasserstein distance. The combination of L2 ball constraint and weight clipping showed satisfactory performance compared to other techniques like WGAN-GP. The combination of weight clipping and regularization ensures Lipschitz functions and valid lower bound estimates of Wasserstein distance. This approach is faster and more stable than using other techniques like WGAN-GP. The sandwiched estimator Ws provides a tighter estimate of Wasserstein distance compared to using a single estimator. Additionally, hierarchical sampling discussed in Section 5.2 can be seen in FIG0 for reconstruction results. In addition to hierarchical sampling, a study on interpolations between rotations was conducted. Instead of linear interpolation, a 2-layer MLP was trained to generate smooth latent representations for rotated objects. The transformation path of rotation in the latent space was found to be smooth, as shown in FIG0. The transformation path of rotation on the latent space is smooth, suggesting the geodesic path of the learned manifold may not be linear. Evaluating the quality of the representation acquired from the learned inference network Q, training on ModelNet40 data, shows that PC-GAN captures inherent patterns and learns basic building blocks of objects. Further study on understanding the geometry of the manifold for point cloud is recommended as future work. Generative models without label information are used to extract latent representations for point clouds, which are then used to train linear SVM and linear classifiers. The Deep Sets architecture allows for sampling different numbers of points as input, resulting in better accuracy than previous methods. Experiments are repeated 20 times to report average accuracy and standard deviation. The approach outperforms previous methods and is competitive with supervised learning algorithms. Training is done on ShapeNet55 and testing on ModelNet40. PC-GAN outperforms existing unsupervised learning algorithms in accuracy on ModelNet40. Techniques from Yang et al. (2018) can be applied to further improve PC-GAN by incorporating additional geometry features. The proposed extension of PC-GAN for point cloud applications shows promise. After training Q as described, a regressor R is trained using different views of the point cloud X to output Q(X). The experiment uses 12 view data and Res18 architecture with output size 256. Results on reconstructing testing data are shown in FIG0. End-to-end training is a potential extension. Single view to point cloud transformation is possible but not the main focus. Various methods are compared for accuracy, with PC-GAN achieving 86.9%. In experiments, the batch size is fixed at 64 with 10,000 samples for training and testing. The inference network consists of 3 mean Permutation Equivariance Layers with hidden layer sizes of 30 and final output size of 15. The activation function used is SoftPlus. The generator is a 5-layer MLP with hidden layer size set to 30, while the discriminator is a 4-layer MLP. The hidden layer size for the discriminator is set to be 30, with changes made to the implementation for BID0 by adjusting the number of filters for the encoder. The decoder has increased from 3 to 4 layers for more capacity. Data augmentation includes uniformly rotating on the x-y plane during training. PC-GAN's random noise z 2 is fixed at 10 dimensions. The single class model Q uses 3 max Permutation Equivariance Layers with an output size of 128 for each layer, followed by a 2-layer MLP with the same width. The generator G x is a 4-layer MLP. The generator and discriminator models have multiple layers with hidden layer sizes set to 128 or 256. Random sources u and z are 64 and 10 dimensional, respectively. For hierarchical sampling, top generator and discriminator models have 5-layer MLPs with hidden layer size of 256. Latent code sizes are 128 and 256 for single class and whole ModelNet40 models."
}