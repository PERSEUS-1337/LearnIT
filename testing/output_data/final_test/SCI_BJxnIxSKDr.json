{
    "title": "BJxnIxSKDr",
    "content": "Deep learning allows training of large function approximators from scratch with a lot of data. Multi-task learning can improve data efficiency by sharing data and representations across tasks. However, in challenging settings like reinforcement learning, learning each task independently may perform better than a single model for all tasks. In this work, a new approach called matrix-interleaving (Mint) is introduced to enable a single model to represent both joint training and independent training. By projecting task activations into different learned subspaces, the model can decide how much to share representations between tasks. This approach consistently outperforms joint training and independent training on challenging multi-task supervised learning and reinforcement learning problems. Through the use of function approximators, deep learning faces challenges with large amounts of data. Multitask learning with deep networks aims to improve performance and data efficiency, but joint training on multiple tasks can sometimes decrease task performance. The Mint approach introduces matrix-interleaving to balance shared representations between tasks, outperforming both joint and independent training methods. In this work, the authors aim to develop a multi-task learning method that can perform well when tasks share very little or a large amount of structure. They found that training models independently per task outperformed three recently proposed methods for multi-task learning. However, this approach requires enough data per task and may not fully utilize the potential data-efficiency gains from multi-task learning. The authors also highlight the challenge of finding the right level of parameter sharing for different problem domains, which often involves manual engineering. Neural network models can represent different levels of model sharing, from independent models to a single model with shared weights. One approach is to condition the model on the task ID using various conditioning methods like FiLM, allowing for separate networks within a single model. This enables selecting different parts of the network for different tasks, enhancing multi-task learning capabilities. In multi-task learning, optimizing over shared parameters can be challenging. A model can optimize on shared parameters, disjoint parameters, or a combination by interleaving per-task matrices in a jointly-trained neural network. This allows for independent training with per-task matrices, standard joint training with identical matrices, or a mix of shared and per-task parameters. Incorporating these matrices into the network enhances its capabilities. The primary contribution of this paper is a simple yet effective approach for multi-task learning called matrix interleaving (Mint). This approach allows for dynamic modulation of shared representations between tasks without the need to optimize shared parameters. It improves data efficiency and generalization in multi-task settings and can be extended to goal-conditioned reinforcement learning. Mint is a novel approach for multi-task learning that allows the model to generate interleaved matrices conditioned on task information. It outperforms previous methods by avoiding the need to optimize shared parameters and shows better performance on challenging multi-task problems. Additionally, Mint is simpler to implement and achieves superior results compared to state-of-the-art approaches. In multi-task learning, the goal is to find a model that performs well across all training tasks from a fixed set. The model is conditioned on a task indicator to specify which task to perform, and this can be extended to goal-conditioned reinforcement learning. The model learns to optimize objectives for all tasks. In multi-task learning, the model aims to optimize objectives for all tasks it is trained on. There are two extremes in multi-task learning: independent training with task-specific parameters and joint training with shared parameters. Joint training offers data-efficiency and generalization benefits but can be challenging to train effectively. To combine the stability of independent training with the efficiency of parameter-sharing in joint training, an algorithm is needed. In multi-task learning, models aim to optimize objectives for all tasks by balancing independent training stability and joint training parameter-sharing efficiency. A proposed approach allows neural networks to adaptively learn how much information to share between tasks. This involves modifying the network architecture to form task-specific, shared, or intermediate activations at different layers. The model transforms representations in both task-general and task-specific ways sequentially, optimizing task-specific weights when tasks share little and shared weights when tasks share more. The network optimizes task-specific weights and leverages shared weights when tasks have a considerable degree of structure. Transformations are introduced at various layers, allowing for different levels of representation sharing in the neural network model. The Mint layer augments traditional fully-connected layers with task-specific weight matrices and bias vectors. The Mint layer introduces task-specific weight matrices and bias vectors to traditional fully-connected layers in a neural network. These task-specific parameters can be learned jointly with shared parameters, allowing for efficient optimization across multiple tasks. Additionally, for tasks with numerous or arbitrary descriptors, separate neural networks can be used to output Mint matrices and biases at each layer, resembling FiLM. Mint introduces task-specific weight matrices and bias vectors to fully-connected layers in a neural network, resembling FiLM. Mint uses a matrix transformation at each layer instead of point-wise multiplication by a vector. The theoretical property of Mint motivates its layer definition, validated in experimental evaluation. The expressive power of multi-task learning architectures is studied when shared parameters cannot be optimized effectively. Using separate task-specific networks is an alternative approach, assuming tasks share no exploitable structure. In the 'worst case' scenario where shared parameters are not useful, Mint network retains the same richness of functions as purely task-specific networks. Mint does not sacrifice expressiveness and can exploit shared structure if it exists. Mint is compared to FiLM network and task indicator concatenation approach in terms of representable functions. The class of functions expressible by task indicator concatenation approach involves one-hot task indicator vectors concatenated to shared layer inputs. Optimal parameters for task-specific networks are considered, along with Mint and FiLM networks. Lemmas 1 and 2 are stated within this setup. Lemma 1 and Lemma 2 highlight the differences in layer-wise expressiveness between Mint and methods like FiLM and task indicator concatenation. Mint can express arbitrary affine transformations at each layer for each task, while FiLM and task indicator concatenation may not be able to express certain affine transformations. The shared parameter matrices are assumed to be invertible to preserve input information. The text discusses the layer-wise expressiveness properties of Mint and FiLM networks in the context of optimal MLPs. It compares the function classes defined by Mint and FiLM networks and states the comparison in Theorem 1. The text shows that Mint networks can have weights effectively equivalent to the target MLP when sharing parameters. In supervised and reinforcement learning settings, Mint layers are applied after every fully connected layer of the model. Task-specific matrices and biases are generated using task identifiers, transforming the model for each specific task. In multi-task reinforcement learning, task-specific matrices and biases are generated using Mint architecture for actor-critic RL algorithms. Transformation functions T (l) \u03c6 and T \u03c8 are represented by 2-layer ReLU networks to produce goal-specific matrices and biases. Multi-task learning focuses on finding a single model that can solve multiple tasks efficiently across various learning domains, including supervised learning and reinforcement learning. However, training a single model on multiple tasks can lead to optimization challenges and negative interference between tasks. Many approaches propose separate task learning before combining solutions into a multi-task model. A new method allows training a single model on multiple tasks, interpolating between joint and independent training. Architectural solutions like multiple modules or task conditioning have been proposed to enhance multi-task learning capability. The approach presented in the curr_chunk allows for a middle ground between fully independent training and single-model joint training. It enables sharing parameters between tasks while avoiding potential task interference. This method is simpler to implement, less computationally intensive, and easier to optimize compared to prior approaches. The approach presented in the curr_chunk is compared to various prior methods in experimental evaluations on multi-task reinforcement learning domains. The goal is to determine the effectiveness of the method in enabling multi-task learning, comparing it to independent and joint training, and assessing its performance against state-of-the-art approaches. The curr_chunk discusses the evaluation of the Mint method on multi-task RL benchmarks MT10 and MT50, as well as on a goal-conditioned RL domain with a Sawyer robot arm. The experiments compare Mint to SAC and other methods in terms of data efficiency and task performance. The task identifier z is concatenated with the activation at each layer and passed as inputs to the next layer. FiLM and Superposition methods combine neural networks for actor and critic learning. Independent learning involves separate actor and critic per task. Architecture details and environment set-up are provided in Appendix B. Mint's performance on RL tasks like MT10 and MT50 is evaluated, showing success rates averaged across tasks. Appropriate actor and critic architectures are designed for the tasks. Mint outperforms other methods in Meta-World benchmark tasks MT10 and MT50 by efficiently learning tasks with expressive power and interpolation capabilities. Mint quickly solves over 60% of tasks in MT50, while SAC struggles to solve 40% even after 35 million steps. Mint outperforms other methods in Meta-World benchmark tasks MT10 and MT50 by efficiently learning tasks with expressive power and interpolation capabilities. Independent networks learn tasks slower than Mint but eventually surpass it. Mint can perform at a similar level to independent training, showcasing its ability to represent separate learning and learning with shared networks. Mint matrices are learned for duplicate tasks, and the pairwise distance is computed between them. The Mint layers for duplicated tasks have the smallest relative distance, except for tasks with structural similarities. Mint outperforms other methods in Meta-World benchmark tasks by efficiently learning tasks with expressive power and interpolation capabilities. Mint outperforms other methods in Meta-World benchmark tasks by achieving a significantly higher success rate with the same number of layers. The pairwise distance between Mint layers for duplicate tasks is small, except for tasks with structural similarities. In the goal-conditioned sawyer pushing domain, Mint is evaluated along with other methods. 9 goals are sampled at each policy rollout step, with 3 paths collected for each goal. The goal space is discretized into 200 goals to prevent an infinite number of replay buffers. 10 goals are sampled for training 10 independent SAC agents to estimate performance in goal-conditioned tasks. In goal-conditioned pushing, Mint outperforms other methods in data efficiency and distance to the goal. Mint's ability to represent joint training and independent networks per task is crucial for multi-task learning. Mint provides theoretical guarantees of universal approximation for multi-task settings. Mint provides theoretical guarantees of universal approximation for multi-task settings, outperforming other approaches in reinforcement learning benchmarks. It can match or improve upon independent training performance while using comparable or fewer parameters. One potential limitation is the task matrices introducing a significant number of parameters, but this can be alleviated by learning a single neural network to produce matrices and biases conditioned on task descriptors. Mint-based networks show strong performance gains over previous methods. Mint is a simple and effective approach for deep multi-task learning, requiring minimal modifications to standard deep networks. It allows for expressing arbitrary affine transformations at different layers for each task. This method shows strong performance gains over previous approaches in reinforcement learning benchmarks."
}