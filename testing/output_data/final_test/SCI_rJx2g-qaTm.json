{
    "title": "rJx2g-qaTm",
    "content": "Our approach focuses on expanding taxonomies with synonyms for large shopping taxonomies. We use WordNet and shopping search queries to generate synonym candidates, filtering them with a binary classifier. By processing taxonomies with thousands of synonyms, we create over 90,000 synonyms. Utilizing contextual features from the taxonomy improves classification performance. Additionally, our method shows potential for transfer learning between different taxonomy domains, reducing the need for new training data. Semantic Networks represent entities, relationships, and properties in a broad variety of contexts. Semantic Networks, also known as knowledge graphs, represent entities and their properties, including multilingual names and aliases. Sub-structures like taxonomies define type-subtype relations, with synonyms improving performance in various applications. For entity extraction and classification, synonyms play a crucial role in Semantic Networks. In this paper, the focus is on expanding taxonomies with synonyms to improve performance in various Semantic Network applications, such as entity extraction, wikification, and natural language instruction grounding. The goal is to enhance recall and generate more varied utterances in applications like conversational agents. The ontologies discussed contain product type taxonomies designed for browsing the product catalog on amazon.com. The taxonomies include complex concepts like combinations of types and attributes, grouping multiple types together. Synonyms generated help identify direct references to taxonomy nodes in text, improving user experience by providing accurate synonyms for nodes within the taxonomy. The taxonomies, authored by experts, contain over 4,300 nodes with depths of over 30 nodes. They represent type properties, values, node equivalence, and other information. Each taxonomy is identified by its root node name, such as \"Baby Products\" with nodes like \"Car Seats\" and \"Accessories.\" The taxonomy nodes are highly detailed, with distinctions based on product types, features, and intended use. The nodes include categories like \"Car Seats,\" \"Car Seat Bases,\" \"Car Beds,\" and \"Accessories,\" with specific subcategories under each. The goal is to identify possible synonyms within the taxonomy for better data organization. Our goal is to collect synonyms from various sources for detailed taxonomy nodes, enabling expansion with synonyms not common in typical text corpora. The method identifies synonyms fitting within the taxonomy structure and uses domain-independent features for cross-domain predictions. The process includes generating synonym candidates for each node of the taxonomy. The method utilizes a taxonomy designed for online shopping catalogs to generate synonym candidates for each node using a thesaurus like WordNet. It then classifies the candidates with a binary classifier to produce the final set of synonyms. The paper discusses the process of generating synonym candidates for nodes in a taxonomy using a binary classifier. The classifier filters candidates based on similarity features to ensure consistency with the taxonomy. Transfer learning is highlighted as a method to predict on new taxonomies without training data. The paper also reviews relevant literature and describes the taxonomies used in the study. The paper discusses generating synonym candidates for taxonomy nodes using a binary classifier. It evaluates the classifier using crowdsourced annotations and cross-domain learning experiments. An alternative method using search queries as synonym candidates is also evaluated. Domain-specific knowledge, like brand names, is used to improve synonym filtering. The paper discusses methods for automatically building knowledge bases from unstructured text, including synonym extraction and expansion to improve search recall. It also mentions using WordNet synonym sets and rules on the WordNet taxonomy to expand queries with keywords. The text discusses using domain-specific ontologies and taxonomies to expand search terms, including methods like text mapping to concepts in a thesaurus for query expansion. Previous work has focused on extracting synonyms from text based on statistically similar contexts or phrases. Other methods include clustering to identify synonyms like \"birth date\" and \"date of birth\" in search queries. The text discusses using domain-specific knowledge to propose synonym candidates for search queries based on past customer purchases. It focuses on identifying aliases for named entities like persons, places, brands, or authors, different from existing work in named entity recognition and synonym extraction from unstructured text. Structure mapping is an established approach for comparing semantically-complex structures, focusing on relational similarity rather than individual features. It has been used in various contexts, such as robot tasks and identifying discrepancies in similar structures. In designing a synonym filtering classifier, concepts from structure mapping were incorporated to compare synonym candidates with multiple nodes in the taxonomy, known as structural similarity features. The approach consists of two stages: identifying synonym candidates using a thesaurus and filtering them using a classifier. The rationale behind the design is to calibrate the generality of a synonym by considering surrounding nodes in the taxonomy. The method involves identifying synonyms for taxonomy node names by using WordNet to find consistent word-level synonyms. Each node's name is split into separate concepts found in WordNet, and all synsets for the words in the node name are selected. The method involves selecting WordNet synsets for words in the node name, performing word sense disambiguation to find the most similar synset, and generating a cartesian product of synset words for each concept in the node's name. The method involves selecting WordNet synsets for words in the node name, performing word sense disambiguation to find the most similar synset, and generating a cartesian product of synset words for each concept in the node's name. This process includes identifying corresponding concepts, building a context vocabulary, comparing synsets, extracting lemmas, and generating synonym candidates. From a taxonomy standpoint, distinguishing between similar product types like \"TV\" and \"LED TV\" is essential. Using word embeddings, we compare synonym candidates with node names in the taxonomy to identify distinctions. This involves summing corresponding vectors for each word in a taxonomy node name or synonym candidate. Using word embeddings, we compare synonym candidates with node names in the taxonomy to identify distinctions. This involves summing corresponding vectors for each word in a taxonomy node name or synonym candidate, and computing cosine similarity values. We utilized Numberbatch, a set of word embeddings from ConceptNet, and implemented a binary gradient boosting classifier using Python's scikit-learn toolkit. Multi-word concepts are identified by searching WordNet with adjacent n-grams in a greedy approach. Word embedding distances are computed between node names and synonym candidates by summing all vectors. The text discusses computing word embedding distances between node names and synonym candidates in a taxonomy. Local features such as word frequency, edit distance, and cosine similarity are used to compare the original node name with synonym candidates. The text discusses computing word embedding distances between node names and synonym candidates in a taxonomy. Structural features such as parent name, taxonomy root, and average distance to direct children are used to compare synonym candidates with the broader taxonomy structure. The hypothesis is that this comparison models how specific a node is with respect to others. The text describes the methodology for training classifiers to classify synonyms in taxonomies created for the amazon.com product catalog. It includes results on predicting synonyms from search queries and the impact of using domain-specific features. The taxonomies enable users to refine products by category and features, with a focus on a broad range of product types. The text discusses the process of generating synonym candidates for nodes in taxonomies, using the WordNet method. A total of 15,197 nodes in eight taxonomies resulted in 182,974 synonym candidates, which were labeled through crowdsourcing. 3331 nodes with distinct names had 4488 corresponding synonym candidates, containing 3056 distinct words. The survey was designed to present original node names and synonym candidates in different categories. Participants were asked a binary question to determine if the phrases meant the same in a given context. 45,000 responses were collected from 10 participants per question, with a skew towards positive answers. The study explored the effect of choosing an annotation threshold for a label set used in training a classifier. The classifier was trained on 90% of labeled data and tested on the remaining 10%, with negative examples included. The classification performance for different annotation thresholds was analyzed. The study analyzed classification performance for different annotation thresholds in the Electronics taxonomy. An annotation threshold of 0.6 was selected for experiments using crowdsourced labels, resulting in high precision and satisfactory recall. Using a combination of local and structural features yielded the best performance, with an F-1 score of 0.92. Including structural features improved classification accuracy, particularly when comparing synonym candidates with the root, parent, or children of the target node. In an ablation study on feature contribution in classification performance, combining local and structural features in the Electronics category resulted in 94% precision and 89-90% recall. The cosine similarity feature between target name and candidate significantly impacted recall, with a standalone F-1 score of 0.77. Selecting two out of three structural features improved F-1 scores, while using all three led to lower performance. The study focused on feature contribution in classification performance, with frequency-based features having high precision but low recall. The thesaurus-based method generated invalid candidates due to different word senses, impacting search term frequency. The selected feature set showed good performance in most categories, with F-1 scores over 0.83. Performance was evaluated in all categories except \"Clothing, Shoes & Jewelry.\" The study evaluated classification performance in different product type taxonomies, showing similar scores except for Clothing. Including candidate-root similarity features led to lower performance. Cross-domain experiments demonstrated degraded but comparable classification performance. In cross-domain experiments, all 56 source-target combinations were tested using the full feature set. The top 5 best and worst performing combinations were based on F-1 scores, with Clothing, Shoes & Jewelry consistently scoring low. The average F-1 score across all combinations was 0.766 with a standard deviation of 0.087. The low scores were mainly due to low recall, while precision remained competitive. Electronics was the most common top performing target taxonomy. The top performing target taxonomy Electronics has slightly lower precision and recall compared to in-domain, with an F-1 score of 0.67 when predicting to Clothing. Label noise and taxonomy diversity are attributed to these performance changes. Additional results using synonym candidates from search queries on amazon.com are described, referencing a related method in the online shopping domain. User behavior is utilized for classification performance in cross-domain experiments. The table in Table 4 shows the classification performance for cross-domain experiments, using a specific feature set. The model associates search queries with product purchases and taxonomy nodes, selecting synonym candidates based on frequency and probability of leading to purchases. Examples of node names in the Electronics taxonomy are provided. The Electronics taxonomy includes node names like portable cell phone power banks, cell phone cases, repeaters, and HDMI cables. The method of selecting synonym candidates from search queries may include specific brand names and product models, which are not ideal for generating synonyms globally. For example, \"Self-Balancing Scooters\" may be referred to as \"hover boards\" in search queries. Using search queries to identify emerging synonyms like \"hover boards\" for \"Scooters\" before they are included in a thesaurus. Queries have high lexical variability due to different intents, making input vocabulary to the classifier more varied. Annotations were collected for 2000 candidate search queries for 337 nodes in the Electronics taxonomy. The study collected annotations for 2000 candidate search queries for 337 nodes in the Electronics taxonomy, with a focus on synonym candidates and their diversity compared to WordNet-generated candidates. Positive responses were skewed towards popular brands in the product category, with a higher proportion of known brand names in the candidates. In a study on synonym candidates in the Electronics taxonomy, positive responses were more common for popular brand names. To address this bias, expert annotations were collected and used in training classifiers with word2vec embeddings. The models included a feature to identify brand names in the candidates. The study focused on brand names in the Electronics taxonomy, using expert annotations to train classifiers with word2vec embeddings. The inclusion of a feature to identify brand names improved precision, although recall decreased due to greater lexical variety in valid candidates. Performance was lower for expert annotations compared to crowdsourced ones. The study compared classification performance using expert and crowdsourced annotations for the Electronics taxonomy. Expert annotations had lower performance, attributed to the effect of genericized brands. Introducing a domain-specific feature, \u03b2, improved results only for expert annotations. Word embedding vectors trained without domain supervision caused issues with brand name identification. The method presented focuses on identifying synonyms for large taxonomies used in online shopping. It involves selecting synonym candidates and filtering them using a classifier with structural similarity features. By comparing synonym candidates with parent, children, or root nodes in the taxonomy, classification accuracy is improved. The approach is also applicable to transfer learning between taxonomies. The method focuses on improving classification performance for synonym candidates extracted from search queries associated with taxonomies. It includes using domain knowledge like brand names to enhance accuracy. Future work will explore using taxonomies in languages other than English and predicting synonyms in different languages."
}