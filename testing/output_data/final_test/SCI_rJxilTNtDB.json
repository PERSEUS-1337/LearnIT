{
    "title": "rJxilTNtDB",
    "content": "Estimating atomic importance in molecules is a challenging problem in chemistry, physics, and material engineering. Traditional methods using density-functional theory are impractical for large databases due to computational complexity. To address this, a machine learning-based approach using reverse self-attention on graph neural networks is proposed for atomic importance estimation. Our method integrates neural networks with graph-based molecular description to efficiently estimate atomic importance without requiring domain knowledge in chemistry and physics. Atomic importance plays a crucial role in interpreting molecular systems, and traditional methods using density-functional theory are challenging due to computational complexity. Machine learning-based approaches, such as reverse self-attention on graph neural networks, offer a more practical solution for atomic importance estimation in large databases. The atomic importance is determined using density-function theory (DFT) through a three-step process involving selecting functional and basis sets, calculating the electronic structure, and interpreting the results. While some methods exist for estimating atom contributions in molecules, DFT is widely used for its general description capabilities. The conventional approach based on Density Functional Theory (DFT) has limitations in efficiency, automation, and generality for computing target molecular properties. DFT calculations have high time complexity, require manual selection of additional methods, and rely on human expertise to estimate atomic importance. The limitations of conventional approaches in estimating atomic importance for molecular properties have led to the proposal of a new concept involving machine learning and graph neural networks. This approach integrates reverse self-attention to overcome the challenges in physics, chemistry, pharmacy, and material engineering. The proposed method integrates reverse self-attention in graph neural networks to estimate the most important atom in a molecule for a target property. This involves training a self-attention-based graph neural network and calculating reverse self-attention scores to determine atomic importance. The proposed method utilizes reverse self-attention in graph neural networks to estimate atomic importance for a target molecular property efficiently and automatically. It reduces computational cost significantly and provides a machine learning-based approach for atomic importance estimation in molecules. The proposed method utilizes reverse self-attention in graph neural networks to estimate atomic importance for a target molecular property efficiently and automatically. It provides a fully-automated way to estimate atomic importance and has been validated using quantitative and qualitative evaluations. The method is based on graph-based molecular analysis and graph self-attention, showing state-of-the-art performance in scientific and machine learning communities. The graph-based molecular machine learning method has shown state-of-the-art performance in scientific applications such as molecular property prediction, molecular generation, and atomic reaction analysis. It represents molecules as undirected feature graphs and aims to estimate atomic importance for target molecular properties efficiently and automatically. The graph-based molecular machine learning aims to build a model f : G \u2192 y using a molecular dataset D. Molecular structures are converted into a molecular graph with adjacency matrix A, node-feature matrix X, and edge-feature matrix U. Graph neural network generates graph-level embedding and predicts target y through aggregation layers. Each node is converted into a node-embedding vector in the aggregation layer, resulting in the output node-embedding matrix H (k). The output node-embedding matrix H (k) is calculated using an aggregation function \u03c8 and a trainable weight matrix W (k). In graph convolutional networks (GCN), H (k) is calculated using an adjacency matrix containing self-loop. The node-embedding matrix of the last aggregation layer is converted into a graph-level embedding vector using a readout function. Mean or max-based operations are commonly used in the readout function. The target for the input graph is predicted by interpreting the output graph-level embedding vector through fully-connected layers. Attention and self-attention mechanisms were originally introduced in natural language processing. The self-attention mechanism, introduced in natural language processing, improves prediction and classification accuracies. In graph neural networks like GAT, it calculates the importance of neighbor nodes for node-embedding vectors. GAT utilizes the attention coefficient between nodes i and j in the kth aggregation layer, defined by a feedforward neural network and trainable weight matrix. This mechanism has shown significant enhancements in prediction and classification accuracies. In GAT, the attention score is calculated based on the attention coefficient \u03b1(k)ij, using a trainable weight matrix and vector concatenation. The node-embedding vector in the kth aggregation layer is determined by the graph attention layer. A machine learning-based approach is used to estimate atomic importance by integrating reverse self-attention with GAT, providing numerical importance of neighbor atoms for target molecular properties. The reverse self-attention in GAT is the inverse of self-attention, showing how much attention a node receives from its neighbors. It involves summing pre-computed self-attention scores and has minimal additional complexities. In GAT, self-attention scores are calculated based on node embeddings from the previous layer, considering 1-hop neighbor nodes. The reverse self-attention in GAT determines the importance of each atom group based on neighbor nodes. This process can be extended to consider k-hop neighbor atoms in subsequent graph attention layers, leading to a fully-automated atomic importance estimator using the reverse self-attention mechanism and GAT. The Machine Intelligence-based Atomic Importance Estimator (MIAIE) utilizes reverse self-attention and GAT to estimate atomic importance in molecules. The process involves training GAT, predicting target properties, calculating reverse self-attention scores, and identifying the most important atoms or groups based on these scores. The Machine Intelligence-based Atomic Importance Estimator (MIAIE) is a fully-automated process that efficiently estimates atomic importance in molecules using graph neural networks. It outperforms conventional approaches like DFT calculations and has been validated through quantitative and qualitative evaluations on molecular datasets. A validation method was devised to assess the performance of the atomic importance estimator. In Section 4.3, a validation method was devised to quantitatively evaluate the performance of the atomic importance estimators using MolView 1 to visualize the estimation results of MIAIE. Two molecular datasets, QM9 and ESOL, were split into 90% train and 10% test subsets for experiments to validate the effectiveness of MIAIE in atomic importance estimation accuracy and generalization capability. In the experiments, the effectiveness of MIAIE was evaluated using the QM9 dataset, a subset of the GDB-17 database containing 133,886 organic molecules with target properties like HOMO and LUMO gaps. The HOMO-LUMO gap was chosen as the target property due to its importance in describing molecular systems. Molecules in the QM9 dataset have HOMO-LUMO gaps ranging from 0.0245 to 0.6221. The ESOL dataset, a subset of 1,128 compounds, was used for qualitative analysis of aqueous solubility. Structural information in ESOL is provided by SMILES representation, ignoring hydrogen. MIAIE was implemented using PyTorch and DGL, with GAT having two graph attention layers and two fully-connected layers. In experiments, GAT with two graph attention layers and two fully-connected layers was used. Mean-based readout function generated graph-level embedding. MAE was the objective function with L2-regularization for model training. Adam SGD with a learning rate of 0.001 was the training algorithm. Additional molecular features were concatenated to improve prediction performance. Source code and experiment scripts are available for review. Based on the assumption that selected atoms are crucial for the target property, the gap between the original molecule and its sub-molecule will be small. AIEE is defined as the error in estimating atomic importance, calculated based on the target property value and sub-molecule size. DFT calculations accurately determine molecular properties, despite their computational demands. In this experiment, the effectiveness of MIAIE using AIEE was quantitatively evaluated on the QM9 dataset. Atomic importance was estimated using MIAIE with reverse self-attention, resulting in a small error of 0.00544 on AIEE for 13,889 test molecules in terms of HOMO-LUMO gap. This error is considered relatively small given the challenge of preserving molecular properties in original molecules. The error in splitting a ring-shaped molecule into sub-molecules is relatively large at 0.01007 compared to the mean error of 0.00544. This is due to the HOMO-LUMO gap being determined by overall electronic distributions in ring-shaped molecules with similar atoms. The limitation of the validation method is that each atom has similar importance, leading to inevitable errors. Future work could involve modifying the estimation step of MIAIE to address this issue. The study conducted a qualitative evaluation on the ESOL dataset to determine the important atom or group of atoms for aqueous solubility. The normalized atomic importance of the selected group of atoms by MIAIE was denoted. Three natural and two interesting estimation results were presented, including 2-Nitropropane and Metronidazole, where nitrogen and oxygen played a significant role. In Indoline, the selected group of atoms with the largest electronic charge improved reactivity to water. The selected group of atoms with the largest electronic charge improves reactivity to water, leading to chemically reasonable estimation results by MIAIE. Benfluralin has low aqueous solubility due to the C-CF3 group. MIAIE identified the C-CF3 group as crucial for solubility. Coumaphos showed the importance of the C-CO2 group over the PO3S group for solubility, supported by chemical reasoning. The MIAIE estimation results show that it can accurately estimate atomic importance in molecules, even without prior domain knowledge of chemistry and quantum mechanics. The symmetric structure of molecules was also tested, with MIAIE correctly identifying the atomic importance of structurally-equivalent groups. For example, Benfluralin and C24O4 molecules with symmetric structures had consistent atomic importance values assigned by MIAIE. The C24O4 molecule has a globally-symmetric structure, with MIAIE accurately estimating the importance of C-CO2 groups. This paper introduces a machine learning approach for estimating atomic importance in molecules using reverse self-attention and graph attention network. The method is efficient, fully-automated, and can estimate atomic importance without human experts. However, it can only estimate the importance of k-hop neighbor atoms. The proposed method can estimate the importance of k-hop neighbor atoms in molecules, but needs modification to handle groups of atoms with arbitrary shapes. Results show accurate capture of important atoms in molecules characterized by nitrogen or oxygen, but errors occur when sub-structures lacking double bonds are selected as important. A descriptor emphasizing key features of molecules is needed for improvement. A descriptor emphasizing bond-features is needed for molecules to improve accuracy in capturing important atoms."
}