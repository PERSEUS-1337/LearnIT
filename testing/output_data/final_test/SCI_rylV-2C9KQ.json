{
    "title": "rylV-2C9KQ",
    "content": "Deep neural networks, particularly convolutional neural networks, are effective for compressing images and solving inverse problems like denoising and inpainting. The deep decoder is a simple image model that can generate natural images with very few weight parameters, unlike traditional tools like wavelets. The deep decoder is a simple architecture with underparameterization that compresses images effectively, comparable to wavelet-based methods. Its simplicity and structure prevent overfitting, leading to state-of-the-art performance for denoising. Each layer consists of upsampling, linear combination, ReLU activation, and normalization, making it amenable to theoretical analysis and shedding light on effective signal representations in neural networks. Deep neural networks have shown superior performance in various imaging tasks such as compression and denoising compared to traditional image models based on expert knowledge. The success of deep networks is attributed to their ability to represent realistic images when trained on large datasets, utilizing learned representations via autoencoders and generative adversarial models. Recent success stories in using deep neural networks for imaging tasks highlight three common features: over-parameterization, convolutional structure, and training on large datasets. An exception is the deep image prior (DIP) algorithm by Ulyanov et al., which can solve inverse problems without training by fitting an over-parameterized network to a single image with strong regularization. This approach has shown competitive performance in various image restoration tasks. The proposed deep neural network model for image restoration performs well without a training dataset, relying on network structure and regularization. It can effectively denoise images and compress them using few parameters, suggesting an underparameterized model for natural images. The deep decoder model enables image compression, denoising, and solving inverse problems with state-of-the-art performance. It is under-parameterized, does not require training, and incorporates all assumptions on the data. The network maps a lower-dimensional space to a higher-dimensional space, similar to sparse wavelet representations, allowing for image compression by storing coefficients. The network in Section 2 demonstrates compression comparable to wavelet thresholding BID1, acting as a natural data model without requiring training or relying on regularization. It does not use convolutions but employs pixelwise linear combinations of channels with shared weights among spatial positions. The deep decoder network uses pixelwise linear combinations without spatial coupling like convolutions. It can represent natural images well and has denoising performance. The network is simple and can only fit a small proportion of noise. The paper introduces the deep decoder, a non-convolutional neural network that enables concise image representations. It demonstrates the performance of the deep decoder on various inverse problems such as denoising. The deep decoder is compared to state-of-the-art wavelet thresholding in terms of image representation. The deep decoder model, denoted by C, uses weights as parameters to generate concise image representations. By fitting the model to 100 randomly selected images from ImageNet, peak-signal-to-noise ratios are computed to evaluate image quality. The deep decoder model generates image representations using few parameters, compared to wavelet compression. For large compression factors, the deep decoder performs slightly better, while wavelets are better for smaller factors. This experiment demonstrates the effectiveness of deep neural networks in representing natural images with minimal parameters. The deep decoder is an effective image model for applications like solving inverse problems and lossy image compression through quantization of coefficients. Image representations are not sensitive to perturbations, showing no detrimental effect on image quality. Deep networks have been used for image compression before, but our work can compress images without any learning. The deep decoder can compress images without learning by transforming a tensor to an image using various operations like linear combinations, upsampling, ReLUs, and normalization. The network architecture can handle grayscale or RGB images with different channel dimensions. The deep decoder enables concise image representations comparable to wavelet-based compression. It consists of layers with a simple structure involving linear combinations, upsampling, ReLU nonlinearities, and channelwise normalization. The network's weights are contained in coefficient matrices, allowing for efficient image compression without the need for learning. The channel normalization operation in the tensor B i involves taking linear combinations of channels, followed by individual channel normalization using parameters \u03b3 and \u03b2. This method, a special case of batch normalization, improves model fitting similar to batch norm in deep neural networks. The operator U i performs bi-linear upsampling on input channels, with the last layer not being upsampled. The default network architecture is a 6-layer network with output images of dimensions 512x512 and 3 channels. The network parameters are given by C, and the output is solely dependent on C. The number of parameters in the deep decoder is a function of C, with N = dk2 + 2dk + 3k. For default architectures with d = 6 and k = 64 or 128, N = 25,536 (k = 64) and N = 100,224 (k = 128) out of an RGB image space of 786,432 parameters. Variations are possible, such as applying upsampling before the relu-nonlinearity for better results. The deep decoder's structure is similar to a convolutional neural network, with pixelwise linear combinations. The deep decoder utilizes pixelwise linear combinations similar to a convolutional neural network, but lacks spatial coupling of pixels. While other networks use convolutional layers with filters of nontrivial spatial extent, simulations show that linear combinations provide more concise representations of natural images. The deep decoder with convolutional layers uses filters of size p \u00d7 p, increasing the number of parameters and improving representation error. Comparing a deep decoder with p = 1 and k = 64 to one with p = 3 and k = 22, the former has a better representation. The deep decoder with p = 1 provides better image representation compared to larger spatial convolutions. It is used as a structure-enforcing model for denoising, super-resolution, and inpainting inverse problems. The image x is recovered from noisy observation y using the deep decoder by minimizing loss with respect to model parameters C. The optimization procedure aims to estimate the image x from observation y by minimizing loss with respect to model parameters C. The Adam optimizer is used, but gradient descent can also yield comparable results. The non-convex optimization problem may not reach a global minimum. The least-squares loss is considered, but the loss function can be adjusted for noise structure. Fitting an image model to observations for solving inverse problems is a common approach, not exclusive to deep decoder models. Various classical signal recovery methods fit this framework, such as compressive sensing with 1-norm minimization. The deep decoder is used for denoising by minimizing the least squares loss. It performs on-par with state of the art untrained denoising methods. The denoising problem is important in practice and serves as an entry point for understanding new methods. The deep decoder demonstrates denoising performance comparable to state-of-the-art untrained methods like Deep Image Prior (DIP) and BM3D algorithm. It can represent natural images well even when underparametrized, filtering out a significant proportion of noise while retaining most of the signal. The parameters of the deep decoder can be chosen based on the number of latent parameters. The deep decoder's parameters can be adjusted based on the number of latent parameters. A larger k reduces representation error but increases noise removal, while a smaller k does the opposite. The optimal k balances these errors, with larger noise levels requiring smaller k values or regularization. Super-resolution is achieved by using a forward model for downsampling. The deep decoder, with k = 128, outperforms bicubic interpolation and is comparable to the deep image prior for image reconstruction. It is also effective for inpainting tasks, although the deep image prior performs slightly better on average. The forward model f is defined by a mask that maps the inpainted region to zero. For the inpainting problem, a more expressive prior with k = 320 is chosen. Image restoration and recovery algorithms can be trained or untrained. The deep decoder image model is related to untrained methods like sparse representations in dictionaries. Successful image restoration schemes rely on structural assumptions about the image, such as exploiting self-similarity for denoising and super-resolution. Deep learning methods can be trained end-to-end for tasks like compression and denoising, or based on learning a generative image model. The Deep Image Prior (DIP) is an untrained method using an hourglass network architecture, similar to U-net, for solving inverse problems like compressed sensing, denoising, and blind deconvolution. It differs from the deep decoder in being over-parameterized and fixed weights after training. The Deep Image Prior (DIP) is highly over-parameterized and relies on regularization through early stopping and noise addition, unlike the deep decoder which does not require regularization. The DIP is a convolutional neural network, while the deep decoder is not. Comparing the two methods by denoising an image, the MSE is plotted over iterations for fitting the noisy image, showing the difference in performance. The deep decoder struggles to fit noise well even with many iterations, unlike the DIP which can. Due to under-parameterization, the deep decoder can only fit a small proportion of noise, enabling image denoising. The deep decoder struggles to fit noise well due to underparameterization, filtering out much of the noise when applied to a natural image. Early stopping is critical for denoising performance as it can only fit a small proportion of the noise. The deep decoder struggles to fit noise well due to underparameterization, filtering out much of the noise when applied to natural images. It can only fit a small proportion of the noise relative to the degree of underparameterization, with insights into how its components contribute to representing images. The deep decoder struggles to fit noise well due to underparameterization, filtering out much of the noise when applied to natural images. Proposition 1 states that the deep decoder can only fit a small portion of the noise energy, determined by its number of parameters relative to the output dimension. The deep decoder with linear or convex upsampling acts as a signal prior promoting piecewise smoothness. Upsampling is crucial for locality in the signal model, unlike convolutional neural networks. The choice of upsampling method affects the resulting signal estimates. The choice of upsampling matrices in the deep decoder strongly impacts the resulting signal estimates. Without upsampling, there is no locality in the image, making all pixels decoupled. Nearest neighbor upsampling results in piecewise constant patches in the output image. The choice of upsampling matrices in the deep decoder strongly impacts the resulting signal estimates. Linear and convex, non-linear upsampling methods affect the multiscale 'character' of the signal estimates. Linear upsampling results in squares of nearby pixels becoming identical, while convex upsampling captures coarse signal structure. The choice of upsampling matrices in the deep decoder strongly impacts signal estimates. Linear upsampling represents smoothly varying portions of the signal, while convex upsampling creates a fractal-like structure that hinders signal representation. The network input is fixed and chosen uniformly at random for incoherence. The deep decoder in the study is trained on an MRI phantom image, achieving a PSNR of 51dB. It is compared for denoising, superresolution, and inpainting tasks, with performance measured in PSNR. The network's ability to convert multiple noise channels into a structured output is highlighted. The deep decoder uses pixelwise linear combinations, ReLU activation functions, and upsampling to convert noise channels into a structured signal. It gradually builds up an image through successive approximations, different from a hierarchical representation. The deep decoder utilizes pixelwise linear combinations, ReLU activation functions, and upsampling to transform noise channels into a structured signal. It constructs an image through iterative approximations, deviating from a hierarchical representation. The network's architecture is detailed with matrix operations and diagonal matrices to define subspaces in R^n. The deep decoder uses pixelwise linear combinations, ReLU activation functions, and upsampling to convert noise channels into a structured signal. It constructs an image through iterative approximations, deviating from a hierarchical representation. The network's architecture involves matrix operations and diagonal matrices to define subspaces in R^n. The number of 2-dimensional subspaces of R^n is bounded by n^2k. The matrices {W0j} determine each subspace, with a limit of n^2k different sets of matrices. Lemmas 1 and 2 provide bounds on the matrices and noise projection onto subspaces. The deep decoder is not overly sensitive to perturbations of its coefficients. It uses pixelwise linear combinations, ReLU activation functions, and upsampling to convert noise channels into a structured signal. The network's architecture involves matrix operations and diagonal matrices to define subspaces in R^n. Lemmas 1 and 2 provide bounds on the matrices and noise projection onto subspaces. The deep decoder with 6 layers and k = 128 is relatively stable to perturbations in its coefficients, showing more sensitivity in higher levels. The weights of the network fitted to the Barbara test image are approximately Gaussian distributed."
}