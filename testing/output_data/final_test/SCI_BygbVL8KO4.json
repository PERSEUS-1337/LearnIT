{
    "title": "BygbVL8KO4",
    "content": "Generative Adversarial Networks (GANs) are used for modeling complex distributions, even when clean samples are not easily available. A novel framework called demixing-GAN is proposed to learn the structure of two components in a target distribution. This framework can generate clean samples from unknown distributions and separate structured signals observed in a superposition model. The separation problem arises when trying to separate two structured signals/components X and N under a superposition model. With enough structural assumptions, separation is possible, leading to denoising (estimating only X) or demixing (estimating both X and N). These techniques are crucial in signal/image processing, computer vision, machine learning, and statistics. Existing demixing methods rely on prior knowledge of the structures of X and N for signal recovery. In this paper, the problem of separating constituent signals from superposed observations is addressed in a fully unsupervised approach. The focus is on learning the prior knowledge about individual components from superposition samples and leveraging the learned constituent distributions for various tasks. In this paper, the focus is on using Generative Adversarial Network (GAN) based generative models to learn an unknown distribution and generate samples from it. Existing methods often assume known structures of sets X and N, which limits real-world applications. In this paper, the focus is on using Generative Adversarial Networks (GANs) as generative models to learn unknown distributions and generate samples. Previous methods assume known structures, but GANs offer a successful tool for generating high-dimensional signals without prior structure constraints. Generative Adversarial Networks (GANs) are effective for generating high-dimensional signals by mimicking the true underlying distribution, without requiring clean samples of the desired signal. GANs have been widely studied and used for capturing the structure of high-dimensional signals, particularly in solving inverse problems. Generative models like GANs are used for generating high-dimensional signals for inverse problems like sparse recovery and compressive sensing. BID4 shows that generative models are a good prior for structured signals, but BID26 proposes a gradient descent algorithm for direct recovery in the ambient space. The AmbientGAN framework addresses the recovery problem in the ambient space, showing theoretical guarantees and improved empirical results over BID4. However, it assumes known observation models and parameters, limiting real-world applications. Our contribution focuses on studying the demixing problem to overcome this limitation. Our framework is a purely unsupervised approach that addresses the demixing problem by learning the distribution of both components. It can be used for tasks like denoising without needing explicit samples from the corruption part. Unlike AmbientGAN, our framework can denoise unseen corrupted images, making it more versatile in real-world scenarios. Generative Adversarial Networks (GANs) are different from other density estimation methods like Variational AutoEncoders (VAEs) as they focus on generating samples from the target probability density function. GANs involve a game between a generator (G) and a discriminator (D) to produce fake samples and distinguish them from genuine ones. The optimization problem involves parameters \u03b8g and \u03b8d for the generator and discriminator networks, respectively. The hidden variables z are assumed to follow a uniform or standard normal distribution. The formulation can also use an identity function instead of log(.). The WGAN A formulation by A. et al. (2017) uses an identity function instead of log(.) in the optimization problem. It guarantees convergence of the generator output distribution to the target distribution. Modifications to the basic GAN setup allow for using GANs as a generative model for demixing structured signals. The main contribution includes learning the distribution of two components and leveraging the generating process for demixing mixed images. Theoretical insights are also provided. The GAN architecture is used for demixing two structured signals from their superposition. Two generators are fed with random noise vectors and their outputs are summed up before being fed to the discriminator. The mixed images consist of 64 MNIST binary images and a second component constructed by random sinusoidal signals. The demixing-GAN framework utilizes two generators to separate mixed samples into their constituent components, one being random sinusoidal signals. This approach is unsupervised, contrasting with AmbientGAN, and can be used for tasks like denoising. Trained generators can demix components in new test images not seen during training. The demixing-GAN framework uses trained generators to separate mixed samples into their constituent components, including random sinusoidal signals. This unsupervised approach can be applied to tasks like denoising and can demix new test images not seen during training by finding hidden representations corresponding to each component. The optimization problem involved in this process can be solved through alternative minimization. The demixing-GAN framework uses trained generators to separate mixed samples into their constituent components, including random sinusoidal signals. The optimization problem can be solved through alternative minimization, with regularizers helping to obtain good quality images and guide the gradient flow in the region of interest. Theoretical intuitions are provided for the demixing-GAN, where the superposition model is defined by Y = X + N. The demixing-GAN framework utilizes trained generators to separate mixed samples into their constituent components, such as random sinusoidal signals. The optimization problem is solved through alternative minimization with regularizers to obtain high-quality images. The superposition model is defined by Y = X + N, with the mini-max loss and optimal discriminator discussed in the context of GAN framework. The demixing-GAN framework uses trained generators to separate mixed samples into their constituent components. The optimization problem involves incoherence between two structures X and N, with the Fourier transform playing a key role. The incoherent condition for a well-conditioned equation is still under investigation, but it is conjectured that incoherence in both the signal and hidden space is crucial for successful demixing. The experiment section investigates the efficacy of the demixing-GAN framework in learning structured distributions and using generative models for inference tasks. Various experiments are conducted on different datasets including MNIST, Fashion-MNIST, and Quick-Draw Qui. The demixing-GAN is tested on Quick-Draw Qui, with experiments involving mixing MNIST digits with random corruption signals like sinusoidal waves and vertical/horizontal lines. Network architectures similar to DCGAN are used, consisting of convolutional layers with batch normalization. The proposed GAN architecture can learn and generate samples from two distributions using random vectors and lines. Despite some mode collapse, the generators can still produce samples from the constituent components, as shown in experiments mixing MNIST digits with random corruption signals. The proposed GAN architecture can generate samples of MNIST digits by learning from fixed random vectors. It can also create mixed images by superimposing digits 1 and 2 without experiencing mode collapse. The demixing-GAN performance is illustrated for the F-MNIST dataset. The demixing-GAN performance is demonstrated on the F-MNIST dataset, consisting of 60000 gray-scale images classified into 10 classes. The generators in InfoGAN architecture are used, similar to DCGAN, with a 62-dimensional input noise. The output samples from two generators show the evolution of learning dress and bag image distributions over 21 epochs. The trained generators in the InfoGAN architecture are tested for demixing on the F-MNIST dataset, focusing on dress and bag images. The performance is evaluated on test mixed images not seen during training, showcasing the ability to separate the two constituent components effectively. In a demixing scenario, the demixing-GAN is compared with Independent component analysis (ICA) on test mixed images. The goal is to separate a digit and a random sinusoidal from their sum using GAN trained on digit and sinusoidal distributions. The demixing-GAN is evaluated by comparing it with Independent Component Analysis (ICA) on mixed images. The GAN successfully separates two digits, while ICA fails. The quality of the recovered components is assessed using mean square error (MSE) and Peak Signal-to-Noise Ratio (PSNR) criteria. The performance of the demixing-GAN is then tested on the F-MNIST dataset. The demixing-GAN outperforms Independent Component Analysis (ICA) in separating mixed images from the F-MNIST dataset. While not exact, the recovered components are semantically similar to the ground-truth ones. The demixing-GAN performance is explored when separating digits 8 from MNIST dataset and dresses from F-MNIST dataset. The experiment results are shown in FIG2. Different generators are used for separating components, with varying training epochs. The demixing-GAN uses two generators trained for different objects, with input noise drawn uniformly. The first generator generates dress samples while the second outputs digit 8 samples. Performance is compared with ICA method for separating test images of digit 8 and dress objects, showing demixing-GAN outperforms ICA. The demixing-GAN outperforms the ICA method in separating images of digit 8 and dress objects. The Quick Draw Dataset, released by Google, consists of 50 million drawings in 345 classes. In the experiment, only face and flower images are considered from the dataset. The dataset used includes 16000 images of size 28 \u00d7 28 for each class, with mixed images of faces and flowers. One generator produces faces while the other generates flowers. A more challenging scenario involves mixed images of airplane shapes, selected randomly from the training set. In the airplane images, two structures are observed: simple ellipse-like shapes and more detailed drawings resembling airplanes from the Quick, Draw game. The demixing-GAN is able to separate airplane shapes into two types, even when both components are drawn from the same distribution. Different features in the shapes allow for demixing by creating incoherence between the components. After 31 epochs, both generators can distinguish between simple ellipse-like shapes and more detailed airplane drawings. In this section, the failure of the demixing-GAN is explored by focusing on the hidden space (z-space) and signal space (output of generators). When hidden vectors in z-space align, the generators cannot separate components. By feeding both generators the same vector, the output samples generated cannot distinguish between digits 8 and 2. After exploring the failure of the demixing-GAN in aligning hidden vectors in z-space, it was observed that when fed with aligned vectors, the generators were unable to separate the distribution of digits 8 and 2 in the output samples. The importance of having independent or close orthogonal vectors in the z-space for successful learning was highlighted. In experiments with demixing-GAN, the importance of vector alignment in z-space for successful learning was highlighted. Further investigation into this area is deferred for future research. An experiment with airplane images showed how rotations affected demixing in the generator space. The demixing-GAN was applied to airplane datasets, showing how rotation degrees affected the generators' evolution. Different rotations made demixing possible by making components incoherent from each other. The demixing-GAN framework was used to learn the structure of components in a superposition observation model. It was shown that distinguishable structures in images can be captured for demixing, and the underlying distribution of each component can be learned. Experimental simulations were conducted to explore the conditions under which the demixing framework fails."
}