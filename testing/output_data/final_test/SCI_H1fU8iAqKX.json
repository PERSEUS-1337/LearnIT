{
    "title": "H1fU8iAqKX",
    "content": "Recent work shows that convolutional neural networks (CNNs) can predict V1 activity more accurately than classical models. A rotation-equivariant CNN was used to categorize V1 neurons into groups based on similar computations, beyond just orientation selectivity and phase invariance. This approach was applied to a population of 6000 neurons in the mouse primary visual cortex, revealing common features extracted by V1 neurons. Our rotation-equivariant network outperforms a regular CNN in predicting neural activity of V1 neurons in the mouse primary visual cortex. This new tool helps study the nonlinear functional organization of the visual cortex, revealing common features shared by many V1 neurons. A functional classification of V1 neurons is essential for understanding its computations, similar to the retina. Recent work proposes learning functional cell types from data in an unsupervised manner. Neurons in V1 extract local oriented features, making it challenging to apply existing frameworks directly to neocortical areas. In this paper, the authors aim to define functional cell types in V1 by treating orientation as a nuisance parameter and learning features independent of orientation. They introduce a rotation-equivariant convolutional neural network model trained on responses of 6000 mouse V1 neurons. The model outperforms state-of-the-art CNNs for system identification and can predict V1 responses with only 16 learned features. The study aims to define functional cell types in V1 by learning features independent of orientation using a rotation-equivariant convolutional neural network model. The model, trained on responses of 6000 mouse V1 neurons, outperforms state-of-the-art CNNs and can predict V1 responses with only 16 learned features. Neurons can be accurately classified based on a small number of features, shedding light on the importance of certain known features of V1 computation under natural stimulation conditions. Recent work in the retina has shown a clear correspondence between anatomical and genetic cell types and their functional output, bringing us closer to understanding the function of each retinal cell type. Additionally, researchers are exploring the idea of learning a shared nonlinear feature representation for a large population of neurons. The idea of learning a shared nonlinear feature representation for a large population of neurons has been pioneered, with a focus on functional cell types and rotation equivariance in CNNs. Previous work has proposed a framework for unsupervised learning of cell types and enforcing a sparse representation to correspond to distinct functional cell types. This approach extends to V1 and includes group-equivariant CNNs for rotation equivariance. Our approach builds on the idea of rotation equivariance in CNNs, using 2D Hermite functions as steerable filters. Unlike RotEqNet, which applies orientation pooling, we maintain all feature maps as inputs for the next layer. Harmonic networks achieve full 360\u00b0 rotation equivariance by limiting the structure of convolutional filters. The network consists of a rotation-equivariant convolutional core and neuron-specific readouts, with static ImageNet images as inputs and V1 responses as prediction targets. The architecture of the network follows the idea of rotation equivariance in CNNs, using 2D Hermite functions as steerable filters. Weight sharing across filter orientations is utilized to achieve rotation equivariance, resulting in eight groups of feature maps. The network consists of a rotation-equivariant convolutional core and neuron-specific readouts, with static ImageNet images as inputs and V1 responses as prediction targets. The network architecture is based on rotation equivariance in CNNs, using 2D Hermite functions as steerable filters. Weight sharing across filter orientations achieves rotation equivariance, resulting in eight groups of feature maps. The model is trained end-to-end on predicting neural responses without transfer learning or pre-training on auxiliary tasks, emphasizing data efficiency and interpretability. The separation into convolutional core and readout pushes the heavy lifting into the core, while the readout weights provide a low-dimensional representation. The core of the network architecture is shared among thousands of neurons, allowing for accurate learning of complex non-linear functions. CNNs are shift-equivariant by construction, enabling representation of neurons performing similar computations in different locations. This property is beneficial for neural system identification. The rotation-equivariant CNN uses group convolutions to model populations of V1 neurons that extract similar features with different orientations. By incorporating rotations by multiples of 45 degrees, each convolutional filter in the first layer generates eight rotated copies, resulting in a total of 128 feature maps. This approach allows for learning representations equivariant to both translation and rotation. In the rotation-equivariant CNN, each convolutional filter in the second layer learns 128 filters to preserve rotation equivariance. Filters are represented in a steerable basis to share weights across filter orientation without aliasing artifacts. The study recorded responses of 6005 excitatory neurons in the primary visual cortex using a large-field-of-view twophoton mesoscope. Activity was measured with a calcium indicator, and cells were selected based on somata classifier. Cells were not filtered based on visual responsiveness, and the acquisition frame rate was 4.8 Hz. Visual stimuli consisted of 5500 images from ImageNet BID22, presented on a 55 \u00d7 31 cm screen at a distance of 15 cm. Each image was shown for 500ms followed by a blank screen. Neuronal activity was analyzed between 50ms and 550ms after stimulus onset using a Hamming window. Images were rescaled to 64 \u00d7 36 pixels for preprocessing. For preprocessing, images were rescaled to 64 \u00d7 36 pixels and standardized by subtracting the mean and dividing by the standard deviation. Neuronal responses were divided by their standard deviation over time. Model weights were initialized randomly, biases in batch normalization layers were set to zero, and biases in neuron readouts were set to a non-zero initial value. The models were optimized using the Adam Optimizer BID15 with a learning rate of 0.002 and early stopping. Validation loss was monitored every 50 iterations, with a decrease in learning rate if loss did not improve. Model evaluation involved computing Pearson correlation coefficients between predictions and average neuron responses over 20 repetitions of 100 test images. This approach assessed how well the model predicted neuron responses to stimuli, ignoring trial-to-trial variability. Our architecture consists of three convolutional layers with filter sizes of 13, 5, and 5 pixels. The receptive fields of the CNN's last layer's units were 21 px, covering both classical and extra-classical receptive fields. We use 16 filter sets in the first two layers and 8 to 48 filter sets in the third layer. Batch normalization is applied after each layer, with a soft-thresholding nonlinearity used after the first and second layers. The feature maps of the third layer provide input for each neuron's readout. Each neuron in the architecture implements a cascade of three LN operations, with regularization applied to convolution kernels and feature weights. Model selection involves cross-validation over the number of filter sets in the third layer. The study involved fitting multiple models with different hyperparameters and selecting the best one based on validation set performance. Baseline models without rotation equivariance were also tested using the same fitting procedure. In the study, various models were fitted with different hyperparameters, and the best one was chosen based on validation set performance. The feature weights in the readout were not enforced to be positive in the present work, unlike previous studies. A control experiment was conducted to enforce positive readout weights. The sparsity of spatial masks was justified due to localized receptive fields, but the desirability of sparsity on feature weights was uncertain. A model without the sparsity regularizer for feature weights was also tested. The network did not implement exact rotation equivariance in the experiments. In a subset of experiments, batch normalization was corrected to apply jointly to all rotated versions, showing no difference in model performance. 384 feature maps were the maximum fit into 16 GB of GPU memory. The rotation-equivariant CNN's performance was compared to controls and regular CNNs, with tools like DataJoint, Numpy/Scipy, Matplotlib, Seaborn, Jupyter, Tensorflow, and Docker used for analysis. Code to reproduce experiments and pretrained models is available. The rotation-equivariant CNN model achieved an average correlation of 0.47 on a dataset of 6005 neurons from the mouse primary visual cortex. The architecture included three convolutional layers with specific filter sizes and feature maps, with the third layer cross-validated for the number of features. Pretrained models and code for reproducing experiments are available at https://github.com/aecker/cnn-sys-ident. The model achieved an average correlation of 0.47 on the test set with 16 features in the third layer. This reduced the dimensionality significantly while maintaining performance. Rotation-equivariant CNN outperformed regular CNN in modeling V1 responses. Our rotation-equivariant CNN outperforms all baselines and requires less data, showing that weight sharing across orientations serves as a good regularizer for fitting a larger, more expressive model. The network learns common features of V1 neurons, as demonstrated by excluding half of the neurons during training and still achieving high test correlation. The rotation-equivariant CNN outperforms baselines, requiring less data and utilizing weight sharing across orientations as a regularizer. Excluding half of the neurons during training still resulted in high test correlation, showing that learned features transfer to unused neurons. Feature weights are sparse, with the spatial mask encoding receptive field locations and feature weights parameterizing nonlinear computations within a 16-dimensional function space. The organization of neurons within this space varies from random directions to discrete functional cell types, impacting the sparsity of feature weights. The feature weights in the rotation-equivariant CNN are maximally sparse, with most neurons using only 1-5 features. The strongest feature captures more than 50% of the energy for 63% of the neurons. An ablation study showed that sparsity is a property of the data, not just a result of the L1 penalty. The rotation-equivariant CNN has maximally sparse feature weights, with most neurons using only 1-5 features. The weights show consistent signs, indicating meaningful features beyond random placement. Neurons are grouped based on their features, showing a simple and accurate description of a large population of neurons. The rotation-equivariant CNN has maximally sparse feature weights, with most neurons using only 1-5 features. Neurons are grouped into 16 groups based on their strongest feature weight, providing a practical and compact description of V1 computation. The 16 groups represent features that cover more than 50% of the variance of a large fraction of neurons. The model is used to approximate the linear receptive field of the 16 most representative examples from each group. The plot shows the model gradient at a gray image, demonstrating rotation equivariance in V1 computation. Linear RFs resemble Gabor filters with differences in symmetry and polarity. A rotation-equivariant CNN model of V1 allows for studying computation independent of orientation preference. Weight sharing across orientations enables fitting larger models with a limited dataset. Future work will need to delve deeper into the learned features, test their generalizability across different conditions, and investigate if neurons in V1 cluster into distinct functional types with similarities in anatomical or genetic properties."
}