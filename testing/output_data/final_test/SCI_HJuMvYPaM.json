{
    "title": "HJuMvYPaM",
    "content": "In the search for more accurate predictive models, capsule networks are customized for diagnosing. Spectral Capsule Networks, a novel variation, converge faster than capsule networks with EM routing. They consist of spatial coincidence filters detecting entities based on feature alignment. Experiments show success in diagnosing tasks and faster convergence of spectral capsule networks. Advances in predictive modeling for healthcare aim to improve care quality through artificial intelligence. Models must identify risk factors and understand complex temporal interactions among symptoms and conditions. In the quest for more accurate predictive models in healthcare, capsule networks are tailored for diagnosing conditions. A new version called Spectral Capsule Networks shows faster convergence compared to EM-Capsules. These networks use spatial coincidence filters to detect entities based on feature alignment, improving diagnostic tasks. The goal is to enhance care quality by identifying risk factors and understanding complex temporal interactions among symptoms and conditions. Spectral Capsule Networks (S-Capsules) are proposed as an improvement over EM-Capsules for diagnosing conditions in healthcare. S-Capsules measure alignment of votes in a linear subspace, leading to faster convergence compared to EM-Capsules. Experiments on a diagnostic task using the MIMIC-III dataset show the success of capsule networks in healthcare. The proposed S-Capsules converge faster than EM-Capsules and show significant correlation with hand-engineered features. The task involves multivariate time series classification to predict patient diseases. Customized EM-Capsules and S-Capsules are compared in their forward pass steps, with the main difference in step 3. Capsules in both networks have activation and pose vectors. The proposed S-Capsules converge faster than EM-Capsules in multivariate time series classification for predicting patient diseases. Features are extracted using one-dimensional convolutions and residual blocks to create a 120-dimensional vector for processing by capsule layers. Primary capsules utilize dense residual networks to generate activation and pose components. Residual blocks are chosen for transformation operations due to the lack of formal understanding of data deformations in healthcare. The EM-Capsule network uses the EM-routing procedure with residual blocks for capsule computations in S-Capsule networks. Capsules in layer L + 1 compute weighted votes from layer L capsules using dense residual blocks, followed by singular value decomposition to obtain the pose vector for each capsule. The pose vector for capsule j is obtained through singular value decomposition of Y j = USV, with the activation computed using the singular values s k. The network is trained end-to-end with binary cross-entropy loss, and a skip connection from extracted features is added. In experiments, adding a skip connection from features in Step 1 to the last capsule layer improves performance. S-Capsules in Step 3 use a more efficient top-1 SVD, reducing computational cost. Activations and poses in Step 3 are inherently normalized, stabilizing training. Using variance preserved in the top singular value helps prevent capsule death in initial training phases. S-Capsules can handle larger learning rates and operate effectively in diagnosing benchmarks. The study focuses on diagnosing benchmarks using multivariate time series data from the MIMIC-III dataset. Data is divided into training/validation/test sets, preprocessed, and algorithms are trained using Adam with batch size 64. EM-Capsules and S-Capsules show convergence behavior in training batches, with improvements in binary cross entropy and micro-AUC. Model selection is done using a separate validation set, and intervals are obtained through bootstrapping on the test set. The study compares the performance of EM-Capsules and S-Capsules on diagnosing benchmarks using multivariate time series data from the MIMIC-III dataset. S-Capsules learn faster and generalize better, achieving a final AUC of 80.50%, outperforming EM-Capsules and deep GRU networks. The pose vectors of the output capsules are analyzed using hand-engineered medical features for continuous variables in the input time series. After analyzing the pose vectors of output capsules using hand-engineered features, it was found that 47.40% of the time the pose vector elements are significantly correlated with the features. This suggests that pose vectors capture variations in the input data, although the percentage should not be too high as hand-engineered features are not perfect summaries. Capsule networks with EM routing were customized for diagnosing tasks, and spectral capsule networks were proposed to improve stability and convergence speed. Spectral capsule networks, similar to EM-Capsules, improve stability and convergence speed by measuring agreement in a linear subspace. S-Capsules are compared to Gaussian Mixture Models and Principal Component Analysis. Results show superior convergence speed and preservation of data variations in pose vectors. Input time series length is 50 with dimension 78, featuring 3 layers of Conv1d Residual blocks for feature extraction, primary capsules, and output capsules with 40 capsules of dimension 15 and kernel width of 3. The S-Capsules architecture consists of 40 output capsules with dimensions of 15, utilizing residual blocks and spectral mapping for stability and convergence speed. The mapping between capsule layers is detailed in Section 2."
}