{
    "title": "ryxmb1rKDS",
    "content": "Symplectic ODE-Net (SymODEN) is a deep learning framework that infers the dynamics of a physical system from observed state trajectories. It incorporates Hamiltonian dynamics with control to learn transparently and draw insights about physical aspects like mass and potential energy. This framework offers interpretable, physically-consistent models for physical systems, enabling new possibilities for model-based control. Deep neural networks have become accurate and widely used in various domains like image recognition, language comprehension, and decision making. Learning approaches incorporate inductive bias to promote simple representations and guide the learning algorithm in choosing hypotheses. The success of predicting outcomes for unseen data depends on how well the inductive bias captures reality. Inductive bias can be introduced as a prior in a Bayesian model or through algorithmic choices. Incorporating physics-based inductive bias in neural networks can improve generalization by leveraging underlying physics in computation graphs. By using a generalization of Hamiltonian dynamics, a learning framework was developed to exploit this bias, leading to insights on physical properties like inertia and potential energy. This approach enables more accurate predictions of future behavior and enhances out-of-sample performance. Learning a physically-consistent model of dynamics allows for model-based controllers to provide performance guarantees for nonlinear systems. Understanding kinetic and potential energy can help synthesize control strategies like controlled Lagrangian and damping assignment methods. Neural networks have been used for identifying and controlling dynamical systems for over three decades, playing a critical role in controlling responses of systems like robotic manipulators and HVAC systems. Recent advances in deep neural networks have sparked renewed interest in learning dynamics of systems. Various approaches have been used, such as learning dynamics with control from high-dimensional observations, adopting a variational approach with recurrent architectures, and learning SE(3) transformations from point cloud data. However, existing work lacks consideration of physics-based priors. The main contribution of this work is introducing a learning approach that incorporates physics-based priors. The main contribution of this work is the introduction of Symplectic ODE-Net (SymODEN), a learning framework that encodes a generalization of Hamiltonian dynamics with an external control term. This allows for learning system dynamics that adhere to Hamiltonian dynamics with control, enabling the synthesis of controllers to track a reference configuration. Additionally, the approach combines physics-based priors with data-driven methods, accommodating non-Euclidean generalized coordinates in physical systems. SymODEN is designed to work with angle data in the embedded form, leveraging differentiable ODE solvers to avoid estimating second-order derivatives of generalized coordinates. Lagrangian and Hamiltonian dynamics provide insights into mechanics, describing a system's configuration with generalized coordinates moving in configuration space over time. Hamiltonian dynamics tracks system states in phase space using generalized coordinates and momenta. It treats q and p equally, leading to symmetric equations of motion and a new approach to classical mechanics. The Hamiltonian H(q, p) describes the time-evolution of a system, where it is often the total energy. The Hamiltonian dynamics describes the time-evolution of a system using generalized coordinates and momenta. It incorporates external control through a generalization of the Hamiltonian dynamics, allowing for the inclusion of forces and torques. The total energy is conserved along a trajectory of the system, and moving along the symplectic gradient keeps the Hamiltonian constant. The generalized dynamics allows for dissipation-free energy exchange with the environment, enabling the synthesis of controllers for driving the system to a reference configuration. By reshaping the energy landscape, nonlinear controllers can be synthesized with provable performance guarantees for fully-actuated systems. Potential energy shaping is a method used to synthesize controllers for fully-actuated systems by shaping the potential energy landscape. This involves creating a controller u(q, p) = \u03b2(q) + v(p) that mimics a desired Hamiltonian H d. The goal is to minimize the energy at a desired reference configuration, ensuring optimal system behavior. The system achieves the lowest energy at the desired reference configuration by adding a damping term. For underactuated systems, both potential and kinetic energy shaping are needed to drive the system to the desired configuration. The network architecture of Symplectic ODE-Net is introduced, with subsections detailing learning an ordinary differential equation with a constant control term and proposing a data-driven approach. In Subsection 3.3, a data-driven approach is proposed for dealing with embedded angle coordinates, leading to the introduction of SymODEN in Subsection 3.4 for learning dynamics on the hybrid space R^n x T^m. The focus shifts to learning the ordinary differential equation (ODE) from time series data, utilizing Neural ODE for approximating the right-hand side function with a neural network. This approach allows for predictions to be made by feeding the approximated function into an ODE solver. In practice, training a neural network with a large number of data points can be challenging due to prediction errors accumulating over time. To address this, weighting data points in a short time horizon more heavily than others is proposed. Introducing a hyperparameter called the time horizon \u03c4 allows for predicting future data points from initial conditions, improving the utilization of data in learning state-space models with Neural ODEs. The challenge in leveraging Neural ODE to learn state-space models is incorporating the control term into the dynamics. By using augmented dynamics and matching input and output dimensions, it becomes possible to feed the function into Neural ODE. This allows for training the model using different constant external forcing to get system responses and apply time-varying inputs. When using Neural ODE to learn state-space models, incorporating the control term into the dynamics is a challenge. By training the model with different constant external forcing, we can generate estimated trajectories. To efficiently learn the dynamics, we can design a network architecture using neural nets to represent the inverse of mass matrix, potential energy, and control coefficient. By incorporating the designed f \u03b8 (q, p, u) into Neural ODE, prior knowledge of Hamiltonian dynamics can be systematically added to end-to-end learning. In physical system models, state variables often involve angles within the interval [\u2212\u03c0, \u03c0), represented as a 2D embedding (cos q, sin q). Generalized momentum data is typically unavailable, with velocity being more common. The angle itself is often used theoretically, rather than the 2D embedding, due to considerations of both the Lagrangian and the system dynamics. Incorporating theoretical Hamiltonian dynamics into a data-driven approach, the goal is to learn the dynamics of x1, x2, and x3 using generalized coordinates. The Hamiltonian H(x1, x2, p) is a function of x1, x2, and p instead of q and p, evolving with the generalized Hamiltonian dynamics Equation (4). The function H(x1, x2, p) is expressed as a function of state variables and control (x1, x2, x3, u) for Neural ODE. Neural nets are used as function approximators. Generalized coordinates are treated as translational and angular coordinates in physical systems like robotics. The architecture combines generalized coordinates on R n \u00d7 T m, with data in the form of (x1, x2, x3, x4, x5, u) t0,...,tn = (r, cos \u03c6, sin \u03c6, \u1e59, \u03c6, u) t0,...,tn. Using three neural nets with Hamiltonian dynamics, a function f \u03b8 is obtained for Neural ODE. The mass matrix M is positive definite in real physical systems, ensuring positive kinetic energy. The derivative of M \u22121 \u03b8 1 (x1, x2) in Equation (17) can be expanded using chain rule. The positive definiteness of the mass matrix M \u03b81 is ensured by adding a small constant to its diagonal elements. Four tasks are used to evaluate the Symplectic ODE-Net model's performance, including pendulum and cart-pole systems. A variant model, Unstructured SymODEN, approximates the Hamiltonian using a fully connected neural net. The Unstructured SymODEN model does not utilize the structure of the Hamiltonian. Baseline models are set up for all experiments to demonstrate learning dynamics with fewer parameters by leveraging prior knowledge. Different baseline models are used for pendulum and other experiments involving angle data. Data is randomly generated for all tasks. Data was generated for various tasks by combining initial conditions of states with different constant control inputs. Trajectory data was generated by integrating dynamics for 20 time steps using simulators specific to each task. OpenAI Gym simulators were used for tasks involving embedded angle data and velocity, with some limitations due to the choice of numerical integration methods. For tasks involving Pendulum-v0, CartPole-v1, and Acrobot-v1 environments, RK4 numerical integrator was used to improve accuracy in modeling dynamics. Model training was done with Adam optimizer over 1000 epochs, with a time horizon of 3 and \"RK4\" integration scheme in Neural ODE. Training set size was varied by doubling from 16 initial states. In Neural ODE, the training set size was doubled from 16 to 1024 initial state conditions, each paired with five constant controls. Trajectories were generated by integrating dynamics 20 time steps forward. Train error per trajectory was logged as mean squared error over 20 time steps. Prediction error per trajectory was evaluated by integrating 40 time steps forward and calculating MSE. The study focused on using unforced trajectories with a constant control of u = 0.0 to avoid velocity fluctuations. The model described in Section 3.2 was used to predict trajectories and learned functions of SymODEN. The dynamics of the task were defined by a Hamiltonian with specific functions for M(q), V(q), and g(q). The ground truth trajectory was energy-conserved, while the baseline model's prediction was not. Both SymODEN and its unstructured variant predicted energy-conserved trajectories. The SymODEN model predicts energy-conserved trajectories with learned functions matching the ground truth well. The potential energy is relative, and only its derivative affects the dynamics. Training data is limited to q \u2208 [\u2212\u03c0, 3\u03c0], leading to poor extrapolation outside this range. To address this, embedded angle data is used. The dynamics are the same as Equation (25), with training data generated by the OpenAI Gym simulator. The SymODEN model synthesizes an energy-based controller without true p data, matching the ground truth with a scaling \u03b2. The dynamics of q are learned correctly even without access to the generalized momentum p, allowing for prediction and control. The desired Hamiltonian has minimum energy when the pendulum rests. The SymODEN model synthesizes an energy-based controller without true p data, matching the ground truth with a scaling \u03b2. The controller successfully controls the pendulum into the inverted position, even with extrapolation. The CartPole system is underactuated, requiring trajectory optimization or kinetic energy shaping for control. SymODEN can learn dynamics and make predictions in various systems, including the CartPole and Acrobot. It can control the systems to reach desired positions and provide accurate short-term predictions. Train error, prediction error, MSE, and total energy are evaluated for all tasks. The model's performance is shown to be consistent across different initial state conditions in the training set. SymODEN outperforms other models in generalization across tasks, showing better predictions by incorporating physics-based priors. It achieves better performance with smaller training datasets, indicating improved generalization with fewer samples. The evolution of MSE and total energy is depicted in Figure 6 for a trajectory with a new initial condition. SymODEN outperforms baseline models in conserving total energy and predicting future states accurately, especially with fewer training samples. It incorporates Hamiltonian dynamics and control into deep learning, providing a systematic approach for better predictions. SymODEN utilizes interpretable state-space models and physics-based priors to learn dynamics of physical systems. It can handle embedded angle data and velocity information. Future work may explore different types of embeddings and combining energy shaping control with end-to-end learning frameworks. The architecture used in experiments has the lowest number of parameters to ensure smooth learned functions. The architectures shown below are fully-connected neural networks with different numbers of parameters. The Tanh activation function is used to ensure smooth learned functions and avoid discontinuities in derivatives. Task 1 involves a Pendulum with 2 state dimensions and 1 action dimension, while Task 2 includes embedded data with 3 state dimensions and 1 action dimension. Various models are compared based on their parameter counts and layer dimensions. The curr_chunk discusses different baseline models for various tasks involving CartPole and Acrobot environments, each with different state dimensions and action dimensions. The models vary in the number of parameters and layer dimensions, utilizing Tanh activation functions for smooth learned functions. The energy-based controller in Hamiltonian Neural Networks (HNN) utilizes a form with potential energy shaping and damping injection terms. The controller can be seen as a PD controller with an additional energy compensation term, providing proportional and derivative control. In SymODEN, true gradients or gradient approximations are not necessary as the estimated gradient is integrated using differentiable ODE solvers. An ablation study of the differentiable ODE Solver is performed to compare the performance of HNN and Unstructured SymODEN, both approximating the Hamiltonian with neural networks. The time horizon \u03c4 = 1 is set for the finite difference estimate of the gradient. In HNN, the initial conditions of trajectories are generated randomly in an annulus, while in this study, they are generated uniformly in a reasonable range. The authors of HNN may have chosen the annulus data generation due to the lack of an angle-aware design, as trajectories may go beyond certain angles without it. The study compares the performance of Unstructured SymODEN and HNN models in predicting trajectories. Unstructured SymODEN outperforms HNN due to the symplectic gradient training loss, leading to lower error accumulation. This difference is illustrated in Table 1 and Figure 7, showing better results for Unstructured SymODEN. In Figure 7, the MSE and total energy of a specific trajectory are compared between Unstructured SymODEN and HNN models. Unstructured SymODEN shows lower MSE than HNN, which periodically touches zero but does not indicate accurate predictions. HNN's energy drifts due to inaccurate finite difference approximation. The choice of RK4 solver is preferred over Euler and \"dopri5\" adaptive solver due to similar error results and faster training time. In our experiments, we found that longer time horizons lead to better models, as they penalize worse long term predictions. However, longer time horizons also require more training time. We trained SymODEN on fully actuated versions of Cartpole and Acrobot, and our future work includes incorporating the control of underactuated systems into the end-to-end learning framework. The experiments showed that longer time horizons improve model performance but require more training time. SymODEN was trained on fully actuated Cartpole and Acrobot systems. The results demonstrate successful control of the pole and cart, as well as the Acrobot from downward to upward positions. The upward position may not have been included in the training data. Statistics on train, test, and prediction errors per trajectory are provided for all tasks. The test errors are based on 64 unseen initial state conditions and 5 constant inputs, with each trajectory containing 20 steps. Prediction error is based on the same 64 initial state conditions during training."
}