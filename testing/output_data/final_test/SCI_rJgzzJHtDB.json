{
    "title": "rJgzzJHtDB",
    "content": "Deep networks face a trade-off between accuracy and robustness. Increasing model capacity can help achieve a balance but comes with challenges for resource-constrained applications. This paper explores multi-exit networks for efficient inference, aiming to optimize model accuracy, robustness, and efficiency simultaneously. Our proposed solution, Robust Dynamic Inference Networks (RDI-Nets), allows inputs to adaptively choose output layers for predictions, enhancing accuracy and robustness while saving computational resources. Deep networks are vulnerable to adversarial attacks despite their high predictive accuracy. Defense methods to increase robustness often compromise accuracy on clean images. Tsipras et al. (2019) highlighted the trade-off between adversarial robustness and standard accuracy in deep networks. The accuracy-robustness trade-off was theoretically quantified in terms of risk for adversarial versus non-adversarial examples. The number of samples needed for adversarially robust generalization is significantly larger. The trade-off between accuracy and robustness in deep networks is a significant factor, as highlighted by various studies. The complexity of a robust classifier must be higher than that of a standard classifier, suggesting that a larger-capacity classifier could alleviate this trade-off. Increasing training data or using a larger-capacity model may lead to a \"win-win\" situation in balancing accuracy and robustness. Deep networks face challenges in being deployed on resource-constrained platforms due to the rise of IoT devices. The paper aims to achieve a triple-win by creating an accurate and robust classifier while keeping it efficient through input-adaptive routing. This approach reduces computation loads and introduces input-adaptive dynamic inference for efficiency. The paper introduces an efficient inference scheme called input-adaptive routing for deep networks, enhancing adversarial defense. By augmenting deep network backbones with multiple early-branch output layers, the model can adaptively choose the output layer for each input, terminating inferences early with high confidence. This approach provides flexibility in composing attacks and defenses compared to single-loss backbones. The study explores white-box attacks and defenses for adaptive multi-output models. The study presents Robust Dynamic Inference Networks (RDI-Nets) for white-box attack and defense on a multi-output network with adaptive inference. The RDI-Nets framework enables dynamic inference by adaptively selecting branches for clean or adversarially perturbed images, achieving better accuracy and robustness with over 30% computational savings compared to existing solutions. The study introduces Robust Dynamic Inference Networks (RDI-Nets) for white-box attack and defense on multi-output networks. Existing defense approaches have been evaded by new attacks, but adversarial training remains a strong defense algorithm. However, most attacks and defenses focus on single-output models, with limited research on more complex networks with multiple outputs. Some related works explore model ensemble in adversarial training for improved defense. Ensemble methods in adversarial training offer benefits of diversity and increased model capacity, but can also increase inference complexity. Injecting randomization at inference time can help mitigate adversarial effects. However, non-random, input-dependent inference for defense has not been extensively studied. Research on improving deep network efficiency can be static, with compact models, or dynamic, where inputs can choose. Many compact architectures have been designed for resource-constrained applications, utilizing lightweight convolutions and model compression techniques such as sparsification and structured pruning. Layer factorization, quantization, and weight sharing have also shown effectiveness in improving deep network efficiency. Recent studies have explored the relationship between deep learning robustness and efficiency. Sparse deep networks with appropriately sparsified weights improve robustness, while over-sparsification makes the model more fragile. Compressed models also show that the relationship between model size and robustness depends on compression methods and can be non-monotonic. Activation quantization may reduce robustness but can be effective with continuity constraints. These methods offer new approaches to enhancing the robustness of compact and compressed models. The proposed RDI-Nets address robustness through dynamic input-adaptive inference, outperforming static methods. By applying dynamic inference on top of static methods, further improvements in robustness and efficiency can be achieved. RDI-Nets reduce computation loads through input-adaptive routing, offering a unique approach to enhancing model efficiency. RDI-Nets are multi-output networks designed for efficient, input-adaptive inference. They utilize side branches appended to deep networks to allow for early-exit predictions, reducing computation loads and improving model efficiency. The final prediction is chosen from the set of predictions via a deterministic strategy. RDI-Nets use a nested weight-sharing mechanism and a deterministic strategy for selecting the final output based on confidence thresholds for early-exit predictions. This progressive and early-halting mechanism saves computation for easier-to-classify samples during both training and inference. The training objective involves minimizing a hybrid loss for each exit. RDI-Nets aim to minimize a hybrid loss of accuracy and robustness for each exit, with balanced weights for K + 1 exits. Details on RDI-Net structures, hyperparameters, and inference branch selection can be found in Appendices 7.1, 7.2, and 7.3. Three ways to generate adversarial images in RDI-Nets are discussed, along with their defenses against white box attacks. Attack forms for an N-output network are considered, independent of attacker algorithms like PGD, C&W, and FGSM. The single attack maximally fools one output, while the average attack maximizes the average of all losses to ensure effectiveness regardless of the output chosen. The max-average attack emphasizes individual output defense strength by balancing between \"commodity\" and \"specificity\" constraints. It increases the averaged loss values from all outputs and maximally fools one individual output, selected from a collection of single attacks. This attack form is used in adversarial training as a defense framework. Adversarial training uses different attack forms to generate adversarial images for training augmentation. Evaluation metrics include Testing Accuracy (TA), Adversarial Testing Accuracy (ATA), and Mega Flops (MFlops). Three CNN models are evaluated on popular datasets. The three CNN models evaluated on popular datasets are defended by adversarial training. RDI-Nets are built by adding side branch outputs to each backbone, resulting in RDI-SmallCNN, RDI-ResNet38, and RDI-MobileNetV2 models. The RDI-Nets models, including RDI-SmallCNN, RDI-ResNet38, and RDI-MobileNetV2, are evaluated with various attacker algorithms to measure their defense against attacks. Different attack forms result in multiple ATA numbers for each defended model. Adversarial training is used to augment training and defend against attacks, with three defense schemes being adopted by default. The RDI-Nets models are evaluated with different attacker algorithms to measure their defense against attacks. Adversarial training is used to augment training with three defense schemes by default. The MNIST experimental results on RDI-SmallCNN show that undefended models are easily compromised by all attack forms, while the Main Branch defended model achieves the best ATA against the same type of attack. The RDI-Nets models are evaluated with different attacker algorithms to measure their defense against attacks. Adversarial training is used to augment training with three defense schemes by default. The Main Branch defended model boosts the closest output branch's robustness but degrades defense on further-away Branch 1. Both Average and Max-Average defenses achieve good TAs and ATAs against all attack forms, with Max-Average slightly better. RDI-SmallCNN with Max-Average defense outperforms SmallCNN defended by PGD-based adversarial training in terms of TA and ATA, with 34.30% computational savings. Defense forms do not significantly alter inference efficiency, saving around 34%-36% MFlops compared to the backbone. The Max-Average defense in RDI-Nets achieves higher TAs and ATAs compared to the defended ResNet-38 and MobileNet-V2 backbones on the CIFAR-10 classification task. It outperforms the Average defense in defending against average attacks, suggesting that averaging all branch losses may diminish useful gradients. The ATA (Worst-Case) of RDI-ResNet-38 surpasses that of ResNet-38 defended by PGD-adversarial training by 1.03%, while saving around 30% inference budget. Different defenses on CIFAR-10 have notable impacts on performance. The Max-Average defense in RDI-Nets achieves higher TAs and ATAs compared to other defenses on CIFAR-10, showing notable impacts on computational saving. Stronger defenses require inputs to pass through more layers before making confident predictions. Visualization of RDIResNet38's exiting behaviors reveals interesting observations, such as the routing behaviors of different defenses for clean and adversarial examples. Max-Average defense shows more uniform usage of multiple outputs, especially for adversarial examples. Our proposed approach, RDI-Net with Max-Average defense, achieves higher ATAs (> 2%) and TAs compared to strong pruning + defense baseline on CIFAR-10. By compressing the network with a state-of-the-art method and then defending it using PGD-10 adversarial training, we consistently achieve better results at similar inference costs. RDI-ResNet-38 outperforms ATMC algorithm in terms of ATA by 0.3% at comparable MFlops. RDI-Nets show better generalized robustness against various attackers, including FGSM and WRM. The approach is inspired by ensemble defense strategies for improving accuracy and robustness. The success of ensemble defense in improving accuracy and robustness aligns with the model capacity hypothesis. A multi-output network can be decomposed into single-output models with weight re-using enforced among them, making it more compact. This calibrated ensemble diversity versus efficiency results in a defended multi-output network inheriting strong accuracy/robustness while keeping inference cost lower. The efficiency gains do not contradict the belief that a more accurate and robust classifier requires a larger model capacity. The paper introduces RDI-Nets, a multi-output network with input-adaptive dynamic inference for adversarial defense. It aims to achieve high accuracy and robustness while reducing inference costs. RDI-Nets achieve better accuracy, stronger robustness, and around 30% inference computational savings. The RDI-Nets utilize a network architecture with four convolutions and three full-connected layers, trained for 13100 iterations with a batch size of 256. The learning rate is adjusted during training. Adversarial defense/attack involves 40-steps PGD with specific perturbation and step sizes. ResNet-38 and MobileNetV2 are used as backbone architectures, with different learning rate schedules. The learning rate for RDI-MobileNetV2 is set at 0.05 and decreased at specific iterations. Hybrid loss weights are defined for RDI-ResNet38 and RDI-MobileNetV2. Adversarial defense/attack parameters include perturbation and step sizes. RDI-Nets architecture involves appending branch classifiers at equidistant points. Entropy is used for prediction confidence measurement. The entropy of vector y in R^C is defined with a small constant. To perform fast inference on a (K+1)-output RDI-Net, K threshold numbers are determined for each branch classifier. Thresholds are adjusted to give middle branches slightly more contribution. Threshold numbers for RDI-SmallCNN, RDI-ResNet38, and RDI-MobilenetV2 are set. Performance comparison between RDI-Net and pruning + defense baseline is shown in Figure 6. The size of the model is proportional to its MFlops, with \u03b3 as the sparsity trade-off parameter. Results against FGSM and WRM attackers are reported in Tables 8 and 9."
}