{
    "title": "BkgWHnR5tm",
    "content": "Despite recent advancements in robotic locomotion control, robot design still heavily relies on human engineering. Automatic robot design faces challenges due to the large search space and difficulty in evaluating candidates. To tackle these issues, Neural Graph Evolution (NGE) is proposed, utilizing graph neural networks for control policies and incorporating Graph Mutation with Uncertainty (GM-UC) to balance exploration and exploitation. NGE significantly improves the efficiency of automatic robot design. NGE significantly outperforms previous methods by an order of magnitude in automatically discovering kinematically preferred robotic graph structures, such as a fish with two symmetrical flat side-fins and a tail, or a cheetah with athletic front and back legs. It efficiently solves searching problems within a day on a single 64 CPU-core Amazon EC2. NGE significantly outperforms previous methods in automatically discovering kinematically preferred robotic graph structures. Robot design aims to find optimal body structures and locomotion for a given objective in an environment. Automatic robot design faces challenges due to the large search space and expensive evaluation of designs. Evolutionary robots often require heavy engineering and human guidance. Automatic robot design algorithms, such as evolutionary, genetic, or random structure search, have been used in pioneering works to evolve robot structures. However, these algorithms struggle to create kinematically reasonable structures due to the large search space and inefficient candidate evaluation. Similarly, automatic neural architecture search also faces challenges in evaluating a large combinatorial search space. Various approaches, such as Bayesian optimization and reinforcement learning, have been proposed to address these issues. In this paper, an efficient search method for automatic robot design, Neural Graph Evolution (NGE), is proposed. NGE co-evolves both the robot design and control policy, unlike recent reinforcement learning work. The approach aims to maximize validation accuracy by evolving recurrent neural networks (RNNs) and convolutional neural networks (CNNs) using reinforcement learning and genetic algorithms. Weight sharing among candidates in the search space helps speed up the architecture search process. NGE formulates automatic robot design as a graph search problem using graph neural networks (GNN) as the controller to maximize agent performance. It iteratively evolves new graphs guided by the learnt GNN controller, sharing weights between controllers to reduce computation time. Key contributions include formulating robot design as a graph search problem and utilizing GNNs for efficient candidate structure evaluation. NGE automates robot design through graph search using GNNs to enhance agent performance. A mutation scheme balances exploration and exploitation, incorporating model uncertainty. Results show NGE outperforms random graph search and naive evolutionary structure search. In RL, the problem is framed as a Markov Decision Process, aiming to maximize total expected reward. In this paper, PPO is used to train RL agents to evaluate robot structures. PPO optimizes a surrogate objective function and iteratively generates samples to solve the problem. GNNs are increasingly used in locomotion control to enhance controller transferability. The use of GNNs in locomotion control has significantly improved controller transferability. A GNN operates on a graph with nodes and edges denoted as u \u2208 V and e \u2208 E. Each node in the GNN receives input features and produces outputs at a node level. The GNN performs internal propagations within each timestep, allowing nodes to communicate with neighbors and update their hidden states. The message sent to neighbors is computed using a specific formula. In locomotion control, GNNs operate on a graph with nodes and edges. Nodes communicate with neighbors using specific formulas to update their hidden states. Robot design components can be represented as nodes connected by edges, naturally forming a graph structure. The robot design is represented by a graph, with nodes and edges representing physical body components. Each robotic design is represented by an undirected graph G = (V, E, A), where V is the collection of body nodes and E is the edges. The mapping A : V \u2192 \u039b assigns structural attributes to each node u \u2208 V. The controller is a policy network parameterized by weights \u03b8, forming a species denoted as \u2126 = (G, \u03b8). The robot design is represented by a graph, with nodes and edges representing physical body components. Each robotic design is a species denoted as \u2126 = (G, \u03b8). NGE evaluates a pool of species in each iteration, with a process called Policy Sharing (PS) for efficiency. NGE performs population-based optimization through mutation, evaluation, and selection, with details on objective and performance metrics introduced. The policy involves eliminating species with the worst fitness and mutating new species using Graph Mutation with Uncertainty (GM-UC). Policies are efficiently inherited through Policy Sharing. The method is outlined in Algorithm 1. Fitness represents the performance of a given graph using optimal controller parameters, which are impractical to obtain due to computational expense and training time. In robotic design, local-optima are difficult to detect as it is hard to tell whether the controller has converged or has reached a temporary optimization plateau. Learning the controllers is a computation bottleneck in optimization. Our work enables transferability between different topologies of NGE, introducing amortized fitness (AF) as the objective function across generations for NGE. AF is defined in the following equation. Our work focuses on optimizing parameters inherited from parent species in robotic design. We use reinforcement learning to train policy network parameters, with a GNN as the controller. Input state vectors are parsed into graphs, nodes fetch observations, and features are extracted. The propagation model involves encoding features and attribute information into node inputs, performing internal propagation steps, and using aggregation and update functions for message passing. The propagation model involves encoding features and attribute information into node inputs, performing internal propagation steps, and using aggregation and update functions for message passing. The output model defines controller nodes as F with Gaussian distributions on each node's controller. The policy distribution of the agent is optimized with PPO. Graphs evolve from parents to children with mutation primitives like Add-Node operation. The M 2 (Add-Graph) operation speeds up evolution by reusing subtrees in the graph. M 3 (Del-Graph) removes body parts, while M 4 (Pert-Graph) perturbs node parameters with Gaussian noise. Examples of fish mutations are visualized in FIG0. To enhance evolution, a GNN predicts graph fitness and guides mutation operations. The model regresses AF score using attribute embeddings, updating weights with L2 loss after each generation. Greedy species pruning risks overfitting to existing species. Graph Mutation with Uncertainty (GM-UC) based on Thompson Sampling is proposed to balance exploration and exploitation in species selection. GM-UC selects the best graph candidates by considering the posterior distribution of the surrogate model. Dropout is used during inference to approximate sampling from the model posterior. At the end of each generation, new species are randomly mutated from surviving species. Policy Sharing (PS) is proposed to reuse old weights from previous graphs for transferability of GNNs. Policy Sharing (PS) is introduced to reuse old weights from parent species in Neural Graph Evolution (NGE) to provide strong weight initialization for new species. This approach aims to prevent domination by ancient species and allows for easier evolution across different graphs in GNNs. Previous methods like naive evolutionary structure search (ESS-Sims) or random graph search (RGS) lack the ability to reuse controllers when the graph structure changes due to differences in parameter space. In Neural Graph Evolution (NGE), the parameter space for \u03b8 may change, affecting transfer learning success. Old species in generation j are denoted as (\u03b8 G , G ) for NGE. The effectiveness of NGE is demonstrated on various evolution tasks, including optimizing body structure from scratch and human-engineered species. An ablation study on GM-UC and computational cost/generation size is also provided. The study focuses on Neural Graph Evolution (NGE) and includes an ablation study on GM-UC and computational cost/generation size. Experiments are conducted in MuJoCo using environments like Fish Env and Walker Env. Baselines are compared to validate the effectiveness of NGE, with a grid search on hyper-parameters. The study explores the use of ESS-Sims-AF in robotic design, replacing evolutionary strategy with PPO and using a 3-layer MLP. The goal is to investigate the impact of GM-UC without a structured model like GNN and determine the necessity of GNN. Both unstructured models like MLP and structured models are tested in the Random Graph environment. In the experiment, the task is to evolve the graph and controller from scratch for fish and walker species. A comparison is made with a Random Graph Search baseline, showing that NGE outperforms RGS in efficiently searching the space of G. The computation budget is the same for all methods, and hyper-parameter grid search is conducted. NGE is found to be the best model in both environments. The genealogy tree generated using NGE for fish shows the reward for each node. NGE agents develop symmetrical side-fins over generations, outperforming AF and GM-UC on ESS-Sims. ESS-Sims and its variants tend to overfit to local species. ESS-BodyShare suggests that structured graph models without message passing may be insufficient for environments requiring global features. Our model visualizes the genealogy tree of fish, showing the evolution of three fins. The algorithm is the first to discover robotic graph structures automatically. Fine-tuning tasks verify NGE's ability to improve upon human-engineered designs, with experiments on graph topology and node attributes. Evolving every species from scratch is costly, so starting with a human-engineered robot is common practice. In experiments with NGE, fine-tuning both attributes and controllers leads to better performance compared to training controllers only. The evolution process results in transformations such as a cheetah's forefoot turning into a claw and a 3D-fish adjusting its fins and tail. Unconstrained fine-tuning with NGE generally improves performance but may not preserve initial structures. Additionally, applying Graph Mutation with Uncertainty enhances performance in the evolution graph search task, outperforming the baseline in fish and walker environments. The proposed GM-UC algorithm improves exploration in graph space. Increasing generation size in NGE shows marginal improvement in the Fish task. NGE is effective with limited computing resources, outperforming RGS and ES with a small generation size of 16. The NGE algorithm for automated robot design co-evolves robot design graph and controllers, reducing evaluation cost and exploring search space effectively. It outperforms random graph search and evolutionary strategy, discovering meaningful robot designs and improving final performance and computation time significantly. This work is a crucial step towards automated robot design and may be beneficial for other graph search problems. The NGE algorithm co-evolves robot design graph and controllers, improving final performance significantly. NerveNet++ model proposes effective modifications to BID37, enhancing robustness and transfer learning ability. Truncated graph inspired by BID22 reduces computational cost by avoiding full back-propagation graph. In NerveNet++, a propagation model with memory state is proposed for evolutionary search or population-based optimization. The truncated graph back-propagation optimizes the policy, saving memory and time consumption. The memory state depends on previous actions, observations, and states, allowing for a flexible number of propagation steps. The full back-propagation graph is computationally intensive due to its length matching the episode length. The authors propose a back-propagation optimization method with a defined length \u0393 for RL agents in BID22. By truncating the back-propagation graph, negligible accuracy loss occurs, and the optimization objective is updated accordingly. The optimization procedure follows a variant of PPO, leading to the evolution of a walking agent into a cheetah-like structure with high speed, as shown in FIG13. The authors propose a back-propagation optimization method with a defined length \u0393 for RL agents in BID22, leading to the evolution of a walking agent into a cheetah-like structure with high speed. Different species are generated by NGE, ESS-Sims, and RGS, with ESS-Sims-AF showing the best performance. Resetting weights for all species forces fair competition, aiding exploration and ultimately resulting in higher rewards, albeit with a longer convergence time. In the graph search task in FIG5, results without controller-resetting are excluded. A qualitative comparison between algorithms in Figure 9 shows our method's stronger dominance in structure and reward. All methods have equal computation budget, with the same number of total timesteps generated by all species for all generations. For example, NGE can evolve for 200 generations with a species size of 64, using 10 training epochs with 2000 sampled timesteps each. Thompson Sampling is a heuristic search strategy used in the graph search problem to balance exploration and exploitation by selecting actions based on their probability of being optimal. It helps in selecting the best graph candidates at each round according to the expected estimated fitness using a surrogate model. Thompson Sampling is a heuristic search strategy used in the graph search problem to balance exploration and exploitation by selecting actions based on their probability of being optimal. It helps in selecting the best graph candidates at each round according to the expected estimated fitness using a graph neural network (GNN) surrogate model. The GNN predicts the average fitness of a graph as a Gaussian distribution, and the weights are trained for this prediction task. Thompson Sampling is similar to greedy search but samples model parameters at each generation to take actions. Dropout during inference approximates Thompson Sampling by sampling from the model posterior. Training policies and models with dropout is key in this process."
}