{
    "title": "SygeY1SYvr",
    "content": "We propose Centroid Networks as a new method for few-shot classification on benchmarks like Omniglot and miniImageNet, where class semantics are too similar. Our approach achieves high accuracies without using labels at meta-evaluation time. The Meta-Dataset, a more challenging benchmark, is introduced for supervised few-shot classification. We also introduce the Class Semantics Consistency Criterion to quantify the difficulty of Meta-Dataset. Supervised few-shot classification involves learning a classifier from a small number of examples, eliminating the need to label large datasets. It is typically formulated as meta-learning on episodes with support and query sets. Centroid Networks is shown to be faster and more accurate than a state-of-the-art learning-to-cluster method. The Omniglot and miniImageNet benchmarks are commonly used for evaluating few-shot classification methods, but they may not be ideal gold standards due to consistent class semantics. This consistency makes the benchmarks too \"easy\" as classes remain the same between meta-training and meta-evaluation. Supervised few-shot classification methods may struggle to adapt to changing class semantics, which is a desirable feature for applications like organizing personal photo galleries. The consistency of class semantics in benchmarks like Omniglot and miniImageNet makes them too \"easy\" for evaluation. The Centroid Networks method achieves high accuracies on Omniglot and miniImageNet without using labels at meta-evaluation time. This suggests that few-shot learning algorithms may not need labels when class semantics are consistent. The Meta-Dataset is a challenging few-shot classification benchmark where class semantics vary across episodes. Centroid Networks are proposed to benchmark the difficulty of this dataset. Centroid Networks are proposed to benchmark the difficulty of the Meta-Dataset by comparing their performance with Prototypical Networks. They outperform a state-of-the-art learning-to-cluster method and achieve high accuracies on Omniglot and miniImageNet without using labels at meta-evaluation time. This highlights the need for harder benchmarks in few-shot classification. Supervised clustering methods like structured SVM and K-Means are used to learn similarity metrics and cluster items. Our work differs by using a nonlinear embedding function compared to linear embeddings in previous studies. Recent deep learning literature has shifted towards the term \"learning to cluster\" instead of \"supervised clustering\", focusing on learning a similarity metric using deep networks. Hsu et al. (2017) introduced a Constrained Clustering Network (CCN) for this purpose, achieving state-of-the-art results by learning a similarity metric and optimizing a neural network for cluster assignments. In recent deep learning literature, there is a shift towards \"learning to cluster\" using deep networks. Constrained Clustering Networks (CCNs) have achieved state-of-the-art results by learning a similarity metric and optimizing neural networks for cluster assignments. Centroid Networks improve upon CCNs in benchmarks, offering simpler training and lower computational costs. Semi-supervised clustering involves clustering data with some supervision, while supervised few-shot classification tasks can be compared to unsupervised few-shot classification methods. The curr_chunk discusses the comparison of Centroid Networks with Prototypical Networks and Semi-Supervised Prototypical Networks. It introduces the concept of Sinkhorn K-Means and its relation to minimizing Wasserstein distance. The work also mentions the theoretical links between K-Means and Wasserstein-2 distance, highlighting the similarities with Regularized Wasserstein-Means. The curr_chunk introduces the Sinkhorn K-Means algorithm for clustering, which is not found in existing literature. It clarifies the distinction between Sinkhorn K-Means and Wasserstein K-Means, emphasizing its application in learning to cluster complex datasets like miniImageNet. The work also discusses the combination of unsupervised learning and meta-learning in recent research. The curr_chunk proposes a method for meta-training an unsupervised representation learning model for clustering tasks. It contrasts with previous work on meta-learning that requires labels for meta-training but not at evaluation time. The main focus is on discussing the class semantics consistency in few-shot classification benchmarks. The curr_chunk discusses the evaluation of semantics consistency in few-shot classification benchmarks through additional categorization tasks. It explains the supervised few-shot classification task where support and query sets are used to predict labels for validation images. The proposed metric for evaluation is the supervised accuracy. The curr_chunk introduces the clustering accuracy metric for few-shot clustering tasks, which is evaluated by matching predicted clusters with ground-truth clusters using the Hungarian algorithm. This metric is commonly used in learning to cluster literature. The curr_chunk discusses the unsupervised few-shot classification task, which involves clustering support set images and associating query set images with predicted clusters. This task is proposed to be harder than supervised few-shot classification. The curr_chunk discusses finding the optimal permutation between predicted clusters and ground-truth clusters to maximize support set accuracy, followed by computing unsupervised accuracy by relabeling query set predictions. Unsupervised accuracy is compared with supervised accuracy in few-shot classification tasks. Protonets is a simple and accurate supervised few-shot classification method that uses an embedding function to map images to a feature space. Protonets compute class prototypes in the embedding space for a supervised task. Centroid Networks have trainable embedding and fixed clustering modules. The embedding function is the only trainable component, simplifying implementation and training. The clustering module of Centroid Networks, Sinkhorn K-Means, takes embedded data as input and outputs centroids for clustering points. It is based on the Sinkhorn distance and is expected to improve performance on tasks. Sinkhorn K-Means proposes an Expectation-Maximization-style procedure to find centroids minimizing the Sinkhorn distance between empirical distributions defined by the data. The algorithm alternates descent on assignments and centroids, using the Sinkhorn algorithm for assignment minimization and setting centroids as the weighted average of assigned points. Initial centroids are placed around zero with added Gaussian noise for symmetry breaking. The Sinkhorn K-Means algorithm proposes an Expectation-Maximization-style procedure to find centroids minimizing the Sinkhorn distance between empirical distributions. Once centroids are computed, different ways to cluster data points are proposed, such as Softmax conditionals and Sinkhorn conditionals. Softmax uses a temperature parameter for more uniform assignments, while Sinkhorn uses an optimal transport plan without a temperature parameter. The Sinkhorn algorithm uses a regularization parameter \u03b3 > 0 instead of a temperature parameter. It favors balanced clusters and is used in clustering support set data in embedding space. Centroid Networks can be trained end-to-end by backpropagating through Sinkhorn K-Means. The approach involves training with a supervised surrogate loss, replacing centroids with class averages, classifying using Softmax or Sinkhorn conditionals, and minimizing log-loss with gradient descent. This method simplifies the need for optimal cluster-class permutation and backpropagation through Sinkhorn K-means, also incorporating a center loss penalty. Center losses, like the one used by Wen et al. (2016), are employed in metric-learning methods to reduce class variance in embedding space. This helps improve clustering and unsupervised accuracies but may slightly decrease supervised accuracy. The Class Semantics Consistency Criterion is introduced to measure the consistency of class semantics across episodes. The Class Semantics Consistency Criterion (CSCC) is defined as a ratio that varies between 0 and 1, indicating the consistency of classes in few-shot classification tasks. It is approximated using supervised accuracy of Protonets and unsupervised accuracy of Centroid Networks, with the constraint of having the same network architecture. The CSCC is a first step towards quantifying the difficulty of few-shot learning benchmarks. The Centroid Networks approach is validated against a few-shot clustering method to assess the difficulty of current few-shot learning benchmarks. The method minimizes the surrogate loss with Softmax conditionals and a center loss, requiring minimal tuning with default hyperparameters. The results show significant improvements in accuracy compared to previous methods. In a comparison of clustering accuracies, Centroid Networks outperformed K-Means on raw and Protonet features. The evaluation was conducted on the Omniglot dataset using the Constrained Clustering Network splits, showing promising results with minimal architectural differences. Centroid Networks showed superior clustering accuracies compared to K-Means on raw data and Protonet features. The study validated Centroid Networks as a competitive approach for few-shot clustering without labels, emphasizing their effectiveness in categorizing examples. Centroid Networks outperform Constrained Clustering Networks on the Omniglot-CCN task, achieving higher accuracy (86.8% vs. 83.3% highest). They are also simpler and faster, making them a more efficient option for few-shot clustering without labels. Centroid Networks are simpler and faster than CCN, but less flexible as they require specifying the number of clusters and assuming equal cluster sizes. They are well-suited for few-shot classification benchmarks and require less information than supervised few-shot learning methods. Extending Centroid Networks to be as flexible as CCNs could lead to new learning-to-cluster methods. Using Centroid Networks to solve Omniglot and miniImageNet without using meta-testing labels (unsupervised few-shot classification). Centroid Networks achieve close to 100% accuracy on Omniglot and close to 80% on miniImageNet, indicating consistent class semantics. Comparison with Protonets shows superior performance. K-Means with K-Means++ initialization on raw images performs poorly, highlighting the importance of learning an embedding function. The study highlights the significance of combining Sinkhorn K-Means and the center loss trick in improving performance on few-shot learning benchmarks. Centroid Networks outperform K-Means on embeddings by a significant margin on Omniglot and miniImageNet. The main contribution is assessing the difficulty of few-shot learning benchmarks using CSCC, reporting CentroidNets' performance on unsupervised tasks and comparing it with Prototypical Networks on supervised tasks. CentroidNets outperform K-Means on embeddings for Omniglot and miniImageNet, achieving high unsupervised accuracy. The study evaluates the difficulty of few-shot learning benchmarks using CSCC, showing nearly perfect class semantics consistency for Omniglot and a fairly high amount for miniImageNet. Using Centroid Networks to solve Meta-Dataset without using meta-testing labels (unsupervised few-shot classification) under the two originally proposed settings: training on ILSVRC, and training on all datasets except Traffic Sign and MSCOCO. Reported supervised test accuracy for Prototypical Networks and unsupervised test accuracy for Centroid Networks, along with approximate CSCCs. When training on all datasets, supervised/unsupervised accuracies and approximate CSCCs are generally higher, except for Traffic Sign and MSCOCO. Training on ILSVRC alone can sometimes be better for transfer learning. Aircraft and Omniglot benefit the most from training on all datasets. High CSCCs are observed in the all datasets sub-table. In the context of training on all datasets, high CSCCs indicate self-consistent class semantics, with Omniglot and Aircraft showing the highest values. ILSVRC and Fungi have the lowest CSCCs. Some datasets exhibit higher CSCCs than ILSVRC itself, suggesting potential inconsistencies in ILSVRC or limitations of the metric. Centroid Networks are proposed for clustering without labels and assessing few-shot classification benchmarks. Our method beats a state-of-the-art few-shot clustering method in known clusters. We introduce the CSCC metric to quantify the difficulty of few-shot learning benchmarks based on class semantics consistency. Omniglot and miniImageNet have high CSCCs, while Meta-Dataset is harder. The CSCC metric confirms that Meta-Dataset is harder than miniImageNet in the ILSVRC only setting. Future work aims to improve CSCC interpretability and reduce dependency on backbone architectures. The Wasserstein-2 distance measures the cost of transporting mass between probability distributions, with Sinkhorn distances being efficiently computed for discrete distributions. The Sinkhorn K-Means algorithm is a key component of Centroid Networks, using distances to transport mass between data points and centroids. The algorithm leverages the log-sum-exp trick to avoid numerical underflows. The architecture for Omniglot and miniImageNet experiments includes a simple convolutional network with stacked blocks for embedding. For Omniglot, a 1600-dimensional embedding is used, while for miniImageNet, a prototypical network is pre-trained for 30-way problems. Omniglot has 1623 classes with 20 examples each, grayscale images of size 28x28. miniImageNet has 100 classes with 600 color images of size 84x84. The Sinkhorn K-Means algorithm is utilized in the experiments. In a 5-way 5-shot setting, the Sinkhorn K-Means optimization problem is compared with regular K-Means. Both involve minimizing centroids and assignments, with K-Means allowing hard assignments and Sinkhorn K-Means allowing soft assignments with balanced clusters. The Sinkhorn K-Means optimization problem involves balancing clusters with soft assignments and an entropy penalty term, leading to more uniform cluster assignments. Removing the balancing constraint results in a regularized K-Means objective similar to EM in a mixture of Gaussians. Sinkhorn K-Means is shown to significantly improve performance in few-shot clustering. Sinkhorn K-Means enforces class distribution, converges better than K-means with entropy regularization, and shows improved performance in few-shot clustering. Comparing CentroidNets with ProtoNets on miniImagenet, Centroid Networks are run with centroids as unweighted averages of data points. This makes the comparison fair as both prototypes and centroids use unweighted averages. The unsupervised accuracy for weighted average is 0.5508 \u00b1 0.0072 and for unweighted average is 0.5497 \u00b1 0.0072, with no significant difference. The clustering accuracy for weighted average is 0.6421 \u00b1 0.0069 and for unweighted average is 0.6417 \u00b1 0.0069, also showing no significant difference. The experiment suggests that using weighted averages does not provide an unfair advantage in comparing ProtoNets and CentroidNets. The unsupervised Bayes accuracy is defined as the highest achievable accuracy in an unsupervised few-shot classification task distribution. This accuracy is limited by cluster-semantic noise. The experiment explores unsupervised few-shot classification tasks using random binary vectors. The algorithm struggles to cluster the support set without knowing the sampled dimension, resulting in a 0.5 accuracy. However, when the dimension index is fixed, the algorithm can learn to cluster the support set based on the first dimension, achieving better accuracy. The experiment explores unsupervised few-shot classification tasks using random binary vectors. The algorithm struggles to cluster the support set without knowing the sampled dimension, resulting in a 0.5 accuracy. However, when the dimension index is fixed, the algorithm can learn to cluster the support set based on the first dimension, achieving better accuracy. The resulting unsupervised Bayes accuracy is 1, with clusters formed by grouping all 1s and all 0s together. The difficulty of unsupervised few-shot tasks lies in the variability of class semantics, which impacts the accuracy. The importance of supervision information in CSCC is not directly related to the difficulty of few-shot learning problems, which can stem from various factors such as visual difficulty and class semantic consistency. Designing meaningful benchmarks for supervised few-shot classification methods requires considering these aspects. The goal is to design benchmarks for supervised few-shot classification methods by understanding the difficulty factors. A benchmark with the same classes sampled repeatedly may seem challenging due to high visual difficulty, but lacks variability in class semantic consistency. The introduced CSCC aims to decouple different difficulty axes, not as a proxy for task difficulty. The study conducts an ablation study on Omniglot and miniImageNet to determine the impact of various proposed tricks and components, such as K-Means vs. Sinkhorn K-Means, Center Loss, and Softmax vs. Sinkhorn conditionals. Sinkhorn K-Means and Center Loss are identified as the most beneficial factors in improving accuracy. At meta-training and meta-evaluation time, it is uncertain whether using Sinkhorn or Softmax conditionals is advantageous for training. Sinkhorn conditionals are better for clustering accuracy, while Softmax conditionals may be better for unsupervised accuracy, although the difference is minimal."
}