{
    "title": "BJe-DsC5Fm",
    "content": "In this paper, a new zeroth-order stochastic optimization algorithm, ZO-signSGD, is designed and analyzed. It combines gradient-free operations with signSGD, achieving comparable convergence speed to SGD-type algorithms. ZO-signSGD requires $\\sqrt{d}$ times more iterations than signSGD, with a convergence rate of $O(\\sqrt{d}/\\sqrt{T})$. Different gradient estimators' effects on ZO-signSGD convergence are analyzed, and two variants are proposed with at least $O(\\sqrt{d}/\\sqrt{T})$ convergence rate. The connection between ZO-signSGD and black-box adversarial attacks in robust deep learning is explored through empirical evaluations on image classification. Zeroth-order optimization, specifically ZO-signSGD, shows superior performance in generating adversarial examples from black-box neural networks. This method is particularly useful for scenarios where obtaining gradients is challenging. Adversarial examples are crafted images with subtle changes to deceive image classifiers. The black-box nature of optimization limits the practical design of these examples, as internal configurations of ML systems are not disclosed. The paper proposes a zeroth-order sign-based descent algorithm, ZO-signSGD, for black-box optimization problems like generating adversarial examples. The algorithm's convergence behavior and stability are studied in theory and practice. In contrast to first-order methods, ZO-signSGD leverages sign information of gradient estimates for superior empirical performance. SignSGD is a method that reduces communication costs and can converge faster than SGD by compressing gradients with a single bit. It achieves O(1/ \u221a T ) convergence rate with a large mini-batch size. SignSGD has been connected to Adam through convex analysis and has shown effectiveness in robust adversarial training of deep neural networks. In this paper, a new ZO algorithm called 'ZO-signSGD' is proposed with a convergence rate of O( \u221a d/ \u221a T ). The algorithm applies to mini-batch sampling schemes with or without replacement and includes variants for centralized and distributed ZO optimization. Extensive synthetic experiments were conducted to benchmark the performance of ZO-signSGD. The performance of ZO-signSGD is benchmarked through synthetic experiments and its parameter sensitivity is investigated. ZO-signSGD outperforms other ZO algorithms for generating adversarial examples from black-box DNNs. Other ZO algorithms like ZO-SGD, ZO-SCD, and ZO-SVRG have been developed for convex and nonconvex optimization. In this section, a background on signSGD is provided, along with the problem setup of interest. The finite-sum problem involves optimization variables x \u2208 R d and nonconvex cost functions {f i }. SignSGD, a method different from SGD and SCD, focuses on the sign of the gradient for solving such problems. SignSGD, a method focusing on the sign of the gradient, is robust to noise and shows fast convergence. Algorithm 1 outlines a sign-based gradient descent framework, including variants like ZO-signSGD. ML models, vulnerable to adversarial attacks, can be countered with signSGD. The text discusses adversarial examples in machine learning models and introduces a sign-based gradient descent method called signSGD. Adversarial examples are crafted by adversaries to cause misclassification, highlighting the limitations of learning models. The generation of adversarial examples can be interpreted through signSGD, which is robust to noise and aids in countering adversarial attacks. The goal of adversarial attacks is to find minimal perturbations that mislead learning models. Adversarial example generation follows the sign-gradient update rule, connecting to signSGD and other attack methods. The proposed ZO-signSGD algorithm is associated with black-box attacks. The proposed ZO-signSGD algorithm is associated with attack BID16 BID3. It addresses the limitation of signSGD BID2, which requires first-order information like stochastic gradients. In scenarios where explicit gradients are hard to obtain, such as generating adversarial examples from black-box neural networks, ZO gradient estimation is used. This involves constructing a gradient estimate through a forward difference of function values at a query point x. The ZO gradient estimate is a biased approximation to the true gradient of a function, but becomes unbiased when using a randomized smoothing function. The random direction vectors can be drawn from a uniform distribution over a unit sphere, which is more practical than the standard Gaussian distribution. ZO-signSGD is motivated by the robustness to gradient noise, particularly in the context of biased ZO gradient estimates compared to true gradients. It shows fast empirical convergence in generating adversarial examples and is robust against sparse noise perturbations. In a toy quadratic optimization problem, ZO-signSGD is shown to be robust against sparse noise perturbation. The algorithm introduces three key differences compared to signSGD, including milder assumptions on mini-batch sampling. In the proposed ZO-signSGD algorithm, the assumption on mini-batch sampling is relaxed, and both the ZO gradient estimator and sign operator introduce approximation errors. Mini-batch sampling without replacement adds difficulty in bounding the variance of ZO gradient estimates. The sign-based descent algorithm evaluates convergence error in 1-norm geometry, causing a mismatch with the 2-norm based gradient. The ZO-signSGD algorithm introduces approximation errors due to mini-batch sampling without replacement. It evaluates convergence error in 1-norm geometry, leading to a mismatch with the 2-norm based gradient. The probabilistic convergence method BID11 is used to bound the eventual convergence error of ZO-signSGD. Multiple variants of ZO-signSGD for centralized or distributed optimization are covered, starting with assumptions used in the analysis and deriving the convergence rate for nonconvex optimization. The ZO-signSGD algorithm introduces approximation errors due to mini-batch sampling without replacement. It evaluates convergence error in 1-norm geometry, leading to a mismatch with the 2-norm based gradient. Proposition 1 under A1 shows that ZO-signSGD bypasses bias by leveraging randomized smoothing techniques for ZO optimization. The convergence of ZO-signSGD is linked to the variance of the ZO gradient estimate. Proposition 2 bounds the variance of \u011d k, dependent on mini-batch sampling. Proposition 2 provides a general result for the ZO gradient estimate \u011d k, with bounds on variance dependent on mini-batch sampling, covering both with and without replacement scenarios. Proposition 2 covers mini-batch sampling with and without replacement, implying that large batch sizes and sampling rates reduce gradient estimate variance and improve convergence rate. The convergence rate of ZO-signSGD is shown in terms of the stationarity of the original function f, with the challenge of bounding the gap between f and its smoothed version f \u00b5. The relationship between f \u00b5 and f is tight, as f \u00b5 is a convolution of f and the density function of a random perturbation v. The convergence rate of ZO-signSGD is determined by various parameters such as the learning rate, problem size, smoothing parameter, mini-batch size, and number of random perturbations. The gradient norm is translated from 1 to 2 in Theorem 1, with a probabilistic output to avoid exhaustive search. The convergence is simplified based on specific parameters, with explicit dependence specified in the theorem. The convergence rate of ZO-signSGD is analyzed through \u2207f(xR)2, meeting a stricter criterion than ZO-SGD. ZO-signSGD may converge to a neighborhood of a stationary point with fast speed, controlled by mini-batch size and random direction vectors. The convergence rate of ZO-signSGD is influenced by the mini-batch size and random direction vectors. When b = n, using mini-batch without replacement yields a better convergence rate compared to using mini-batch with replacement. If b > n, ZO-signSGD is limited to using mini-batch sampling with replacement. The study explores three variants of ZO-signSGD for gradient estimation using different methods. The central difference method requires more function queries but may improve convergence rate. The ZO-signSGD with this method yields the same convergence rate as the original ZO-signSGD under certain conditions. The study examines different variants of ZO-signSGD for gradient estimation. ZO-signSGD with gradient estimator (10) maintains the same convergence rate as ZO-signSGD with estimator (3). The gradient estimator (11) using majority vote also shows improved convergence rate. ZO-M-signSGD, a variant of ZO-signSGD with majority vote, achieves faster convergence under the condition of unimodal symmetric gradient noise. This improvement eliminates the error correction term and outperforms ZO-signSGD in certain scenarios. The text discusses the implications of gradient distributions on optimization algorithms. It introduces ZO-D-signSGD as a variant of ZO-signSGD for distributed optimization, highlighting its convergence rate and error correction term compared to ZO-M-signSGD. In this section, the effectiveness of ZO-signSGD is empirically demonstrated on synthetic and real-world datasets like MNIST and CIFAR-10. The comparison includes various variants such as SGD, signSGD BID2, ZO-SGD BID11, and ZO-SCD BID22 in solving binary classification problems with nonconvex loss functions. The least squared formulation is used instead of the conventional cost function of logistic regression. A synthetic dataset is generated with training samples and testing samples. The best constant learning rate is found through a greedy search. ZO-signSGD outperforms other algorithms in terms of convergence performance. In experiments, ZO algorithms show improved convergence with increasing parameters b and q. ZO-signSGD and ZO-M-signSGD approach the performance of signSGD. As problem size d increases, all algorithms degrade in convergence, but ZO-signSGD and ZO-M-signSGD outperform ZO-SGD and ZO-SCD. ZO-signSGD outperforms ZO-M-signSGD and ZO-D-signSGD, with faster convergence as mini-batch size increases. In black-box adversarial attack experiments, ZO-signSGD and its variants outperform ZO-SGD in converging to moderate accuracy quickly within a few tens of iterations. Adversarial examples are generated from a black-box image classifier trained by a deep neural network model, falling under ZO optimization. The DNN models trained on MNIST and CIFAR-10 are used as zeroth-order oracles for crafting adversarial examples. Different ZO optimization algorithms (ZO-SGD, ZO-signSGD, ZO-M-signSGD) are compared in black-box attacks with the same attacking loss function. In black-box adversarial attack experiments, ZO-signSGD and its variants outperform ZO-SGD in converging quickly. Parameters like \u00b5 = 0.01, q = 9, and \u03b4 = 0.05 for MNIST and \u03b4 = 0.0005 for CIFAR-10 are set for each method. The performance is benchmarked against NES using the central difference of two function values. ZO-signSGD usually takes fewer iterations than other methods. ZO-signSGD outperforms ZO-SGD in quickly finding successful adversarial examples with lower distortion. It takes fewer iterations compared to other methods for both MNIST and CIFAR-10 datasets. ZO-signSGD and ZO-M-signSGD are more efficient than ZO-SGD in finding successful adversarial examples with lower distortion. ZO-signSGD may not converge to high accuracy but is fast for black-box attacks. ZO-NES is less effective in query efficiency compared to ZO-signSGD. ZO-signSGD offers a provable and efficient black-box adversarial attacking method with a convergence rate of O( \u221a d/ \u221a T ). It outperforms ZO-NES in query efficiency and attack distortion. Despite a slower convergence rate compared to signSGD, ZO-signSGD has gradient-free advantages and shows superior performance on synthetic and real-world datasets for black-box attacks. Future work aims to extend the analysis to nonsmooth and nonconvex optimization problems. In the analysis of nonsmooth and nonconvex constrained optimization problems, the presence of a sparse noise vector v affects the convergence performance of different algorithms. Sign-based first-order and ZO algorithms show faster convergence compared to stochastic gradient-based descent algorithms due to the inaccurate gradient values caused by the noisy component v1. The sign information is more robust to outliers, leading to better convergence performance of sign SGD and its variants. Comparison of gradient-based and gradient sign-based algorithms in sparse noise perturbation shows sign-based algorithms have faster convergence. The gradient estimators (3) and (10) have a significant impact on the convergence of ZO-signSGD. Sign operation helps mitigate the negative effect of gradient noise, leading to faster convergence compared to SGD and ZO-SGD. Coordinate-wise variance of gradient noises is examined, showing improved performance of signSGD and ZO-signSGD. In the context of gradient estimators, ZO-signSGD shows faster convergence by reducing noise variance compared to ZO-SGD. The variance of gradient noise is analyzed, highlighting the benefits of using signSGD and ZO-signSGD. The smoothing function f\u00b5 has a Lipschitz continuous gradient and is L-smooth. By relaxing a probability inequality, we obtain a new inequality. Substituting equations leads to a final inequality, with randomness from two sources. The text discusses the variance of a variable \u011d k, which is influenced by two sources of randomness: mini-batch sampling and random direction sampling. Mini-batch sampling can be done with or without replacement, and a new variable Wi is introduced to represent this. The variance of \u011d k is calculated using specific formulas and equalities. The text discusses the variance of a variable \u011d k influenced by mini-batch sampling and random direction sampling. The vectors {zi} are i.i.d. under both sampling methods. By applying specific formulas and equalities, the variance of \u011d k is calculated. The text discusses bounding the variance of \u011d k through various substitutions and formulas, ultimately leading to gradient estimates. The text discusses bounding the variance of gradient estimates \u011d k through substitutions and formulas to ensure sign consistency."
}