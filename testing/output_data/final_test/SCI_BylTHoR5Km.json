{
    "title": "BylTHoR5Km",
    "content": "Dementia in the elderly can be detected by classifiers trained on linguistic features from narrative transcripts, but aging impacts these features differently, making it difficult for machine learning classifiers to isolate the effects of aging. Deep neural network classifiers can infer ages from linguistic features, leading to potential unfairness across age groups. The issue is caused by undesired activations in causality diagrams and can be addressed with fair representation learning. Neural network classifiers are built to learn low-dimensional representations reflecting dementia impacts while discarding age effects. Evaluation using a model-agnostic score shows that the best models outperform baseline classifiers in disentanglement, with a slight compromise in accuracy. Dementia impacts cognitive abilities, leading to changes in linguistic features of speech. Classifiers can detect cognitive impairments with high accuracy using lexical-syntactic and acoustic features. Aging also affects cognitive abilities differently from dementia. Aging affects cognitive abilities differently from dementia, inhibiting fluid cognitive abilities more than consolidated abilities. Changes in linguistic features, such as more pauses and decreased short-term memories, may be attributed to normal aging rather than dementia. However, the high correlation between dementia and aging makes it challenging to distinguish between the two. Age is a confounding factor in detecting dementia, as traditional machine learning algorithms struggle to isolate the effects of confounding factors due to sampling biases in the data. Traditional neural network classifiers can bias on age to infer dementia, leading to avoidable false positives and false negatives in the medical domain. Demographic factors should not heavily influence classifier decisions to isolate the effects of confounding factors. Graphically, age and dementia can cause changes in a feature, creating a v-structure that affects the classifier's inference model. Traditional neural network classifiers can bias on age to infer dementia, leading to avoidable false positives and false negatives in the medical domain. Controlling confounding factors like age can be challenging, with stratified distributions often not representing the real world accurately. Conducting randomized control trials on variables like age can help remove causal paths but may not always be practical. To address biases in neural network classifiers related to age and dementia inference, fair representation learning frameworks can be used to train classifiers while filtering out age-related information. This approach aims to protect age as a \"sensitive attribute\" and improve accuracy in medical domain predictions. Fair representation learning frameworks aim to train classifiers to consider subjects with different sensitive attributes equally, such as race or age. BID32 proposed a framework where classifiers were penalized for differences in classification probabilities among demographic groups, resulting in better demographic similarities with minimal accuracy compromise. Adversarial training, as introduced by BID9 using generative adversarial networks, further advances fair representation learning by limiting the adversary's ability to classify based on sensitive attributes. Fair representation learning aims to train classifiers to treat subjects with different sensitive attributes equally. Current approaches only handle binary attributes, like binarized age. To address this limitation, a fairness metric is formulated to evaluate classifiers' ability to isolate continuous-valued attributes. Four models are proposed to compress high-dimensional feature vectors into low-dimensional representations that encrypt age from adversaries. Empirical results show that these models achieve better fairness metrics than baseline deep neural network classifiers, with minimal accuracy compromise. Various entanglement measures between classifier outcomes and specific variables are reviewed, and a new metric is proposed. The text discusses the use of correlation and information theoretic measures to compare classification outputs with input features. It also explores mutual information to assess the relationship between random variables like age and dementia. The challenge lies in estimating these relationships accurately due to the size of clinical datasets. An alternative approach involves fitting variables into probabilistic models. The text discusses using correlation and information measures to compare classification outputs with input features, focusing on mutual information to assess the relationship between variables like age and dementia. Challenges arise in accurately estimating these relationships due to dataset size, with an alternative approach involving fitting variables into probabilistic models. The text proposes explainable metrics and an agnostic model to address these challenges. The literature in fairness representation learning offers metrics for evaluating bias in classifiers. Demographic parity aims for equal outcomes between protected groups and the whole population. Cross-entropy loss measures fairness in models with an adversary component. The loss in fairness representation learning depends on the adversary network's ability. Equalized odds BID12 aims for equal false positive rates across groups. BID22 defines fairness distance as the difference in false positive and false negative rates between groups. A metric extension for continuous sensitive attributes is proposed for evaluating classifiers. R(.) reconstructs input data from hidden representation in age-indep-consensus-nets FIG0. Discriminator D(.) identifies modality origin. Age groups are divided with participants having positive and negative diagnoses. Aim for constant FP and FN rates across groups. Measure variability using sum of differences against mean. Special cases show metric application. The fairness metric discussed in the text chunk illustrates limitations, bounds, and disentanglement. It highlights how the metric becomes less informative with more age groups and is bounded by 0 and an upper limit based on the number of age groups. The metric also shows disentanglement by indicating a higher variation of incorrect predictions. The text discusses the importance of a lower \u2206 (N ) eo value for classifiers to isolate age effects better. It explains design choices like linearity and indirect optimization for fairness. Different ways of building representation learning models are described, such as age-indep-simple, age-indep-autoencoder, age-indep-consensus-net, and age-indep-entropy. The text introduces various models for representation learning, including age-indep-simple, age-indep-autoencoder, age-indep-consensus-net, and age-indep-entropy. These models involve an interpreter network to compress input data, an adversary to predict age, and a classifier to estimate labels. Training involves minimizing classification loss, maximizing adversarial loss, and optimizing iteratively. The age-indep-autoencoder structure is similar to previous work. The age-indep-autoencoder structure is an extension from the age-indep-simple model, incorporating a reconstructor network to recover input data from hidden representations. The goal is to minimize the reconstruction loss term while training the interpreter and reconstructor, in addition to targets from the age-indep-simple network. This approach borrows from consensus networks, emphasizing the benefits of agreements between multiple modalities for classification. The age-indep-consensus-net aims to disentangle data modalities for classification by encouraging indistinguishable representations. It utilizes multiple interpreters to compress input data into low-dimensional representations, with a discriminator identifying the modality. The loss functions are optimized iteratively to train the networks. The detailed algorithm for optimizing networks is in the Appendix. Combining the consensus network with the reconstructor decreases performance due to conflicting goals. A model for fair representation learning is inspired by categorical GANs, introducing an additional loss function term to encourage interpreter improvement. The model for fair representation learning introduces an additional loss function term to encourage interpreter improvement by increasing uncertainty and letting the adversary become more confident in predicting ages. The loss functions are set up with a hyper-parameter \u03bb H, and experiments show that both terms in the loss function are better applied together. The training procedure for fair representation learning is similar to age-indep-autoencoder. Models are implemented in PyTorch and optimized with Adam, using fully connected networks with ReLU activations and batch normalization. DementiaBank is a dataset for assessing cognitive impairments using speech, with 473 narrative picture descriptions from subjects aged 45 to 90. The Famous People dataset BID1 contains 252 transcripts from 17 people, including 8 with dementia (such as Gene Wilder, Ronald Reagan, and Glen Campbell) and 9 healthy controls (like Michael Bloomberg, Woody Allen, and Tara VanDerveer). Out of the data samples, 182 are labeled as 'control' and 213 as 'dementia'. The mean age of participants is 68.26 with a standard deviation of 9.00. The Famous People dataset includes transcripts from 17 individuals, with 8 having dementia. Data samples were collected across a wide age range, with cognitive impairments more likely in older participants. 413 linguistic features were extracted and normalized for analysis. The linguistic features extracted from the Famous People dataset, including acoustic, speech fluency, lexical, PoS, syntactic, and semantic features, contain information indicating age. Simple neural networks can predict age with mean absolute errors of 15.5 \u00b1 1.3 years and 14.3 \u00b1 2.5 years on different datasets. Neural networks can infer age from linguistic features, leading to potential bias. Benchmarks for classifiers are set up and evaluated with fairness metrics. Results are compared against a DNN baseline, with additional evaluation of age-indep-entropy variants. Our fair representation learning models, with age-indep prefix replaced by \"*\", show better disentanglement scores but compromise accuracy compared to DNN baselines. The age-indep-autoencoder model reduces accuracy the least, while age-indep-consensus and age-indep-entropy models have slight compromises in accuracy. These models also improve disentanglement/fairness significantly, especially when measured by two-group scores \u2206eo. The Famous People dataset has higher variance compared to DementiaBank due to the smaller number of samples per age group. Fairness metrics are stable when the number of samples per label per group is kept small. The age-indep-entropy model performs best with a loss function containing both binary classification and uncertainty minimization terms. Age-indep-simple and age-indep-autoencoder achieve the best fairness metrics overall. The study introduces a fair representation learning task to address the entanglement of age in cognitive impairment detection. Four models are proposed to minimize age information in data samples, with the best model improving fairness metrics while maintaining accuracy. Age-indep-simple and age-indep-autoencoder outperform traditional classifiers in fairness metrics. The study introduces a fair representation learning task to address age entanglement in cognitive impairment detection. Four models are proposed to minimize age information in data samples, with age-indep-autoencoder, age-indep-consensus-net, and age-indep-entropy showing significant or marginally significant differences in fairness metrics. Pseudo-code algorithms are provided for the remaining three models."
}