{
    "title": "rJx5_hNFwr",
    "content": "Unsupervised domain adaptive object detection involves learning a robust detector in a domain shift scenario. The proposed Stacked Complementary Losses (SCL) method utilizes detection objectives and auxiliary losses to adapt model parameters to both source and target domains. A gradient detach operation is used to force networks to learn discriminative representations. Our proposed method aims to improve adaptation learning by integrating data from different domains more effectively. Experimental results on seven datasets show that our method outperforms state-of-the-art methods by a significant margin. For example, in the Cityscapes to FoggyCityscapes transition, we achieve a 37.9% mAP, surpassing the previous best method by 3.6%. Object detection in domain-shift scenarios faces challenges such as variations in viewpoint, background, and illumination, making it a challenging research topic in recent years. Domain-shift object detection is a challenging research topic in recent years, with approaches focusing on training supervised models or unsupervised cross-domain representation learning. The latter is preferred due to its efficiency, but challenges remain in matching source and target domain data in a common space. The curr_chunk discusses the importance of defining feature alignment mechanisms for domain adaptation, such as subspace alignment, H-divergence, and adversarial learning. It also mentions a learning-based alignment method called SCL with an end-to-end framework. The visualization of features from different domains using t-SNE is shown, indicating the source and target examples. The curr_chunk introduces a new feature embedding design for convolutional neural network optimization, showing superior results on dissimilar and similar domains. It aims to improve training on tasks that adapt to different domains, drawing on previous literature on unsupervised domain adaptation. Our method draws on previous work in domain-invariant alignment for object detection, focusing on local regions of interest. Inspired by multi-feature alignment techniques, we aim to improve model efficiency while preserving critical context information. In domain adaptive object detection, deep supervision plays a crucial role. The paper explores stacked complementary objectives and their combinations for improved results. By introducing a new sub-network for context feature learning, competitive results were achieved on various benchmarks. Object detection benchmarks were improved by introducing complementary objectives in training. The COL method involved updating parameters alternately with primary and complement objectives. The complement entropy was defined as the average of sample-wise entropies over complement classes in a mini-batch. Parameters were updated simultaneously using gradient detach instead of the alternate strategy. Our method updates parameters simultaneously using gradient detach strategy with primary and complement objectives, aiming to adapt the network on both source and target domain data while distinguishing objects. It is a deeply supervised formulation that utilizes auxiliary losses to promote domain mixing through domain classifiers for detection, leading to better generalization for network adaptation. Stacked Complementary Losses (SCL) is proposed as a simple yet effective approach for domain-shift object detection, aiming to adapt shallow layer parameters to both source and target domains. The method utilizes gradient detach and visualizes features obtained by different models to showcase its effectiveness in achieving remarkable performance. The current study proposes an end-to-end learnable framework for domain adaptive object detection, utilizing complementary losses and a gradient detach learning strategy. The method integrates information from both source and target domains effectively, with extensive ablation studies confirming its performance boost. This work is pioneering in investigating diverse loss functions and gradient detach for domain adaptive object detection. Our method achieves the highest accuracy on domain adaptive object detection benchmarks by defining source and target domains and aiming to learn a domain-invariant feature representation. The focus is on complementary objective learning for robust detection across different domains. The recursive function for layers is defined with complementary losses, including a domain classifier loss. A gradient reverse layer is used for adversarial training, reversing gradients during backpropagation. Instance-context alignment loss considers instance-level representation and context vectors. The instance-level vectors from the RoI layer focus on local object representation, while the context vector combines hierarchical global features. By aligning instance and context representation simultaneously, the model can mitigate variances in object appearance and environmental factors. The proposed solution uses a detach strategy to update gradients, improving the joint training of detection and context networks. The domain label d i distinguishes between source and target images, aiding in formulating the instance-context alignment loss. The detach strategy prevents gradient flow from the context sub-network through the detection backbone, improving context discriminability. Empirical evidence shows that suppressing gradients from this path enhances task performance. Instance and context focus on different image parts, with a sub-network generating context information from early detection layers. In this paper, the authors propose to suppress gradients during backpropagation to ensure that the representation of the context sub-network is dissimilar to the detection network. This approach aims to improve context discriminability in domain adaptive object detection, which is a novel contribution compared to previous works. The context sub-network architecture is detailed in Appendix A. The framework is based on Faster RCNN, with the detection loss objective including classification and bounding-box regression losses. The overall objective function includes a trade-off coefficient between detection loss and complementary loss. The approach is evaluated in three domain shift scenarios: Similar Domains, Discrepant Domains, and From Synthetic to Real Images. In experiments, domain shift datasets like Cityscapes to FoggyCityscapes, KITTI to Cityscapes, PASCAL to Clipart, and GTA to Cityscapes are used. The model is trained with SGD optimizer, resizing images to 600, and adjusting learning rate. Mean average precision (mAP) with IoU threshold of 0.5 is reported for evaluation. In an extensive ablation study, the authors explore the combination of different losses for domain adaptive object detection. They follow guidance from previous works on domain adaptation and utilize cross-entropy (CE) loss to measure classification model performance and least-squares (LS) loss to align low-level features during training. The authors explore different losses for domain adaptive object detection, using cross-entropy (CE) loss for classification performance and least-squares (LS) loss to align low-level features. Focal Loss (FL) is also utilized to focus on hard-to-classify examples during training. Results show that \"LS-CE-FL\" achieves the best accuracy with Context and Detach, indicating the importance of placing LS on low-level features and FL on high-level locations. The study focuses on domain adaptive object detection using different losses such as cross-entropy (CE), least-squares (LS), and Focal Loss (FL). It is important to place LS on low-level features and FL on high-level locations for effective training. The proposed method outperformed the baseline Strong-Weak model and other state-of-the-arts in adaptation between Cityspaces and KITTI datasets. The study evaluates domain adaptive object detection on KITTI dataset, outperforming Strong-Weak model. Results show significant improvement in AP for car detection in both adaptation directions. Additionally, the INIT Dataset is introduced for instance-level image-to-image translation task. The INIT dataset is utilized for domain adaptive object detection, showing consistent improvement over baseline methods in various domain pairs. Results for adaptation from real images to cartoon/artistic domains are also discussed using the PASCAL VOC dataset. The study utilizes the PASCAL VOC dataset for training and evaluates performance on Clipart and Watercolor datasets. Results show that the proposed SCL outperforms all baselines, with further improvements observed by replacing FL with CE loss. Additionally, the SCL consistently outperforms other state-of-the-arts in adapting from PASCAL to Watercolor domain. The SCL consistently outperforms other state-of-the-arts in adapting from Sim10K to Cityscapes domain. Results show that the proposed method performs best when hyper-parameter K is set to 3 on all three datasets. Parameter sensitivity analysis shows that \u03bb and \u03b3 control the trade-off between SCL and detection objectives, with \u03b3 controlling the strength of hard samples in Focal Loss. In experiments on domain adaptations, \u03bb and \u03b3 parameters influence performance. Best results are achieved with specific values on different dataset pairs. IoU threshold is crucial for detection quality, with higher values indicating better coverage. Previous experiments used a threshold of 0.5, but performance varies with IoU on different datasets. Our method outperforms baselines on different thresholds by a large margin. Gradient detach helps improve performance significantly by allowing the model to learn more discriminative features from the target object and context. Visualization of heatmaps shows stronger contrast in object areas and context in detach-trained models compared to models without detach training. Additional visualizations are available in Appendix C. Detection examples on three test sets with domain adaptation are shown in Figure 10. Our method outperforms baselines on three test sets with domain adaptation, detecting more small and blurry objects in dense scenes and suppressing false positives. We address unsupervised domain adaptive object detection through stacked complementary losses, utilizing gradient detach training and multiple complementary losses for better optimization. Our proposed method utilizes multiple complementary losses for optimization and outperforms state-of-the-art approaches in experiments. Future work will focus on domain-shift detection without pre-trained models. Context networks with three branches are used to deliver context information, showing adaptation results on source domains. Our proposed method utilizes multiple complementary losses for optimization and outperforms state-of-the-art approaches in experiments. Surprisingly, the best-trained models on target domains are not performing best on the source data. We conjecture that the adaptation process for target domains affects the learning and performance on source domains. Further investigation is needed to understand this behavior. In experiments, our method outperforms state-of-the-art approaches by utilizing multiple losses for optimization. The gradient detach-based models in Table 15 and 16 adapt source and target images better than models without detach."
}