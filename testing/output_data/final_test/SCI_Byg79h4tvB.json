{
    "title": "Byg79h4tvB",
    "content": "This paper introduces a novel Prototype-Assisted Adversarial Learning (PAAL) framework for unsupervised domain adaptation (UDA) to address class mismatch issues. PAAL combines instance probabilistic predictions with class prototypes to improve domain alignment reliability. The PAAL scheme aligns instance feature representations and class prototypes to alleviate class mismatch in semantically different classes. It also uses class prototypes to minimize within-class variance in the target domain for semantically similar classes. This leads to the Prototype-Assisted Conditional Domain Adaptation (PACDA) framework, which effectively addresses class mismatch issues in unsupervised domain adaptation tasks. The PAAL scheme and PACDA framework show good performance in object recognition and synthetic-to-real semantic segmentation tasks. Recently, deep unsupervised domain adaptation (UDA) methods have shown significant performance improvements by leveraging supervision from various sources, such as maximum mean discrepancy (MMD) and generative adversarial learning. Adversarial learning schemes in UDA face challenges due to cross-domain misalignment, where target instances may not align with source instances. Inspired by pseudo-labeling strategies, new approaches like the Prototype-Assisted Conditional Domain Adaptation (PACDA) framework aim to address class mismatch issues effectively. Previous methods in deep unsupervised domain adaptation have utilized pseudo-labeling strategies to minimize distribution discrepancies between source and target domains. However, relying solely on probabilistic predictions or pseudo labels may lead to misalignment issues, as they may not accurately represent the semantic information of input instances. This can result in misleading alignment, as shown in a toy example where the pseudo label of an instance is 'square' while the ground truth label is 'circle'. In deep unsupervised domain adaptation, previous methods have used pseudo-labeling to align source and target domains. However, relying on inaccurate predictions can lead to misalignment issues. To address this, a new approach proposes using class prototypes for domain alignment instead of relying solely on predictions. This method aims to ensure semantic consistency in the alignment process. Our Prototype-Assisted Adversarial Learning (PAAL) scheme integrates instance-level pseudo labels and global class prototypes to improve distribution alignment in deep unsupervised domain adaptation. Class prototypes are used to enhance the reliability of conditional indicators for guiding source-target feature representation alignment. By summarizing class prototypes from all instances based on their predictions, we reduce the reliance on inaccurate instance predictions and encourage more certain instances to contribute significantly. The PAAL scheme updates class prototypes dynamically through a moving average strategy to improve accuracy. By broadcasting prototypes to instances based on probability predictions, inaccurate semantic distribution is alleviated. The proposed PAAL scheme aligns instance feature representations and class prototypes to relieve alignment among dissimilar instances. An intra-class objective in the target domain promotes class compactness to further alleviate confusion among similar instances. The PACDA framework, built on the PAAL scheme, leverages class prototypes in conditional adversarial learning to address misalignment in unsupervised domain adaptation. It offers a domain adversarial learning framework to align semantically similar and dissimilar instances. The generic PAAL scheme and PACDA framework achieve state-of-the-art results in unsupervised domain adaptation tasks. Our framework achieves state-of-the-art results in unsupervised domain adaptation tasks, including object recognition and semantic segmentation. Different approaches have been used to address the covariate shift problem, such as nonparametric instance re-weighting and feature transformation with cross-domain metrics. Deep learning methods have significantly improved performance in various vision tasks, categorized into discrepancy-based and adversarial-based methods. Recent advancements in unsupervised domain adaptation tasks have led to the development of discrepancy-based and adversarial-based methods in deep learning for vision tasks. Discrepancy-based methods focus on mitigating dataset shift by matching higher moment statistics of features from different domains, while adversarial learning leverages an extra domain discriminator to promote domain confusion. Pseudo-labeling is also utilized in semi-supervised learning strategies for domain adaptation. Some popular SSL strategies like entropy minimization, mean-teacher, and virtual adversarial training have been successfully applied to unsupervised domain adaptation (UDA). Pseudo-labeling is favored for its convenience in UDA methods, with approaches like tri-training, self-training, and obtaining target-specific prototypes. Additional techniques like curriculum learning, self-paced learning, and re-weighting schemes are also used to address false pseudo-labels in UDA. Pseudo-labels can enhance domain alignment in adversarial learning by minimizing distribution discrepancies and aligning domain-specific layers. Various methods leverage probabilities and discriminative information for fine-grained alignment of data distributions. Additionally, a multi-way adversarial approach inspired by semantically-consistent GAN has been proposed. The proposed PACDA framework enhances domain alignment in adversarial learning by utilizing class prototypes to guide the process. It complements feature representations with reliable semantic features and involves two low-dimensional domain discriminators. This approach simplifies the domain alignment process, making it more conditional and reliable. The framework can be applied to image classification and semantic segmentation tasks. In a vanilla UDA task, label-rich source domain data and unlabeled target domain data are used to learn a discriminative model for predicting labels. The framework consists of a feature extractor network, a classifier network, and a discriminator network. The goal is to predict labels for unlabeled target samples using domain adversarial learning. The vanilla domain adversarial learning method aims to optimize a minimax problem involving global class prototype matrix and domain classifier. Misalignment in UDA challenges popular adversarial learning, with previous works conditioning target domain data on pseudo labels for alignment. The discriminator in vanilla domain adversarial learning considers feature representations and predictions jointly, leveraging classification predictions to align feature representations. Previous works have used the outer product of feature representations and predictions for alignment, showing better performance than simple concatenation. Some recent works utilize multiple class-wise domain discriminators to align feature representations based on corresponding predictions, but relying solely on pseudo labels for alignment may be inaccurate due to domain shift. Class prototypes are suggested as a more robust alternative for alignment. In domain adversarial learning, class prototypes are proposed as a robust alternative to pseudo labels for alignment. The adversarial loss is reformulated to incorporate global class prototypes, which are broadcasted to instances for reliable conditional information. Feature representations of instances within the same class are summarized to obtain accurate class prototypes, with predictions used as weights to control contributions of typical and non-typical instances. The text discusses the use of class prototypes in domain adversarial learning to improve the reliability of global class prototypes. Feature representations are gathered for each instance to generate batch-level class prototypes, which are then used to compute global class prototypes through an averaging strategy. This process ensures more reliable conditional information for discriminators. The text introduces the Prototype-Assisted Conditional Domain Adaptation (PACDA) framework, which aligns instance-level and prototype-level features to improve intra-class compactness in the target domain. The framework includes a backbone feature extractor, a task classifier, and two discriminators (instance-level and prototype-level). The objective function includes a supervised classification loss on the source domain data. The PACDA framework aligns instance-level and prototype-level features to enhance intra-class compactness in the target domain. It includes various loss functions such as supervised classification loss, adversarial loss for feature alignment, adversarial loss for prototype alignment, and a loss for promoting intra-class compactness. Instance-level alignment is achieved through a discriminator to align feature representations, while prototype-level alignment helps align class prototype representations. The PACDA framework focuses on aligning class prototype representations across domains to ensure semantic consistency. It addresses the misalignment among semantically similar instances by incorporating class prototypes into instance predictions. Our PACDA framework promotes intra-class compactness in the target domain to address misalignment in domain adversarial learning. By minimizing a specific loss for target domain samples, we aim to enlarge the margin between instances of semantically similar classes. Experimental verification on UDA tasks demonstrates the effectiveness and generalization ability of our methods. The curr_chunk discusses various datasets used in cross-domain object recognition and synthetic-to-real semantic segmentation tasks, including ImageCLEF-DA, Office31, OfficeHome, GTA5, Cityscapes, and Synthia. Office-Home dataset contains 65 object categories in 4 settings, ImageCLEF-DA is for domain adaptation, Office31 includes 31 object categories from 3 domains, and Cityscapes is a dataset of urban street scenes with pixel-level annotations. The curr_chunk discusses datasets used in cross-domain object recognition and synthetic-to-real semantic segmentation tasks, including GTA5 with 24,966 labeled synthetic road scenes and Synthia with 9,400 synthetic images. Implementation details include using ResNet-50 model pretrained on ImageNet for object recognition with specific network parameters. The implementation details include training the classifier layer through backpropagation with specific lambda values, using a two-layer domain discriminator, fixing batch size and learning rate, adopting DeepLab-V2 for semantic segmentation, and optimizing the network with specific parameters and learning rate policies. The discriminator network follows the architecture of DCGAN and is optimized using Adam. The implementation details involve optimizing discriminators with specific parameters using Adam, setting lambda values for different tasks, and conducting experiments on a single Titan X GPU. The total iteration numbers vary for object recognition and semantic segmentation tasks. Data augmentation techniques and ensemble evaluation methods are not utilized. The comparison results between PAAL, PACDA, and state-of-the-art approaches for object recognition show improvements in accuracy. PACDA outperforms previous methods in various benchmarks. Additionally, PAAL consistently outperforms CDAN in transfer tasks. In synthetic-to-real semantic segmentation tasks, PAAL and PACDA outperform state-of-the-art methods, achieving new SOTA results with mean IoU values of 46.6% and 49.2% for GTA5\u2192Cityscapes and Synthia\u2192Cityscapes, respectively. The effectiveness of each component in the models is verified through quantitative analysis. In synthetic-to-real semantic segmentation tasks, PAAL and PACDA outperform state-of-the-art methods with mean IoU values of 46.6% and 49.2% for GTA5\u2192Cityscapes and Synthia\u2192Cityscapes. Empirical convergence curves show variants converge after 10k iterations, with PACDA framework improving tasks. A-distance measures domain discrepancy, with PACDA showing minimum distance for better feature learning. The study introduces a prototype-assisted adversarial learning scheme for unsupervised domain adaptation tasks. PAAL and PACDA are shown to improve adaptation performance in object recognition and semantic segmentation tasks, with PACDA achieving the best results by pushing away semantically confusing classes. The framework also minimizes domain discrepancy for better feature learning. Our proposed adversarial learning scheme leverages reliable class prototypes to align multi-class distributions across domains effectively, preventing misalignment. By imposing intra-class compactness with prototypes, our UDA methods outperform established baselines in object recognition and semantic segmentation tasks. The effectiveness of our PAAL is supported by the domain adaptation theory proposed in (Ben-David et al., 2010). The disagreement between hypotheses F1 and F2 in classifier classes H is quantified by the H-divergence. An upper bound on the target risk of classifier F is given by Ben-David et al. (2010). The empirical H-divergence converges to the true H-divergence for classifier classes H of finite VC dimension. Ganin & Lempitsky (2015) introduce a binary domain discriminator to minimize the empirical H-divergence, aligning marginal distributions. The proposed PAAL scheme leverages reliable conditional information in the adversarial learning module to align semantically similar samples from different domains, reducing the second term in the upper bound equation. Compared to previous methods, the input to the adversarial learning module is more compact, aiding in decreasing the second term further."
}