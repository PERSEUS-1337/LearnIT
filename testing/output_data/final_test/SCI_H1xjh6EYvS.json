{
    "title": "H1xjh6EYvS",
    "content": "Existing deep learning based artifact reduction methods in medical images are limited by their training set, leading to restricted clinical adoption. A new \"Zero-Shot\" medical image Artifact Reduction (ZSAR) framework is introduced in this paper, utilizing deep learning without pre-trained networks or clean image references. By leveraging the low internal visual entropy of an image, a light-weight image-specific artifact reduction network is trained to reduce artifacts in CT and MRI images better than current methods. The ZSAR framework utilizes deep learning to reduce artifacts in medical images without the need for a priori training sets, outperforming existing methods in both quality and speed. This approach addresses the limitations of current deep learning frameworks that rely on paired image datasets for artifact reduction. To address the limitations of current deep learning frameworks for artifact reduction in medical images, a \"Zero-Shot\" image-specific artifact approach is introduced. This method does not require paired data or clean image references, offering both high performance and versatility. The \"Zero-Shot\" image-specific artifact reduction network (ZSAR) is a deep learning method that reduces artifacts in medical images without the need for clean image references or prior training data. ZSAR extracts artifact patterns directly from input images and iteratively trains an autoencoder for artifact reduction. Experimental results show that ZSAR outperforms state-of-the-art methods in terms of quality and speed. The discussion focuses on reducing artifacts in medical images using deep learning, specifically for CT and MRI scans. Various types of artifacts are identified, influenced by factors like scan settings and patient characteristics. These artifacts can occur randomly and simultaneously in an image. The method discussed does not require prior training data and aims to improve image quality. Various deep learning methods have been proposed for reducing noise and artifacts in medical images, specifically for CT and MRI scans. These methods include CNNs, directional wavelet transforms, GANs, and multi-channel CNNs. The goal is to improve image quality by addressing various types of artifacts that can occur randomly and simultaneously in an image. In 2018, researchers explored multi-channel CNN for 3D MRI and deep learning methods to reduce artifacts. Kang et al. (2018) and You et al. (2018) used cycle-consistent adversarial denoising network to address bias in simulated data. However, clean image reference is still required, which may be challenging to obtain in some cases. The study focuses on identifying regions with significant artifacts in medical images to synthesize paired data. The proposed Zero-Shot Artifact Reduction (ZSAR) framework works iteratively to reduce artifacts in medical images without the need for pre-training. It extracts artifact patterns and synthesizes paired dirty-clean images for each specific input image. The process involves training the model to obtain weights and then applying it to reduce artifacts in the input image. The Zero-Shot Artifact Reduction (ZSAR) framework iteratively reduces artifacts in medical images without pre-training. The synthesized image is used to train a light-weight Artifact Reduction Network (ARN) to reduce artifacts in the input image. The iterative process stops when artifact levels no longer decrease, typically requiring no more than four iterations. For 3D volumes, training is done on one 2D slice as artifacts are similar across slices, allowing other slices to use the trained ARNs. In the 1st iteration, artifact patterns are extracted from the input image through an unsupervised approach. In the iterative Zero-Shot Artifact Reduction (ZSAR) framework for medical images, artifact patterns are identified through unsupervised clustering using K-means on cropped image patches. The goal is to classify patches into two clusters based on the presence of structure boundaries, allowing for effective artifact reduction. The iterative Zero-Shot Artifact Reduction (ZSAR) framework identifies artifact patterns through unsupervised clustering of image patches using K-means. The feature of each patch is extracted by calculating the standard deviation and mean value of pixel values. Clusters are formed based on the presence of structure boundaries, allowing for effective artifact reduction. In the iterative Zero-Shot Artifact Reduction (ZSAR) framework, artifact patterns are identified through unsupervised clustering of image patches using K-means. The difference between clean and output images in each iteration is considered as reduced artifact, with zero-mean artifact patterns generated by subtracting mean pixel values. Scaled artifact patterns are superposed on input images to create dirty images for training data synthesis. Paired dirty-clean data sets are formed for training neural networks for artifact reduction. In the Zero-Shot Artifact Reduction framework, artifact patterns are identified through unsupervised clustering. A compacted 11-layer contextual autoencoder is designed for artifact reduction and structural restoration. The network uses skip connections to capture contextual information and converges quickly with few epochs. The loss function is pixel-wise mean square error to preserve structural information. The network should be initialized and retrained in every iteration for more effective artifact reduction. Our CT dataset includes 48 3D cardiac CT volumes from 24 patients, with 11,616 gray-scale 2D images acquired through a 256-slice CT scanner. Dosages range from 80 kVp/55 mAs to 100 kVp/651 mAs. The MRI dataset contains 286 pulse sequences with 17,844 2D MRI images from 11 patients scanned by a 3T system. In free-precession sequence, CT and MRI images are evaluated by radiologists for structural preservation and artifact level. For quantitative evaluation in CT, the most homogeneous area in regions of interest is selected, with low standard deviation and minimal mean discrepancy after artifact reduction. ZSAR was implemented in Python3 with TensorFlow library using NVIDIA GeForce GTX 1080 Ti GPU. Xavier initialization and Adam optimization were used for training the networks. ZSAR was trained using the Adam optimization method with a learning rate of 0.0005 and 1,000 epochs. It was compared with CCADN, a deep learning method for medical image artifact reduction, and Deep Image Prior (DIP), a general-purpose denoising method. ZSAR does not require paired training data like CCADN and is based on deep learning but does not need prior training data. The study compared ZSAR, CCADN, and DIP for medical image artifact reduction. Parameters in BM3D were tuned for best quality. Results were presented with comparisons between methods using limited test images. Additional results can be found in the appendix. Mean and standard deviation were evaluated in selected regions of an input image. Fluctuations in mean were observed with increasing iterations. In the experiment, CCADN, BM3D, DIP, and ZSAR were compared for medical image artifact reduction. Results showed that CCADN, BM3D, and ZSAR preserved structure well, while DIP was visually oversmoothed. Quantitative comparison revealed DIP reduced artifacts effectively but had over 200% mean discrepancy, a critical issue for CT images. The study also applied the methods to MRI motion artifact reduction. For MRI motion artifact reduction, ZSAR showed the best results among CCADN, BM3D, and DIP. ZSAR achieved higher SNR than BM3D and similar SNR but less mean discrepancy than DIP. In non-ideal scenarios, where different artifact patterns or noise levels were present, ZSAR still performed well. For CT denoising, ZSAR outperforms CCADN and BM3D qualitatively, preserving structures well. DIP has oversmoothing issues causing tissue disappearance. Quantitatively, ZSAR achieves lower standard deviation in CT images and higher SNR in MRI compared to CCADN and BM3D. CCADN, trained in a different scenario, may even have lower SNR than the input image in some cases. ZSAR demonstrates advantages over DIP in image denoising, achieving lower SNR in certain regions. Test-time training is feasible, with ZSAR requiring less time than CCADN, BM3D, and DIP despite being trained on the spot for each input image. In this paper, ZSAR is introduced as a \"Zero-Shot\" medical image artifact reduction framework, utilizing deep learning to suppress artifacts without pre-trained networks. It converges within four iterations with minimal training data, taking about 1,000 epochs per iteration. ZSAR is simpler in structure compared to CCADN or DIP, allowing for quicker testing of 2D slices of 3D images. Experimental results on cardiac CT and MRI images show that ZSAR outperforms state-of-the-art methods in reducing noise and motion artifacts. ZSAR outperforms CCADN, DIP, and BM3D in medical image artifact reduction for CT and MRI images, achieving better results qualitatively and quantitatively with shorter execution time. ZSAR achieves higher SNR compared to CCADN, BM3D, and DIP in medical image artifact reduction for CT and MRI images."
}