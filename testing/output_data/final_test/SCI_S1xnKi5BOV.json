{
    "title": "S1xnKi5BOV",
    "content": "Recently, deep neural networks have shown the ability to memorize training data, even with noisy labels, impacting generalization performance. To address this, a method is proposed that is robust to noisy labels, with a focus on a variance regularization term to penalize the Jacobian norm of the neural network. This encourages generalization and prevents overfitting to corrupted labels. Experimental results show that this approach achieves state-of-the-art performance with high tolerance to severe noise. Large-scale datasets can be collected through crowd-sourcing, web crawling, and machine generation at a low cost, but mislabeled examples can harm generalization. Deep neural networks are susceptible to memorizing training data with randomly-flipped labels, leading to overfitting. To combat this, algorithms robust to label noise are crucial for good generalization. One approach is to reweigh training examples to prioritize those with higher correctness probabilities. Existing methods for reweighting training examples to prioritize correct ones have limitations. Ideal weighting mechanisms focus only on clean examples, neglecting incorrectly labeled data. This results in insufficient utilization of training data. Prior knowledge of noise ratio or access to a clean validation dataset is usually required, which is impractical in real applications. Correction-based approaches involve estimating noisy corruption matrices to correct labels, but this can be challenging. In this paper, the authors discuss the challenges of estimating noise corruption matrices in the presence of a large number of classes and propose a simple yet effective baseline method that outperforms complex approaches. They emphasize the importance of simpler models with smoother decision boundaries for better generalization and introduce a new algorithm that leverages noisy examples to improve overall performance. Their main contribution lies in establishing a connection between model generalization and training with noisy labels. The authors propose a novel approach for training with noisy labels, improving generalization by connecting model smoothness with subspace dimensionality. Their method is effective across various datasets, showing significant improvement over strong baselines. The authors introduce a new robust training algorithm for handling noisy labels by emphasizing that a model with lower complexity is more resilient to label noise and generalizes better. They propose a method to regularize the dimensionality of the learned subspace and the smoothness of decision boundaries to indicate the complexity of the model. The authors propose a method to regularize the predictive variance for low subspace dimensionality and smooth decision boundaries. This regularization is independent of labels and aims to improve generalization and robustness by smoothing the mapping function and decision boundaries. The variance is estimated by comparing predictions under perturbations, including input and network noise. The regularization method proposed aims to improve generalization by estimating the predictive variance through perturbations, including input and network noise. It helps learn a low-dimensional feature space capturing the data distribution and implicitly estimates the Jacobian norm. The perturbation is assumed to be small and additive, sampled from a Gaussian distribution. The Jacobian norm is related to generalization performance in neural networks. Regularization methods impose prior knowledge on model structure, encouraging low-dimensional feature spaces for better clustering of training examples and reducing prediction variance. The learning objective in neural networks focuses on reducing complexity by clustering boundaries. The method is effective across different datasets and architectures, with results shown on CIFAR-10 and CIFAR-100. Performance relative to clean settings is demonstrated, with fixed hyper-parameters for experiments. Our method achieves significantly better resistance to label noise in experiments on CIFAR-10 and CIFAR-100, with an error rate of 13.31% on CIFAR-10 and 25.73% on CIFAR-100. The method outperforms a baseline approach and does not suffer from overfitting label noise during training. Our method proposes a variance regularizer to prevent overfitting to corrupted labels, improving generalization performance of DNNs trained with noisy labels. Previous work has studied learning with noisy labels, with methods such as minimizing a distance measure and using a regularization term to select reliable examples. The proposed method introduces a variance regularizer to prevent overfitting to corrupted labels, improving DNN generalization. Previous studies focused on minimizing distance measures and using regularization to select reliable examples. Hendrycks et al. (2018) introduced Golden Loss Correction to mitigate label noise effects by estimating a corruption matrix and re-training the network. Ren et al. (2018) used a small clean validation dataset to determine training example weights. The success of these methods relies on clean data being from the same distribution as corrupted and test data, but real scenarios may involve varying distributions and class mismatches. The proposed method does not require a clean validation dataset. The proposed method introduces a variance regularizer to prevent overfitting to corrupted labels, improving DNN generalization. It does not require a clean validation dataset to work well. Label precision is computed as the portion of true clean examples among them, with 100% being ideal. The method achieves higher label precision, demonstrating better robustness. Class-dependent noise is simulated by mapping classes to semantically similar ones. The transition matrix has a probability \u03b7, with 1 \u2212 \u03b7 on the diagonal and \u03b7 off the diagonal. Results are compared to other loss-correction methods. The proposed method is robust to noise types and shows consistent performance. Test accuracy on CIFAR-100 is also shown. The algorithm's sensitivity to the hyper-parameter \u03bb was assessed, showing stable performance across a wide range of choices. Embeddings of the algorithm on test data were visualized in 2D using t-SNE, demonstrating a more separable feature space."
}