{
    "title": "BklBp6EYvB",
    "content": "A recent problem receiving attention is how to efficiently perform multiple tasks in the same network while maximizing prediction accuracy. One popular approach involves a multi-branch architecture on top of a shared backbone, jointly trained on a weighted sum of losses. However, the shared representation can lead to suboptimal performance due to conflicting gradients of uncorrelated tasks. Recent solutions involve channel-wise modulation of feature-maps along the shared backbone with task-specific vectors. A novel architecture is proposed to address this issue further. The architecture proposed modulates the recognition network channel-wise and spatial-wise with a top-down image-dependent computation scheme. It utilizes a shared top-down modulation network for all tasks, achieving comparable or superior results to other methods on various tasks. Additionally, it offers advantages in terms of model size, adding new tasks, and interpretability. Multi-task learning aims to enhance learning efficiency and prediction accuracy by training multiple tasks together in a shared network. Various architectures have been proposed for this purpose, typically involving task-specific branches on a shared backbone. While a shared representation can be more memory and sample efficient, it may lead to performance issues in cases where tasks are not correlated. The performance of multi-branch architectures in multi-task learning is influenced by relative loss weights and task correlations. Task-specific modules integrated along a feed-forward backbone have been proposed as an alternative approach. This method involves executing one task at a time during training and evaluation, which may limit the ability to add new tasks later on. The proposed architecture introduces a top-down modulation network without task-specific modules, aiming to address capacity and interference issues seen in other architectures. The proposed architecture introduces a top-down modulation network without task-specific modules. The modulation network combines task information with image information from a bottom-up network and modulates a common network for all tasks. The modulation is channel-wise and spatial-wise, allowing for task-specific spatial modulation of the image. This approach differs from previous works by being \"image-aware\" and accumulating information from the image in the modulation process. Our approach does not use multiple branches or task-specific modules, allowing scalability without additional layers. The modulation scheme includes a spatial component for attention to specific image locations. It is image-dependent and can modulate regions based on content rather than location. Empirical evaluation showed comparable accuracies with fewer parameters on uncorrelated tasks, outperforming baselines on correlated tasks, and scaling well with the number of tasks. Our proposed scheme, demonstrated on the CUB200 dataset, can handle uncorrelated and correlated tasks effectively, outperforming the channel-wise modulation approach. Inspired by Multiple Task Learning, our approach in computer vision shows distinct advantages over traditional methods. In computer vision, multi-task learning has applications in various fields like natural language processing and across modalities. Different architectures have been proposed to combine training and evaluation of multiple tasks, with recent ones using task-specific branches on top of a shared backbone. These architectures use a weighted sum of losses to train the tasks effectively. Several methods have been proposed to address the challenges of multi-task learning, such as dynamically tuning gradients magnitudes, deriving task weights based on intrinsic uncertainty, and applying adaptive weighting to force a pareto optimal solution. Several methods have been proposed to address the challenges of multi-task learning, such as dynamically tuning gradients magnitudes, deriving task weights based on intrinsic uncertainty, and applying adaptive weighting of tasks to achieve a pareto optimal solution. Other approaches include adding task-specific modules like task-specific attention networks and low-weight task-specific modules along the recognition network, such as residual convolutional layers, squeeze and excitation blocks, and batch normalization layers. These modules aim to decrease destructive interference between tasks. Our design differs from previous methods by not using multi-branch architecture or task-specific modules. Instead, our network is fully-shared between tasks and modulates feature-maps in the recognition network channel-wise and spatial-wise based on the task and specific image. Neuroscience research supports the idea of top-down modulation in the visual pathway, where top-down signals adjust neural activity in lower-order areas to enhance task-relevant representations or suppress task-irrelevant ones. In this work, a model is proposed that utilizes top-down modulation in multi-task learning, deviating from previous methods by employing a fully-shared network for all tasks. The mechanism involves adjusting neural activity to enhance task-relevant representations and suppress task-irrelevant ones, supported by neuroscience research on attention mechanisms. Our approach optimizes parameters in convolutional layers for top-down modulation in multi-task learning applications, using featuremaps as modulation tensors. This method enhances task-relevant representations and suppresses task-irrelevant ones, supported by neuroscience research on attention mechanisms. The network optimizes parameters for top-down modulation in multi-task learning using featuremaps as modulation tensors. The vector-modulation module switches between modulation vectors for different tasks, influencing the output tensor Y accordingly. Our method efficiently addresses limitations of the vector-modulation module by incorporating spatial-wise modulation and image information, leading to improved accuracy in various tasks. The modulation tensor Z is defined as Z \u2208 R H\u00d7W \u00d7C, with featuremaps used to optimize it to avoid computational challenges. Our method proposes using created featuremaps as modulation tensors to optimize weights of convolutional layers instead of directly optimizing Z. This approach allows for scalability to large images and multiple tasks, as demonstrated in our experiments. Additionally, a gated modulation module with a residual connection is defined for improved accuracy in various tasks. The network design includes a residual gated modulation module where the modulation tensor Z is gated with a sigmoid or tanh function before being added to the input tensor X. This operation is denoted by the symbol \u2297 and is used in all experiments. The design features a bottom-up recognition network modulated by a top-down modulation stream, with lateral connections between the two streams. Our architecture includes three sub-networks (BU1, TD, BU2) with the option to add auxiliary losses at the end of BU1 or TD streams for multi-task learning. A localization loss in the last TD featuremap helps generate an attention map during inference time. The approach is validated on three datasets, including MultiMNIST. The MultiMNIST dataset consists of multiple MNIST images placed on the same image for multi-task learning experiments. Different classes are assigned to tasks like classifying digits in specific positions. The CLEVR dataset, used for VQA, includes images of 3D primitives and is a diagnostic dataset. The dataset CUB200 is a fine-grained recognition dataset with bird images and binary attribute annotations. The tasks in our setup for the CLEVR dataset involve questions about 3D primitives with various compositionary properties. In contrast to previous work, attributes were re-organized into 12 tasks with 16 classes each for bird parts. LeNet, VGG-11, and resnet-18 were used as backbone architectures for experiments. BU streams share weights and consist of convolutional layers. TD stream includes parts' location as an auxiliary target. The BU streams share weights and consist of the backbone's first part. The TD stream mirrors the BU stream in structure and channels, with bilinear upsampling layers. Lateral connections via 1x1 convolutions link BU1, TD, and BU2 streams. A task embedding layer is added to the TD stream, with a classifier only attached to BU2. Comparison is made with single task and uniform scaling approaches, as well as the \"ch-mod\" architecture. See figure 1d for an illustration of the full scheme and detailed architecture in the supplementary materials. We implemented a channelwised vector modulation architecture (ch-mod) and a multi-objective optimization approach with dynamically tuned loss weights. Performance was demonstrated on the Multi-MNIST dataset for 2, 3, and 4 tasks recognition problems using a standard LeNet architecture. Training was done with a batch size of 512 images on 1 GPU with a learning rate of 1e \u22123 using the Adam optimizer. The scatter plot in Figure 4b shows the performance profile of the 2-classes experiment for single task and multi-branched approaches with manually tuned loss weights. The results of our Multi-MNIST experiment show that our method achieves better accuracies than the single-task baseline while using fewer parameters. Scaling the number of tasks maintains the accuracy gap without additional parameters. Ablation studies were conducted to examine various aspects of our proposed architecture. Ablation studies on Multi-MNIST were conducted to analyze the proposed architecture. Results show that using both image-aware and spatial-wise modulation improves accuracies compared to channel-wise modulation. Our approach, utilizing image-aware and spatial-wise modulation, boosts accuracies by approximately 3.3%. The number of channels in the TD stream is crucial, as shown in Table 2b where our proposed architecture outperforms cheaper alternatives with varying channel configurations. Our architecture incorporates two sets of lateral connections, enhancing information flow between streams. Our proposed architecture utilizes different connectivity types to improve accuracy in information flow between streams. Addition connectivity along the TD stream and gated modulation connectivity along the BU2 stream show higher accuracy. The approach also demonstrates better accuracies on a correlated set of tasks with fewer parameters compared to single task and uniform scaling approaches. Our proposed architecture utilizes different connectivity types to improve accuracy in information flow between streams. The gated modulation connectivity type was used in all experiments due to its slightly higher results. Auxiliary losses were also explored, but no additional improvement was observed in the Multi-MNIST experiment. A TD auxiliary segmentation loss can be used for interpretability, as shown in the CUB200 experiment. Our results on the CLEVR dataset demonstrate improved performance in correlated tasks with an enlarged task set using a modified VGG-11 architecture. Training was done with a batch size of 128 images on 2 GPUs, achieving better results with fewer parameters compared to single task and uniform scaling approaches. The channelwise modulation approach with the smallest number of parameters yielded the worst results. Scaling the number of tasks without additional hardware is feasible and may improve individual task results. Using a TD layers replica of VGG-11 BU layers, reducing parameters by decreasing channel dimensions in the TD stream is possible but not the main focus. Performance on correlated tasks in real-world images was demonstrated using the CUB-200 dataset and a Resnet backbone architecture, showcasing better results without parameter reduction. We trained models using a Resnet-18 architecture with a batch size of 128 images on 2 GPUs. An auxiliary loss was added at the end of the TD stream, targeting a one-hot 224x224 mask. The cross-entropy loss was minimized for each visible ground-truth annotated task/part. Results were compared to a channel-wised modulation architecture trained with the same localization auxiliary loss. Our novel architecture for multi-task learning using a top-down modulation network outperformed baselines, including the channel-wise modulation scheme, on the CUB200 database. Attention maps in Figures 4c and 4d illustrate the localization accuracy of our architecture, with Table 4 summarizing our quantitative results showing improved accuracy. Our novel architecture for multi-task learning uses a top-down modulation network that does not rely on task-dependent branches or modules. The modulation process is executed spatial-wise and channel-wise, guided by the task and image information. Tested on three datasets, our network achieved competitive accuracies on correlated and uncorrelated tasks. The scheme allows for adding tasks without increasing parameters and enables interpretability by highlighting relevant image locations. Multiple-task learning algorithms are crucial for efficient execution of various tasks in a single network. In future work, the architecture will be adapted for a wider range of applications and different approaches will be explored. The MultiMNIST experiments used an architecture based on LeNet with shared backbone and task-specific branches. The architecture includes a recognition network and a top-down stream with an embedding layer. The architecture includes a recognition network with lateral connections and a top-down stream with an embedding layer and convolutional layers. The network was trained with an auxiliary localization cross entropy loss for interpretability. More examples were presented to demonstrate the ability to identify relevant regions affecting network predictions. The network prediction successfully localizes the target part in images, with good and bad localization examples shown. Errors in localization may be due to annotation errors or the correlated nature of tasks."
}