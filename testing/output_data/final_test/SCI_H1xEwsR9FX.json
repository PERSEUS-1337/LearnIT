{
    "title": "H1xEwsR9FX",
    "content": "The best models for semantic image segmentation have traditionally combined Conditional Random Fields (CRFs) with CNNs. However, CRF post-processing has become less popular due to slow training and inference speeds. To address this, a new approach adds conditional independence to fully-connected CRFs, allowing for efficient implementation on GPUs. This significantly speeds up training and inference, with parameters easily optimized using backpropagation. Semantic image segmentation is crucial for visual perception, with Convolutional Neural Networks being strong in this task. However, deep neural networks may not be ideal for structured predictions like semantic segmentation. Authors have combined CNNs with CRFs to address this issue effectively. Structured models like CRFs have fallen out of favor due to their slow optimization and reliance on hand-crafted features. CRF inference is significantly slower than CNN inference, making CRF-based approaches impractical for many applications. To address these issues, the proposal suggests adding the assumption of conditional independence to fully-connected CRFs. The proposal introduces ConvCRFs, a framework based on fully-connected CRFs, allowing for efficient inference using convolutions on GPUs. Training with backpropagation BID30 is fast, with inference taking less than 10ms, a significant speed improvement over FullCRFs. The method aims to revive CRFs for structured tasks, leveraging recent advances in semantic segmentation with deep neural networks. Transposed convolution layers and atrous convolutions are used to produce high-resolution outputs. Many architectures utilize atrous convolutions to preserve spatial information in feature space, relying on powerful feature extraction by CNNs. Structured knowledge and background context are often ignored in these models, but integrating fully-connected CRFs on top of CNN predictions has shown success in weakly and semi-supervised segmentation tasks. This approach can benefit from the contributions proposed. Parameter learning in CRFs involves using a CRF based loss function. Different approaches have been proposed, such as optimizing parameters with expectation maximization and grid-search, using gradient descent, and implementing joint CRF and CNN training. These methods rely on hand-crafted features for Gaussian kernels and quadratic optimization to learn the Gaussian features. Quadratic optimization has been proposed for learning Gaussian features in FullCRFs, but it does not integrate well with deep learning pipelines. Piecewise training is another method for learning pairwise features, which speeds up training by avoiding repeated CRF inference. However, this approach is approximate and still results in slow inference speeds. Some CRF-based pipelines down-sample the output by a factor of 8x8 to speed up inference, but this compromises predictive capabilities. Deep learning semantic segmentation pipelines perform best when challenged to produce full-resolution predictions. Recent CRF-based approaches in semantic segmentation are primarily based on the Fully Connected CRF (FullCRF) model. The segmentation task involves modeling an input image as a random field with pixel labels. The energy function in the CRF is defined by unary potentials, which can be predicted using any segmentation pipeline. Most newer approaches aim to produce full-resolution predictions for improved performance. In semantic segmentation, newer approaches utilize CNNs to compute unary potentials. Pairwise potentials model interactions between pixels based on similarity. FullCRFs define pairwise potentials as a weighted sum of Gaussian kernels. The compatibility transformation function, like the Potts model, assigns similar pixels the same prediction. BID41 suggests using 1x1 convolutions for compatibility transformation. BID41 proposes using 1x1 convolutions for compatibility transformation in FullCRFs, which utilize Gaussian kernels with hand-crafted features for pairwise potentials. Inference in FullCRFs is achieved using the mean field algorithm, with highly parallelized steps easily implemented on GPUs. The message passing in CRF computation is a bottleneck due to its quadratic complexity. To address this, the permutohedral lattice approximation is proposed, which is efficient but complex. Gradient computation for this approximation is also challenging. Convolutional CRFs add a conditional independence assumption to FullCRFs. ConvCRFs enhance FullCRFs by assuming conditional independence based on pixel distance. This assumption reduces pairwise potential complexity, aligning with CNNs' local feature processing. The paper demonstrates efficient message passing in ConvCRFs, eliminating the need for permutohedral lattice approximation and enabling GPU computation and feature learning. The paper introduces efficient message passing in ConvCRFs by reformulating the process as a convolution with truncated Gaussian kernel. This allows for GPU computation and complete feature learning, similar to regular convolutions in CNNs. The convolution operation in the paper is efficient and implemented using standard CNN operations, with a focus on minimizing data reorganization in GPU memory to improve speed. The process involves tiling the input to obtain data with specific shape, similar to 2d-convolutions. The convolution operation in the paper, referred to as im2col, replaces the spatial dimension matrix multiplication with a batched dot-product over the channel dimension. Design choices include softmax normalization, the Potts model, and handcrafted gaussian features. Gaussian blur is applied to pairwise kernels, increasing the effective filter size by a factor of 4. Additional experiments involve replacing input features with learnable variables to learn Gaussian features. We implement a learnable compatibility transformation using 1 \u00d7 1 convolution and evaluate our method on the PASCAL VOC 2012 image dataset. Training involves using 10,582 labelled images, fine-tuning internal CRF parameters on 200 images, and training the unary CNN on the remaining 10,382 images. Results are reported on 1464 images of the official validation set using a ResNet101 to compute unary potentials and a simple FCN for segmentation predictions. The network is initialized using ImageNet. The CNN is trained for 200 epochs on Pascal VOC data with specific hyperparameters and data augmentation methods applied. The trained model undergoes data augmentation techniques such as flip, random rotation, and resize, along with color adjustments. It achieves a validation mIoU of 71.23% and a train mIoU of 91.84%. CRF mean-field inference is computed for 5 iterations, and Convolutional CRFs are evaluated on a synthetic task using PASCAL VOC dataset with augmented ground-truth labels. The CRF performance shows artefacts at object boundaries. The permutohedral lattice approximation is visible at object boundaries. The CRF is challenged to denoise predictions and compared to the original label of the Pascal VOC dataset. Augmentation involves down-sampling the ground-truth, adding random noise in low-resolution space, and up-sampling to simulate inaccuracies and prediction errors. Comparison between FullCRFs and ConvCRFs is done with hand-crafted Gaussian features. The remaining five parameters are initialized to default values. Performance of CRFs is robust with respect to these parameters. Results show ConvCRFs provide higher quality output compared to FullCRFs. In this section, experiments on Pascal VOC data using a two-stage training strategy are discussed. The unary CNN model is first trained for semantic segmentation, followed by optimizing internal CRF parameters based on CNN predictions. Decoupled training offers flexibility and allows standalone CRF training on any segmentation approach. Unary predictions serve as input for CRF training, ensuring the two stages do not need to interface. The two-stage training strategy involves training a unary CNN model for semantic segmentation first, followed by optimizing internal CRF parameters based on CNN predictions. Decoupled training allows standalone CRF training, effectively tackling the vanishing gradient problem. CRF models are trained on held-out images and evaluated on the Pascal VOC dataset, showing improved performance compared to unary baseline results. The experiments confirm that utilizing a learnable compatibility transformation and Gaussian features performs best. End-to-end training allows the CNN and CRF model to co-adapt for optimum output. Training the network involves 250 epochs with a protocol similar to CRFasRNN. Zheng et al. suggest training the unary potential first, then optimizing the CRF and CNN jointly with a reduced learning rate. In this work, the authors greatly reduce the learning rate during the second training stage and use different batch sizes for each stage. The training process takes about 30 hours using four GPUs in parallel. They introduce Convolutional CRFs as a novel design, which outperforms CRFasRNN at a much higher speed. The removal of the permutohedral lattice approximation enables efficient message passing on GPUs through convolution operations. The authors introduce Convolutional CRFs for efficient message passing on GPUs, improving training speed significantly. They also achieve a modest accuracy boost and plan to explore learning Gaussian features further. Future work includes investigating more advanced CRF architectures and applying ConvCRFs to other structured applications like instance segmentation and weakly supervised learning."
}