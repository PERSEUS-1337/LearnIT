{
    "title": "SJDJNzWAZ",
    "content": "Existing sequence prediction methods focus on time-independent sequences, which are suitable for data like natural languages but inefficient for real-world events with unequal time intervals. This work introduces methods for incorporating time into sequence prediction, utilizing neural sequence models like RNN for handling time-dependent event representation. The text introduces methods for time-dependent event representation in sequence prediction using recurrent neural nets. Two methods for event representation and using next event duration for regularization are discussed and evaluated on various datasets, showing accuracy gains over baseline models. Event sequence prediction is crucial for tasks like next word prediction in language modeling or next place prediction based on previous visits. The text discusses discrete-time and continuous-time event sequence prediction, focusing on predicting the next event in a sequence based on temporal information modeling. Continuous-time event sequence prediction aims to predict when the next event will occur in sequences with asynchronous events, such as varying time intervals between events like clinical visits or log-ins. Proper representation of temporal information in the past is crucial for predicting future events accurately. Proper representation of temporal information is crucial for event sequence prediction, especially in cases where events are associated with timestamps. Incorporating time as an additional input into sequence models like recurrent neural networks can be challenging but essential for accurate predictions. Incorporating time as a crucial factor in event sequence prediction is challenging for recurrent neural networks due to the wide value range of continuous input. Humans excel at characterizing time spans with high-level concepts, which vary depending on the event. Our paper introduces two methods for time-dependent event representation in neural sequence prediction models. The text discusses the use of time span associated with events to enhance event characterization in neural sequence prediction models. Two methods for time-dependent event representation are proposed, including using next event duration as a regularizer for training. The methods are evaluated on various datasets to improve sequence prediction accuracy. Recent experiments in literature have shown the effectiveness of recurrent neural networks (RNN) with Long-Short Term Memory (LSTM) in improving prediction accuracy for discrete-time event sequences. These methods have been successful in tasks such as neural machine translation, image captioning, and speech recognition. The conditional probability of the next event is estimated using RNN with parameters \u03b8 and a hidden state vector h t, which encodes past event information. Event representation in a continuous vector space is achieved by feeding events as categorical variables into the network. Event representation in a continuous vector space is achieved through embedding, providing a dense representation that improves learning. Embedding vectors encode the meaning of events relative to each other, with similar events having closer vectors. Temporal point processes model inter-event intervals as continuous random variables for event sequence prediction. In this work, the focus is on expanding the flexibility of temporal point processes using recurrent neural networks to predict the timing of the next event based on the current hidden state. The approach aims to let the model learn a proper representation for encoding temporal information in a sequence, similar to learning embeddings for words. This method is considered an \"embedding\" approach rather than proposing a new model. Our approach is an \"embedding\" approach for time in event sequence prediction models, incorporating duration and intervals. We treat idle periods as special events, making duration an inherent property of an event. We propose methods to integrate continuous time into neural sequence prediction models for timedependent event representation. Our approach integrates continuous time into neural sequence prediction models for timedependent event representation. To address the issue of disambiguating words in neural machine translation, we propose a method to learn a time mask to contextualize event embedding, enhancing the resolving power of the recurrent layer. Our approach involves computing a time context vector for duration using a nonlinear transformation implemented as a neural network. A time mask is generated by linearly transforming the context vector, followed by a sigmoid activation to create a mask for event embedding. This mask is then applied to enhance the resolving power of the recurrent layer in event sequence prediction. Our approach involves encoding the duration of an event using soft one-hot encoding and forming a joint embedding with the event. This is achieved by projecting the scalar duration value onto a vector space using a weight matrix and bias vector. The duration of an event is encoded using soft one-hot encoding by projecting the scalar value onto a vector space with a weight matrix and bias vector. Softmax function is applied to the projection vector to compute the soft one-hot encoding, which is then projected onto a time embedding space. The joint embedding of an event and its duration is formed by taking the mean of their embedding vectors, which is then input to the recurrent layer. A regularization technique involves predicting the duration of the next event and using the prediction error as an additional loss component during backpropagation. This helps in learning and can be combined with the recurrent layer output for event prediction regularization. The regularizer for duration prediction error at step t is defined as the negative log likelihood. Minimizing the squared error can be formulated as maximizing the probability density of a zero-mean Gaussian distribution. The regularizer for duration prediction error is updated iteratively during training based on the duration prediction error distribution. Softmax is used to project duration values onto a categorical space, allowing for the computation of cross entropy loss as a regularizer. The effectiveness of these approaches is evaluated on five real-world datasets. The proposed approaches on five real-world datasets include Electrical Medical Records, Stack Overflow Dataset, Financial Transaction Dataset, and App Usage Dataset. The goals range from predicting major diseases in ICU patients to predicting the next badge a user will receive on a question-answering website. The App Usage Dataset involves predicting the next app a user will use based on their app usage history, with 5,891 app usage sequences and 2.8 million app usage events collected. The Music Recommendation dataset aims to predict the next five unique songs a user has not listened to, based on their listening history involving millions of listening events. The dataset includes 5,891 app usage sequences with 2.8 million events. Sequences with less than 50 app launches or shorter than a week were excluded. The dataset was split into training (80%), validation (10%), and test (10%) sets with no overlap in users. Events with less than 5 occurrences in training were assigned an OOV id. There are 7,327 events in the vocabulary, including unique apps, idle event, and OOV. In practice, Precision@K is used to evaluate the performance of predicting the next 5 apps in a dataset with 7,327 events and 7,325 unique apps. For music recommendation, sequences shorter than 50 events and songs with fewer than 50 listens were removed. This resulted in 221,920 sequence examples with 71,619 unique songs for recommendation. Each example consists of a listen history and a set of 5 unique songs to recommend, generated by splitting original listen sequences into segments. We allocated 221,920 sequence examples with 71,619 unique songs for training, validation, and testing. Different models like NoTime, TimeConcat, TimeMask, TimeJoint, and RMTPP were compared using MAP@K and Precision@K for evaluating music recommendation performance. For the music recommendation experiments, various models were compared using MAP@K and Precision@K metrics. The models included RMTPP and four regularized models based on R FORMULA3. A two-layer hierarchical softmax was used for the output layer due to the large vocabulary size. LSTM units were used for the recurrent layer, and ReLu for the activation function. Parameters were determined based on training and validation datasets, with event embedding dimension, LSTM units, and projection layer size set to 128. The same setting as the app prediction experiment was used for the music recommendation data. For the App Usage and Music Recommendation tasks, models were implemented in TensorFlow with specific architecture and hyperparameters chosen based on validation datasets. Truncated back-propagation through time was used for the App Usage experiment with an adaptive gradient descent optimizer. Dropout was not utilized in the experiments. For the Music Recommendation experiment, full sequence back-propagation through time with 2% dropout ratio on the recurrent layer was used for better generalization. The Adam optimizer by BID11 with a learning rate of 0.00005 and a gradient clipping threshold at 1.0 was employed. Training was conducted on a distributed learning infrastructure with 50 GPU cores. Comparisons between models on three public datasets are presented in FIG2. The proposed methods for time-dependent event embedding outperformed other approaches on public datasets like Stack Overflow and Financial, but not on MIMIC II. TimeJoint showed superior performance and efficiency in representing time compared to scalar values in RNN models. Our methods also outperformed RMTPP for event prediction, especially on App Usage and Music Recommendation datasets. TimeJoint consistently outperformed other methods, while TimeMask also showed good performance. Our proposed methods for time-dependent event embedding outperformed other approaches on public datasets like Stack Overflow and Financial, but not on MIMIC II. TimeJoint showed superior performance and efficiency in representing time compared to scalar values in RNN models. Additionally, using time directly without proper representation, like TimeConcat, can sometimes hinder performance. The effectiveness of event duration regularization was demonstrated, showing performance improvement in many cases. The crossentropy regularizer, R X t, consistently improved performance with temporal embedding approaches. The TimeJoint approach learned to project scalar time values into a soft one-hot encoding, particularly for short time periods. For short time periods, more dimensions are needed to express differences in continuous time values. As time periods grow, fewer dimensions are required. Methods were proposed for leveraging temporal information for event sequence prediction, including time masking and time-event joint embedding. Two methods for using next duration as regularization for training sequence prediction models were introduced. Experiments on real data showed consistent performance gains by incorporating time into the models. Experiments on real data demonstrate consistent performance gains by incorporating time into event representations before feeding them to recurrent neural networks."
}