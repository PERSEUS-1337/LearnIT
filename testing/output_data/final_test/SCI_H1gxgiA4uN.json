{
    "title": "H1gxgiA4uN",
    "content": "Deep learning approaches typically require a large amount of labeled data to generalize, while humans can learn new concepts with just a few samples. This paper focuses on classifying multiple objects with few samples from each category, introducing a new task for few-shot multiclass classification. The authors created a dataset for this purpose and demonstrated its effectiveness using an extension of prototypical networks. Few-shot learning approaches aim to bridge the gap between human and machine capability in learning new concepts with limited labeled samples. Mini-ImageNet and tiered-Imagenet BID19 datasets are developed to aid research in few-shot classification. Learning multiple new concepts simultaneously with only a few samples each is a challenging task for both humans and machines. Understanding how humans achieve this high cognition task remains an active area of study. In this paper, the focus is on extending few-shot learning to multi-class few-shot classification to bridge the gap between human cognitive capability and machine learning approaches. The goal is to define a dataset, setup, and evaluation metric to address this problem. The study aims to understand how humans can learn multiple new concepts in parallel with only a few samples. The paper proposes a new task of multi-object few-shot classification to test models' ability to represent several objects in an image. It introduces an extension to prototypical-style models for efficient solving of the task and constructs a new dataset for clean and controlled environment of multi-object images. The paper introduces a new task of multi-object few-shot classification, providing a framework, benchmarks, and code for exploring controlled scenarios. Few-shot learning involves learning new concepts with limited labeled data, addressed by datasets like mini-Imagenet and tiered-Imagenet. Different approaches include optimization-based and metric-based frameworks. Meta-learning approaches in few-shot learning involve learning a parameterized function for classifiers and a metric-based framework that minimizes intra-class distances while maximizing inter-class distances. Approaches like Matching networks and Prototypical networks use episodic training with attention mechanisms and metric spaces to improve one-shot classification. Several methods have been proposed to improve few-shot learning, such as leveraging unlabeled samples, augmenting support sets with hallucinated examples, and using task-dependent adaptive metrics. One approach, TADAM, relies on conditional batch normalization for task adaptation. A task of multi-object few-shot classification is proposed to test the ability to disentangle unseen objects in an image. In meta-learning, a dataset consists of tasks rather than input-label pairs. Each task in a K-shot N-way classification has a support set and a query set. Prototypes are computed by embedding images and averaging for each class. A proposed extension is the K-shot N-way D-dense task, where the support set includes D labels for each object. The learner is exposed to every object class exactly K times in a tuple of D labels. The query set contains images with ground truth labels, and multi-prototype networks are proposed to handle the exponential label size. The model is trained to produce D embeddings for each image to extend the proto-net setup. The model is trained to produce D embeddings for each image in the proto-net setup. A dataset based on Shapenet 3D models rendered with Blender is developed for reliable experiments. The dataset allows for constructing single or multiple object tasks with flexibility in task parameters. Results are compared with the TADAM BID17 model for different object setups. The dataset was created using 3D meshes from Shapenet BID3 dataset, with 55 classes split into subsets for training, validation, and testing. Images were rendered by placing meshes on canvases with random colors and textures. The model was trained using a prototypical network and TADAM with 12-block. The dataset is simpler than mini-ImageNet but not trivial. The proposed MultiProtoNet is applied to increase the number of objects per image. All experiments use a 12-block residual network optimized with Adam. The accuracy drops significantly when transitioning from single to multiple objects. In this work, a few-shot multi-object classification task was introduced along with a dataset generation environment. The dataset was compared to existing ones for single-object cases, and experiments were conducted using prototypical networks for multi-object cases. The task aims to diagnose metric-learning models disentangling multiple objects in an image. Future directions include lifting known object order limitations, using stronger feature extractors, and extending the work to more natural data."
}