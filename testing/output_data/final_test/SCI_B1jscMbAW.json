{
    "title": "B1jscMbAW",
    "content": "The learning of algorithmic tasks through observation of input-output pairs is focused on tasks amenable to divide and conquer. Neural architectures leverage this principle by learning atomic operations to split inputs and merge partial solutions. The model can be trained in weakly supervised environments and incorporates a dynamic architecture. The Divide-and-Conquer Network demonstrates flexibility and efficiency in solving combinatorial and geometric tasks such as convex hull, clustering, knapsack, and euclidean TSP. The model's dynamic programming nature leads to significant improvements in generalization. The \"black-box\" vision of algorithmic tasks hides fundamental questions about optimal solutions and generalization. Tasks often exhibit scale invariance or self-similarity, leading to recursive solutions and dynamic programming. In discrete mathematics, this principle is essential, while in image and audio processing, invariance principles like translation invariance and scale separation are critical for success. The model of divide and conquer in discrete algorithmic tasks allows for parameter sharing across tasks. The divide and conquer principle allows for parameter sharing across scales, similar to CNNs and RNNs. Attention mechanisms can have quadratic complexity, impacting generalization performance. Dynamic neural networks split sets, while another network merges solutions at different scales. Our Divide-and-Conquer Networks (DiCoNet) utilize a split phase to create a hierarchical partition encoded as a binary tree and a merge phase to combine partial solutions. Each phase is controlled by a neural network for parameter sharing across scales, promoting good sample complexity and generalization. The goal is to incorporate scale-invariance prior with weak supervision. Our framework, Divide-and-Conquer Networks (DiCoNet), incorporates scale-invariance prior with weak supervision. It utilizes a split phase for hierarchical partitioning and a merge phase for combining solutions. The split parameters are trained using policy gradient, while the merge phase uses standard backpropagation. The dynamically determined architecture includes computational complexity as a regularization term. Experimental results on algorithmic and geometric tasks show that computational complexity correlates with generalization error in tasks with scale self-similarity. The current research focuses on using neural networks for algorithmic tasks, with models tracing back to context-free grammars. RNNs, LSTMs, sequence-to-sequence models, attention mechanisms, and external memory models dominate the field. Neural GPU defines a convolutional neural architecture applied iteratively. Neural Programmer-Interpreters introduce a compositional model based on LSTM for learning generic programs with full supervision using execution traces. BID4 incorporates recursion to enhance capacity with recursive execution traces. Hierarchical attention mechanisms improve model complexity from traditional attention to o(n log n). Pointer Networks modify attention mechanisms for variable input-dependent outputs on geometric algorithmic tasks. The text discusses models for geometric algorithmic tasks in the \u0398(n^2) category class, focusing on tasks with variable-sized input sets and ordered output sets. It emphasizes tasks that are self-similar across scales, where the solution can be estimated from partial solutions. The text discusses solving tasks by recursively splitting input sets into smaller subsets and merging the outputs. It focuses on binary splitting for simplicity, extending to more general versions. The goal is to learn how to perform tasks for any size n using input-output examples. The model uses a trainable binary split module to partition input data into a binary tree structure. This tree is data-dependent and varies for each input example. A merge module then produces an estimate based on the binary tree partition. The model utilizes a binary split module to partition input data into a tree structure, with a merge module producing an estimate based on the partition. The setup involves transforming inputs at the leaves of the split tree using a neural network, ensuring computation load does not diverge. Additionally, the model can address problems where costs or rewards are assigned to input partitions, mapping inputs to partitions evaluated by an external black-box for cost assessment. The model uses a binary split module to partition input data into a tree structure, with a merge module producing an estimate based on the partition. The cost function assigns costs to input partitions evaluated by an external black-box. Optimizing the cost function over partitions is generally intractable, but hierarchical splitting can be used as an efficient strategy for tasks with self-similarity. The model utilizes a binary split module to divide input data into a tree structure, optimizing a cost function over partitions. The recursive application of a single block enables better generalization and computational complexity regularization in tasks with scale invariance. This approach allows for a trainable divide-and-conquer architecture to achieve optimal computational complexity. In a trainable divide-and-conquer architecture, the split block S \u03b8 minimizes computational complexity by regularizing the split operation. It receives a variable-sized set X and produces a binary partition X = X 0 X 1 encoded with binary labels z 1 . . . z n. These labels are sampled from probabilities p \u03b8 (z m = 1 | X) invariant by permutation of input elements. The Set2set model constructs a nonlinear set representation by cascading R layers. The parameters of S \u03b8 are \u03b8 = {B 0 , B 1,r , B 2,r , b}, with input normalization to avoid covariate shifts. The binary partition tree is constructed recursively by computing p \u03b8 (z | X) and sampling from the distributions to obtain X = X 0 X 1. The resulting distribution over tree is denoted by a normalization of input variables x j and mean and variance \u00b5(X) = (\u00b5 0 , \u03c3) fed to the first layer. Graph neural networks or neural message passing can be applied if the input has a structured form like vertices of a graph. The merge block M \u03c6 takes input sequences Y 0 , Y 1 to produce output sequence O. A stochastic matrix \u0393 Y is computed to express the output O by binarizing its entries and multiplying it by the input. The target output exists at the coarsest scale of the partition tree for weakly supervised tasks. A generative version M g \u03c6 of the merge block uses predictions to sample an output sequence. The merge block M \u03c6 uses predictions to sample an output sequence, employing Pointer Networks and Graph Neural Networks. Pointer Networks encode input sequences and decode output sequences using RNNs, with trainable parameters \u03c6. The Divide and Conquer Networks can be applied to problems formulated as paths on a graph, leveraging Graph Neural Networks to merge partial solutions. The merge operation is performed at each node in a partition tree, using a symmetric, non-negative function parametrized with a neural network. The merge operation in Divide and Conquer Networks is performed at each node in a partition tree using a symmetric, non-negative function parametrized with a neural network. The merge module outputs a stochastic matrix that acts as a factorized attention mechanism over the input partition. The model in Divide and Conquer Networks uses a merge operation at each node in a partition tree, connecting outputs as inputs to the next block. The recursive merge over the binary tree reparametrizes the global permutation matrix. The model is trained with maximum likelihood using non-binarized stochastic matrices, and regularization is applied to avoid singularities. Binarization of stochastic matrices at fine scales is done when the model is close to convergence. The model in Divide and Conquer Networks uses a merge operation at each node in a partition tree, connecting outputs as inputs to the next block. Binarization of stochastic matrices at fine scales is done when the model is close to convergence. The model parameters {\u03b8, \u03c6} are estimated under two different learning paradigms using non-binarized stochastic matrices. The merge phase M \u03c6 is akin to a structured attention mechanism, and the gradient is well-defined and non-zero almost everywhere. However, \u2207 \u03b8 log p \u03b8,\u03c6 (Y | X) is not well-defined due to discrete sampling steps, so an identity used in policy gradient methods is used instead. The curr_chunk discusses the use of a policy gradient method to estimate the probability density of a random partition in a model. It also mentions training the model with a black-box system producing rewards and presents experiments on algorithmic tasks. The convex hull of a set of points in 2D geometry is efficiently computed using divide and conquer strategies, achieving an algorithm complexity of \u0398(n log n). The process involves splitting the points into two subsets and recursively solving the problem for each, with a merge phase done in linear time. The DiCoNet algorithm efficiently computes the convex hull of points in 2D geometry using a divide and conquer approach. It involves splitting points into subsets and recursively solving the problem, with a merge phase done in linear time. The model is tested on a dataset of n points sampled in the unit square, showing good performance despite a non-optimal split strategy. The DiCoNet algorithm efficiently computes the convex hull of points in 2D geometry using a divide and conquer approach. The model is tested on a dataset of n points sampled in the unit square, showing good performance despite a non-optimal split strategy. Parameters are initialized for the baseline and train both split and merge blocks to save computational time. The merge block is supervised with the product of continuous \u0393 matrices. The depth of the tree is fixed based on the partition size. Results show improved performance when both blocks are trained jointly. The DiCoNet algorithm tackles clustering tasks by finding k clusters of data points in R d using a GNN for the split block. The model is tested on two datasets, including one constructed by sampling k points in a Gaussian distribution. The DiCoNet algorithm uses a GNN for the split block to find k clusters in data points in R d. Two datasets are tested, one with points sampled from a Gaussian distribution and another with random patches from CIFAR-10 images. The baseline model is compared with DiCoNet, which optimizes k-means FORMULA0 without split regularization for balanced partitions. The 0-1 Knapsack problem involves selecting a subset of items to maximize total value without exceeding a weight limit. DiCoNet algorithm shows better scalability with the number of clusters compared to the baseline model. It combines aspects of Lloyd's and its recursive version, achieving the best results in the CIFAR-10 patches dataset. The NP-hard combinatorial optimization problem of the 0-1 Knapsack involves selecting items to maximize value without exceeding weight limit. Dynamic programming can provide a polynomial time approximation within a factor of the optimal solution. Recently, LSTM-based models were used to approximate knapsack problems. DiCoNet algorithm utilizes a GNN architecture to select a subset of inputs that fill a fraction of the target capacity. The DiCoNet algorithm uses a GNN split module to select a subset of inputs that fill a fraction \u03b1 of the target capacity W. It samples from a multinomial distribution without replacement until reaching \u03b1W, then recursively fills the rest of the capacity (1-\u03b1)W. This process is repeated a number J of times, with the last call filling all the capacity. The model is trained on 20000 problem instances of size n=50 and evaluated on new instances of size n=50, 100, 200 with uniform distributions for weights, values, and capacities. The DiCoNet algorithm uses a GNN split module to select a subset of inputs that fill a fraction \u03b1 of the target capacity. It samples from a multinomial distribution without replacement until reaching \u03b1W, then recursively fills the rest of the capacity. The model is trained using REINFORCE and achieves better performance compared to other models, but the Dantzig greedy algorithm outperforms it for larger input sizes. The DiCoNet algorithm uses a GNN split module to select a subset of inputs that fill a fraction \u03b1 of the target capacity. It samples from a multinomial distribution without replacement until reaching \u03b1W, then recursively fills the rest of the capacity. The model is trained using REINFORCE and achieves better performance compared to other models, but the Dantzig greedy algorithm outperforms it for larger input sizes. Eventually, a 5-layer GNN outperforms DiCoNet for n = 200, suggesting potential improvements by relaxing scale invariance or incorporating extra prior knowledge. The knapsack problem approach does not perform as well as BID2 in obtaining the best approximation, but the algorithm has strengths such as generalizing to larger ns than those used for training. It would be interesting for future work to combine the strengths of both approaches. The DiCoNet algorithm uses a GNN split module to select a subset of inputs that fill a fraction \u03b1 of the target capacity. It performs better than the non-recursive model, especially for n \u2264 100, but its performance degrades at n = 200. The model achieves better solutions with more splits as n increases, highlighting the problem's highly constrained nature. The DiCoNet architecture significantly outperforms the baseline and the Dantzig algorithm. The DiCoNet algorithm utilizes a neural architecture to exploit scale invariance in algorithmic tasks by recursively splitting large inputs, solving subproblems, and merging solutions. This approach leads to improved generalization and sample complexity across various problem sizes. The model outperforms non-recursive models, especially for smaller inputs, but its performance degrades for larger inputs. In future work, the plan is to extend the results of the TSP by increasing the number of splits, refining the supervised DiCoNet model with the non-differentiable TSP cost, and exploring higher-order interactions using Graph Neural Networks. Additionally, experiments will be conducted on other NP-hard combinatorial tasks. The TSP is a prime example of a NP-hard combinatorial optimization problem with practical applications, motivating data-driven models to generalize existing heuristics or improve them. Data-driven approaches to the TSP can be formulated in two ways: using the input graph and ground truth TSP cycle to train the model, or considering other methods. The text discusses training models for the Traveling Salesman Problem (TSP) using ground truth cycles or minimizing the cost of predicted cycles. Reinforcement learning has been used to address the non-differentiability issue, but generalization to larger instances is a challenge. The focus is on supervised learning with ground truth cycles, comparing a baseline TSP formulation with a Graph Neural Network to a DiCoNet model with split and merge modules. The split module uses a GNN to output binary probabilities for each node. DiCoNet is a Graph Neural Network (GNN) trained for the Traveling Salesman Problem (TSP) with a split module that outputs binary probabilities for each node. It is applied recursively until a fixed scale J, and a merge module combines signals from its leaves to generate a signal over the edges of the complete union graph. The model has been trained for n = 20 nodes and leverages scale invariance at larger scales. The DiCoNet, a Graph Neural Network trained for the Traveling Salesman Problem (TSP), leverages scale invariance at larger scales for better results and scalability. Preliminary results show that the dynamic model outperforms the baseline due to its powerful prior on scale invariance. The merge block M \u03c6 takes input sequences Y 0 , Y 1 and produces an output sequence O, essential for constructing the final solution. The architecture for this module is modified to perform fine-scale computation using a Pointer Network (PtrNet) as the merge block M \u03c6. PtrNet is an auto-regressive model that encodes input sequences into a global representation and decodes the output sequence. The trainable parameters \u03c6 are regrouped to the RNN encoder and decoder parameters for target sequence prediction. The architecture utilizes a Pointer Network (PtrNet) as the merge block M \u03c6 for fine-scale computation. The conditional probability of the target given the inputs is computed through attention over embeddings, leading to an output expressed in terms of a probability distribution over input indexes. In weakly supervised tasks, a generative version of the merge block is considered for sampling an output sequence. The initial merge operation at the finest scale is defined as the previous merge module applied to the input. The successive merge blocks are connected to evaluate and run the whole system."
}