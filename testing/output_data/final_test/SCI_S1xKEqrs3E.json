{
    "title": "S1xKEqrs3E",
    "content": "Data augmentation is a technique to enlarge the training set and prevent overfitting in machine learning tasks. The proposed Parallel Adaptive GAN Data Augmentation (PAGANDA) automatically enriches the training set with sample images from Generative Adversarial Networks (GANs). This strategy improves model performance in tasks like image classification and inpainting. Data augmentation enlarges the training set to prevent overfitting in machine learning tasks. Prior work has focused on strategies like crop, mirror, rotation, and distortion. Adversarial data augmentation strategies have also been explored. Source code and experimental details are available at the provided URL. Recent work in data augmentation has shifted towards utilizing generative adversarial networks (GANs) to produce images that better encode features in the latent space of training data. This approach aims to circumvent the need for domain-specific knowledge and manual operations required by traditional data augmentation methods. By optimizing the generator G and the discriminator D in the GAN, images similar to the training data can be generated. In this paper, the authors propose Parallel Adaptive Generative Adversarial Network Data Augmentation (PAGANDA), where the training set enriches itself with sample images automatically constructed from GANs trained in parallel. Their contribution includes a general adaptive black-box data augmentation strategy to enhance training data without task-specific requirements. The authors propose a black-box data augmentation strategy to diversify training data and introduce a novel K-fold parallel framework in their model. Experiments show the effectiveness of their method across various datasets and tasks. Previous work on data augmentation includes traditional heuristic strategies and adversarial data augmentation methods. Adversarial Data Augmentation strategies aim to maximize the loss function of the classification model with limited supervision. While effective, these methods have limitations in generalization. BID18 BID4 transform the problem into a reinforcement learning policy search, but have limited augmentation methods and high computation overhead. BID19 proposed a CNN for classifying environmental sounds with limited samples, but many algorithms have constraints that hinder generalization. Recent research on sample complexity reduction in GAN training aims to reparametrize input noise using variational inference, but faces mathematical limitations. Transfer learning techniques in GAN training require a pre-trained network and may not be applicable with limited data. Parallel/Distributed GANs have been proposed, but they require large datasets and have high computational complexity. The Parallel Adaptive Generative Adversarial Network Data Augmentation (PAGANDA) method is described, consisting of three components. The Parallel Adaptive Generative Adversarial Network Data Augmentation (PAGANDA) method involves generative data augmentation, parallel image generation, and adaptive weight adjustment to make full use of existing images. It starts with a limited training set and uses a generative adversarial net to generate varied images by adding samples. The procedure involves generating sample images using a specific method and calculating the Inception Score to measure image authenticity. The generated images are then added back to the training set for further augmentation epochs. The process is independent of the GAN architecture used and aims to reveal potential image features. Our method automatically enriches the training set by generating images with potential features not visually evident in the original training images. It involves a parallel data generation strategy inspired by K-fold cross validation in machine learning, where each generator is trained on a different data group. The sample images produced during augmentation epochs are fed back into the respective training data groups. The generator images are inserted into training data groups to maximize usage and prevent overfitting. Adaptive generator weighting is used to determine the most effective generators for authentic image generation. The inception scores of generators are used to determine their weights for sampling images to be sent to other data groups for training. This method allows generators with better performance to contribute more to the training data, resulting in more realistic training sets and improved image generation. The strategies work together seamlessly without the need for model-specific considerations. Training different GANs in parallel from various data folds significantly enhances training set quality and generated image quality. PAGANDA is effective for image classification and inpainting tasks, using datasets from Imagenet, Cifar-10, and Places. The augmented datasets improve classification results and inpainting quality compared to unaugmented datasets. In a multi-threaded environment, the model is trained simultaneously on all data groups. Experiments are conducted on a server with Tesla-V GPU and Intel Xeon Processor E5. Classifier accuracies with and without augmentation are compared for Cifar-10 and Imagenet datasets. For inpainting, a WGAN-GP model is trained on an augmented dataset, and testing images with gray masks are used for evaluation. Our paper demonstrates the effectiveness of PAGANDA in improving performance for various machine learning tasks without requiring task-specific considerations. The approach involves generating patches on masked images using a trained WGAN-GP model. Visual comparisons show the success of our method, which is simple to implement and adaptable to different settings. Future work includes exploring the relationship with other methods and optimizing the strategy further. Our aim is to optimize our strategy using recent theoretical advances and investigate scenarios where interrelated tasks are involved. We plan to apply our parallel GAN model to multi-modal image synthesis with limited training data."
}