{
    "title": "rk4Wf30qKQ",
    "content": "Recent work has introduced attacks that extract architecture information from deep neural networks (DNN) to enhance an adversary's capability to conduct attacks on black-box networks. This paper presents an in-depth security analysis of DNN fingerprinting attacks that exploit cache side-channels. The attack, named DeepRecon, reconstructs the victim network's architecture using internal information extracted via Flush+Reload, a cache side-channel technique. By passively monitoring the accesses of target functions in the shared framework, the attacker can reconstruct the victim's entire network. In our evaluation, we demonstrate that an attacker can accurately reconstruct complex networks (VGG19 and ResNet50) with just one forward propagation. The attacker can build a meta-model to fingerprint the architecture and family of the pre-trained model. We also propose new defense techniques to obfuscate the attacker's observations and understand DNNs' vulnerability to cache side-channel attacks. DNN architectures are crucial in various applications like face recognition, speech recognition, and autonomous driving. The performance of a DNN depends on its network architecture, which includes the number and types of layers and activation functions. Researchers and practitioners work on designing different DNN architectures for high performance in various tasks. However, these architectures are vulnerable to DNN fingerprinting attacks, where adversaries probe confidential models to distinguish them from others. DNN fingerprinting can reveal secret information to adversaries and enable attacks on black-box models. Adversarial machine learning often assumes a white-box setting, but researchers are now focusing on black-box settings. Adversaries conduct DNN fingerprinting attacks to infer model information and craft adversarial examples to evade the model, enabling model extraction and other attacks. Recent work has explored attacks that utilize information leaked by architectural side-channels on the hardware where the DNN model runs. BID8 demonstrated extracting the network architecture of a model running on a hardware accelerator by monitoring. In this paper, the authors investigate the vulnerability of DNNs to side-channel attacks and the information needed for architecture fingerprinting. They introduce DeepRecon, an attack that reconstructs a black-box DNN architecture using the Flush+Reload technique. New framework-level defenses against these attacks are proposed and evaluated. The authors introduce DeepRecon, an attack targeting specific network architecture attributes of a deep learning framework by flushing lines of code from the instruction cache. This attack allows for the reconstruction of a black-box DNN architecture and proposes new framework-level defenses against such attacks. The DeepRecon attack targets specific network architecture attributes of a deep learning framework by manipulating the shared instruction cache. By learning which functions were accessed during inference, an attacker can extract 8 architecture attributes across 13 neural network architectures with high accuracy. This attack can reconstruct the victim's DNN architecture without query access, assuming the attacker and victim are co-located and use the same DL framework. The attacker demonstrates reconstructing network architectures of VGG16 BID20 and ResNet50 BID6 as proof of concept using DeepRecon. They also show model fingerprinting in a transfer learning attack. Countermeasures are proposed to obfuscate attackers from extracting correct attributes and sequences, increasing errors in extracted attributes. Cache side-channel attacks exploit information leaks from vulnerabilities in computer systems due to shared L3 cache in modern micro-processor architecture. Cache side-channel attacks exploit vulnerabilities in computer systems by monitoring access time to shared contents in the L3 cache between CPU cores. Attackers can use techniques like Prime+Probe or Flush+Reload to identify accessed memory addresses or shared data, potentially stealing cryptographic keys or breaking isolation between virtual machines. These attacks can create covert channels between processes, posing a significant security risk. The Flush+Reload technique is used in cache side-channel attacks to monitor shared memory accesses between CPU cores. By repeatedly calling the clflush instruction, an attacker can determine which data is in use and identify the control flow of the victim's process. This method produces less noise compared to Prime+Probe, making it a preferred choice for attacking black-box DNNs. The Flush+Reload technique is used in cache side-channel attacks to monitor shared memory accesses between CPU cores, producing less noise compared to Prime+Probe. Various methods have been proposed to attack black-box DNNs, including model extraction and inversion attacks. However, these attacks often require unrealistic conditions. The DeepRecon attack aims to reconstruct black-box DNN architectures, bridging the gap between realistic scenarios and their conditions. The DeepRecon attack aims to reconstruct black-box DNN architectures using side-channels such as memory, timing, power, and cache. Unlike previous methods, this attack does not require physical access to the hardware and can help meet the assumptions of other attacks. Concurrent work by BID30 shows that attackers can reveal architecture details through reverse engineering GeMM libraries. GeMM-based reverse engineering can only expose parameters of certain layers, as activation and pooling layers are harder to characterize. DeepRecon can be performed independently of hardware, making it more versatile for DNNs running on different hardware. Using Known Student Models proposes a transfer learning technique where attackers identify teacher models using known student models from the Internet. The attacker can estimate the victim's architecture by using a brute-force approach and meta-models. They trained all possible architectures, pruned models with inferior performance, and trained a meta-model to identify the network architecture using mutated samples and labels. However, this process is time-intensive and limited in architectural choices. In contrast, the approach in this study goes further by fingerprinting families of architectures and reconstructing arbitrary teacher model architectures with high accuracy. The threat model for the DeepRecon attack involves an attacker launching a process on the same machine as the victim to observe the victim's DNN behavior without querying the model directly. The attacker can achieve co-location by logging into the machine or disguising their process as a benign program. The attacker can easily launch a monitoring process by reverse-engineering shared DL frameworks to identify addresses of functions in the instruction cache. This allows them to evade malware detection in common black-box attacks by actively monitoring and synthesizing evasive samples. The attacker can evade detection by monitoring the victim model with a chrome add-on, training a surrogate model, and crafting malware that evades detection offline. This method reduces the risk of being caught compared to common black box attacks. The DeepRecon attack involves the attacker analyzing the victim's deep learning framework, collecting target functions, and launching a process on the same host machine to monitor and extract information during the victim's model training or predictions. The attacker periodically flushes cache lines to measure access time to target instructions, evading detection by monitoring the victim model with a chrome add-on and crafting malware offline. The attacker flushes cache lines to measure access time to target instructions, collecting data on the victim's architecture attributes. By analyzing TensorFlow v1.9.0-rc0 framework, the attacker identifies target functions corresponding to these attributes, which can be applied to other popular ML frameworks like PyTorch/Caffe2. The attack on TensorFlow leverages the ML framework's structure, monitoring functions below the API interface and above system-dependent code. It is independent of the specific TensorFlow API or processing hardware used by the victim. The monitored functions track control flow and architecture attributes, allowing observation of queries and model updates during training. The function monitoring queries is crucial for individual observations. The architecture attribute functions in TensorFlow allow observation of neural network attributes and sequence. The bias operator gradient function helps attackers determine layers updated during training, revealing freezing points in backpropagation. This knowledge aids in identifying inherited layers from the training model. The relevance of identifying inherited layers from the training model will be discussed in our application of DeepRecon to model fingerprinting. The attack can extract fine-grained information but is limited to computations on a CPU and cannot estimate inputs and parameters in a data-independent way. The attack on DNNs targets instructions and cannot estimate inputs and parameters independently. The attack was conducted on Ubuntu 16.04 with an i7-4600M processor, using TensorFlow v1.9.0-rc0 framework. Thirteen CNN architectures were considered in the experiment. The study conducted attacks on various CNN architectures including VGG19 and ResNet50, reporting errors in attribute extraction. The attacker's average errors were 2.6 in VGG19 and 3.1 in ResNet50 for short attacks. Long attacks showed similar error rates in both networks. DeepRecon achieves better accuracy by reconstructing the DNN architecture of the victim model without query access. CNN architectures consist of feature extractor and classifier layers, with standard blocks in VGGs and ResNets. Reconstruction process of ResNet50 is described in detail. The reconstruction process of ResNet50 involves identifying the number of blocks, counting convolutional layers in each block, and estimating the number of fully connected layers at the end. The attacker accurately captures computation sequences with few errors. The attacker successfully estimates the victim architecture as ResNet50 with high accuracy by analyzing the number of fully connected layers. Reconstruction errors do not show specific patterns, making it difficult for the attacker to filter them out. The computation sequences captured by the attacker are listed in a table, with errors marked in bold and red. The attacker identifies victim neural network architectures using statistical models trained on features and labels. Errors in computation sequences are attributed to background noise and common errors associated with the Flush+Reload attack. This capability allows the attacker to fingerprint pre-trained models used in transfer learning. The attacker can fingerprint the architecture of pre-trained models used in transfer learning by observing the training process and extracting network architecture and frozen layers of the victim model. This information allows the attacker to identify the victim network's teacher model and utilize pre-trained models for further attacks, such as increasing the success rate of black-box attacks. The attacker can craft adversarial samples using internal representations from teacher models, transfer across different models for the same task, and easily perform model extractions. By gaining partial knowledge of the victim's training data and frozen layers, the attacker can estimate the parameters of the entire network. This fingerprinting attack involves training decision tree classifiers on various networks. The fingerprinting attack involves training decision tree classifiers on 13 networks to identify network architectures using extracted attributes and labels. Classification accuracy is measured, and essential attributes are analyzed based on mutual information scores. The attacker can train models offline for use in attacks, unaffected by host machines or operating systems. Three types of classification tasks are conducted to identify networks and network families. The study involved identifying 13 networks and their architecture variants using decision trees, achieving 100% accuracy. Essential attributes like #relus, #merges, #convs, and #apools were identified for defensive strategies against side-channel attacks. Previous defenses require specific hardware or kernel-level features, which have not been widely deployed. The proposed framework-level defenses do not require specialized hardware or kernel-level updates, aiming to obfuscate essential architecture attributes to reduce the success of attacks like DeepRecon. By running a decoy process alongside the actual process, a simple but effective defensive strategy can be implemented against cache side-channel attacks on deep learning frameworks. The decoy process invokes target functions in the shared framework, utilizing TinyNets with few layers to minimize computational overhead. Three TinyNets are experimented with, causing significant errors in attribute extraction for attackers. The defense using TinyNets is highly effective at curbing reconstruction attacks by increasing errors in extracted attributes. By running TinyNets with fewer layers, such as only one convolutional layer, the number of convolutional layers can be significantly increased, allowing defenders to choose which attributes to obfuscate and dynamically change the noise added to attackers' observations. The defense against cache side-channel attacks involves adaptively changing the noise added to attackers' observations, increasing defense effectiveness. The defense incurs a minimal overhead of 5.91-8.38 seconds per inference. Another defense is to obfuscate computation order and number using oblivious model computations, such as adding extra layers to the victim's architecture without affecting performance. The defense against cache side-channel attacks involves adaptively changing the noise added to attackers' observations. To obfuscate the architecture, additional layers are added at random locations to make the network appear different to attackers. By splitting computational paths with skip-connections into multiple paths without skip-connections, the architecture becomes harder for attackers to decipher. This obfuscated architecture of ResNet50 is evaluated using an attack method to assess its effectiveness. The study evaluates the effectiveness of obfuscating the ResNet50 architecture to defend against DNN fingerprinting attacks. By obfuscating the first 3 blocks of ResNet50, the errors detected by DeepRecon increased significantly. Although less effective than previous defenses, this method still marginally obfuscates attacker observations. The computational time only slightly increased from 17.88 to 24.03 seconds. This research provides the first comprehensive analysis of DNN fingerprinting attacks exploiting cache side-channels. The DeepRecon attack reconstructs the architecture of a victim network using the Flush+Reload technique, allowing an attacker to fingerprint the architecture and family of a pre-trained model. The essential attributes for these attacks are identified through a meta-model, with details on the VGG16 reconstruction steps provided. The DeepRecon attack reconstructs the architecture of a victim network using the Flush+Reload technique. By identifying basic building blocks and counting convolutional layers, the attacker can determine the victim architecture, such as VGG16. The attacker can identify the victim architecture as VGG16 with ConvNet configuration 'C' or 'D'. An obfuscated ResNet50 architecture is constructed using the unraveled view of the first three blocks, making it difficult for the attacker to estimate the architecture attributes and computation sequences. Each network forms a distinct cluster in the attribute space. In FIG4, each network forms a distinct cluster in the attribute space, with networks of the same family clustering close to each other. Table 8 shows the influence scores of the principal axes, with #convs, #relus, and #merges being the most influential attributes. Table 9 displays the extracted architecture attributes of 11 networks, considering 8 attributes from short and long attacks."
}