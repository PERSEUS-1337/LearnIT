{
    "title": "HkgH0TEYwH",
    "content": "Deep SAD is a novel deep methodology for semi-supervised anomaly detection that utilizes labeled anomalies in addition to normal samples. It is based on an information-theoretic perspective and aims to minimize the entropy of the latent distribution for normal data. Anomaly detection methods aim to identify unusual samples in data by learning a compact description of the data in an unsupervised manner. Deep SAD is a novel methodology for semi-supervised anomaly detection that minimizes the entropy of the latent distribution for normal data, outperforming competitors in various experiments. Anomaly detection methods like One-Class SVM, Kernel Density Estimation, and Isolation Forest are limited in scalability and effectiveness on high-dimensional data, leading to interest in novel deep approaches for unsupervised anomaly detection. In real-world applications, semi-supervised anomaly detection involves having access to labeled normal or anomalous samples in addition to unlabeled data. Semi-supervised anomaly detection involves learning a model that characterizes the \"normal class\" using a mix of labeled normal and unlabeled samples. Existing methods mainly focus on using labeled normal samples without labeled anomalies, falling under Learning from Positive and Unlabeled Examples (LPUE). Some works have explored incorporating labeled anomalies in the learning process. Existing research on deep semi-supervised anomaly detection has primarily concentrated on classification tasks, assuming the cluster assumption that similar points belong to the same class. However, this assumption is not valid for the \"anomaly class\" as anomalies are not necessarily similar to each other. Semi-supervised AD approaches need to find a concise representation of the normal class while accurately detecting anomalies. Deep SAD is introduced as a deep method for semi-supervised anomaly detection, based on an information-theoretic framework and derived from the Deep SVDD method. Extensive experiments are conducted to establish scenarios for the general semi-supervised AD problem and introduce novel baselines. The study of theoretical foundations in deep learning is an active research effort. The study of deep learning is an active research effort, with a focus on information theory and the Information Bottleneck principle. It involves finding a minimal compression of input data while retaining informativeness for predicting labels. Supervised deep learning aims to minimize the mutual information between input X and latent representation Z while maximizing the mutual information between Z and label Y. Unsupervised deep learning, on the other hand, follows the Infomax principle to maximize the mutual information between data X and latent representation Z. The Infomax principle is applied to data X and its latent representation Z with a regularization constraint to achieve desired statistical properties for downstream tasks. It has been used in various tasks such as independent component analysis, clustering, generative modeling, and unsupervised representation learning. In the context of deep learning for anomaly detection, the Infomax principle has been applied in autoencoders, which are a common approach in deep anomaly detection. In deep anomaly detection, the Infomax principle is utilized in autoencoders to maximize mutual information I(X; Z) through regularization of the latent code Z. Various regularization methods include sparsity, KL divergence, adversarial loss, or bottleneck dimensionality. The goal is to ensure a compact latent representation of normal data, leading to a supervised classification approach that recognizes anomalies similar to those seen during training. Deep SAD is a deep method for general semi-supervised anomaly detection that incorporates label information through a novel representation learning regularization objective based on entropy. It builds upon the unsupervised Deep SVDD method and generalizes it to the semi-supervised anomaly detection setting. The objective is to train a neural network to minimize the volume of a data-enclosing hypersphere in the output space. The One-Class Deep SVDD method minimizes the volume of a hypersphere in output space Z around a predetermined point c. It penalizes the mean squared distance of mapped samples to the hypersphere center, forcing the network to extract stable factors of variation within the dataset. Normal data points are mapped near the center, while anomalies are mapped further away. Deep SVDD is optimized using SGD with backpropagation, initialized by pre-training an autoencoder and setting the hypersphere center as the mean of network outputs. The Deep SVDD method minimizes the volume of a hypersphere in output space around a predetermined point. It penalizes the mean squared distance of mapped samples to the hypersphere center, extracting stable factors of variation within the dataset. The anomaly score for a test point is determined by the distance to the center of the hypersphere. Deep SVDD can be interpreted geometrically as minimum volume estimation and probabilistically as entropy minimization over the latent distribution. Deep SAD introduces a new objective for anomaly detection in deep learning. It focuses on minimizing the entropy of the latent distribution of normal data while maximizing the entropy of anomalies. This is in contrast to Deep SVDD, which minimizes empirical variance and follows the Infomax principle. The Deep SAD model aims to capture anomalies by maximizing the entropy of the latent distribution of anomalies, in contrast to Deep SVDD which focuses on minimizing empirical variance. This approach does not impose any cluster assumption on the anomaly-generating distribution, emphasizing the importance of high entropy in anomaly detection. The Deep SAD model incorporates the assumption that most unlabeled data is normal and introduces a new loss term weighted by the hyperparameter \u03b7. This parameter controls the balance between labeled and unlabeled data, with \u03b7 > 1 emphasizing labeled data and \u03b7 < 1 emphasizing unlabeled data. Different loss terms are applied to normal and anomaly labeled samples to learn a latent distribution with low entropy for normal data and penalize anomalies by mapping them further away from the center. Anomalies are penalized by mapping them away from the center to a heavy-tailed distribution with high entropy. Autoencoder pretraining is used to maximize mutual information. Setting \u03b7 = 1 consistently improves performance. Experimentation with different loss functions showed that negative squared norm loss caused optimization issues. Negative robust losses introduce scale parameters that are challenging to optimize. The Deep SAD anomaly score is defined by the distance of the mapped point to the center and optimized using SGD with backpropagation. It outperformed other loss functions and was evaluated on various datasets, comparing to different competitors in unsupervised, semi-supervised, and supervised settings. Further details on the optimization procedure are provided in the appendix. The curr_chunk discusses various unsupervised deep anomaly detection methods, including OC-SVM, SVDD, Isolation Forest, KDE, autoencoders, and Deep SVDD. Some methods are labeled as \"semi-supervised\" if trained on only labeled normal samples. Additionally, a shallow SSAD method with a Gaussian kernel is considered for general semi-supervised AD approaches. The curr_chunk introduces a novel hybrid SSAD baseline that applies SSAD to the latent codes of autoencoder models, showing performance improvements on high-dimensional data. It also includes comparisons with a deep semi-supervised learning method (SS-DGM) and a fully supervised deep classifier. In experiments, hyperparameters were optimized for shallow and hybrid methods to maximize AUC on a subset of the test set. Deep methods used the same network architecture. Results for competitive methods are reported in the main text, while underperforming methods are deferred to an appendix. In experiments, hyperparameters were optimized for shallow and hybrid methods to maximize AUC on a subset of the test set. Deep methods used the same network architecture. Results for competitive methods are reported in the main text, while underperforming methods are deferred to an appendix. For the underperforming methods in Appendix F, semi-supervised anomaly detection setups were conducted on MNIST, Fashion-MNIST, and CIFAR-10 datasets. Ten classes were used to derive ten AD setups on each dataset, with one class set as normal and the remaining nine as anomalies. The AUC measure was computed on the original test sets for quantitative comparison. In experiments, hyperparameters were optimized for shallow and hybrid methods to maximize AUC on a subset of the test set. Deep methods used the same network architecture. The study examines three experimental scenarios varying the ratio of labeled training data, pollution in unlabeled training data, and the number of anomaly classes included. One scenario investigates the impact of adding labeled anomalies during training on detection performance to assess the benefit of a general semisupervised AD approach. The study explores different experimental scenarios involving varying ratios of labeled training data, pollution in unlabeled training data, and the number of anomaly classes included. Labeled anomalies are added during training to assess the benefit of a general semisupervised anomaly detection approach. The training set is polluted with anomalies to test the robustness of different methods. In the study, different experimental scenarios are explored involving ratios of labeled training data, pollution in unlabeled training data, and the number of anomaly classes included. Labeled anomalies are added during training to assess the benefit of a general semi-supervised anomaly detection approach. The training set is polluted with anomalies to test the robustness of different methods. The impact of learning from labeled anomalies in a semi-supervised approach on detection performance is hypothesized to alleviate the negative effects of pollution. In the study, different experimental scenarios are explored involving ratios of labeled training data, pollution in unlabeled training data, and the number of anomaly classes included. Labeled anomalies are added during training to assess the benefit of a general semi-supervised anomaly detection approach. The training set is polluted with anomalies to test the robustness of different methods. The impact of learning from labeled anomalies in a semi-supervised approach on detection performance is hypothesized to alleviate the negative effects of pollution. Only one out of the nine anomaly classes is considered, with a fixed ratio of labeled training examples and a pollution ratio for the unlabeled training data. Results are reported for different scenarios and statistical tests are conducted on the best performing methods. The study explores different experimental scenarios involving ratios of labeled training data, pollution in unlabeled training data, and the number of anomaly classes included. Results show the benefit of a semi-supervised approach to anomaly detection, with Deep SAD performing best on the CIFAR-10 dataset. The detection performance of all methods decreases with increasing data pollution, but Deep SAD proves to be the most robust. Additionally, the more diverse the labeled anomalies in the training set, the better the detection performance. Deep SAD is beneficial on complex data, showing sensitivity to anomaly classes. Experiments analyze its robustness to hyperparameter \u03b7 and dimension d variations, with results indicating its resilience. The experiments varied the output space dimension d to assess Deep SAD's sensitivity, showing improved detection performance with higher d values. Comparison with a hybrid SSAD baseline was conducted, revealing the importance of setting d sufficiently high for optimal performance. Additionally, detection performance on non-image datasets was evaluated, highlighting the effectiveness of Deep SAD compared to shallow approaches. Deep SAD method shows competitive performance on small, low-dimensional benchmarks compared to shallow kernel methods. Deep methods excel on complex data with hierarchical structure, while Deep SAD is versatile across different data types due to its performance with both deep and shallow networks. Deep SAD is a deep method for general semi-supervised anomaly detection based on an information-theoretic framework. It outperforms other methods on the CIFAR-10 dataset and is recommended when labeled information on normal samples or anomalies is available. In this experiment, the detection performance on AD benchmark datasets is evaluated using the SAD method. The evaluation includes deep and shallow approaches on non-image, tabular datasets with random train-to-test set splits. Standardized features are used with 1% of the training set labeled as anomalies. Shallow kernel methods perform slightly better on small, low-dimensional benchmarks, while Deep SAD remains competitive. Deep SAD remains competitive with shallow kernel methods on small, low-dimensional benchmarks. Using SGD allows Deep SAD to scale with large datasets, with linear computational complexity and low memory requirements. Fast predictions are enabled by a forward pass on the network. Initialization of the network weights W and the center c for Deep SAD involves autoencoder pre-training and fixing the hypersphere center as the mean of network representations, leading to smoother and faster SGD convergence. Initialization of the network weights W and the center c for Deep SAD involves autoencoder pre-training. Using labeled normal examples for mean initialization can minimize distortions from polluted unlabeled data. Preventing hypersphere collapse is crucial, achieved by ensuring no bias terms and unbounded activation functions in the network. If labeled anomalies are abundant, hypersphere collapse is not a concern for Deep SAD. We use LeNet-type CNNs on MNIST, Fashion-MNIST, and CIFAR-10 datasets with different configurations of convolutional modules and dense layers. On MNIST, a CNN with two modules and a final dense layer of 32 units is employed. Fashion-MNIST uses a CNN with two modules and two dense layers of 64 and 32 units. CIFAR-10 employs a CNN with three modules and a final dense layer of 128 units. Standard MLP feed-forward architectures are used on classic AD benchmark datasets like arrhythmia and cardio. For the convolutional autoencoders, the encoder networks follow a 3-layer MLP architecture with specific units, and the decoder networks are constructed symmetrically. The OC-SVM and SVDD algorithms are used with Gaussian/RBF kernels, with hyperparameters selected to maximize AUC on a subset of the test set. The RBF scale parameter and \u03bd-parameter are varied to find the best performing values, and the number of trees is set to 100 for the models. The text discusses the selection of hyperparameters for different algorithms such as Kernel Density Estimator (KDE), SSAD, and (Convolutional) Autoencoder ((C)AE) to optimize performance. Hyperparameters are chosen based on recommendations from previous works and through cross-validation to maximize AUC on a subset of the test set. Autoencoder ((C)AE) is constructed symmetrically with decoders based on architectures from Appenidx D, using upsampling and deconvolutions instead of max-pooling and convolutions. The autoencoders are trained on MSE reconstruction loss, serving as the anomaly score. Hybrid methods combine OC-SVM, IF, KDE, and SSAD with bottleneck representations from converged autoencoders. Unsupervised Deep SVDD includes Soft-Boundary and One-Class variants, optimizing radius R on mini-batches and experimenting with \u03bd values. Weight decay hyperparameter is set to \u03bb = 10 \u22126 for Deep SVDD. For Deep SVDD, weight decay hyperparameter is set to \u03bb = 10 \u22126 and bias terms are removed from the network. Deep SAD sets \u03bb = 10 and equally weights unlabeled and labeled examples. Latent class probability estimate is used as the anomaly score in semi-supervised DGM. The semi-supervised deep generative model suffers from overfitting to known anomalies during training, leading to poor anomaly detection performance. A supervised deep binary classifier is used to interpret anomaly detection as a binary classification problem, with most unlabeled data assumed to be normal. Despite having accurate label information, the supervised classifier fails to generalize to novel anomaly classes during testing. The study uses the Adam optimizer with Batch Normalization in SGD optimization. A two-phase learning rate schedule is employed, with a searching phase using \u03b5 = 10 \u22124 for 50 epochs and a fine-tuning phase with \u03b5 = 10 \u22125 for 100 epochs. Different initialization methods are used for various models, and unsupervised pre-training is done for Deep SVDD and Deep SAD. Experimental results are detailed in Tables 3-6. Table 6 presents the results on classic AD benchmark datasets with no pollution and a ratio of labeled anomalies in the training set. The average AUC with standard deviation is reported over 10 seeds."
}