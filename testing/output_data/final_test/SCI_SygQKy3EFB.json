{
    "title": "SygQKy3EFB",
    "content": "Stochastic gradient descent (SGD) is crucial in modern machine learning, with various gradient estimators available. Choosing the best estimator balancing cost and variance is essential. This paper analyzes SGD convergence rates based on time, not iterations, to determine the optimal estimator for optimization guarantee. A technique is proposed to automatically select the best estimator from a finite pool, extended to infinite pools indexed by control variate weights using a mixed-integer quadratic program. Empirical results show comparable performance to manually selecting the best estimator. In stochastic gradient variational inference (SGVI), multiple gradient estimators with varying costs and variances are used. Estimators can be obtained through different techniques such as the reparameterization trick or the score function method. Adding control variates to an estimator can help reduce variance, impacting optimization convergence speed. The choice of estimator significantly affects optimization performance, with the optimal cost-variance tradeoff being situation-dependent. This paper investigates how to automatically choose the best gradient estimator for stochastic optimization from a pool of estimators based on cost-variance tradeoffs. The \"G2T principle\" predicts the optimal estimator for convergence guarantees in terms of time. Two selection algorithms are proposed for finite and infinite pools of estimators. The paper discusses selecting the best gradient estimator for stochastic optimization from a pool based on cost-variance tradeoffs. The goal is to find the estimator with the best convergence guarantee for optimization algorithms. The G2T principle suggests choosing the estimator with the minimum product of expected squared norm and computational cost. The paper proposes using estimates for gradient estimators in stochastic optimization. It suggests forming estimates for each estimator through an initial profiling phase and updating them as optimization proceeds. The approach is justified under two assumptions and can use multiple control variates to reduce variance in the gradient estimator. The paper suggests using estimates for gradient estimators in stochastic optimization and utilizing multiple control variates to reduce variance. It discusses the selection of control variates based on their computational cost and variance reduction. The approach involves obtaining estimates for each estimator efficiently by indexing them with control variate weights. The paper proposes using gradient estimators and control variates to reduce variance in stochastic optimization. It introduces a method to efficiently obtain estimates for all estimators through shared statistics and presents an optimization problem that can be solved quickly. The experiments focus on inference problems using SGVI with three models: logistic regression, hierarchical regression, and Bayesian neural network. The paper introduces gradient estimators and control variates to reduce variance in stochastic optimization. It presents an empirical validation for two algorithms using different gradient estimators and updates the estimator used during training. The experiments focus on inference problems with three models: logistic regression, hierarchical regression, and Bayesian neural network. The paper presents an empirical validation for Algorithm 2 (control variate selection) using three models: logistic regression, hierarchical regression, and Bayesian neural network. The goal is to compare Alg. 2 against using fixed subsets of control variates with weights that minimize the estimator's variance. The paper validates Algorithm 2 for control variate selection using logistic regression, hierarchical regression, and Bayesian neural network models. Different models were considered, including a Bayesian neural network, a hierarchical Poisson model, and Bayesian logistic regression. The models focus on measuring stop-and-frisk events in different precincts in New York City for different ethnicities. The study uses a subset of the \"Red-wine\" dataset to implement a neural network with one hidden layer for regression analysis. Control variates are utilized for simulations, including differences in entropy and prior terms. Algorithmic details involve using M = 400 for estimation. Algorithmic details: For Alg. 2, M = 400 is used to estimate \u011c 2 (except for Logistic regression, where M = 200). The optimal estimator is re-selected three times during training. Optimization details include using SGD with momentum (\u03b2 = 0.9) and 5 samples z \u223c q w (z) for Monte Carlo gradient estimates. An initial set of parameters is found by optimizing with the base gradient for 300 steps and a fixed learning rate of 10 \u22125. Performance depends on the step-size, with Figs. 1 and 2 showing results with the best step-size for each estimator. The results show the best step-size for each estimator, with control variates expressed as an expression for T(ga) obtained by computing the base gradient and control variates with non-zero weights. Using Tw(\u03be) = \u00b5 + D 1/2 \u03be, where \u03be \u223c N(0, I), allows for computing T(ga) for all ga \u2208 G by profiling the base gradient and each control variate individually. Similarly, \u011c2(ga, w) is determined by the same set of evaluations regardless of the value of a, enabling computation using M evaluations of the base gradient and each control variate. Equations (3) and (4) characterize the process. The optimal control variate weights are determined by solving a minimization problem that can be reduced to a MIQCP, which can be efficiently solved using solvers like Gurobi. The problem involves finding the weights that result in the best cost-variance tradeoff for different gradient estimators, with a set of J control variate weights. This is achieved by solving a mixed integer quadratically constrained program with specific variables and constraints. The theorem proves that a mixed integer quadratic program involves quadratic and linear constraints, with some variables restricted to be integers. The final minimization problem resembles a general MIQCP, with additional constraints accepted by solvers like Gurobi."
}