{
    "title": "HkxzDiAcK7",
    "content": "This paper focuses on classifying noise type/position of impact noises in buildings, a common issue in apartment complexes. A floor impact noise dataset is recorded and classified using a convolutional neural network based classifier. The model is also tested on an environmental sound dataset to demonstrate its versatility. The conflict between residents due to incorrect noise source localization and the importance of noise type/position classification for noise reduction are highlighted. Impact noises like footsteps and hammer hitting in living spaces cause annoyance and pose a health threat to residents. With over 60% of residential buildings in Korea being apartment housings, conflicts arising from impact noise have become a serious social issue. The Korea government established the Floor Noise Management Center in 2012 to address impact noise identification and conflict mediation, handling over 119,500 civil complaints in 6 years. The Floor Noise Management Center in Korea has handled 119,500 civil complaints of impact noise over 6 years. Previous work focused on noise reduction, annoyance measurement, and noise classification, with a study on impact noise classification using a CNN-based model. To improve the previous work, this study gathered 1,000 impact noise data on 10 more positions in the building to validate the model's robustness. The study gathered new data to validate the model's robustness in classifying noise types and positions in a building. The model was also validated on a standard environmental sound dataset to show its extensibility to other problems. The impact noise dataset created in previous work was used for this study. In 2018, impact noise data was collected from 19 locations in a building using a smartphone microphone. A report by the Floor-Noise-Management-Center revealed that 79.4% of complaints were from upper floor residents, with footstep noise being the most common type at 71.0%. Unidentified sources accounted for 10.1% of complaints. This data was used to focus on the generation of impact noise. The report focused on impact noise generation on different floors of a building. The top four noise types occupying 81.5% of identified noise types were selected for analysis. Different tools were used to generate low frequency noise, with a medicine ball and a vacuum cleaner being used on the middle floor (2F) only. The study analyzed impact noise on different floors of a building, focusing on the top four noise types. A dataset with 2,950 floor impact noises classified into 59 categories was created. A noise type/position classifier using CNN was explained, with applications in audio areas and environmental sound classification. CNN is widely used in audio domain for tasks like environmental sound classification and music classification. Models typically use time-frequency patches or raw waveforms as input features. The design pattern of these models is similar to those used in visual recognition tasks, with convolutional layers, pooling layers, and fully connected layers. Some studies have shown that models designed for visual recognition tasks can also perform well in audio event classification. However, the performance of CNN models is limited by the size of the dataset, as they contain a large number of learnable parameters. Transfer learning can be used in situations where the dataset is small. Transfer learning is a technique used to improve model performance when dataset is small. Parameters are pre-trained in a source task and then transferred and fine-tuned in a target task. Studies have shown success in visual knowledge transfer to audio domain using pre-trained models like VGG16 from ImageNet dataset. The model performs well in the audio domain with a small performance difference compared to the state-of-the-art model. Pre-trained parameters are accessible on the VGG website and managed by the group. To overcome the limitation of a small dataset, pre-trained parameters from BID25 on ImageNet are transferred to VGG16 and fine-tuned for noise classification. The model VGG16-PRE is fine-tuned on noise types for impact noises. Impact noise signals are converted to log-scaled Mel-spectrograms using LibROSA BID14. The size of the spectrogram is fixed to 224 \u00d7 224. The Mel-spectrogram is converted to a logscaled version and supplied to all input channels of VGG16-PRE. Impact noises are labeled into 5 types and fine-tuned on a dataset named TV-set. L2-regularization is applied to the last layer with a penalty value of 0.01. The dataset TS-set is generated from positions used for finetuning for testing noise type classification. VGG16-PRE is evaluated using 5-fold cross validation with fine-tuning minimizing cross-entropy loss. Impact noises in TV-set are labeled into 9 positions for testing against TS-set. The noises in the TV-set are classified into 9 positions based on their impact positions, labeled as 1F00m, 1F06m, 1F12m, 2F00m, 2F06m, 2F12m, 3F00m, 3F06m, and 3F12m. The TS-set is composed of impact noises from these positions for fine-tuning. The model is fine-tuned with an adaptation layer dimension of 9 and pre-trained parameters transferred to VGG16-PRE. Performance testing for position classification on TS-set is suggested, with noise positions illustrated in FIG3 on 3F. In FIG3, noise positions on 3F are shown with virtual boundaries dividing them into groups. Impact noises on boundaries are excluded from performance measurement. True labels are assigned based on closest positions. VGG16-PRE is evaluated on ESC-50 dataset for environmental sound classification, verifying its robustness and extensibility. The study evaluates the robustness and extensibility of VGG16-PRE on ESC-50 dataset for environmental sound classification. The dataset consists of 50 categories with 40 environmental sounds each, pre-arranged into five folds for fair comparison. Audio clips are converted to log-scaled Mel-spectrograms with specific parameters. VGG16-PRE is fine-tuned on each fold for 10 epochs with defined batch size and learning rate. Validation accuracy is measured, and accuracies of noise type classifier on TV-set and TS-set are shown in TAB1. The study evaluates the robustness of VGG16-PRE on ESC-50 dataset for environmental sound classification. Validation accuracy on TV-set is 99.7%, while on TS-set it is 99.2%. VGG16-PRE shows robustness on position change for noise type classification. The accuracy difference between validation and test accuracy is 0.5%. Validation accuracy of the position classifier on TV-set is 94.1%, with lower accuracy on 1F compared to 3F. Test accuracy of the position classifier on TS-set is also measured. The test accuracy of the position classifier on TS-set is 69.6%, lower than the validation accuracy due to different noise positions. Changing to floor classification raises the test accuracy to 98.8%. Confusion matrices in FIG4 show misclassifications to neighboring positions, especially at X = 6m. The confusion matrix in TAB2 displays test results for position classification to noise types HH and MB, with test accuracies of 74.1% and 65.0% respectively. Our model outperforms the top-ranked model BID22 on ESC-50 repository by 12.3% in validation accuracy, supporting the effectiveness of visual knowledge transfer in environmental sound classification. In this study, a convolutional neural networks based model is proposed for noise type/position classification of impact noise. An impact noise dataset is built for evaluation of the model, divided into training/validation and test sets. The most confusing category is engine, and the most confusing major category is Exterior/urban noises with a validation accuracy of 97.6%. The categories of ESC-50 can be rearranged into 5 major categories. The dataset is split into a training/validation set and a test set. Models for noise type and position classifications are designed separately, but with similar architectures. VGG16 with an adaptation layer is used for the tasks instead of creating a new model. Parameters of VGG16 pre-trained on ImageNet are transferred due to the small impact noise dataset. The method shows potential for environmental sound and impact noise classification. Future work includes testing the model on other standard environmental sound datasets."
}