{
    "title": "BJx_JAVKDB",
    "content": "The representation learning community has not focused much on remote sensing, so to accelerate progress in this area, simplified access to 5 remote sensing datasets has been provided. The study explores characteristics that make a dataset suitable for remote sensing representation learning and achieves state-of-the-art performance on these datasets. Remote sensing through computer vision and transfer learning is crucial for addressing climate change, with applications in food security, water sustainability, disaster prevention, deforestation detection, urban planning, and monitoring air quality. Earth observing satellites, numbering over 700, generate terabytes of imagery data daily. Ground truth data acquisition is costly and labor-intensive. The remote sensing community is applying deep learning methods to remote sensing problems, but this domain has received little attention from the representation learning community. Challenges include diverse data sources, the need for domain knowledge, and the lack of standard benchmark datasets. Recently, new large-scale datasets have been generated, but a consistent evaluation framework is still missing. The curr_chunk discusses the importance of standardized remote sensing datasets for easy reuse and the development of general remote sensing representations. It aims to simplify research iteration and inspire representation learning experts to test their methods in this domain. The main contributions of this work include exploring in-domain representation learning for generic remote sensing, generating standardized datasets, establishing common evaluation protocols, and setting state-of-the-art baselines for various remote sensing datasets. The study also discusses the use of off-the-shelf feature extractor networks and fine-tuning approaches for better results in transfer learning applications. Deep learning approaches have been applied in the medical domain, prompting questions on their effectiveness. Training bigger models on larger datasets with weaker labels has shown improvements, as well as closer matching of domains. Sample-efficient methods using semi or self-supervision are promising. Common remote sensing problems include land-use classification, parameter estimation, target detection, and time-series analysis, which can be addressed with deep learning techniques like classification and object detection. Remote sensing data is acquired in different modes like optical, SAR, and lidar, providing unique information about the Earth's surface. The imagery ranges from high resolutions for urban monitoring to low resolutions for atmosphere and ocean monitoring. Deep learning approaches in remote sensing are currently based on various methods like classification and object detection. Deep learning in remote sensing primarily relies on optical imagery from satellites like Landsat and Sentinel-2, with increasing use of multi-spectral and radar imagery. Due to the high cost of labeling data, benchmark datasets like UC Merced with limited images have been a challenge for training state-of-the-art networks. Researchers have explored smaller network architectures and pre-training models on natural images to overcome this limitation. Researchers have explored using pre-trained models on natural images to fine-tune models for remote sensing tasks. Some examples include using CNN features from pre-trained models like Overfeat and GoogLeNet, as well as developing transfer learning pipelines. However, there is a lack of work on training representations specific to remote sensing tasks. Lin et al. (2017) and Xie et al. (2015) developed transfer learning pipelines for mapping poverty distribution using nighttime lights prediction. Conditional GANs were also used for cloud removal from RGB images by fusing different bands. Five diverse datasets were selected, including imagery from the ESA Sentinel-2 satellite constellation. The Sentinel-2 satellite constellation provides medium resolution imagery of the Earth's surface every three days, with additional channels at various frequencies. One dataset includes imagery from a dual-polarimetric synthetic aperture radar instrument of ESA's Sentinel-1. The datasets are diverse in terms of visual diversity, label imbalance, label domain, and label quality. BigEarthNet is a challenging multi-spectral dataset with 590,326 image patches from the Sentinel-2 satellite, providing 12 frequency channels and annotations for multiple land-cover classes. The label distribution is highly unbalanced, with a range from 217k images of \"mixed forest\" to only 328 images of \"burnt areas\". The dataset contains 328 images labeled as \"burnt areas\" with 12% of patches affected by snow or clouds. A shallow CNN achieved precision and recall values of 69.93% and 77.1% after removing affected samples. EuroSAT dataset includes 27,000 images from Sentinel-2 satellites with 10 LULC classes. NWPU RESISC-45 dataset consists of 31,500 RGB images divided into 45 scene classes. The So2Sat LCZ-42 dataset consists of co-registered SAR and multi-spectral image patches acquired by Sentinel-1 and Sentinel-2 satellites, with LCZ labels. It covers 42 cities across different continents and cultural regions, aimed at learning features to distinguish urban zones. The dataset poses a challenge due to its small image size (32x32) and high diversity within classes. The UC Merced Land-Use Dataset is a high-resolution dataset with 256x256 RGB images covering 21 land-use classes. It has been widely used for remote sensing scene classification tasks since 2010 and can achieve nearly perfect accuracy with modern convolutional neural networks. The dataset has standard train, validation, and test splits using the 60%, 20%, and 20% ratios, respectively. The remote sensing domain requires special attention during pre-processing and model construction. Characteristics include higher precision input data, variable number of channels depending on the satellite instrument, and diverse channel distributions determined by different technologies. The remote sensing domain requires special attention during pre-processing and model construction, with characteristics such as higher precision input data, variable number of channels, and diverse channel distributions. Values distribution can be highly skewed, and images acquired from space are usually rotation invariant. Source data can be delivered at different product levels, and lower resolution data aggregates a lot of information in a single pixel. Image axes might be non-standard, setting requirements on pre-processing and data augmentation for remote sensing data. Rescaling and clipping the range of values per channel is recommended for the discussed problems. In remote sensing, rescaling and clipping values per channel is recommended. Data augmentation affecting intensity should be avoided, while rotation invariance can be utilized to generate additional images. Multi-spectral data like Sentinel-2 can use different channel subsets. The goal is to create representations for various remote sensing applications. Training involves upstream training on proxy datasets and downstream evaluation on new tasks using trained features. The quality of trained representations is evaluated on reduced downstream training sizes to assess efficiency. Experiments use ResNet50 V2 architecture with sweeps over hyper-parameters and augmentations. Performance is reported using accuracy metrics for computer vision tasks. The quality of trained representations is evaluated on reduced downstream training sizes to assess efficiency using accuracy metrics for computer vision tasks. For multi-label problems, mean average precision (mAP) is used to measure relative performance improvement over datasets with different accuracy levels. In-domain representations are obtained by training models from scratch or fine-tuning ImageNet on each full dataset, which are then used to train models on other remote sensing tasks. The evaluation of in-domain representations for remote sensing tasks showed that fine-tuning the representations trained on RESISC-45 dataset yielded the best results with only 1000 training examples. These representations consistently outperformed ImageNet-based representations across various downstream tasks. The RESISC-45 dataset outperformed ImageNet-based representations for remote sensing tasks due to its various resolutions, high class diversity, and between-class similarity. This learning can be applied to adjust augmentation schemes by varying image scales and applying other transformations. The best representations for RESISC-45 come from the UC Merced dataset, which had a small training size but benefited from aggressive augmentation techniques. The training size was balanced with aggressive augmentation techniques. The largest datasets, BigEarthNet and So2Sat, did not yield the best representations possibly due to weak labeling and low training accuracy. Further exploration with self or semi-supervised learning approaches may enhance performance. Fine-tuning in-domain representations was evaluated against ImageNet and training from scratch at various data sizes, with results shown in Table 3. Fine-tuning from ImageNet outperforms training from scratch in most cases, with in-domain fine-tuning showing even better results. However, on the BigEarthNet dataset, the gap between in-domain and ImageNet pre-training is significant, which requires further investigation. These results establish new state-of-the-art baselines for the datasets, as shown in Table 4. Some results may not be directly comparable due to previous evaluations on limited data or lack of public benchmarking results. The study focused on the impact of in-domain knowledge on model accuracy in remote sensing applications. Results showed that smaller datasets benefited more from in-domain knowledge compared to larger datasets. In-domain representations led to higher accuracy gains with a small number of training examples, which is crucial for reducing ground truth data acquisition. Models were trained with training sizes ranging from 25 to 2500, using simplified hyper-parameters. The study focused on the impact of in-domain knowledge on model accuracy in remote sensing applications. Results showed that smaller datasets benefited more from in-domain knowledge compared to larger datasets. In-domain representations led to higher accuracy gains with a small number of training examples. The results demonstrate the enhanced performance of in-domain representations, especially for tasks with limited training samples, achieving state-of-the-art performance on five diverse datasets. The study explores dataset characteristics for remote sensing representation learning, finding that multi-resolution datasets lead to more generalizable representations. Factors like label quality, number of classes, visual similarity, and diversity within classes also play a role. Surprisingly, representations from smaller, diverse human-curated datasets outperformed those from large weakly-supervised datasets. Further investigation is needed to understand the main factors of a good remote sensing dataset for representation learning. The section provides information on the datasets used, including the SENTINEL-2 SATELLITE constellation characteristics and the ResNet50 v2 architecture used for training models with specific hyper-parameters. The training schedules for the models involve linear warm-up for learning rate and decreasing the rate by 10 per phase. Three schedules are used: short, medium, and long, with specific steps/epochs and hyperparameters settings. These settings are based on previous research with minor modifications. The models in Tables 2 and 3 were trained by sweeping over all hyperparameters. The best performing models from fine-tuning ImageNet were used for experiments in Table 2 and Table 3. Data pre-processing and augmentation were crucial for performance, with two settings used: resize to 224x224 and crop & rot with random rotations. During evaluation, resize to 256x256 and crop to 224x224. Table 6 compares different fine-tuning strategies from ImageNet."
}