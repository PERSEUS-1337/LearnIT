{
    "title": "SJPO7JMyG",
    "content": "The fabrication of semiconductors involves an etching process to remove selected areas from wafers. Manual measurement of etched structures in micro-graphs is time-consuming. A deep learning approach is used to detect masks of objects in the etched structure, followed by automatic measurement using image processing. Generative Adversarial Network (GAN) is used to generate more data due to limited dataset availability. Experiments conducted on 10 SEM images show a mean accuracy of over 96% for measurements, outperforming traditional image processing methods. Deep learning applied in semiconductor industry for automatic measurement during fabrication process, particularly in etching. As semiconductor devices become more densely packed, features and sizes of etched structures are shrinking, leading to higher aspect ratios. During semiconductor fabrication, precision in removal and patterning is crucial for product quality. Challenges include inaccurate measurements of critical dimensions and slight deformations causing defects in next-generation products. Advanced technologies like AFM and DIRE have improved measurements, but ensuring accuracy remains a challenge. Automated measurement and profile characterization of etched structures in semiconductor manufacturing is essential for achieving consistent and accurate evaluation of device quality. Traditional manual methods are time-consuming and subjective, making automation highly desirable. Machine learning techniques like random forest, SVM, and AdaBoost offer potential solutions for efficient and accurate evaluation in the semiconductor industry. This paper explores the segmentation of silicon SEM images using traditional machine learning methods, which have shown limited success in detecting boundaries due to unknown variations. The rise of deep learning approaches has sparked interest in automatic image segmentation and recognition across various fields. Deep learning has not been used in etched structure detection for semiconductor wafer images. Data augmentation is crucial for training models with limited datasets. Generative Adversarial Networks (GAN) can generate pseudo images to reduce the need for labeled data. The paper adopts the U-Net fully convolutional network for profile characterization of etched structures in semiconductor SEM images. The U-Net model is chosen for object boundary detection in semiconductor images due to similarities with neuronal structure segmentation datasets. Convolutional layers replace fully connected layers for seamless segmentation results. High-resolution output images aid in measuring critical dimensions of chips. Data augmentation includes using GAN for pseudo image generation and other techniques like cropping and flipping. Key point localization is used for critical dimension measurement. This paper contributes to object boundary detection in semiconductor images by using deep learning for segmentation, exploring data augmentations like flipping and rotation, implementing cross-validation methods to prevent data leakage, and utilizing GAN for data generation. Key point localization is used for measuring critical dimensions of etched structures in wafers. The paper discusses the use of GAN for data generation in semiconductor image analysis. It also categorizes scanning technologies into optical imaging, SEM, and Optical Microscopy. SEM is highlighted for its high resolution in observing geometric features in extreme environments. The research work on wafer inspection in the semiconductor industry focuses on automatic inspection to replace traditional manual inspection methods. Direct approaches use reference images without flaws to identify defects, such as golden templates and neighborhood templates. These methods are relatively fast compared to manual inspection by process engineers. Segmentation techniques for SEM images in the semiconductor industry are crucial for locating key points and measuring critical dimensions. While direct methods are fast, they can be challenging to adjust for potential offset values. Indirect approaches compare segmented images with masks to detect defects, with BID7 using a hybrid ridge detector for robustness but facing computational intensity issues. BID14 proposed a segmentation method for SEM images using global-local thresholding and watershed segmentation algorithms, achieving high accuracy. However, this method may not be suitable for measuring critical dimensions with jagged lines. Deep learning networks like BID13's training method show robust segmentation with limited data, while BID16's fully convolutional network trains end-to-end for state-of-the-art results. BID16 replaces max pooling with up-sampling convolutional operations for high-resolution information capture and feature localization. U-Net BID19 shows superior results with limited training samples and precise masks, utilizing massive feature channels in the up-sampling path. The network architecture consists of 23 convolutional layers and different operations. The U-Net BID19 model consists of 23 convolutional layers with various operations. It utilizes ReLU activation, max pooling, batch normalization, and up-sampling convolutional operations to capture high-resolution information and increase feature localization. The discriminating path leads to spatial contraction with increased abstraction information, while the localizing path includes up-sampling convolutional operations and shortcut connections. The U-Net BID19 model utilizes convolutional layers with ReLU activation, max pooling, batch normalization, and up-sampling operations. The localizing path includes shortcut connections and generates a high-resolution segmentation map with two channels. The semiconductor images used in the study are publicly available on the official website of Oxford Instruments. Limited training samples suggest the need for data augmentation. In experiments with SEM images of wafer etch structures, data augmentation is crucial due to limited training samples. The initialization approach from BID10 is used to calibrate the unit variance, determined to be 2/N with N as 576. Both generic image augmentation and Generative Adversarial Net (GAN) are applied to expand the training dataset, combating overfitting and maintaining robustness. In order to enlarge the training dataset for U-Net training, both GAN and traditional augmentation methods were used. GANs efficiently generate counterfeit images to increase the dataset size, with preliminary experimental results showing SEM wafer images generated by GAN. The use of GAN for generating images showed some similarities to the original ones, but issues like object boundary disconnection and noise in the background hindered the learning process of U-Net. The training dataset accuracy slightly decreased while the testing dataset improved by 0.5%. However, the improvement was not significant, and the manual labeling of newly generated images required considerable effort and expense. As a result, only generic augmentation methods were applied to extend the original dataset for further experiments on semiconductor wafers. The dataset was extended using generic augmentation methods like clipping and flipping. The distribution of 10 images included Type A (4 images), Type B (1 image), Type C (2 images), and Type D (3 images). Cross-validation techniques were used to prevent data leakage. The input image tiles for training were 400 \u00d7 400 pixels, and the output segmentation maps were the same size. The network was implemented using Keras, and the server had Dual 8-Core Intel Xeon Processors, 128 GB memory, 4 \u00d7 2TB SATA3 hard disk, and 4\u00d7 NvidiaTitan \u00d7 12GB GDDR5 GPU cards. The OS used was Ubuntu 14.04. The server used for training had 4 \u00d7 2TB SATA3 hard disk and 4\u00d7 NvidiaTitan \u00d7 12GB GDDR5 GPU cards. The OS was Ubuntu 14.04 with Keras 2.0.7 and Tensorflow 1.0.0. Transfer learning was applied to boost performance with limited data. Training speed was fast, with a single image taking less than 1 second. Results showed superiority over traditional machine learning approaches. Intersection over Union (IoU) and Dice metric (DM) are commonly used to evaluate image segmentation results. The performance of pre-trained models and models trained from scratch was compared on different types of silicon wafer images, with Type D SEM image achieving the highest accuracy of 99.57%. In our study, transfer learning's superiority is not evident due to diverse SEM image types. U-Net's performance on the whole dataset decreased to 94.23% as it struggles with multiple datasets. Despite this, U-Net is suitable for shape modeling on semiconductor wafer structures. Results show Type D performs best with 95.59% accuracy, while Type B performs the worst. This demonstrates U-Net's effectiveness in semiconductor image segmentation, paving the way for further analysis on silicon wafer dimensions and key points. The study focused on measuring critical dimensions and key points of silicon wafers, using different types (Type A, B, C, D) to identify specific parameters. Measurement parameters were quantified using average, max, min, and variance, with comparisons to ground truth showing high accuracy. The results demonstrate acceptable variability and potential for automatic measurement of etched structures to ensure quality and functionality. The paper demonstrates the application of deep learning methods like U-Net for etched structure segmentation in wafer products, showing superiority over traditional machine learning. Generic data augmentation methods are found to be more efficient than GAN for enlarging datasets without manual labeling. Transfer learning's effectiveness is limited due to diverse data types. Fast prediction with testing time of less than 1 second on a single image is achievable despite diverse data types."
}