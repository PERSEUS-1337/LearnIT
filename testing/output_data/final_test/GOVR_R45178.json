{
    "title": "R45178",
    "content": "Artificial intelligence (AI) is a rapidly growing field of technology that has captured the attention of commercial investors, defense intellectuals, policymakers, and international competitors. China, Russia, and the U.S. have all outlined strategies to lead in AI, recognizing its importance in future warfare. The U.S. military is already using AI systems in combat through Project Maven to identify insurgent targets in Iraq and Syria. The U.S. military is utilizing AI algorithms to identify insurgent targets in Iraq and Syria. Congress has raised questions about the limits and advantages of military AI applications, as well as how AI will impact warfare and the military balance with U.S. competitors. Congress has oversight, budgetary, and legislative tools to shape the future development of AI technology. There is no commonly accepted definition of AI, and the FY2019 NDAA directs the Secretary of Defense to produce a definition by August. The FY2019 NDAA directs the Secretary of Defense to produce a definition of artificial intelligence by August 13, 2019. The definition includes AI as any system that performs tasks without human oversight, learns from experience, and can solve tasks requiring human-like abilities. The field of AI research began in 1956, with a surge of interest around 2010 due to big data, machine learning advancements, and increased processing power. Narrow AI focuses on specific tasks like game playing and image recognition, with machine learning being the prevalent approach. Machine learning involves statistical algorithms replicating human cognitive tasks by deriving procedures from large data sets. General AI development is expected to take decades, but Narrow AI algorithms are gaining commercial interest. U.S. tech companies invested $20-$30 billion in 2016, with estimates of up to $126 billion by 2025. DOD's AI contract expenditures increased from $600 million in FY2016 to over $800 million in FY2017. AI has unique characteristics that are important for national security. It can be integrated across various applications, improving the \"Internet of Things.\" Many AI applications have dual-use capabilities, with both military and civil applications. AI is relatively transparent in its integration into products. AI procurement is transparent and may not result in countable objects. Algorithms are purchased separately and integrated into existing systems. Experts emphasize the use of AI to solve problems in various applications. Members of Congress have called for a national effort to maintain a technological edge in military AI. Former Deputy Secretary of Defense Robert Work highlights the need for addressing AI issues at the highest levels of government. The federal government needs to address AI issues at the highest levels, as the Pentagon cannot fix them alone. Analysts are calling for a national AI strategy to drive government initiatives. The Department of Defense has published a classified AI strategy and is establishing a Joint Artificial Intelligence Center to coordinate AI technology development. The initiatives include establishing a National Security Commission on Artificial Intelligence and assessing militarily relevant AI technologies for strengthening U.S. competitiveness. Congress may also review current DOD funding levels for AI, as funding has been identified as a barrier to future progress. Despite increased funding in 2018, some experts argue that additional DOD funding is needed for AI development. Some experts argue that additional DOD funding is necessary for AI development to keep pace with U.S. competitors and avoid an \"innovation deficit\" in military technology. Critics suggest leveraging R&D from the commercial sector, while the 2017 National Security Strategy emphasizes strategic partnerships with private sector R&D resources. The Office of Management and Budget directs DOD to rapidly field innovative technologies from the private sector for federal needs. Some experts argue for additional DOD funding for AI development to avoid an \"innovation deficit\" in military technology. Critics suggest leveraging commercial sector R&D, while the 2017 National Security Strategy emphasizes partnerships with private sector resources. The Office of Management and Budget directs DOD to field innovative technologies from the private sector for federal needs, rather than duplicating efforts. AI R&D appropriations in DOD lack a stand-alone program element, making it challenging to evaluate funding levels accurately. In the Defense Authorization Act, AI funding is distributed across various programs. A dedicated PE for AI may be challenging due to the lack of a government definition. Congress may need to consider specific policies for military AI applications, as technology development outpaces policy implementation. Former Chairman Thornberry highlights the need for better policies to govern technology use. Congress may need to assess the need for new policies to address AI developments and ensure bias-free applications. The absence of an independent entity to enforce AI safety standards is a concern, with suggestions for an \"AI czar\" to coordinate efforts. Policy debates on Lethal Autonomous Weapons Systems (LAWS) using AI are ongoing, with international discussions at the United Nations. Approximately 25 state parties have called for a treaty banning \"fully autonomous weapon systems\" for ethical reasons. Some analysts are concerned that efforts to ban or regulate LAWS could impose strict controls on AI applications that could be adapted for lethal use, stifling development of other useful military or commercial technology. One expert suggested that considering military AI applications should focus on the role of humans in wartime decision making. Congress may need to consider international competition in the AI market and the risk of foreign exploitation of U.S. AI. The Chinese government is aggressively pursuing AI investments in the United States, leading to concerns about foreign exploitation of U.S. AI technology for military purposes. President Trump blocked a Chinese firm from acquiring Lattice Semiconductor, a critical design element for AI technology, to protect strategically significant technologies like AI. The Foreign Investment Risk Review Modernization Act of 2018 expands CFIUS's ability to review foreign investments involving \"emerging and foundational technologies.\" The Foreign Investment Risk Review Modernization Act of 2018 expands CFIUS's ability to review foreign investments involving \"emerging and foundational technologies.\" Congress may monitor the implementation of FIRRMA and assess whether additional reforms might be necessary to maintain effective congressional oversight of sensitive transactions. Analysts believe that reforming federal data policies associated with AI may be necessary, as government data is crucial for developing military AI applications. However, much of this data is classified or access-controlled, posing challenges for AI development. Analysts suggest implementing a new data policy to balance data protection and AI development. AI algorithms are vulnerable to bias and manipulation without proper data curation. Deputy Defense Secretary advocates for higher cybersecurity standards in the commercial sector. Leading technology companies also call for increased scrutiny to prevent a \"commercial race to the bottom.\" The lack of regulation in AI development could lead to a \"commercial race to the bottom\" for tech companies. Section 813 of the FY2016 NDAA established a panel to address intellectual property rights concerns in partnering with DOD. Recommendations include increased training for acquisitions professionals and a pilot program for intellectual property valuation in procurement. DOD is exploring various applications for AI, with R&D currently managed by research organizations, DARPA, and the Intelligence Advanced Research. The JAIC oversees AI initiatives costing over $15 million annually for DOD components. It also manages National Mission Initiatives using AI to address operational challenges. The Algorithmic Warfare Cross-Functional Team, known as Project Maven, transitions to the JAIC as the first National Mission Initiative. Project Maven started in April 2017 to integrate AI into DOD operations. Project Maven, launched in April 2017, aims to incorporate AI into DOD systems to demonstrate its potential in various applications such as intelligence, surveillance, reconnaissance, logistics, cyberspace operations, and autonomous vehicles. The project's focus is on automating intelligence processing, utilizing computer vision and machine learning algorithms. The intelligence community is using AI to automate the analysis of footage from aerial vehicles to identify hostile activity. This technology aims to streamline the work of human analysts, allowing for more efficient decision-making. Additionally, there are numerous AI research projects underway, with the CIA alone working on 140 projects involving tasks like image recognition and predictive analytics. IARPA is also funding projects to develop analytic tools, including algorithms for multilingual speech recognition and translation in noisy environments. AI is being used in military logistics, such as predictive aircraft maintenance by the Air Force. This approach tailors maintenance schedules to individual aircraft needs using real-time sensor data and predictive algorithms. The Army is also utilizing AI in logistics. The Army's Logistics Support Activity (LOGSA) has contracted IBM's Watson to develop tailored maintenance schedules for the Stryker fleet based on sensor data. This AI technology aims to analyze shipping flows for repair parts distribution, potentially generating significant cost savings. AI is expected to play a crucial role in advancing military cyber operations. In 2016, Admiral Michael Rogers emphasized the importance of AI in military cyber operations, stating that relying solely on human intelligence is ineffective. AI-enabled tools can detect anomalies in network activity, providing a more dynamic defense against cyber attacks. DARPA's Cyber Grand Challenge showcased the potential power of AI in cybersecurity. The competition showcased AI algorithms that can rapidly detect and patch software vulnerabilities, demonstrating the potential of AI-enabled cyber tools in offense and defense. Deep fake technology poses a threat by creating realistic forgeries for information operations, potentially influencing public discourse and trust. The DARPA Media Forensics (MediFor) project aims to combat deep fake technologies by automatically detecting manipulations in visual media. Despite initial tools developed, the challenge lies in machine-learning systems outmaneuvering forensic tools. DARPA plans to host contests to ensure forensic tools keep pace with deep fake advancements. Artificial intelligence could also create full \"digital patterns-of-life\" by merging an individual's digital footprint with purchase data. The U.S. military is utilizing AI to create comprehensive behavioral profiles by merging digital footprints with various data sources. This information could be used for targeted influence operations or blackmail. The Air Force is developing a Multi-Domain Command and Control system to centralize planning and execution of operations across different domains. AI may be used to fuse data from sensors to provide decisionmakers with a common operating picture. The Air Force is working with Lockheed Martin, Harris, and AI start-ups to develop an AI-enabled common operating picture for comprehensive data fusion. DARPA's Mosaic Warfare program aims to use AI to coordinate autonomous forces and create multidomain command and control nodes. Future AI systems could identify and address communication disruptions caused by adversaries. AI algorithms in military systems are advancing to provide commanders with real-time analysis for faster decision-making. The U.S. military is integrating AI into various vehicles like fighter aircraft, drones, and ground vehicles, similar to commercial autonomous vehicles. The Air Force Research Lab's Loyal Wingman program tests pairing older fighter jets with AI technology. The Loyal Wingman program pairs an older F-16 with an inhabited F-35 or F-22, with the F-16 autonomously reacting to unforeseen events. AI may enable the \"loyal wingman\" to assist its flight lead by jamming electronic threats or carrying extra weapons. The Army and Marine Corps are testing similar vehicles that can follow soldiers or vehicles on the battlefield to perform independent tasks, such as the Marine Corps' MUTT, a remote-controlled ATV-sized vehicle capable of carrying extra equipment. The systems are not fully autonomous yet, but future versions aim for greater independence. The Army plans to deploy Robotic Combat Vehicles (RCVs) with autonomous functionality like navigation, surveillance, and IED removal to support the Next Generation Ground Vehicle. DARPA completed testing of the Sea Hunter prototype, which could provide the Navy with autonomous navigation and submarine-hunting capabilities at a lower cost. The Sea Hunter prototype, estimated to cost $20,000 a day to operate, offers autonomous navigation and submarine-hunting capabilities for the Navy at a lower cost. The Department of Defense is exploring AI-fueled capabilities for swarming, involving cooperative behavior among unmanned vehicles for various military tasks. The Navy is testing AI technology for defending harbors, hunting submarines, and scouting in front of larger ships. They are also exploring swarms of underwater drones and air-dropped micro-drones. Lethal Autonomous Weapon Systems (LAWS) can independently identify and engage targets without human interaction, using computer vision and advanced machine learning algorithms. The U.S. military does not currently have LAWS in its inventory, but there are no legal prohibitions on their development. The DOD Directive 3000.09 outlines policies for semiautonomous and autonomous weapon systems, requiring human judgment over the use of force and weapons review process. Approval is needed for autonomous and limited semiautonomous weapons before development and fielding by key defense officials. The DOD Directive 3000.09 requires human oversight for autonomous weapons, with exemptions for certain non-lethal uses. Despite concerns from military leaders, the development of LAWS is necessary to address potential threats from adversaries. Adversaries are pursuing LAWS, with commercial companies leading AI development for military applications. DARPA's Strategic Computing Initiative invested over $1 billion in artificial intelligence but was cancelled due to slow progress. Today, a small number of companies are developing strategically important technology commercially, with DOD adapting their tools for military use. The adoption of AI for military purposes faces challenges related to technology, process, personnel, and culture. Commercial AI technology varies in adaptability for military use, with some transitions being seamless while others require significant adjustments. For example, semiautonomous vehicles developed in data-rich environments may need modifications for complex combat settings. The integration of military AI faces challenges such as operating in locations with poor map data and GPS jamming, navigating off-road terrain, and aligning civilian and military standards of safety and performance. Standing DOD processes also present obstacles to integrating military AI. The integration of military AI faces challenges in combat environments due to unpredictable failure modes and the need for adjustments in DOD's acquisitions process to accommodate rapidly evolving technologies like AI. Commercial companies typically deliver AI products in six to nine months, while DOD takes an average of 91 months from initial analysis to operational capability. The Defense Department faces challenges in integrating military AI due to the lengthy acquisitions process, with commercial companies delivering AI products much faster. A GAO study found that companies avoid working with DOD due to the complexity of the acquisition process. To address this, DOD has established rapid acquisition avenues like the Strategic Capabilities Office and Project Maven to streamline processes and accelerate timelines. Critics emphasize the need for comprehensive acquisitions reform to replicate Project Maven's success at scale and address concerns about intellectual property. Companies are hesitant to partner with the DOD due to concerns about intellectual property and data rights. The DOD faces challenges in recruiting AI expertise due to lower research funding and salaries compared to commercial companies. Technology workers believe they can make a bigger impact outside the government. The Obama Administration launched the Defense Digital Service in 2015 to recruit private sector technology workers for short assignments in the DOD. Former Deputy Secretary of Defense Bob Work proposed an \"AI Training Corps\" for advanced technical education in exchange for training with government systems. Other analysts suggest new military training programs to address challenges in recruiting AI expertise. The establishment of new military training and occupational specialties is recommended to cultivate AI talent in response to a national emergency. However, a cultural divide between DOD and commercial technology companies may hinder AI adoption, with challenges including process issues, mutual distrust, and differing incentive structures. Some companies are hesitant to collaborate with DOD due to ethical concerns about AI use in surveillance or weapon systems. Google canceled government contracts for robotics companies Boston Dynamics and Schaft, and prohibited future work for AI startup DeepMind. Employees successfully lobbied to withdraw from Project Maven. Some companies continue to support DOD contracts, with Amazon CEO emphasizing the importance of tech companies working with the Department of Defense. Resistance to AI integration within the defense establishment is reported due to disruptions and unclear benefits. Resistance to AI integration within the defense establishment is reported due to disruptions and unclear benefits. Deputy Director for CIA technology development Dawn Meyerriecks has expressed concern about senior leaders' willingness to accept AI-generated analysis, citing the defense establishment's risk-averse culture as a potential obstacle to future competitiveness. Analysts fear that DOD may not fully leverage AI's potential for game-changing warfighting benefits, instead opting for incremental improvements or reinforcing current operational concepts. Congressional members may examine these challenges as DOD progresses in AI adoption for military applications. Senator Ted Cruz expressed concerns about ceding leadership in AI development to foreign governments, highlighting potential national security implications. AI has been recognized as an emerging technology with profound implications for adversaries' capabilities, as stated by Director of National Intelligence Daniel Coates. The potential implications of adversaries' AI capabilities are significant, including increased vulnerability to cyberattacks, attribution challenges, advancements in foreign weapon systems, accident risks, liability issues, and unemployment concerns. China is a major competitor in AI development, with ambitious plans to dominate the industry by 2020. This raises national security concerns, as foreign governments may have fewer ethical qualms about using AI for military purposes. China aims to lead in AI investment by 2030, with recent achievements showcasing its potential. Chinese companies have surpassed US competitors in AI development, with applications in surveillance and social credit systems. Research is ongoing in autonomous vehicles, including air, land, sea, and undersea. In 2017, a Chinese university with military ties showcased an AI-enabled swarm of 1,000 drones at an airshow. Chinese development of military AI is influenced by U.S. defense innovation plans, aiming to exploit intelligence and accelerate battlefield decision-making. Concerns exist about maintaining U.S. military superiority in light of Chinese advancements. China's military AI adoption may face challenges due to centralized command authority and mistrust of subordinates. Unlike the U.S., China has not been in active combat for decades, which some argue could lead to more innovative concepts of operation. China's AI ecosystem lacks boundaries between commercial companies, research labs, the military, and the government, contrasting with the U.S. The Chinese government's centralized control over AI development involves university research labs, the military, and the central government. They have established the Military-Civil Fusion Development Commission to facilitate the transfer of AI technology to the military. China is also leveraging data collection and labeling to build large databases for AI training, aiming to possess a significant share of global data by 2030. This effort is fueling speculation in the U.S. AI market, with China investing in companies developing militarily relevant AI applications. China is investing in U.S. AI companies, totaling $1.3 billion between 2010 and 2017. CFIUS reforms aim to oversee these investments to prevent national security threats. Despite reforms, China's history of industrial espionage may still grant access to U.S. AI developments. China's government and the United States have agreed not to support cyber theft of intellectual property. Analysts believe China's AI development has advantages but also note inefficiencies in funding management and challenges in recruiting AI engineers. China has a potential to overinvest in projects and struggles to retain experienced data scientists compared to the United States. China has less than 5 years of experience. Less than 30 Chinese universities produce AI-focused experts and research products. China surpassed the United States in research paper quantity from 2011 to 2015 but ranked 34th globally in paper quality. Efforts are being made to address these deficiencies, with a focus on military AI applications. The Beijing Institute of Technology established the first educational program in military AI. Experts warn that China's focus on being the first in military AI may lead to less safe applications. Russia is actively pursuing military AI applications, with plans to robotize 30% of its military equipment by 2025. The country's AI development lags behind the United States and China, but efforts are being made to close the gap through the establishment of organizations dedicated to military AI development. In 2018, the Russian government released a 10-point AI agenda, including the establishment of various AI initiatives and a defense research organization focused on autonomy and robotics. However, some analysts are concerned that the proliferation of research institutions may lead to bureaucratic inertia. The Russian military is researching AI applications, particularly semiautonomous and autonomous vehicles. In November 2017, Viktor Bondarev, chairman of the Federation Council's Defense and Security Committee, stated that artificial intelligence could replace soldiers and pilots, with a focus on autonomous vehicles. Russia successfully tested the Nerehta ground vehicle, which outperformed manned combat vehicles. The country plans to use Nerehta for AI research and development, potentially deploying it in combat, intelligence, or logistics roles. Russia is also developing AI-enabled autonomous systems for military use. Russia is planning to incorporate AI into various military vehicles and develop swarming capabilities. They are also exploring AI for electronic warfare and have used AI for propaganda and surveillance. Despite aspirations, analysts doubt significant progress due to budget cuts and limited research papers on AI by Russian academics. Many analysts note that Russian academics have produced few research papers on AI and the technology industry in Russia lags behind the United States and China in AI applications. However, some argue that Russia has been a disruptive force in cyberspace despite not being a leader in internet technology. International institutions like the G7, OECD, and APEC have examined AI issues, with the U.N. CCW focusing on military applications, particularly LAWS. The CCW aims to ban or restrict weapons causing unnecessary suffering to combatants. The CCW has been discussing LAWS since 2014, focusing on banning or restricting weapons causing unnecessary suffering. A Group of Governmental Experts was established in 2016 to assess emerging technologies in this area, but has not yet defined LAWS or provided guidance. This lack of progress has raised concerns about the pace of diplomacy in addressing these issues. The international community is warned about the lag in diplomacy compared to technological advancements. AI in national security presents opportunities and challenges. The Obama Administration's strategy focuses on autonomous systems to maintain military superiority. Experts believe autonomous systems can enhance or replace human tasks, benefiting the military. Autonomous systems offer significant benefits in military tasks, reducing risk to warfighters and cutting costs. Analysts argue for the development of autonomous systems as a tactical and strategic necessity. AI enables systems to operate at gigahertz speed, potentially accelerating combat pace. Some analysts believe that increasing combat pace through AI could be destabilizing if it surpasses human control, but it could also provide a warfighting advantage and enhance intelligence gathering capabilities. AI has the potential to enhance human capabilities and make military systems more capable and cost-effective. AI systems have the potential to enhance military capabilities, increase productivity, and potentially render some current platforms obsolete. They could also enable smaller countries and nonstate actors to have a significant impact on the battlefield. Additionally, AI may help cope with the exponential increase in data available for analysis. The military operates over 11,000 drones, generating vast amounts of high-definition footage daily. However, there is a lack of resources to analyze this data effectively. By 2020, the global data pool is expected to grow significantly, creating a need for AI-powered systems to process and extract actionable intelligence from large data sets. AI algorithms can identify patterns and generate additional data for analysis, improving intelligence capabilities. AI tools can convert unstructured data into reports, potentially providing a warfighting advantage by improving decision-making. In a military context, AI algorithms can produce unpredictable and unconventional results, offering a combat advantage if they surprise adversaries. However, AI systems can also fail unexpectedly. AI systems can surprise adversaries with their results, but they can also fail unexpectedly. Despite surpassing human performance in image recognition, AI technology is still limited and can make errors in ways that humans wouldn't. An example of this is when an AI system incorrectly labeled a distorted image of a panda as a \"nematode,\" highlighting its capacity for failure. AI systems may exhibit surprising results but can also fail unexpectedly. For instance, an AI system mislabeled a distorted image as a gibbon with high confidence, showcasing its limitations in understanding context. Additionally, AI systems can be prone to algorithmic bias due to training data, leading to implications for military applications. AI systems may exhibit surprising results and fail unexpectedly, with potential implications for military applications. Gender bias and domain adaptability challenges could lead to significant risks if AI systems are deployed at scale in a combat environment. AI systems have the potential to fail simultaneously and produce large-scale effects when interacting with adversary systems. Rushing to field AI technology without understanding potential hazards may lead to \"technical debt\" and compounding risks. The highest performing AI algorithms are unable to explain their processes, posing challenges for predictability. Google created a cat-identification system that achieved impressive results on YouTube, but developers couldn't explain how it worked. DARPA and other research organizations are working on creating explainable AI tools to address this issue. Researchers found that an AI algorithm designed to identify curtains first looked for a bed instead of a window because most images in the training data set featuring curtains were bedrooms. The training data set showed that most images featuring curtains were in bedrooms, leading to potential errors in AI systems. Lack of explainability in AI reasoning can affect confidence in military contexts, with concerns that humans may be hesitant to rely solely on AI analysis. Increasing explainability is crucial for building trust in AI systems. Dawn Meyerriecks from the CIA emphasized the need for AI to show its reasoning to be considered a decision quality product. In military contexts, explainability in AI systems is crucial for building trust. Issues such as goal alignment, task alignment, and human-machine interface must be addressed to ensure effective human-machine interaction. Timely decisions in military AI applications require efficient interfaces to prevent performance slowdowns. In military AI applications, traditional machine interfaces may slow down performance, but real-time coordination between humans and machines is essential to build trust. Explainability challenges the military's ability to verify AI system performance before deployment. The lack of explainable output hinders certification of meeting performance standards. The DOD is developing a framework to test AI system lifecycles and methods for testing in diverse environments with complex human-machine interactions. AI systems create pathways for adversary exploitation, increasing the number of hackable systems, potentially leading to lethal effects. AI systems are vulnerable to theft due to being software-based, making it easy to reproduce stolen code. The dual-use nature of the technology and open collaboration in the AI research community have led to the sharing of tools that could be adapted for military use, posing a risk for major military powers and nonstate actors. Adversaries can manipulate image classifiers by introducing errors, highlighting the need for robust data security in military AI applications. Experts predict AI's potential in the combat arena. AI's potential impact on future warfare is being predicted by experts, considering factors like commercial investment, competition with international rivals, AI capability advancements, military attitudes, and warfighting concepts. Despite the sense of inevitability surrounding AI, General Paul Selva of the Joint Chiefs of Staff suggested in January 2016 that it may be too early to determine its full potential. The evaluation is ongoing to determine if commercial technologies can provide significant force multipliers. Experts are predicting AI's impact on future warfare, considering factors like commercial investment, competition with international rivals, AI capability advancements, military attitudes, and warfighting concepts. General Paul Selva of the Joint Chiefs of Staff suggested it may be too early to determine AI's full potential. The military will seek to improve its capabilities slightly if commercial technologies cannot provide significant force multipliers. Congress may consider these future scenarios for military AI applications. Critics point to potential safety problems and trends that may minimize AI's impact in the long run. Some experts believe AI development may plateau in the next 10 years due to limitations in current algorithms and the need for advancements in enabling technologies like quantum computing. Military's reluctance to fully embrace AI technology could also hinder progress, as historical \"AI Winters\" have shown. The Defense Innovation Board highlighted the Department of Defense's struggle with innovation adoption, preferring small changes over real transformation. Poor expectation management could impede AI adoption, leading to decreased trust and usage. Analysts predict AI will significantly impact warfare, potentially causing disruptive changes. Analysts predict that AI technology may bring dramatic improvements in military effectiveness and combat potential, with the ability to make existing weapon systems faster and more efficient. However, they caution that AI is unlikely to advance beyond narrow, task-specific applications in the near future. Proponents believe AI will make combat more controllable by reducing uncertainty, while critics emphasize the enduring necessity for human presence on the battlefield. The presence of humans on the battlefield is seen as a key factor in preventing technology from completely changing warfare. Analysts highlight the complexity of social systems and the psychological impact of autonomous systems on adversaries. The balance of international AI development will also play a role in shaping the future of warfare. Experts emphasize the importance of the balance of international AI development in shaping the magnitude of AI's influence on warfare. The U.S. military aims to maintain an enduring competitive edge through technological advancements, fearing falling behind countries like China and Russia. The democratization of AI technology further complicates military strategies. The democratization of AI technology poses challenges for the U.S. military's pursuit of an AI advantage, as state competitors and nonstate actors will also have access to advanced technologies. AI's impact on warfare may be limited if adversaries possess similar capabilities, although some experts believe it will revolutionize warfighting methods. The 2018 National Defense Strategy recognizes AI as a technology that will change the character of war. AI's transformative potential is seen as challenging long-standing warfighting principles, with proponents arguing that it will lead to a profound military revolution by facilitating information superiority and enabling faster decision-making in combat operations. AI and autonomous systems are predicted to distance humans from direct combat roles, with AI exclusively handling tactical decisions. This shift may challenge traditional military preferences for quality over quantity, favoring large numbers of less expensive systems. Potential consequences include near-instantaneous responses to enemy operations. AI systems have the potential to provide positive results such as near-instantaneous responses to adversary operations and domination at a time and place of our choosing. However, there are concerns that AI could lead to a loss of human control in warfare and induce strategic instability by accelerating the pace of combat beyond human decision-making capabilities. This could create an incentive for preemptive strikes and unpredictable actions in close proximity to adversaries. Analysts caution that accurately predicting the future impacts of AI in warfare is challenging. Historians note that the true utility of AI may only become clear in combat. Military leaders and Congress may need to evaluate the implications of AI developments and oversee emerging trends to shape its trajectory. Congressional actions on AI funding, acquisitions, norms, and international competition could significantly influence AI development. The trajectory of AI development is crucial for U.S. national security and military effectiveness."
}