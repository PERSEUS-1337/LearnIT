{
    "title": "HklCmaVtPS",
    "content": "The UW-Net is a new CNN-based network for underwater image classification, achieving 99.3% accuracy. It utilizes an inception-attention module to improve performance in special environments like fog and underwater. The IA module can also enhance existing object recognition networks, as shown by a 10.7% error rate reduction in Inception-ResnetV2. The Inception-ResnetV2 network achieves a 10.7% top1 error rate and 0% top5 error rate on ILSVRC-2012 subset, showcasing the importance of background attention in image classifications. Underwater images pose challenges due to distortions like low contrast, blurring, and noise, requiring specialized classification algorithms. The classification of underwater images faces challenges due to various backgrounds, the presence of salient objects in both underwater and air environments, and the need for a simple network structure to avoid over-fitting. Increasing the depth and width of a CNN can improve performance but may lead to over-fitting with limited training data. The inception module proposed by Szegedy et al. in 2015 addresses this issue by performing multi-scale convolution and pooling in a CNN. The UW-Net is a proposed underwater image classification network that incorporates multi-scale features and an attention mechanism. Unlike traditional models, UW-Net focuses more on large-scale features like the background in understanding underwater images. The UW-Net is a CNN-based model for underwater image classification that utilizes inception-attention modules to focus on background features, achieving better performance. It is the first model of its kind and simulates visual correlation between images and background areas. The paper introduces the UW-Net, a CNN-based model for underwater image classification using inception-attention modules to focus on background features. It discusses the lack of focus on underwater image classification and the incorporation of recent attention mechanisms in the network. The popularity of CNNs in image recognition tasks is also highlighted, with a focus on increasing depth and parameters for better performance. The inception architecture, including 1x1 convolution for dimension reduction, has been proposed to improve image representation in deep networks. Inception V3, V4, and Resnet are further advancements in network structures to address gradient disappearance in deep convolution networks. The attention mechanism has been proven effective in deep learning models, with examples like SeNet and RAN achieving high accuracy rates. However, existing studies on attention mechanisms do not focus on background features. Despite surpassing human performance in some tasks, current image classification models still have room for improvement. When light passes through water, absorption and scattering determined by internal optical properties affect underwater imaging. Factors like dissolved organic matter and sea snow impact image quality. Depth in water causes light color disappearance. Artificial lighting leads to uneven lighting and worsens scattering. These challenges complicate designing effective underwater image classification algorithms. Designing effective underwater image classification algorithms is challenging due to factors like absorption, scattering, and artificial lighting. The UW-Net utilizes an inception module with multiple receptive fields and an attention mechanism to emphasize background features in underwater images. The network structure includes I-A modules and a convolutional layer with 7x7 kernels. An auxiliary classification branch is added for optimization, making the network suitable for complex visual classification tasks. The UW-Net introduces key components like the I-A module with inception and attention modules, and a classification branch. Inception models use multiple convolutional kernels of different sizes, but not all features are relevant for image classification tasks. Large convolution kernels extract global information that may not be useful for fine-grained classification, leading to computational resource waste in underwater image analysis. The UW-Net utilizes convolution kernels with larger sizes and average pooling to address the challenges posed by underwater images, such as poor quality and varying background proportions. Experimentation shows that using convolution kernel sizes of 1 \u00d7 1, 5 \u00d7 5, and 7 \u00d7 7 in the inception module yields the best classification results. The UW-Net structure includes two I-A modules, with one branch for auxiliary classification and another as the network backbone, resulting in a model with two outputs. The UW-Net model has two outputs, with an attention module based on soft attention. The trunk branch transmits basic image features to deep layers, while the mask branch performs down-sampling and up-sampling operations to maintain feature map size. The activation function for the convolutional layers is Relu. The UW-Net model includes an attention module with soft attention. The activation functions for the convolutional layers are Relu and Sigmoid. The adaptive weight N(x) can be learned after the mask branch, affecting the output of the attention module. An auxiliary classification branch is added to reduce over-fitting, shown to accelerate convergence in the UW-Net model. The UW-Net model incorporates an auxiliary classifier to speed up convergence and enhance test set accuracy. The loss function J includes cross entropy terms, weight attenuation coefficient \u03b1, and L2 regularization. The model consists of two I-A modules, with specific parameter settings detailed in Table 1. Image size is adjusted before the first I-A module, and feature map size and channel are modified after. The final prediction is made after average pooling. The UW-Net model includes an auxiliary classifier for faster convergence and improved accuracy. Experiments demonstrate its performance in underwater image classification and the effectiveness of the I-A module in enhancing existing networks. Various image classification models are compared using re-trained datasets with over 4,000 underwater images collected from different sources. The UW-Net model is trained on a dataset of underwater and non-underwater images, with data augmentation to prevent over-fitting. The model is initialized using He et al.'s method and trained with SGD. The training process includes weight decay, momentum, and learning rate adjustments, with the training ending at 3k iterations. Visualized examples of regional contributions to classification are shown. The UW-Net model achieves high accuracy on training and testing datasets, outperforming other models like AlexNet, VGG16, InceptionV3, Resnet-50, and SE-Resnet-50. Class activation maps show that UW-Net focuses more on background areas for underwater image classification. The UW-Net model outperforms competing models in underwater image classification with fewer computation units and parameters, higher accuracy, and a smaller network depth. The I-A module in UW-Net enhances performance and can be applied to other image classification networks. The module is tested in models like GoogleNet, InceptionV3, InceptionV4, and Inception-ResnetV2, showing improved performance across different image categories. The experimental results show that replacing the inception module with the I-A module in various networks like GoogleNet, InceptionV3, InceptionV4, and Inception-ResnetV2 significantly reduces error rates in image classification. The proposed I-A module demonstrates better generalization and effectiveness in simulating visual understanding mechanisms. Additionally, a new underwater image classification network UW-Net with the inception-attention module is introduced, showcasing improved performance. UW-Net with an inception-attention module achieves 100% accuracy on the training set and 99.3% accuracy on the testing set by refining multiscale features. Future work aims to enhance other underwater image analysis models with the I-A module."
}