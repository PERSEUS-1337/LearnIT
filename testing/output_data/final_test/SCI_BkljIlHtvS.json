{
    "title": "BkljIlHtvS",
    "content": "Meta-learning methods like Model-Agnostic Meta-Learning (MAML) have been successful in quickly adapting to new tasks after training on similar tasks. The success of MAML is attributed to deep models, with early layers learning task-invariant features and later layers used for adaptation. This suggests that these models require greater capacity than necessary for individual tasks. Our method proposes separating the adaptation aspect of meta-learning into parameters used only for adaptation, not part of the forward model. This approach enables more effective meta-learning in smaller models suited for individual tasks. Meta-learning, specifically Model-Agnostic Meta-Learning (MAML) and its variants, has shown promise in improving learning efficiency and model robustness by quickly adapting to new tasks. However, there is a lack of understanding of how MAML works in theory or practice. Parameters of a meta-learning model need to encode both common knowledge from prior tasks and the ability to adapt to new tasks, raising questions about how these two sets are balanced. In deep learning models, knowledge is distributed in parameters, with lower layers encoding task-general bias and higher layers encoding task-specific bias. The question arises whether a deep learning model needs more depth than necessary for target tasks to meta-learn effectively. Is there a way to have a smaller, yet adaptable, meta-learnable model? In this work, the study investigates the necessity of depth in meta-learning models, focusing on MAML. The findings suggest that depth is crucial for successful meta-learning, with higher layers adapting to new tasks and lower layers learning task-general features. The research prompts the proposal of a new method for meta-learning. The study explores the importance of depth in meta-learning models, highlighting the role of higher layers in adapting to new tasks and lower layers in learning task-general features. A new method for meta-learning is proposed, introducing a meta-optimizer to guide the optimization process of a small model. Empirical results show that the algorithm with small models achieves similar performance to larger models using MAML. This work complements a recent study by Raghu et al. on improving MAML. The text discusses the significance of optimization-based meta-learning (OBML) algorithms, particularly focusing on MAML. MAML has been widely used in various domains such as computer vision, natural language processing, and robotics. It serves as the basis for extensions in continual learning, reinforcement learning, transfer learning, and domain adaptation. The adaptation procedure MAML, now known as Generalized Inner Loop MetaLearning, has gained popularity in practical applications. Recent studies have provided convergence guarantees for MAML in approximating first-order stationary points for non-convex loss surfaces. Other analyses have explored the generalization ability of OBML, the bias induced by restricting adaptation steps, and the impact of higher-order terms in meta-gradient estimation. In related works, various methods aim to enhance adaptation mechanisms in OBML. Meta-SGD learns per-parameter learning rates, Alpha MAML adjusts learning rates via gradient-descent, and MetaCurvature proposes a Kronecker-factored pre-conditioning matrix for fast-adaptation updates. T-Nets decompose weight matrices into two components, updating them differently during evaluation loss and fast-adaptation. Our work differentiates from previous methods by addressing the entanglement between modelling and adaptation in meta-learning. We identify a failure mode of MAML with linear components and propose solutions. In the meta-learning regime, MAML aims to optimize model parameters for fast adaptation to new tasks. It minimizes expected task loss through gradient descent, using a learning rate \u03b1 for adaptation. Our work addresses entanglement between modeling and adaptation, proposing solutions for MAML's failure mode with linear components. The learning rate \u03b1 for the adaptation phase in MAML aims to adapt quickly with one-step gradient descent. Shallow models can be challenging to meta-learn due to the entanglement between modeling and adaptation. The minimizer of the meta-learning loss is crucial for providing a good initialization point for adaptation, especially when tasks have different global minimizers. The ideal initialization point for MAML should be the \"mean\" of the minimizers of training tasks. A study on a synthetic dataset and the Omniglot task showed that MAML can adapt quickly to different tasks using logistic regression models. The logistic regression model fails to adapt quickly to test tasks, even when initialized at the origin. Despite the simplicity of the tasks, both shallow and deep models struggle to perform better than chance. The logistic regression model, when overparameterized and combined with linear networks, achieves significantly better results after adaptation with MAML. The adapted model reaches 92% accuracy on average in 1-step adaptation. Similarly, on the Omniglot dataset, a shallow logistic regression model achieves 45% accuracy on average, but with a linear network, the accuracy increases to 70% on average. Experiments show that deep models with higher accuracy (70% on average) require enough depth to be meta-learnable and adaptable. Depth enables task-general feature learning and fast adaptation, with lower layers learning task-invariant features and higher layers facilitating quick adaptation. After meta-training a model with four convolutional layers and a fully-connected layer on Omniglot and CIFAR-FS, layer-wise ablation experiments were conducted to study the effect of each layer on adaptation. Freezing lower layers (C1-C3) did not significantly impact post-adaptation accuracy, indicating their task-invariant feature learning capability. The study found that freezing lower convolutional layers (C1-C3) did not affect post-adaptation accuracy, showing their task-invariant nature. However, the last convolutional layer (C4) and the fully-connected layer (FC) were crucial for adaptation, with perturbations in FC leading to significant performance degradation. This highlights the importance of both C4 and FC in the mechanism for fast adaptation. The study showed that freezing lower convolutional layers did not impact post-adaptation accuracy, emphasizing the importance of the last convolutional layer and fully-connected layer for adaptation. MAML requires models with the capacity to encode both task-general features and adaptation information, as seen in linear and nonlinear models. Reducing the number of layers in MAML-trained models leads to a loss in performance. Meta-learning in deep learning models involves learning both task-general features and task-specific adaptation parameters simultaneously. The model needs to be large enough to handle strong dependencies between layers, but in some cases, the model's capacity may exceed what is needed for test tasks. It is challenging to collapse layers in nonlinear deep models for inference on test tasks. The question arises if there is an alternative adaptation mechanism to enable smaller models to adapt effectively for test tasks. The new approach of learning meta-optimizers for meta-learning aims to separate modeling from adaptation. The meta-optimizer transforms the parameter update process for the model to converge quickly to its minimizer, learned from meta-training tasks. This allows the model for the task to not need to know how to adapt, only requiring enough capacity to represent the target task. Traditional tools for compressing models are ineffective in meta-learning scenarios, as they often require a lot of labeled data or degrade performance. A meta-optimizer, or learnable optimizer, is a parameterized function. A meta-optimizer, also known as a learnable optimizer, is a parameterized function that defines the model's parameter updates to accelerate the minimization of the loss function. However, storing the optimizer's parameters becomes infeasible for modern machine learning models with millions of parameters, leading to computational challenges. To address the issue of parameter dimensionality in meta-optimizers, factorizations of the optimizer's parameters are proposed. This approach allows for efficient computation of updates while reducing memory requirements compared to non-factored cases. The Kronecker-factorization of weight matrices in meta-optimizers allows for efficient computation of updates with reduced memory requirements. This linear transformation can be used as a building block for implementing more expressive and non-linear meta-optimizers, such as fully-connected networks with interleaved activation functions. The choice of Kronecker factorization is arbitrary and can be used to implement various meta-optimizers involving a composition of linear maps. Refer to Appendix A.3 for pseudo-code and schematics of the model-optimizer loop. The choice of Kronecker factorization in meta-optimizers allows for efficient computation with reduced memory requirements. This decomposition offers computational and memory benefits, ensuring full-rankness and symmetry in the matrix, which is useful for approximating the Hessian or its inverse. In experiments, meta-optimizers can recover gradient descent update by using identity matrices. The approach is applied to synthetic and benchmark datasets like Omniglot, mini-ImageNet, and CIFAR-FS. All models are trained using MAML, with learnable deep optimizers for model and optimizer parameters. In experiments, models with learnable deep optimizers meta-learn both model and optimizer parameters. The optimizer's name is added to the model for differentiation. Testing accuracies on Omniglot dataset are reported for different model setups. Logistic regression models do not meta-learn, while overparameterized logistic regression models do. Our approaches, including LR W/ KLIN and LR W/ KFC, can meta-learn successfully with smaller deep nonlinear models to match bigger deep models on the Omniglot and CIFAR-FS datasets. The performance improvement is attributed to better adaptation rather than better modeling. The model used for 10-way classification with 3-shots and 2 adaptation steps is a CNN with 32 hidden units. Results are detailed in Table A2 and Figure 3. Comparisons with other approaches like Meta-SGD and Meta-Curvature show that our approach has a slower degradation rate and can adapt smaller models effectively. Our approach outperforms other methods in learning optimizers, approaching the upper bound of performance. We analyze success and failure modes of optimization-based metalearning methods, finding that successful methods tend to adapt better than SCNN with MAML. Our method for decomposing modeling from adaptation using factored meta-optimizers enables successful meta-learning in models that do not work with traditional optimization-based methods. This approach allows the forward model to focus on learning task-specific features and adapt quickly to different tasks. The data-generation process, model architectures, and learning hyper-parameters for experiments in Section 5 involve initializing meta-optimizers' parameter matrices to the identity. Task decision boundaries and data points are sampled from standard Gaussian distributions. Models are trained for 30,000 iterations using stochastic gradient descent to minimize the 1-step MAML loss. Logistic regression results include meta and adaptation learning rates, while the linear network consists of 3 hidden layers of 64 units. The network (LR+LinNet) has 3 hidden layers of 64 units and is trained with meta-and fast-adaptation learning rates set to 1.9. The Kronecker-factored linear meta-optimizer also uses the same learning rates set to 3.33. The meta-optimizer has 10,001 parameters, while the Kronecker-factored fully connected meta-optimizer has 20,002 parameters. Omniglot experiments replicate Finn et al. (2017) setup with 1,200 classes for meta-training, 100 for validation, and 423 for testing. Training tasks consist of five classes with rotated character images. The logistic regression model uses a meta-learning rate of 0.0005 and an adaptation learning rate of 1.0. The linear network has 4 hidden layers and flattens character images into a 784-dimensional vector. The KLin experiment uses a meta-learning rate of 0.003 and an adaptation learning rate of 0.9. The KFC meta-optimizer consists of 4 hidden layers with ReLU activations and learning rates set to 0.001 and 0.01. For non-linear model experiments, one KFC optimizer is learned per layer with separate processing of gradient magnitude and direction. The gradient is scaled to unit norm before being fed to the KFC network and then rescaled by a learnable factor. Convolutional models flatten weight dimensions to share optimizers across filters of the same layer. The convolutional layer has shape NxCxHxW, with meta-optimizers not using a bias term. Omniglot dataset replicates linear model experiments with 10 ways and 5 shots. The 4-layer CNN network uses meta-learning rate of 0.003 and adaptation learning rate of 0.5, while the 2-layer CNN has lower parameters. Meta-SGD, Meta-Curvature, and KFC optimizers have the same learning rates. The KFC architecture has 4 layers with a total of 134,171 parameters for the 2-layer CNN model and 267,451 parameters for the 4-layer CNN. Experiments on CIFAR-FS were conducted with 100 classes split into 64 training, 16 validation, and 20 testing classes. A total of 20,000 training tasks and 600 validation and testing tasks were generated. The model used in the experiments closely resembles the one used in Omniglot experiments, with the main difference being the absence of max-pooling layers and averaging of the last two convolutional feature dimensions before the fully-connected layer. The 4-and 2-layer CNNs have different numbers of parameters and use varying meta-and fast-adaptation learning rates. The KFC optimizer has 4 layers with ReLU activations and different parameter counts for the 4-layer and 2-layer CNN models. In the Omniglot experiment, the 4-layer and 2-layer CNNs use the same meta-learning rate and fast-adaptation settings. The 4-layer CNN and 2-layer CNN models have different parameter counts and use varying meta-learning and fast-adaptation rates. The KFC optimizer has 4 layers with different parameter counts for each model. In the Omniglot experiment, both CNN models use the same meta-learning rate and fast-adaptation settings. Additional experimental evidence supports the claims made in the main text regarding adaptability. The model's adaptability is crucial for gradient-based meta-learning, with depth being a key factor. Even simple tasks show that width plays a less important role in adaptability. Models with one or more hidden layers can eventually solve the meta-learning problem regardless of width. The modelling layers (C1-C3) are insensitive to parameter scaling, pre-or post-adaptation. Parameter scaling has different effects on modelling layers (C1-C3) compared to adaptation layers (C4 & FC) in deep meta-trained models. Modelling layers are insensitive to parameter scaling, while adaptation layers are crucial for fast-adaptation. The last FC layer is particularly important for post-adaptation accuracy. In deep meta-trained models, parameter scaling affects modelling layers (C1-C3) differently from adaptation layers (C4 & FC). Modelling layers are not impacted by scaling, while adaptation layers play a crucial role in fast-adaptation. The last FC layer is especially important for post-adaptation accuracy. In deep meta-trained models, parameter scaling affects modelling layers differently from adaptation layers. Post-adaptation accuracy is not impacted by scaling weights of C4-FC. However, pre-adaptation rescalings can be disastrous, leading to significant drops in accuracy. Additional methods are detailed, including Cholesky-factored Meta-Optimizers based on low-rank Cholesky decomposition. The linear transformation in Section 4 involves a bias term and weight gradient vectorization. Chaining linear transformations with activation functions creates more adaptable meta-optimizers. Cholesky decomposition offers flexibility in memory usage, with the choice of r impacting the meta-optimizer's expressivity. Initialization scheme for the Kronecker product can be a challenge. The initialization scheme for meta-optimizers is crucial, with the choice of Kronecker product leading to hypergradient descent. Experimentation shows that Glorot initialization for the Cholesky factor works well. Comparing low-rank Cholesky-factored meta-optimizers to Kronecker ones, CFC models offer a competitive alternative, although they do not outperform KFC counterparts. Post-adaptation pruning effects are also studied. Post-adaptation pruning of a meta-trained model offers a competitive alternative to explicitly separating adaptation from modeling. However, pruning 4-layer CNN models to match the parameters of a 2-layer SCNN can lead to significant accuracy drops. Results show that on Omniglot, the pruned model reaches 70.06% post-adaptation accuracy, while on CIFAR-FS and mini-ImageNet, pruning struggles to outperform chance prediction, achieving around 10.00% and 12.20% accuracy respectively. The text discusses post-adaptation pruning of a meta-trained model, showing that pruning can lead to accuracy drops when reducing a 4-layer CNN model to match a 2-layer SCNN. The process involves computing loss, gradients, updating parameters, and measuring metrics using a NVIDIA Titan XP."
}