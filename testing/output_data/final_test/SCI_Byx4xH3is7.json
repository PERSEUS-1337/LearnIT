{
    "title": "Byx4xH3is7",
    "content": "Verifying a person's identity based on their voice is a challenging problem in biometric security. A framework using Generative Adversarial Networks for learning domain invariant speaker embeddings has shown improved performance over baseline systems. The model combines adversarial training with an angular margin loss function to optimize for cosine similarity between classes. Results indicate that models with adversarial adaptation outperform unadapted models, demonstrating the effectiveness of this approach. Our proposed adversarial speaker embedding models reduce the distance between source and target data distributions, performing better on the latter. Inspired by successful GAN-based unsupervised domain adaptation methods in computer vision, we adapt these ideas for feature learning in a verification setting. Domain adaptation GANs operate in lower-dimensional spaces to generate features that are indistinguishable between the source and target domains. In this study, the authors propose a novel objective for updating the generator network in domain adaptation GANs operating in low-dimensional embedding space. They found that optimizing GAN models with this objective was unstable, but stabilizing it with an auxiliary loss function improved training. The analysis of transformed data distributions using Maximum Mean Discrepancy and Fr\u00e9chet distances showed that good distributional distance corresponded to good verification performance in speaker verification experiments. The proposed adversarial speaker embedding framework delivers robust performance, outperforming a strong i-vector baseline in speaker verification experiments. State-of-the-art results are achieved by averaging scores from different GAN models. Learning discriminative speaker embeddings involves mapping speech frames to a feature vector using neural networks, with a focus on 1-dimensional convolutional filters for speech modeling. The proposed feature extractor uses self-attention models to focus on speaker-discriminative speech fragments. Attention layers compute scalar weights for each time-step, which are then normalized. Self-attention is applied to convolutional feature maps, with the last residual block outputting a tensor of size nB x nF x T. The feature extractor utilizes self-attention models to focus on speaker-discriminative speech fragments. It equips the network with a robust framework for computing similarity between classes using cosine. The discriminator is trained using Binary Cross-Entropy loss, with source and target data represented as Xs and Xt. The adversarial game between the discriminator and feature extractor is defined by Equation FORMULA6, allowing for different adversarial frameworks. Gradient reversal is employed to optimize the true minmax objective. The model trained with gradient reversal is referred to as Domain Adversarial Neural Speaker Embeddings (DANSE). Instead of using the minimax loss in GAN, the generator is trained using inverted label loss. This approach splits the optimization into two independent objectives for the generator and discriminator. In this work, updating the generator with both source and target data is considered beneficial. In this work, a novel framework for learning domain-invariant speaker embeddings is presented. The generator loss inverts the discriminator loss, and the Fr\u00e9chet Distance is used to measure domain adaptation. The model shows the best performance on source domain speaker verification experiments."
}