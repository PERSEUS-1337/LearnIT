{
    "title": "Skz3Q2CcFX",
    "content": "In this work, the authors propose a methodology to analyze and visualize embeddings by using explicit axes defined as algebraic formulae. This approach allows for a semantically meaningful projection of embeddings into a lower dimensional subspace, enabling comparisons and detailed analyses among different sets of embeddings. The proposed methodology analyzes and visualizes embeddings using explicit axes, allowing for a meaningful projection into a lower dimensional subspace. This approach provides profound insights compared to classical methods and is widely applicable. Learning representations, such as real-valued vectors or embeddings, is crucial in modern machine learning and natural language processing research. Understanding the embedded space can lead to a better understanding of the data and the problem at hand. The proposed methodology analyzes and visualizes embeddings using explicit axes for a meaningful projection into a lower dimensional subspace, providing profound insights compared to classical methods. Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) are commonly used techniques for visualizing embeddings in two dimensions. PCA projects embeddings onto a lower dimensional space based on the highest variance directions, making interpretation difficult. Visualizing the first two dimensions of a PCA projection reveals semantic relatedness between points, but embeddings that are close in the projected space may not be close in the original space. Additionally, PCA projections are not comparable among different embedding spaces. The t-SNE method optimizes embeddings to preserve distances in the original space, improving cluster visualization compared to PCA. However, t-SNE is sensitive to hyperparameters and lacks interpretability of axes. A new method is proposed to inspect and debug embedding spaces at a fine-grained level. A new method is proposed to inspect and debug embedding spaces at a fine-grained level by defining axes explicitly through vector algebra over the embeddings themselves. This approach provides interpretable semantics to the axes of projection, allowing for detailed analysis of how embeddings relate to each other in terms of interpretable dimensions of variability. It also enables comparison of embeddings from different datasets with common labels. Visualizations and case studies demonstrate the methodology's utility for tasks such as bias detection, polysemy analysis, and fine-grained embedding analysis. The proposed methodology introduces a new approach to inspect and debug embedding spaces by defining axes through vector algebra. This allows for detailed analysis and comparison of embeddings, aiding in tasks such as bias detection and polysemy analysis. An open-source interactive tool is released to enable researchers in various fields to better understand the semantics of their embeddings. The main contribution lies in using user-defined algebraic formulae to project embedding spaces into interpretable subspaces for visualization. The methodology introduces a new approach to inspect and debug embedding spaces by defining interpretable axes through vector algebra. This methodology can be widely used through case studies on various models and data, validated through a user study. Several methods for learning embeddings from symbolic data have been proposed recently, with positive results in learning embeddings for words sparking renewed interest in these methods. In a recent paper, BID12 identified tasks using embeddings in visual analytics for NLP, such as comparing concepts and predicting contexts. iVisClustering BID18 visualizes topic clusters with keywords in a 2D scatter plot. ConceptVector BID26 encodes relevance scores with keyword sets. BID21 displays analogous word pairs on a 2D plane. Our work offers more control over conceptual axes and filtering logic compared to existing literature, allowing users to define concepts using algebraic formulae, metadata filtering, and multidimensional comparisons. The main idea is that inspecting embedding spaces can be goal-oriented, focusing on items and dimensions of variability, such as analyzing gender bias by examining how professions are distributed among the concepts of \"male\" and \"female\". In this section, we analyze the distribution of concepts among \"male\" and \"female\" dimensions of variability using algebraic formulae. These formulae define axes in the embedding space, representing concepts like male = man and female = woman. More complex formulae can also be used, such as male = man + him and female = woman + her. Defining axes explicitly as algebraic formulae gives interpretable semantics to the dimensions of variability in the visualization. Different distance and similarity measures can be used to project on the axes, with cosine similarity being used in this paper. The items of the goal are defined by extension or intention, with rules using items' embeddings or metadata. Intentions identify a semantically coherent region of the embedding space through logical formulae. Rules using item's embeddings are defined as distance or similarity functions with algebraic formulas. Rules using item's metadata involve categorical, set, and numerical fields associated with each item. These rules are defined as inclusion in a set based on categories, sets, or ranges. For example, professions can be selected based on specific criteria such as stop-words, parts of speech, or unigram frequencies in a corpus. In defining rules for item selection, professions like \"doctor\", \"nurse\", \"teacher\", and \"astronaut\" can be chosen based on specific criteria such as frequency range, cosine similarity, and exclusion of stop-words. Visualizing the selected items in a subspace of the embedding space can be done using a Cartesian view for few dimensions of variability and many items, displaying similarities or distances of the items on each axis. The Cartesian view displays similarities or distances of items on each axis. A polar view is preferred for many dimensions of variability, allowing visualization of more axes but limited in the number of items displayed. Explicit axes enable comparison of different embedding spaces, like embeddings trained on different corpora or models. The only requirement for embedding spaces to be comparable is that they contain embeddings for all labels present in the formulae defining the axes. Items will now have two sets of coordinates, one for each embedding space, displayed as lines. Short lines indicate similar embeddings in both spaces, while long lines show different locations. The two embedding spaces could be trained on different corpora, such as Wikipedia and Twitter, or different time slices of the same corpus to compare how words changed over time. The methodology and visualizations can be used in linguistics, digital humanities, social studies, computational linguistics, and machine learning. The task involves comparing two datasets using Cartesian comparison view. GloVe BID28 embeddings were used from Wikipedia and Twitter datasets for bias detection. The task of bias detection involves identifying and correcting bias in data reflected in embeddings trained on Twitter data. Studies have shown how embeddings incorporate gender and ethnic biases, with some focusing on de-biasing techniques. A methodology is proposed to visualize biases, specifically gender bias in professions using cosine similarity for projection. Visualizations show professions like nurse and dancer closer to the \"female\" axis, while boss and captain are closer to the \"male\" axis. The visualization of gender bias in professions using cosine similarity shows words like chef and doctor closer to the \"male\" axis in Twitter compared to Wikipedia, while dancer and secretary are closer to the bisector in Twitter. Further analysis is needed to draw definitive conclusions about the significance of these shifts. The authors demonstrate how a binary orthonormalization operator can help distinguish different meanings of polysemous words in embeddings. They use the operator nqnot(a, b) = a \u2212 a\u00b7b |b| 2 b to orthonormalize the word \"suit\" with respect to \"lawsuit\" and \"dress\". The study focuses on the 20000 most frequent words in the Wikipedia embedding space, removing stop-words, and provides a comparison plot to illustrate the concept. The authors demonstrate how a binary orthonormalization operator can help distinguish different meanings of polysemous words in embeddings. They use the operator nqnot(a, b) = a \u2212 a\u00b7b |b| 2 b to orthonormalize the word \"suit\" with respect to \"lawsuit\" and \"dress\". The study focuses on the 20000 most frequent words in the Wikipedia embedding space, removing stop-words, and provides a comparison plot to illustrate the concept. The overall plot zooms in on items closer to each axis, showing words related to dresses and wearing on one axis and words related to law on the other. Another polysemous word, \"apple\", is also analyzed in relation to \"fruit\" and \"computer\". The visualizations demonstrate the ability of the nqnot operator to disentangle multiple meanings from polysemous embeddings. When visualizing embeddings in two dimensions, nuances among similar words can be lost. A Cartesian view allows for a more detailed visualization, highlighting subtle differences. By selecting google and microsoft as dimensions of variability, the authors demonstrate how close words in the embedding space can have distinct meanings. The focus is on the 30000 most frequent words, excluding stop-words, and the 500 most generic words. This approach emphasizes the importance of considering cosine similarity in analyzing word embeddings. The text discusses the importance of considering cosine similarity when analyzing word embeddings. It highlights how words with similar embeddings can have distinct meanings when visualized in two dimensions using google and microsoft as dimensions. The focus is on identifying polarized words by selecting those with cosine similarity above 0.4 with both google and microsoft, but below 0.75 with respect to the formula google + microsoft. The visualization shows how certain words are closer to either the google or microsoft axis, revealing nuances in word meanings. The text discusses the importance of cosine similarity in analyzing word embeddings, highlighting how words can have different meanings when visualized in two dimensions using google and microsoft as dimensions. The focus is on identifying polarized words with specific cosine similarity thresholds. The methodology enables a detailed inspection of the embedded space, visualizing multi-dimensional similarity nuances using the polar view. The text discusses using cosine similarity to analyze word embeddings, focusing on identifying polarized words with specific thresholds. It also explores visualizing multi-dimensional similarity nuances using the polar view. Additionally, it mentions a study on comparing food items across different countries to demonstrate the effectiveness of user-defined algebraic formulae in visualizations. The study compared Explicit Formulae to t-SNE in goal-oriented tasks with data scientists and machine learning researchers. Tasks included identifying common or polarized words using visualizations with specific word pairs. The study compared Explicit Formulae to t-SNE in goal-oriented tasks with data scientists and machine learning researchers. Tasks included identifying common or polarized words using visualizations with specific word pairs. Test subjects were given pairs of words like banana & strawberry, google & microsoft, nerd & geek, book & magazine. They were asked to provide lists of five words for each pair, which were compared to a gold standard set by computational linguistics experts. Measures included accuracy, speed, and overall preference for visualizations. The study compared Explicit Formulae and t-SNE in goal-oriented tasks with data scientists and machine learning researchers. Significant differences in accuracy were found for Projection, Task, and Obfuscation factors. Explicit Formulae outperformed t-SNE in accuracy for Commonality and Polarization tasks. Non-obfuscated words resulted in better accuracy but slower speed. Post-hoc tests confirmed the superiority of Explicit Formulae over t-SNE. The study compared Explicit Formulae and t-SNE in goal-oriented tasks with data scientists and machine learning researchers. Explicit Formulae outperformed t-SNE in accuracy for Commonality and Polarization tasks. Nine out of twelve subjects preferred Explicit Formulae over t-SNE. Speed did not show significant differences between the two methods. The study compared Explicit Formulae and t-SNE in goal-oriented tasks, showing better accuracy with Explicit Formulae. Users preferred Explicit Formulae over t-SNE. The methodology allows for fine-grained comparison and cross-dataset analysis. The proposed methodology assigns explicit semantics to measures of variability for interpretable results in computational linguistics. The methodology assigns explicit semantics to measures of variability for interpretable results in computational linguistics, natural language processing, machine learning, social sciences, and digital humanities."
}