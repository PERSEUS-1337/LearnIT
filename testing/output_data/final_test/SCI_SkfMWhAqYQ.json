{
    "title": "SkfMWhAqYQ",
    "content": "Deep Neural Networks (DNNs) are effective in complex perceptual tasks, but understanding their decision-making process is challenging. A new DNN architecture called BagNet simplifies decision explanations by focusing on local image features rather than spatial ordering. This approach, similar to bag-of-feature models, achieves high accuracy on ImageNet and allows for easy analysis of image influences on classification. BagNets perform comparably to other deep neural networks like VGG-16, ResNet-152, and DenseNet-169. The improvements of DNNs over previous classifiers are mostly achieved through better fine-tuning rather than different decision strategies. Understanding DNN decision-making is hindered by complex dependencies between input and hidden activations. To address this, a new DNN architecture inspired by bag-of-feature models is formulated for easier interpretation. The architecture in the current chunk is inspired by bag-of-feature models, known for their success in large-scale object recognition before deep learning. It combines the interpretability of BoF models with the performance and flexibility of DNNs, allowing for easier explanation of image-level decisions. The BagNets model combines the interpretability of BoF models with the performance of DNNs, achieving high accuracy on ImageNet with small image patches. It can be useful for diagnosing failure cases, benchmarking diagnostic tools, or serving as interpretable parts of a computer vision pipeline. Similarities in decision-making behavior with popular DNNs suggest reliance on local statistical information. BagNets model combines interpretability of BoF models with DNN performance, achieving high accuracy on ImageNet with small image patches. BoF representations are akin to bag-of-words, counting occurrences of important words in a document. The bag-of-words document representation and bag-of-feature representations are used in image classification models. The term vector for an image is the number of occurrences of visual words in the vocabulary, which is then input to a classifier like SVM or MLP. Linear BoF models are easy to interpret, as the influence of a part of the input on the classifier is independent of the rest. A linear DNN-based BoF model is constructed by inferring a 2048 dimensional feature representation from each image patch using stacked ResNet. The BagNet-q architecture utilizes multiple stacked ResNet blocks to extract feature representations from image patches of size q \u00d7 q pixels. A linear classifier is then applied to infer class evidence for each patch, with the class evidence averaged across all patches to determine image-level class evidence. The architecture differs from other ResNets by using 1 \u00d7 1 convolutions to limit the receptive field size of the topmost convolutional layer. The model includes a linear classifier on top of the local feature representation, with q values tested in the range of [9, 17, 33]. The combination of linear spatial aggregation and a linear classifier integrates evidence from local image patches into one image-level decision. Some model architectures fuse elements from DNNs and BoF models, using DNNs to replace hand-tuned feature extraction in BoF models. Research explores how insights from DNN training transfer to BoF and Improved Fisher Vector models, and compares SIFT and CNN feature descriptions. Our proposed BoF model architecture is simpler and closer to standard DNNs used for object recognition while maintaining interpretability. This work explores the relationship between BoF and DNN models, offering a simpler approach compared to other methods. Our approach simplifies the extraction of patches for higher accuracy and interpretability compared to other methods like soft decision trees and prototype-based classification. Class activation maps by BID31 also share similarities with our CNN-based approach. The class activation maps by BID31 use a CNN with global average pooling and a linear classifier to extract class-specific heatmaps. In contrast, our approach restricts CNN representations to small image patches for better traceability. Another related work by BID22 uses scattering networks with small receptive fields but does not increase interpretability due to the non-linear classifier on top of local scattering features. Our approach differs from region proposal models by extracting features only from small local regions, without relying on whole image inference. We compare BagNets with other high-performance DNNs and show similarities in decision-making. Training BagNets directly on ImageNet is discussed in the appendix. BagNets are trained directly on ImageNet, achieving high performance with small patch sizes. Comparing runtime with ResNet-50, BagNets show slower inference due to less downsampling. Each patch infers evidence for ImageNet classes, producing precise heatmaps. BagNets are trained on ImageNet, showing slower inference compared to ResNet-50. Each patch provides evidence for ImageNet classes, generating precise heatmaps. Most evidence is around object shapes or specific image features like glowing borders. Background features are often ignored. Misclassified images are analyzed with heatmaps showing true and predicted labels. Class probability is reported for BagNet-33 and VGG-16. Top patches with the most class evidence are identified across all validation images. In FIG2, top-7 patches from correct and incorrect images for various classes and BagNets are shown, revealing insights like book jackets identified by text, keys mistaken for handheld computers, and tench class recognized by fingers on a green background. Flamingos are detected by beaks, leading to confusion with storks, while grooms are primarily identified by the suit-to-neck transition. In the analysis of misclassified images by BagNet-33 and VGG-16, the green cucumber in a \"cleaver\" image led to confusion with \"granny smith.\" Similarly, a \"thimble\" image resembled a gas mask, and letters in a \"miniskirt\" image caused a \"book jacket\" prediction. The decision-making of BagNets is compared to high-performance DNNs like VGG-16, ResNet-50, ResNet-152, and DenseNet-169, with no definitive answer due to a lack of a sensible distance metric between networks. The decision-making process of BagNets is compared to other models like VGG-16 and ResNets, focusing on the neglect of spatial relationships between image parts and the impact of image scrambling on model decisions. Scrambling image parts while maintaining their counts does not affect BagNets' decisions, but it is challenging to do the same for models like VGG or ResNets due to overlapping receptive fields. Scrambling an image to maintain feature histograms invariant is challenging for models like VGG-16. The texture synthesis algorithm based on Gram features works well for VGG-16 but not for ResNet and DenseNet architectures. VGG-16 relies on statistical regularities in local image features rather than global shape integration for perceptual discrimination. BoF models with a linear classifier do not interact with spatially distinct image manipulations. For BoF models with a linear classifier, invariance to spatial arrangement of image parts is expected. The marginal presence or absence of an image part should have a consistent effect on evidence accumulation. Non-linear interactions between image parts are measured using Pearson correlation. BagNet-q holds as long as modifications are separated by more than q pixels. In experiments, image patches are masked with their DC component to study non-linear interactions. VGG-16 shows few interactions beyond 30 pixels, increasing in deeper models. The study measures Pearson correlation between masked and unmasked patches for different patch sizes and DNN models. The error distribution and spatial sensitivity of BagNets and DNNs are analyzed. The error distribution is consistent between models, and the spatial sensitivity shows how masking image parts affects prediction. Various attribution techniques are compared to determine the most predictive image parts. In this study, the authors introduced BagNets, a novel interpretable DNN architecture that classifies images based on linear bag-of-local-features representations. The results show that BagNets produce more predictive heatmaps for class-relevant image parts compared to other models. Deeper architectures are more robust to masking local patches, indicating they consider larger spatial relationships. This suggests that complex tasks like ImageNet can be solved using small image features. The study introduces BagNets, a DNN architecture solving complex tasks like ImageNet using small image features. Key properties of BagNets, such as invariance to spatial relationships, are also found in common computer vision models like ResNet-50 and VGG-16. Decision-making in DNNs trained on ImageNet follows a bag-of-feature strategy, with VGG-16 closely resembling bag-of-feature models. Deeper networks exhibit stronger nonlinear interactions between image parts and are less sensitive to local maskings, unlike bag-of-feature models. Texturisation works well in VGG-16 but fails for ResNet and DenseNet architectures. DNNs trained on ImageNet recognize textures and local image features associated with objects, leading to poor generalization to distribution shifts. BagNets can be used to evaluate task performance based on observable length-scales and trade accuracy for interpretability. They are beneficial in medical imaging for identifying predictive image features and spatial locations related to diseases. BagNets also aid in benchmarking feature attribution techniques and can be part of computer vision pipelines for better understanding of edge and image features. The pretrained BagNets (BagNet-9, BagNet-17, and BagNet-33) for PyTorch and Keras were released to aid in understanding edge and failure cases in computer vision pipelines, such as in autonomous cars. While deep neural networks (DNNs) may be more powerful than previous algorithms, they may not necessarily learn different representations. The hope is for future work to focus on encouraging models to learn more causal models of the world. Training of the models was done using PyTorch with default parameters. The study used pretrained BagNets (BagNet-9, BagNet-17, and BagNet-33) with default parameters. They tested the classification accuracy sensitivity of BagNet-33 by thresholding the logits in two ways. Results showed that for certain binarization thresholds, the top-5 accuracy was within 3-4% of the vanilla BagNet performance. The study tested BagNet-33's classification accuracy sensitivity by thresholding the logits. Results indicated that the heatmaps' amplitude is not crucial, with top-5 accuracy being 3-4% close to the vanilla BagNet performance."
}