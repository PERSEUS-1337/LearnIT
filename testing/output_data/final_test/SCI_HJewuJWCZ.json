{
    "title": "HJewuJWCZ",
    "content": "In the field of artificial intelligence, the role of teaching is often overlooked in favor of machine learning. This paper argues for equal attention to teaching, proposing an optimization framework called \"learning to teach\". This approach involves two intelligent agents - a student model and a teacher model - interacting to determine effective teaching strategies. The proposed approach involves two intelligent agents, a student model, and a teacher model, interacting to optimize teaching strategies using reinforcement learning. By applying learning to teach techniques in training deep neural networks, it shows the ability to achieve high accuracy with less data and iterations across various machine learning tasks. The evolution of modern society relies heavily on an advanced education system to equip students with necessary knowledge and skills. The importance of the teacher in the growth of a student and the training of artificial intelligence agents is highlighted. Researchers have focused more on optimizing algorithms for the student rather than realizing the critical role of the teacher in the learning process. Researchers have primarily focused on designing optimization algorithms to enhance the learning ability of intelligent agents. Limited attention has been given to developing effective teaching strategies, such as machine teaching, curriculum learning, self-paced learning, and graduated optimization. These approaches either rely on task-specific heuristic rules or pre-known oracle models, failing to reflect the nature of education and best practices. In this paper, the need for a formal study on the role of 'teaching' in artificial intelligence is emphasized. Analogies are drawn between teaching in AI and teaching in human society, highlighting the importance of adaptive teaching strategies and continuous improvement based on student feedback. An optimization framework is proposed for updating teaching skills in AI based on student feedback. In the L2T framework, teaching skills should be updated based on student feedback to achieve teacher-student co-evolution. The framework involves two intelligent agents - a student model and a teacher model, with sequential interactions during training to refine the machine learning problem. The teacher model updates teaching actions based on state information, guiding the student model's learning process. The teacher model receives inputs from the teacher model and provides reward signals back. It updates its parameters using policy gradient methods. This process is end-to-end trainable and adaptable to new learning scenarios and students without re-training. The approach is demonstrated with training data scheduling, showing improved accuracy and convergence speed for various neural networks. Our method connects CNNs and RNNs for image classification and text understanding. The teacher model can be transferred to other tasks, achieving good performance with less training data. This approach combines advanced learning with meta learning, improving AI by evolving the meta-level model slowly and task-level model quickly. Meta learning is important for improving AI and has been widely adopted in machine learning scenarios. Researchers are designing general optimizers and neural network architectures based on meta learning. It has also been studied in few-shot learning scenarios. Teaching has evolved as a new research direction, with efforts focused on machine teaching and hardness-based methods. Machine teaching aims to construct a minimal training set for the student model to learn a target model. Machine teaching is applied in limited areas with the assumption of oracle existence, while hardness-based methods assume data order benefits learning. Curriculum learning measures hardness heuristically, while self-paced learning quantifies it by data loss. Teaching strategies lack generalization ability, and 'pedagogical teaching' is applied to inverse reinforcement learning. The application of 'pedagogical teaching' in inverse reinforcement learning involves the teacher adjusting its behavior to facilitate student learning through communication. However, limitations exist in formally defining the teaching problem and differentiating it from a learning problem. Most works rely on heuristic and fixed strategies. In supervised learning, the framework of learning to teach involves choosing a function that can predict labels based on input data. The goal is to minimize the risk by evaluating the gap between the predicted label and the actual label. In supervised learning, the goal is to minimize the risk by evaluating the gap between the predicted label and the actual label using a function. Practical issues in training a machine learning model include selecting a good function based on training data, employing a surrogate loss, and searching for a good function within a hypothesis space. The training process involves optimizing an objective function to output a function with parameters that minimize the loss. In the learning to teach framework, a teacher model provides a good training set and loss function to guide the training process of the student model. The teacher model aims to help the student achieve low risk efficiently by optimizing the training data and loss function. The teacher model designs a good loss function L to guide the student model's training process by defining a function class \u2126 for the student to search from. Different hypothesis spaces lead to varying optimization difficulty and errors. The goal is to provide D, L, and \u2126 to the student for achieving lower risk efficiently. The teacher model designs a loss function to guide the student model's training process by defining a function class for the student to search from. The learning and teaching strategies in L2T are modeled as a sequential decision process with states representing information available to the teacher model. The teacher model interacts with the student model by providing training data, a loss function, or a hypothesis space. The teacher model updates its parameters based on the performance of the student model during training. The teacher model can update its parameters after the training process. It can teach new student models or the same student models in different learning scenarios. Generalization is possible as long as the state representations are the same. Reinforcement learning is used to optimize the teacher model, which acts as a policy interacting with the environment. The teacher model acts as a policy interacting with the environment, updating itself based on teaching actions and providing rewards to the student model. The interactive process between the teacher and student models stops when the student model converges, forming one episode of training. The objective of the teacher model in the L2T framework is to maximize the accumulated reward by updating its parameters. The student model interacts with the teacher model in a step state. Using data scheduling as an example, the learning to teach framework helps with deep neural network training. The student model is a deep neural network for classification tasks, with accuracy as the evaluation measure. It follows mini-batch stochastic gradient descent for learning. The teacher model provides training data to the student, determining the next mini-batch data for sequential SGD. The teacher model dynamically selects training instances from the mini-batch data to help the student model make faster progress. Reinforcement learning is used to model the interaction between student and teacher, with specific concepts introduced for state representation and batch size. The teacher model selects training instances to aid student progress using reinforcement learning. The reward is based on student learning speed, with accuracy threshold \u03c4 and terminal reward r T computed accordingly. The teacher model's action is sampled per step using a policy \u03c6 \u03b8 with parameters \u03b8 to be learned. The teacher model uses reinforcement learning to select training instances for student progress. The state feature vector g(s) effectively represents state s by including data features and student model features. Data features include label category, sentence length, and linguistic features, while student model features reflect the neural network's training progress. The teacher model uses reinforcement learning to select training instances for student progress. State features represent the current student model status with simple features like mini-batch number, training loss, and validation accuracy. Features combine data and learner model information, including predicted probabilities, loss value, and margin value. State features are computed after each mini-batch of training data. The teacher model is trained by maximizing the expected reward. The teacher model is trained using reinforcement learning to maximize expected reward by optimizing the state-action value function. The REINFORCE algorithm is used for policy gradient optimization, with experiments conducted on various neural network architectures for image classification tasks. The popular deep learning tasks include image classification for MNIST and CIFAR-10, as well as sentiment classification for IMDB movie reviews. ResNet is used as the CNN student model and LSTM as the RNN student model. Different optimization algorithms are used for training the student models. NoTeach refers to training without any teaching strategy, while Self-Paced Learning filters out training data based on loss value. During training, the loss value l(d) > \u03b7 is filtered out, with the threshold \u03b7 increasing gradually. The SPL method filters data based on loss rank in mini-batches, not absolute loss value. The teacher model in the Learning to Teach (L2T) framework uses state features g(s) and a three-layer neural network as the policy function \u03c6. RandTeach randomly filters data instances per epoch for comparison. In the L2T framework, different hyper-parameters are set for L2T and SPL, with variations in the validation threshold \u03c4 for L2T and different speeds for SPL. The model is implemented using Theano on NVIDIA Tesla K40 GPU. Test accuracy is reported for each teaching strategy based on the number of effective training instances. The convergence speed is determined by the quality of taught data, not by model updating frequencies. In the L2T framework, different hyper-parameters are set for L2T and SPL, with variations in the validation threshold \u03c4 for L2T and different speeds for SPL. The experimental curves are the average results of 5 repeated runs. Generalization ability of the teacher model is tested by teaching a new student with the same model architecture. The teacher model's generalization ability is tested by teaching a new student with the same architecture but different datasets. In another setting, the teacher model trains on MNIST for a MLP student and then teaches a CNN model on CIFAR-10. The teacher model is trained on a portion of the dataset and then used to train the student model. The student model is trained using the second fold D student train, along with various teaching strategies. The student model is then tested on the test set D test, with L2T showing the best convergence speed compared to other teaching strategies. L2T achieves good classification accuracy with reduced training data for MNIST, CIFAR-10, and IMDB datasets. This demonstrates that L2T performs well when teaching a new student model with the same architecture as the teacher model. The student model is trained using various teaching strategies, with L2T showing the best convergence speed. L2T performs well when teaching a new student model with the same architecture as the teacher model. In further investigation, L2T filters more data as training progresses, favoring harder data for MNIST and CIFAR-10 tasks. However, for the LSTM student model on IMDB, L2T teaches from easy to hard order, similar to CL/SPL. The LSTM student model on IMDB is taught from easy to hard order, which is consistent with previous findings. The teacher model can provide hard instances to the student model for image tasks from the beginning, while for natural language tasks, the student model needs to start from easy instances. This adaptivity of L2T in different learning tasks suggests the advantage of learning to teach over fixed teaching rules. In more challenging scenarios, the teacher model is trained through interaction with a student model and then used to teach another student model with different architecture. The first scenario involves training the teacher model with ResNet32 as a student and then teaching a deeper ResNet110 model on CIFAR-10. The second scenario is training the teacher model with an MLP student on MNIST and then teaching a ResNet32 student on CIFAR-10. The accuracy curves for both scenarios are shown in Fig. 4. The ResNet32 model's accuracy curve on the CIAR-10 test set is displayed in Fig. 4(b). L2T demonstrates strong generalization ability in challenging scenarios, boosting the convergence of the MLP student model trained with MNIST. The learning curves of training a ResNet32 model on CIFAR-10 using different teaching strategies are shown in Fig. 4, with the teacher model in L2T trained on MNIST with MLP student models. L2T achieves training time reduction for the student model by providing high-quality training data. The teacher model in L2T helps improve final accuracy for the student model, trained on IMDB using half of the dataset initially. The teacher model is then applied to train the student model on the full dataset until convergence. Results are shown in Table 1, indicating a boost in convergence speed and accuracy. The framework of learning to teach, L2T, achieves better classification accuracy for training LSTM networks compared to other teaching policies. Results in Table 1 show L2T surpasses the SPL baseline by more than 0.6 points. Inspired by human education systems, L2T is an end-to-end trainable method for automating the teaching process. Future directions include exploring applications in machine translation and speech recognition. The study focuses on data teaching and empirical verification of the L2T framework through experiments. The dataset used is CIFAR-10, containing 60k RGB images categorized into 10 classes. Data augmentation is applied to training images, and ResNet BID10 is used for image classification on CIFAR-10. The study utilizes ResNet32 and ResNet110 models for image classification on CIFAR-10 dataset. The mini-batch size is set to 128 with Momentum-SGD as the optimization algorithm. The initial learning rate is 0.1 and is adjusted after specific model updates. Test accuracy reaches around 92.4% and 93.2% for ResNet32 and ResNet110, respectively. The IMDB dataset consists of 50k movie review comments with positive/negative sentiment labels, evenly split into train/test sets. The sentences in the IMDB dataset are lengthy, with an average of 281 words. The study uses LSTM BID12 RNN for sentiment analysis on lengthy sentences from the IMDB dataset. The word embedding size is 256, hidden state size is 512, and mini-batch size is 16. Adam optimizer is used for training with early stopping. Test accuracy is 88.5%. In L2T, a three-layer neural network with layer sizes d \u00d7 12 \u00d7 1 is used as the teacher model. All weight values are initialized between (-0.01, 0.01). The network values are initialized uniformly between (-0.01, 0.01) with bias terms set as 0 except for the last-layer bias initialized as 2. Adam optimizer is used for policy optimization. A moving average of historical rewards is used as a baseline. The teacher model is trained until convergence. Features used to construct the state feature vector are detailed, including data features with label information. The features used in the classification tasks include data features with label information, model features representing the current model status, and combined features such as predicted probabilities, loss values, and margins. Signals are divided by pre-defined maximum numbers to constrain their values in the interval [0, 1]. The features used in classification tasks include data features, model features, and combined features like predicted probabilities, loss values, and margins. The state feature vector dimensions for different tasks are specified, and the features are normalized. Studies are conducted on the importance of different features in constructing a good L2T policy. The importance of different features in constructing a good L2T policy is studied. Model features and combined features are critical for success, as shown by poor convergence when either is removed. Data features are relatively less important, with the performance dropping slightly when removed. Training of the teacher model in L2T is also investigated. The training of the teacher model in L2T is examined, showing that after 50 episodes, the teacher model is ready for deployment with a higher reward compared to scratch training and minimal model variation."
}