{
    "title": "ByxQB1BKwH",
    "content": "MXGNet is a multilayer graph neural network designed for visual reasoning tasks, combining object-level representation, graph neural networks, and multiplex graphs. It extracts object-level representations from diagram panels, forms a multi-layer multiplex graph to capture relations between objects, and uses this information to select the most probable answer from given candidates. Tested on Diagram Syllogisms and Raven Progressive Matrices tasks, MXGNet shows promising results. MXGNet achieves state-of-the-art accuracy in Diagram Syllogisms and Raven Progressive Matrices tasks, outperforming other models by a significant margin. Abstract reasoning, particularly in the visual domain, is crucial for human intelligence and Artificial General Intelligence. Humans can quickly infer relations between elements in complex scenes, such as assembling LEGO bricks to build complex structures. Various tests have been developed to measure human abstract reasoning abilities. Tests like Raven Progressive Matrices (RPM) and Diagram Syllogism task are used to measure human ability for abstract reasoning in the visual domain. RPM tasks involve inferring abstract relationships in diagrams, while Diagram Syllogism tasks require participants to infer conclusions based on given premises. These tests are essential for understanding human intelligence and Artificial General Intelligence. Recently, Barrett et al. (2018) introduced the Procedurally Generated Matrices 'PGM' dataset and the Wild Relation Network (WReN) for RPM-style tasks. WReN surpasses other vision models but still lags behind deep neural nets in other tasks. Object-level representations have gained attention for visual reasoning, enabling the use of symbolic programs and scene graphs to capture object relations directly. However, symbolic programs are less suitable for RPM-style tasks where programs are generated from given questions in the Visual-Question Answering setting. In this paper, MXGNet, a multi-layer multiplex graph neural net architecture for abstract diagram reasoning, is introduced. The graphs are built across different diagram panels, with edges encoding multiple relations between element attributes. This approach is tested on a Diagram Syllogism dataset to demonstrate its effectiveness. MXGNet, a multi-layer multiplex graph neural net architecture, improves performance on the original model for abstract diagram reasoning. It encodes subsets of diagram panels into multiplex graphs and combines summarisation of graphs to predict the correct answer. MXGNet achieves 83.91% test accuracy on the PGM dataset without auxiliary training, outperforming existing models. It is also robust to variations in object-level representations and achieves higher test accuracies than existing models for the two datasets. MXGNet, a multi-layer multiplex graph neural net architecture, achieves higher test accuracies than existing models for abstract diagram reasoning tasks. Various approaches have been proposed for Raven Progressive Matrices, including a Convolutional Network model by Hoshen & Werman (2017) and a Relation Network architecture called WReN by Barrett et al. (2018). Steenbrugge et al. (2018) improved performance by replacing the CNN part of WReN with a pre-trained Variational Auto Encoder. Additionally, Zhang et al. (2019) introduced RAVEN, a RPM-style dataset with structured labels, and proposed Dynamic Residual Trees, a simple tree neural network for reasoning tasks. Anonymous (2020) applies Multi-head attention on RPM tasks, a form of visual reasoning. Leading approaches on CLEVR dataset use synthetic programs for object-level representations, not applicable to RPM-style problems without explicit questions for program synthesis. Recently, there has been a surge of interest in applying Graph Neural Networks (GNN) for datasets structured as graphs, such as social networks. Various GNN variants have been proposed based on learning feature representations of nodes by aggregating information from neighbor nodes and edges. Methods have been developed to extract graph structures from visual scenes for tasks like visual question answering and video classification. Wang et al. (2018b) introduced non-local neural networks that create dense graphs connecting pixels in feature maps in space-time dimensions. They also developed Euler-Net, a neural net for Euler diagram syllogism tasks, but it lacks scalability. The addition of a multiplex graph improves performance and scalability for more entities in diagrams. The Raven Progressive Matrices (RPM) improve performance and scalability for more entities. The RPM dataset includes XOR relations of object positions in diagrams. The meta-targets encode relations, object types, and attributes. The RAVEN dataset provides structured labels of relations in diagrams. MXGNet is a model with three main components: an object-level representation module, a graph processing module, and a reasoning module. Structured labels of relations in diagrams were found to not improve results and were not used in the implementation. The object-level representation module extracts representations of objects in diagrams as nodes in a graph. The multiplex graph module is used for a subset of the data. The multiplex graph module G \u03c6 learns multiplex edges capturing relations between nodes in a multi-layer graph for a subset of diagrams. MXGNet considers a subset of cardinality 3 for 3 \u00d7 3 diagram matrices and developed a pre-training method to reduce the search space of subsets. Each diagram is considered as a node in a graph, with relations between adjacent diagrams embedded as edges. The architecture embeds nodes, edges, and subsets using neural nets. CNNs embed diagram nodes, MLPs embed edges based on node embeddings, and subsets based on edge embeddings. Simple combinations of CNNs and MLPs train faster while reducing the search space. The architecture embeds nodes, edges, and subsets using neural nets. It embeds nodes first, then edges based on node embeddings, and subsets based on edge embeddings. Subset embeddings are summed and passed through a reasoning network to predict answer probability. Gating variables control the contribution of each subset to the final result, with L1 regularization used in training to suppress non-contributing subsets. This architecture quickly identifies contributing subsets while deactivating others. The experiment results in section 5.1 show how the method can be applied to multi-frame reasoning tasks for search space reduction. Subsets are hard-gated by rounding gating variables, reducing subset space to treat only rows and columns as valid subsets. The graph module summarizes object relations in subsets into embeddings, while the reasoning module predicts the probability of each answer being true based on embeddings from context rows/columns and last rows/columns with different candidate answers filled in. The curr_chunk discusses object-level representation in the PGM dataset, focusing on shapes and background lines. Two types of object-level representations are experimented with for shapes in MXGNet: CNN grid features and spatial attention. The curr_chunk discusses extracting object representations using spatial attention in the final CNN feature map. This method allows for attending to object locations and predicting the presence of objects in each attended location. The total number of objects can vary based on the presence variables. The paper discusses object representation using spatial attention in the final CNN feature map. The experiment compared a recurrent encoder with LSTM to a feed-forward conv-net encoder, finding the latter performed better. The object-level representation module outputs representations with multiple parallel relation embeddings using a multiplex edge-embedding network. The paper introduces a multiplex edge-embedding network for object representation, utilizing different layers of edge embeddings to encode similarities/differences in various feature spaces. These embeddings are useful for comparing nodes in subsequent reasoning tasks, similar to Mixture of Experts layers in Neural Machine Translation. The approach involves projecting concatenated node embeddings to different embeddings, with a focus on inter-layer edges for efficiency. In this work, a new cross-multiplexing gating function is developed for node message aggregation in graph summarization tasks. The graph module summarizes relations in diagrams by aggregating information using different set operations like max, min, sum, and mean. Multiple aggregation functions are used to cater to different reasoning sub-tasks. The cross-multiplexing gating function is developed for node message aggregation in graph summarization tasks. It combines aggregated node information from each layer using gating variables to regulate information flow. The gating function accepts node embeddings as input and outputs gating variables for each layer, which are then multiplied with node embeddings and passed through a small MLP to produce final node embeddings. The final node embeddings are produced by concatenating and processing node embeddings and background embeddings through a residual neural block. The reasoning network infers the correct answer based on relation feature embeddings from all graphs. A meta-predicting network is applied to context rows and columns to obtain probabilities of each meta-target category. MXGNet is end-to-end trainable with any gradient descent optimizer, with RAdam optimizer used in practice for its fast convergence and robustness. The loss function for the PGM dataset is balanced between answer prediction and meta-target prediction. For the RAVEN dataset, auxiliary targets did not improve performance. The Search Space Reduction model reduced subset space for both datasets. Gating variables for rows and columns in PGM and rows in RAVEN were above 0.5 after 10 epochs. In Appendix D, experiment statistics are provided. MXGNet achieved 99.8% accuracy on 2-contour and 3-contour tasks, outperforming the original paper. MXGNet scales well for more entities in the diagram. Appendix E contains more details. MXGNet variants are compared against state-of-the-art models for PGM and RAVEN datasets. MXGNet outperforms other models on the PGM dataset, showing that the multi-layer graph is a better way to capture relations in reasoning tasks. Model variants using grid features slightly outperform other models. In experiments for PGM, model variants using CNN features outperform spatial-attention-based object representations. The increased parameters in the spatial attention variant may lead to overfitting. Results show that auxiliary training with meta-target or structure labels does not improve MXGNet performance on the RAVEN dataset. MXGNet significantly outperforms ResNet models in test accuracies. In the PGM dataset, different data regimes are used to evaluate neural network generalization capabilities. The 'interpolation' and 'extrapolation' regimes were selected for reporting results due to space limitations. For more data splits of PGM, refer to Appendix G. In the 'interpolation' regime, training data restricts attribute values to even-indexed values in the spectrum of attributes. MXGNet, a graph-based approach to diagrammatic reasoning problems, combines object-level representation, graph neural networks, and multiplex graphs to capture relations in reasoning tasks. It outperforms previous models on RPM datasets and shows better generalization performance. Future work aims to make MXGNet interpretable and extract logic rules from it. MXGNet is designed for RPM style reasoning tasks and can be extended to other diagrammatic reasoning tasks. One real-world application is robots assembling parts into a whole, like building a LEGO model. MXGNet captures relations between parts, such as piecing and locking them together. MXGNet presents configurations of model variants for RPM style reasoning tasks, describing object-level representations with CNN and Spatial Attention features. Different models are used for PGM and RAVEN datasets, applying Batch Normalization and Rectified Linear Unit activation function in all layers. The CNN approach uses spatial locations in the final feature map as object feature vectors. The curr_chunk discusses the use of object vectors and residual modules in extracting CNN features for object representation. It also mentions the use of spatial attention to attend to object locations and extract representations. The curr_chunk explains the use of spatial attention to extract object-level representations in a CNN model. It utilizes a spatial attention module to identify objects in an input image and outputs binary values indicating object presence at different locations. The curr_chunk discusses the use of a binary variable z pres and an affine transformation matrix z where to identify objects in an image. The binary variable is sampled from a Gumbel-Sigmoid distribution, and the affine transformation is set to a translation and scaling matrix for the PGM dataset. An object encoder network samples patches using a grid sampler, which are then processed to generate object embeddings. The curr_chunk discusses the multiplex edge embeddings in the graph architecture, detailing the configurations for the model layers and gating function. Different configurations are used for PGM and RAVEN datasets based on the number of relation types. Gated embeddings are processed with a final fully connected layer. The module summarizes node embeddings and background embeddings to create a diagram subset embedding representing relations in diagrams. Various approaches were tested, with the best results achieved by keeping embeddings as feature maps and processing them with residual blocks. Background feature map embeddings are generated with an additional residual block on top of lower layer feature-extracting resnet. Object representations from CNN-grid features can be reshaped into a feature map and processed with conv-nets to match background feature map embeddings. Spatial attention can be used with a Spatial Transformer to place node summary embeddings on a canvas. The reasoning network configuration for RPM tasks involves processing relation embeddings with residual blocks of varying sizes and a final fully connected layer with 8 units for answer candidates. This approach differs from previous methods that led to overfitting on the RAVEN dataset. The reasoning network configuration for RPM tasks involves processing relation embeddings with residual blocks and a fully connected prediction layer with Sigmoid activation. The architecture is implemented in Pytorch framework with specific optimization parameters and training details. In the PGM dataset, elements like shapes and lines with different attributes are present, along with five types of relations. The RAVEN dataset, on the other hand, lacks logic relations but includes additional arithmetic relations. The PGM dataset contains various types of relations such as 'Progression' and 'XOR' between objects in diagrams, along with background line objects. The architecture used for Search Space reduction involves node embeddings generated by a Conv-Net with 4 convolutional layers and a fully connected layer. The model architecture includes convolutional layers, fully connected layers, edge embeddings, subset embeddings, gating variables, and a reasoning net. Training parameters include RAdam optimizer, learning rate of 0.0001, batch size of 64, and a training loss function with a tested lambda value of 0.01. After 10 epochs, only gating variables above 0.5 for subsets are considered. After 10 epochs of training, only gating variables for subsets with values above 0.5 are considered. The top-16 ranked subsets are shown in Table 3, indexed by 2 connecting edges. Figure 9 illustrates the indexing method, with subsets connected by red and blue arrows. The original model uses a Siamese Conv-Net to process input premise diagrams. Wang et al. (2018a) utilizes a Siamese Conv-Net model to process two input premise diagrams and generate consistent conclusions. Convolutional layers with shared weights are applied to the diagrams, and the top layer feature maps are used as object-level representations. A multi-layer multiplex graph captures object relations between the diagrams, with final node embeddings processed by a convolutional layer. Ablation study experiments were conducted to assess the model's performance. The ablation study experiments tested model variants with and without graph modules using vanilla edge embeddings on the PGM dataset. The model without graph modules achieved 83.2% test accuracy, lower than MXGNet's 89.6% but higher than WReN's 76.9%. The graph model with vanilla edge embeddings achieved 88.3% accuracy, slightly lower than MXGNet with multiplex edge embeddings, showing the efficiency of multiplex edge embeddings in capturing relations between objects. MXG-Net achieves 84.1% accuracy for Meta-target prediction, with a 92.4% accuracy when the Meta-target is correctly predicted. The model performs best for the OR relation (95.3%) and worst for the XOR relation (92.6%). Unfortunately, analysis of distractors in the dataset is not possible due to the lack of ground truth labels."
}