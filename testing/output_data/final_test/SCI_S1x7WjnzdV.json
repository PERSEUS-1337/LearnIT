{
    "title": "S1x7WjnzdV",
    "content": "We introduce a neural rendering architecture called the Spatial Broadcast decoder to enhance variational autoencoders' ability to learn disentangled representations. By broadcasting the latent vector across space and using a fully convolutional network with 1x1 stride, we dissociate positional from non-positional features in the latent space without explicit supervision. This architecture improves disentangling, reconstruction accuracy, and generalization in data space, complementing state-of-the-art techniques. Humans excel at generalization in various aspects, from learning new languages to interpreting art. Machine learning algorithms struggle with overfitting and domain specialization. To improve generalization, one approach is to learn compositional representations in an unsupervised manner, allowing for recombination of components. This enhances the ability to generalize in machine learning tasks. In this work, the focus is on feature compositionality in creating disentangled representations from images. The process involves broadcasting a latent sample to image dimensions and adding coordinate channels before feeding it to a convolutional decoder. This approach aims to improve generalization in machine learning tasks by allowing for recombination of components. The Spatial Broadcast decoder is a modification of the VAE decoder that improves reconstruction accuracy and disentangling in VAEs on datasets of simple objects. It shows significant benefits for small objects and improves representational generalization to out-of-distribution test datasets. The VAE decoder consists of an MLP and an upsampling deconvolutional network, leading to entangled representations. New variations of the VAE objective aim to promote disentanglement but introduce additional hyperparameters. Upsampling deconvolutional networks like the standard VAE decoder face optimization challenges, potentially impacting latent space representation-learning. The Spatial Broadcast decoder simplifies the position learning process by removing upsampling deconvolutions and using a tiled latent vector with fixed coordinate channels. This architecture allows for better disentanglement and reconstructions with shallower networks and fewer parameters compared to a standard deconvolutional architecture. The CoordConv technique, highlighted as a way to improve positional generalization, has been used in various works before. However, the combination of CoordConv with spatial tiling in a generative model, as done in this study, is a novel approach. The Spatial Broadcast decoder, combined with CoordConv, is showcased using a dataset of colored 2D sprites with 8 factors of variation. A comparison between a standard DeConv VAE and a Spatial Broadcast VAE is presented in Figure 3, showing rate-distortion curves for different \u03b2 values. The Spatial Broadcast VAE outperforms the DeConv VAE in terms of the Mutual Information Gap (MIG) disentangling metric and traversal visualizations, despite hyperparameters being chosen to minimize model error rather than for disentangling properties explicitly. The Spatial Broadcast decoder improves disentangling in VAE models, leading to a more efficient representation of data compared to a DeConv decoder. Various metrics exist to evaluate disentangling quality, but consensus on which to use is lacking. Visualizations demonstrate the effectiveness of the Spatial Broadcast decoder in inducing a better representation of data. The Spatial Broadcast decoder enhances disentangling in VAE models, improving data representation efficiency compared to a DeConv decoder. Metrics like MIG are used to assess disentangling quality, with visualizations showing the Spatial Broadcast decoder's effectiveness in creating a better data representation. The MIG metric is sensitive to rotation in latent space, as seen in geometry plots showing ground truth factor grid embedding in the latent subspace. Latent space locations corresponding to generative factor space points are plotted, revealing the model's latent space embedding of generative factor space. The Spatial Broadcast decoder for Variational Autoencoders improves learned latent representations, especially for datasets with objects varying in position. It enhances disentangling in the latent space, leading to better generalization and performance in terms of data representation efficiency. The Spatial Broadcast decoder enhances latent representations in VAE models, improving disentangling and reconstruction accuracy. It suggests using a Bernoulli decoder distribution for normalized datasets with pixel values in [0, 1], or a Gaussian distribution for stability and similar results. The Spatial Broadcast decoder enhances VAE models by improving disentangling and reconstruction accuracy. It suggests using a Gaussian decoder distribution with mean parameterized by the decoder network output and variance constant at 0.3.ReLU activations and weights initialized by a truncated normal BID8 were used in all networks, with biases initialized to zero. No other neural network tricks were employed, and models were trained with the Adam optimizer.\u03b2-VAE and FactorVAE models used a standard VAE loss with a KL term coefficient \u03b2 = 1. The Spatial Broadcast decoder requires fewer parameters than the DeConv decoder but more memory to store weights. The DeConv decoder requires 50% more memory for weight storage. Additional deconv layers were added to the Spatial Broadcast decoder for better reconstructions on the 3D Object-in-Room dataset. Models were trained with a learning rate of 3 \u00b7 10 \u22124 and batch size 16. All layers have \"same\" padding. Network architectures for Vanilla VAE, \u03b2-VAE, CoordConv VAE, and ablation study were optimized to minimize ELBO loss on colored sprites data. For the FactorVAE model, hyperparameters from the FactorVAE paper were used. Optimization hyperparameters included a learning rate of 10^-4 for VAE updates, 2 * 10^-5 for discriminator updates, and batch size 32. Instability was encountered during training on colored sprites, leading to hyperparameter sweeps for improved stability. The dataset used for the model is the binary dsprites dataset with colors sampled in HSV space. It contains 737,280 images with colors sampled online, making the dataset effectively infinite. Unlike other datasets, it has only a single channel in its images and consists of 86,366 images with 6 factors of variation. The dataset consists of 480,000 images with 6 factors of variation: Camera angle, object size, object shape, object color, wall color, and floor color. Colors are sampled uniformly from a continuous set of hues. The images are procedurally generated with various combinations of factors using a custom image generator in PyGame. Five datasets were created controlling subsets of factors like X-position, Y-position, Size, and Color, named X-Y, X-H, R-G, X-Y-H Small, and X-Y-H Tiny. These datasets can be seen in different figures. The datasets with dependent factors were created by holding out a quarter of the dataset, generating 500,000 training images for each dataset. The number of training steps for each model can be found in TAB6. Training iterations differ for FactorVAE due to instability, but this does not affect the results as comparisons are not made across models. The study compares decoder architectures, specifically focusing on the importance of the organization of coordinate channels in the Spatial Broadcast decoder. An ablation study is conducted by randomly permuting the coordinate channels to demonstrate their significance in providing positional information. The study focuses on the importance of coordinate channels in the Spatial Broadcast decoder, showing improved disentangling and rate-distortion trade-off for \u03b2-VAE BID6. The decoder is also introduced to FactorVAE BID9, enhancing disentangling in FactorVAE models. Additionally, it addresses the issue of discontinuity in object position representation in DeConv VAEs. The study highlights the importance of coordinate channels in the Spatial Broadcast decoder for improved disentangling in small objects. The decoder's bias towards representing positional variation continuously is beneficial in the small-object regime. The study also introduces CoordConv VAE BID14 as a decoder architecture to enhance the continuity of VAEs. CoordConv VAE BID14 is a decoder architecture that improves VAE representations by appending coordinate channels to feature layers. The model shows entangled latent space on the colored sprites dataset, using upscale deconvolutions to go from spatial shape 1 \u00d7 1 to 64 \u00d7 64. The Spatial Broadcast decoder is better suited for datasets with X-and Y-position factors of variation. On datasets without positional factors of variation like Chairs and 3D Object-in-Room datasets BID1 BID9, a Spatial Broadcast VAE learns disentangled representations comparable to SOTA methods. However, Latent space traversals are entangled when traversing all 10 latent components, including non-coding ones. This is achieved without modifying the standard VAE objective. See Figures 10 for results. The Spatial Broadcast Decoder's good performance on datasets like Chairs and 3D Object-in-Room is attributed to its shallower network and avoidance of upsampling deconvolutions. Model hyperparameters were selected based on minimizing ELBO loss, not considering disentangling. Large-scale sweeps were conducted to analyze hyperparameter sensitivity for both DeConv and Spatial Broadcast decoders on the colored sprites dataset, revealing insights on ELBO and VAE loss. The curr_chunk discusses key quantities in evaluating VAE models, such as ELBO, NLL, KL, Latents Used, MIG, and Factor VAE metric. It highlights the importance of these metrics in assessing the performance and representation capabilities of VAE models. The Spatial Broadcast decoder in the FactorVAE paper shows that as the ConvNet depth increases, the model moves towards lower rate/higher distortion, leading to a drop in latent space information and reconstruction accuracy. Adding an MLP to the input vector had a similar effect as increasing the number of convolutional layers. Adding an MLP to the input vector had a qualitatively similar effect as increasing the number of convolutional layers on the colored sprited dataset, decreasing latent capacity and giving poorer reconstructions. However, on the 3D Object-in-Room dataset, adding the MLP improved the model when using ConvNet depth 3. Increasing the MLP layers in the DeConv decoder had a similar effect as increasing the ConvNet layers. Adding a pre-broadcast MLP with 2 or 3 layers improves accurate reconstructions and disentangling in the dataset generative factors. This is an alternative to increasing ConvNet depth in the model. There is a continuum of models between the Spatial Broadcast decoder and the Deconv decoder, where convolutional layers can be replaced by deconvolutional layers with stride 2. Table 10 shows the progression of this replacement, indicating potential improvements in the model. Replacing broadcast decoder with deconvolutional layer with stride 2 negatively impacts disentangling in Spatial Broadcast VAE without affecting other metrics. Results on colored sprites dataset show decreasing performance as convolutional layers are replaced by deconvolutional layers. Additional experiments on various datasets and FactorVAE models confirm the detrimental effect of upscaling deconvolutional layers on VAE representations. In this section, additional results are presented on generative factor pairs and their impact on disentangling. Different datasets were generated with independent and dependent generative factors, and VAE models were run with DeConv and Spatial Broadcast decoder. Results show that the Spatial Broadcast decoder significantly improves disentangling, especially with positional variation. Even with no positional variation, the decoder improves latent space geometry in generalization experiments. The Spatial Broadcast decoder improves disentangling in VAE models, especially with positional variation. It also enhances latent space geometry in generalization experiments. Additionally, using this decoder in a dataset with dependent factors, such as images with no objects, shows a significant improvement in disentanglement compared to the DeConv decoder. The MIG metric may not capture disentangling well in some cases due to the choice of basis. The MIG metric may not effectively quantify disentangling due to basis choice and other metrics have shortcomings. There is no consensus on which metric to use, as a single scalar cannot fully capture the quality of a representation. The disentangling-distortion trade-off in representation learning involves balancing reconstruction and disentanglement. Subjective preference and dataset characteristics play a role in this balance. Latent space visualization is crucial for representational analysis due to the challenges in defining disentangling metrics. Latent space traversals can be revealing but have shortcomings such as entanglement and time-consuming cross-referencing. It is advised not to heavily rely on traversals for evaluating latent space geometry. Factor visualizations are often more informative. Latent space analysis for an independent X-Y dataset is shown in FIG0. The Spatial Broadcast decoder improves FactorVAE and VAE, with a messy latent space in DeConv FactorVAE. Using a fixed-variance Normal decoder distribution helps, but Spatial Broadcast FactorVAE performs best. Including shape or size variability in the dataset aids FactorVAE disentanglement. FactorVAE is sensitive to hyperparameters. Latent space analysis for a dependent X-Y dataset is shown. The Spatial Broadcast decoder significantly improves image representation in latent space analysis, demonstrating generalization and extrapolation capabilities across different datasets. The Spatial Broadcast decoder shows improved image representation in latent space analysis for an independent X-H dataset. The representation is axis-aligned and nearly linear in the positional direction, though non-linear in the hue direction. This suggests that the architecture's inductive bias overrides the objective function's bias. The Spatial Broadcast decoder improves image representation in latent space analysis for a dependent X-H dataset. FactorVAE shows significant contraction in latent space to eliminate unused regions. FactorVAE sacrifices latent space geometry to remove \"hole\" from latent space prior distribution, Spatial Broadcast decoder benefits from being a shallower network. The \"hole\" in generative factor space affects extrapolation in both pixel and generative factor space, leading to slightly lower MIG scores. Latent space analysis for X-H dataset with blank images is also discussed. The Spatial Broadcast VAE improves latent space geometry by allocating a relevant latent to indicate the presence or absence of an object in the dataset with blank images."
}