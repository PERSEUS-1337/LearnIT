{
    "title": "rkxoNnC5FQ",
    "content": "Deep Learning for Computer Vision relies on supervision sources. A new unsupervised domain adaptation algorithm, SPIGAN, uses Simulator Privileged Information (PI) and Generative Adversarial Networks (GAN). The approach improves performance in semantic segmentation by training on real-world and synthetic data with z-buffer PI. This method outperforms other unsupervised domain adaptation techniques, addressing the challenge of learning with minimal human supervision in Machine Learning and Computer Vision. Training in simulation has shown improvements in various Computer Vision tasks, but domain gaps between synthetic and real data remain a challenge. Supervised domain adaptation involves labeling real-world data to train models on mixed synthetic and real data. Unsupervised domain adaptation algorithms leverage Generative Adversarial Networks for pixel-level adaptation. The paper introduces SPIGAN, an adversarial learning algorithm that leverages simulator Privileged Information (PI) for GAN-based unsupervised learning from unpaired real-world data. It aims to adapt synthetic images to be more realistic by utilizing additional information not available in the real world. The SPIGAN algorithm utilizes a discriminator, task network, and privileged network to adapt synthetic images with privileged information from a simulator. This method is evaluated on semantic segmentation in urban scenes using real-world datasets without training labels. SPIGAN is a method that uses simulator privileged information to learn a semantic segmentation network without real-world labels. It outperforms other unsupervised domain adaptation methods and bridges the sim-to-real gap. The paper is organized into sections discussing related works, the SPIGAN algorithm, quantitative experiments on semantic segmentation, and conclusions. Domain adaptation is typically approached as domain-invariant learning or statistical alignment, with a focus on unsupervised adaptation methods in deep learning. Our work focuses on unsupervised adaptation methods in deep learning, specifically addressing the domain gap between source and target distributions. The Domain Adversarial Neural Network (DANN) is a popular approach for learning domain invariant features. Curriculum Domain Adaptation is a recent evolution for semantic segmentation that reduces the domain gap through a curriculum learning approach. Recent advancements in unsupervised domain adaptation include the use of adversarial domain adaptation based on GANs, such as CycleGAN and Variational Auto-Encoders (VAEs). These techniques aim to bridge the domain gap between synthetic and real-world images by learning generative models for image translation. SimGAN leverages simulation for generating annotated datasets to refine synthetic images. Sadat BID40 effectively uses synthetic data to refine images, treating foreground and background differently. SPIGAN learning algorithm involves four networks: a generator, discriminator, perception task network, and privileged network. It aims to improve synthetic images to look more realistic by learning from unlabeled real-world images and simulator outputs. The recent methods focus on predicting the simulator's PI z s to support learning, with PixelDA BID1 being a domain adaptation method using simulation as the source domain. BID21 and BID41 study semantic segmentation in adversarial training, while BID42 leverages the GAN framework for shared representation learning. BID5 uses target guided distillation for task network imitation. Our approach introduces Privileged Information from a simulator in a novel way by incorporating a privileged network in our architecture. This significantly improves semantic segmentation in urban scenes, especially in challenging real-world conditions with a large sim-to-real domain gap. Our work is inspired by Learning Using Privileged Information (LUPI) and distillation techniques. The text discusses the use of Privileged Information (LUPI) BID51 for unsupervised domain adaptation from a simulator to real-world data. Inspired by previous works, the goal is to leverage additional data available at training time to improve perception tasks. Our goal is to design a procedure for unsupervised domain adaptation from a synthetic domain to a real domain using neural networks. The source domain has labeled synthetic images with Privileged Information (PI), while the target domain has unlabeled images. The challenge is bridging the gap between the synthetic and real domains. The main challenge addressed is bridging the gap between synthetic and real domains for unsupervised domain adaptation using neural networks. The simulator's Privileged Information (PI) is leveraged within a GAN framework called SPIGAN to guide and constrain the training of the target task network. SPIGAN utilizes a generator to transform images from a source domain to an adapted domain, aiming to make them statistically close to the target domain for accurate testing. The discriminator distinguishes between fake and real images in an adversarial game. The target task network is trained on synthetic images to predict labels, while the privileged network predicts privileged information assuming the generator preserves it. The main learning goal is to train a model that can correctly perform a perception task in the target real-world domain. The joint learning objective involves optimizing a minimax objective with weights for adversarial loss, task prediction loss, PI regularization, and perceptual regularization. The privileged network's information is used to constrain the learning of the perception task and encourage the generator to model the target domain while being label-and PI-preserving. The learning objective involves optimizing a minimax objective with weights for adversarial loss, task prediction loss, PI regularization, and perceptual regularization. Adversarial loss is based on least-squares, stabilizing training and improving image results. Task prediction loss optimizes the task network over synthetic images and their adapted versions. Different tasks require different loss functions, with the assumption that the generator is label-preserving. In experiments, different tasks like semantic segmentation and predicting PI require specific loss functions. For semantic segmentation, cross-entropy loss is used, while predicting PI involves depth and 1-norm losses. Perceptual loss is also utilized to maintain image semantics. Adversarial training is employed for optimization. In practice, adversarial training is used to optimize joint learning objectives by updating discriminator and generator parameters alternately. The method is evaluated on semantic segmentation in a real-world domain without training labels, using the SYNTHIA dataset for synthetic source domain with automatic annotations. In our experiment, we use SYNTHIA-RAND-CITYSCAPES for semantic segmentation labels and Cityscapes BID6 and Mapillary Vistas BID33 datasets for real-world urban scene images. Cityscapes dataset has 2,975 training and 500 validation images, while Mapillary Vistas has 16,000 training and 2,000 evaluation images. No labels from real-world domains are used during training. In the experiment, adaptation from SYNTHIA to Cityscapes is evaluated on 16 classes using standard evaluation protocols. Ablation studies are conducted with and without PI (depth) during adaptation to Cityscapes and Vistas. Intersection-over-union (IoU) and mean IoU are used as validation metrics. The generator and discriminator models are adapted from CycleGAN and BID23, with a PatchGAN network for the discriminator. The FCN8s architecture is used for both the task predictor and privileged network. The FCN8s architecture is utilized for the task predictor and privileged network. The perceptual loss is implemented using activations from a pre-trained VGG19 network. Hyper-parameters are set through grid search on a separate validation set. Joint adversarial loss weights are determined for GAN, task, privileged, and perceptual objectives. The values found show robustness and generalization across datasets and experiments. The key factors in the objective are the GAN and task losses, with regularization terms playing a secondary role. Stabilizing effects of task and privileged losses help determine an effective early stopping criterion based on discriminator and generator loss comparison. The discriminator loss outperforms the generator loss consistently, inspired by previous semi-supervised results. Evaluation is done at two resolutions: 320 \u00d7 640 and 512 \u00d7 1024. Images are resized during training and evaluation. Different crop sizes are used for lower and higher resolutions. The Adam optimizer is used with an initial learning rate of 0.0002 in PyTorch implementation. In this section, the SPIGAN algorithm is evaluated for adapting a semantic segmentation network from SYNTHIA to Cityscapes using depth maps as PI. Results are compared to other domain adaptation algorithms, showing quantitative results for the semantic segmentation task on Cityscapes. SPIGAN achieves state-of-the-art semantic segmentation adaptation on Cityscapes by utilizing depth maps as PI. Results show a 3% improvement in mean IoU compared to non-PI methods, thanks to the regularization provided during training. This confirms the main contribution of leveraging synthetic data and PI for improved generalization. The study compares SPIGAN with and without PI, as well as SPIGAN-base, on semantic segmentation adaptation across sim-to-real domains. Experiments include training on source and target domains at 320 \u00d7 640 resolution, with results on the challenging Vistas dataset. Adaptation results for both target domains are presented in Table 2, along with conventional segmentation performance metrics. SPIGAN with perceptual regularization outperforms SPIGAN-base in semantic segmentation adaptation across sim-to-real domains. The adaptation is stabilized during training, leading to significant improvements in all categories, especially in \"nature\", \"construction\", and \"vehicle\" categories. For Cityscapes dataset, SPIGAN shows a dramatic improvement in mean IoU by 17.1%, with perceptual regularization contributing 7.4% to the improvement. SPIGAN demonstrates significant improvements in various categories such as \"nature\", \"construction\", and \"vehicle\", with a notable +15% increase in IoU for the \"human\" category. Qualitative results for adaptation from SYNTHIA to Cityscapes are provided. On the Vistas dataset, SPIGAN reduces the domain gap by +4.3% mean IoU, highlighting the importance of perceptual regularization for generalization performance. Negative transfer is observed in SPIGAN-no-PI, with a decrease of -13% in performance compared to the FCN source. The difference in results between Cityscapes and Vistas is attributed to the visual diversity of the datasets. Cityscapes is a more visually uniform benchmark than Vistas, recorded in German cities with nice weather. Vistas has crowdsourced data from around the world with varying cameras and environments. Cityscapes is more amenable to image translation methods, with adaptation happening at color and texture levels. A larger domain gap increases the risk of negative transfer, as seen in SPIGAN suffering from artifacts. SPIGAN's artifacts are less severe and consistent with the scene depth, addressing the domain gap and avoiding catastrophic failures. The consistent improvement brought by PI in both experiments shows that PI promotes better task-oriented training and guides training to reduce domain shift. Unsupervised adaptation methods show similar performance in certain categories, with the \"vehicle\" category seeing the largest improvement. However, the \"human\" category did not show the same improvement due to the limited human presence in the SYNTHIA subset used in the experiments. SPIGAN is a novel method that leverages synthetic data and Privileged Information (PI) to perform unsupervised domain adaptation of deep networks. It jointly learns a generative adaptation network, target task network, and privileged information models to address domain gaps between synthetic data and real-world domains, such as semantic segmentation of urban scenes. Future work includes applying SPIGAN to additional tasks with different types of PI obtained from simulation."
}