{
    "title": "ryfMLoCqtQ",
    "content": "Recent attention has been focused on the generalization puzzle in deep learning, where large, deep networks perform well but existing theories on generalization error are inadequate. The hope is that knowledge can transfer across tasks to improve generalization. A new analytic theory has been developed for the nonlinear dynamics of generalization in deep linear networks, providing solutions for training and testing errors based on various factors. This theory shows that deep networks gradually learn the most important task structure. Our theory reveals that deep networks learn important task structures first, affecting generalization error at early stopping time. Tight bounds on generalization error must consider task structure. A learning algorithm out-performs neural network training. Knowledge transfer in transfer learning depends on SNRs and input feature alignments. Training is stopped early to prevent overfitting. The procedure of stopping training early to prevent overfitting in deep networks raises a generalization puzzle as existing theories provide loose bounds on generalization error. A new analytic theory for deep linear networks is developed to explain their impressive generalization capabilities, considering learning dynamics and task structures. Deep linear networks serve as a good theoretical model for generalization dynamics, with an analytic theory developed for training and test error based on various factors. The theory reveals that networks with small weight initialization prioritize learning important aspects of a task first, impacting optimal test error at early stopping time. Task structure and SNR play a significant role in generalization dynamics, rather than network architecture. Our theory on generalization dynamics highlights the importance of considering task structure in addition to network architecture. It also introduces a non-gradient-descent learning algorithm that out-performs neural network training. Multi-task learning facilitates knowledge transfer between tasks, reducing generalization error. The amount of knowledge transferred between tasks depends on their SNRs and feature space alignments. In a student-teacher scenario, an ensemble of low-rank, noisy teacher networks generates training data for a more complex student network. The study focuses on understanding the dynamics of training and test errors in linear teacher networks with multiple layers and weight matrices. The study focuses on the singular value decomposition of weight matrices in a teacher network with multiple layers. The teacher network generates noisy outputs from orthonormal inputs for training data. The analysis is done in the limit of infinite input and output dimensions with a low, finite rank teacher. The teacher network generates noisy outputs from orthonormal inputs for training data. The input covariance is assumed to be white, and noise scaling is chosen for non-trivial generalization effects. Generalization performance depends on the ratio of teacher singular values to noise variance. The study focuses on the singular value decomposition of weight matrices in a teacher network with multiple layers. In the main paper, the focus is on one hidden layer networks with orthonormal inputs, but the theory extends to networks of arbitrary depth and white inputs. Student networks can have more hidden units than the teacher, with training and test errors defined accordingly. The text discusses the error dynamics of a student network in relation to the alignment of its singular modes with those of the training data and teacher. The focus is on one hidden layer networks with orthonormal inputs, but the theory extends to networks of arbitrary depth and white inputs. The student networks can have more hidden units than the teacher, with training and test errors defined accordingly. The text explores the error dynamics of a student network learning from a teacher network, considering student network size, initialization, teacher SNR, and training time. It focuses on the training error of the student network undergoing batch gradient descent with learning rate \u03bb. Two classes of student initializations are considered, with the first involving random weights that form a composite map with random singular vector matrices. The text discusses the error dynamics of a student network learning from a teacher network, focusing on student initialization and training time. It considers random singular vector matrices for student weights, with a special class of training aligned initial conditions leading to unchanged singular vectors during learning. The text discusses how the singular vectors of a student network's composite map remain unchanged during learning, while the singular values evolve according to a learning curve function. This function describes how each training set singular value drives the dynamics of the corresponding student singular value, showing a wave of singular mode detection sweeping from large to small values. The text discusses the mode detection wave in training data modes with singular values evolving over time. The analytic solution for the TA learning dynamics approximates the student learning dynamics for both training and generalization errors. The results assume a single hidden layer, with the possibility of applying the theory to deeper networks. The singular modes of a TA network are related to the training data through a perturbation of the low rank teacher matrix by a high dimensional noise matrix. In the high dimensional limit, the top singular values and vectors of the perturbed matrix converge to the transfer function from teacher to training data singular values. The singular vectors can also overlap with the teacher modes. The singular vectors of the teacher overlap with the modes of the training data through a relation. The singular values of the training data are distributed according to the Marchenko-Pastur distribution, showing a phase transition. The imprinting of teacher modes on the training data depends on the teacher's singular value, with a phase transition occurring at a specific value. The teacher mode is imprinted in the training data when s > A 1/4, with the training data singular value popping out of the MP sea. The inflation effect decreases at larger s, with the alignment approaching unity as s increases. The singular mode structure of the teacher is imprinted in the training data covariance. The teacher's influence is seen in the training data covariance through various modes. The time evolving singular modes of a network are driven by this structure. Experimental results show a close match between theory and practice for different types of teachers and students. Analytic expressions for training and testing errors are derived for a TA network. Learning curves closely resemble those of a random network. The TA network's learning curves closely approximate those of a random student with time-evolving singular vectors. Training error is influenced by distinct regions in the data covariance, with some singular values being unlearnable by a rank N2 student. The MP distribution in terms of f, the point where MP density has mass to the left and right, is discussed. For a full rank student, f = 1 - \u221aA, with training error going to zero as singular values approach those of the training data. Test error behavior differs, with a theory of generalization dynamics based on data distribution and student complexity. The architectural complexity of the student, including its rank, number of layers, and initialization norm, along with training time, provide insight into generalization dynamics early in learning and overfitting later. Simulation results show a match between theory and performance for different student types and teacher ranks. Learning involves detecting singular modes in training data, with strong singular values associated with high SNR teacher modes learned initially. The behavior differs based on teacher rank. The student's learning curve shows early drops with a high SNR teacher, while overfitting is indicated by a rise in test error. The random student lags behind the TA in learning singular vectors but achieves similar optimal stopping times and minimal test errors. The theory can be extended to describe learning dynamics in deeper networks. There is a good match between TA and student networks, with optimal stopping errors matching. The alignment lag is longer for randomly-initialized networks in deeper layers, but the curves are similar. The theory is also extended to nonlinear networks, showing qualitative replication of phenomena observed in linear networks. The theory extends to deeper and nonlinear networks, showing similarities in learning dynamics. Nonlinear networks exhibit earlier overfitting than linear networks due to mode co-opting. Overall, learning patterns are similar, with interesting phenomena in nonlinear networks understandable in the linear case. The dynamics of memorization and transfer in deep learning are explored, showing similarities between linear and nonlinear networks. An intriguing observation is made that deep networks can memorize data with randomly permuted labels, raising questions about generalization in deep learning. The learning dynamics of training error for randomized labels can be slower than for structured data in deep linear networks. Randomized data leads to slower initial training error drops due to dilution of signal variance over many more modes. The learning dynamics of training error for randomized labels can be slower than for structured data in deep linear networks. Randomized data leads to slower initial training error drops due to dilution of signal variance over many more modes. In the case of a rank 1 teacher, optimal early stopping occurs before the detection wave penetrates the MP sea, minimizing test error. The optimal generalization error with a rank 1 teacher is related to the alignment of training data singular vectors with teacher singular vectors. As learning progresses, the student overfits on the first mode but learns lower modes. This suggests a superior non-gradient training algorithm for setting each singular value optimally. The text suggests a non-gradient training algorithm for setting each singular value optimally, outperforming standard gradient descent learning. The algorithm extracts top singular values from training data covariance, computes optimal singular values, and constructs a matrix with outlier singular values shrunk. This algorithm is proven to outperform neural network training. The text discusses the transfer benefit between two teacher networks and two student networks, as well as the concept of learning tasks simultaneously. The transfer benefit is defined as the difference in optimal test errors when learning tasks separately versus together. Positive transfer benefit implies lower test errors when learning tasks simultaneously. The transfer benefit in learning tasks simultaneously is independent of output singular vectors. Relevant input features, not responses, drive knowledge transfer. Transfer can occur from high SNR to low SNR tasks, increasing with task alignment. Joint learning with related tasks can capture signals that would otherwise be lost. High SNR in one task requires strong alignment in the other. The theory predicts that transfer between tasks depends on alignment and signal-to-noise ratio (SNR). High SNR in one task requires strong alignment in the other for beneficial transfer, with interference otherwise. Nonlinear networks also show similar phenomena, suggesting insights for choosing auxiliary tasks. Knowledge transfer relies on aligning input features, not responses, emphasizing the importance of feature alignment for successful transfer. The analytic results offer insight into generalization and transfer phenomena in nonlinear cases. The work aims to inspire the search for tighter upper bounds on generalization error, non-gradient based training algorithms, and theory-driven selection of auxiliary tasks. The dynamics of convergence in a single-hidden-layer network towards training data singular modes are described, with a focus on the differential equation governing mode strength. The equation is separable and can be integrated for any number of layers, with a focus on 5 layers. The expression is numerically inverted for analysis. Randomly-initialized networks behave similarly to TA networks but show a lag in mode alignment with data. Stronger modes align more quickly, and mode alignment is relatively independent of teacher rank. Deeper networks exhibit slower mode alignment. Deeper networks exhibit slower mode alignment, with a larger lag between randomly-initialized and TA networks. When evaluating a network's loss on a subset of outputs, a slight generalization of train and test error formulas is needed. This involves applying a projection operator and expressing errors in terms of student, training data, and teacher SVDs. The transfer benefit between networks A and B is determined by singular values and unaffected by certain factors. Alignment of network modes to data modes and growth of singular values are shown in graphs for different network configurations. Deeper networks exhibit slower mode alignment, with alignment completed as singular values increase. The transfer effects between networks A and B are driven by the relationship between matrices V A and V B and the singular values, as the eigenvectors of these matrices are in bijection. The alignment between the output modes is not relevant for the transfer. The transfer benefit between networks A and B is determined by the alignment of eigenvectors of matrices V A and V B, weighted by their eigenvalues. In special cases like rank one with equal singular values, the transfer can be calculated precisely. The interference between tasks is due to changing the singular dimensions of Y A from V A to V AB in the rank one case. In the multi-task setting, transferring knowledge from one task to another comes at the cost of ignoring differences between the tasks, as shown by changing the singular dimensions of Y A to V AB. This allows the common structure to be emphasized while the distinctions between tasks are diminished. In the multi-task setting, transferring knowledge between tasks can lead to a cost of ignoring task differences. Incorporating task B can introduce noise into task A's signal, explaining why transfer can be beneficial or detrimental. The transfer benefit arises from alignment between task input modes, as shown in Figure 10. Theoretical insights extend beyond linear networks to non-linear networks, demonstrating generalized transfer patterns. In non-linear networks, transfer patterns generalize. Results from teacher networks with different sizes and leaky relu non-linearities are shown. Training a student on a task with support from an aligned task can improve performance. Task interference and alignment effects are influenced by signal-to-noise ratio. Strong signal tasks are less affected by other tasks unless well aligned. The focus is on test error dynamics with equal examples and inputs. The formula for test error curves is modified as the number of training examples P is varied, focusing on the case of a full rank student with aspect ratio A = 1. The effects of varying the number of training examples P on test error and minimum generalization error are discussed. The minimum generalization error is determined by SNR P/N 1, leading to convergence to a single asymptotic line as P increases. When P < N 1, curves for different SNRs separate due to initial SNR effects. The training set provides second-order training statistics for student learning, involving matrices X, \u0176, Z, input correlation matrix \u03a3 11, and input-output correlation matrix \u03a3 31. Noise matrix Z elements are Gaussian with zero mean and variance \u03c3 2 z /N 1. Noise scaling ensures non-trivial generalization effects. Training inputs are close to unit-norm. The training inputs are chosen to be close to unit-norm, with the input covariance matrix \u03a3 11 made as white as possible. For P > N 1, rows of X are chosen to be orthonormal and scaled up by P/N 1, while for P < N 1, columns of X are orthonormal. Generalization performance depends on the ratio of teacher singular values to noise variance parameter \u03c3 2 z, with \u03c3 z set to 1. Teacher singular values can be seen as signal to noise in the context of unit-norm inputs. The teacher singular values act as signal to noise ratios for unit-norm inputs. The dynamics of test error vary with the number of training examples. Two regimes are considered: oversampled (D > 1) and undersampled (D < 1). In the undersampled regime, the projection operator onto the column space of inputs is crucial for learning dynamics. The student map is transformed from the input subspace to the output space. In the undersampled learning problem, the student map is frozen in the N 1 \u2212 P dimensional subspace orthogonal to the image of P. The effective aspect ratio is no longer A = N 3 /N 1 but D = P/N 1. Modifications in the equations account for generalization error and training modes that cannot be correlated with the teacher. The dynamics of test error vary with the number of training examples, with oversampled and undersampled regimes considered. The projection operator onto the column space of inputs is crucial for learning dynamics. In the undersampled learning problem, the student map is frozen in the N 1 \u2212 P dimensional subspace orthogonal to the image of P. The effective aspect ratio is now D = P/N 1. The third term accounts for learned correlations between the student and teacher, with transformations involving aspect ratio replacement and singular value attenuation. The singular vector overlap computation is also adjusted accordingly. The theory matches empirical simulations for varying values of P in oversampled and undersampled measurement regimes. Notably, the minimum generalization error improves with P, but the asymptotic generalization error does not due to a frozen subspace of modes that are not overfit when P < N 1. In the undersampled learning problem, the minimum generalization error improves with P, but the asymptotic generalization error does not due to a frozen subspace of modes that are not overfit when P < N 1. The curves for different SNRs separate when P < N 1, while converge to a single asymptotic line as P increases when P \u2265 N 1. Gaussian inputs yield similar results to orthogonalized data matrices, with slightly higher optimal stopping error. The theory remains exact for TA networks of any rank, showing similar optimal stopping generalization error between TA and random networks. The optimal stopping time in randomly initialized networks lags behind that of aligned networks, with the lag increasing as the student rank decreases. Random networks of varying ranks show similar trends of increasing optimal stopping error and time as SNR decreases. Aligned networks predict trends of increasing optimal stopping error and time with decreasing SNR. (Plots made with a rank 1 teacher and N1 = N3 = 100)"
}