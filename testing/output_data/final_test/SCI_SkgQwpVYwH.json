{
    "title": "SkgQwpVYwH",
    "content": "In the literature, studies focus on eliciting distributional information from self-interested agents for building data-intensive learning systems. Asking for complex distribution $p(x)$ is challenging due to cognitive loads. A deep learning aided method is introduced to incentivize credible sample contributions from agents for building an image classifier. A deep learning method is proposed to incentivize truthful sample contributions from rational agents by designing an incentive-compatible score function. Accurate estimation of an $f$-divergence function allows for approximate incentive compatibility. The study introduces the problem of sample elicitation and establishes a connection between sample elicitation and $f$-GAN for distribution estimation. The availability of credible samples is crucial for building high-fidelity machine learning models, especially for data-hungry deep learning systems. Crowdsourcing from a decentralized population is a scalable way to collect training samples, as seen in the example of ImageNet. The main challenge is to incentivize agents to report private information truthfully, which can be addressed using proper scoring rules. Incentivizing agents to report private information truthfully is crucial for collecting credible samples from self-interested agents. Strictly proper scoring rules can be applied to elicit information about a random vector X from a distribution P, but this approach has limitations when the outcome space is large or infinite. This has led to further research on eliciting properties of distributions. In this work, the goal is to collect credible samples from self-interested agents by studying sample elicitation. Instead of asking for the entire distribution, samples drawn from the distribution are elicited truthfully. A score function is designed to compare different distributions, relaxing reporting complexity requirements and finding applications in machine learning tasks. This approach resembles property elicitation methods in previous research. Our approach focuses on eliciting individual sample points from distributions, different from property elicitation which aims to elicit statistical properties. We use f-divergence to incentivize truthful reporting of samples and employ deep learning techniques to design a score function. Additionally, we propose a variational approach to efficiently estimate the divergence function using reported samples. Our framework uses a variational form of the f-divergence function and deep neural networks to efficiently estimate divergence functions from reported samples. This allows for approximate incentive compatibility in eliciting truthful samples, even without access to ground truth samples. Additionally, we employ a generative adversarial approach to reconstruct the distribution from the elicited samples, providing estimates with provable finite sample complexity. In this paper, the focus is on developing theoretical guarantees for scoring mechanisms with provable finite sample complexity. The contributions include proposing a sample elicitation framework for complex distributions, addressing cases where the mechanism designer lacks ground truth information, and developing estimators using deep learning techniques with strong theoretical guarantees. This aids in establishing approximate incentive-compatibility and recovering the targeted distribution from elicited samples. Our contribution focuses on eliciting credible training samples by deep learning for deep learning. The relevant literature includes strictly proper scoring rules and property elicitation for complex distributions. Score functions for linear properties and the complexity of eliciting properties are also discussed in the literature. Our work complements the information elicitation literature by proposing a variational approach to estimate f-divergence functions, extending the line of work on divergence estimation. Various methods for estimating divergence, including density function estimation and variational forms, have been explored in the literature. The curr_chunk discusses the estimation of divergence through density ratio modeling and the use of Generative Adversarial Networks (GAN). It also introduces notation for empirical distribution and Lebesgue measure. The work builds on previous research in divergence estimation methods. The curr_chunk discusses sample elicitation in two scenarios: one with group truth samples and the other with samples from agents. It focuses on designing a score function for multi-sample elicitation with ground truth samples. The curr_chunk discusses designing a score function for sample elicitation with peer samples, where agents may have subjective biases or local observation biases. It aims to ensure properness in scoring rules when samples are drawn from different distributions. The curr_chunk focuses on designing a score function for sample elicitation in a peer prediction setting, ensuring properness in scoring rules despite subjective biases or local observation biases among agents. The goal is to achieve a (\u03b4, \u03f5)-Bayesian Nash Equilibrium in truthful elicitation. The text discusses the use of divergence functions as score functions for eliciting samples in a peer prediction setting, aiming to achieve properness in scoring rules. It involves evaluating the f-divergence between two distributions without knowing their probability density functions, using sample forms instead of analytic forms. The focus is on designing a score function for truthful elicitation in a Bayesian Nash Equilibrium. The text discusses error bounds for estimating D f (q\u2225p) with assumptions on bounded density ratio and smoothness of functions. The support is assumed to be on \u2126 \u2282 R d with a \u03b2-H\u00f6lder function class defined. Regularity conditions for the function f (\u00b7) are also assumed. In the context of error bounds for estimating D f (q\u2225p) with assumptions on bounded density ratio and smoothness of functions, regularity conditions for the function f (\u00b7) are discussed. The conditions in Assumption 3.4 are highlighted, showing that they hold for commonly used functions in f -divergence. The bound (3.2) is shown to hold under Assumptions 3.1, 3.3, and 3.4. The focus is on multi-sample elicitation with ground truth samples in this section. The mechanism designer obtains ground truth samples for evaluation. Algorithm 1 computes a function to pay the agent based on estimated divergence between reported and true samples. The f-scoring mechanism achieves properness and pays reported samples using constants a and b. The proof relies on error bounds in estimating f-divergence. The mechanism designer uses Algorithm 1 to pay agents based on divergence between reported and true samples. To address caveats, single point elicitation without verification is considered with 2n agents holding samples x i \u223c P i 4, divided into two groups with joint distributions P and Q. The mechanism designer uses Algorithm 1 to pay agents based on divergence between reported and true samples. Two groups of n agents are required to report their single data point according to distributions P and Q. This setup is similar to a Generative Adversarial Network (GAN). The joint distribution of p and q is denoted as p \u2295 q, and the product of the marginal distribution as p \u00d7 q. The divergence between the two distributions is considered, leading to the definition of generalized f-mutual information and f-divergence. The generalized f-mutual information between distributions p and q is defined, along with estimators for empirical distributions. Algorithm 2 is presented for estimating f-divergence and paying agents based on reported samples. The f-scoring mechanism in Algorithm 2 achieves certain results. The f-scoring mechanism in Algorithm 2 achieves (2\u03b4(n), 2b\u03f5(n))-BNE by establishing error bounds in estimating f-divergence. As the number of samples grows, \u03b4(n) and \u03f5(n) decrease polynomially fast, approaching strict approximate incentive-compatibility. The method handles complex information from high dimensional continuous spaces without requiring prior knowledge. Our framework covers cases where the mechanism designer has no access to ground truth, contributing to peer prediction literature by handling complex information structures. An estimator of f-divergence is introduced, establishing the statistical rate of convergence for estimating f-divergence between distributions P and Q with probability density functions p and q. The rate of convergence can be extended to mutual information estimation. Estimating f-divergence between distributions P and Q is equivalent to solving an optimization problem. A deep neural network approach is proposed to approximate the solution, with sparsity achieved through techniques like dropout or specific network architectures. The family of sparse networks is defined with sparsity parameter s. Estimators are proposed with a theorem characterizing their convergence rate. The estimators achieve optimal nonparametric convergence rate. Learning a representative probability density function from samples is discussed. Learning the probability density function p from samples involves solving for Q in the probability density function space. The formulation of f-GAN connects to this process, where q(\u00b7) is the generator and t(\u00b7) is the discriminator. The f-divergence Df(q\u2225p) characterizes the deviation of q from p. The covering number of the probability density function space Q is defined, with q* = p being the unique minimizer of the problem. The f-divergence Df(q\u2225p) quantifies the difference between q and p. The error bound for estimating q* by q is characterized in Theorem 5.3, where the generalization error and approximation error are discussed. If the approximation error vanishes, q converges to the true density function q* = p optimally. Sample elicitation is introduced as an alternative to complex distribution elicitation, utilizing f-divergence functions for accurate estimation. The text discusses the use of f-divergence functions for accurate estimation of divergences using samples, with theoretical guarantees on estimators and incentive compatibility. It aims to find more efficient mechanisms for sample elicitation with strict truthfulness. The proof and results are deferred to specific sections for further details. The text discusses using the norm of parameters to control error bounds in neural networks. The optimization problem is formulated to derive error bounds on estimated f-divergence. Theorem A.3 states that for any \u03b5 > 0, with probability at least 1 - \u03b5, the error bound holds. The text discusses error bounds in neural networks using parameter norms. Theorem A.4 provides bounds on estimated f-divergence with probability at least 1 - \u03b5. The proof is deferred to Section B.7. The text discusses error bounds in neural networks using parameter norms. The expected payment per sample i is derived with probability at least 1 \u2212 \u03b4(n). Misreporting according to a distribution p will lead to a derivation with probability at least 1 \u2212 \u03b4. Truthful reporting leads to a divergence term difference of at most 2\u03f5(n) with probability at least 1 \u2212 2\u03b4(n), establishing a (2\u03b4(n), 2b\u03f5(n))-BNE. The text then proceeds to bound \u2225t * \u2212 t\u2225 L2(P) by finding t \u2208 \u03a6 M (L, k, s). The text discusses error bounds in neural networks using parameter norms. It proceeds to bound \u2225t * \u2212 t\u2225 L2(P) by finding t \u2208 \u03a6 M (L, k, s) with certain parameters. The ground truth t * lies on a finite support, and with m \u2032 = log n, Theorem D.5 is utilized to construct some t. By invoking Theorem A.1, it is shown that with probability at least 1 \u2212 \u03b5 \u00b7 exp(\u2212\u03b3 2), certain conditions hold. Additionally, A 1 and A 2 are bounded with probability at least 1 \u2212 exp{\u2212n d/(2\u03b2+d) log 5 n}. The proof of the theorem involves bounding the max deviation of the estimated function. A lemma provides a bound under certain assumptions, stating that with a sufficiently large sample size, the bound holds with high probability. The proof also involves finding the optimal q among all q \u2208 Q, with a high probability guarantee. The proof of Theorem A.1 involves establishing lemmas to bound the deviation of the estimated function. It includes finding the optimal q among all q \u2208 Q with a high probability guarantee. The proof concludes by combining inequalities and establishing bounds on the right-hand side. The proof of Theorem A.1 involves establishing lemmas to bound the deviation of the estimated function. By using the Lipschitz property of f \u2020, we can derive a bound with high probability. The error bound holds for any t \u2208 \u03a6 M. The proof of Theorem A.1 involves linking generalization error to empirical Rademacher complexity (ERC) using Lemma B.4. The ERC is defined for class L(\u03a6 norm) with i.i.d. Rademacher random variables. Lemma B.4 establishes a bound on generalization error for any \u03b5 > 0 under the condition sup \u03c6\u2208\u03a6norm |L(\u03c6)| \u2264 M1. The proof of Theorem A.1 connects generalization error to empirical Rademacher complexity (ERC) using Lemma B.4. The lemma provides a bound on generalization error for any \u03b5 > 0 under the condition sup \u03c6\u2208\u03a6norm |L(\u03c6)| \u2264 M1. Additionally, Lemma B.5 bounds the ERC for Lipschitz continuous loss functions and bounded inputs. The theorem is then proven by establishing relationships between minimizers and loss functions within the defined network family. The proof of the theorem connects generalization error to empirical Rademacher complexity using Lemmas B.4 and B.5. By bounding the max deviation of the estimated f-divergence among all q in Q, the theorem is proven with probability at least 1 - \u03b5. The proof of the theorem connects generalization error to empirical Rademacher complexity using Lemmas B.4 and B.5. By bounding the max deviation of the estimated f-divergence among all q in Q, the theorem is proven with probability at least 1 - \u03b5. The proof involves Lemma B.1 and the peeling device to establish the conclusion. The proof of Lemma B.5 utilizes Lemmas C.1 and C.2 to characterize the Lipschitz property of \u03c6(x; W, v) in the input x and network parameter pair (W, v). The proof involves invoking Theorem D.3 and combining equations (C.6) and (C.8) to finish the lemma proof. The proof of Lemma B.6 involves deriving the covering number of Q and utilizing the Lipschitz property and bounded spectral norm of W j recursively. The proof concludes by applying the union bound and Theorem A.3. The proof of Lemma C.2 involves bounding the spectral norm of W j recursively and utilizing the 1-Lipschitz property of \u03c3 vj (\u00b7). This is done by applying the triangle inequality and previous arguments recursively. Lemma D.1 proves statements regarding entropy. It states that for a given distribution Q and a set G with bounded norms, certain inequalities hold."
}