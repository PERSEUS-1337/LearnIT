{
    "title": "ByftGnR9KX",
    "content": "Conversational machine comprehension is enhanced by Flow, a mechanism that incorporates intermediate representations during the process of answering previous questions. FlowQA, the model utilizing Flow, outperforms traditional models on conversational challenges like CoQA and QuAC. Additionally, FlowQA shows improved performance on tasks like sequential instruction understanding in SCONE. The young girl and her dog ventured into the dark and cold woods, despite her fear. Conversational machine comprehension datasets like BID20 and BID3 aim to assist in information-seeking dialogs by incorporating question/answer pairs with conversation history. Existing approaches enhance models with Flow, improving performance on challenges like CoQA and QuAC. FLOWQA is a conversational machine comprehension model that incorporates the entire hidden representations generated during the process of answering previous questions, providing additional clues for the current conversation. This mechanism effectively tracks world states for sequential instruction. The FLOW mechanism in FLOWQA effectively tracks world states for sequential instruction understanding by interpreting a sequence of interconnected instructions and generating corresponding world state changes as answers. The mechanism stacks single-turn QA models along the dialog progression, allowing rich information flow in the reasoning process. The design is similar to recurrent neural networks, with each update unit representing an entire question answering process. FLOWQA introduces an alternating parallel processing structure to speed up training significantly, achieving strong results on conversational machine comprehension tasks. It also outperforms existing systems on understanding a sequence of natural language instructions. The code can be found at https://github.com/momohuang/FlowQA. In this section, the task formulations of machine comprehension in single-turn and conversational settings are introduced. The main ideas of state-of-the-art MC models are discussed, where the task is to find the answer to a question based on an evidence document (context). In the extractive setting, the answer must be a span in the context. Conversational machine comprehension involves answering multiple, potentially inter-dependent questions in sequence, where the current question's meaning may depend on the conversation history provided as input. For single-turn machine comprehension, top-performing models consist of question encoding, context encoding, reasoning, and answer prediction components. Word embeddings of question and context tokens are inputted and processed through integration layers like LSTMs or self attentions to generate query-aware hidden vectors for context words, facilitating implicit reasoning for answer extraction. Our model, FLOWQA, aims to incorporate conversation history more comprehensively through a FLOW mechanism. It introduces the concept of FLOW, proposes INTEGRATION-FLOW layers, and presents an end-to-end architecture for conversational machine comprehension. Successful conversational MC models should understand how the conversation flows. FLOWQA aims to grasp conversation flow by understanding the main topic, relevant events, and facts. The model considers FLOW as a sequence of latent representations based on context tokens. Depending on the topic, the answer to a question may vary significantly. For example, the answer to \"What did he feel?\" changes from \"lonely\" to \"we saved each other\" as the conversation topic shifts. The FLOWQA model integrates hidden vectors from each integration layer for question turns and context words, improving efficiency during training. An INTEGRATION-FLOW (IF) layer is composed of a context integration layer and a FLOW component, processing questions in parallel during training. The FLOWQA model reshapes context sequences for question turns and processes them using a GRU. The outputs are then concatenated for further contextualization to predict answer span tokens. Removing the FLOW component turns the IF layer into a regular context integration layer. The FLOWQA model is based on a single-turn MC structure and uses BiLSTM for context integration. It incorporates pretrained embeddings like GloVe, CoVE, and ELMo. Attention is computed at the word level to enhance context word embeddings with the question. The FLOWQA model utilizes BiLSTM for context integration and incorporates pretrained embeddings like GloVe, CoVE, and ELMo. It generates question-specific context input representations denoted as C0i and integrates questions with QHierRNN using hierarchical LSTM encoding. Pointer vectors are built for each question for answer prediction, and fully-aware attention is used for reasoning with IF layers on top of context encoding. The FLOWQA model utilizes BiLSTM for context integration and incorporates pretrained embeddings like GloVe, CoVE, and ELMo. It generates question-specific context input representations denoted as C0i and integrates questions with QHierRNN using hierarchical LSTM encoding. Pointer vectors are built for each question for answer prediction, and fully-aware attention is used for reasoning with IF layers on top of context encoding. The model uses fully-aware attention BID10 for computing attention scores between context and question, with details of each layer provided. FLOWQA model utilizes BiLSTM for context integration and pretrained embeddings like GloVe, CoVE, and ELMo. It generates question-specific context input representations and integrates questions using hierarchical LSTM encoding. Pointer vectors are built for answer prediction, and fully-aware attention is used for reasoning with IF layers on top of context encoding. The model computes attention scores between context and question with fully-aware attention. In the evaluation section, FLOWQA is tested on QuAC and CoQA datasets, which both follow a conversational setting. QuAC asks for highlighted answer spans, while CoQA asks for free text answers. The model's extractive approach can handle Yes/No answers effectively. The extractive approach of BID31 demonstrates a high upper-bound of 97.8% F1 for handling Yes/No answers. This approach is applied to CoQA by computing probabilities for answering yes and no, and finding answer spans in the context for other questions. Evaluation metrics include F1 for different context domains in CoQA and original metrics like F1 and Human Equivalence Score (HEQ) for QuAC. HEQ-Q measures question accuracy based on model performance compared to human scores. Comparison Systems: FLOWQA is compared with baseline models like PGNet, DrQA, and BiDAF++ on CoQA and QuAC datasets. Different approaches are used to address abstractive answers and incorporate dialog history. FLOWQA appends a binary feature similar to BiDAF++ to improve performance. Yatskar FLOWQA (N -Ans) model improves performance by appending binary feature vector encoding previous answer spans to context embeddings. Ablated systems include \"-FLOW\" and \"-QHIER-RNN\" components. Results show substantial improvement on CoQA and QuAC datasets. FLOWQA captures long-range conversation history effectively, with contributions from QHierRNN, FLOW, and N -Ans components. The FLOW component is crucial for performance improvement in the FLOWQA model, with a substantial drop in performance when removed. Providing gold answers is more crucial for the QuAC dataset compared to CoQA. The model leverages the entire conversation history, allowing for better understanding of follow-up questions. The FLOW component is essential for performance in the FLOWQA model, with a significant drop in performance when removed. The selected answer span is important, and the speedup of the proposed parallel processing structure is measured. The speedup is 8.1x on CoQA and 4.2x on QuAC, with CoQA showing a higher speedup due to longer dialog sequences. The task involves understanding a sequence of natural language instructions, reduced to a conversational MC task using FLOWQA. The task involves understanding a sequence of natural language instructions by modifying the world state accordingly. This is achieved by encoding the current world state as context, treating each instruction as a question, and encoding the world state change as the answer. The model outputs the answer at each time step, mapping it to the next world state based on reduction rules. The history of instructions is encoded by concatenating preceding questions. The model encodes the history of instructions by concatenating questions and marking previous answers. FLOWQA is simplified to prevent overfitting, with details in Appendix C.2. Gold answers are used during training, while predicted answers are used at test time. Evaluation is done on the SCONE BID15 dataset with three domains (SCENE, TANGRAMS, ALCHEMY). Comparison is made with prior works BID15 BID8, semantic parsers that update the world based on logical forms. The model, FLOWQA-FLOW, updates the world state based on logical forms and achieves comparable results in Tangrams and Alchemy domains. When augmented with FLOW, it outperforms state-of-the-art models in all three domains. Sequential question answering in knowledge base settings has been studied, framed as a semantic parsing problem. Recent datasets have been used for evaluation. Sequential question answering in knowledge base settings, such as semantic parsing problems, has been studied using recent datasets. Existing approaches have focused on single-turn models like BiDAF and DrQA, while a new architecture for multi-turn tasks using the FLOW design is proposed. Dialog response generation requires reasoning about conversation history, which has been explored in social chit-chats and goal-oriented dialogs. The main challenge lies in reasoning with the knowledge base or conversation history. The main focus of our work is on conversational machine comprehension, specifically on reasoning about context based on conversation history. We introduced a novel FLOW component that enhances the encoding of conversation history in machine comprehension models, resulting in improved performance. Our model, FLOWQA, outperforms existing models on conversational challenge datasets and sequential instruction understanding tasks. While our approach shows significant performance gains, there is still room for further improvement in modeling conversation flow and enabling more natural conversational behaviors in machines. The FLOW operation enhances machine comprehension models by improving the encoding of conversation history. It involves a big memory operation on a matrix, visualizing changes in memory over time to guess the current conversation topic. This visualization is not attention but shows how hidden memory evolves during the conversation. The example from CoQA BID20 demonstrates how hidden memory changes over time, not through attention but visualization. Sally had an exciting summer vacation, making friends at summer camp and enjoying activities like walking in the woods and canoeing. She also visited the beach with her family, collecting shells to make arts and crafts with her friend Tina. Sally had an exciting summer vacation, making friends at summer camp and enjoying activities like walking in the woods and canoeing. She also visited the beach with her family, collecting shells to make arts and crafts with her friend Tina. Sally had a fun summer vacation, going to summer camp for the first time where she made a new friend named Tina. They enjoyed activities like walking in the woods, making art with leaves, and canoeing. Sally also visited the beach with her family and collected shells to make arts and crafts with Tina. Sally had an exciting summer vacation, going to summer camp for the first time where she made a new friend named Tina. They enjoyed activities like walking in the woods, making art with leaves, and canoeing. Sally also visited the beach with her family, collecting shells to make arts and crafts with Tina. Sally had a fun summer vacation, going to camp for the first time where she made a new friend named Tina. They enjoyed activities like walking in the woods and canoeing. Sally also visited the beach with her family, collecting shells to make arts and crafts with Tina. Sally had an exciting summer vacation, enjoying activities like walking in the woods, canoeing, and visiting the beach with her family. She collected shells to make arts and crafts with her friend Tina. She also liked fishing, cooking on the grill, and swimming in the ocean. Sally was eager to go back to school to share her summer adventures with her friends and teachers. Sally had an exciting summer vacation, going to summer camp for the first time where she made a new friend named Tina. They enjoyed activities like walking in the woods and making art with leaves. Sally also went to the beach with her family, collecting shells to send to Tina for arts and crafts. She enjoyed fishing, cooking on the grill, and swimming in the ocean. Sally was sad when camp ended but looked forward to going back to school to share her adventures. Sally had an exciting summer vacation, going to summer camp for the first time where she made a new friend named Tina. They enjoyed activities like walking in the woods and making art with leaves. Sally also went to the beach with her family, collecting shells to send to Tina for arts and crafts. She enjoyed fishing, cooking on the grill, and swimming in the ocean. Sally had a fun summer vacation with activities like fishing, cooking, and swimming. She was excited to go back to school and share her experiences with her friends and teachers. Memory regions changed significantly during conversations, with FLOW operation capturing the context at the start and focusing on specific topics later on. The trip to the beach and activities with Sally's family are highlighted in memory regions during conversations. Sally recalls going fishing, cooking on the grill, and swimming in the ocean with her family. Memory activity shifts with the conversation topics. Sally traveled far to be with her dying father, experiencing loneliness and sadness after his passing. After experiencing loneliness and sadness following her father's passing, Sally found a thin, abandoned cat outside her apartment. She brought the cat inside, fed him, and learned he had been left behind by his owner. Despite uncertainty, the cat quickly bonded with Sally, providing her with companionship. BiDAF++ struggles to understand topic shifts, unlike FLOWQA which can capture them effectively. Question-specific context input representation in FLOWQA includes word embeddings, binary indicators for context words in the question, and output from attention mechanisms. The answer span selection method in FLOWQA estimates start and end probabilities for context tokens in questions. To address unanswerable questions, the probability of having no answer is computed. Hyper-parameter settings include tokenization with spaCy, fine-tuning GloVe embeddings, and using RNN output sizes of 125. The attention hidden size in fully-aware attention is set to 250. During training, a dropout rate of 0.4 is used after the embedding layer and before any linear transformation. Variational dropout is applied when model parameters are shared. Dialogs are batched instead of individual questions, with a batch size of one for CoQA and three for QuAC. The optimizer is Adamax with a learning rate of 0.002. Models are implemented in PyTorch, with a maximum of 20 epochs for convergence. For the sequential instruction understanding task, simplifications were made to the FLOWQA model. This included using 100-dim GloVe embeddings instead of 300-dim, training embeddings for context tokens from scratch, removing word-level attention, and self-attention due to the short context. Hidden sizes were tuned independently for different domains, batch size was set to 8, and a dropout rate of 0.3 was used. In SCENE, TANGRAMS, and ALCHEMY, environments have specific characteristics and actions. SCENE has ten positions with various actions and properties, TANGRAMS has a list of shapes with different actions, and ALCHEMY has numbered beakers with unique actions and properties. The encoding of context from the world state involves representing each position with integers in SCENE. In TANGRAMS, there are five images with positions represented by integers and binary features indicating presence. Images can be removed and appended back. ALCHEMY has seven beakers with positions represented by color and units. An embedding layer converts integers into 10-dim vectors. In ALCHEMY, the embedding layer converts integers into 10-dim vectors to encode world state changes into four integers representing action type, context position, and additional property. Predictions are made through multi-class classification using a linear layer."
}