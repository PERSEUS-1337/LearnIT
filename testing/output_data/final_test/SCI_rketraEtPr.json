{
    "title": "rketraEtPr",
    "content": "Improving the accuracy of numerical methods is crucial for nonlinear simulation problems like fluid flow. This paper introduces a data-driven approach using a neural network to enhance the accuracy of numerical solvers. The method involves using a fine simulation resolution to acquire reference data and then employing the neural network to correct coarse results quickly. The approach is versatile and can be applied to various partial differential equations. The approach presented in this paper uses a neural network to improve the accuracy of numerical solvers, particularly for fluid flow simulations. Traditional methods focus on fine discretizations in space and time to enhance accuracy, but there is a need for better efficiency. The Navier-Stokes equations are commonly used in computational fluid dynamics for modeling fluid dynamics. Despite recent advances, there is still a need for better efficiency and accuracy in computer simulations. A data-driven approach is proposed to assist numerical methods in improving accuracy, particularly focusing on the time dimension in the context of fluids. Two variants are introduced: a supervised version with an optimization algorithm for acquiring temporally constrained correction data, and an unsupervised version with a differentiable PDE solver that autonomously considers temporal information during training. Experiments show that using these trained models improves simulation accuracy. Using trained models significantly improves simulation accuracy, yielding improved dynamics and allowing coarse simulations to closely replicate reference data. Data-driven approaches have been effective in inferring unknown PDEs and coefficients, with successful applications in various problems such as Navier-Stokes equations, advection diffusion problems, PDE formulations, and Poisson equations. In the context of fluid dynamics, data-driven approaches, including deep learning, have been utilized to improve solutions for complex and nonlinear problems. Turbulence modeling has been a key focus, with studies on steady and unsteady flows, multiphase flows, and airfoil flow using convolutional neural network (CNN) based methods. Data-driven approaches, including deep learning with generative adversarial models, have been used for efficient fluid simulation, particularly in computer graphics. Neural network models have been employed to transform space-time data into reduced latent spaces for re-simulating fluid simulations. Liquid droplets and scalar transport have also been efficiently tackled using stochastic models. Our aim is to enable the learning of general correction functions for challenging two-dimensional flow problems by considering temporal dynamics. Numerical methods approximate smooth functions with an error of O(h k), where h is the step size. Higher order methods are preferred but difficult to achieve in practice. Fluid motions are represented in our setting, and we propose a new approach for learning corrections. In our setting, fluid motions are represented by vector fields v(x) on Cartesian Eulerian grids with square cells. The accuracy of the fluid motion depends on the discretization error for v, which scales with the grid spacing h. Practical methods aim to keep h as large as possible to compute solutions quickly, as varying resolutions can lead to significant differences in solutions due to the nonlinear nature of flow equations and truncation errors of numerical schemes. In order to improve the accuracy of numerical methods on coarse grids, a correction function is proposed to compensate for discretization errors. A CNN is employed for its translation invariance, targeting time-dependent problems with per time step corrections. The focus is on finite difference approximations for smooth target functions represented by discrete physical quantities. The correction approach targets solutions of the Navier-Stokes equations for incompressible fluids, using fully convolutional networks to compute the correction function. Fine discretization is used to compute reference data, with the goal of finding an optimal approximation for the correction function. The correction approach aims to find an optimal approximation of the correction function for the reference data, focusing on the velocity v for fluids. The correction is applied additively to match the reference velocity v R as closely as possible, even if the reference has a different resolution. Transferring functions between different discretizations requires careful consideration. When transferring functions between different discretizations, care is needed, especially when considering additional constraints like conservation laws. An optimization approach is used to minimize the distance between representations on grids of different dimensionalities. The goal is to find the closest vector field in a finer space to a given vector field in a coarser space. Interpolation operators are used to introduce new data points within the vector field. The goal is to find the closest vector field in a finer space to a given vector field in a coarser space by introducing new data points. This involves a constrained optimization problem with equality constraints solved using Lagrange multipliers. The correction is inferred by minimizing the supervised loss for a pre-computed data set. The NN model is coupled with a differentiable PDE solver for recurrent training. The model unrolls multiple time steps to consider temporal information when learning. An extension is introduced to account for the temporal evolution of the correction function, targeting vector fields obtained from numerical simulations. The correction is acquired by running the simulation with a reduced step size in space and time to minimize approximation errors. The correction vector field is computed by running the simulation with a reduced step size in space and time to minimize errors. The correction function has a nonlinear relationship with the observable data, making it difficult to learn. Supervision in data is introduced to address this challenge. In order to address the challenge of learning the correction function in data acquisition for simulations, supervision is introduced through temporal regularization. This regularization ensures that correction vector fields change smoothly over time by penalizing temporal changes, allowing for accurate representation of spatial and temporal changes in the target function. Temporal regularization is introduced to ensure smooth changes in correction vector fields over time, minimizing error in inferred corrections. The regularization coefficient \u03b2 is set to 0 in experiments, proving effective for accuracy and training. This approach allows for the NN to learn corrections from low-resolution input simulations. Randomized initial smoke volume sizes lead to significant differences in simulations after 1,000 steps. The basic simulation and reference simulation show significant differences due to variations in initial volume. A training approach using recurrent observation of temporal dynamics allows a NN to learn correction functions unsupervised. This method reduces human intervention and improves model accuracy. The NN learns correction functions unsupervised by observing temporal dynamics, integrating a differentiable Navier-Stokes solver for analytic derivatives. This enables end-to-end training in recurrent settings, reducing human intervention and improving model accuracy. The unsupervised approach uses a differentiable Navier-Stokes solver for end-to-end training in recurrent settings, allowing for correction functions to be learned by observing temporal dynamics. This eliminates the need for explicit preparation of learnable input-output pairs. The model evaluates intermediate results using a differentiable solver and correction model. It compares these results with reference frames to update weights. Simulation sequences are used to generate input and correction velocity fields for training the neural network. An example involves hot smoke rising in an enclosed container. The model evaluates intermediate results using a differentiable solver and correction model to update weights based on reference frames. It simulates hot smoke rising in an enclosed container, comparing density fields between different methods and setups. Initial smoke volume sizes are randomized, showing significant differences in results even after short periods of time. Boussinesq model is used for simulation. The study uses a MacCormack scheme for basic simulation and an advection-reflection scheme for reference. The ground truth version is corrected by a full correction function. The model is trained using data from 20 simulations with 20,000 samples collected. Input features and correction vector fields are extracted from each simulation. From each simulation, pairs of input features x L and a correction vector field v L are extracted using multiple channels. Nine channels, consisting of velocity and density fields, give the best results. The data is split into a 95% training set and a 5% validation set. Network model A is used for training with 200 epochs and a batch size of 32. The L sup loss and Adam optimizer are utilized. The model is tested on two simulations not in the training set, producing results closer to the ground truth than basic simulation. Our model shows close results to the ground truth compared to basic simulation. Errors accumulate over time, becoming more apparent in later frames. Despite the nonlinear simulation steps, the correction field moves the solution close to the desired state. Average errors in density and velocity fields are depicted in Fig. 4, showing that our supervised model corrects simulations well. Errors remain close to ground truth values, deviating slightly after 400 simulation steps. The proposed optimization approach for computing the correction function is evaluated, with a naive downsampling of the reference correction to the target domain yielding results. The correction function is downsampled to the target domain, producing comparable results for rising smoke. A regularized and \"naive\" correction function are applied directly, showing almost identical results. Training with the \"naive\" NN model leads to higher errors and unusable function approximation. Inference errors quickly arise without optimization steps. The correction function, when trained with a \"naive\" NN model, leads to unusable function approximation due to inference errors. In contrast, the temporal regularization in our approach allows for accurate representation of the correction function with a CNN. This method generalizes to other fluid flow problems and emphasizes the importance of smooth changes in the correction field for successful learning. Our unsupervised learning approach addresses the need for manual input in making the correction function suitable for learning. The evaluation of the trained model with 48 recurrent steps successfully removes the majority of errors in the simulation, as shown in Fig. 6. The model utilizes semi-Lagrangian advection and reference data generated from 100 steps with 20 randomized initial sizes of the smoke volume. The NN model sees a larger amount of samples due to intermediate output states from recurrent iterations. The model with 48 recurrent steps significantly reduces errors in the simulation, improving long-term accuracy. It performs well in complex settings and shows corrected results with relative errors. The unsupervised model learns quickly within the first 300 steps. The unsupervised model quickly learns accurate corrections within the first 300 steps, outperforming the precomputed supervised version. However, gains diminish in very long sequences, suggesting the need for more training steps to anticipate long-term changes. The approach results in improved performance of trained models, with correction velocity fields inferred on a low-resolution grid at a fixed O(n) cost for each solving step. The unsupervised model quickly learns accurate corrections within the first 300 steps, outperforming the precomputed supervised version. However, gains diminish in long sequences, suggesting the need for more training steps. The approach improves trained model performance by learning correction functions to assist numerical solvers at a fixed O(n) cost. Training times are longer due to evaluating complex numerical procedures, but using larger timestep sizes could help the model learn corrections for longer horizons. The novel approach improves numerical methods by learning correction functions to enhance solution accuracy, emphasizing the importance of temporal information. An optimization step ensures accurate learning of correction sequences by a NN model, benefiting previously unseen PDE solves. Unsupervised training with a differentiable solver can further enhance corrections for longer time spans. The approach, initially tested on fluids, can be extended to various domains with spatio-temporal problems. Two network models used in experiments are detailed in Fig. 9. The models A and B, with 405K and 265K training parameters, are implemented using TensorFlow. Comparing models with different input channels, the model trained with three subsequent states performs slightly better. Extending the method to fluid simulations, a liquid stream over a backward facing step with a second step on the right side is introduced. Height and width of steps are randomized for data generation. The study demonstrates the use of a method for fluid simulations, showcasing vortex structures in the flow. The simulations use the APIC method without surface tension but with a gravitational force and fixed inflow velocity. The grid resolution for the simulations is 32\u00d716, with a reference grid four times finer. The study uses the APIC method for fluid simulations without surface tension but with a gravitational force and fixed inflow velocity. The grid resolution is 32\u00d716, with a reference grid four times finer. The network model B is trained with data from ten simulations, showing improvements in resolving rotating motions behind step geometries. The model successfully reintroduces lost vortices and improves vortex shapes. Performance gains are illustrated with timings measured on an Intel Xeon E5-1620 3.70 GHz processor with 128 GB memory. The trained neural network models were evaluated using CUDA support and TensorFlow on an NVIDIA GeForce GTX 960 GPU with 4 GB video memory. The reference simulation had four times higher resolution and used an optimized CPU-based solver."
}