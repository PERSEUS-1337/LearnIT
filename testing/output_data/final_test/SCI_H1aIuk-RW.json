{
    "title": "H1aIuk-RW",
    "content": "Convolutional neural networks (CNNs) are commonly used for recognition and learning tasks by training on a large dataset of supervised examples. However, collecting labeled images is expensive, so active learning methods are being explored to select images for labeling from a large collection. The study explores the ineffectiveness of active learning heuristics for CNNs in batch settings. It introduces core-set selection as a solution, selecting a subset of points that yield competitive results for the remaining data. The method outperforms existing approaches in image classification experiments. Deep convolutional neural networks (CNNs) require a large amount of labeled data to learn their parameters. Active learning aims to optimize data labeling for higher accuracy within a fixed budget, addressing the challenge of collecting more data efficiently. Active learning aims to maximize accuracy within a fixed labeling budget by choosing data points to label effectively. Many heuristics have been proven effective in practice, but they are not as successful when applied to CNNs due to correlation caused by batch acquisition. Active learning for CNNs involves batch sampling to overcome limitations of selecting single points at each iteration. This is done through core-set selection, aiming to find a small subset from a large labeled dataset without using labels, ensuring competitiveness of the model over the entire dataset. Active learning for CNNs involves batch sampling through core-set selection without using labels. A rigorous bound is provided between average loss over a subset of the dataset and the remaining data points. The algorithm minimizes this bound, equivalent to the k-Center problem, with empirical analysis showing state-of-the-art performance in image classification. Our work defines active learning as core-set selection for CNNs, considering both fully supervised and weakly supervised cases. Existing approaches include acquisition functions like information theoretical methods, ensemble approaches, and uncertainty-based methods. Bayesian active learning methods using Gaussian processes are not directly applicable to large CNNs. A recent approach by BID10 equates dropout with approximate Bayesian inference, allowing Bayesian methods in deep learning. Bayesian active learning is effective for small datasets but not scalable to large datasets due to batch sampling. Uncertainty-based methods like highest entropy and geometric distance are not effective for CNNs. Optimization-based approaches can balance uncertainty and diversity in batch mode active learning. BID8 and BID49 use discrete optimization, while BID18 frames the problem as matrix partitioning. BID18 addresses matrix partitioning, but its optimization algorithms are not scalable to large datasets due to the high number of variables used. Various pool-based active learning algorithms exist for specific machine learning algorithms. Our algorithm, similar to BID26 and BID44, filters the pool based on diversity without using uncertainty information, and is the first applied to CNNs. In comparison to BID26 and BID44, our algorithm for CNNs focuses on core-set loss optimization. BID26 lacks theoretical justification, while BID44 minimizes the difference between distributions. Our approach differs from BID1, which is limited to k-NN algorithms. Additionally, BID43 and BID40 have introduced active learning algorithms for CNNs. The algorithm proposed in BID40 focuses on recognizing CAPTCHA images through active learning. However, it is not effective for general image classification. Theoretical results show limitations of greedy active learning in algorithm and data agnostic cases, but data-dependent strategies can improve sample complexity. Active learning in a batch setting can also be achieved using the greedy algorithm with importance sampling. Core-Set Selection is a problem related to active learning, aiming to select a subset of a fully labeled dataset for model training. While existing algorithms like core-sets for SVM and k-Means exist, there is a gap for CNNs. A similar algorithm to the proposed one is the unsupervised subset selection algorithm, which uses a facility location problem. The new algorithm differs in its approach. Our algorithm uses a minimax formulation of the facility location problem for diverse dataset cover. It is applied for the first time to active learning with theoretical guarantees for CNNs. The paper is also related to weakly-supervised deep learning, experimenting with ladder networks and adversarial methods for feature learning. Our method is agnostic to the weakly-supervised learning algorithm choice. In this section, the problem of active learning in the batch setting is formally defined. The classification problem is defined over a compact space X and a label space Y = {1, . . . , C}. A loss function is parametrized over the hypothesis class, and class-specific regression functions are considered to be Lipschitz continuous. The active learning algorithm only has access to a subset of data points and their corresponding labels from an initial pool chosen uniformly at random. The active learning problem in the batch setting is formally defined as having a budget of queries to ask an oracle to minimize future expected loss. This formulation considers multiple rounds with a myopic approach, solving for the single round of labeling. In active learning, the algorithm has two stages: selecting data-points to label and training a classifier. Training can be fully or weakly supervised. While existing literature focuses on fully-supervised models, we consider both cases. The classical active learning setting acquires labels one by one, but this is not feasible for training CNNs. In active learning, the algorithm selects data points to label and trains a classifier. Training can be fully or weakly supervised. Existing literature focuses on fully-supervised models, but we consider both cases. Querying an oracle for each point is not feasible for training CNNs due to local optimization algorithms and large-scale problems. Instead, we focus on batch active learning, where a set of points is labeled at each iteration. The goal is to design an effective active learning strategy by considering the population risk of the model learned using a small labeled subset. The population risk in active learning is controlled by the training error on a small labeled subset, generalization error over the full dataset, and the core-set loss. CNNs have low training error and good generalization, with core-set loss being critical for active learning. The active learning problem is re-defined based on this observation. The active learning problem is re-defined based on the observation that CNNs have low training error and good generalization, with core-set loss being critical. If a set of selected points is the \u03b4 s cover of the dataset, the goal is to find a set of points to query labels such that the model's performance on the labeled subset and the whole dataset is as close as possible. An upper bound for the optimization objective is provided, considering loss functions that are Lipschitz and satisfy certain properties. Theorem 1 states that with certain assumptions and properties satisfied, the core-set loss is equal to the average error over the entire dataset. This theorem provides an upper bound for the optimization objective in active learning, considering Lipschitz loss functions. The theorem suggests that the core-set loss can be bounded by the covering radius and a term that decreases with n, independent of the number of labeled points. This bound applies to CNNs, with the loss function being Lipschitz-continuous with respect to input images. CNNs typically use cross-entropy loss for classification problems. Theoretical study shows the loss function for CNNs is Lipschitz-continuous with respect to input images. The algorithm is effective for cross-entropy loss in experiments. Loss function defined as 2-norm between class probabilities and softmax output of CNN. The loss function for CNNs is Lipschitz-continuous with respect to input images, and minimizing it is equivalent to the k-Center problem. This problem involves choosing center points to minimize the largest distance between a data point and its nearest center. The k-Center problem involves minimizing the largest distance between a data point and its nearest center. It is NP-Hard, but a greedy algorithm can efficiently provide a 2 \u2212 OP T solution. Iteratively querying upper bounds can further improve the solution by determining if OP T \u2264 \u03b4 using a mixed integer program. The k-Center problem can be optimized using a mixed integer program (MIP) as a sub-routine. A binary search is performed between the result of the greedy algorithm and its half to find the optimal solution within that range. The MIP also addresses the weakness of the k-Center algorithm by allowing an upper limit on outliers. The program is formulated with binary variables and can choose not to cover a certain number of unsupervised data points. In this solution, the 4th node is chosen as a center and nodes 0, 1, 3 are in a \u03b4 ball around it. The distance metric used is the l2 distance between activations of the final fully-connected layer. Ladder networks and VGG-16 are used for weakly-supervised learning, with models optimized using RMSProp. Gurobi framework is used for checking feasibility of the MIP, with an upper bound on outliers set at \u039e = 1e\u22124 \u00d7 n. We tested our algorithm on classification tasks using three datasets: CIFAR BID28, Caltech-256 BID16, and SVHN BID33. CIFAR BID28 has tasks over 10 and 100 classes. Our method was compared with random labeling, best empirical uncertainty, and Deep Bayesian Active Learning (DBAL) baselines. Deep Bayesian Active Learning (DBAL) uses Monte Carlo dropout for improved uncertainty measures and compares acquisition functions like max-entropy, BALD, and Variation Ratios. The Best Oracle Uncertainty algorithm replaces uncertainty with label information for the entire dataset. Batch Mode Discriminative-Representative Active Learning (BMDR) minimizes MMD between dataset samples and actively chosen points. CEAL (BID43) is another active learning approach. CEAL BID43 is a weakly-supervised active learning method for CNNs. Experiments were conducted on active learning for fully-supervised and weakly-supervised models, starting with a small set of images sampled randomly from the dataset. The weakly-supervised model has access to labeled and unlabeled examples, while the fully-supervised model only has access to labeled data points. The query algorithm is run iteratively to optimize the number of labeled points for classification accuracy. CEAL BID43 is a weakly-supervised active learning method for CNNs, optimizing the number of labeled points for classification accuracy. Results show the algorithm outperforms baselines, especially in weakly-supervised models due to better feature learning. Performance varies across datasets, with the algorithm being less effective in CIFAR-100 and Caltech-256 compared to CIFAR-10 and SVHN. The core-set loss scales with the number of classes, suggesting fewer classes are better. A state-of-the-art batch mode active learning baseline (BMDR BID44) may not outperform greedy methods due to uncertainty information. Our method does not use uncertainty, but incorporating it in a principled way is a future research direction. Pure clustering-based batch active learning (k-Medoids) is also ineffective as it fails to sample the tails of the data distribution. Oracle uncertainty information and Bayesian estimation are suggested for improvement. Our results suggest that oracle uncertainty information and Bayesian estimation improve over empirical uncertainty but are not effective in the batch setting where random sampling outperforms them. The correlation in queried labels in batch active learning affects the performance. Qualitative analysis using tSNE BID30 embeddings confirms that uncertainty-based methods fail to cover a large portion of the space due to sample correlation. Our proposed method utilizes a greedy 2-OPT solution for the k-Center problem as an initialization. Our algorithm for the k-Center problem uses a greedy 2-OPT solution as an initialization and improves accuracy compared to the uncertainty oracle method. The utility of solving the expensive MIP should be further investigated, along with comparing run-time and accuracy with other solutions. Our algorithm for the k-Center problem uses a greedy 2-OPT solution as an initialization and improves accuracy compared to the uncertainty oracle method. The MIP runtime is practical for datasets of 50k images, making our algorithm easily applicable in practice. Using the optimal solver is preferred over the 2-OPT solution, which shows a small drop in accuracy. Our active learning strategy with the 2-OPT solution still outperforms other baselines, demonstrating scalability to any dataset size with minimal accuracy loss. Our algorithm for the k-Center problem uses a greedy 2-OPT solution as an initialization and improves accuracy compared to the uncertainty oracle method. The MIP runtime is practical for datasets of 50k images, making our algorithm easily applicable in practice. Re-formulating the active learning problem as core-set selection for CNNs, we validated our algorithm with an extensive empirical study, showing state-of-the-art performance on three datasets. A proof for Lemma 1 demonstrates the optimal solution for the softmax function over C classes. The proof for Theorem 1 involves the Lipschitz constant of the soft-max layer and a claim from a previous study. It discusses the relationship between ReLU and max-pool layers in convolutional networks."
}