{
    "title": "HkxMG209K7",
    "content": "In this paper, the authors propose building an alarm system to detect unsatisfactory segmentation results. They suggest projecting the results into a low dimensional feature space and using shape features to predict segmentation quality. The shape feature is obtained by testing the segmentation result with a Variational Auto-Encoder trained on ground truth masks. The authors propose an alarm system to detect poor segmentation results by using a Variational Auto-Encoder trained on ground truth masks. The VAE can detect abnormal shapes in segmentation results, allowing for reliable prediction of segmentation quality across different algorithms and datasets. Increasing the number of training data is a common approach to address rare events in segmentation algorithms, but collecting labeled data is challenging. Various methods have been proposed to improve the use of training data, such as sampling strategies. Another direction is to enhance the algorithm's robustness to rare events, like using Bayesian neural networks to model uncertainty and make the algorithm more resilient to noisy data. To improve segmentation algorithms' robustness to rare events, an alarm system can be built to detect failures in the segmentation results. Quality assessment methods, such as using Bayesian neural networks to capture uncertainty, have been proposed. However, rare events can still cause mistakes in segmentation algorithms. Another effective approach is projecting segmentation results into a feature space and learning from them. By projecting segmentation results into a feature space and learning from it, heuristic features like size and intensity are used to indicate segmentation quality. A classifier is then trained on this feature space. In an NIH CT dataset for pancreas segmentation, the Dice score between GT and prediction is 47.06, while between prediction and Recon-Prediction is 47.25. The latter Dice score is used to predict the former real Dice score, which is often unknown in real applications. In real applications, uncertainty-based methods distribute different uncertainties mainly on the boundary of predicted masks, making it difficult to detect failure cases. By selecting more representative features like shape instead of size, it becomes easier to distinguish good segmentation results from bad ones. The key challenge lies in identifying these good features and capturing them effectively. The shape feature is crucial for judging segmentation quality, as bad results often have bad shapes. Using a Variational Auto-Encoder (VAE) to capture shape features from ground truth masks shows great potential in transfer learning and generalization. The loss function value in VAE network testing serves as a shape feature for segmentation results. It is optimized to approximate log P(Y) during training, allowing for prediction of segmentation quality. A VAE-based alarm system for segmentation algorithms was proposed in this paper to effectively predict segmentation result qualities. Our system effectively predicts segmentation results quality by testing on multiple algorithms trained on one dataset and tested on others. It outperforms other alarm systems, highlighting the importance of shape features and the power of VAE in capturing them. Previous works utilized Bayesian neural networks to model uncertainty in medical segmentation tasks. The BID5 method used Bayesian neural networks to model uncertainty in medical segmentation tasks. They calculated a doubt score based on pixel-wise uncertainty, showing that the algorithm is confident in its mistakes. Another method by Valindria et al. used registration for quality assessment, but it is inefficient and slow for 3D images. In our work, we learn a statistical prior of the segmentation mask to determine quality by how well a mask fits the prior, related to Out-of-Distribution (OOD) detection. Previous methods used softmax output in a classifier for OOD detection, but we take a different approach. In our work, we use a Variational Autoencoder (VAE) to learn shape representation from the volumetric mask for Out-of-Distribution (OOD) detection. Unlike previous methods that used softmax output in a classifier, VAE can be trained end-to-end without the need for pre-training with RBM. The text discusses using a Variational Autoencoder (VAE) to learn shape representation for Out-of-Distribution (OOD) detection. It focuses on defining a task formally, dividing datasets into training and validation sets, and finding a function to calculate the similarity of segmentation results without using validation data. The main question is how to design this function to extract valuable information from the segmentation result and input data. The text discusses using a Variational Autoencoder (VAE) for Out-of-Distribution (OOD) detection. It focuses on extracting valuable information from segmentation results and input data. In uncertainty-based methods BID5 and BID9, the uncertainty of output helps predict quality but relies heavily on the trained function F. The formulation is changed to DISPLAYFORM1 to incorporate constraints and still utilize information from F and X indirectly. The text proposes a two-step method using a Variational Autoencoder (VAE) to predict the quality of segmentation results. It involves encoding the segmentation result into a feature space and learning from it to estimate quality. The shape feature is captured from VAE trained with ground masks, defining the shape of segmentation masks as the distribution in volumetric form. The goal is to estimate the quality of predictive masks based on the distribution of the masks. The text discusses using a Variational Autoencoder (VAE) to estimate the quality of predictive masks by minimizing the Kullback-Leibler divergence. The goal is to optimize the variational lower bound of log P(Y) by minimizing the difference between Q(z|Y) and P(z|Y). The training process involves minimizing a function to fit log P(Y) using a Variational Autoencoder (VAE). The shape feature S(Y; \u03b8) is chosen as an approximation for log P(Y), with Dice Loss used during training. The final form of S includes terms controlled by \u03b8 and a coefficient \u03bb to balance them. The shape feature indicates that after training with normal shape data, the predictive mask tends to align with the distribution of normal shapes. The training process involves minimizing a function to fit log P(Y) using a Variational Autoencoder (VAE). The shape feature S(Y; \u03b8) is chosen as an approximation for log P(Y), with a linear regression model used to optimize the energy function. The parameter \u03b8 is learned during training and fixed in the next step. The training process involves using a linear regression model to optimize the energy function for segmentation results. A jackknifing training strategy is employed to overcome high quality segmentation algorithm issues. The training process involves using a linear regression model to optimize the energy function for segmentation results. A jackknifing training strategy is employed to overcome high quality segmentation algorithm issues. The optimizing function is then changed to minimize a certain formula to simulate the performance of F on the testing set. Our method achieves the highest accuracy and correlation in segmentation results evaluation without using ground truth. The BNN is trained on NIH and tested on other datasets, showing effectiveness with a two-fold split. Testing on various segmentation algorithms and data predicts the quality using a specific formula. The alarm system is tested on recent algorithms for automatic pancreas segmentation trained on a public medical dataset. Our system demonstrates reliable predictions for pancreas segmentation quality assessment and transferability across different datasets. Evaluation metrics include MAE, STD, P.C., and S.C. using 3 public medical datasets and 4 segmentation algorithms. The CT scans have resolutions of 512 \u00d7 512 \u00d7 h voxels with fully annotated pancreas regions. The NIH Pancreas-CT Dataset, Medical Segmentation Decathlon, and Multi-atlas Labeling Challenge provide CT scans for evaluating segmentation algorithms. The testing data for the last two datasets is not used in the experiment. Segmentation algorithms include V-Net, 3D Coarse2Fine, and Deeplabv3. The segmentation algorithms used in the study are V-Net BID11, 3D Coarse2Fine BID20, Deeplabv3, and 3D Coarse2Fine with Bayesian structure BID9. These algorithms are compared with three baseline methods, including one based on uncertainty and one using regression network on the prediction mask. BID5's method calculates pixel-wise predictive entropy using Bayesian inference and weighs it by the distance to predicted boundary to regress quality. The method presented in BID9 divides uncertainty into aleatoric and epistemic terms, calculating doubt scores similarly to BID5. A regression neural network is used to learn the quality of predictive masks, with training data from segmentation algorithm predictions and Dice's coefficient as supervision. Voxel size variations are addressed through pre-processing to ensure accurate segmentation predictions. During the segmentation process of the pancreas, CT scans and annotation masks are resampled to 1mm\u00d71mm\u00d71mm. A cube bounding box is used to crop and resize the pancreas region to 128\u00d7128\u00d7128 for training a VAE. Mild disturbances like rotation and translation are applied for data augmentation during training to enhance data distribution while maintaining alignment. The VAE model for segmentation training uses a latent space dimension of 128, with a hyperparameter \u03bb set to 2 \u22125 to balance Dice Loss and KL Divergence. Training is done with SGD optimizer and batch size 4, using TensorFlow on NVIDIA Tesla V100 GPU. The training process takes 5 hours over 20000 iterations. Data is split into four folds for training and validation, with experiments conducted on NIH, MSD, and MLC datasets. Our evaluation method uses training data from MSD and MLC for validation. We first train the VAE parameter using NIH dataset labels, then apply the BNN algorithm with a specific training strategy. Results show our method outperforms baseline models, with the BNN achieving high Dice scores on NIH, MSD, and MLC datasets. The BNN achieves high Dice scores on NIH, MSD, and MLC datasets. The segmentation algorithm trained on NIH may fail on other datasets, requiring an alarm system. Uncertainty-based methods can predict quality better, with stability in predicting quality on other datasets. Table 2 shows quality assessment results for different segmentation algorithms, with DeepLab algorithm accuracy lower on MLC dataset. The paper presents a VAE-based alarm system for segmentation algorithms that predicts segmentation quality without using ground truth. It emphasizes the importance of shape features in predicting segmentation quality and utilizes a VAE trained on ground truth masks to capture these features. By detecting out-of-distribution shapes based on loss function values, the system can improve segmentation results. Training on segmentation algorithm results and extracting shape features helps learn regression parameters for improved performance. The proposed method improves segmentation results by jackknifing training on the segmentation algorithm, obtaining more accurate regression parameters. The shape feature captured from VAE is proven to be meaningful and useful for quality assessment. It outperforms uncertainty-based and direct regression methods, with better transferability to other datasets and segmentation algorithms."
}