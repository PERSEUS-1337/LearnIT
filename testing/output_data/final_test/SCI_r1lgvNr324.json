{
    "title": "r1lgvNr324",
    "content": "The backpropagation algorithm is widely used for credit assignment in artificial neural networks. Variants like Feedback Alignment aim to improve the algorithm by changing functions in the equations. This study shows that these function changes are equivalent to adding an implicit learning rate, leading to early convergence in neural networks. Competitive performances were achieved on MNIST and CIFAR10 datasets. Performances with early convergence on MNIST and CIFAR10 datasets using large deep neural network architectures. Credit assignment BID10 involves identifying responsible neurons and weights for predictions, with backpropagation (BP) being the standard algorithm. Variants of BP, like Feedback Alignment BID5, use random weight matrices for credit assignment. Despite not scaling to ImageNet, Feedback Alignment offers a biologically plausible alternative to traditional backpropagation. In this work, the backpropagation algorithm is discussed, showing how function changes in the equations can be equivalent to adding an implicit learning rate in stochastic gradient descent. The algorithm iteratively computes gradients in a neural network using the derivative chain rule, and can be interpreted as a product of functions. The backpropagation algorithm computes gradients in a neural network using the derivative chain rule, represented as a product of functions. Lillicrap et al. proposed replacing certain terms in the backpropagation equation with b-functions to create a more biologically plausible credit assignment algorithm. This includes replacing the activation function derivative with a b-function, which can be beneficial in stochastic gradient optimization. Replacing the activation function derivative with the b-function can adjust the learning rate adaptively based on pre-activations. Gradient noise can be beneficial for optimization, but it's crucial for g(z l ) to equal 0 when \u03c3 (z l ) = 0 to avoid harming the gradient optimization process. Feedback alignment also involves using a random matrix B in the neural network. In an experiment comparing b-function changes in a neural network for a binary classification task, ReLU partial derivatives were replaced with derivatives from other activation functions in FC2. The network architecture was Input ->FC1 ->ReLU ->FC2 ->ReLU ->FC3 ->Softmax, with frozen weights except for FC2. Training was done using batch gradient descent on Adam with a learning rate of 0.1 for 100 epochs, using cross entropy loss function. FIG0 shows evidence of gradient information despite b-function changes. In an experiment comparing b-function changes in a neural network for a binary classification task, ReLU partial derivatives were replaced with derivatives from other activation functions in FC2. The aim is to demonstrate that learning an optimal b-function is analogous to learning an optimal learning rate. Bayesian optimization is used to learn these b-functions in the backpropagation procedure. In the experiment, Bayesian optimization is used with Gaussian process priors and Expected Improvement as the acquisition function for black-box optimization. The learning framework includes a target network, a meta-network to approximate a b-function, and an optimization component to learn b-functions for the target network. The black-box optimization problem is formulated with the weights of the meta-network serving as input. The goal is to minimize the cost function for the target network during training. The framework involves using Bayesian optimization with Gaussian process priors and Expected Improvement for black-box optimization. The evaluation is based on the area under the loss curve (AULC) when training the target network. The method was tested on CIFAR-10 using SimpleNet BID2 architecture, with results illustrated in FIG1. The approach allows for learning an implicit learning rate as a weight in the network via backpropagation. Function A outperforms backpropagation in terms of convergence time for CIFAR10 on SimpleNet using our proposed method. The meta-network architecture includes one input, hidden, and output neuron, with corresponding performances of the b-functions shown in FIG1."
}