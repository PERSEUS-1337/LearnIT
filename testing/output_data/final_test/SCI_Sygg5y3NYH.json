{
    "title": "Sygg5y3NYH",
    "content": "Variational Auto Encoders (VAE) can generate realistic images, sounds, and video sequences. A new approach incorporates past knowledge by learning the prior directly from the data, addressing the problem of sequential learning without revisiting all previous data. Empirical studies on MNIST and Fashion MNIST datasets show the proposed method outperforms comparable approaches in avoiding catastrophic forgetting in image generation tasks. Unsupervised learning is crucial for real-world datasets. In unsupervised learning, generative models like VAEs are crucial for obtaining samples from complex distributions. However, VAEs often produce blurred reconstructions due to issues with latent variables. Various approaches have been proposed to improve VAE performance, such as reducing amortization gap, annealing KL-term, and introducing alternative optimization objectives. The choice of prior distribution is critical, as the default Gaussian prior can overregularize the encoder. This work focuses on constructing an optimal prior for VAE to address these challenges. The optimal prior for VAE is constructed by maximizing a lower bound of the marginal likelihood through greedy KL-divergence projection. The method shows potential in incremental learning by storing information about previously learned tasks to avoid catastrophic forgetting. The algorithm proposed aims to have one model capable of solving multiple tasks sequentially. The algorithm proposed for VAE aims to update only the prior with one pair of encoder-decoder for sequential image generation tasks on MNIST and Fashion-MNIST datasets. It involves maximizing expected marginal log-likelihood through amortized inference and optimizing the prior distribution using variational and empirical bayes approaches. In the present paper, the VampPrior is discussed, addressing its drawbacks related to computational expense and choosing the appropriate number of components. A maxentropy variational inference framework is proposed to add components to the prior in a greedy manner, showing that fewer components are needed for comparable performance. In this work, a boosting algorithm for density distributions is combined with the VampPrior concept to address catastrophic forgetting in incremental learning. The proposed algorithm for training VAE involves optimizing the evidence lower bound with respect to the encoder parameters in two steps. The BooVAE algorithm optimizes the evidence lower bound in two stages: first by updating encoder and decoder parameters, and then by learning a new component for the prior distribution. This approach addresses catastrophic forgetting in incremental learning where subsets of data arrive sequentially. The BooVAE algorithm optimizes the evidence lower bound in two stages: updating encoder and decoder parameters, and learning a new component for the prior distribution. Regularization is added to ensure consistent encoding and decoding of prior components. Experiments are conducted on MNIST and fashion MNIST datasets for sequential learning tasks. Performance evaluation is done using negative log-likelihood on the test set with importance sampling method. BooVAE algorithm compares favorably to VampPrior and Mixture of Gaussians prior in overcoming catastrophic forgetting. Results show that BooVAE outperforms EWC regularization with standard normal prior in handling similar classes in the dataset. Detailed task-specific results are provided in Appendix D. In this work, a method for learning a data-driven prior using a MM algorithm is proposed, allowing a reduction in the number of components in the prior distribution without performance loss. An efficient algorithm for incremental VAE learning is suggested, with a single encoder-decoder pair for all tasks. Samples from the prior illustrate the generation ability of different methods after training on ten tasks sequentially, with detailed evaluation provided in Appendices E and F. Incremental VAE learning with a single encoder-decoder pair for all tasks reduces catastrophic forgetting. A regularization term is added to ELBO to maintain encoding and decoding of prior components. The objective is to approximate an optimal prior close to the mixture of variational posteriors at all training points. Trained prior is used as a proxy for previous task data. Optimal prior for tasks 1:t is expressed using prior from the previous step and current training dataset. During training, the optimal prior is approximated using a mixture of variational posteriors. To evaluate diversity of generated images, KL-divergence is calculated between Bernoulli distribution and empirical distribution of classes. A classification network is trained to label generated objects with high probability, aiming for diversity in generated images as tasks increase. The boosting approach generates diverse images by approximating the optimal prior, resulting in samples close to uniform compared to other methods."
}