{
    "title": "rJYFzMZC-",
    "content": "Neural Process Networks are introduced to understand procedural text by simulating action dynamics and tracking entities through action operators. The model can reason about implicit causal effects of actions, providing accurate contextual information and interpretable representations. Neural Process Networks introduce a procedural language understanding system that tracks common sense attributes through neural simulation of action dynamics, interpreting natural language instructions as a process of actions and their effects on entities. Neural Process Networks introduce a procedural language understanding system that tracks common sense attributes through neural simulation of action dynamics, interpreting natural language instructions as a process of actions and their cumulative effects on entities. The model attentively selects actions to execute on entities, remembers state changes with a recurrent memory structure, and abstracts away from surface strings to reason about attributes like \"SHAPE\" and \"CLEANLINESS\". This approach complements text-centric modeling of language by focusing on worldcentric modeling of procedural language. The model introduced in the curr_chunk learns explicit action representations as functional operators from text, focusing on explaining causal effects of actions by predicting natural language attributes. It adjusts its representations based on errors in predicting resultant state changes, allowing for modeling of action causality not readily available in existing simulation environments. The model introduced in the curr_chunk focuses on parametrizing explicit action embeddings to improve context representations for understanding natural language procedural text. It offers more interpretable internal representations and can reason about unstated causal effects of actions. Additionally, a new dataset with fine-grained annotations on state changes is included to encourage future research in this direction. The neural process network interprets natural language sentences by simulating actions on entities using learned representations. It includes a simulation module with action and entity embeddings, changing entity state information as it reads text. The neural process network simulates actions on entities using learned representations, changing entity state information as it reads text. Entity state embeddings are updated based on actions performed and entities affected in the sentence, predicting end states for state changes. The process involves five modules and utilizes parametrized linear projections and biases. The neural process network updates entity state embeddings based on actions performed in the sentence, using a soft attention mechanism to select relevant entities. The neural process network updates entity state embeddings with a soft attention mechanism to select relevant entities, considering entities mentioned in previous sentences. It uses a unique key for each entity and attention weights for entity embeddings. The model can choose affected entities from the current or previous step's attention distribution. Prior entity attentions can propagate forward for multiple steps. The neural process network updates entity state embeddings with a soft attention mechanism to select relevant entities. A unique key is used for each entity, and attention weights are applied to entity embeddings. The model can choose affected entities from the current or previous step's attention distribution, with prior entity attentions propagating forward for multiple steps. The entity memory receives attention weights, normalizes them, and computes a weighted average of relevant entity state embeddings. The applicator applies selected actions to selected entities, outputting new proposal entity embeddings. The entity updater interpolates entity representations after actions are simulated on them. The applicator simulates actions on entity embeddings, updating them based on attention weights. The entity updater interpolates new proposal entity embeddings and updates current entity embeddings. The state predictor predicts changes in entity embeddings along six dimensions. In this work, the model focuses on physical action verbs in cooking recipes, predicting end states for state changes along dimensions like LOCATION, COOKEDNESS, TEMPERATURE, SHAPE, CLEANLINESS, and COMPOSITION. Actions like cut and bake induce changes in these dimensions, which are annotated using Amazon Mechanical Turk. The neural process network is trained using a subset of the Now You're Cooking dataset, with crowdsourced workers annotating actions, entities, and state changes for training, development, and testing sets. Dense annotations are used for tuning hyperparameters and evaluation, with a focus on optimizing multiple losses for action selector, entity selector, and state change predictors. Weak supervision is employed due to the high cost of acquiring dense annotations at a large scale. The text discusses the training process of a neural process network using the Now You're Cooking dataset. It involves extracting verb mentions and entities from recipe steps, training an action selector and entity selector using cross-entropy loss, and minimizing the negative log-likelihood for state change prediction. Weak supervision is used due to the high cost of acquiring dense annotations at scale. The text introduces a coverage loss term penalizing narratives with attention weights not summing to 1 for entities mentioned. The model is evaluated on tracking entities and state changes in recipes, showing potential for recipe task dynamics simulation. Additionally, a qualitative analysis of the model's internal components is provided, along with evaluation of state quality for generating future steps. The model is evaluated on tracking entities and state changes in recipes, focusing on the quality of states encoded for generating future steps. Evaluation metrics include F1 score for entity selection, recall for combined and uncombined entities, and prediction accuracy for state changes in recipe steps. The study evaluates models on tracking entities and state changes in recipes, focusing on the quality of encoded states for future steps. Two baselines are compared, including a GRU model and a Recurrent Entity Network BID4 with modifications for the task. The models are trained with entity selection and memory cell utilization for predicting entities and state changes. The study evaluates models on tracking entities and state changes in recipes. Six ablations are reported, including removing recurrent attention, training without coverage penalty, pruning connections, not pretraining the action selector, and initializing action embeddings differently. The generation task tests the system's ability to produce the next step in a recipe based on previous steps. The model is evaluated on tracking entities and state changes in recipes. It generates the next step in a recipe based on previous steps. Metrics like BLEU score, ROUGE score, VF1, and SF1 are reported. The model inputs context sentences through a neural process network and extracts end states using a lexicon. The model evaluates entity state vectors in recipes by generating the next step based on previous steps. It involves steps like melting marshmallows, adding sprinkles, cereal, and raisins, spreading barbecue sauce, adding cheeses, onion mixture, chicken breast, and jalapenos, and making dough with flour, butter, sugar, and vinegar. The model selects entities for recipe steps by encoding vectors using a bidirectional GRU and minimizing negative log-likelihood for predicting the next word in the sequence. Implementation details can be found in the appendix. Our full model outperforms all baselines at selecting entities, with an F1 score of 55.39%. Recurrent attention, coverage loss, action connections, and action selector pretraining improve performance in predicting both uncomposed and composed entities. The model must select entities in a Cooking lasagna recipe, showcasing difficulty in selecting the full set for a composed entity. The full model outperforms baselines in state change tracking, attributing higher accuracy to predicting a smaller number of total state changes. In our model, each action is assigned its own embedding, with actions that perform similar functions being neighbors in embedding space. Learning action representations through state changes has allowed the model to cluster actions by their transformation functions. Our model combines state embeddings of entities, applies action embeddings, and writes them to memory. The soft attention mechanism allows similarities to leak between entity embeddings, enabling the modeling of compositionality patterns. Results show that sequences generated using entity states as input yield higher scores than competitive baselines, allowing the model to predict next steps based on a representation of the entities. The model uses entity states to predict next steps in a simulated world. Higher VF1 and SF1 scores indicate better prediction accuracy. Example generations for different baselines are provided in Table 6. The model uses entity states to predict next steps in a simulated world. The NPN generator can use information about ingredient states to reason about the most likely next step, such as refrigerating a cooked flan. The model learns to predict next steps in a simulated world by interpreting text in terms of the effects actions induce in entities. It provides an inductive bias for learning how to represent stored memories and track entity states. Our work aims to provide a structured representation of domain-specific action knowledge to enhance the reasoning process. We introduce a framework for learning representations of a wide range of actions and their effects on the state space, integrating action and entity relations into the neural network architecture. This complements existing models that focus on building discrete graph representations of recipes using probabilistic models. Our work introduces the Neural Process Network to model state changes in embedding space using text-based signals, learning action transformations that affect entity states. The model tracks entity states with a recurrent memory structure and predicts state changes. Empirical results show the model can learn causal effects. Our model can learn causal effects of action semantics in the cooking domain and track dynamic state changes of entities, outperforming competitive baselines. Training details include a hidden size of 100 for the instruction encoder, embedding sizes of 30 for action functions and entities, dropout rate of 0.3, Adam optimizer with a learning rate of .001, and early stopping criteria. The model is trained with skipgram embeddings BID15 and a word2vec model on a vocabulary size of 7358 for words and 2996 for entities. Gradients for coverage loss are backpropagated only when no entity is selected. Hidden sizes for context and state encoders are 200, state vectors have dimensionality 30. Dropout of 0.3 is used during training. Learning rate starts at 0.0003 and halves every 5 epochs. The model uses single-layer encoders and decoder. The learning rate is initially set at 0.0003 and is halved every 5 epochs. The model is trained with the Adam optimizer and uses a dropout rate of 0.3. Word embeddings are initialized with skipgram embeddings using a word2vec model trained on the training set. The vocabulary size for words is 7358. Recurrent Entity Networks tie memory cells to entities in the document, with 12 entity cells initialized for a recipe with 12 ingredients. All hyperparameters are the same as in the bAbI task from BID4. The hyperparameters for the model are the same as in the bAbI task from BID4. The learning rate starts at 0.01 and is halved every 25 epochs. Entity cells and word embeddings are 100 dimensional. Intermediate supervision from weak labels helps predict entities. A separate encoder computes attention over memory cells and content to write to memory. Dropout of 0.3 is used in the encoders. The batch size is 64. The vocabulary size is 7358 for words and 2996 for entities. The encoder and decoder are single-layer GRUs with hidden size 200. The Adam optimizer is used with a learning rate of 0.0003 halved every 5 epochs. The encoder is bidirectional and trained to minimize negative loglikelihood of predicting the next word. The model is trained with the same hyperparameters as the bAbI task from BID4, using a multiplicative attention mechanism between the decoder hidden state and context vectors. Workers are provided with verbs, definitions, images, and sentences to identify state changes caused by the verbs. Seven workers annotate each verb, and a state change is assigned based on majority vote. Workers annotate verbs and assign state changes based on majority vote. Out of 384 verbs, 342 have identified state change types, with 74 having multiple types. Workers are given a verb, state change type, and example to determine the end state of the ingredient. These end states are used as labels for predicting state changes. Annotators note entities undergoing state changes and new ingredient combinations. In a separate task, workers identify actions in recipe sentences through a majority vote. Table 8 shows results for entity and state change selection when training labels are randomly dropped."
}