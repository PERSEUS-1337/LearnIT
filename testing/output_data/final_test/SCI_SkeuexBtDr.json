{
    "title": "SkeuexBtDr",
    "content": "We propose a rule-exemplar model for collecting human supervision to combine the scalability of rules with the quality of instance labels. The supervision is designed to be natural for humans and synergistic for learning. Our training algorithm denoises rules and trains the model through a soft implication loss. Empirical evaluation shows that our algorithm is more accurate than existing methods for learning from a mix of clean and noisy supervision. The coupled rule-exemplar supervision effectively denoises rules, addressing the challenge of limited labeled data in machine learning adoption. Various strategies exist to reduce the burden of human supervision, including active learning and rule-based methods. Learning from scalable but noisy supervision is gaining interest, although clean instance labels remain crucial for reliable results. In this paper, a unique blend of cheap coarse-grained supervision in the form of rules and expensive fine-grained supervision in the form of labeled instances is proposed. Each labeling rule is attached with exemplars of where the rule correctly 'fires', denoising rules and addressing the challenge of limited labeled data in machine learning adoption. Humans provide paired supervision of rules and exemplars demonstrating correct deployment of that rule. Sentiment Classification and Slot-filling tasks in NLP can benefit from a blend of cheap rule-based supervision and expensive labeled instances. Rules can be generalized from labeled examples but may not always be reliable on unseen instances. Slot-filling tasks, like identifying cuisine or location in restaurant reviews, can also benefit from this approach. In NLP tasks like sentiment classification and slot-filling, rules can be generalized from labeled examples but may not always be reliable on unseen instances. Developing algorithms for training models under rule-exemplar supervision is the focus of this paper, with the main challenge being noisy labels induced by rules. Learning with noisy labels has been a long-standing interest in ML. The paper focuses on developing algorithms for training models under rule-exemplar supervision to address noisy labels induced by rules in NLP tasks. The proposed method denoises over-generalized rules using latent coverage variables and trains a classification model with a soft implication loss. Key contributions include proposing supervision in the form of rules generalizing labeled exemplars and designing a training method to address noisy labels. The paper introduces a classification model with a soft implication loss for training under rule-exemplar supervision. Experimental results across various tasks demonstrate the effectiveness of this approach compared to recent frameworks. The method addresses noisy labels induced by rules in NLP tasks by denoising over-generalized rules using latent coverage variables. The paper presents a classification model with a soft implication loss for training under rule-exemplar supervision. It aims to address noisy labels induced by rules in NLP tasks by denoising over-generalized rules using latent coverage variables. The model uses labeled instances as exemplars for rules, where each rule can have multiple exemplars associated with it. The goal is to train a classification model to maximize accuracy on unseen test instances by using labeled and unlabeled instances. The paper introduces a classification model with a soft implication loss for training under rule-exemplar supervision to address noisy labels in NLP tasks. It aims to denoise over-generalized rules using latent coverage variables, associating a latent Bernoulli random variable with each instance to model noise induced by rules. The paper proposes a model to address noisy labels in NLP tasks by denoising over-generalized rules using latent coverage variables. It introduces a network to learn the distribution of latent coverage variables and jointly model the true label and coverage for each rule and instance. An example is provided to illustrate the concept. The paper introduces a model to handle noisy labels in NLP tasks by denoising over-generalized rules using latent coverage variables. It aims to learn the distribution of latent coverage variables and jointly model the true label and coverage for each rule and instance. The revised boundaries of the rules are determined based on consensus on the labeled data and the set of rules, excluding examples wrongly covered. This approach helps in training the classifier effectively. The paper proposes a model to handle noisy labels in NLP tasks by denoising over-generalized rules using latent coverage variables. It aims to jointly learn the distribution of latent coverage variables and model the true label and coverage for each rule and instance. The supervision includes ground truth values for y and r j, with human-labeled data defining the log-likelihood for P \u03b8 (y|x) and sure-shot labeled data for P j\u03c6 (r j |x). The paper introduces a model for handling noisy labels in NLP tasks by denoising over-generalized rules using latent coverage variables. It aims to learn the distribution of latent coverage variables and model the true label and coverage for each rule and instance. The supervision includes ground truth values for y and r j, with human-labeled data defining the log-likelihood for P \u03b8 (y|x) and sure-shot labeled data for P j\u03c6 (r j |x). The model enforces causal constraints on the relationship between r ji and y i, converting them into a probability constraint. The paper introduces a model for handling noisy labels in NLP tasks by denoising over-generalized rules using latent coverage variables. It aims to learn the distribution of latent coverage variables and model the true label and coverage for each rule and instance. The supervision includes ground truth values for y and r j, with human-labeled data defining the log-likelihood for P \u03b8 (y|x) and sure-shot labeled data for P j\u03c6 (r j |x). The model enforces causal constraints on the relationship between r ji and y i, converting them into a probability constraint. The hard constraint is converted into a log probability of the constraint being satisfied under the P \u03b8 (y|x) and P j\u03c6 (r j |x) distributions. A surface plot of the log probability is shown, indicating a sharp drop in likelihood when P (r j |x) is close to 1 but P (y = j |x) is close to zero. The training loss in the model is denoised by enforcing constraints on the relationship between rules and labels. The log-likelihood is flat and close to zero, providing a soft enforcement of constraints without unwanted biases. The final training objective includes maximizing the log probability of the constraint being satisfied. This denoised rule-label implication loss is referred to as ImplyLoss. The ImplyLoss method enforces constraints between rules and labels in the training of neural networks. It consistently outperformed other methods such as posterior regularization and co-training. The network architecture consists of three modules: a shared embedding layer, a classification network, and a description of the embedding module for each task in the experiments section. The network architecture includes a classification network and a rule network that models P j\u03c6 (r j = 1|x). Training algorithms are compared against baselines and error-tolerant learning methods across various datasets and task types. The datasets were augmented with rules obtained manually and from pre-existing public sources. The Question Classification dataset consists of 5452 instances split into training, validation, and unlabeled sets. Generalized rules were created for the unlabeled set, covering 4637 instances, significantly more than the labeled set. The dataset was augmented with rules, covering 4637 instances in the unlabeled set, significantly more than the labeled set. The precision of rule labels was 63.8%, with 22.5% of instances having conflicts. The task involved slot-filling in sentences about restaurant search, with training data split into labeled, validation, and unlabeled sets. The dataset was augmented with rules, covering 4637 instances in the unlabeled set. The rules had a precision of 63.8%, with conflicts in 22.5% of instances. The task involved slot-filling in restaurant search sentences, with training data split into labeled, validation, and unlabeled sets. The rules created for labeling the highest-rated burger within ten miles were evaluated using the F1 metric on a test set of 14.2k tokens. The dataset contained 5.5k text messages labeled as spam/not-spam, with 69 exemplars manually generalized to rules. The rules checked for keywords or phrases in the SMS to classify them as spam. The task involves classifying comments on YouTube videos as Spam or Not-Spam using labeling functions from Snorkel's Github page. The Census Income dataset from the 1994 U.S. census is used for binary classification on whether a person earns more than $50K. The task involves classifying comments on YouTube videos as Spam or Not-Spam using labeling functions from Snorkel's Github page. The Census Income dataset from the 1994 U.S. census is used for binary classification on whether a person earns more than $50K. The train data consists of 32563 records, with 83 random data points as L, 10k points as U, and 5561 points as validation data. Rules were created synthetically by extracting a decision list from a proxy for human knowledge. Pretrained resources like ELMO network and Snorkel's architecture are utilized for network architecture. The architecture for the classification networks in the MIT-R dataset and YouTube involves hidden layers with ReLU activation. Hyperparameters were tuned using a validation dataset. In Table 2, comparisons are made between different methods on five datasets. The Majority method, which predicts based on rules without learning a network, shows poor accuracy. The Only-L method, which trains a classifier only on labeled data, outperforms Majority even with a small labeled set. The baseline method uses clean labeled data and outperforms noisy majority labels. Training the classifier on labeled data along with majority labels from rules shows gains. Using noise-tolerant loss functions improves learning from noisy labels. Learning to Reweight (L2R) is a recent method for training with a mix of clean and noisy labeled data. It meta-learns to re-weight the loss on noisy labeled instances with the help of clean examples. Comparisons with other methods like L+Usnorkel show mixed results with no consistent gains over using clean labeled data only. The SnorkelNoise-Tolerant method is compared with other approaches like Only-L and L+Umaj, showing inconsistent gains. Posterior Regularization (PR) is another method that uses soft constraints to train neural networks for structured outputs, with a teacher-student setup. The teacher-student method uses constraints to minimize violations, while the student updates parameters to minimize KL distance. This approach outperforms other methods, including PR, by providing better accuracy on all datasets. The training process is simple and fits into the batch stochastic gradient training template, unlike PR which requires special computations. The teacher-student method outperforms PR by minimizing violations through constraints and updating parameters to reduce KL distance. Diagnostics experiments show the effectiveness of learning true coverage via the P j\u03c6 network, with precision improving significantly on all datasets, especially on noisier rules. P j\u03c6 denoises rules by capturing the distribution of latent true coverage variables with limited loss. The importance of exemplar-rule pairs in learning the P j\u03c6 and P \u03b8 networks is evaluated. Excluding the likelihood on rule-exemplar pairs from the loss results in a drop in performance of ImplyLoss. However, even without exemplar-rule pairs, ImplyLoss still outperforms most methods, indicating the effectiveness of the training objective in learning from rules and labeled instances. Increasing labeled data L while keeping the number of rules fixed on the Question dataset shows the accuracy of ImplyLoss. In the attached plot, the accuracy of the method (ImplyLoss) is compared against Only-L and Posterior Reg on the Question dataset. The gap between the methods narrows as labeled data increases. Learning from noisily labeled data has been extensively studied, with different algorithms addressing noise robustness. Our model introduces systematic and instance-dependent noise, and compares with a state-of-the-art method that aligns with a clean validation set. Ren et al. (2018b) proposed a method that aligns with a clean validation set using meta-learning. Other approaches include Shen & Sanghavi (2019) iteratively selecting examples with smallest loss, and Veit et al. (2017) learning a separate network to transform noisy labels. In contrast, our method involves rule-specific cleaning with latent coverage variables and an implication loss. Different from previous works, we do not assume an instance-independent confusion matrix. Tanaka et al. (2018) uses classifier confidence to eliminate noise. The curr_chunk discusses the integration of logical rules with labeled examples for training networks, focusing on structured outputs. Different from other methods, this approach corrects noisy rules to improve the classifier. The use of posterior regularization for soft rules is also mentioned. The curr_chunk introduces a novel approach of coupled rule-exemplar supervision for training deep structured output networks, aiming to learn non-linear networks to restrict rule boundaries. This method outperforms existing frameworks by harnessing rules and noisy supervision in a more powerful way. The curr_chunk proposes a model for collecting human supervision to improve rule-based learning. It suggests training the classifier while denoising rules using latent coverage variables. Empirical results show the effectiveness of this approach on various datasets. The goal is to apply this framework to other tasks with limited human supervision. The curr_chunk introduces a model using latent coverage variables to improve rule-based learning. It enforces constraints on the joint distribution Q and uses a KL term to match trained marginals. The model enforces constraints on the joint distribution Q and uses a KL term to match trained marginals. This leads to an alternating optimization algorithm within the posterior regularization framework. In the posterior regularization framework, the model enforces constraints on the joint distribution Q and uses a KL term to match trained marginals. This leads to an alternating optimization algorithm where parameters \u03b8 and \u03c6 are updated to match corrected Q distributions using stochastic gradient techniques. The training algorithm involves updating parameters \u03b8 and \u03c6 using stochastic gradient techniques to minimize the loss in Equation 14. The optimization variable Q(y, r) is constrained to equal 1, with a Langrangian multiplier \u03b7. The objective function is rewritten as F(Q, \u03b8, \u03c6) and solved for \u2202F/\u2202Q(y,r) = 0. The objective function is rewritten as F(Q, \u03b8, \u03c6) and solved for \u2202F/\u2202Q(y,r) = 0, with the marginals expressed in expanded forms. Equating it to zero gives the solution for Q(y, r) in Equation 11. Rules for each task type are provided. Experiments use a learning rate of 1e-4, batch-size of 32, and a dropout of 0.8. The models were trained for a maximum of 100 epochs with early stopping using a validation set. Hyperparameters used in the experiments are listed. Table 9 shows the meta-learning rate of Learning to Reweight method (L2R) for various datasets."
}