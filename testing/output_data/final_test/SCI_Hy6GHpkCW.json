{
    "title": "Hy6GHpkCW",
    "content": "Sketch-rnn is a recurrent neural network trained on human-drawn images to generate stroke-based drawings of common objects. The model can create coherent sketches in a vector format, using new training methods. This approach differs from traditional image generation models like GANs and VI, focusing on abstract representation rather than pixel grids. In this paper, a generative model for vector images is proposed as an alternative to traditional pixel image modelling approaches. The goal is to train machines to draw and generalize abstract concepts similar to humans, starting with training the model on hand-drawn sketches represented as a sequence of motor actions controlling a pen. The model has various potential applications, from assisting artists in the creative process to teaching students how to draw. The paper outlines a framework for generating vector images using a recurrent neural network-based model. It includes a unique training procedure for vector images and explores the latent space for conditional generation. The methodology is applied to sketches of common objects, with creative applications discussed. A dataset of 50 million hand-drawn vector images is provided for further development, along with an open-source implementation of the model. The text discusses the use of neural networks for generative models of vector images, focusing on techniques like reinforcement learning and Hidden Markov Models. Previous works have mainly focused on mimicking digitized photographs, with limited research on vector image generation using neural networks. Recent work has focused on utilizing Mixture Density Networks to generate continuous data points for handwriting generation. This approach has also been used to model Chinese characters as a sequence of pen stroke actions, allowing exploration of the latent space representation of vector images. Additionally, a methodology combining Sequence-to-Sequence models with a Variational Autoencoder has been outlined for modeling natural English sentences in latent vector space. In the realm of generative vector drawings, research has been limited by the lack of publicly available datasets. Previous datasets like Sketch and Sketchy provided a foundation for exploring feature extraction techniques. ShadowDraw is an interactive system that predicts finished drawings based on incomplete brush strokes. A new dataset of 50 million vector sketches has been made publicly available for further research. QuickDraw is a dataset of 50 million vector sketches obtained from an online game where players draw objects in less than 20 seconds. Each class in QuickDraw has 70K training samples, along with validation and test samples. The data format represents a sketch as a set of pen stroke actions, with each point consisting of 5 elements. The curr_chunk discusses the structure of the pen stroke actions in a sketch, including the offset distance and pen states. It also mentions the architecture of a Sequence-to-Sequence Variational Autoencoder used for encoding sketches. The curr_chunk describes the process of encoding sketches using a bidirectional RNN and a VAE approach. The final hidden states are used to generate latent vectors, which are then used by an autoregressive RNN decoder to produce output sketches. The latent vector is a random vector conditioned on the input sketch, not a deterministic output. The decoder RNN outputs parameters for a probability distribution of the next data point based on the latent vector z. The model uses a Gaussian mixture model and a categorical distribution to represent the ground truth data. The generated sequence is conditioned on a latent code z sampled from the encoder. The decoder RNN outputs parameters for a probability distribution of the next data point based on the latent vector z. It uses a Gaussian mixture model with five parameters for each bivariate normal distribution. The output vector y is of size 5M + M + 3, including the logits needed to generate (q1, q2, q3). The next hidden state of the RNN projects into the output vector y using a fully-connected layer, breaking it down into the parameters of the probability distribution of the next data point. Operations like exp and tanh are applied to ensure non-negative standard deviation values and a correlation value between -1 and 1. The probabilities for categorical distributions are calculated using logit values. Training the model to stop drawing is a challenge due to unbalanced probabilities of pen stroke events. Different weightings were used for each pen event in previous approaches, but a simpler and more robust approach was developed for diverse image datasets. All sequences are generated to a maximum length N max in this new approach. In the new approach, sketches are generated up to a maximum length N max, with parameters sampled from GMM and categorical distributions. The sampling process is non-deterministic, controlled by a temperature parameter \u03c4, and continues until a stopping condition is met. During the sampling process, a temperature parameter \u03c4 is introduced to control the level of randomness in samples. As \u03c4 approaches 0, the model becomes deterministic, generating the most likely points in the probability density function. Unconditional generation of sketches can be achieved by training only the decoder RNN module, removing the need for input or latent vectors. The decoder RNN in an autoregressive model is initialized with zero hidden states and cell states. Sketch images are unconditionally generated with varying temperature parameters. Training follows a Variational Autoencoder approach with Reconstruction Loss and Kullback-Leibler Divergence Loss optimization. The reconstruction loss, L R, is calculated using the generated parameters of the pdf and training data. It consists of log loss terms for offset and pen state, normalized by sequence length. The KL divergence loss measures the difference between the latent vector distribution and a Gaussian vector. This methodology allows the model to learn when to stop drawing effectively. The loss function includes a weighted sum of the reconstruction loss (L R) and KL divergence loss (L KL) terms, with a tradeoff between optimizing for one over the other. As the weight for KL loss approaches zero, the model becomes more like a pure autoencoder, sacrificing prior enforcement over the latent space for better reconstruction metrics. For unconditional generation, only the reconstruction loss is optimized. Tradeoff between L R and L KL is illustrated in Figure 4 for models trained on single class datasets, showing the impact of different w KL settings on validation loss. Figure 4 shows the tradeoff between w KL settings and L R/L KL metrics in conditional and unconditional sketch-rnn models. Experiments were conducted on various QuickDraw classes like cat, pig, face, and firetruck, as well as multi-class datasets. Test set evaluation results are recorded for different settings of w KL. The sketch-rnn model uses LSTM BID10 as the encoder RNN and HyperLSTM as the decoder RNN. Results for test set evaluation on various datasets are shown in Table 1, displaying loss figures for different w KL settings. The ability of HyperLSTM to adapt to diverse datasets is highlighted. The reconstruction loss decreases as the w KL parameter is relaxed, while the KL loss increases. The conditional model has lower L R compared to the standalone decoder model. The conditional model has lower reconstruction loss (L R) compared to the standalone decoder model. Validation-set loss graphs show the tradeoff between L R and KL loss as w KL settings vary. Reconstructed sketches maintain similar properties to input images, occasionally adding or removing details. Non-standard images may result in unexpected reconstructions. The model generates sketches with cat-like features when inputting images from different classes. Interpolating between latent vectors visualizes the morphing of images. A Gaussian prior on the latent space reduces gaps. Models trained with higher w KL settings produce images closer to the data manifold. The text discusses training models with various w KL settings to generate coherent interpolated images. Models with higher w KL produce more coherent images, suggesting that latent vectors encode conceptual features of a sketch. Sketch drawing analogies are possible for models trained with low w KL numbers, allowing for vector arithmetic on the latent vectors. The text explores how models organize latent space to represent concepts in generated sketches. By performing vector arithmetic on latent vectors, different concepts can be represented. Sketch-RNN can predict possible endings for incomplete sketches, and using the decoder RNN independently allows for generating conditioned sketches. By using the decoder RNN independently, sketches can be generated based on previous points. Results from decoder-only models trained on individual classes show potential for assisting artists in expanding their creativity. Sketch-rnn enables exploration of latent space between objects, leading to unique intersections and relationships in drawings. Additionally, pattern designers can utilize sketch-rnn to create numerous similar yet distinct designs. Pattern designers can use sketch-rnn to generate a variety of unique designs for textile or wallpaper prints. The model can be applied to create abstract designs that resonate with the target audience. Additionally, the tool can be used for educational purposes to teach students how to draw, as demonstrated with QuickDraw sketches improving the authors' proficiency in drawing animals, insects, and sea creatures. The work has improved drawing skills in animals, insects, and sea creatures. By encoding and generating drawings with a model trained at high KL setting and low temperature, more aesthetically pleasing reproductions can be created. Future research may involve enhancing the latent vector for drawing aesthetics using user-rating data. Exploring hybrid sequence-generation models with Image-to-Image models like Pix2Pix for generating realistic images from sketches is another potential direction. In this work, a methodology is developed to model sketch drawings using recurrent neural networks. The model, sketch-rnn, can generate possible ways to complete unfinished sketches and encode existing sketches into a latent vector to generate similar looking sketches. Interpolating between different sketches through the latent space and manipulating sketch attributes by augmenting the latent space are also demonstrated. Enforcing a prior distribution on the latent vector is shown to be important for coherent image generation during interpolation. The QuickDraw dataset contains a large collection of sketch drawings with hundreds of classes and approximately 50 million sketches. Each class has 70K training samples and 2.5K validation and test samples. Stroke simplification using the Ramer-Douglas-Peucker algorithm has been applied to simplify the lines. The data was normalized using a scaling factor to adjust offsets in the training set. A sample sketch was shown before normalization of data columns. Reconstruction loss term L R and KL loss term L KL were defined. The loss function is a weighted sum of both terms. During training, annealing the KL loss term in the loss function (Equation 15) improves results by focusing on the reconstruction term first before optimizing for the KL loss term. This approach has been used in various studies. The annealing term starts at a minimum value and converges to 1 for large training steps. During training, annealing the KL loss term in the loss function improves results by focusing on the reconstruction term first before optimizing for the KL loss term. This approach involves setting a floor on the KL loss term to encourage better metrics for the reconstruction loss term. The KL min term is typically set to a small value to achieve this. In training, annealing the KL loss term improves results by focusing on the reconstruction term first before optimizing for the KL loss term. The model uses 20 mixture components for the decoder RNN and a latent vector with 128 dimensions. Layer Normalization and recurrent dropout are applied during training with specific parameters. Data augmentation is performed by multiplying offset columns by random factors. The model is trained with specific batch sizes, learning rate, and gradient clipping. Sketch-rnn can model a variety of sketches but has limitations, especially with longer sketches. The Ramer-Douglas-Peucker algorithm is used to simplify strokes. More complex images like mermaids have lower reconstruction loss compared to simpler classes. Sketch-rnn struggles to model a large number of classes simultaneously, resulting in incoherent samples when trained on 75 classes. The model tends to produce smoother, more circular line segments that resemble an averaging of many sketches in the training set, similar to the blurriness effect of a Variational Autoencoder. This smoothness can be aesthetically pleasing depending on the use case. The 75-class model struggles with coherence, generating sketches with features from multiple classes. The four-class unconditional model mostly produces single-class samples but occasionally combines features. Future work will explore incorporating class information outside the latent space. Examples of conditional generated sketches with single class models are shown, with latent space interpolation between sketches. Additional examples demonstrate interpolation between four sketches to gain insights from the model. The text discusses the interpolation of latent vectors in a grid to generate samples from different classes, such as pig, rabbit, crab, face, yoga poses, mosquitoes, and mermaids. The model transitions smoothly between different classes, creating unique sketches with interpolated colors. The text explores interpolation between various classes such as pig, rabbit, crab, face, yoga poses, mosquitoes, and mermaids. It also discusses the importance of balancing reconstruction loss and KL loss for higher quality image reconstructions. The text discusses how a lower L R number does not guarantee higher quality reconstructions compared to a higher L R number. It gives an example of reconstructing a face with incoherent facial features scoring lower L R compared to a coherent face. The reconstructed images generated using models trained with various w KL settings are compared. The model trained with higher w KL weights tends to generate sketches with features of a single class that look more coherent, omitting inconsistent features. In contrast, models with lower w KL values try to keep both inconsistent features, resulting in less coherent sketches. This trend is observed even when models are trained on single-class images, showing that better KL loss terms lead to more meaningful interpolations in the latent space. Models with better KL loss terms generate more meaningful reconstructions from the interpolated space between latent vectors. Lower L KL values control more meaningful parts of drawings, allowing for direct manipulation of animal features. In contrast, higher L KL values result in scattered movement of line segments without altering meaningful conceptual features. Lower L KL models are likely to generate coherent images even with noisy input, while higher L KL models show incoherent reconstructions. When using sketch-rnn on a new dataset, it is recommended to try different w KL settings to balance between meaningful conceptual features and specific line segments encoded in the latent vectors. This tradeoff can help in choosing the best w KL setting for the desired requirements."
}