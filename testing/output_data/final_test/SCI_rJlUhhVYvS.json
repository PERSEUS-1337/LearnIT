{
    "title": "rJlUhhVYvS",
    "content": "In recent years, there has been a rapid increase in classification methods for graph structured data. Incorporating graph isomorphism features into models has been a common practice, but it can lead to isomorphism bias due to repeating instances in datasets. This bias artificially increases model accuracy by memorizing target information from the training set, raising questions about the validity of results. An analysis of 54 datasets reveals the existence of isomorphism bias, prompting recommendations for setting up models and the release of new datasets for future experiments. Recently, there has been a growing interest in developing machine learning models for graph structured data in various fields such as chemoinformatics, bioinformatics, neuroscience, computer vision, system security, natural language processing, and others. Graph classification problems have led to the creation of many graph kernels and neural networks. One common assumption is that models capable of distinguishing isomorphic instances are essential. Efforts have been made to incorporate efficient graph isomorphism methods into classification models. Various heuristics have been proposed to determine if two graphs are isomorphic, as computing complete graph invariants is GI-hard. Different graph kernels, such as the graphlet kernel, have been developed based on theoretical developments in graph isomorphism literature. The Kelly conjecture, anonymous walk kernel, and WL kernel are all based on graph isomorphism algorithms. The k-dimensional WL algorithm captures all combinatorial properties of a graph, making it a strong baseline for graph isomorphism. Graph neural networks also leverage graph isomorphism algorithms and have been shown to be as powerful as the k-dimensional WL algorithm. Experimental evaluation shows that models utilizing theoretical constructions like the WL algorithm outperform those without, such as the Vertex histogram kernel. This can introduce bias in comparing classification algorithms, as models may simply use graph isomorphism methods to determine labels. However, solely evaluating accuracy may lead to unfair comparisons, as it doesn't assess generalization ability on new instances. Many graph classification datasets have isomorphic instances, with some having as low as 20% unique non-repeating graphs, challenging previous assumptions. The study analyzes 54 graph datasets commonly used in graph classification. It reveals varying proportions of isomorphic graphs, some with different target labels, making them unsuitable for learning classifiers. The causes of isomorphic graphs include node and edge labels, numerical attributes, and dataset sizes. An upper bound for the generalization gap is expressed through Radamacher complexity. The text discusses the generalization gap in classifiers using Radamacher complexity and the impact of isomorphic graphs on classification accuracy. It introduces a model-agnostic method to improve performance on datasets with isomorphic instances and provides cleaned datasets with non-isomorphic instances. Recommendations for working with graph structured data are also given, highlighting the importance of measuring dataset quality. In the computer vision domain, recent studies have found duplicate images in popular datasets like CIFAR and ImageNet, leading to a drop in model accuracy when tested on new datasets. In the graph domain, research has focused on understanding the expressiveness of graph kernels and dataset quality, with a comparison of existing graph kernels and insights into model behavior. Additionally, a study on isomorphism metrics has revealed pairs in 54 datasets and proposed new metrics. Graph kernels and graph neural networks are two competing paradigms for designing graph representations and solving graph classification. Recent studies have shown that current datasets exhibit isomorphism bias, which can artificially boost evaluation metrics. Various methods have been explored to justify the performance of different families of methods, such as maximizing mutual information between variables and predicted label distribution. The model is trained to return a small subgraph and the most influential graph-specific attributes for decision-making by a GNN. The VC dimension of GNNs models grows as O(p 4 N 2), comparable to RNN models. Stability and generalization properties of convolutional GNNs depend on the largest eigenvalue of the graph filter. Expressivity of graph kernels has been studied in statistical learning theory and property testing. Our approach analyzes the effect of different datasets on the final performance of graph classification tasks. We examine 54 commonly used graph datasets, which include graphs with categorical labels, node and/or edge labels, and come from biological or social network domains. The datasets can be used to improve scoring in graph classification methods. Biological and social network datasets contain graphs representing molecules or relationships between people. Labels encode properties like toxicity or interaction types. Synthetic and computer vision datasets are also included. The graph isomorphism problem asks if two graphs are isomorphic. The graph isomorphism problem involves determining if two graphs are isomorphic. Efficient algorithms exist for certain classes of graphs, but in general, only a quasi-polynomial algorithm is known. Many solvers use the individualization-refinement paradigm to find canonical permutations of graphs. State-of-the-art solvers can efficiently handle most pairs of graphs, only struggling with highly symmetrical structures. Graph orbits are used to distinguish between isomorphic graphs in a dataset. In a dataset of graphs, graph orbits are used to identify isomorphic graphs. The orbit of a graph G consists of all isomorphic graphs to G in the dataset. The number of orbits in a dataset indicates its cleanliness. Additional metrics like the aggregated number of non-trivial orbits and proportions of isomorphic graphs are also considered. In a dataset of graphs, graph orbits are used to identify isomorphic graphs. The orbits consist of all isomorphic graphs to a specific graph in the dataset. The number of orbits in a dataset indicates its cleanliness. The proportion of isomorphic graphs is calculated by running the nauty algorithm on all possible graph pairs in the dataset. The results are presented in tables for the top-10 datasets and all datasets. The results show that most graphs in the top-10 datasets are isomorphic to each other, with varying proportions of isomorphic graphs in different datasets. Over 80% of datasets have at least 10% of graphs in non-trivial orbits. Mismatched graphs are also prevalent, indicating the need for additional information for graph classification. The distribution of orbit sizes varies across datasets, as shown in Figure 1. The distribution of orbit sizes varies across datasets, with isomorphic graphs affecting training procedures, test performance, and model confusion. This highlights the need for additional information for graph classification. Meta-information about graphs includes node and edge features in addition to the graph topology. Some datasets have node features and edge features, such as scalar attributes or distances. Including categorical and numerical features in the analysis improves the distinction between graphs and their labels. The analysis now includes node labels when computing graph isomorphism. Tables show the impact on isomorphic graphs, with a significant decrease in mismatched graphs. For example, the MUTAG dataset saw a decrease from 42.02% to 19.15% in isomorphic graphs and from 6.91% to 0% in mismatched graphs. After considering node labels in graph isomorphism, there is a significant change in the orbit size distribution. Large orbits disappear, and the number of small orbits decreases in label-preserving settings. This highlights the importance of including node/edge labels in graph classification models. The presence of many isomorphic graphs in datasets can also be attributed to the small sizes of graphs, which limits diversity. The number of non-isomorphic graphs with a certain number of vertices and edges grows rapidly, as shown by Polya enumeration theory. For instance, a graph with 15 nodes and 15 edges has 2,632,420 non-isomorphic graphs. The average size of graphs impacts the structure of the dataset, with larger graphs being more diverse. Isomorphic graphs have consequences on classification methods, denoted by F \u2286 Y X for binary classifiers. The prior probability of a positive class is represented by \u03c0, and a zero-one loss function is considered. In the context of graph classification, classifiers from F can detect isomorphic graphs in dataset D using Weisfeiler-Lehman graph kernels. This leads to a weighted loss interpretation of the classification problem, with a measurable weighting function u. The theoretical risk is defined as E P l(f (x), y), and the weighted empirical risk is calculated. The goal is to derive an upper bound for the excess risk in this scenario. To quantify the upper bound for the excess risk in graph classification, a weighted loss interpretation is used with a measurable weighting function u. Previous studies have explored classification performance with weighted losses, but there is a gap in deriving an explicit upper bound for the excess risk considering class imbalance and weighting schemes. This gap is addressed in the following analysis. The excess risk in graph classification is upper bounded using a weighted loss interpretation with a weighting function u(x, y). By tuning the weight parameter w, the upper bound can be tightened, leading to improved classification accuracy. The optimal weight w opt is approximately 0 for N 1, demonstrating how weighting influences classification accuracy. The presence of isomorphic graphs in the training data set could have a negative effect similar to using a non-optimal weight value in classification with a weighted loss function. This provides theoretical evidence on the impact of isomorphic graphs on graph classification accuracy. The final metric considers accuracy on two subparts of the data set: the isomorphic test instances and the new test instances. The accuracy on the new set will be lower if the model performs better on the isomorphic set. This highlights the impact of isomorphic graphs on graph classification accuracy. The model's performance on isomorphic instances can falsely increase accuracy on the new test set. Misclassification on isomorphic instances can be due to mismatched labels or lack of expressiveness in mapping graph structures to labels. Testing on new instances evaluates generalization capabilities, while isomorphic instances can lead to memorization of correct labels. The model's performance can falsely increase accuracy on the new test set by memorizing correct labels from training data. A model-agnostic approach guarantees improved classification performance when dealing with isomorphic graphs. If the set of isomorphic graphs is homogeneous, a peering model can be defined to output target labels, ensuring accuracy. However, if there are noisy labels in the training set, the model may not guarantee correct target labels for these instances. The model's performance can falsely increase accuracy on the new test set by memorizing correct labels from training data. A peering model can be defined to output target labels for homogeneous isomorphic graphs, ensuring accuracy. Experimentation compares neural network model with graph kernels, showing that the peering model on homogeneous data is always the top performer. The presence of isomorphism bias can lead to an overestimation of classification model performance by up to 5% on certain datasets. It is recommended to evaluate classification models on new instances to avoid measuring performance inaccurately. To address isomorphism bias, new \"clean\" data sets are proposed to eliminate isomorphic instances. Graph orbits are considered, and only one graph from each orbit with the same label is kept. Orbits with multiple labels are removed to prevent memorization of training labels. Data set orbits without node or edge labels are also taken into account to avoid isomorphism based on graph topology. Incorporating node and edge features into graph models is necessary to distinguish non-isomorphic graphs. Analyzing 54 graph data sets, we address isomorphism bias in classification models by providing rules to avoid unfair comparisons. The influence of isomorphism bias on graph classification performance is theoretically characterized, highlighting the need for larger graph verification. In the study, the influence of isomorphism bias on graph classification performance was analyzed. It was found that any model can memorize correct answers from training sets in current datasets. New clean datasets were open-sourced to address this issue. The NN model from Xu et al. (2018) was evaluated on PyTorch-Geometric datasets using 10-fold cross-validation. Training was done for 350 epochs, selecting the best performing model on the validation set. Performance during the initial epochs was noted to be unstable for small datasets. The final model NN is evaluated on test instances after 50 epochs. Peering models NN-PH and NN-P are derived from NN by replicating target labels for different Y iso types. We use Weisfeiler-Lehman and Vertex histogram kernels from Sugiyama & Borgwardt (2015) code. SVM model is trained with C parameter from [0.001, 0.01, 0.1, 1, 10]. New data sets are introduced to address isomorphism bias, and Theorem 6.1 is proven using a composite loss class L. The excess risk of the model is bounded using McDiarmid's concentration inequality. By relating the empirical Rademacher complexity to the Rademacher complexity, a bound on the difference between the expected loss of the model on the population and the expected loss on the training set is derived."
}