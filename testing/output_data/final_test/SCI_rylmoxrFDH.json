{
    "title": "rylmoxrFDH",
    "content": "The training of stochastic neural network models with binary weights and activations is studied using continuous surrogate networks. Mean field theory is used to derive scalar equations describing signal propagation in these networks. The choice of surrogate model determines if networks exhibit an order to chaos transition and depth scales that limit maximum trainable depth. Surrogates using the Gaussian local reparameterisation trick show no critical initialisation, while deterministic surrogates based on analytic Gaussian integration do. The theory is applied to various binary neuron and weight design choices, categorizing algorithms based on their behaviour at initialisation. This study explores the training of stochastic neural networks with binary weights and activations using continuous surrogate networks. It is found that common weight initialization schemes used in standard continuous networks yield poor training performance when applied to the mean values of stochastic binary weights. The means of the stochastic binary weights should be initialized close to $\\pm 1$ for deeper networks to be trainable. Binary neural networks are seen as a promising solution for reducing memory usage in neural networks deployed on low-power devices. Binary neural networks with both binary weights and neurons can significantly reduce power consumption and improve processing speed, allowing neural networks to run efficiently on CPUs. Training these networks involves using a differentiable surrogate network to handle the challenges of optimization with discrete variables. By defining an appropriate surrogate network and leveraging automatic differentiation libraries and GPUs, binary neural networks can be trained directly via backpropagation. This approach involves considering binary stochastic variables to smooth out the non-differentiable network, making both weights and neurons stochastic for improved performance. In this work, two classes of surrogates are studied for binary neural networks with stochastic weights and neurons. The surrogates utilize the Gaussian central limit theorem at the receptive fields of each neuron and are written as differentiable functions of the continuous means of stochastic binary weights. Two approximations are considered, one based on analytic integration yielding deterministic surrogates, and the other based on the local reparameterisation trick yielding stochastic surrogates. Previous works have not properly addressed the initialization question, potentially limiting performance. The seminal papers by Saxe et al. (2013), Poole et al. (2016), and Schoenholz et al. (2016) studied the impact of initialization on learning dynamics in neural networks. They found that networks must be initialized at \"criticality\" to be trainable, preserving initial correlation to any depth. This helps avoid the vanishing and exploding gradients problem. The paper presents new algorithms for stochastic neural networks, including a new derivation that covers both surrogates and all choices of stochastic binary weights. It simplifies the representation of the network as a Markov chain, allowing for extensions like the LRT to stochastic binary neurons. Additionally, it provides a theoretical analysis of both classes of surrogates. Theoretical analysis of surrogates at initialization shows the importance of criticality for trainability. Results indicate that deterministic surrogates with stochastic binary weights and neurons can achieve criticality, while the LRT cannot. The LRT surrogate cannot achieve criticality for networks with stochastic binary weights and continuous neurons. Critical initialization involves randomly initializing the means of binary weights close to \u00b11. This paper provides insights into the dynamics and training of binary neural network models, focusing on signal propagation properties and differentiable surrogate networks. The initialization of binary neural network algorithms has not been studied extensively, although the impact of quantization levels has been explored. The paper by Blumenfeld et al. (2019) discusses surrogates for binary neural networks, focusing on the limitations of the \"Straight-Through\" estimator. It offers practical advice on initialization and training, presenting new surrogates in a coherent framework. The LRT surrogate is unable to achieve criticality for networks with stochastic binary weights and continuous neurons. The paper discusses surrogates for binary neural networks, focusing on limitations of the \"Straight-Through\" estimator. It presents new surrogates for stochastic binary weights and neurons, deriving signal propagation equations and critical initializations. Numerical simulations validate the mean field description, and experimental results test trainability claims. The key results are summarized in section 5, providing insights into neural network models. The model consists of weight matrices and bias vectors in each layer, with a pointwise non-linearity function. A deterministic binary neural network uses weights of {\u00b11} and sign function, while a stochastic binary network uses smooth variables for training. The goal is to train a deterministic binary network that can generalize well. Stochastic binary networks are less computationally efficient. In stochastic binary neural networks, matrices denoted as S have independently sampled binary weights. Neuron activation is binary due to pre-activation stochasticity. The propagation rules factorize the distribution of x when conditioned on x -1. The neuron's mean function depends on the noise model, and a binary random variable x can be expressed via a latent variable formulation. The form of the non-linearity in stochastic binary neural networks impacts performance. Recent papers aim to adapt binary stochastic weights for differentiable functions. Deterministic and stochastic binary neurons yield similar signal propagation equations. The idea is to use stochastic models to smooth out discrete variables for continuous optimization techniques. In a supervised classification task, we derive deterministic and LRT-based surrogates in a common framework. The stochastic neural network produces a probability distribution over classes, with expectations given by mean values. The method is described as Type II maximum likelihood or empirical Bayes, with the starting point being the marginalization of a Markov chain representation of the network. The stochastic neural network uses a Markov chain representation for the forward pass, propagating joint distribution of layer activations. Continuous random variables are introduced by modeling the field h as Gaussian in the large layer width limit. The field h converges to a Gaussian random variable under the Lyapunov central limit theorem for stochastic binary networks. Assumption 2 states that correlations are zero between pre-activation fields in different dimensions, approximated by a mean field assumption. This assumption holds true at initialization but may not hold in subsequent layers due to shared stochastic neurons. The weights help decorrelate the fields, making the correlation insignificant. The choice of surrogate influences the level of dependence in neural networks. The local reparametrization trick reduces correlations by sampling variables, while a deterministic surrogate discards them. The surrogate models approximate marginal distributions to form Gaussian approximations for each layer. The deterministic surrogate uses analytic integration based on the Gaussian CDF to obtain accurate results. The forward pass in neural networks can be expressed more generally using Gaussian CDF and error functions. This approach includes backpropagation through variance terms, which were previously ignored. The derivation is simpler and does not require Bayesian message passing arguments. The LRT surrogate method aims to reduce correlations by sampling variables, while a deterministic surrogate discards them. The LRT surrogate method involves rewriting Gaussian fields to enable sampling for differentiable networks. Previous approaches focused on stochastic binary weights and neurons without utilizing a Markov chain representation. The resulting network is differentiable but not deterministic, with approximations applied successively to produce a function of the parameters. The mean field approximation method involves replacing pre-activation fields with Gaussian random variables to enable gradient descent training of binary networks. This approach aims to produce a deterministic binary network by setting weights based on the most likely values and using sign activations for neurons. The recursion for covariance in binary networks is derived from layer to layer using Gaussian measures. The correlation recursion equation, denoted as \u03c7, controls the propagation of correlations to prevent gradient issues. Critical initializations are defined to manage the growth or vanishing of gradients with depth. This concept also applies to surrogate models. The distribution of M ij is drawn independently from P(M) with mean zero and variance \u03c3^2m. The stochastic and deterministic binary neuron cases lead to the same signal propagation equations. The variance and covariance are computed using recursive formulae, with the denominator \u03a3MF,ii being a self-averaging quantity. This allows for its safe replacement with its expectation for large N. The variance and correlation recursion equations are derived based on the self-averaging property of \u03a3MF,ii for large N. The critical initialization condition \u03c71 = 1 determines the stability of the correlation map fixed point c* = 1. Hyper-parameters can be solved for by rearranging equations and numerically solving for \u03c32b. Equations 13 and 15 are solved numerically to find the critical initialization point for different neuron noise models and non-linearities. The depth scales provide an indicator of the number of layers correlations will survive for in a network. Asymptotically, the variance and correlations of signals propagate over depth scales \u03beq and \u03bec. The correlation depth scale is of particular interest as it relates to \u03c7. The correlation depth scale is of interest as it relates to \u03c7. The variance depth scale is derived in the appendices but is not of prime practical importance. The pre-activation field for the perturbed surrogate with stochastic binary weights and neurons is given by a non-linear function \u03c6(\u00b7). The variance map does not depend on the variance of the means of the binary weights. The variance map is independent of the means of binary weights. The covariance map shows no simplification due to uncorrelated perturbations. Theory accurately predicts behavior of randomly initialized networks. Simulation results match mean field theory for variance and correlation. Strong agreement seen even for finite networks. Variance and correlation depth scales are presented in the appendices. In Appendix D, variance and correlation depth scales are presented as a function of \u03c3 m and different bias variance values \u03c3 b. Experimental testing of mean field theory predictions is done by training networks to overfit a dataset in the supervised learning setting. Performance of deterministic and LRT surrogates is evaluated using the MNIST dataset with reduced training set size. Experimental results match the correlation depth scale derived. The experimental results match the correlation depth scale derived, indicating a maximum attenuation in signal strength before trainability becomes difficult. Different scaling was found for the LRT surrogate compared to the deterministic surrogate. Training time increases with depth, requiring smaller learning rates for deeper networks. Shallower networks had an advantage over deeper networks due to the same number of epochs used regardless of depth. The theory does not specify how long critical initialization effects will persist during training. The experiments validate the theory qualitatively rather than quantitatively, showing similar results for different optimizers. Training performance for deterministic and stochastic networks on the MNIST dataset is compared, with the stochastic network matching the continuous surrogate as the number of samples increases. The number of samples needed for better classification depends on the training epochs. The relationship between the number of training epochs and the performance of shallow networks is discussed. The study shows that as the number of samples increases, stochastic networks approach deterministic networks in terms of performance. The advice given is to use deterministic networks for training with binary weights and neurons. When training networks with binary weights and neurons, it is recommended to use the deterministic surrogate over the LRT surrogate. The LRT surrogate is critical for binary weights only, while both are critically initialized when \u03c3 2 b \u2192 0 and weights are set to \u00b11. Results show that binary networks perform worse than continuous models during training, especially with increasing depth. Stochastic binary networks outperform deterministic ones with more samples. The study discusses the behavior of binary networks trained via gradient descent on a surrogate model. Signals in binary networks show different behavior based on the training stage, with closer resemblance to randomly initialized cases in early stages. Differences in behavior between binary and heuristic surrogates are highlighted. The form of each neuron's probability distribution in binary networks depends on the noise model, with a latent variable formulation using a natural parameter \u03b8. Introducing a scaling factor \u03b1 controls the variance of the noise, with Gaussian or logistic noise models commonly used. The probability of the binary variable taking a positive value is determined by the known probability density function for the noise. The Gaussian and logistic noise models determine the probability distribution for binary random variables in neural networks. The natural parameter \u03b8 controls the variance of the noise, with the probability of the variable being positive dependent on the cumulative distribution function. Stochastic neurons use the incoming field as the natural parameter, approximating each neuron's probability distribution and applying the central limit theorem for successive layers. The Gaussian and logistic noise models determine the probability distribution for binary random variables in neural networks. The integration over the pre-activation field is exact for neurons with latent Gaussian noise. The mean field approximation to the covariance between stochastic binary pre-activations is denoted by \u03a3 M F. The new approximate probability distribution can be used in the Gaussian CLT for the next layer, propagating approximate means for the neurons. The integration of stochastic neurons with logistic and Gaussian noise is presented as part of their latent variable models. The forward equations for deterministic binary neurons are derived, with the mean of the next layer being a scaled and shifted version of the neuron's noise model CDF. The constant \u03b7 = 1/\u221a2 is standard for the Gaussian CDF to error function conversion. The logistic case in stochastic neurons is an approximation of the Gaussian case, motivated by approximating the logistic CDF with the Gaussian CDF. The interest in logistic CDFs is due to the heavier tails compared to Gaussian distributions, historically influenced by the prevalence of logistic-type functions in neural network literature. There is no clear justification for using logistic CDFs over Gaussian noise models. The historic preference for logistic functions in neural networks is due to the heavier tails of logistic CDFs compared to Gaussian distributions. Integrating over the analytic probability distribution for each neuron allows for calculating means in the next layer. The Gaussian integral of the Gaussian CDF can be used to derive the exact probability distribution for stochastic binary neurons. Approximating logistic noise with scaled Gaussian noise and tanh with erf helps in propagating means from layer to layer. The text discusses approximating the tanh function with erf, deriving the field variance in stochastic and deterministic binary neurons, and scaling constants for the tanh function. The text presents derivations for signal propagation in continuous network models, starting from the variance calculation given a signal. It discusses the correlation recursion and stability at the fixed point in the network. The text discusses stability at the fixed point in continuous network models by computing the slope of correlations mapping between layers. It contrasts critical initialization perspectives and the mean squared singular value control of the input-output Jacobian matrix. Corrections are needed for the Gaussian model studied here. The text discusses corrections needed for the Gaussian model studied here to calculate the true mean squared singular value. The mean squared singular value of the single layer Jacobian approaches \u03c7, and the analysis involves determining if it is well approximated by \u03c7. This idea provides complementary depth scales for gradient signals travelling backwards. The signal propagation equations for continuous neurons and stochastic binary weights yield variance and covariance maps. The variance map does not depend on the variance of the means of binary weights, while the covariance map retains a dependence on \u03c3. The critical initialization condition is found by setting a fixed point in the correlation map. Experimentally confirmed, different noise models can be investigated for perturbed surrogates. In investigating perturbed surrogates with different noise models, the neural network consists of binary weights and continuous neurons. All neurons are sign functions of their input, with randomly distributed weights maintaining a zero mean. The pre-activation field and length map are determined, showing similarities to perturbed Gaussian models. The covariance and correlation maps can be found in closed form, with a joint density integral rewritten for analysis. The integral is rewritten with h for a joint density p(h a , h b ), rescaled so that variance is 1. The correlation c ab is now equal to covariance, with a fixed point at c * = 1. The derivative \u03c7 diverges at c ab = 1, indicating no critical initialization for the system. Correlations do not propagate to arbitrary depth in deterministic binary networks. The variance map q is discussed, with stochastic binary neurons and pre-activation parameters. The expectation and covariance maps are defined in terms of nested conditional expectations for neurons with pre-activation parameters. The equations for this case are equivalent to the perturbed surrogate model, showing no critical initialization exists. Concerns about binary stochastic weights becoming non-stochastic with certain initializations are addressed, ensuring correct variance under the central limit theorem. The central limit theorem variance remains invariant to weight stochasticity, unlike deterministic neurons with tanh() functions."
}