{
    "title": "HJl4FJnEYr",
    "content": "Score matching is an effective approach for learning flexible unnormalized models, but its scalability is limited by the need to evaluate a second-order derivative. This paper connects learning objectives like score matching to Wasserstein gradient flows, allowing for a scalable approximation similar to single-step contrastive divergence. Applications include training implicit variational and Wasserstein auto-encoders with manifold-valued priors. Unnormalized models define the model distribution as q(x; \u03b8) \u221d exp(\u2212E(x; \u03b8)), useful for density estimation and gradient estimation for implicit variational inference. Intractable learning objectives in latent space are approximated using score matching, optimizing the Fisher divergence. Calculating the equivalent objective for complex parameterizations remains difficult due to second-order derivatives, leading to the use of scalable approximations like kernelized Stein discrepancy. In this work, a unifying perspective is presented to derive scalable approximations for various objectives, including score matching, in models on manifolds. The objectives are interpreted as the initial velocity of distribution-space gradient flows, leading to a scalable approximation algorithm similar to single-step contrastive divergence. This approach is referred to as \"minimum velocity learning objective\" and is a distribution-space generalization of previous work on intractable learning objectives in latent space. Our work presents a distribution-space generalization of previous work by Movellan (2007) and addresses the issue of approximating score matching with CD-1. We offer a simple fix to the infinite variance problem, enabling the use of regularization techniques like early-stopping. Our framework has applications in learning unnormalized models on manifolds for fields such as image analysis, geology, and bioinformatics. Our framework enables flexible inference for VAEs and WAEs with manifold-valued latent variables, improving their performance. It addresses the issue of approximating score matching with CD-1 and offers a fix for the infinite variance problem. This has applications in various fields such as image analysis, geology, and bioinformatics. The text discusses the minimum velocity learning (MVL) objectives, which correspond to the initial velocity of the gradient flow. It explains how score matching is a special case of the MVL objective when the space of distributions is chosen as the 2-Wasserstein space P(X). The gradient flow of KL q can correspond to common samplers, such as the Langevin dynamics in P(X). This connection is utilized to design a scalable approximation to these objectives. The text discusses designing a scalable approximation to minimum velocity learning (MVL) objectives using Langevin dynamics. The approximation becomes unbiased when the limit approaches zero, and a control variate is used to reduce high variance in the sampler. The objective is defined using Langevin dynamics with a batch size of 1 in the approximation. A control variate is needed to reduce variance in the sampler. The control variate is the inner product of \u2207 x E(x + ) and the diffusion term. This concept can also be applied to CD-1 and denoising score matching. In the context of learning unnormalized models on Riemannian manifolds, the gradient flow of KL q in the 2-Wasserstein space becomes the Riemannian Langevin dynamics. The Riemannian score matching objective is a sample from the Riemannian LD, enabling approximation of new objectives easily. The framework is applied to learning implicit VAEs and WAEs with manifold-valued prior. The VAE objective is intractable, but can be approximated by simplifying the entropy term. The Riemannian score matching objective enables approximation of new objectives easily, such as learning implicit VAEs and WAEs with a manifold-valued prior. It involves approximating the score function \u2207 z log q(z) using score matching, which aligns the learnt score function to the data score for better gradient approximation. When dealing with a latent space as an embedded manifold, score estimation on the manifold can still be achieved by estimating the log derivative of the density w.r.t. the manifold Hausdorff measure. The method involves fitting an unnormalized model on a manifold using an approximate objective. The approach is applied to train implicit hyperspherical VAEs and WAEs on the MNIST dataset, with a focus on parameterizing an energy network for gradient estimation. Experimental comparisons are made with VAEs and WAE-GAN, reporting negative log likelihood and results from synthetic experiments. In this section, background knowledge on Wasserstein gradient flow and its connection to sampling algorithms is reviewed. A manifold is a topological space locally diffeomorphic to an Euclidean or Hilbert space, covered by a set of charts. The hyperspherical prior outperforms the Euclidean prior in various experiments, with the method showing improved performance by addressing the lack of flexibility in inference. A manifold is a topological space locally diffeomorphic to an Euclidean or Hilbert space, covered by a set of charts. It possesses a Riemannian structure that enables differentiation of functions along curves, with the gradient flow generalizing the Euclidean-space notion. The gradient flow generalizes the Euclidean-space notion. Two types of manifolds are considered: the data space X and the space of probability distributions over X. The 2-Wasserstein space P(X) is a Riemannian manifold with useful properties. Other spaces of distributions are also explored. On the data space, the notion of density is introduced. In the context of manifolds and distributions, density is introduced using the Hausdorff measure. The data space X is embedded in R^n, and sampling algorithms like diffusion-based MCMC and particle-based variational inference are reviewed. Riemannian Langevin Dynamics is discussed for target distribution density p(x). Particle-based samplers approximate the gradient flow of KL p in various spaces using deterministic or stochastic interacting particle systems. For example, Stein variational gradient descent (SVGD) simulates the gradient flow in the H-Wasserstein space, replacing the Riemannian structure with the RKHS inner product. The birth-death accelerated Langevin dynamics and stochastic particle-optimization sampler simulate the gradient flow of KL p in the Wasserstein-Fisher-Rao space. The density of the target measure is defined w.r.t. the Hausdorff measure of X, not the Lebesgue measure. Other particle-based samplers exist as well. The curr_chunk discusses various particle-based samplers and their applications in different gradient flows. It also mentions the application of control variate in CD-1 and denoising score matching. The text highlights the independence of the derivation from the distribution space chosen and the ability to derive approximations using samplers other than Langevin dynamics. The curr_chunk discusses the use of different sampling algorithms like SVGD, SPOS, and birth-death accelerated Langevin dynamics to derive novel learning objectives. These objectives generalize previous discussions and establish connections between sampling algorithms and learning objectives, potentially useful in various scenarios such as learning kernel exponential family models and direct estimation of the score function. In this section, the authors analyze the variance of two approximations to the score matching objective: CD-1 and denoising score matching. They show that these approximations become unbiased as the step-size hyper-parameter approaches zero but do not perform as well as exact score matching in practice. The analysis leads to the development of novel control variates for these approximations, resulting in variance-reduced versions with comparable performance to the exact score matching objective. The norm represents a noise-corrupted sample, with the optimal denoising direction satisfying \u03c8 = \u03c3 2 \u2207 logp. The stochastic estimator Denotex is derived using Hutchinson's trick, with a finite-variance estimator obtained by subtracting the bias. The CD-K learning rule updates model parameters with a learning rate \u03bd. The CD-K learning rule updates model parameters with a learning rate \u03bd, where p K is obtained from p by running K steps of MCMC. When K = 1 and the sampler is Langevin dynamics, the gradient produced by CD-1 recovers the gradient of the score matching objective. However, CD-1 does not correspond to a valid learning objective, hindering its practical utility. In this section, it is shown that using local coordinates in deriving the MPF objective does not affect the validity of the method. Proposition 3 proves that the local coordinate representation provides a valid approximation to the MVL objective in the compact case. Additionally, Remark 4 argues that using local coordinates does not result in numerical instability. Lemma 2 states that for any manifold M with a normal neighborhood B of x, there exists a constant C > 0 such that the first exit time \u03c4 from B of the Riemannian Brownian motion satisfies certain conditions. Proposition 3 assumes the data manifold X is compact and that E(\u00b7; \u03b8) is in C 1 for all \u03b8. It shows that the true Riemannian Langevin dynamics targeting the WMVL objective can be recovered. The Riemannian Langevin dynamics is discussed in relation to a compact data manifold X and a continuous energy function E. The first exit time of the Riemannian Langevin dynamics is shown to be greater than a certain value, and the proof is completed by showing convergence of a term to zero. This concept is similar to standard augmentation used in stochastic process texts. The standard augmentation used in stochastic process texts involves modifying the algorithm to return 0 if y escapes the chart. Simulating diffusion-based MCMC in local coordinates can lead to numeric instabilities, but in the context of approximating MVL objectives, this is not the case. Different step-sizes and local charts can be used for each sample, making scalable learning algorithms for unnormalized models possible. In the context of scalable learning algorithms for unnormalized models, previous work has been discussed, including a CD-like algorithm by Liu and Wang (2017) and other methods like noise contrastive estimation and Parzen score matching. However, these have not been applied to complex models parameterized by DNNs. The current work introduces a new algorithm in the framework, with a slight generalization when replacing SVGD with SPOS. The minimum probability flow framework studies objectives related to sampling dynamics, but does not lead to scalable learning algorithms for continuous-state unnormalized models. Many of the derived objectives are instances of the Stein discrepancy, helpful for theoretical properties but not for scalable implementations without higher-order derivatives. Proposed estimators are evaluated on low-dimensional synthetic data to show small bias and variance. In this section, the authors evaluate the bias and variance of their estimators using the 2-D banana dataset and an EBM model distribution. They compare their estimators to sliced score matching and present an experiment confirming the effectiveness of their control variate on CD-1. The squared bias is estimated with a stochastic upper bound using 5,000,000 samples. The authors estimate the squared bias using Cauchy's inequality, with bias approaching 0 as K, M approach 0. They choose K = 100, M = 50000 and plot the confidence interval. The model distribution q is chosen as an EBM with parameterized energy function \u03c8(x; \u03b8) using a feed-forward network. \u03c8(x; \u03b8) has 2 hidden layers with Swish activation and spectral normalization. The authors use spectral normalization in a feed-forward network with 2 hidden layers to train an EBM with 100 units per layer. They train the EBM for 400 iterations with a batch size of 200 and a learning rate of 4 \u00d7 10 \u22123. Results show negligible bias for both estimators, with no significant difference in variance between estimators. The authors evaluate their approximation to the Riemannian score matching objective by learning an unnormalized model using a mixture of two von Mises distributions on S1. The energy function is parameterized with a feed-forward network with tanh activation and 2 hidden layers of 100 units each. 50,000 samples are generated from the data distribution for training using full batch training. The authors trained a model with 100 units on a dataset of 50,000 samples using full batch training for 6,000 iterations. They used a learning rate of 5 \u00d7 10 \u22124 and a step-size hyperparameter of 10 \u22125 in the MVL approximation. Results showed that their method is suitable for density estimation on manifolds and effectively addresses the variance issue in CD-1 training. With the introduction of the control variate, CD-1 performs as well as other score matching methods in auto-encoder experiments. The method corrects the score estimation in previous work to ensure a conservative field, leading to slightly worse results in Euclidean-prior auto-encoders. The results for the VAE experiment are slightly worse than (Song et al., 2019), but significantly better for WAE experiments. The implicit hyperspherical VAE result is still better than the implicit Euclidean VAE result reported in (Song et al., 2019). The energy function in this experiment is parameterized using a score-net-inspired method with a feed-forward network. In the WAE experiment on MNIST, the energy network is trained with a step-size of 10^-4. The training setup includes 100,000 iterations using RMSProp, a batch size of 128, and a learning rate of 10^-3. In the VAE experiments, the energy network is trained with a step-size of 10^-4 and L2 regularization with coefficient 10^-5. The WAE-GAN baseline uses Wasserstein GAN with a critic parameterized as a feed-forward network with 2 hidden layers of 256 units. Different parameterizations were tested, including tanh activation, spectral normalization, and L2 regularization with coefficient 10^-4. Training follows a setup of 100,000 iterations using RMSProp, a batch size of 128, and a learning rate of 10^-3, with a fixed Lagrange multiplier hyperparameter \u03bb of 10. The energy network in the VAE experiments is trained with a step-size of 10^-4 and L2 regularization with coefficient 10^-5. The GAN baseline uses standard parameterization for the critic and trains for 100,000 iterations with RMSProp and a learning rate of 10^-4. FID scores are calculated using a specific implementation. The parameter space is d-dimensional, and the tangent space of P(X) is defined in a formal derivation of SPOS. The SPOS sampler is derived as the gradient flow of the KL divergence functional with a new metric. It involves the SVGD update direction and connects to the tangent space of P(X) through a function space H \u03c1,\u03b1. The SPOS sampler is the gradient flow of the KL divergence functional with a new metric on the function space H \u03c1,\u03b1. It involves the SVGD update direction and connects to the tangent space of P(X) through a Riemannian metric. The eigendecomposition of the gradient flow is calculated, and the derivation is completed. The derivation of the MVL objective from SPOS involves the Fisher divergence and the kernelized Stein discrepancy. It connects to SVGD and Langevin dynamics, showing that SPOS corresponds to SVGD with generalized-function-valued kernels. In this section, the relative entropy w.r.t. the Hausdorff measure is derived for a latent-space distribution on a p-dimensional manifold in Euclidean space. The derivation of the MVL objective from SPOS involves the Fisher divergence and the kernelized Stein discrepancy. It connects to SVGD and Langevin dynamics, showing that SPOS corresponds to SVGD with generalized-function-valued kernels. The derivation is largely similar to the Euclidean case, with key details from Federer (2014) theorem."
}