{
    "title": "S14h9sCqYm",
    "content": "In this paper, the focus is on aligning knowledge graphs from different sources or languages, crucial for applications like knowledge graph construction and question answering. The proposed unsupervised framework based on adversarial training aims to align entities and relations in knowledge graphs without or with minimal aligned triplets. This framework can be integrated with existing supervised methods for better alignment accuracy. Knowledge graphs are collections of knowledge facts represented as triplets. They are crucial for applications like question answering and semantic search. Our proposed approach effectively aligns knowledge graphs from different sources or languages using limited aligned triplets as guidance. This approach has been proven effective in both weakly-supervised and unsupervised settings. To construct more unified knowledge graphs, integrating multiple knowledge graphs from different sources or languages is necessary. However, aligning entities and relations across different knowledge graphs is essential before integration. Recent studies focus on aligning entities and relations from a source knowledge graph to a target one by representing them in a low-dimensional space and learning a mapping function. In this paper, an unsupervised approach for knowledge graph alignment is proposed using the adversarial training framework BID11. The approach aims to align entities and relations from a source knowledge graph to a target graph without the need for labeled data. The approach proposed in this paper for knowledge graph alignment involves aligning triplets in the source and target knowledge graphs by improving the plausibility of aligned triplets through a triplet discriminator. This discriminator distinguishes between real triplets in the target graph and those aligned from the source graph, providing a reward function to measure plausibility. The alignment functions are optimized to maximize this reward, forming an adversarial training procedure. The approach for knowledge graph alignment involves addressing mode collapse by matching the posterior entity distribution with the prior entity distribution in the target knowledge graph. This is achieved through an adversarial training framework that can be integrated with existing supervised methods for weakly-supervised alignment. Stochastic gradient descent is used for optimization, with alignment function gradients calculated using the REINFORCE algorithm. The REINFORCE algorithm is used to calculate gradients for alignment functions in knowledge graph embedding. Extensive experiments show the effectiveness of the proposed approach in weakly-supervised and unsupervised settings. Various techniques for knowledge graph embedding have been proposed to preserve semantic similarities, which are utilized as features for knowledge graph alignment. In this paper, the focus is on knowledge graph alignment using only triplets in knowledge graphs for alignment. Unlike other methods that rely on contextual features, this approach incorporates adversarial training for better results in weakly-supervised and unsupervised settings. It belongs to the domain alignment family and aims to improve alignment models. Our approach in knowledge graph alignment utilizes adversarial training for better results in weakly-supervised and unsupervised settings. It belongs to the domain alignment family and aims to map data from one domain to another, with a focus on triplets in knowledge graphs. The approach involves training a domain discriminator to distinguish between data points from different domains and optimizing the alignment function by fooling the discriminator. In knowledge graph alignment, two GANs are used to align knowledge graphs. A triplet discriminator is trained to distinguish between valid and invalid triplets, and entity distribution is matched between aligned and target knowledge graphs using another GAN. Knowledge graphs consist of entities, relations, and triplets. To broaden coverage, knowledge graphs are typically constructed from a single source or language. In knowledge graph alignment, integrating multiple knowledge graphs from different sources or languages requires aligning entities and relations. The problem is defined as aligning entities and relations from a source knowledge graph to a target knowledge graph. Our approach proposes an unsupervised method for learning alignment functions in knowledge graph alignment. By aligning entities and relations between source and target knowledge graphs, we aim to improve the plausibility of aligned triplets expressing true facts. Our approach trains a triplet discriminator to distinguish valid triplets, builds a reward function from it, and uses adversarial training to address mode collapse. The goal is to align entities between knowledge graphs and improve the plausibility of aligned triplets. Our approach integrates unsupervised and supervised methods to align entities and relations between knowledge graphs. It starts by learning entity and relation embeddings, treating them as features for alignment functions. The probability of alignment is defined using a temperature parameter and normalization. The method for learning entity and relation embeddings is introduced, followed by leveraging the triplet discriminator and regularization mechanism to facilitate training the alignment functions. Additionally, a simple supervised method is introduced. In this paper, the method for learning entity and relation embeddings is introduced, followed by leveraging the TransE algorithm for alignment functions training. A simple supervised method is also illustrated, along with the optimization algorithm. The paper introduces a method for learning entity and relation embeddings and utilizes the TransE algorithm for alignment functions training. It also discusses training a triplet discriminator to distinguish between valid and invalid triplets in knowledge graphs. The paper introduces a method for learning entity and relation embeddings using the TransE algorithm for alignment functions training. It discusses training a triplet discriminator to distinguish between valid and invalid triplets in knowledge graphs, where the reward function R measures the plausibility of a triplet. Different reward functions lead to various adversarial training frameworks, with the optimal solution being the distribution of aligned triplets matching the real triplet distribution in the target knowledge graph. During optimization, the gradient for alignment functions cannot be directly calculated due to discrete triplet sampling. The REINFORCE algorithm is used to calculate the gradient. The triplet discriminator provides effective rewards, but some entities in the source knowledge graph align to only a few entities in the target graph. This issue is addressed by constraining the aggregated posterior entity distribution from the alignment functions to match the prior. The aggregated posterior entity distribution is aligned with the prior entity distribution in the target knowledge graph. An entity discriminator is trained to distinguish between the two distributions, enforcing the alignment function to match the prior distribution. The entity alignment function is trained to fool the discriminator by maximizing the objective, integrating unsupervised knowledge graph alignment with supervised methods using labeled data for weakly-supervised approach. The objective function for aligning entity pairs involves maximizing the probability of aligning a source entity to the target entity while minimizing the entropy of the probability distribution. This strategy encourages confident predictions and is optimized using stochastic gradient descent. The alignment functions are pre-trained with labeled data, then fine-tuned with a triplet discriminator and regularization mechanism for better performance. The optimization framework involves updating the triplet discriminator and alignment functions, as well as the entity discriminator and alignment functions. Four datasets are used for evaluation, including knowledge graphs with different triplets and languages. The curr_chunk discusses the datasets used for entity alignment tasks, including FB15k-1, FB15k-2, WK15k(en-fr), and WK15k(en-de). These datasets contain labeled data and test data for evaluating alignment functions. The datasets vary in the percentage of shared triplets and languages used. The dataset used in BID6 for entity alignment tasks is similar to WK15k(en-fr). Various algorithms like supervised word translation, unsupervised word translation, KAGAN-sup, and KAGAN are applied for knowledge graph alignment. KAGAN leverages labeled data for pre-training and fine-tunes the model with a triplet discriminator and regularization mechanism. The KAGAN model includes variants KAGAN-t and KAGAN-e, utilizing triplet GAN and entity GAN respectively for pre-training and fine-tuning. Parameters such as \u03bb, \u03b3, and learning rates are set, with SGD optimization. Training stops if validation performance drops. Results are shown in TAB3. In the supervised setting, the approach outperforms all compared methods on FB15k-1 and FB15k-2 datasets. In weakly-supervised WK15k datasets, performance is comparable or superior with less labeled data. Ablation studies show improvements with triplet discriminator and regularization mechanism. The regularization mechanism (KAGAN-e) improves pre-trained alignment models (KAGAN-pre) and combining them (KAGAN) leads to better results in unsupervised and weakly-supervised settings. Using the regularization mechanism alone achieves impressive results on the FB15k-2 dataset due to leveraging similarity in knowledge graph structures. Integrating the triplet discriminator with the regularization mechanism (KAGAN) solves the problem of mode collapse and achieves the best results in all cases. Different reward functions can be chosen in the approach, leading to different adversarial training frameworks. In this section, different reward functions are compared in adversarial training frameworks on the WK15k datasets. Results show significant improvement with all reward functions, with x 1\u2212x and x yielding the best results. The optimization methods are also compared, with the pre-training and fine-tuning framework outperforming the joint training framework. Additionally, fixing entity/relation embeddings during training is shown to yield better results than fine-tuning them. Visualization results are presented to demonstrate the effects of the approach. Visualization results are presented to intuitively show the impact of the triplet discriminator and regularization mechanism in an unsupervised setting on the FB15k-2 dataset. The PCA algorithm is used to compare entity embeddings with and without the mechanisms, addressing the issue of mode collapse and improving alignment from the source knowledge graph. The paper proposes an unsupervised approach for knowledge graph alignment using an adversarial training framework. The method aligns entities and relations from a source knowledge graph to a target knowledge graph, showing effectiveness in both unsupervised and weakly-supervised settings through experimental results on real-world datasets. The paper proposes an unsupervised approach for knowledge graph alignment using an adversarial training framework. Future plans include learning alignment functions from both source to target and target to source directions to enhance results."
}