{
    "title": "SJlVY04FwH",
    "content": "Min-max formulations in machine learning have gained attention due to deep generative models and adversarial methods. This study focuses on bilinear zero-sum games, analyzing gradient updates for convergence. Alternating updates are shown to converge better than simultaneous ones. This optimization approach is particularly relevant in the context of generative adversarial networks and adversarial training. In the context of machine learning, the search for saddle points in bivariate functions has been a focus. Various algorithms have been proposed over the years, with recent ones tailored for training GANs. However, the convergence behavior of these algorithms in deep learning settings remains poorly understood, especially in non-convex scenarios. In this work, the focus is on studying bilinear zero-sum games to understand min-max optimization. Gradient algorithms converge linearly on these games, with Jacobi and Gauss-Seidel style updates being common. Jacobi updates simultaneously adjust both sets of parameters, while GS updates do so alternately. The focus is on studying bilinear zero-sum games for min-max optimization. Gradient algorithms converge linearly on these games, with Jacobi and Gauss-Seidel style updates being common. Jacobi updates adjust both sets of parameters simultaneously, while GS updates do so alternately. The main goal is to answer questions about solving bilinear zero-sum games and optimal convergence rates. Table 2 summarizes optimal convergence rates for Jacobi and Gauss-Seidel EG algorithms, with \u03b1 denoting the step size and \u03b2 parameters for EG and OGD. The algorithms are introduced in \u00a72, with supporting experiments in \u00a75. \u03c3 1 and \u03c3 n represent the largest and smallest singular values of matrix E, and \u03ba is the condition number. The table shows that in most cases studied, linear convergence is achieved. The study shows that Jacobi and Gauss-Seidel updates converge in most cases, with the former usually converging faster. Generalizing existing gradient algorithms can lead to faster convergence rates. Bilinear games are important for analyzing GAN training and can represent simple GAN formulations. Mathematically, bilinear zero-sum games can be formulated as a min-max problem. The min-max problem for bilinear games can be formulated as min x\u2208R n max y\u2208R n x Ey. Saddle points are found when E is invertible, with b = c = 0. Gradient-based algorithms for min-max optimization have been proposed, but simultaneous gradient descent ascent does not converge for bilinear games. These algorithms belong to the class of general linear dynamical systems. The convergence of k-step linear dynamical systems in bilinear games relies on spectral analysis, specifically on the spectral radius of the characteristic polynomial. Schur's theorem is used to analyze if all roots of the polynomial lie within the unit disk for convergence. Schur's theorem states that a real polynomial is Schur stable if all its roots lie within the unit disk of the complex plane. A real quadratic polynomial is Schur stable if b < 1 and |a| < 1 + b, while a real cubic polynomial is Schur stable if |c| < 1. Jacobi and Gauss-Seidel updates are defined for linear systems in bilinear games. The characteristic polynomials of Jacobi and Gauss-Seidel updates in linear systems simplify subsequent analyses. Gauss-Seidel updates shift lower block triangular matrices one step to the left. Gradient algorithms for finding saddle points in min-max problems are defined. The generalized gradient descent update is defined with step sizes \u03b1 1 and \u03b1 2. Convergence of averaged iterates for convex-concave games is analyzed when \u03b1 1 = \u03b1 2. A generalized version of the EG algorithm is studied, with linear convergence proven for bilinear games under certain restrictions. Optimistic gradient descent (OGD) and the momentum method, a modification of Polyak's heavy ball method, were analyzed in various studies with linear convergence proved for bilinear games. The OGD version with \u03b1 1 = \u03b1 2 = 2\u03b2 1 = 2\u03b2 2 was proven to have linear convergence, while a more generalized version with \u03b1 1 = \u03b1 2 and \u03b2 1 = \u03b2 2 also showed linear convergence. The EG and OGD algorithms can be treated as approximations of the proximal point algorithm for convex-concave games. They converge to saddle points sublinearly for smooth convex-concave games. The algorithms can be specialized to a bilinear function and rewritten as a 1-step or 2-step LDS. The text discusses the formulation of necessary and sufficient conditions for convergence in gradient-based algorithms for bilinear games. It introduces shorthand notations for Jacobi and Gauss-Seidel style updates, presents characteristic polynomials for both updates, and shows that the convergence regions for Gauss-Seidel are often larger than those for Jacobi. The text also mentions the proofs for several theorems and the computation of characteristic equations, along with a scaling symmetry obtained from section 3. The text discusses convergence conditions in gradient-based algorithms for bilinear games. It introduces shorthand notations for updates, presents characteristic polynomials, and shows that Gauss-Seidel convergence regions are larger than Jacobi's. Theorems are mentioned, along with characteristic equation computations and scaling symmetry. Theorem 3.3 (OGD) states that Jacobi and Gauss-Seidel updates achieve linear convergence in generalized OGD if the convergence region of GS updates strictly includes that of Jacobi updates. Theorem 3.4 (momentum) shows that for the generalized momentum method, Jacobi updates never converge, while GS updates converge under certain conditions. This improves upon previous work by considering more general cases of parameters. Theorem 3.4 justifies the necessity of negative momentum for GS updates to converge. The results extend the Stein-Rosenberg theorem to cover nontrivial bilinear games, studying the optimal convergence rates of EG and OGD. The exponent of linear convergence is defined as the spectral radius. The spectral radius is crucial for analyzing convergence rates in gradient algorithms. By generalizing these algorithms, better convergence rates can be achieved. The optimal exponent of linear convergence is determined by tuning parameters such as \u03b1, \u03b2, and \u03b3. Different variations of OGD and EG algorithms have specific conditions for achieving optimal convergence rates. The original OGD algorithm may not always be optimal, as shown in a one-dimensional bilinear game example. A numerical method is provided to find the optimal exponent of linear convergence by scaling polynomials and using a binary search. See details in Appendix D.3. The experiments on a simple bilinear game confirm predicted linear rates. Heat maps of spectral radii for different algorithms are shown in Figure 2, indicating convergence if spectral radius is less than one. Density plots of spectral radii are also provided for EG, OGD, and momentum with Jacobi and GS updates. In experiments with a WGAN learning a Gaussian mean, different optimization algorithms show varied convergence behaviors. Adam diverges, SGD oscillates, and EG converges. Generalized algorithms like EG with scaling exhibit better convergence rates compared to traditional ones. Jacobi and GS updates are compared in terms of convergence. In experiments with a WGAN learning a Gaussian mean, different optimization algorithms show varied convergence behaviors. EG has better convergence rates compared to traditional algorithms. Comparisons between Jacobi and GS updates in terms of convergence are made, showing that GS updates converge even when Jacobi updates do not. Additionally, comparisons between Jacobi and GS updates of Adam are provided in the appendix. In this work, the focus is on the convergence behavior of gradient-based algorithms for solving bilinear games. By connecting to discrete linear dynamical systems and using Schur's theorem, necessary and sufficient conditions for gradient algorithms are provided. Results indicate that Gauss-Seidel updates converge more easily than Jacobi updates. Optimal exponents of linear convergence for EG and OGD are found, along with a numerical method for determining the exponent. Experimental validation of theoretical findings is conducted, suggesting further analysis and exploration of future directions, including potential applications to more general games like GANs. The text discusses the convergence behavior of gradient-based algorithms for solving bilinear games, connecting to linear dynamical systems and Schur's theorem. It suggests extending the results to more general games and exploring applications to constrained cases and stochastic noise. The Proximal Point (PP) algorithm is also mentioned, with references to previous studies on linear convergence for bilinear games. Rockafellar (1976) studied the linear convergence for bilinear games. Gauss-Seidel PP is not considered due to lack of meaningful solutions. For bilinear games, the inverse matrix can be computed or the spectrum of the original matrix can be analyzed. The characteristic equation can be derived using eigenvalues. Linear convergence is ensured with specific scaling symmetry and notations. The proximal point algorithm guarantees linear convergence for bilinear games. Theorem 2.3 establishes a connection between Jacobi and Gauss-Seidel updates. Jacobi updates have a characteristic polynomial of p(\u03bb, 1) while Gauss-Seidel updates have p(\u03bb, \u03bb). The block linear iterative process in Jacobi updates involves decomposing matrices into lower block triangular and upper parts. The convergence behavior of the block linear iterative process in Jacobi and Gauss-Seidel updates is governed by the largest modulus of the roots of the characteristic polynomial. The Gauss-Seidel update can be rewritten elegantly, and its convergence is also determined by the characteristic polynomial's roots. A real quadratic polynomial is Schur stable if certain conditions are met. A real cubic polynomial is Schur stable if |c| < 1. The proof involves conditions for quartic polynomials and simplifying inequalities to determine stability. The Schur condition for cubic and quadratic polynomials is derived, completing the proof. The proof is now complete in Appendix C.4 and C.5, deriving exact forms of LDSs and characteristic polynomials for gradient-based methods. Using Schur's complement, the update equations and characteristic polynomials for Gradient Descent and Extra-gradient methods are computed. The characteristic polynomials for Optimistic Gradient Descent and Momentum method are derived using spectral decomposition and Lemma C.1. The equations for Jacobi OGD and GS updates are obtained by taking determinants and applying Theorem 2.3. The characteristic polynomials for Jacobi GD and Gauss-Seidel GD are derived, showing that Jacobi GD always diverges while Gauss-Seidel GD can have a limit cycle. The Schur conditions are violated for both methods. Linear convergence for Jacobi and Gauss-Seidel updates is achieved under certain conditions related to singular values. The convergence regions of Gauss-Seidel updates strictly include those of Jacobi updates. The characteristic polynomials for both methods can be expressed as quadratic polynomials. Using Corollary 2.1, Schur conditions equations 3.4 and 3.5 can be derived. When \u03b2 1 + \u03b2 2 + \u03b1 2 < 2/\u03c3, the GS convergence region strictly contains that of the Jacobi convergence region. An example is given where Jacobi converges while GS does not under certain conditions. Theorem 3.3 states that for generalized OGD with \u03b1 1 = \u03b1 2 = \u03b1, Jacobi and Gauss-Seidel updates achieve linear convergence under certain conditions. The Jacobi characteristic polynomial is quartic while the GS polynomial is cubic. Schur conditions are derived to determine convergence. The convergence region of GS updates strictly includes that of Jacobi updates. Theorem C.1 from Cheng & Chiou (2007) allows for the derivation of equations 3.8 and 3.9. The relation between the convergence regions of Jacobi OGD and GS OGD is studied, aiming to prove the last sentence of Theorem 3.3. The proof outlines how the Jacobi region is contained within the GS region, considering different cases based on the values of \u03b1, \u03b21, and \u03b22. The third Jacobi condition in equation 3.8 is now redundant, with \u03b1 > \u03b2 1 or \u03b1 < \u03b2 2 for both methods. Solving the quadratic feasibility condition for \u03b1 gives u = (\u03b2 1 \u03b2 2 + 1). The Schur condition for Jacobi and Gauss-Seidel updates reduces to: \u03b2 1 \u2265 \u03b2 2 = 0. Within this larger region, GS Schur condition equation 3.9 is always satisfied. Combining the cases, it is shown that \u03b1 < 0. The Jacobi region is contained in the GS region, with a proof provided in the sub-sub-sections below. The inclusion can be shown by taking specific values for \u03b2 1 and \u03b2 2, and as \u03b1 approaches 0, the Jacobi regions do not contain a certain point described by a singular value in equation 3.8, while all GS regions do. The proof is still missing some details, but can be verified manually or with Mathematica code. The Jacobi region is contained in the GS region, with a proof provided in the sub-sub-sections below. The inclusion can be shown by taking specific values for \u03b2 1 and \u03b2 2, and as \u03b1 approaches 0, the Jacobi regions do not contain a certain point described by a singular value in equation 3.8, while all GS regions do. The proof is still missing some details, but can be verified manually or with Mathematica code. In equation C.33, the first case is not possible, and the only possible case is \u03b2 1 < \u03b1 < (u + \u221a u 2 + tv)/t. The feasibility region can be solved with 0 < b2 < 1 && b2 <= b1 < b2/(2 (1 + b2^2)) + 1/2 Sqrt[(4 + 5 b2^2)/(1 + b2^2)^2]. The Jacobi region is contained in the GS region, with a proof provided in the sub-sub-sections below. The inclusion can be shown by taking specific values for \u03b2 1 and \u03b2 2, and as \u03b1 approaches 0, the Jacobi regions do not contain a certain point described by a singular value in equation 3.8, while all GS regions do. The proof is still missing some details, but can be verified manually or with Mathematica code. Theorem 3.4 states that for the generalized momentum method with \u03b1 1 = \u03b1 2 = \u03b1, the Jacobi updates never converge, while the GS updates converge iff for any singular value \u03c3 of E, we have: This condition implies that at least one of \u03b2 1 , \u03b2 2 is negative. Jacobi momentum never converges due to specific conditions not being satisfied. Gauss-Seidel condition is computed with specific conditions as well. Theorem C.1 provides conditions for simplifying equations, leading to the conclusion that at least one of \u03b21 and \u03b22 must be negative. Three cases are considered, resulting in constraints for \u03b1 that depend on singular values \u03c31 and \u03c3n. Equations C.37, C.38, and C.39 are derived carefully to further analyze the constraints. Theorem C.1 establishes conditions for simplifying equations, indicating that either \u03b21 or \u03b22 must be negative. Equations C.37, C.38, and C.39 are derived to analyze constraints based on singular values \u03c31 and \u03c3n. Further simplification is done by reducing the equations under specific conditions for \u03b1, \u03b21, and \u03b22. The Schur condition defines the convergence region for bilinear games and gradient-based methods. The optimal linear rates for EG and special cases of OGD are studied analytically. The optimal spectral radius is obtained by solving a min-max optimization problem. The spectral radius is determined by solving a min-max optimization problem, where the function r(\u03b8, \u03c3) depends on parameters and singular values. Analyzing EG and special cases of OGD involves expressing r(\u03b8, \u03c3) using root functions of quadratic polynomials. For cubic and quartic polynomials, analytic formulas for the roots exist but are complex to optimize. The optimal linear rates for EG and OGD are based on the conditional number \u03ba := \u03c3 1 /\u03c3 n. The optimal convergence rate of EG and Jacobi updates depends on the conditional number \u03ba := \u03c31/\u03c3n. For Jacobi updates, the min-max problem is solved by setting \u03b21 = \u03b22 = \u03b2. A super-linear convergence rate is achieved when \u03c31 = \u03c3n = \u03c3 and \u03b1 \u2192 0, \u03b2 = 1/\u03c32. The optimization problem simplifies when \u03b21 = \u03b22, reducing to the previous case. The optimization problem involves finding the lower bound for \u03b1 and \u03b2 in different cases to optimize the function. Different choices of \u03b1 and \u03b2 can lead to super-linear convergence rates for Gauss-Seidel updates. By solving a specific equation, the optimization reduces to minimizing over \u03b1 and \u03b2 at both end points. The minimum convergence rate can be achieved at \u03b1 \u2192 0 and \u03b2 = 2/(\u03c31^2 + \u03c3n^2), similar to Jacobi updates. The optimization problem involves finding the lower bound for \u03b1 and \u03b2 to optimize the function. Different choices of \u03b1 and \u03b2 can lead to super-linear convergence rates for Gauss-Seidel updates. The optimal radius is achieved at \u03b21 = \u03b22 = 2/(\u03c31^2 + \u03c3n^2) and \u03b1 \u2192 0. The optimal convergence rate for OGD can be achieved with different choices of \u03b1 and \u03b2. For Jacobi OGD, \u03b1 \u2264 2\u03b2 is required for optimal linear rate. Gauss-Seidel OGD achieves optimal linear rate at \u03b1 = \u221a2/\u03c31. Special cases for spectral radii functions can be studied by solving quadratic polynomials. The characteristic polynomial for Jacobi OGD equation can be factorized to obtain conjugate equations. The spectral radius satisfies a specific condition and is minimized at \u03b1 = 2\u03b2. Supplementary material is provided for Sections 5 and 6, including proofs and experiments on the performance of Jacobi updates compared to GS updates. In some cases, Jacobi updates outperform GS updates, as demonstrated in Appendix E.3 with an example of OGD on bilinear games. The WGAN considered is locally a bilinear game near the saddle point. Training the vanilla GAN with Jacobi updates using Adam shows faster convergence compared to GS updates. The red curve represents the Jacobi polynomial, while the blue curve represents the GS polynomial. Jacobi OGD outperforms GS OGD for certain parameter settings, with a spectral radius of 0.8. Numerical solutions show that Jacobi OGD has better performance with specific parameter values. In this study, numerical solutions for Jacobi and Gauss-Seidel OGD equations were obtained with optimal parameter settings. For Jacobi OGD, the best parameters were \u03b1 = 0.7, \u03b2 1 = 0.1, and \u03b2 2 = 0.6, while for Gauss-Seidel OGD, \u03b1 = 1.4, \u03b2 1 = 0.7, and \u03b2 2 = 0 were found to be optimal. Additionally, the Gauss-Seidel momentum equation was solved with \u03b1 = 1.8, \u03b2 1 = -0.1, and \u03b2 2 = -0.05, yielding an optimal rate of 0.5. In this study, gradient-based algorithms are interpreted as splitting methods for Jacobi and Gauss-Seidel updates. The inverse for EG always exists, and the splitting method can be applied to second-step methods like OGD and momentum. The bilinear game is considered with a non-singular square matrix E for simplicity, but the general case allows E to be in R m\u00d7n. Saddle points exist if b \u2208. In the general case, saddle points exist if b \u2208 R(E), c \u2208 R(E). The set of saddle points is {(x, y)|y \u2208 N(E), x \u2208 N(E)}."
}