{
    "title": "ByeMHULt_N",
    "content": "While recent work focuses on learning deep discrete latent variable models with variational inference, it remains challenging due to the need for high-variance gradient estimators. An alternative approach is proposed, optimizing a non-ELBO objective derived from the Bethe free energy approximation to an MRF's partition function. This objective leads to a saddle-point learning problem, where inference networks are trained to optimize it. The approach shows promising results in learning high-order neural HMMs on text, outperforming other approximate inference schemes in terms of true held-out log likelihood. Recent interest in learning deep generative models with discrete latent variables has focused on variational inference, particularly with variational autoencoders. Variational inference involves maximizing the evidence lower-bound (ELBO) but may require high-variance gradient estimators when dealing with models with discrete latent variables. In this paper, an alternative objective to the ELBO is proposed for learning discrete latent variable models. The approach involves approximating the intractable log marginal likelihood using the Bethe free energy, which is related to loopy belief propagation. The Bethe free energy can be efficiently evaluated without the need for sampling, making it attractive for models with low-degree factors in the factor graph. Proposing to learn deep, undirected graphical models with latent variables using a saddlepoint objective that utilizes the Bethe free energy approximation to the model's partition functions. Amortizing inference with \"inference networks\" to optimize the objective efficiently without sampling, providing an approximation to the log marginal likelihood. Unlike the ELBO, this approach does not form a lower bound on the log marginal likelihood but can be optimized effectively. In learning deep, undirected graphical models with latent variables, a saddlepoint objective utilizing the Bethe free energy approximation is proposed. This approach optimizes efficiently without sampling and outperforms other inference methods in terms of log likelihood. The factor graph structure is defined, with variable nodes (V), factor nodes (F), and undirected edges (E). The joint distribution factorizes accordingly, with observed variables denoted as x and unobserved variables as z. The potentials functions in deep, undirected graphical models with latent variables are parameterized by \u03b8 and the partition function is denoted as Z(\u03b8). Subvectors x \u03b1 and z \u03b1 participate in the factor indexed by \u03b1, and marginalizing out unobserved variables leads to minimizing a specific function with respect to \u03b8. The Bethe free energy is a function of a parameterized factor graph and its marginals, serving as an approximation of the partition function. The Bethe free energy is defined as an approximation of the partition function in deep, undirected graphical models with latent variables. It is calculated using marginal probabilities of subvectors and factor-neighbors in the graphical model. The Bethe free energy is an approximation of the partition function in deep, undirected graphical models with latent variables. It is calculated using marginal probabilities of subvectors and factor-neighbors in the graphical model. In tree-structured graphical models, the Bethe approximation simplifies expressions by finding a product of marginals. In non-tree-structured models, the Bethe approximation may still work well in practice, but the minimization of the free energy may not correspond to a true KL divergence. The Bethe free energy approximates the partition function in deep, undirected graphical models with latent variables by using marginal probabilities of subvectors and factor-neighbors. Loopy belief propagation corresponds to finding fixed points of an optimization problem with constraints on pseudo-marginal vectors to ensure local consistency in marginals. The Bethe approximation in equation 2 is attractive for factor graphs with many small-degree factors, as it is only linear in the number of factors. This allows for tractable evaluation of the Bethe free energy. MRFs can have arbitrary pairwise dependence, unlike directed graphical models. Learning can be done by minimizing an approximation to the log marginal likelihood using the Bethe approximation. The Bethe free energy, F x, does not consider marginals for settings of x that do not agree with x, resulting in a smaller \u03c4 x compared to \u03c4. This leads to a defined loss approximation and a saddle-point learning problem. LBP is used for pseudo-marginals in deep generative modeling but has limitations. In the context of deep generative modeling, the iterative message-passing algorithm LBP is unappealing due to its slow convergence and sensitivity to message passing order. Instead, trainable inference networks are proposed to predict approximate minimizers of the Bethe free energy, residing in a constraint set C of positive pseudo-marginals summing to one and respecting local consistency. These networks, similar to graph neural networks but simpler, aim to handle these constraints efficiently. The constraints on pseudo-marginals involve linear equality constraints on \u03c4, expressed as A\u03c4 = b, where A consists of constraint rows. In optimization, it is common to optimize over the subspace defined by these constraints. In the context of using inference networks, it is more natural to output vectors of length n, rather than n - m, which depends on the number of constraints. The constraints on pseudo-marginals involve linear equality constraints on \u03c4, expressed as A\u03c4 = b. In optimization, it is common to optimize over the subspace defined by these constraints. In the context of using inference networks, it is more natural to output vectors of length n, rather than n - m, which depends on the number of constraints. Minimizers can be written as V V + \u03c1 +\u03c4, where V + is the Moore-Penrose pseudoinverse of V. Positive constraints are imposed during training to keep predicted pseudo-marginals positive. A linear penalty function is defined to penalize non-positive values in the predicted pseudo-marginals. The training objective involves orthogonal projections and constraints on \u03c4 and \u03c4 x. Approximate inference is used to learn neural HMMs on text with various variational inference methods. Bethe-based objective is compared with other approaches, specifically for undirected models like full HMMs. Neural HMMs and their inference networks are parameterized to model joint distribution over observations and latent variables. The emission distribution is parameterized using softmax function. The emission distribution in Neural HMMs is parameterized using a softmax function. To stabilize training, a word embedding matrix W and layer normalization are utilized. Amortized variational inference with a mean field-like posterior generates approximate posteriors q(z t | x 1:T ) for each timestep t. In a structured inference network, the approximate posterior q(z 1:T | x 1:T ) is not assumed to factorize independently over timestep posteriors. The emission distribution in Neural HMMs is parameterized using a softmax function with a word embedding matrix W and layer normalization for training stability. Amortized variational inference generates approximate posteriors for each timestep. Structured inference networks do not assume independent factorization over timestep posteriors. In the case of Bethe Inference Networks, the inference HMM is parameterized similarly to the neural directed HMM, with transition factors being homogeneous and given by specific equations. In sequential models like HMMs, discrete state embedding vectors are used for parameterization. Factor embeddings are formed by concatenating embedding vectors for each factor and running a bidirectional LSTM. Pseudo-marginals are predicted for each factor using a linear layer applied to the LSTM output. The parameterization of f x (G, x; \u03c6 x ) is similar, with log observation potentials concatenated onto the factor embeddings before feeding them to the LSTM. The text discusses the performance of learning directed HMMs and pairwise MRF HMMs with various objectives and posterior approximations. The models were trained with K = 20 latent states on a dataset of 16,737 sentences. The study evaluated models trained on a dataset of 16,737 sentences using VAE-style and Bethe objectives. Results were based on true perplexity on a held-out sample of 1,585 sentences. Models were sensitive to hyperparameters and random seeds, with the best results reported after a random search. The saddle-point objective F was optimized through alternating maximization and minimization steps. Projection matrices were pre-calculated, and feasible pseudo-marginals could be obtained. Experiments can be replicated using available code. The study evaluated models trained on a dataset of 16,737 sentences using VAE-style and Bethe objectives. Results were based on true perplexity on a held-out sample of 1,585 sentences. Models were sensitive to hyperparameters and random seeds, with the best results reported after a random search. The saddle-point objective F was optimized through alternating maximization and minimization steps. Projection matrices were pre-calculated, and feasible pseudo-marginals could be obtained. Experiments can be replicated using available code. The results obtained by maximizing the true log marginal likelihood of the training data under both the directed and undirected models are compared, showing comparable perplexities between the two models when trained with exact inference. The directed HMM results trained with approximate inference are also discussed. The study evaluated models trained on a dataset of 16,737 sentences using VAE-style and Bethe objectives. Results showed poor performance with approximate inference, leading to a gain of almost 200 points in perplexity over exact inference. Tighter IWAE objectives improved performance slightly, but the most significant improvement came from using a first-order HMM posterior in maximizing the ELBO. However, there is still a perplexity penalty of more than 100 points over exact inference. The study compared different inference methods on models trained on a dataset of 16,737 sentences. Results showed that optimizing F as a saddle point problem in Pairwise MRFs outperformed approximate inference for directed models. Minimizing the F objective using exact marginals yielded similar results to the exact objective, suggesting potential improvements in performance. The study compared different inference methods on models trained on a dataset of 16,737 sentences. Optimizing F as a saddle point problem in Pairwise MRFs outperformed approximate inference for directed models. Despite some drawbacks, the F objective is reasonable for HMM models, but may over or under-estimate perplexity in practice. Finding correlated proxies of perplexity during training is necessary, and alternative approaches to constrained optimization may be needed for some models. Latent-variable MRFs based on the Bethe approximation to the partition function show slightly better held-out perplexities than other inference methods for neural HMMs. Future work will focus on scaling the method to larger MRFs and improving correlation with true perplexity. Empirical investigation on VAE-style gradient estimators in learning a directed 3rd-order neural HMM reveals component-wise standard deviations of the gradient as training progresses. The variational posterior shows substantial variance in estimators every 5 minibatches for the first 350 minibatches. Performance seems to be inversely correlated with variance during training. Model hyperparameters are listed in TAB1. Models were trained with minibatches of size 16 using Adam for MRF models and SGD for directed models."
}