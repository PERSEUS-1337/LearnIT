{
    "title": "H1lDSCEYPH",
    "content": "Generative neural networks require paired input/output datasets for transformation. However, they struggle when faced with unknown target distributions. Generating samples outside the trained data manifold is a challenging problem. Neuron editing is a technique introduced to address the problem of learning transformations in a latent space using an autoencoder. It allows for complex transformations with simpler distribution shifts to neuron activations, working on various data domains. The technique is demonstrated on image transformations and biological applications like removing batch artifacts and predicting drug synergy. Learning transformations from one dataset to another is a common task, but less studied is applying this transformation to a third dataset with no known target. This can lead to issues like domain shift and overfitting. Neuron editing is a technique that addresses this problem by allowing for complex transformations in a latent space using an autoencoder. It has been demonstrated in various domains, including image transformations and biological applications such as predicting drug synergy. Learning transformations from one dataset to another is a common task, with challenges in isolating treatment-induced variation from sample-specific variation. A neural network-based method is proposed for general transformation learning across various data modalities, from image-to-image translation to biological settings. Popular neural network architectures like GANs focus on outputting data in the target distribution space, regardless of the input data source. The generator in neural networks aims to produce output that matches the target distribution, fooling the discriminator. Neuron editing, a proposed method, involves learning transformations in the latent space of an autoencoder neural network with non-linear activations. This approach allows for editing between source and target pairs, without assuming systematic differences between sources. Neuron editing involves extracting differences between source/target activation distributions in a neural network's latent space to generate a synthetic target dataset. This technique can be applied to various architectures, leveraging the autoencoder's denoising ability and training stability. Neuron editing involves extracting differences between source/target activation distributions in a neural network's latent space to generate a synthetic target dataset. Our work differs from previous approaches by not requiring a richly supervised pre-trained model and modeling the shift between distributions as a complex, non-constant function. Comparing to the \"constant-shift\" approach, we demonstrate the necessity of a more complex transformation modeling. Neuron editing involves modeling complex transformations in the internal layer of an autoencoder to influence the output space. It draws connections with domain adaptation, aiming to learn a transformation from known source to target samples that can be applied to an unknown target dataset. This extends domain adaptation by focusing on learning a transformation instead of a classifier for unlabeled data. Neuron editing involves learning a distribution transformation for unlabeled data, different from domain adaptation which aligns features between labeled and unlabeled datasets. Unlike traditional domain adaptation techniques, neuron editing does not require a pre-trained classifier. This approach expands the field by learning transformations on data with known targets and applying them to data with unknown targets. Neuron editing extrapolates better than generative models on two important criteria: it closely resembles the predicted change on the original source dataset and produces more complex variation by preserving existing data variation. Comparisons are made with standard GAN approaches, parametric statistical methods, and alternative autoencoder frameworks. The process involves editing neurons of a trained encoder/decoder to include source-to-target variation and cascading the transformation back into the original data space. Neuron editing involves learning transformations on neuron activations for source data and applying them to extrapolation data. It addresses hurdles like out-of-sample input and complex data variation. The method is motivated by natural image domain transfer on the CelebA dataset and has applications in correcting batch effects and predicting combinatorial drug effects. Neuron editing involves learning transformations on neuron activations for source data to achieve specific properties. Instead of using GANs, a simpler transformation on a space learned by a neural network is employed. An encoder/decoder pair is trained to map data into an abstract neuron space with high-level features. The NeuronEdit transformation is applied to activations from different data distributions without further training. It involves a piecewise linear transformation on neuron activations to achieve specific properties in the abstract neuron space learned by the neural network. The NeuronEdit function operates on distributions of activations over network input samples, transforming them based on the difference between source and target distributions. This transformation is crucial for generating distributions like T and can be applied to X by editing the activations of the internal layer computed by the encoder. The NeuronEdit function transforms activations through the decoder without further training, resulting in a transformed outputX. This turns an autoencoder into a generative model by freezing training and applying transformations exclusively on inference. This approach allows for the network to learn new distributions and not be constrained to producing the identity function. Training a GAN in this setting could exclusively utilize the data in S and T, while neuron editing can model the variation intrinsic to X in an unsupervised manner. GANs are notoriously tricky to train due to oscillating optimization dynamics, uninterpretable losses, and mode collapse, which results in a loss of diversity in the generator's output. Neuron editing avoids common pitfalls in data generation by learning an unsupervised model of the data space using an autoencoder. It isolates the variation in neuron activations to differentiate between source and target distributions. This approach is similar to word2vec embeddings in natural language processing, where transformations like changing gender are represented as constant vectors in a latent space. Neuron editing extends word2vec's vector arithmetic by transforming entire distributions. Comparisons with generation-based approaches like GANs show struggles with criteria. Neuron editing is motivated for inference, contrasting with regularized autoencoders. The study compares neuron editing transformation with a naive \"latent vector arithmetic\" approach. It involves finding a constant vector between the mean of the source and target in an autoencoder's internal layer and applying it to all neurons in the target. Regularized autoencoders penalize differences in distributions using maximal mean discrepancy. Training involved convolutional layers for image experiments and fully connected layers for other models. In a motivational experiment using minibatches of size 100 and the Adam optimizer, a study on socially unbiased neural networks explores the challenge of model performance variations when trained on specific image attributes. The approach of mapping between sets of images with different attributes may lead to decreased performance on unseen data, highlighting the need for models to generalize across diverse populations. The study explores challenges in training neural networks on specific image attributes, such as mapping between images with different attributes like male and blond hair. The GAN models struggle to accurately transform out-of-sample data, often generating artifacts. Neuron editing, using stable training like an autoencoder, shows promise in avoiding these complications. Success is measured using the Frechet Inception Distance metric. Neuron editing achieves the best results in transforming image attributes, with stable training and lower standard deviation compared to GAN-based methods. The complex transformation of changing specific features like hair color is decomposed into a simple linear shift in the neuron space, allowing for general transformations on different attributes. Neuron editing can transform image attributes effectively, showing stable training and lower standard deviation compared to GAN-based methods. It simplifies complex transformations into linear shifts in neuron space, enabling general attribute changes like mustache and glasses. The glasses attribute's bimodal nature is addressed by learning non-constant transformations for sunglasses and reading glasses. Neuron editing also demonstrates its capability in biological batch correction by learning to transform distributions based on separate source/target pairs in cell population analysis. Batch effects are a common issue in biological experimental data that can lead to inaccurate conclusions in analysis. Various models, including deep learning methods, aim to address these technical artifacts. One method for addressing batch effects in biological data is to repeatedly measure an unvarying control set of cells (spike-ins) with each sample of interest. By modeling and removing technical artifacts from the spike-ins, we can correct for batch effects in the sample data. Existing methods of batch correction based on spike-ins operate independently on each dimension and only crudely match distribution statistics. Neuron editing can be applied to a wide range of data types and modalities, including mass cytometry datasets measuring protein levels in cells infected with dengue virus. The spike-ins in the sample data provide an opportunity for deep learning to transform abstract feature spaces and correct for batch effects. In this experiment, four datasets with measurements of 35 proteins are analyzed. The datasets include spike-ins referred to as Control1, Control2, Sample1, and Sample2. A biaxial plot is used to visualize batch effects and biological differences. The goal is to correct artificially low readings of protein IFNg in Sample1 without losing other true biological variations, such as higher amounts of protein CCR6. The study aims to correct low IFNg readings in Sample1 while preserving other biological variations, like higher CCR6 levels. Performance is evaluated by correlating changes in median marker values between spike-ins and samples. Neuron editing outperforms other batch correction methods in the comparison. Neuron editing outperforms other batch correction methods in accurately modeling the true distribution of data, while GANs and traditional batch correction methods perform poorly due to limitations in preserving variation. Regularized autoencoder reproduces input unchanged. PCA embedding in Figure 5a visualizes data space for Control1 and Control2. In Figure 5b, PCA embedding visualizes data space for Control1, Control2, Sample1, and post-transformation Sample1. The transformation from Control1 to Control2 mirrors that applied to Sample1, preserving intra-sample variation. Global assessments show that neuron editing accurately reflects the variation seen in controls. Biological data from a combinatorial drug experiment on cells from patients with acute lymphoblastic leukemia is also considered. The dataset consists of cells under four treatments: no treatment (basal), BEZ-235 (Bez), Dasatinib (Das), and both Bez and Das. In a combinatorial drug experiment on cells from patients with acute lymphoblastic leukemia, cells were treated under four conditions: no treatment (basal), BEZ-235 (Bez), Dasatinib (Das), and both Bez and Das (Bez+Das). The study aimed to predict the effects of applying Das to cells previously treated with Bez, using mass cytometry data on 41 dimensions. The approach of fitting coefficients to an interaction term in a linear regression model limited the model's ability to capture nonlinearity and protein regulatory networks in biological contexts. Neuron editing in cellular function facilitates richer transformation than non-deep learning methods. It accurately predicts transformation direction and magnitude across dimensions, preserving data variation better than GANs. Applying Das shows a decrease in p4EBP1. Neuron editing accurately models changes in p4EBP1 without affecting pSTATS. Residual connections in ResnetGAN still struggle to mimic target distributions due to GAN objective limitations. Future work could involve extending the current single pair distribution learning to multiple distributions, training parallel encoders with the same decoder, or generating conditionally."
}