{
    "title": "S1x8WnA5Ym",
    "content": "Generative models are effective for representing high-dimensional probability distributions and generating realistic images. They can produce multi-modal outputs but are prone to mode collapse during training. This paper introduces a generative model inspired by Determinantal Point Process (DPP) to address mode collapse and improve sample quality. DPP is used to model diversity in real and synthetic data, with a generation penalty term encouraging the generator to produce diverse data similar to real data. Our Generative DPP approach, embedded in adversarial training and variational autoencoder, resists mode-collapse on various datasets like MNIST, CIFAR10, and CelebA. It outperforms state-of-the-art methods in data-efficiency, convergence-time, and generation quality. Deep generative models like GANs and VAEs have gained significant interest for unsupervised learning of high-dimensional data. Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) are two dominant generative approaches in deep learning. GANs involve training a generator and a discriminator to produce high-quality images, but they can suffer from mode collapse where the generator only produces a few modes. To address this issue, Determinantal Point Processes (DPP) are proposed to model diversity within data samples, which has been mainly used for subset selection problems. Our work focuses on modeling diversity within real and fake data during training to address mode collapse in generative models. By back-propagating the DPP metric through the generator, the model learns to cover more modes of the real distribution, reducing mode collapse. This approach differs from previous methods that either improve convergence or enforce diverse mode capture. Our model introduces a new loss function called Generative Determinantal Point Processes (GDPP) to encourage diversity in generated samples. This approach aims to avoid adding extra parameters while converging faster to a fair equilibrium point in training. GDPP is introduced as a complement to the original adversarial loss to address mode collapse in Generative Adversarial Networks. It outperforms other methods in terms of diversity and generation quality, including mapping data back to noise and learning a reconstruction network. Likelihood-free variational inference (LFVI) and VEEGAN incorporate the concept of learning implicit densities using hierarchical Bayesian modeling. BID2 proposed regularization methods for adversarial learning, including mode regularization to address mode collapse and stabilize GAN training. InfoGAN introduces an information-theoretic extension for surrogate objective functions. InfoGAN is an information-theoretic extension of GANs that aims to obtain disentangled data representation through a penalty term in its objective function. BID8's ModeGAN method assumes sufficient samples of every mode in the training data, linking real and generated samples to the same mode. BID28's Unrolled-GAN proposes a new objective for updating the generator based on the unrolled optimization of the discriminator, improving the training process. Improving generator training process to reduce mode collapse problem by using pullback operator to map generated samples to data manifold. Strategies like spectral normalization and gradient penalization have been proposed to stabilize training. These methods are complementary and can be combined to enhance training stability of generator models. Multiple generator and discriminator architectures have been proposed to address mode collapse in GANs. BID24 suggests using two generators with shared parameters to learn the joint data distribution, while BID6 and BID8 introduce multiple discriminators and generators to improve sample quality. MAD-GAN, proposed by BID8, incorporates multiple generators and one discriminator, forcing different generators to learn unique modes for better coverage. DPP-GAN addresses mode collapse in GANs without the need for extra networks, providing easier and faster training while being less prone to overfitting. BID23 also tackles mode collapse by modifying discriminator input with concatenated samples to improve diversity within real data, but faces constraints due to increased batch size. DPP, a probabilistic measure from quantum physics, offers an efficient way to capture negative correlation in similarity. DPP is a probabilistic measure that captures negative correlation with a similarity measure to quantify diversity within a subset. It is agnostic about the order of items and can model data randomly sampled from a distribution. A determinantal point process on a ground set V is a probability measure on the power set of V, with a symmetric similarity kernel L representing the subset's similarity. The matrix L must be real, positive semidefinite, and all its principal minors must be non-negative. The marginal kernel L contains all information to compute subset probabilities in V. BID20 proposed decomposing L as a Gram matrix, with quality scores q(e i) and normalized feature vectors \u03c6 i. The kernel L is a real positive semidefinite matrix with a geometric interpretation based on eigenvalues. DPP models diverse data representations by utilizing the determinant of the feature matrix. It is a valuable tool for diversity enforcement in tasks like document summarization. The diversity kernel is constructed using a generator and feature extraction function, with the aim of generating similar data points. The diversity kernel LD B is constructed to match fake data diversity kernel LS B to real data diversity kernel LD B. Inspired by DPP, a subset diversity is modeled using a kernel. The feature representations of real and fake batches \u03c6 real and \u03c6 f ake are extracted, and diversity kernels LS B and LD B are constructed. The loss encourages G to synthesize data with diversity LS B similar to real data diversity LD B. Various applications like pose estimation and video summarization have utilized similar techniques for diversity quantification and synthesis. The GDPP loss encourages the generator to sample diverse fake data similar to real data diversity by matching eigenvalues and eigenvectors of DPP kernels. This approach models diversity within real and fake data, optimizing the network to generate samples with similar diversity to the training data. The DPP kernel connects real and fake data manifold structures, simplifying the matching problem during training. A generative model produces a batch of samples following a DPP, with a feature representation constructed using a noise vector inputted to the generator. The aim is to match the diversity kernels of real and generated data batches by comparing their eigenvalues and eigenvectors. The GDPP loss consists of diversity magnitude and structure components, with the structure loss scaled to induce noise invariance in eigenvector similarity learning. This helps mitigate the impact of outlier structures in real data on learning the diversity kernel of fake data. Integrating GDPP loss with GANs and VAEs involves utilizing features extracted by the discriminator and applying normalization to ensure a positive semi-definite matrix. The generator loss of the standard adversarial loss is modified to integrate the GDPP loss into the GAN objective. The key property of the GDPP loss is its generality in matching diversity kernels of real and generated data batches. Integrating GDPP loss with VAEs involves embedding the loss within Variational Auto-Encoders. The process includes feeding input training batches to the encoder, generating fake batches with the decoder, and computing the loss using normalized features. Experimental evaluation focuses on mode collapse and sample quality. The study evaluates the performance of a method on synthetic data to address mode collapse and sample quality issues. The same architecture is used for all models, with a focus on mixtures of Gaussian distributions. The evaluation includes comparing results with previous studies using the same architecture and training paradigm. The study compares different GAN methods on synthetic data to address mode collapse and sample quality. Results show that vanilla-GAN generates high-quality samples but only captures a single mode, while WGAN-GP captures almost all modes but with scattered samples. GDPP-GAN creates a precise representation of the true data distribution. Performance evaluation includes quantifying mode collapse and generation quality. GDPP-GAN outperforms other methods in generating high-quality samples and mode detection, showing a 63% relative improvement in high-quality samples and 15% in mode detection over WGAN-GP on the challenging 1200D dataset. Ablation study on 2D Ring and Grid data demonstrates the individual effects of each component in the loss function. Optimizing the determinant of the structure loss directly increases sample diversity, especially effective on the 2D Ring dataset. However, for more complex data like the 2D Grid, optimizing the determinant fails to represent the true manifold structure. Scaling the structure loss by true-data eigenvalues helps disengage the model from noise and focus on learning the prominent structure. Training data requirements for reaching the same local optima are evaluated on both the 2D Ring and Grid datasets. In the experiment, different GAN methods were trained on mixtures of Gaussians arranged in a ring and a grid. WGAN-GP produced higher quality samples with fewer data, while GDPP-GAN outperformed other methods on sample quality once trained on enough data. Time efficiency was also considered in the evaluation. In the experiment, GDPP-GAN outperformed other methods on sample quality once trained on enough data. Time efficiency was also considered, with GDPP-GAN being the fastest method over other baselines. The experimental setting of state-of-the-art BID11 and BID28 is used to evaluate models on Stacked MNIST and CIFAR10 datasets. On CelebA, the experimental setting of state-of-the-art BID17 is utilized. The robustness of the method is tested using a challenging setting proposed by BID37, with results shown in Table 5 of Appendix C. The focus is on comparing with state-of-the-art methods that adopt a change in the original adversarial loss. The method is shown to be robust to random initialization. Performance of various methods on real datasets is evaluated based on captured modes and KL-divergence for Stacked-MNIST, and Inference-via-Optimization for CIFAR-10. The Stacked-MNIST dataset has 1000 discrete modes created by stacking three MNIST digits. Models are trained for 15,000 iterations, except for DCGAN and unrolled-GAN which require 30,000 iterations. Evaluation is based on the number of recovered modes and divergence between true and fake distributions using 26,000 fake images. GDPP-GAN is used to identify modes in generated images by utilizing a classifier trained on the MNIST dataset. It reduces KL-Divergence and increases the number of modes captured when applied to VAE. An experiment on MNIST assesses mode collapse severity, while CIFAR-10 evaluation includes Inception Score for generation quality. GDPP-GAN outperforms other methods in mode collapse and sample quality on CIFAR and Stacked MNIST datasets. Applying GDPP to VAE reduces IvO by 63%, but both inception scores remain low. Inference-via-optimization is used to measure mode collapse severity by comparing real and generated images. The text discusses optimizing the loss between x and generated image G(z) by modifying the noise vector z to capture more modes. Inception score is used to evaluate image quality, with DCGAN showing the least mode collapse. DCGAN shows unstable training on CIFAR-10, while adding GDPP penalty to the generator loss improves image quality early on. Progressive-Growing GANs are trained with our loss on CelebA dataset, showing improved performance. Unlike CIFAR-10, CelebA dataset only contains faces, not natural scenes, making Inception Score evaluation inaccurate. IvO optimization for large-scale datasets like CelebA can lead to divergence or convergence issues, affecting metric effectiveness. SWD metric evaluates image quality and mode-collapse severity, showing similarity between real and fake images. TAB4 displays SWD metric averages and minimums over the last 10K training iterations, indicating saturation in training loss for all methods. In this work, a novel criterion using Determinantal Point Process (DPP) is introduced to train generative networks to capture diversity similar to real data. The criterion is applied to Generative Adversarial training and Variational Autoencoder by learning a kernel from features extracted from the discriminator/encoder. The GDPP framework does not require extra trainable parameters, operates in an unsupervised setting, and consistently outperforms state-of-the-art methods in generating quality and avoiding mode collapse on synthetic and real image datasets. GDPP-GANs show improved generation quality and stability in training compared to other methods. The GDPP criterion is versatile and can be used with various generative models. Specific network architectures and optimization parameters are detailed for different datasets used in experiments. For Stacked MNIST, CIFAR-10, and CelebA datasets, a learning rate of 2 \u00d7 10 \u22124 is used for both the generator and discriminator in DCGAN training. The training is stabilized by applying a learning rate scheduler with a decay ratio of 1/(#max \u2212 iters) at each iteration. Three data collections are introduced, including a mixture of 2D Gaussian distributions for mimicry and structured knowledge of true data modes' locations. The last collection involves ten 700 dimensional Gaussian distributions in a 1200 dimensional space, mimicking natural image manifolds. Poor initializations can affect generative model results, with GDPP-GAN respecting true data structure even with poor initializations. WGAN-GP tends to map generated data to a dispersed distribution with low quality generations. In a challenging experimental setting, our approach outperforms others by generating 427 modes with high quality on the Stacked MNIST dataset compared to 99 modes by DCGAN in a different setting. Our method shows clear advantages over other methods for CIFAR-10 and Stacked-MNIST, covering 90.6% more modes on Stacked-MNIST and at a higher quality. GDPP-GAN outperforms all baselines on Stacked-MNIST and CIFAR-10 datasets in a challenging experimental setting. The eigendecomposition in the loss function has a runtime analysis of O(n^3), where n is the batch size. The method used batch sizes of 512 for synthetic data and 64 or 16 for real data, showing no significant delay due to eigendecomposition. The eigendecomposition in the loss function has a runtime analysis of O(n^3), where n is the batch size. Our method shows the closest time to the standard DCGAN running time and outperforms all baselines on Stacked-MNIST and CIFAR-10 datasets. The evaluation metric NDB proposed by BID34 assesses mode collapse severity in generative models. The NDB/K metric is used to compare the distribution of samples in different bins between true-data and fake-data distributions. Results from various models on MNIST dataset are compared in Table 7, showing the number of statistically different bins divided by the number of bins K. Lower values indicate better performance."
}