{
    "title": "H1eWPNr224",
    "content": "This paper investigates the robustness of over-parameterized neural network training with first-order methods like gradient descent. It shows that these methods are provably robust to noise on a fraction of labels due to early stopping, shedding light on the empirical robustness of deep networks. This paper focuses on the robustness of overparameterized neural networks to label noise when trained with early stopping. Experiments on the MNIST dataset show that while the network fits the corrupted training data well, it does not generalize to the test data, leading to degraded accuracy. The study focuses on the robustness of overparameterized neural networks to label noise when trained with early stopping. Experiments on the MNIST dataset reveal that the model overfits with many iterations, but with early stopping, the test accuracy remains high even with corrupted labels. This demonstrates the unique generalization and robustness capabilities of overparameterized neural networks combined with early stopping. The paper aims to demystify the surprising robustness of overparameterized neural networks when early stopping is used. It shows that gradient descent is robust to noise on a fraction of labels, finding a model close to initialization that fits only to correct labels after early stopping. The dataset model used in the theoretical results assumes input samples come from clusters on a unit Euclidean ball. A 4-layer neural network is trained on a dataset of 50,000 samples from MNIST with varying label corruptions. The neural network architecture consists of convolutional layers with 64 and 128 kernels, and fully-connected layers with 256 and 10 outputs. There are 4.8 million trainable parameters. The training accuracy is shown for corrupted and uncorrupted labels, as well as the test accuracy. Performance after 200 epochs of Adadelta and with early stopping is depicted. The dataset model assumes input samples come from clusters on a unit Euclidean ball. The data set consists of input/label pairs from clusters with well-balanced points. Cluster centers are distinct unit Euclidean norm vectors. Input data points have a noise level \u03b5 0 and labels belong to K classes. All elements in the same cluster have the same label. The data model assumes elements in the same cluster have the same label. Classes can have multiple clusters, with labels separated by a class separation \u03b4. The model allows for non-linear separability, with a maximum of K \u2264 2\u03b4 + 1 classes. This setup is related to providing polynomial guarantees for learning shallow networks. The data model assumes elements in the same cluster have the same label, with classes separated by a distance \u03b4. The model allows for non-linear separability with a maximum of K classes. Definition 2.1 establishes a notion of separation in neural networks to distinguish cluster centers. The noisy/corrupted dataset model allows for a fraction \u03c1 of corruptions in each cluster. The depicted example shows K = 6 clusters and K = 3 classes with n = 30 data points. Each cluster contains 5 data points with labels \u03b11 = \u22121, \u03b12 = 0.1, and \u03b13 = 1. The network model involves studying neural networks' ability to learn this corrupted dataset model with one hidden layer mapping R d to R. The network in question has an activation function \u03c6, input weight matrix W, and output weight vector v. The output vector v is fixed to simplify the model. The focus is on optimizing the weight matrix W for robust learning. The network's prediction at an input x is determined by the activation function \u03c6. Training involves minimizing empirical risk using quadratic loss and gradient descent with a constant learning rate \u03b7. The main result shows that overparameterized neural networks, trained with gradient descent and early stopping, are robust to label noise. Diversity in the input training data is crucial for reliable learning, especially when input data are similar but have different labels. The notion of diversity is quantified using a condition number related to a covariance matrix involving the activation function \u03c6 and cluster centers. The matrix of cluster centers is defined as \u03a3(C), with the minimum eigenvalue denoted by \u03bb(C). The condition number \u03ba(C) quantifies the ability of the neural network to distinguish between distinct cluster centers, with larger \u03bb(C) indicating more diversity.\u03ba(C) characterizes the distinctness of the cluster centers, with a smaller value indicating more diversity. The condition number \u03ba(C) quantifies the ability of the neural network to distinguish between distinct cluster centers, with larger \u03bb(C) indicating more diversity. Empirical verification shows \u03bb(C) is strictly positive, and for ReLU activation, if cluster centers are separated by distance \u03bd > 0, then \u03bb(C) \u2265 \u03bd 100K 2. Assumptions like \u03bb(C) > 0 for data points provide convergence guarantees for DNNs. The main result is stated with a quantitative characterization of distinctiveness/diversity. The main result presented in the text discusses the properties of gradient descent with early stopping in neural networks. It shows that the solution degrades gracefully as label corruption increases, and provides guarantees on the correct assignment of input samples to ground truth labels. The text discusses the robustness of gradient descent with early stopping in neural networks as label corruption increases. It shows that the final model can correctly classify samples, even with corrupted labels, up to a certain level of corruption. The result is independent of the number of clusters and only depends on the number of classes. Future work aims to improve robustness to allow for a higher number of corrupted labels using multi-output classification neural networks. The result shows that overparameterization is needed when the number of parameters exceeds the number of classes to the power four. The amount of overparameterization is independent of the training data size and only depends on the number of clusters and conditioning of cluster centers. The network weights do not stray far from the initialization, with updates traveling within a certain radius that grows with the square root of the number of clusters. The Rademacher complexity of the function space depends on the distance to initialization and should grow with the square-root of the number of input clusters for expressive learning. In the limit of perfectly clustered data, overparameterization can be improved. Theorem A.1 discusses training with perfectly clustered data, where the initial weight matrix is randomly selected, and gradient descent updates are performed. The number of parameters must satisfy a certain condition with the neural net cluster condition number. The neural net cluster condition number \u03ba(C) is crucial for training with perfectly clustered data. The iterates W\u03c4 have bounded distance from the initial point W0, and the network makes accurate predictions with noise level \u03c1 \u2264 \u03b4/8. Overparameterization can be reduced to kd \u2273 K/2 in the limit of perfectly clustered data. This result is a nontrivial analogue of previous findings, emphasizing the importance of cluster condition number over data points. The cluster condition number is crucial for training with perfectly clustered data. Early stopping enables robustness and generalizable solutions by preventing overfitting to corrupted labels. The network never overfits to the corrupted data in this scenario, and a robust network is trained quickly without the need for early stopping. The model needs to travel a longer distance from the initialization point based on the distance from cluster centers and corruption level. If two close input points have different labels, the network must map them to distant outputs, requiring a large enough network to amplify input differences. A randomly initialized network with isometric properties is formalized in Theorem B.1 for vectors x1, x2, with certain conditions on W, \u03c6', \u03c6'', y1, and y2. The model requires a large network to fit data with corrupted labels, as shown by a lemma. The lemma clarifies that more label corruption within a class necessitates a model with a larger norm. This result emphasizes the importance of network norm over the distance to initialization. The model requires a large network to fit data with corrupted labels, as shown by a lemma. The lemma clarifies that more label corruption within a class necessitates a model with a larger norm. This result emphasizes the importance of network norm over the distance to initialization. Using the triangular inequality, a guarantee on the distance from initialization can be obtained. The model needs to traverse a certain distance to fit corrupted labels perfectly, while the distance to initialization for uncorrupted true labels grows at most by a certain amount after a certain number of iterations. This highlights the gap in required distance for generalization and overfitting. In conclusion, a network with good generalization capabilities and robustness to label corruption can be found within a small neighborhood of the initialization, independent of the corruption level. However, fitting to corrupted labels requires traveling a much greater distance, increasing the search space. In this section, the approach to proving robustness of overparameterized neural networks is outlined. The goal is to fit a general nonlinear model with parameters \u03b8 \u2208 R p, such as neural network weights. Gradient descent iterations with a constant learning rate \u03b7 are used to minimize a nonlinear least-squares loss. The iterations start from an initial point \u03b8 0 and take the form J (\u03b8) is the n \u00d7 p. The approach involves fitting a general nonlinear model with parameters \u03b8 \u2208 R p using gradient descent iterations starting from an initial point \u03b8 0. The hypothesis is that the model has a bimodal spectrum Jacobian matrix, inspired by the clusterable nature of realistic datasets in a nonlinear representation space. The mapping f has a Bimodal Jacobian with respect to complementary subspaces S + and S \u2212, where the Jacobian is approximately low-rank when \u03b1 is small. This assumption is formalized for later reference. Let \u03b2 \u2265 \u03b1 > 0 be scalars, and consider a set D \u2282 R p containing the initial point \u03b8 0. The Jacobian structure of the dataset model has a low-rank property when the input examples are equal to cluster centers. The subspace S+ is determined by the cluster membership, while a bimodal Jacobian structure is observed when data points differ from cluster centers. This bimodal structure is verified in real datasets. In Section D, the Jacobian matrix of real datasets shows a bimodal structure with few large singular values, motivating Assumption 2. This aligns with previous findings on deep networks' Hessian matrices. Our approach argues that the residual vector r lies on subspace S+ in the absence of corruption, and corrupted labels lie on the complement space. The Jacobian mapping J(\u03b8) is associated with a nonlinear mapping. The text discusses the robustness of gradient descent to sparse label corruptions when the Jacobian mapping is low-rank. It introduces the concept of subspace diffusedness and presents a meta result for perfectly clustered data. The initial residual with respect to uncorrupted labels is considered, and gradient descent updates are run with a learning rate. The text discusses the robustness of gradient descent to sparse label corruptions when the Jacobian mapping is low-rank. It introduces the concept of subspace diffusedness and presents a meta result for perfectly clustered data. Gradient descent iterations remain close to the initial point, and estimated labels enjoy sample-wise robustness guarantees. The text discusses the robustness of gradient descent to label corruptions and the importance of a well-conditioned Jacobian. It introduces a meta result for perfectly clustered data and highlights the challenges of fitting corrupted labels with a low-rank model. The text explains the difficulty of fitting corrupted labels with a model that strays far from initialization, emphasizing the importance of early stopping for robustness in gradient descent. The text discusses the impact of label corruption on deep networks and the need for iterates to stray further from the initial model to fit corrupted data. Experiments on the MNIST dataset explore the relationship between loss, accuracy, and label corruption. The experiments study the impact of label corruption on the MNIST dataset and the distribution of loss and Jacobian on the CIFAR-10 dataset. Results show that more corruption leads to a larger distance from initialization. Noise robustness of gradient descent is also assessed using Resnet-20 on CIFAR-10. In the study, the impact of label corruption on the MNIST dataset and the distribution of loss and Jacobian on the CIFAR-10 dataset were examined. The experiments showed that increased corruption led to a greater distance from initialization. The noise robustness of gradient descent was evaluated using Resnet-20 on CIFAR-10, where it was found that the loss distribution of corrupted vs clean samples was separable when 30% of the data was corrupted. Increasing the corruption level to 50% resulted in the distributions overlapping, in line with theoretical predictions. The technical framework utilized a bimodal prior on the Jacobian matrix for a multiclass task. The Jacobian matrix for a multiclass task in a neural network model used for CIFAR-10 has around 270,000 parameters. The Jacobian of the network has few singular values larger than 0.1\u00d7 the spectral norm, whether at initialization or after training. The study focused on the impact of label corruption on the MNIST dataset and the distribution of loss and Jacobian on the CIFAR-10 dataset. The study unfolded a tensor to create a matrix, confirming bimodality with only a few significant singular values. Analyzing the Jacobian matrix revealed that the spectrum remains bimodal even at random initialization. The size of the Jacobian grows with the number of classes, but focusing on the Jacobian provides advantages in requiring only first-order information. The cross-entropy loss concentrates on the class associated with the label, allowing for efficient computation of partial derivatives. The spectrum before and after training remains similar, indicating the bimodal nature of the spectrum. In FIG10, the study verifies findings for a corrupted dataset model with K=2 classes generated randomly on a unit sphere. Input samples are generated around these clusters, ensuring they are at least 1 distance apart. A network with 1000 hidden units trained on 400 samples with 30% corrupted labels shows good classification initially but overfits later on. The model achieves good classification initially but overfits later on. In FIG10, the loss distribution of clean and corrupted data is visualized, showing a resilient gap despite high corruption levels. However, after many iterations, the model overfits, as demonstrated by the overlapping distribution of the two classes, indicating a lack of generalization/robustness. The average Jacobian is defined for analysis. Experimentation is done with a corrupted dataset model. Parameters are set for training with corrupted data. The residuals obey a specific equation. Sparse vectors have small projection on a certain set. Sparse vectors with small projection on a specific set are analyzed. The proof involves bounding the projection of a vector with nonzero entries. The proof is done inductively over gradient descent properties, aiming to show robustness and closeness to initialization despite a low-rank Jacobian model. Sparse vectors with small projection on a specific set are analyzed in the context of bounding the projection of a vector with nonzero entries. The proof is done inductively over gradient descent properties to show robustness and closeness to initialization despite a low-rank Jacobian model. The residual is tracked and partitioned, with conditions ensuring that the iterations stay within a Euclidian ball around the initial point. The range space of the Jacobian is considered, leading to the conclusion that \u03b8 \u03c4 +1 remains within the set D. The proof of \u03b8 \u03c4 +1 \u2208 D follows from the upper bound on the spectral norm of the Jacobian over D. Gradient descent iterate can be written as C(\u03b8 \u03c4 ) is a subset of S +, showing the induction. C(\u03b8 \u03c4 ) contracts the space S +. Claim 2 states that the projection matrix to S+ is a positive semi-definite matrix. The proof utilizes the upper bound on the learning rate and induction hypothesis. The upper bound on the spectral norm of the Jacobian over D is used to show that C(\u03b8 \u03c4 ) contracts the space S+. The space of Jacobian is a subset of S+. Lemma E.4 discusses matrices A and C obeying certain conditions. The proof involves showing that A is greater than or equal to B in a positive semi-definite sense. The induction process is used to establish the final statements. The residual satisfies certain conditions, leading to the conclusion of the proof. The proof involves using induction to establish final statements and bounding the infinity norm of the residual. By controlling the residual term, the proof concludes with the advertised result. If the matrix is sparse and diffused, applying Lemma C.1 yields the desired outcome. If a sparse matrix is diffused, applying Lemma C.1 yields the outcome. Define matrices J+ and J- using Assumption 1 to bound spectral norms. Projecting the residual on S+ and S- yields constraints on the optimization process. Gradient descent may need to traverse a long distance if E- is nonzero. The approach focuses on fitting the residual over the signal space rather than the noise space. The next section formalizes algorithmic guarantees based on the intuition that the solution should learn the signal and avoid overfitting to noise. Definitions for the input dataset and support subspace are introduced, along with the Jacobian of the learning problem. The Jacobian mapping with respect to the input-to-hidden weights has properties of smoothness, bounded top singular value, and well-structuredness at initialization. The Jacobian is not well-conditioned but is structured. The minimum singular value of a matrix over a subspace is defined by projecting the matrix onto the subspace and then finding the minimum singular value. The Jacobian properties at a clusterable dataset include smoothness, bounded top singular value, and well-structuredness at initialization. The smoothness and top singular value of a matrix are bounded at initialization. The range space obeys certain properties with high probability. The Jacobian at the cluster center matrix satisfies the conclusions of the theorem. The clean dataset Jacobian matrix is related to the cluster center Jacobian through row duplication. Each row is duplicated within a certain range. At initialization, the smoothness and top singular value of a matrix are bounded. The Jacobian at the cluster center matrix satisfies certain properties. The entries of p repeat within a range, establishing bounds on singular values. The spectral norm is scaled by at most c up n K. Data points x 1 , x 2 , ..., x n \u2208 R d with unit euclidean norm are aggregated in matrix X \u2208 R n\u00d7d. Labels y \u2208 R n are generated from a noisy dataset. At initialization, the smoothness and top singular value of a matrix are bounded. The Jacobian at the cluster center matrix satisfies certain properties. The entries of p repeat within a range, establishing bounds on singular values. The spectral norm is scaled by at most c up n K. Data points x 1 , x 2 , ..., x n \u2208 R d with unit euclidean norm are aggregated in matrix X \u2208 R n\u00d7d. Labels y \u2208 R n are generated from a noisy dataset. The lemma proves the projection of label noise on the cluster induced subspace for a given dataset. The Jacobian at the cluster center matrix, with rank K and column space S +, shows the difference between noiseless and noisy labels. The error pattern associated with each cluster is analyzed, considering non-overlapping cluster memberships and supports. The projection to subspace S + is represented by the P matrix. The error bound is determined based on the maximum distance between two labels. The text discusses the error analysis within clusters and the bounds on the Jacobian spectrum. It focuses on ensuring a uniform bound for beta and verifying Assumption 2 over a neighborhood of the cluster center matrix. The choice of parameters guarantees certain properties with high probability. The text discusses error analysis within clusters and bounds on the Jacobian spectrum, ensuring a uniform bound for beta and verifying Assumption 2. Parameters guarantee properties with high probability, leading to correct classification of labels, even with noise. The text discusses error analysis within clusters and bounds on the Jacobian spectrum, ensuring a uniform bound for beta and verifying Assumption 2. Parameters guarantee properties with high probability, leading to correct classification of labels, even with noise. DISPLAYFORM0 has mean zero, and by using the fact that weighted sum of subGaussian random variables are subgaussian, we conclude that DISPLAYFORM1 with high probability. Denote average neural net Jacobian at data X via DISPLAYFORM0 T be the input matrix obtained from Definition 1.1. Given weight matrices W 1 , W 2 ,W 1 ,W 2 , we have that DISPLAYFORM1. We first bound DISPLAYFORM2 using results on the spectrum of Hadamard product of matrices. Secondly, DISPLAYFORM4 is bounded by reusing Schur's result and the boundedness of \u03c6. Combining both estimates yields DISPLAYFORM6. The text discusses error analysis within clusters and bounds on the Jacobian spectrum, ensuring a uniform bound for beta and verifying Assumption 2. Parameters guarantee properties with high probability, leading to correct classification of labels, even with noise. Starting from W 0, consider the gradient descent iterations over the losses. The proof is by induction, and at t + 1, via (E.37) we have that DISPLAYFORM11. The proof by induction establishes bounds on the Jacobian spectrum and error analysis within clusters. Theorem 2.2 is obtained by ignoring log terms and treating certain parameters as constants. The theorem addresses training neural nets with corrupted labels in a noisy dataset scenario. The proof by induction establishes bounds on the Jacobian spectrum and error analysis within clusters for training neural nets with corrupted labels in a noisy dataset scenario. The per sample normalized 2 norm bound and total number of prediction errors are analyzed, along with the assignment of input samples to correct ground truth labels. The total distance to initialization is also bounded for any iteration count. The number of iterations is set to achieve small error in the clean input model and to be applicable for gradient descent iterations. Prediction residual vectors are compared between noiseless and original problems. The total distance to initialization is bounded for any iteration count. The text discusses error bounds and classification rates in a model, showing that the total number of errors is at most a certain value. It also demonstrates how to achieve zero error by comparing prediction residual vectors. The text discusses error bounds and classification rates in a model, showing that the total number of errors is at most a certain value. It also demonstrates how to achieve zero error by comparing prediction residual vectors. The argument presented in the current chunk involves bounding terms and distances to ensure correct decision outputs for all samples. In the limit of perfectly clustered data, overparameterization can be improved. This refined result is obtained via a perturbation argument."
}