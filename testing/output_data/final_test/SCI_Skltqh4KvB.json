{
    "title": "Skltqh4KvB",
    "content": "Various methods have been developed to measure unit selectivity in neural networks, but they provide divergent estimates, leading to different conclusions about selective object representations. A comparison of selectivity measures on units in AlexNet shows that precision and class-conditional mean activity selectivity measures give misleadingly high estimates, with the most selective units having poor hit-rates or high false-alarm rates. The most selective units in neural networks had poor hit-rates or high false-alarm rates in object classification, making them ineffective object detectors. No units were found to be as selective as 'grandmother cell' units. Selectivity measures on units in VGG-16 and GoogLeNet also showed poor performance in object classification. Various methods have been used to analyze hidden units in neural networks, but they provide divergent estimates on unit selectivity. The study explores how neural networks exhibit selective responses to object categories, challenging the assumption of distributed representations. Questions arise regarding the functional importance, learning conditions, and relationship to cortical neurons. Direct comparison of selectivity measures and signal-detection methods is conducted to gain a better understanding. The study focuses on assessing single-unit selectivity to object categories in neural networks like AlexNet, VGG-16, and GoogLeNet. Various quantitative and qualitative methods are used to compare selectivity measures, with a particular emphasis on AlexNet trained on ImageNet. Jitterplots are used to visually display how units respond to different image categories. The study by Zhou et al. (2018a) evaluates the selectivity of single hidden units in neural networks like AlexNet, VGG-16, and GoogLeNet. They find that precision and CCMAS measures can be misleading, while signal-detection measures better capture selectivity. Units with interpretable AM images do not necessarily show high selectivity. The Network Dissection method may also provide misleading results for \"object detectors.\" The authors argued that neural networks learn specific representations to co-activate multiple letters or words in short-term memory without ambiguity. Selective units have been observed in hidden layers of CNNs trained for image classification. Selective units have been observed in hidden layers of CNNs trained for image classification, with studies showing highly selective units characterized as 'object detectors'. Different measures of selectivity have been applied across studies, making direct comparisons challenging. Different selectivity measures are frequently used in studies on neural networks. For example, human interpretability and localist selectivity have been used to discuss 'grandmother cells', while precision metrics have been used to claim the importance of object detectors in CNNs. However, conflicting findings suggest that methods focusing on highly selective single units may be misleading. Different selectivity measures are frequently used in studies on neural networks. For example, human interpretability and localist selectivity have been used to discuss 'grandmother cells', while precision metrics have been used to claim the importance of object detectors in CNNs. However, conflicting findings suggest that methods focusing on highly selective single units, such as activation maximization, may be misleading. To directly compare selectivity measures, the study assessed localist, precision, and CCMAS selectivity of units in AlexNet, VGG-16, and GoogLeNet models trained on ImageNet and Places-365 datasets. Various signal detection methods were employed to evaluate selectivity, revealing that precision and CCMAS measures often vary. The precision and CCMAS measures in neural networks may overestimate object selectivity, with the most selective units showing low hit-rates or high false-alarm rates. These units are not accurately described as 'object detectors' but may be sensitive to unknown features weakly associated with the class. Various methods were used to evaluate selectivity in AlexNet, VGG-16, and GoogLeNet models, revealing discrepancies in selectivity measures. The study evaluated selectivity in neural networks using quantitative measures, jitterplots, and activation maximization (AM) images. Few hidden units with interpretable AM images were found to be not highly selective. The analysis was conducted on \u223c1.3M photos from the ImageNet ILSVRC 2012 dataset classified by the pre-trained AlexNet CNN. The study analyzed the fully connected and convolutional layers of the pre-trained AlexNet CNN using jitterplots to depict localist selectivity in neural networks. Activation files are available for correctly classified images. The study analyzed the fully connected and convolutional layers of the pre-trained AlexNet CNN using jitterplots to depict localist selectivity in neural networks. Activation files are available for correctly classified images. Precision method involves identifying critical image patches that drive unit activation. Object detectors are units with precision score > 75%. In this study, the Class-conditional Mean Activation Selectivity (CCMAS) was used to assess class selectivity in neural networks. An activation maximization method called Plug & Play Generative Networks was utilized to generate images that highly activate specific units in the network. Participants were shown 100 images that maximally activated units in different layers of AlexNet and were asked to identify repeating objects, animals, or places. Recall with perfect and 95% precision were used to measure localist selectivity, with the latter allowing for 5% false alarms. Maximum informedness identifies the class and threshold with the highest proportion of images above the threshold and the lowest proportion below it. It summarizes the diagnostic performance based on recall and specificity, computed for each class at each threshold. Sensitivity or recall at Maximum Informedness is the proportion of items from the selected class above the threshold. Network Dissection assesses unit selectivity by computing Intersection over Union (IoU) of annotated input images and spatial activation maps. Units are considered detectors for concepts if IoU exceeds a predefined threshold. Selectivity measures are applied to conv5, fc6, and fc7 layers. The results of selectivity measures on the conv5, fc6, and fc7 layers of AlexNet show high precision and CCMAS scores in multiple units. However, other measures indicate reduced selectivity, with some units having low recall and high false alarm rates. The selectivity measures in the conv5, fc6, and fc7 layers of AlexNet show contrasting results. While some units exhibit high precision and CCMAS scores, others have low recall and high false alarm rates, with a false alarm rate exceeding 99% in one unit. The selectivity levels of units in AlexNet vary, with some showing high precision and specificity while others have low recall and high false alarm rates. The term \"object detector\" implies a higher level of selectivity than 8% recall at perfect precision, suggesting that units must strongly activate for a specific object category with more hits than misses and false alarms. Some units in AlexNet show high precision and specificity, responding strongly to features correlated with specific object categories. However, the pattern of performance does not align with labeling these units as 'object detectors'. Activation Maximization is commonly used to explain what a single unit has learned in CNNs. In a behavioral experiment, 100 Activation Maximization (AM) images were generated for each unit in layers conv5, fc6, and fc8 in AlexNet. A total of 3,299 image panels were used, and 333 volunteers were asked to identify common objects or animals in the images. The study analyzed human recognition of objects in Activation Maximization (AM) images generated for units in different layers of AlexNet. Results showed that fc8 units were most recognizable as objects (71.2%) and matched ImageNet categories consistently (95.4%). In contrast, conv5 and fc6 units had fewer interpretable images (<5%) and weak category matches. This suggests few interpretable units in hidden layers of AlexNet and that image interpretability does not imply high selectivity. The study analyzed human recognition of objects in Activation Maximization (AM) images generated for units in different layers of AlexNet. Results showed that fc8 units were most recognizable as objects (71.2%) and matched ImageNet categories consistently (95.4%). In contrast, conv5 and fc6 units had fewer interpretable images (<5%) and weak category matches, indicating few interpretable units in hidden layers of AlexNet. The selectivity of hidden units in AlexNet was assessed, showing that no units can be characterized as object detectors despite high precision and CCMAS scores. See Fig. 4 for examples of images rated as objects or non-objects by participants. The study analyzed object recognition in different layers of AlexNet. Results showed fc8 units were most recognizable as objects, while conv5 and fc6 units had fewer interpretable images. Despite high precision and CCMAS scores, no units were characterized as object detectors. To address this, jitterplots were displayed for units with high IoU scores in GoogLeNet and VGG-16 trained on Places-365, showing more object detectors in models trained on scene categorization datasets. Selectivity of BUS category was illustrated, revealing some degree of selectivity in the most selective units. The study analyzed object recognition in different layers of AlexNet, showing that the most selective units exhibit some degree of selectivity, with BUS images being more active compared to non-Buses. However, these units are not more selective than those observed in AlexNet, with precision measures and CCMAS scores lower than expected. The most selective VGG-16 unit trained on Places-365 also had lower precision and CCMAS scores compared to other units. Different measures of selectivity lead to different conclusions, and even the most selective units are far from being considered object detectors. Different measures of single-unit selectivity for objects in AlexNet, VGG-16, and GoogLeNet show varying conclusions. While some measures suggest highly selective units in certain layers, others show low levels of selectivity with poor hit-rates or high false-alarm rates. This discrepancy in assessments highlights the complexity of evaluating object selectivity in neural networks. The precision, CCMAS, and Network Dissection measures provide misleading estimates of selectivity in neural networks, leading to mistaken conclusions about unit selectivity for objects in AlexNet, VGG-16, and GoogLeNet. For example, the Network Dissection method identified object detectors in CNNs, but jitterplots and signal detection scores show these conclusions are unjustified. Additionally, Activation Maximization images also provide a misleading estimate of selectivity. The Activation Maximization images provided misleading estimates of selectivity in neural networks, leading to confusion and delayed theoretical progress. The hypothesis that selectivity is reduced in CNNs compared to RNNs has not been considered in the machine learning community. The failure to observe localist units in CNNs like AlexNet suggests contrasting results with RNNs. The emergence of localist units in neural networks supports the co-activation of multiple items in short-term memory. Selective representations in response to the superposition constraint may explain the presence of highly selective neurons in the cortex. The size of the networks may influence the contrasting results between CNNs and RNNs in terms of learning localist units. Authors have reported selective units in larger RNNs with LSTM units, termed 'grandmother cells'. Recent reports also highlight selective representations in Generative Adversarial Networks and Variational Autoencoders. Future work will explore the selectivity of these units and computational pressures to learn highly selective cells. In future work, selective units in larger RNNs with LSTM units, known as 'grandmother cells', will be explored. One hundred generated images were analyzed in layers conv5, fc6, and fc8 in AlexNet. A total of 3,299 image panels were used in the experiment, divided into 64 lists and tested for interpretability by paid volunteers. Participants in the experiment were asked to identify objects in images with over 80% agreement. They were given practice trials before starting the main experiment, which included images of varying interpretability. The images presented to participants were from conv5, and some were agreed to have no obvious object in common. In conv5, human participants identified images with no common objects, while some were recognized as containing 'dogs'. Activation maximization images for units conv5.65, conv5.183, and fc6.1199 were also analyzed. The highest CCMAS score in AlexNet was .94 for unit fc7.31, indicating close to 'perfect' selectivity, but with a low precision score of 11%. This means that although the activation for a given class is high relative to others, the proportion of items from that class in the top 100 activations is low. See appendix Sec. C for more details. Table A2 shows positive correlations between selectivity measures, with moderate correlations between precision and CCMAS, and precision and Recall at 95% precision. All four selectivity measures are negatively correlated with the number of classes in the top 100 active items. The CCMAS measure compares mean activation of a category with all other items, but is problematic due to many units not activating at all for certain images. The CCMAS selectivity is heavily influenced by the proportion of images with an activation value of zero, leading to different estimates of selectivity compared to precision or localist selectivity. A high CCMAS score may not imply selectivity for a class, but rather for a small subset of items within a class. The CCMAS score may not accurately reflect class selectivity, as demonstrated by a unit with a low score despite active items from the same class. The CCMAS scores for the most selective and second most selective categories were similar across different layers. For example, unit fc7.0 had a high CCMAS for 'maypole' but also a high CCMAS2 for 'chainsaw'. In investigating object detectors claimed by Zhou et al. (2018a), focus was placed on units from a single layer reported as 'bus detectors' with an IoU \u2265 .04. Testing was done using the first 100 images per class from the ImageNet 2012 dataset, specifically looking at bus classes. Data for bus unit detectors for different models were analyzed, showing higher mean activation for buses compared to non-buses. The analysis of object detectors focused on units identified as 'bus detectors' with higher mean activation for buses compared to non-buses. However, precision scores were below .6, indicating poor specificity for buses. This suggests that the units may be responding to 'bus-like' features in non-bus objects."
}