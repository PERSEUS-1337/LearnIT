{
    "title": "BJgr4kSFDS",
    "content": "Answering complex logical queries on large-scale incomplete knowledge graphs is a challenging task. Prior work models queries as single points in a vector space, limiting their ability to handle complex queries. The query2box framework proposed here allows reasoning over queries with conjunctions, disjunctions, and existential quantifiers in massive and incomplete KGs by embedding queries as boxes. The query2box framework embeds queries as boxes to handle complex logical queries with conjunctions, disjunctions, and existential quantifiers in large and incomplete knowledge graphs. It can handle arbitrary logical queries in a scalable manner by transforming them into Disjunctive Normal Form, achieving up to 25% relative improvement over existing methods. Knowledge graphs (KGs) capture relationships between entities. Answering logical queries over KGs is crucial in question answering and AI. First-order logical queries can be represented as Directed Acyclic Graphs (DAGs) and reasoned to obtain answers. However, subgraph matching has drawbacks such as exponential complexity and sensitivity to missing relations. Imputing missing relations would only make the KG denser, exacerbating the scalability issue. Recently, a promising alternative approach has emerged for answering logical queries over Knowledge Graphs (KGs) by embedding queries and entities into a low-dimensional vector space. This approach robustly handles missing relations, improves speed, and avoids the issue of modeling a set of active entities with a single point in the vector space. QUERY2BOX is an embedding-based framework for reasoning over Knowledge Graphs that addresses limitations in prior work, such as handling disjunction effectively in the vector space and modeling sets with a single point. It involves obtaining query embeddings through a sequence of box operations and can handle conjunctive queries as well as disjunction. QUERY2BOX is an embedding-based framework for reasoning over Knowledge Graphs that uses boxes to represent sets of entities and execute logical operators efficiently. QUERY2BOX updates boxes based on the query computation graph, handling conjunctive queries by transforming EPFO logical queries into Disjunctive Normal Form. Each conjunctive query in the DNF is represented as individual boxes, with nearest neighbor entities returned as answers. The framework provides strong generalization and is evaluated on standard KG benchmarks. QUERY2BOX is evaluated on standard KG benchmarks and demonstrates strong generalization by answering complex queries not seen during training. It is robust in answering EPFO queries accurately even when relations are missing in the KG, showing up to 25% improvement over baselines. The approach handles a larger subset of first-order logic and embeds queries as boxes for better accuracy and generalization. Related work includes embedding approaches for multi-hop reasoning and structured embeddings associating various concepts with geometric objects. The QUERY2BOX approach utilizes geometric objects to model sets of entities in knowledge graphs, allowing for reasoning over incomplete KGs. It introduces an objective function to learn entity embeddings and geometric logical operators over boxes, enabling accurate answering of complex EPFO queries even with missing relations in the KG. The QUERY2BOX approach uses geometric operators to learn entity embeddings and logical operators over boxes to accurately answer complex EPFO queries on knowledge graphs. The system can generalize to unseen query structures by training on a set of queries and their answers. The KG uses binary output to show directed edges between entities in conjunctive queries, which are a subclass of first-order logical queries. The goal is to find a set of entities that satisfy the query, represented by a dependency graph (DG) that must be a Directed Acyclic Graph (DAG). The computation graph for conjunctive queries in Knowledge Graphs involves using anchor entities as source nodes and a unique sink node as the target. The graph consists of operators like Projection and Intersection applied iteratively to reason and obtain answer entities. This process is akin to traversing KGs following the computation graph structure. Box embeddings are used to efficiently model and reason over sets of entities in the vector space, allowing for the handling of logical operations and disjunction operators in first-order logic. This methodological advance enables the decomposition of complex queries into logical operations executed in the vector space to obtain query embeddings and answers. The box embeddings in the vector space model entities in a set efficiently, with each entity assigned a vector inside a box. The framework reasons over Knowledge Graphs using the embeddings, updating them based on logical operations in the computation graph of the query. The framework utilizes box embeddings to represent entities in a set efficiently, updating them based on logical operations in the computation graph of the query. It describes setting initial box embeddings for source nodes and modeling projection and intersection operators as geometric operators operating over boxes. The framework uses box embeddings to represent entities in a set efficiently, updating them based on logical operations. It models projection and intersection operators as geometric operators operating over boxes, with adaptive box sizes to model different numbers of entities/vectors in the set. The intersection of box embeddings is calculated by performing attention over the box centers and shrinking the box offset using the sigmoid function. Our model utilizes geometric intersection operators to constrain center positions and model shrinking set sizes. It calculates entity-to-box distances based on a fixed scalar, effectively capturing the relationship between entities and boxes. The model uses geometric intersection operators to constrain center positions and shrinking set sizes, calculating entity-to-box distances with a fixed scalar. The training objective involves learning entity embeddings, geometric projection, and intersection operators through negative sampling loss optimization. The model uses geometric intersection operators to constrain center positions and shrinking set sizes, calculating entity-to-box distances with a fixed scalar. The training objective involves learning entity embeddings, geometric projection, and intersection operators through negative sampling loss optimization. In handling a wider class of logical queries, Existential Positive First-order (EPFO) queries are focused on, involving \u2228, \u2203, and \u2227. The computation graphs for EPFO queries are similar to conjunctive queries, with an additional type of directed edge called union. Defining a geometric operator for union and embedding the query poses a challenge for box embeddings due to their location variability in the vector space. Theorem 1 states that for any set of disjoint conjunctive queries, the VC dimension of the function class must be greater than or equal to the number of queries to model any EPFO query accurately. The proof in Appendix A highlights the challenge of introducing a union operation for box embeddings due to their variable location in the vector space. The introduction of the union operation in modeling powersets in a vector space is crucial for accurately representing real-world Knowledge Graphs (KGs). The complexity of the distance function for EPFO queries needs to be as large as the number of KG entities, requiring a dimensionality of \u0398(|V|) for common distance functions. The dimensionality of logical query embeddings needs to be \u0398(|V|) for EPFO queries, which is not scalable for large KGs. To address this, the key idea is to transform queries into Disjunctive Normal Form (DNF) for reasoning in low-dimensional space and aggregating results efficiently. This transformation can be done directly in the computation graph by moving union operations to the last step. The computation graph for EPFO queries is transformed by moving union operations to the last step, simplifying the graph. Nodes with incoming union edges are merged with their parent nodes to create different computation graphs. The final equivalent computation graph is obtained by converting sink nodes into bound variables and creating a new target sink node. The EPFO query computation graph is transformed by moving union operations to the last step, simplifying the graph. Variable nodes are merged with parent nodes to create new computation graphs. A new target sink node is created, and all variable nodes are connected to it. The resulting computation graphs represent conjunctive queries, which can then be used to obtain embeddings. Aggregated distance functions are defined between the EPFO query and entities in the graph. The EPFO query computation graph is simplified by moving union operations to the last step. Aggregated distance functions are defined between the EPFO query and entities in the graph, with computational complexity equivalent to answering N conjunctive queries. In the experiment section, QUERY2BOX aims to discover answers to complex logical queries by predicting missing edges in the KG. Query structures are specified with anchor entities and relations for logical queries. Models are trained on the first 5 query structures. In the experiment section, QUERY2BOX aims to discover answers to complex logical queries by predicting missing edges in the KG. Models are trained on the first 5 query structures and evaluated on all 9 query structures using standard KG benchmarks FB15k and FB15k-237, subsets of Freebase. The KG is augmented with inverse relations to double the number of edges, creating three graphs: G train for training, G valid for validation, and G test for testing. We generate two larger graphs: G valid (G train + validation edges) and G test (G valid + test edges). 9 query structures are considered, with 5 used for training and all 9 for evaluation. Query results are obtained from G train, G valid, and G test. Positive examples are used for training, while at test/validation time, focus is on queries requiring edge imputation for answers. The method validates on non-trivial answers with missing relations, evaluating on queries not seen during training. For each non-trivial answer in a test query, ranking is done using dist box to calculate metrics like MRR and H@K. Results are reported after averaging over queries within the same structure. The evaluation protocol is applied to the validation stage by comparing the framework QUERY2BOX with the state-of-the-art GQE. GQE embeds a query to a single vector and uses the L1 distance between query and entity vectors. A fair comparison is made with GQE-DOUBLE, and the original GQE is extended to handle general EPFO queries using a DNF-query rewriting strategy. Extensive ablation study is also performed. The evaluation protocol compares QUERY2BOX with GQE, which handles general EPFO queries. An extensive ablation study is conducted considering different variants of QUERY2BOX. The method and its variants are listed, including Q2B, Q2B-AVG, Q2B-DEEPSETS, Q2B-AVG-1P, and Q2B-SHAREDOFFSET. Training queries jointly with a minibatch size of 512 queries per query structure is done using an embedding dimensionality of d = 400 and setting \u03b3 = 24, \u03b1 = 0.2 for the loss. In each iteration, a minibatch size of 512 queries is sampled for each query structure, along with 1 answer entity and 128 negative entities. The loss is optimized using Adam Optimizer with a learning rate of 0.0001 over 250 epochs. Comparing QUERY2BOX with GQE on FB15k and FB15k-237 shows significant performance improvement across all query structures. On average, QUERY2BOX achieves 9.8% and 3.8% higher H@3 on the test set compared to the best baselines on FB15k and FB15k-237, respectively. Q2B outperforms GQE on FB15k and FB15k-237 with higher H@3. Increasing embedding dimensionality in GQE has limited performance improvement. Q2B effectively models entities with box embeddings, showing large performance gains compared to GQE-DOUBLE. Q2B performs well on new query structures and intersection modeling using attention mechanism is crucial. Ablation studies in Tables 5 and 6 highlight the importance of attention mechanism in Q2B. Q2B outperforms GQE on FB15k and FB15k-237 with higher H@3. Q2B achieves better performance in answering queries involving intersection operations. On FB15k-237, Q2B obtains significant gains in H@3 compared to Q2B-AVG and Q2B-DEEPSETS. Training on complex logical queries improves reasoning performance. Q2B-AVG-1P excels in 1p and 2u queries but struggles with other types involving logical operators. QUERY2BOX is a reasoning framework that effectively models and reasons over sets of entities and handles EPFO queries in a vector space by transforming logical queries into DNF, embedding conjunctive queries into boxes, and outputting entities closest to their nearest boxes. Adaptive box size is crucial for different queries, as shown by the variant Q2B-SHAREDOFFSET not performing well on all query types due to varying numbers of answer entities. QUERY2BOX is a reasoning framework that effectively models and reasons over sets of entities by embedding conjunctive queries into boxes. It outperforms existing methods in handling diverse logical queries related to EPFO. The model learns entity vectors to represent queries and their corresponding denotation sets. QUERY2BOX is a reasoning framework that models and reasons over sets of entities by embedding conjunctive queries into boxes. It outperforms existing methods in handling diverse logical queries related to EPFO by learning entity vectors to represent queries and their denotation sets. The goal is to find conjunctive queries that are disjoint with each other, using two types of queries: '1p' and '2i'. In QUERY2BOX, two types of queries, '1p' and '2i', are used to generate conjunctive queries with disjoint denotation sets. 308,006 queries of type '1p' are instantiated, with 129,717 having multiple answer entities. A set of queries of type '2i' is created by combining two queries from '1p'. This results in 10,812 conjunctive queries with disjoint denotation sets. In QUERY2BOX, conjunctive queries are generated using query structures '1p' and '2i'. A total of 13,365 queries with disjoint denotation sets are obtained. Training, validation, and test queries of different structures are generated using KG and query structures. Queries are instantiated by assigning entities and relations to nodes and edges in the query structure DAG using pre-order traversal. The QUERY2BOX method generates conjunctive queries using query structures '1p' and '2i' from a Knowledge Graph (KG). Entities and relations are assigned to nodes and edges in a query structure DAG through pre-order traversal. Degenerated queries are filtered out during entity and relation assignment. A post-order traversal of the DAG on the KG starting from anchor nodes provides a set of answer entities. The generated datasets will be publicly available. The QUERY2BOX method generates conjunctive queries from a Knowledge Graph. Validation and test queries are filtered to avoid trivial answers. Experiments are conducted on NELL995, with new splits created for validation and test sets. Queries are sampled similarly to FB15k and FB15k-237. Results are compared. Results comparing query2box and its baselines (GQE and query2box variants) are shown in Tables 13, 14, 15, 16. Query2box outperforms GQE and its variants by a large margin, following a similar trend as the two FB15k datasets."
}