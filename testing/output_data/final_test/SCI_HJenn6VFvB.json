{
    "title": "HJenn6VFvB",
    "content": "The Hamiltonian Generative Network (HGN) is introduced in this paper as the first approach capable of consistently learning Hamiltonian dynamics from high-dimensional observations without restrictive domain assumptions. HGN allows for sampling new trajectories, performing rollouts forward and backward in time, and adjusting the learned dynamics speed. The Hamiltonian Generative Network (HGN) is modified to create Neural Hamiltonian Flow (NHF), a powerful normalizing flow model using Hamiltonian dynamics to model expressive densities. This work demonstrates the value of the Hamiltonian formalism in machine learning by providing a practical demonstration. Predicting environmental dynamics is crucial in both biological and artificial intelligence systems. Hamiltonian dynamics, with its structure-preserving transformations, has been used in physics to unify and categorize physical entities. Hamilton's equations, developed over a century, provide a way to predict a system's future behavior from its current state in phase space. Hamiltonian mechanics induce smooth dynamics with conserved physical quantities and reversible time evolution, useful for machine learning systems. For example, capturing time-reversible dynamics can help agents understand the effects of their actions on the world state. The text discusses the proposal to extend the image manifold hypothesis with a Hamiltonian assumption, suggesting that natural images lie on a low-dimensional manifold within a high-dimensional pixel space. This approach aims to utilize the tools provided by Hamiltonian descriptions of system dynamics to solve outstanding problems in representation learning and generative modeling. The Hamiltonian formalism can be adapted to solve machine learning problems by learning a system's Hamiltonian from data and inferring its abstract phase space from high-dimensional observations. The Hamiltonian Neural Network (HNN) approach addressed the first question by learning Hamiltonians of physical systems from noisy observations. However, addressing the second question requires inferring properties that may not have a physical role in classical mechanics but can still affect behavior, like color or shape. The Hamiltonian Neural Network (HNN) approach addressed learning Hamiltonians from noisy observations but had limitations with scaling to complex video datasets. In contrast, the Hamiltonian Generative Network (HGN) introduces a model that overcomes these restrictions by inferring abstract states from pixels and unrolling learned Hamiltonian dynamics. HGN outperforms HNN significantly on simulated physical systems, producing meaningful samples with reversible dynamics and controllable rollout speeds. The Neural Hamiltonian Flow (NHF) model directly models continuous dynamics using Hamiltonian differential equations, offering computational benefits over standard flow-based models. This approach avoids discretization errors and allows for longer rollouts with slower divergence. The Neural Hamiltonian Flow (NHF) model utilizes Hamiltonian dynamics as normalizing flows, making it computationally cheaper and suitable for modeling physical systems. Unlike other approaches, NHF exploits invertible and volume-preserving Hamiltonian dynamics, distinguishing it from related works like neural ODEs and Hamiltonian Neural Networks. The Hamiltonian Neural Network (HNN) learns Hamiltonian dynamics by training neural network gradients to match the time derivative of a target system. It maps a system's state to a scalar quantity interpreted as the Hamiltonian, satisfying the Hamiltonian equation by minimizing derivatives computed through backpropagation. This learning procedure is applicable when the true state space and its time derivatives are known, rather than from pixel observations. The model learned directly from the ground truth state space, using a concatenated pair of images as input to map to a low-dimensional embedding space. The embedding was treated as an estimate of the system's position and momentum, with an enforced assumption that momentum equals velocity. The approach presented in the paper does not make assumptions on the dimensionality of the learned phase space or the form of momenta coordinates, making it more general and suitable for a wider range of image domains. The Hamiltonian flows transform the initial density using learned dynamics, with Euler updates depicted for simplicity, while a leapfrog integrator is used in practice. The Hamiltonian formalism describes the time evolution of a system in phase space using Hamiltonian equations. The Hamiltonian specifies a vector field over the phase space representing the system's dynamics. Identifying a system's Hamiltonian is a challenging task. Modeling a system's Hamiltonian from raw observations involves inferring the system's state with a generative model and using Hamiltonian equations. The goal is to learn a Hamiltonian from high-dimensional noisy observations, where each observation is a function of the generalised position in phase space. The abstract state and Hamiltonian dynamics are inferred by observing motion sequences discretised into time steps. The Hamiltonian Generative Network (HGN) is a model trained to follow Hamiltonian dynamics in an abstract phase space learned from raw image observations. HGN consists of an inference network, a Hamiltonian network, and a decoder network. The inference network in the Hamiltonian Generative Network (HGN) outputs a posterior over the initial state using a diagonal Gaussian parametrization. Samples from the posterior are mapped to the system's initial state with another function for increased expressivity in the abstract phase space. The Hamiltonian function initializes the system's state as (q,p), using a neural network to map it to a scalar H \u03b3 (s t ) \u2208 R. A leapfrog integrator is used for rollouts in the abstract state space, with a decoder network for deconvolutional tasks. The decoder network used in the system is a deconvolutional network that reconstructs high-dimensional pixel images from a low-dimensional representation vector. The objective function of the system is optimized to reconstruct a sequence of images using a temporally extended variational autoencoder approach, with rollouts generated using Hamiltonian equations of motion in learned phase space. The architecture described above can be modified for flexible density estimation by using normalizing flows to transform a simple prior distribution into a more expressive form. This process involves computationally expensive computations for inverting the flows and calculating the determinants of their Jacobians. The ideal pendulum, mass-spring, and two-and three-body systems were used to train HGN. Recent work has proposed alternatives for flow-based generative models in machine learning, but none have achieved both computationally scalable sampling and density evaluation steps. Normalizing flows require invertibility and volume preservation, properties that Hamiltonian dynamics possess. This is evident through the determinant of the Jacobian induced by the Hamiltonian H. The Neural Hamiltonian Flow (NHF) model is a modification of HGN that acts as a normalizing flow. It involves chaining multiple Hamiltonians to transform a sample from a simple prior to a more expressive final density. Unlike HGN, each step of the flow in NHF can be parametrized separately for greater flexibility. The Neural Hamiltonian Flow (NHF) model involves chaining multiple Hamiltonians to transform a sample from a simple prior to a more expressive final density. Each step of the flow can be parametrised by a different Hamiltonian, and the resulting density is computed without the need for calculating the trace of the Jacobian. NHF is more computationally efficient compared to other flow-based approaches and is a structured form of a Neural ODE flow with volume-preserving properties. The Hamiltonian dynamics impose a structure on the state-space, which can be constraining for density estimation. To address this, the momentum is treated as a latent variable in Hamiltonian Monte Carlo (HMC) literature. This approach avoids splitting the density into disjoint sets, resulting in a data density exclusively parametrised by p(q T ). The ELBO in Eq. 6 is not explicitly in the form of a reconstruction error term plus a KL term. To compare HGN to HNN, four datasets were generated resembling those in Greydanus et al. (2019), with observations of mass-spring, pendulum, two-and three-body systems. Trajectories were generated by sampling initial states, producing a 30-step rollout following Hamiltonian dynamics, adding Gaussian noise, and rendering 64x64 pixel observations. 50,000 train and 10,000 test trajectories were generated for each dataset. The pendulum dataset is more challenging than Greydanus et al. (2019), with fixed radius and initial angle. Mass-spring system dynamics are modeled by Hamiltonian with fixed constants. Pendulum dynamics are modeled by a different Hamiltonian with fixed parameters. Radius is sampled from a uniform distribution for both systems. In an n-body problem, particles interact through an attractive force. The dynamics are represented by a Hamiltonian equation. Two-and three-body problems are considered with specific parameters set. HGN and HNN baseline were tested for learning the dynamics of different systems. The study compared different versions of Hamiltonian Generative Networks (HGN) in learning the dynamics of pendulum and two-body systems. Various modifications of HGN were tested, including versions trained with different integrators and network structures. Results showed that HGN and its modifications performed well in learning the dynamics. The study found that HGN and its modifications learned well on four datasets, while HNN often collapsed to 0 and failed to reproduce dynamics. HGN had significantly better pixel reconstruction MSE compared to HNN versions. The deterministic version of the model produces accurate reconstructions but lacks sampling capabilities, similar to the distinction between autoencoders and VAEs. Using a simpler integrator may be conceptually appealing but sacrifices energy conservation and reversibility properties compared to a more complex integrator. The full version of HGN can reproduce dynamics well, generate diverse samples, and allows for reversible, time-altered rollouts. The NHF model can transform a simple soft-uniform prior distribution into complex densities with multiple modes. It is capable of expressive density modeling using learned Hamiltonian flows, and performs well with various priors, including a Normal distribution. The trained model is interpretable when decomposed into kinetic and potential energies. The NHF model can transform a simple soft-uniform prior distribution into complex densities with multiple modes. It is capable of expressive density modeling using learned Hamiltonian flows. HNN did not learn the dynamics of the system but reconstructed an average image. Mass-spring learned potential energy V (q) with attractors at the modes of the data. NHF performance compared to RNVP baseline is discussed, showing NHF's computational efficiency. The first deep learning approach, HGN, can reliably learn Hamiltonian dynamics from pixel observations. It outperformed the relevant baseline by a large margin on four classical physical systems. Hamiltonian dynamics have useful properties for machine learning, inducing a smooth manifold and vector field in phase space with reversible time evolution. These properties can impact areas like reinforcement learning, representation learning, and generative modeling. The learned Hamiltonian dynamics can be used as normalizing flows for efficient density modeling. The Hamiltonian Generative Network (HGN) consists of an encoder, Hamiltonian transition network, and decoder. The encoder transforms raw training images into a probabilistic prior representation, creating a downsized spatial representation in latent space. The encoder network is a convolutional neural network with 8 layers and uses normalizing flows for efficient density modeling. The final encoder transformer network is a convolutional neural network with 3 layers and 64 filters. The Hamiltonian transition network uses a symplectic integrator to generate subsequent states based on the Hamiltonian equations. It consists of 6 layers with 64 filters each, and a discrete timestep of dt = 0.125. The decoder network decodes the abstract position part of the state back into an output image of the same shape as the input images. The decoder network consists of 3 residual blocks that resize the input image by a factor of 2 using nearest neighbor method. It includes 2 blocks of a one layer convolutional neural network with 64 filters and a leaky ReLU activation function, followed by a sigmoid activation in each block. The final output image is generated with the right number of channels using a one layer convolutional neural network. The optimization is done using Adam optimizer with a learning rate of 1.5e-4, fixing the variance of the decoder and introducing a Lagrange multiplier for the KL term. The Hamiltonian flow in NHF experiments involves soft-plus MLPs for kinetic and potential energy terms, with a parametrized encoder network using ReLU MLPs. Leapfrog integrator is used for approximating the Hamiltonian flow with two steps found to be sufficient. Parameters are optimized using Adam. The Hamiltonian Neural Network (HNN) learns a differentiable function H(q,p) that maps a system's state in phase space to a scalar quantity interpreted as the system's Hamiltonian. This model is trained to satisfy the Hamiltonian equation by minimizing derivatives computed through backpropagation. The Hamiltonian Neural Network (HNN) computes \u2202H \u2202q and \u2202H \u2202p through backpropagation. In the original paper, the Hamiltonian was learned from the ground truth state space directly, rather than from pixel observations. The PixelHNN variant of the HNN can learn a Hamiltonian from images without true state or time derivatives in some cases. This required modifying the model to take concatenated, flattened pairs of images as input. The encoder neural network mapped concatenated image pairs to a low-dimensional embedding space, matching the ground truth dimensionality of the phase space. The latent embedding estimated the position and momentum of the system, with momentum assumed to be the system's velocity. A constraint enforced the relationship between position and momentum latents to aid learning. The loss function is based on the assumption that an image embedding representing the position and velocity of a system will minimize the loss. The embedding space is used as input for an HNN to learn the system's Hamiltonian using the embedding instead of the true system state. This approach enables stable learning in the system. The PixelHNN uses an autoencoding loss to encourage the network embedding to reflect input images. The full loss includes a finite difference estimate of the time derivative of the embedding, weight decay, and Lagrange multipliers. The architecture is reimplemented and trained using the full loss. In this paper, a PixelHNN with HNN, encoder, and decoder subnetworks is used, each parameterized by an MLP. The encoder and decoder MLPs have ReLU nonlinearities and consist of 4 layers with 200 units in each hidden layer. The HNN MLP uses tanh nonlinearities and has two hidden layers with 200 units. To compare performance, a variant of the PixelHNN architecture with the same convolutional encoder and decoder as HGN is also used. Identical hyperparameters are used, and mapping between the convolutional latent space and the vector-valued latent required by the HNN is done using one additional linear layer. The PixelHNN model is trained using stochastic gradient descent with minibatches of size 64 and 15000 training steps. The Adam optimizer with a learning rate of 1e-3 is used. Rollouts are produced using a Runge-Kutta integrator, and datasets are generated similarly to previous work for comparative purposes. The datasets simulate Hamiltonian dynamics using scipy solver. Trajectories are rendered as images with circular objects representing different systems. HGN and HNN were trained for 15000 iterations with batch sizes of 16 and 64 respectively. Smoothed circles without hard edges were used for visualization. In this study, HGN was trained for around 5 epochs and HNN for around 19 epochs, totaling 16 hours. Three methods of numerical integration were explored: Euler, Runge-Kutta, and leapfrog integration. Euler integration estimates future values by extrapolating along the first derivative. The Euler integration method estimates a function's future value by extrapolating along its first derivative, but its errors accumulate rapidly over longer periods. To address this limitation, the four-step Runge-Kutta integration (RK4) method is used, which accumulates multiple estimates of the function's value in the interval [t, t + dt], resulting in a more stable estimate of the function's value. RK4 estimates the state at time t+dt more stably than Euler integration. Symplectic integrators like leapfrog conserve phase space volume, while non-symplectic integrators cause divergence. Leapfrog updates position and momentum variables in phase space. The leapfrog integrator updates position and momentum variables in a way that leapfrogs over each other, making it more stable and accurate than Euler or RK4 integrators. It is a symplectic integrator that preserves the Hamiltonian's special form, ensuring stability over long rollouts. Visual comparisons show the difference between symplectic (leapfrog) and non-symplectic (Euler) integrators. The Hamiltonian Flow defines a density model over the joint space using leapfrog integration. The observable variable represents q T while p T is treated as a latent variable to be marginalized over. The lower bound on the marginal likelihood is derived due to the intractability of the integral using variational distribution."
}