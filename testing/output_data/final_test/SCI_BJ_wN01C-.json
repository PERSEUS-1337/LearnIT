{
    "title": "BJ_wN01C-",
    "content": "Neuromorphic hardware imposes limits on deep network connectivity, while generic hardware and software are more efficient for sparse networks. DEEP R algorithm allows training of sparsely connected neural networks by automatically rewiring connections during supervised training. It maintains a strict limit on the total number of connections, resulting in minor performance loss on benchmark tasks. DEEP R is based on stochastic sampling of network configurations from a posterior. Neural network connectivity is crucial for hardware implementation efficiency. Memory bottleneck affects energy consumption in TPUs and FPGAs. Memory reference consumes significantly more energy than ALU operations in LSTM implementations. Neuromorphic hardware faces limitations on network connectivity due to restricted on-chip memory. The implementation bottleneck in hardware systems like SpiNNaker is due to limited on-chip memory for local processing cores. This limitation will worsen with the increasing number of neurons in deep learning applications. Evolutionary solutions in the human brain show that dynamic synaptic connectivity, with constant rewiring during learning, is crucial for efficient neural network operation. The implementation bottleneck in hardware systems like SpiNNaker is due to limited on-chip memory for local processing cores. Evolutionary solutions in the human brain show that dynamic synaptic connectivity, with constant rewiring during learning, is crucial for efficient neural network operation. Previous methods for simultaneous training and rewiring in artificial neural networks are not known, but there are heuristic methods for pruning larger networks. These methods are useful for downloading a trained network on neuromorphic hardware but not for on-chip training. Several methods have been proposed for reducing connectivity during training. In this paper, the algorithm extends gradient descent with stochastic weight updates to perform Markov Chain Monte Carlo (MCMC) sampling from the posterior distribution, allowing sampling of network structure and imposing a hard constraint on the total number of connections. The training goal is to produce samples \u03b8 with high probability in p * (\u03b8) = 0 if \u03b8 violates the constraint DISPLAYFORM0. The learning dynamics sample from a posterior distribution over network parameters \u03b8 and constrained network architectures. The DEEP R algorithm addresses limited network connectivity during training due to hardware memory constraints. DEEP R guarantees a hard limit on maximal connectivity needed during training by assigning connection parameters and signs to each connection. This ensures that the algorithm achieves the learning goal on network configurations by sampling network weights, biases, and connectivity under given constraints. DEEP R algorithm uses a single index for connections instead of double index for neurons. Sampling from the posterior over \u03b8 is equivalent to sampling from the posterior over network configurations. Gradient updates are performed only on parameters of the algorithm. DEEP R algorithm in practice involves gradient updates on active connections, computed using backpropagation. It includes a cross-entropy error term and a regularization term. A random walk in parameter space is introduced by adding noise to the update. The DEEP R algorithm combines gradient descent on the regularized error function with a random walk in parameter space. Theoretical analysis shows the impact on test classification accuracy for different connectivity levels in feed forward and CNN networks trained on MNIST and CIFAR-10 datasets. Accuracies are compared for various algorithms, with soft-DEEP R not guaranteeing a strict upper bound on connectivity. Iteration number refers to the parameter updates during training. The rewiring has functional consequences discussed in the following paragraph. The DEEP R algorithm involves gradient descent on a regularized error function and a random walk in parameter space. The rewiring aspect of the algorithm ensures a fixed number of active connections during training and minimizes computational demands for dormant connections. The DEEP R algorithm involves gradient descent on a regularized error function and a random walk in parameter space to ensure a fixed number of active connections during training. Testing on MNIST and CIFAR-10 datasets involved a fully connected feed-forward network and a convolutional neural network with specific architectures. The experiments involved training networks using DEEP R, soft-DEEP R, standard training, and randomly chosen connectivity. The connectivity in the last network was not completely random but based on the number of connections found by soft-DEEP R. This approach is expected to yield better performance than treating all layers equally. FIG1 illustrates the setup. The experiments compared the performance of DEEP R, soft-DEEP R, standard training, and randomly chosen connectivity on MNIST and CIFAR-10 datasets. DEEP R achieved a classification accuracy of 96.2% with 1.3% connectivity, dropping to 96.3% with 1.0% connectivity after doubling training epochs. Training on fixed random connectivity performed well for connectivities around 10%. Soft-DEEP R did not guarantee an upper bound on network connectivity and performed worse than DEEP R for networks with low maximum connectivity. On CIFAR-10, DEEP R achieved 84.1% classification accuracy at 5% connectivity, close to fully connected network performance at 20% connectivity. Monitoring newly activated connections in DEEP R showed stable values post-convergence. Rewiring was also tested on recurrent neural networks with BPTT, showing stable dynamics despite differences from feed forward networks. In a test using an LSTM network trained on the TIMIT dataset, rewiring algorithms were applied to all connections, including those to gating units. Performance was initially similar to a fully connected LSTM, but significantly improved with the inclusion of a regularizer in the training objective. Including a regularizer in the training objective improved the setup with 2 regularization, achieving a phoneme error rate of 28.3%. Despite better results reported in the literature using CTC cost function and deeper networks, this study stuck to a simpler setup with a medium-sized network and standard cross-entropy error function. Connectivity was significantly reduced with algorithms DEEP R and soft-DEEP R, outperforming the fully connected baseline at around 10% connectivity. DEEP R performed better than soft-DEEP R and BPTT with fixed random connectivity at various levels. Comparison of DEEP R and soft-DEEP R to pruning algorithms like 1-shrinkage and the algorithm by Han et al. (2015b) in terms of network connectivity constraints during training. DEEP R and soft-DEEP R show better performance in reducing connectivity compared to the pruning algorithms. Despite strict connectivity constraints, DEEP R and soft-DEEP R outperformed unconstrained pruning algorithms on CIFAR-10 and TIMIT at all connectivity levels. On MNIST, larger connectivities showed slightly better pruning results. Additionally, for very low connectivities, rewiring with DEEP R or soft-DEEP R produced reasonable networks while 1-shrinkage failed completely. Error rate evolution of the LSTM on TIMIT also showed interesting results. Observation of error rate evolution in LSTM on TIMIT shows that pruning induced large increases in error rate due to instabilities in recurrent networks. DEEP R had fewer glitches, indicating better sparsification of network connectivity. DEEP R supports transfer learning by continuously exploring network configurations. This adaptability allows for online learning setup adjustments to task demands. The experiment on the MNIST dataset showed transfer learning capabilities in a network trained with DEEP R. Performance improved even after shuffling target classes, indicating information transfer across tasks. The experiment on the MNIST dataset demonstrated transfer learning capabilities in a network trained with DEEP R. Performance improved even after shuffling target classes, suggesting information transfer across tasks. Connectivity for MNIST and CIFAR-10 algorithms was analyzed, with a focus on network sparsity and accuracy. The study also examined performance on the TIMIT dataset and phoneme error rates across training iterations. The hypothesis that early layers developed invariant features to target shuffling was tested by analyzing parameter dynamics and layer weight correlations. The study analyzed the correlation between neuron outputs in subsequent training epochs, finding that early layers learned features invariant to target shuffling. A soft-DEEP R algorithm was introduced for easier theoretical analysis compared to the hard constraints of DEEP R. The convergence in soft-DEEP R is towards the target distribution over network configurations, not a specific parameter vector. The soft-DEEP R algorithm, presented in Algorithm 2, utilizes a random walk for connection parameters, allowing dormant connections to be re-activated at random times. This approach does not impose a hard constraint on network connectivity but uses 1 norm regularization for a soft constraint. However, simulating dormant connections makes the algorithm computationally inefficient for sparse networks. An approximation could involve re-activating silent connections at a constant rate to improve efficiency. The soft-DEEP R algorithm involves re-activating dormant connections at a constant rate, similar to DEEP R but with a strict connectivity constraint. This concept applies to spiking neural networks and standard deep neural networks, using a stochastic differential equation for parameter dynamics. The soft-DEEP R algorithm involves re-activating dormant connections at a constant rate, similar to DEEP R but with a strict connectivity constraint. It applies to spiking neural networks and standard deep neural networks, using a stochastic differential equation for parameter dynamics. Gradient ascent on the log posterior combined with a random walk in parameter space leads to a unique stationary distribution. The network output is interpreted as a multinomial distribution over class labels, with the derivative of the log likelihood equivalent to the negative cross-entropy error. Regularization terms and discretization of time result in parameter updates for non-negative and negative parameters, with a reflecting boundary introduced to avoid divergence. The DEEP R algorithm involves advancing active connections and replenishing dormant ones. A binary constraint vector is used to represent active connections, linking DEEP R to a compound Markov chain operator. The stationary distribution of this Markov chain is determined by the joint distribution. The DEEP R algorithm uses a binary constraint vector to represent active connections, linking it to a compound Markov chain operator. The stationary distribution of this chain is determined by a joint probability distribution. The posterior distribution of DEEP R is identical to soft-DEEP R if connectivity constraints are met. Sampling network architectures with DEEP R and soft-DEEP R is proportional, with DEEP R exclusively visiting architectures with a specific number of active connections. DEEP R algorithm solves a constraint optimization problem by sampling parameter vectors \u03b8 within the space of constrained connectivities. It spends most time in network configurations supporting the desired network function, maintaining active connections with high probability. Related work includes sequential Monte Carlo sampling and stochastic gradient updates in mini-batch learning. BID3 proposed momentum scheme and temperature annealing. DEEP R extends the BID3 algorithm by using stochastic gradient Monte Carlo sampling for parameter updates and network connectivity sampling. It enforces a hard constraint on the network architecture, performing constrained sampling or constrained stochastic optimization. A correct sampler is developed to efficiently handle sparse connection matrices. DEEP R introduces a novel method called random reintroduction of connections to optimize connectivity graph during training while maintaining a bound on the total number of connections. This method ensures that the sign of a weight remains constant during learning, similar to neurobiology principles. DEEP R introduces a novel method of superimposing gradient-driven dynamics with a random walk, inspired by neurobiology. Despite its stochastic nature, DEEP R's learning dynamics are theoretically tractable, converging to a stationary distribution of network configurations. This allows for immediate adjustment to task changes while transferring previously gained competences. Implementations of DEEP R are available on github.com/guillaumeBellec/deep rewiring, with hyper-parameters like learning rate \u03b7 defined for each task independently. DEEP R introduces a novel method of superimposing gradient-driven dynamics with a random walk, with hyper-parameters like learning rate \u03b7 defined for each task independently. The remaining hyperparameters are the regularization coefficient \u03b1 and the temperature T. Performance of DEEP R is not strongly dependent on temperature T, but the choice of \u03b1 is crucial. Ideal values of \u03b1 varied for different datasets, with significant accuracy loss for small deviations. In MNIST, 96.3% accuracy was achieved with \u03b1 = 10^-4 and T = \u03b7^2 * 10^-12. In TIMIT, \u03b1 = 0.03 and T = 0. In CIFAR-10, different \u03b1 values were assigned to each connectivity matrix to reach 84.1% accuracy with 5% connectivity. The main difference between soft-DEEP R and DEEP R is the connectivity constraint. Soft-DEEP R does not have a global connectivity constraint, making it advantageous for generating sparse network solutions without clear connectivity ideas. Performance in soft-DEEP R depends on hyperparameters \u03b1, T, and \u03b8 min, which have inter-dependent relationships. Unlike DEEP R, soft-DEEP R relies more on temperature for performance due to the rate of connectivity. Soft-DEEP R relies more on temperature for performance, with hyperparameters \u03b1, T, and \u03b8 min having inter-dependent relationships. An exhaustive parameter search found that \u221a 2T \u03b7 should be slightly below \u03b1. High \u03b8 min leads to high performance but also sets a lower bound on connectivity. The lower bound can be estimated analytically, with \u03b8 min \u2248 \u2212 DISPLAYFORM0 for targeted connectivity bounds. Different values of \u03b8 min were used for MNIST, TIMIT, and CIFAR-10 datasets to explore connectivity ranges. In TIMIT and CIFAR-10, a simpler strategy was used with fixed relationships \u03b1 = 3/2\u03b8 min, varying only \u03b1 to produce solutions. 1-shrinkage was implemented using the operator \u03b8 \u2190 relu (|\u03b8| \u2212 \u03b7\u03b1) sign(\u03b8) after each gradient descent iteration. Performance was evaluated for different \u03b1 values on a logarithmic scale for sparse connectivity or high accuracy. For MNIST, \u03b1 values ranged from 10^-4 to 10^-12 with optimal n = 9. Pruning phases were implemented following Han et al. (2015b), with multiple training-pruning iterations for increased performance. The training phase involves complete training of the neural network with 2-regularization. Pruning phases are conducted based on the standard deviation of weights within a weight matrix. Grid search is used to optimize the 2-regularization coefficient and quality parameter. The results for MNIST are reported using a standard feed forward network architecture with two hidden layers. In Figure 5, a standard feed forward network architecture with two hidden layers of 200 neurons each and rectified linear activation functions was used for MNIST classification. A learning rate of 0.05 and batch size of 10 with stochastic gradient descent were employed. Learning stopped after 10 epochs, and performance was evaluated based on classification error on the MNIST test set. The hyper-parameters for DEEP R, soft-DEEP R, pruning, and 1-shrinkage algorithms were chosen from the tensorflow 2 tutorial for convolutional networks. For training algorithms like DEEP R and soft-DEEP R, a decreasing learning rate was used with a high temperature parameter to increase connection re-activation. Weight decay was accompanied by annealing of the temperature. The TIMIT dataset was preprocessed for LSTM architecture with 12 MFCC coefficients and log energy computed for input time series. The TIMIT dataset was preprocessed for LSTM architecture with MFCC coefficients and log energy computed for input time series. 61 phonemes were grouped into 39 output classes to report error rates comparable to the literature. A validation set and early stopping were used to train a network with dense connectivity matrix on TIMIT. Trained for 40 epochs using mini-batches of size 32 and the ADAM optimizer with a learning rate of 0.01. Changing a parameter improved stability in fully connected networks during training. Applied 1-shrinkage after each iteration of ADAM, reaching minimal error rate with this setup. The performance of networks depended strongly on initial connectivity. Heuristics were followed to generate initial connectivity for DEEP R, soft-DEEP R, and control setup with fixed connectivity. Learning time increased and performance dropped if initial connectivity matrices were not chosen carefully. Typically, performance dropped drastically if the output layer was initialized to be very sparse. The number of parameters is dominated by large connectivity matrices to hidden layers. The number of parameters is mainly influenced by large connectivity matrices to hidden layers. A rule of thumb suggests equal active connections for large and intermediate weight matrices, with output layers being densely connected. Two approaches are recommended to refine this rule: analyzing connectivity matrices after convergence of DEEP R or soft-DEEP R, or initializing soft-DEEP R with a dense matrix and observing the connectivity matrix after convergence. In experiments, the connectivities after convergence aligned with the rule of thumb, eliminating the need for an intensive search for ideal initial connectivity matrices. For MNIST, the number of parameters in each layer was 235k, 30k, and 1k from input to output, following the suggested rule of thumb for a given global connectivity p0. The layers were initialized with different connectivities for a given global connectivity p0. For CIFAR-10, the baseline network had specific filter shapes and fully connected layers. The number of parameters per connectivity matrices varied. For TIMIT, the connection matrix sizes and connectivity values were specified. Weight matrices were initialized accordingly. The weight matrices for CIFAR-10 were initialized based on the reference implementation, while for MNIST and TIMIT, they were initialized with specific parameters. To address the issue of dormant connections becoming active after a single noisy iteration in soft-DEEP R, parameters of dormant connections were uniformly initialized between a clipping value and zero. An experiment variant of MNIST involved shuffling target labels after each training epoch to enhance generalization capability. The generalization capability of DEEP R over a small number of epochs was enhanced by shuffling target labels after every training epoch. Noise exploration was increased by setting batch size to 1 for updating connectivity matrices at every time step. Different layers were used for iterations, with varying numbers of potential connections. Parameters for a larger network with 400 neurons in each hidden layer were set, including connectivity constraints and initialization values. DEEP R parameters were also specified. The parameters of DEEP R were set for training on MNIST, with rewiring behavior shown per network layer. Newly established connections were initially small but stabilized proportionally to the total potential connections in each layer. DEEP R continued to rewire connections even late in the training process, with additional details on convergence properties provided. The proof in Algorithm 2 shows that the stochastic parameter dynamics converge to the target distribution in supervised learning. The synaptic sampling dynamics describe how parameters change over time with noise, leading to a distribution of parameters at each time point. The distribution of parameters at each time point is denoted by p FP (\u03b8, t) in the context of stochastic parameter dynamics. The updates of the soft-DEEP R algorithm involve a special case of general discrete parameter dynamics, incorporating automatic network rewiring by applying a nonlinear transformation to determine synaptic weights. The soft-DEEP R algorithm involves a nonlinear transformation to determine synaptic weights, with a parameter \u03b3 that affects the smoothness of the mapping. The gradient of the log-likelihood function can be computed using the sigmoid function. Theorem 1 requires Eq. (12) to be twice differentiable, which holds for any finite value of \u03b3. In simulations, a large \u03b3 results in dormant connections being mapped to zero weight. The soft-DEEP R algorithm involves a nonlinear transformation to determine synaptic weights, with a parameter \u03b3 affecting the smoothness of the mapping. The gradient vanishes for dormant connections, making parameter updates independent of the error gradient. The term \u221a 2T \u03b7 \u03bd k results from the diffusion term, and a reflecting boundary at \u03b8 min is introduced to prevent parameter values from diverging to -\u221e. The DEEP R algorithm converges to a stationary distribution Eq. (4) by evolving parameters \u03b8 and connectivity constraints through Markov chain iterations. Each iteration involves two update steps described in Algorithm 3 using transition operators T \u03b8 and T c. The DEEP R algorithm converges to a stationary distribution by evolving parameters \u03b8 and connectivity constraints through Markov chain iterations. Transition operators T \u03b8 and T c are used in each iteration for updating parameters and connections. The operators draw new samples for \u03b8 and c based on conditional probability distributions. Active connections are updated by advancing the SDE, while dormant connections are randomly selected for activation. The DEEP R algorithm uses transition operators T \u03b8 and T c to update parameters and connections through Markov chain iterations. The constraint C(\u03b8, c) ensures compatibility between parameters \u03b8 and constraint vector c. The transition operator T c (c|\u03b8) samples a new c compatible with \u03b8, with \u00b5(\u03b8) possible vectors. The DEEP R algorithm utilizes transition operators T \u03b8 and T c to update parameters and connections in a Markov chain. The operator T c samples new connections compatible with \u03b8, introducing randomly new connections for missing ones in \u03b8. This process models the connectivity update of Algorithm 3. The transition operator T \u03b8 evolves the parameter vector \u03b8 under the constraint c, producing parameters confined to the connectivity constraint. The transition operator T \u03b8 of the Markov chain updates parameters under the constraint c, leaving a distribution invariant. The proof involves showing the distribution p and its normalization constant equal p * (\u03b8 / \u2208c < 0). The proof involves showing the distribution p and its normalization constant equal p * (\u03b8 / \u2208c < 0). The distribution p * (\u03b8 \u2208c |c) can be factorized by noticing a strong property of this distribution related to the constraint satisfaction. This allows for the separation of the integral over \u03b8 into two simpler integrals. The conditioned posterior can be factorized when the dormant parameters are negative. The operator T \u03b8 also factorizes similarly, splitting into two independent operations. The integration over \u03b8 can be separated into two integrals by ensuring that all factors depend only on \u03b8 \u2208c or \u03b8 / \u2208c. The double integral can be split into two integrals, with the second integral over \u03b8 / \u2208c being simpler due to T \u03b8 being the identity operator. The first integral over active connections \u03b8 \u2208c integrates over a sparse network architecture, aiming to find the relationship between the stationary distribution of the new operator and p * (\u03b8). The tempered posterior of the dense network marginalized and conditioned over dormant connections is equal to the stationary distribution of the SDE in the sparse network. The drift in the SDE of the sparse network is given by the log-posterior of the dense network. The prior and likelihood of the sparse network are defined in terms of the prior and likelihood of the dense network. The prior of soft-DEEP R is defined with zero-weight dormant connections, satisfying a constraint in the sparse network. The posterior of the sparse network is proportional to a specific product, independent of dormant connections. This implies that the posterior of the sparse network is equal to the posterior of the dense network conditioned on negativity. The posterior of the sparse network is proportional to the conditioned posterior of the dense network, implying equality. The SDE evolution of the sparse network leaves the tempered and conditioned posterior of the dense network invariant. The normalization constant L(c) is equal to p * (\u03b8 / \u2208c < 0) and there exists a distribution \u03c0(\u03b8 | c) that is left invariant by the operator T \u03b8. The compound operator T evolves both \u03b8 and c, with T \u03b8 and T c performed sequentially. The distribution left stationary by T is a product of Eq. (33) and a uniform prior over constraint vectors with K active connections. This analysis helps understand the dynamics of Algorithm 3. Theorem 2 analyzes the dynamics of Algorithm 3, stating that under certain assumptions, the Markov chain over \u03b8 and c with specific transition operators leaves the stationary distribution invariant. The proof involves showing an equality that demonstrates the invariance of the tempered posterior of the dense network. The prior p C (c) in Eq. (43) ensures selection of constraints with exactly K active connections. The stationary distribution (43) is unique, as shown by Theorem 2. Algorithm 3 samples the network architecture identified by c from the probability distribution DISPLAYFORM24. DEEP R implements connections becoming negative by setting them to 0, unlike formal algorithm 3 where T c keeps dormant connection parameters constant. DEEP R's practical implementation works well without storing parameters for dormant connections to save memory. The difference between algorithm 3 and DEEP R lies in the treatment of negative connections. While algorithm 3 maintains dormant connections, DEEP R sets them to 0. The convergence properties to a stationary distribution may extend to DEEP R with appropriate priors on negative connections. Overall, algorithm 3 serves as a suitable mathematical formalization of DEEP R for the purposes of the paper."
}