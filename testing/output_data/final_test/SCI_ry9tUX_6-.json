{
    "title": "ry9tUX_6-",
    "content": "Entropy-SGD optimizes a PAC-Bayes bound on the risk of a Gibbs classifier by optimizing the bound's prior, violating the PAC-Bayes theorem. Implementations of Entropy-SGD quickly achieve zero training error on random labels. To obtain a valid generalization bound, an \u03b5-differentially private prior is needed. Using stochastic gradient Langevin dynamics, generalization error on MNIST falls within acceptable limits. In this work, the study focuses on generalization error on MNIST falling within bounds computed under the assumption of perfect samples from SGLD. The goal is to develop high-performance learning algorithms with strong generalization guarantees, as the generalization properties of optimization-based learning algorithms are not well understood. The study focuses on an optimization algorithm called Entropy-SGD BID10, designed to improve generalization error when optimizing empirical risk by maximizing local entropy. This connection to statistical learning theory shows that optimizing local entropy minimizes a PAC-Bayes bound on risk. The study discusses Entropy-SGD, an optimization algorithm aimed at reducing generalization error by maximizing local entropy. Despite connections to PAC-Bayes bounds and theoretical stability claims, Entropy-SGD can still overfit like SGD. The study proposes two changes to control generalization error and prevent overfitting, focusing on optimizing the prior mean. The PAC-Bayes theorem requires an independent prior, but Entropy-SGD disrupts this by optimizing the prior mean, leading to an invalid bound. By incorporating differential privacy through Entropy-SGLD, a data-dependent prior mean can be made \u03b5-differentially private, resulting in a looser generalization bound. Incorporating differential privacy through Entropy-SGLD results in a looser generalization bound, with the distribution of SGLD's output converging weakly to the stationary distribution. While not achieving pure \u03b5-differential privacy, the bounds obtained are reasonably tight but conservative in experiments. When combining differential privacy with PAC-Bayes bounds using Entropy-SGLD, the test error of the learned network can be significantly higher than the state of the art, even when tuned to contribute minimally to generalization error. Chaudhari et al. modified the noise term in SGLD by dividing it by a factor ranging from 10^3 to 10^4, leading to improved empirical results. The modification to the noise term in SGLD by Chaudhari et al. significantly increased the Lipschitz constant of the objective function, impacting the smoothness of the Entropy-SGD objective. This change also affected the differential privacy of the prior mean. By dividing the SGLD noise by a factor of only 4 \u221a m, tighter generalization bounds were achieved compared to previous work. However, these bounds are subject to an approximation regarding the privacy of the prior mean. In this work, a differentially private PAC-Bayes bound is introduced, with experiments on MNIST providing empirical validation. Inspired by previous research on SGD properties, it is noted that SGD can achieve zero training error on MNIST and CIFAR without regularization, while still obtaining weights with very small generalization error. This observation highlights the gap between pure and approximate differential privacy. The first observation indicates that fitting random labels on a large dataset implies a rich set of classifiers accessible to SGD. The second observation suggests that SGD performs capacity control and implicit regularization, leading to generalization even with massive overparametrization. Recent progress in understanding the complexity of ReLU networks has been made by introducing \"path\" norms as a measure. New PAC-Bayes bounds have been developed by perturbing weights learned by SGD, controlled by the flatness of the empirical risk surface and the L2 distance from random initialization. These bounds have shown to be numerically nonvacuous and are correlated with generalization. Advances in spectral norm bounds have been linked to generalization error and distinguishing true labels. This work connects to early regularization schemes based on information-theoretic principles. BID1 provides an information-theoretic argument for a generalization of Hinton and Camp's objective, involving prior and posterior weights. Linear PAC-Bayes bounds are related to this objective for an appropriate range of \u03b2. Varying \u03b2 has been observed to correlate with overfitting on random labels. Our work is related to the connections between varying \u03b2 and overfitting on random label datasets. It also ties into the interest in nonvacuous generalization bounds, particularly in the context of neural networks. Dziugaite and Roy (2017) demonstrated nonvacuous generalization bounds for random perturbations of SGD solutions using PAC-Bayes bounds. This work builds on insights from previous research on nonvacuous bounds for neural networks. The analysis of Entropy-SGLD relies on the stability of a data-dependent prior, which is connected to generalization. It is an instance of differentially private empirical risk minimization, studied in the context of private training via SGD. The analysis also relates to the differential privacy of Bayesian and Gibbs posteriors, and approximate sampling algorithms. The differentially private PAC-Bayes bound uses a data-distribution-dependent prior permitted in the PAC-Bayesian framework. In the PAC-Bayes literature, there is a focus on data-distribution-dependent priors for Bayesian and Gibbs posteriors. Catoni derived bounds on the complexity term KL(Q P (S)||P * (Q P )) using these priors, which are known as \"local\" priors and bounds. In our work, we make a data-dependent but private choice of the prior P = P(S) and use a differentially private PAC-Bayes generalization bound to control the generalization error of the associated Gibbs posterior Q P(S) in terms of KL(Q P(S)||P). We also evaluated differentially private versions of local bounds, where the complexity term is a uniform bound on KL(Q P(S)||P*(Q P)). The bounds were virtually indistinguishable, and so we do not report them here. In the batch supervised learning setting, we aim to choose a predictor with minimal risk under an unknown distribution D on Z. Randomized predictors are represented by probability measures on weight vectors, and empirical risk is studied as a stand-in for true risk. In the context of batch supervised learning, the focus is on characterizing the generalization error in classification tasks. The study involves parametric families of probability-distribution-valued classifiers, where the standard loss function considered is the cross entropy. Entropy-SGD is a gradient-based learning algorithm proposed as an alternative to stochastic gradient descent for better generalization performance in classification tasks. It uses cross entropy loss and is bounded below. The output in binary classification is represented by a probability in [0, 1]. Entropy-SGD is modified to improve stability and control overfitting by optimizing the local entropy surface instead of the empirical risk surface. The algorithm applies stochastic gradient ascent to maximize the objective function F \u03b3,\u03c4 (\u00b7; S), known as the local entropy. Maximizing the local entropy surface in Entropy-SGD aims to achieve \"flat minima\" in the empirical risk surface, leading to good generalization performance. Chaudhari et al. propose a Monte Carlo estimate of the gradient for this purpose. The local entropy is differentiable and its derivative is Lipschitz, contributing to stability and control overfitting. The local entropy in Entropy-SGD focuses on perturbations accepted or rejected based on performance compared to typical perturbations. It concentrates on weight space regions with low empirical risk. Entropy-SGD aims for \"flat minima\" in the risk surface for good generalization. The Entropy-SGD algorithm focuses on achieving flat minima in the risk surface for generalization by scaling the noise term in the stochastic gradient step. The role of thermal noise exponentiates the density defining local entropy, impacting the smoothness analysis. The algorithm's stability analysis does not consider the critical role of the scaling factor \u03b5. The Entropy-SGD algorithm aims to achieve flat minima in the risk surface for generalization by scaling the noise term in the stochastic gradient step. The analysis of Entropy-SGD does not consider the role of \u03b5, which is crucial as it affects the smoothness of the local entropy surface. The Kullback-Liebler divergence of probability measures Q and P is defined, and a PAC-Bayes theorem is presented for bounding the generalization error of a classifier on a finite set of labels K. Theorem 3.1 (PAC-Bayes BID31 BID28) states that under 0-1 loss, for every \u03b4 > 0, m \u2208 N, distribution D on R k \u00d7 K, and distribution P on R p, a PAC-Bayes bound is established. Theorem 3.2 (Linear PAC-Bayes Bound) introduces a bound for any bounded loss function, with specific conditions on \u03bb, L max, \u03b4, m, D, and P. Additional generalization bounds are introduced with the consideration of differential entropy, connecting local entropy to PAC-Bayes bounds through notation for Gibbs distributions. The text discusses the concept of Gibbs distributions and Gibbs posteriors in the context of maximizing local entropy and minimizing a linear PAC-Bayes bound. The linear PAC-Bayes bound is optimized with respect to the mean of a multivariate normal distribution, connecting local entropy to PAC-Bayes bounds through notation for Gibbs distributions. The text discusses the optimization of a linear PAC-Bayes bound with respect to a multivariate normal distribution mean, connecting local entropy to PAC-Bayes bounds through notation for Gibbs distributions. The analysis falls short for unbounded loss functions, as the PAC-Bayes bound used only applies to bounded loss functions. The text discusses PAC-Bayes generalization bounds for unbounded loss functions and the need for knowledge of data distribution to approximate statistics. Theorem 4.1 shows that Entropy-SGD optimizes a PAC-Bayes bound with a data-dependent prior. By optimizing the prior term in a differentially private way, a PAC-Bayes theorem can still hold with a slightly looser bound. The text discusses the PAC-Bayes theorem and differential privacy. It mentions a key result by Dwork et al. (2015b) and provides a theorem for computing tail bounds on generalization error. If a classifier is learned in a differentially private way, the tail bound holds on the classifier with less confidence. The PAC-Bayes theorem allows for choosing the prior based on the data-generating distribution D, not on the data S \u223c D m. Using differential privacy, a data-dependent prior P(S) can be considered. Theorem 5.4 states that under 0-1 loss, for every \u03b4 > 0, m \u2208 N, distribution D on R k \u00d7K, and \u03b5-differentially private data-dependent prior P, the bound holds with P replaced by P(S) if the probability of failure is inflated. Theorem 5.1 provides a bound on the probability of failure based on \u03b4 = 3 \u03b2. If 2m\u03b5 2 \u2264 ln(1/\u03b2), then the probability that S \u2208 R(P(S)) is less than or equal to \u03b4. This bound holds for any posterior Q, including a differentially private version of Theorem 3.1. The constraint between \u03b5, \u03b2, and m can be incorporated via a max operation affecting the confidence interval width. In realistic scenarios, \u03b4 is typically large relative to \u03b5. In realistic scenarios, \u03b4 is large relative to \u03b5, where an \u03b5-differentially private prior contributes to the generalization error. To match the KL term decay rate, \u03b5 must be in O(m^(-1/2)). Entropy-SGD learns weights as the mean of a data-dependent prior, which needs to be \u03b5-differentially private for a risk bound on the Gibbs posterior classifier. Entropy-SGD uses stochastic gradient ascent on negative local entropy with biased gradient estimates from SGLD. Existing privacy analyses of SGD worsen after every iteration due to bias from using SGLD to compute expectations. The exponential mechanism is commonly used for optimizing data-dependent objectives in a private manner. The privacy of sampling from the local entropy distribution is established in Theorem 5.5, with specific conditions on \u03b3 and \u03c4. Theorem 5.5 states that sampling from the local entropy distribution is 2\u03b2 L max \u03c4 m-differentially private, with the proof relying on Lemmas 5.6 and 5.7. Lemma 5.6 establishes the differential privacy of a Gibbs distribution sampling algorithm, while Lemma 5.7 defines F \u03b3,\u03c4 (w; S) and its relation to differential privacy. To optimize the local entropy F \u03b3,\u03c4 (\u00b7; S) in a private way to obtain the prior mean w, the exponential mechanism is used with modifications to address obstructions in cross-entropy loss and sampling from the local entropy distribution. SGLD is employed to generate an approximate sample from the local entropy distribution. Entropy-SGD is modified by adding noise in the outer loop to create Entropy-SGLD. The algorithm utilizes biased gradient estimates via an inner loop of SGLD. Previous privacy analyses of SGLD have focused on delivering (\u03b5, \u03b4)-differential privacy, but do not consider the fact that SGLD converges weakly to the Gibbs distributions. In the analysis, it is approximated that SGLD has the same privacy as its limiting invariant measure. In this section, the privacy of Stochastic Gradient Langevin Dynamics (SGLD) is approximated to be equivalent to the exponential mechanism. The study explores the combination of differentially private optimization and PAC-Bayesian bounds, with a focus on empirical findings and generalization bounds. An empirical study comparing SGD, SGLD, Entropy-SGD, and Entropy-SGLD on the MNIST dataset is conducted, highlighting the data-dependent nature of the generalization bounds. SGLD and Entropy-SGLD are found to be \u03b5-differentially private, allowing for the application of differentially private versions. The degree of privacy in differentially private optimization is determined by the local entropy parameter \u03c4, which impacts generalization error bounds. The weights learned by SGD, SGLD, and Entropy-SGD differ from those learned by Entropy-SGLD, affecting neural network parametrization and error computation. The validity of generalization bounds depends on privacy approximation adherence. The generalization error of classifiers trained with different optimization methods is evaluated under various thermal noise settings. SGLD shows low generalization error on true labels but high error on random labels for low thermal noise values. Entropy-SGD performs well on true labels with lower empirical risk, but overfits on random labels for certain thermal noise values. Thermal noise of 0.01 produces good performance on both true and random labels. Entropy-SGLD is \u03b5-differentially private with \u03b5 \u2248 0.0327, achieving close to zero generalization error on true labels and not overfitting on random labels. The performance of the network learned by Entropy-SGLD is compared to a deterministic network parametrized by the same weights. The choice of parameter \u03c4 varies in effectiveness between the two label settings. Parameter \u03c4 varies in effectiveness between true labels and random labels. Experiments on a two-class variant of MNIST involve random labels and three network architectures: FC600, FC1200, and CONV. Training and test sets are denoted as S and S tst. The text discusses tracking training and test errors for different learning algorithms, computing various bounds such as PAC-Bayes, Hoeffding-style, and Chernoff-style bounds. It also mentions modifying the cross entropy loss function for privacy in SGLD and Entropy-SGLD. The text discusses achieving privacy in SGLD and Entropy-SGLD through an affine transformation of neural networks output. The choice of parameters makes Entropy-SGLD \u03b5-differentially private. Results for different architectures are presented in figures. The text discusses the performance of SGLD with various levels of thermal noise under true and random labels. SGLD shows a tradeoff between empirical risk and generalization error, with higher thermal noise improving generalization performance but worsening risk performance. Entropy-SGD achieves good risk and low generalization error on both true and random labels with 0.01 thermal noise, outperforming SGD at the same levels. However, Entropy-SGD's test-set performance at 0.01 thermal noise is still worse than that of SGD, raising questions about potential overfitting. Further study is needed to understand this difference. The performance of Entropy-SGLD with \u03c4 = \u221a m on true and random labels is presented in FIG2. The mean and Gibbs classifier learned by Entropy-SGLD have approximately 2% test error on true labels, with zero generalization error. The PAC-Bayes risk bounds are around 3%, tighter than H-and C-bounds. Entropy-SGLD does not overfit on random labels even after many epochs. The error bounds are tighter than those reported by BID18, with improved generalization bounds and test error. Privacy-based bounds rely on the privacy approximation of SGLD for validity. Despite tighter generalization bounds and better test error, Entropy-SGLD still falls short of SGD performance. The results highlight the challenges of combining differential privacy and PAC-Bayes bounds. We may need weaker notions of stability/privacy for further improvement. Despite coarse privacy approximation, no bounds are violated, possibly due to loose bounds or data not being worst-case. Entropy-SGD optimizes a PAC-Bayes generalization bound effectively. Using differential privacy, a private computation on the data can bridge the gap between data distribution and PAC-Bayes priors. This approach allows for extracting information about the underlying distribution without compromising the statistical validity of the PAC-Bayes bound. The use of a data-dependent prior may loosen the bound, but the benefits of choosing a distribution-dependent prior outweigh the expansion of the bound. Choosing a data distribution-dependent prior can compensate for the bound expansion due to privacy concerns. The approach involves replacing SGD with a sample from the Gibbs distribution to make Entropy-SGD private. While generating an exact sample is impractical, practitioners use SGLD as an approximate solution. The privacy approximation assumes that SGLD achieves the same level of privacy as the exponential mechanism. The privacy-based bounds for Entropy-SGD may be optimistic, potentially achievable with advancements in private optimization. Despite tighter bounds compared to previous studies, test set error remains higher than SGD. Differential privacy might be too restrictive, leading to underfitting, yet good generalization is achieved with Entropy-SGD even without strong differential privacy. Entropy-SGLD learns slowly compared to Entropy-SGD, with loose PAC-Bayes bounds. There is a tradeoff between learning speed, excess risk, and the ability to certify generalization error. Characterizing this relationship is an open problem. Differential privacy terms are formally defined, with independence assumptions. The text discusses randomized algorithms and differential privacy, with a focus on (\u03b5, \u03b4)-differential privacy and post-processing. The relationship between learning speed, excess risk, and generalization error is highlighted as an open problem. The text discusses differentially private algorithms and architectures for MNIST classification. Three architectures were studied: CONV, FC600, and FC1200. CONV is a convolutional neural network with 126,711 parameters. FC600 and FC1200 are fully connected neural networks with 834,601 and 2,385,185 parameters, respectively. ReLU activations were used, with a sigmoidal output layer. Dropout and batch normalization were used in previous experiments, but not in this study. The achieved bounds with and without batch normalization were similar. The text discusses differentially private algorithms and architectures for MNIST classification, including CONV, FC600, and FC1200 networks. Dropout was not used in this study. The bounds achieved with and without batch normalization were similar. The objective was to minimize a bounded variant of empirical cross entropy loss, involving an affine transformation to remove extreme probability values. An epoch for SGD involved processing a minibatch of size 128, with 468 steps in total. An epoch for Entropy-SGD and Entropy-SGLD is defined as 468 steps of SGD. SGLD learns a network with 3% higher error than Entropy-SGLD on true labels. The C-bound on the true error of SGLD is around 8%. The inner loop runs for 20 steps with a minibatch size of 128. The step sizes for SGLD must be square summable but not summable. The step sizes for the inner SGLD loop are of the form \u03b7 t = \u03b7t \u22121, with \u03b7 = 1 \u03b3\u03c4. The estimate produced by the inner SGLD loop is computed using a weighted average with \u03b1 = 0.75. SGLD is used to sample from the local Gibbs distribution when estimating the Gibbs risk and the KL term. We run SGLD for 1000 epochs to obtain our estimate, using weighted averages with \u03b1 = 0.005.\u03b3 = 1 and \u03c4 = \u221a m are kept fixed during optimization. The values of \u03c4, L max, and \u03b2 determine the differential privacy of Entropy-SGLD. The differential privacy parameter \u03b5 and confidence parameter \u03b4 contribute when the empirical error is close. The KL version of the PAC-Bayes bound Theorem 3.1 is tighter than the Hoeffding-style bound. Computing the largest value p for KL(q||p) \u2264 c can be approximated using Newton's method. Monte Carlo estimates can be obtained for both terms using Markov chains and i.i.d. P. The estimate is a lower bound with high probability, yielding an upper bound on the KL term. Generalization bounds are evaluated on the MNIST classification task using a fully connected network with 1024 hidden units per layer. The neural network produces a probability vector via a soft-max operation and uses a bounded variant of the cross entropy loss when training privately. The FC1024 network trained on true labels shows a generalization gap close to zero, with both train and test errors low. The CONV network trained on true labels also performs well, with no overfitting observed. When trained on random labels, the FC1024 network shows overfitting after 1000 epochs, while the CONV network trained on random labels exhibits almost no overfitting."
}