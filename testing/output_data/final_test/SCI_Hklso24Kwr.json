{
    "title": "Hklso24Kwr",
    "content": "Approaches to continual learning involve learning a set of related tasks online. Recent frameworks enable deep learning in this scenario, with a key decision being the extent to which the architecture should be shared across tasks. Introducing CLAW, an approach based on probabilistic modeling and variational inference, which adaptively identifies shared network parts. Continual learning (CL) involves retaining knowledge from past tasks to use in present and future tasks. CLAW, a framework based on probabilistic modeling and variational inference, achieves top performance in continual learning benchmarks by addressing catastrophic forgetting and adapting to domain shifts. Continual learning frameworks must adapt to domain shifts and update incrementally to avoid catastrophic forgetting. Balancing adaptation to new tasks with stability is crucial to preserve knowledge. Many approaches use architectures divided a priori. Automating architecture adaptation in continual learning aims to balance stability and adaptation by allowing each neuron to either remain global or adapt locally to new tasks. This variational inference framework offers flexibility in determining the level of sharing across tasks, moving away from a predefined architecture division. The inference framework allows for flexible adaptation of neuron parameters through variational inference. It expands on a continual learning algorithm and automates adaptation of architecture for multi-task learning, optimizing between preventing forgetting and improving task transfer. The probabilistic variational inference algorithm supports incremental updates with adaptively learned parameters and does not require additional neurons. State-of-the-art results in six experiments on five datasets demonstrate the framework's effectiveness in reducing catastrophic forgetting. Related approaches to continual learning include regularisation-based, architecture-based, and memory-based methods. The elastic weight consolidation (EWC) algorithm by Kirkpatrick et al. (2017) imposes a penalty on parameter differences for stability in prediction. The architecture-based approach divides the architecture into global and local parts to address stability and adaptation issues. The memory-based approach relies on episodic memory for storing data from previous tasks. CLAW is a method that stores data from previous tasks without the overhead of data storage, replay, or optimization. It combines variational inference and automates architecture building, making it orthogonal to memory-based methods. It is used in conjunction with Variational Continual Learning (VCL) framework. Variational Continual Learning (VCL) is a framework where the posterior of model parameters is continually updated from a sequence of datasets. The intractable posterior is approximated using a tractable variational distribution, allowing for incremental updates in an online fashion. In Variational Continual Learning (VCL), the approximation of the posterior is done by minimizing KL-divergence over a family of tractable distributions. To address catastrophic forgetting, a coreset of representative data from previous tasks can be used as memory. Previous work on VCL lacked automatic architecture building or adaptation, but a multi-task, continual model is proposed to balance adaptation and stability by allowing data-driven architecture adaptation. The proposed multi-task, continual model allows for data-driven architecture adaptation, automating neuron contributions and maximizing adaptation capacity without expanding the network size. The model parameters are estimated through variational inference, incrementally learning from successive tasks without storing previous task data. The proposed model allows for data-driven architecture adaptation by learning the adaptation decisions and maximum allowed degree of adaptation for each neuron. The model learns binary adaptation variable \u03b1 and a variable s to control adaptation. The adaptation process involves learning the probabilistic contributions of neurons on a task-by-task basis. The model allows for data-driven architecture adaptation by learning binary adaptation variables \u03b1 and a control variable s for each neuron. The adaptation probability \u03b1 follows a Bernoulli distribution initially, but is replaced with a Gaussian for scalable inference. Variational Gaussian estimation is used for higher fidelity in inference. The model enables data-driven architecture adaptation by learning binary adaptation variables \u03b1 and a control variable s for each neuron. The Bernoulli distribution for \u03b1 is replaced with a Gaussian for scalable inference, matching mean and variance. The adaptation range is controlled by variables b T and a T, with the addition of 1 facilitating probability distribution usage. Prior on the weights q 0 (w) is set before facing the first dataset and learning task t = 1. The prior on the weights q 0 (w) is chosen as a log-scale prior before facing the first dataset and learning task. Adapting neuron contributions is likened to attention mechanisms in continual learning, applied throughout the network. Variational inference enables learning of adaptation parameters within the model. The model parameters \u03b8 include weight vectors w. Automating adaptation involves inference on p i,j, previously a hyperparameter. Multiplying w by (1 + b\u03b1) with \u03b1 from (5) and random noise variable \u223c N(0,1) yields the KL-divergence between variational posterior q(w|\u03b3) and prior p(w). The variational parameters are \u03b3 i,j and p i,j, with a switch from (9) to (10) due to entropy computation of Gaussian q(w i,j |\u03b3 i,j). The switch from (10) to (11) involves a log-scale prior. E q(w|\u03b3) log || is computed via an accurate approximation. The KL-divergence between the approximate posterior after the first task and the prior is computed using a third degree polynomial approximation. This divergence is minimized with respect to p i,j to learn the contributions of each neuron in the network per task. Values of p i,j are constrained between 0 and 1 during training. The KL-divergence is minimized with respect to p i,j to learn neuron contributions per task, constrained between 0 and 1. Learning the maximum adaptation variable s i,j involves task-specific values s i,j,t, similar to meta-learning procedures. The warm initialization of s i,j benefits from the general value s i,j rather than random initial conditions. The new information from task t updates the general value s i,j. Divide sample N t into two halves to learn task-specific values s i,j,t. Update the general value s i,j using the second half of the data from task t with step-size parameters \u03c9 1 and \u03c9 2. The algorithm uses learned values s i,j,t for each neuron, with negligible storage overhead. The key steps involve initializing parameters, computing values using stochastic gradient descent, and updating general values based on task-specific information. The algorithm's complexity for updating parameters is based on additive terms. The algorithm's complexity for updating parameters is based on additive terms. The experiments evaluate the performance of CLAW in continual learning, focusing on classification accuracy and reduction in catastrophic forgetting. The experiments evaluate the performance of CLAW in continual learning, focusing on classification accuracy and reduction in catastrophic forgetting. Six experiments are conducted on five datasets, comparing CLAW to six different state-of-the-art continual learning algorithms. The study compares CLAW to various continual learning algorithms based on classification accuracy in six experiments using different datasets. CLAW achieves state-of-the-art classification accuracy in all six experiments, with minibatch sizes of 128 for Split MNIST and 256 for other experiments. Permuted MNIST involves random permutations on labeled MNIST images for each task, with unique permutations for each task. The hyperparameter \u03bb of EWC controls the contribution from previous tasks. In this experiment, EWC with \u03bb = 100 consistently outperformed EWC with \u03bb = 1. Fully connected single-head networks with two hidden layers and 100 units each were used, along with ReLU activations. Adam was the optimizer with specific parameters. CLAW achieved higher classification results than competitors after 10 tasks in Split MNIST experiments. In a MNIST based experiment, CLAW achieves the highest classification accuracy in five binary classification tasks. Fashion-MNIST presents more challenging tasks with clear classification improvement by CLAW. Omniglot involves sequential learning of handwritten characters from 50 alphabets. The Omniglot dataset involves sequential learning of handwritten characters from 50 alphabets using a CNN model. The CLAW framework achieves better classification accuracy on this dataset. The CLAW framework achieves higher classification accuracy on the CIFAR-100 dataset, consisting of 60,000 color images. It outperforms the previous state-of-the-art and shows consistent results across multiple experiments. Additionally, CLAW scales well and performs effectively on various datasets like Omniglot and CIFAR-100. CLAW achieves good results with Omniglot and CIFAR-100, showing high performance retention degrees in continual learning. MNIST, Split MNIST, Split notMNIST, Split Fashion-MNIST, Omniglot, and CIFAR-100 are included in the evaluation. CLAW addresses catastrophic forgetting effectively, leading to better overall continual learning results. The experiment evaluates CLAW's ability to avoid negative transfer by adapting its architecture based on tasks and data, achieving state-of-the-art results in 4 out of 5 experiments. The framework shows promise for future applications in CNNs. Based on variational inference, CLAW adapts neuron contributions instead of rigidly dividing the architecture into shared and task-specific parts. It evaluates the impact of learning previous tasks on the last task to measure forward transfer. CLAW achieves state-of-the-art results in avoiding negative transfer without expanding the architecture. The introduced framework CLAW adapts neuron contributions without adding new layers or neurons. Results from six experiments on five datasets show strong empirical performance in continual learning accuracy, forward transfer, and reducing catastrophic forgetting. Relevant sections in the Appendix include related works, statistical significance of classification accuracy, experimental details, and ablation results. The regularisation-based approach to balance adaptability with catastrophic forgetting involves protecting important parameters while allowing others to change freely. The elastic weight consolidation (EWC) algorithm prevents catastrophic forgetting by prioritizing important synapses during task changes. The weight consolidation (EWC) algorithm, introduced by Kirkpatrick et al. (2017), imposes a quadratic penalty on parameter differences between old and new tasks. One limitation is the computation of the Fisher information matrix diagonal for old task parameters, requiring summation over all possible output labels. The regularisation term involves a sum over previous tasks with a hand-tuned hyperparameter, leading to a lot of hand-tuning. Chaudhry et al. (2018) proposed penalising confident fitting with a maximum entropy regulariser. The VCL algorithm, a form of continual learning, uses variational inference to match posterior moments of a Bayesian neural network trained on different tasks. Other approaches include sparsity-based regularization to prevent catastrophic forgetting. For example, encouraging sparsity in neuron activations or using l2 distance between hidden activations of old and new tasks for regularization. These methods have shown promising results but can be computationally expensive. The VCL algorithm uses variational inference for continual learning, while other approaches involve sparsity-based regularization to prevent catastrophic forgetting. These methods can be computationally expensive. Another approach involves dividing the architecture into reusable parts for stability and adaptation. The work focuses on addressing scalability issues in continual learning by using neural architecture search and optimizing representations to minimize error while limiting forgetting. Different frameworks aim to solve the neural architecture structure learning problem by balancing adaptation and stability through reinforcement learning strategies. The optimal number of neurons and filters to add to each layer is determined through combinatorial optimization with rewards based on validation accuracy and network complexity. The curr_chunk discusses various approaches to mitigate catastrophic forgetting in neural networks, including RL agents with a synaptic model, shared layers for different tasks, a clipped version of maxout networks, dynamic network expansion using a generative adversarial network, and a memory-based approach. These methods aim to address performance loss on earlier tasks due to alterations in shared layers. The memory-based approach addresses the adaptation-catastrophic forgetting tradeoff by using episodic memory to store data from previous tasks. However, limitations include data availability and overhead from memory requirements. Generative replay is another approach used to mitigate forgetting. Shin et al. (2017) train a deep generative model using GANs to mimic past data, addressing catastrophic forgetting. Replay mechanisms in reinforcement learning have also been used to alleviate forgetting. Lopez-Paz & Ranzato (2017) store gradients of previous tasks to reduce forgetting. Other algorithms based on replay mechanisms include Aljundi et al. (2019a). Tradeoffs between adaptation and stability are discussed in the literature. The literature discusses the tradeoff between adaptation and stability, focusing on the ability to rapidly adapt to new tasks while maintaining stability. Recent works explore measures of intransigence and forgetting, aiming to optimize the transfer-interference tradeoff to maximize transfer and minimize interference. The ORACLE algorithm by Yoon et al. (2019) addresses the sensitivity of continual learning. The ORACLE algorithm by Yoon et al. (2019) addresses the sensitivity of a continual learner to the order of tasks by establishing an order robust learner. Another algorithm (Titsias et al., 2019) achieves functional regularization through approximate inference over the function space using a Gaussian process. The proposed CLAW model can be applied to continual learning frameworks other than VCL, with relevance to variational inference. The CLAW model, based on variational inference, does not expand the network like other algorithms. It can inspire extensions to adaptively expand networks without adding nodes or filters for each task. Statistical significance and standard error comparisons with other continual learning frameworks are provided. In Table 1, average accuracy values from the last two tasks of six experiments are listed, with bold entries indicating significantly higher classification accuracy for CLAW compared to competitors. Significance is determined using a paired t-test with p = 0.05. CLAW outperforms competitors with average accuracy values of 99.2%, 98.7%, 95.8%, 96.9%, 92.9%, and 97.8% on different experiments. Fashion-MNIST, Split Fashion-MNIST, Omniglot, and CIFAR-100 datasets are used in various tasks with different accuracy percentages. MNIST dataset is utilized in Permuted MNIST and Split MNIST experiments. The MNIST dataset consists of handwritten digit images with 28x28 pixels. It has 60,000 instances for training and 10,000 for testing. Data is split into training, validation, and test sets with 60%, 20%, and 20% respectively. CLAW required 10 epochs for most experiments except for Omniglot and CIFAR-100 (15 epochs). \u03c9 1 and \u03c9 2 values used were 0.05 and 0.02. The network used for Omniglot and CIFAR-100 consists of 4 blocks of convolutions with 64 filters. CLAW achieves higher classification accuracy on both datasets. The importance of adaptation parameters is demonstrated in Figures 4-9, comparing CLAW to cases where adaptation is not learned, always happens, or never takes place. The differences in classification accuracy between CLAW and the other plots in Figures 4-9 show the relevance of adaptation parameters, where adaptation never occurs."
}