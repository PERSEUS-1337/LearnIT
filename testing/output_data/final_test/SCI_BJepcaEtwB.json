{
    "title": "BJepcaEtwB",
    "content": "Few shot link prediction is a challenging task due to the inability of current methods to transfer knowledge between graphs and learn from sparse data. To address this, a new gradient-based meta learning framework called Meta-Graph is introduced. This framework leverages higher-order gradients and a learned graph signature function to generate a graph neural network initialization. Meta-Graph shows fast adaptation, better final convergence, and effective learning with a small sample of true edges in few shot link prediction benchmarks. Link prediction aims to infer new relationships between nodes in a graph. It is commonly used in social networks for friendship recommendations and in biological networks to predict connections between drugs, proteins, and diseases. Previous work on link prediction typically focuses on large, complete graphs, but this study explores the more challenging few shot link prediction setting. In few shot link prediction, the goal is to predict links on multiple graphs with limited true edges. This is crucial in scenarios like biological interactomics and social networks where graphs are sparse and noisy. Learning algorithms need to leverage information across these graphs to overcome sparsity. Link prediction is important for making quick predictions on sparsely-estimated graphs, especially in new locales. Few shot link prediction aims to transfer knowledge from denser graphs to predict edges on new sparse graphs, similar to few shot classification. This approach leverages experience from multiple graphs to improve accuracy in predicting edges on new graphs, resembling a form of meta learning. Meta-Graph is a new framework for few shot link prediction, adapting gradient-based metalearning for graphs. It aims to transfer knowledge between graphs and learn from sparse data, improving accuracy in predicting edges on new graphs. Meta-Graph is a framework for few-shot link prediction using neural networks. It introduces a graph signature function for fast adaptation to new graphs and achieves better results than non-meta learning baselines, with an average improvement of 5.3% in AUC. The setup involves sampling training graphs from a distribution and representing them with nodes, edges, and node attributes. The goal is to learn a global link prediction model from sampled graphs with real-valued attributes, represented as adjacency matrices. The model aims to quickly adapt to new graphs and optimize a set of parameters for effective link prediction. The goal is to optimize global parameters and a graph signature function for effective link prediction on multiple sampled graphs. Few shot link prediction differs from standard link prediction by learning from sparse true edges and distinguishing between global and local parameters. The distinction between global parameters and local parameters in few-shot link prediction allows for individually-tuned models on specific graphs. Traditional meta learning focuses on classification tasks, while our approach considers a distribution over graphs for link prediction. The challenge lies in the non-i.i.d. nature of individual predictions for each graph. Meta-Graph proposes a novel approach to few-shot link prediction by defining local link prediction models for specific graphs and using gradient-based meta learning to optimize a shared parameter initialization for these models. This method aims to generate effective parameter initializations for the local models while also learning a parametric encoding of each graph to modulate the shared parameter. The Meta-Graph approach aims to optimize a shared parameter initialization for local link prediction models by learning a parametric encoding of each graph. This encoding can modulate the parameter initialization in a graph-specific way, particularly in the context of variational graph autoencoders (VGAEs) for link prediction. The Meta-Graph approach utilizes gradient-based meta learning to optimize a shared parameter initialization for variational graph autoencoders (VGAEs) in link prediction. It also learns a graph-specific parametric encoding to modulate this initialization. The Meta-Graph approach uses gradient-based meta learning to optimize a shared parameter initialization for variational graph autoencoders (VGAEs) in link prediction. It also incorporates a graph-specific parametric encoding to modulate this initialization, including a global initialization \u03b8 and a graph signature s Gi = \u03c8(G i ) to condition the inference model q \u03c6i for each graph G i. The Meta-Graph approach utilizes gradient-based meta learning to optimize a shared parameter initialization for variational graph autoencoders (VGAEs) in link prediction. It incorporates a graph-specific parametric encoding with global parameters \u03b8 and a graph signature function \u03c8 to condition the inference model for each graph. The algorithm involves sampling a batch of training graphs, initializing VGAE models using global parameters and signature function, and optimizing through gradient descent. The Meta-Graph approach utilizes gradient-based meta learning to optimize variational graph autoencoders (VGAEs) for link prediction. It involves updating the GCN based encoder for local link prediction parameters and global parameters using second order gradients. Different instantiations of the Meta-Graph framework modulate the VGAE inference parameters based on the output of the graph signature function. The output of the graph signature function modulates the parameters of VGAE inference models by adding a modulation function to the standard GCN propagation rule. This modulation is based on computing a structural signature from the input graphs. The modulation involves computing a structural signature from input graphs to condition the initialization of local link prediction models. The modulation function is applied to the GCN parameters, providing flexible modulation while being relatively constrained. The linear modulation in Meta-Graph is extended with a sigmoid gating term to adaptively control the influence of \u03b3 and \u03b2. Graph neighborhood information is separately aggregated with and without modulation, then merged via a convex combination. This approach is a simplification of model agnostic meta learning (MAML) for few shot link prediction. In few shot link prediction, there are differences in setup compared to few shot classification. The core idea involves leveraging inner and outer training loops, using second order gradients to optimize global parameters, and adapting MAML to the graph setting. Meta-Graph introduces a graph signature function that influences modulated parameters from sampled edges, contrasting with MAML's likelihood maximization over all edges in a distribution. The text discusses the explicit influence of \u03c8 on modulated parameters \u03c6 j in a few-shot link prediction task. Three novel benchmarks are designed for this task, with training, validation, and test graph splits. The goal is to achieve high link prediction accuracy by fine-tuning or training a model on the test graphs. The text discusses train/val/test splits at both graph and edge levels for optimizing a model. The goal is to investigate the performance of Meta-Graph compared to various baselines and address key empirical questions. Meta-Graph's performance is evaluated in terms of fast adaption and achieving strong performance with a small number of gradient steps on test graphs. The necessity of the graph signature function for strong performance and the comparison of different variants are also explored. The study uses benchmarks from protein-protein interaction networks and 3D point cloud data adapted for link prediction. The study evaluates Meta-Graph's performance in fast adaption and achieving strong results with few gradient steps on test graphs. A novel multi-graph dataset is created based on AMINER citation data for link prediction. Node features are generated using embeddings of paper abstracts. Link prediction is done by training on a subset of edges and predicting unseen edges. Baseline details and key dataset statistics are provided. The study evaluates Meta-Graph's performance in fast adaption and achieving strong results with few gradient steps on test graphs. Meta-Graph, MAML, Finetune, and No Finetune models are compared using Bayesian optimization for hyperparameter selection. Link prediction AUC results are shown for different percentages of graph edges used for training. Meta-Graph achieves the highest average AUC in most settings, showing a 4.8% improvement over MAML and 5.3% over Finetune. It maintains strong performance with sparse training data and outperforms MAML as training set density increases. This is attributed to the optimization challenges in MAML, which are mitigated in Meta-Graph with the gating mechanism. In GS-gating, the computational complexity is slightly higher compared to MAML, but the graph signature function is only updated in the outer loop. Additional results in the Appendix show that Meta-Graph's gains decrease with more training edges. In fast adaptation, Meta-Graph outperforms MAML and Finetune with an average improvement of 9.4% and 8.0% respectively. Meta-Graph can quickly learn on new data with sparse samples of edges, showing poor performance for MAML in the Ego-AMINER dataset due to low learning rates. Early stopping is essential as Meta-Graph can overfit after a small number of updates. An ablation study on the FirstMM DB dataset examines the impact of different graph signature functions. The performance of different model variants and baselines is shown as training progresses. Various signature functions are compared, including a random baseline for few-shot link prediction. GCN based inference network and simple MLP on node features are also evaluated. Some signature functions outperform MAML and other baselines, with simple modulation and GS-Gating showing superiority. The graph signature's learning process is further explored using FirstMM DB and Ego-AMINER datasets. The study compares the output of the signature function with various graph heuristics using the FirstMM DB and Ego-AMINER datasets. The cosine similarity between graph signatures and other pairwise statistics like node features shows a strong positive correlation, indicating sensitivity to feature information. The graph signature function is highly sensitive to feature information, especially with sparse samples of edges. There is a moderate negative correlation between graph signature output and other graph statistics. Link prediction, meta-learning, few-shot classification, and few-shot learning in knowledge graphs are briefly discussed. Link prediction methods have various successful applications such as friend recommendations, shopping recommendations, and identifying criminals based on past activities. These methods utilize topological graph features and approaches like Adamic/Adar measure, Jaccard Index, Matrix Factorization, and deep learning techniques. The objective is to predict links in a single dense graph. Our approach considers link prediction tasks over multiple sparse graphs drawn from real-world scenarios like protein-protein interaction graphs, 3D point cloud data, and citation graphs in different communities. Meta-learning aims to learn from prior experiences to adapt quickly to unseen tasks, with notable approaches in few-shot learning tasks categorized into metric-based, augmented memory, and optimization-based approaches. In the intersection of meta-learning for few-shot classification and graph-based learning, recent works include Latent Embedding Optimization by Rusu et al. (2018) and message propagation rule by Liu et al. (2019). These methods focus on tasks in the image domain and do not explore meta-learning over a distribution of graphs. Another related area is few-shot relation prediction in knowledge graphs, with methods like Meta Relational Learning framework (MetaR) by Chen et al. (2019) aiming to transfer relation-specific meta information. The Meta-Graph framework addresses few-shot link prediction by transferring relation-specific meta information to new relation types in a knowledge graph. It optimizes a shared parameter initialization for local link prediction models and learns a graph-specific encoding to modulate this initialization. Substantial gains were observed empirically. The Meta-Graph framework improves few-shot link prediction by transferring relation-specific meta information in a knowledge graph. It optimizes parameter initialization in a graph-specific way and shows substantial gains compared to baselines. Future work includes extending Meta-Graph to multi-relational data and learning a similarity metric between graphs. Ego-Aminer dataset is constructed by creating citation graphs from various fields of study. In this study, citation graphs from different fields are created and the top 100 graphs with a minimum of 5-edges per node are selected for further analysis. Ego networks are then constructed by sampling nodes from the 5-core graph. A total of 72 graphs are analyzed, with results showing decreasing gains of Meta-Graph with more training edges available."
}