{
    "title": "HkeoOo09YX",
    "content": "This paper introduces a meta-learning algorithm for designing the continuous dynamics of Stochastic gradient Markov chain Monte Carlo (SG-MCMC) samplers. The learned sampler improves traversal and exploration of energy landscapes, outperforming generic SG-MCMC algorithms on various Bayesian neural network tasks. There is a resurgence of research interests in Bayesian deep learning, applying Bayesian inference to neural networks for better uncertainty estimation, exploration in reinforcement learning, resisting adversarial attacks, and continual learning. Stochastic gradient Markov chain Monte Carlo (SG-MCMC) is a popular approach for Bayesian inference on neural networks, with recent advances in optimization techniques making it highly scalable to many deep learning tasks. This paper introduces meta-learning techniques to automate the design of SG-MCMC proposals for neural network weight sampling, aiming to generalize common knowledge acquired from training on multiple tasks. The paper introduces meta-learning techniques for SG-MCMC samplers in neural network weight sampling, extending Hamiltonian dynamics with learnable matrices for generalization across datasets and architectures. Extensive evaluation on Bayesian neural networks shows improvements over traditional SG-MCMC schemes. The paper focuses on sampling from a target density using Bayesian modeling with Bayesian neural networks as an example. It discusses the energy function and the posterior distribution, emphasizing the use of SG-MCMC samplers for neural network weight sampling. The paper discusses sampling from a target density using Bayesian modeling with Bayesian neural networks. It highlights the use of SG-MCMC samplers for neural network weight sampling, which is beneficial for deep learning tasks with large datasets. SG-MCMC uses a stochastic differential equation to maintain target density invariance. It\u00f4 diffusion is governed by continuous-time SDEs, with Langevin dynamics as a simple example. Stochastic gradient Langevin dynamics approximates the update rule with a mini-batch gradient estimate, resembling stochastic gradient descent with added Gaussian noise. SG-MCMC is a scalable method for sampling posterior distributions of neural network weights on large datasets. It uses a stochastic differential equation framework with drift, curl, diffusion, and correction terms. The framework ensures that the stationary distribution of the SDE is proportional to exp(\u2212H(z)), making it computationally efficient. The distribution of SDE for positive semi-definite matrix D and skew-symmetric matrix Q; for any It\u00f4 diffusion process with unique stationary distribution \u03c0, there exist matrices D and Q governing the process. SG-MCMC algorithm construction involves defining state-space and D, Q matrices. Designing these matrices can improve mixing and reduce sample bias, historically based on physical intuitions from statistical mechanics. In the context of SG-MCMC algorithm construction, practitioners may find it challenging to select the best sampling method for machine learning tasks. The proposed meta-learning algorithm focuses on searching for SG-MCMC samplers within a large subset of It\u00f4 diffusion processes, ensuring each instance is a valid posterior sampler. This completeness result enhances the algorithm's ability to generalize to diverse test tasks. The meta-learning algorithm aims to design a parameterization for SG-MCMC proposal from data, training on simple tasks and generalizing to complex densities. The state-space is augmented with a momentum variable, and the Hamiltonian is defined accordingly. The meta-learning algorithm designs a parameterization for SG-MCMC proposal by using neural networks with preconditioning matrices to reduce computational burden. The curl matrix controls deterministic drift forces introduced by the energy gradient. The deterministic drift forces in SGHMC are influenced by the energy gradient and pre-conditioning effect introduced by matrices. The algorithm uses neural networks to design a parameterization for SG-MCMC proposal, with the curl matrix controlling these forces. The discretized dynamics of the state are computed using a modified forward Euler discretization. The computation graph of eq. FORMULA10 in FIG0 visualizes the acceleration of \u03b8 and friction on momentum. In the big-data setting, noisy gradient is Gaussian distributed with variance V(\u03b8). BID25 suggested a correction scheme using Gaussian noise DISPLAYFORM6. These corrections are unnecessary with small step-size \u03b7. Functional forms for \u03c6 Q and \u03c6 D aim for a balance between generalization power and computational efficiency. The curl matrix Q(z) controls the drift of dynamics. The curl matrix Q controls the drift of dynamics, with the energy function U identifying low-density regions. Momentum is included in the inputs of \u03c6 Q, and an offset \u03b2 is added to prevent matrix vanishing. The matrix D is responsible for friction and stochastic gradient noise for better exploration around high-density regions. The energy gradient is added to inputs for better exploration in high-density regions. Stochastic estimates are used for efficiency, and inputs are rescaled for consistency. Finite difference approximations are used when computational budget is limited. A meta-learning procedure is designed for faster convergence and low bias on test tasks. The proposed loss functions, cross-chain loss and in-chain loss, aim to encourage faster convergence and low bias on test tasks. The cross-chain loss focuses on minimizing the KL-divergence between the sampler's distribution and the stationary distribution, while also utilizing Monte Carlo variational inference for estimating the lower-bound. Variational inference (MCVI, BID31 Blundell et al., 2015) estimates the lower-bound with samples obtained by simulating parallel Markov chains. The cross-chain loss accumulates lower-bounds through time to improve sampler convergence. Thinning mitigates the cost of simulating multiple chains by collecting samples every \u03c4 step. The in-chain loss is defined as the ELBO evaluated at the averaged distributionq. The ELBO is approximated using Monte Carlo with samples obtained by thinning. The Stein gradient estimator is used to estimate intractable gradients for cross-chain and in-chain losses. The proposed sampler architecture generalizes SG-Riemannian-HMC by decoupling the design of matrices and learning their functional form from data. RNNs are not used in this approach, leaving the combination of learnable RNN proposals for future work. The proposed sampler architecture in BID25 combines stochastic gradient and Gaussian noise with a neural network to approximate the posterior distribution. Unlike other approaches, this sampler is guaranteed to be correct within the BID25 framework. Recent research has explored improving HMC with trainable transition kernels, such as introducing a trainable re-sampling distribution for momentum and parameterizing the HMC transition kernel. The proposed sampler architecture in BID25 combines stochastic gradient and Gaussian noise with a neural network to approximate the posterior distribution. BID39 parameterized the HMC transition kernel with a trainable invertible transformation called NICE and trained it with Wasserstein adversarial training. BID14 augmented the state space with a binary direction variable and parameterized the transition kernel with a non-volume preserving invertible transformation inspired by RealNVP flows. The sampler is trained with the expected squared jump distance BID29. Adversarial training is not considered in this paper due to its unreliability for high dimensional data. The jump distance does not explicitly consider sampling bias and convergence speed. These approaches aim to improve the HMC-like sampler on the target distribution directly. Our goal is to learn an SG-MCMC sampler that can be transferred to sample from different Bayesian neural network posterior distributions of varying dimensions. The meta-learned SG-MCMC sampler, NNSGHMC, demonstrates fast convergence and low bias when sampling Gaussian variables. The code for the sampler is available at https://github.com/WenboGong/MetaSGMCMC. The meta-learned SG-MCMC sampler, NNSGHMC, shows faster convergence and lower bias compared to SGHMC when sampling Gaussian variables. Results indicate better efficiency of the meta sampler with a higher effective sample size. Trajectory plots confirm that the meta sampler explores more efficiently and is less affected by noise. Bayesian neural network classification on MNIST data with generalization tests for network architecture, activation function, and dataset. Comparison of SGLD, SGHMC, and PSGLD algorithms for long-time horizon generalization results. PSGLD uses RMSprop-like preconditioning techniques. In this study, comparisons were made between SGLD, SGHMC, and PSGLD algorithms for Bayesian neural network classification on MNIST data. The NNSGHMC algorithm showed the fastest convergence and lowest test error compared to the other methods. Results also indicated that NNSGHMC performed on par with SGLD in terms of test log-likelihood. The NNSGHMC algorithm was tested with sigmoid activation function and showed faster convergence and lower error compared to other methods. It achieved the best NLL results and performed on par with SGHMC. Additionally, it was evaluated on MNIST data with a smaller MLP and tested on a larger MLP without prior knowledge of the test task's data. NNSGHMC caught up quickly and had similar NLL results to PSGLD. The algorithm was also tested on CNNs for CIFAR-10. The meta sampler algorithm is tested on convolutional neural networks (CNNs) for CIFAR-10 classification with three generalization tasks. It is trained using a smaller CNN with specific architecture details and utilizes a \"replay\" technique at the beginning of each \"meta-epoch\". The test CNN has different architecture specifications, resulting in increased dimensionality. The meta sampler achieves successful results as shown in FIG6. The meta sampler algorithm demonstrates faster learning and better performance in test accuracy and NLL compared to PSGLD. It outperforms in both accuracy and NLL over 200 epochs, showing faster convergence and finding a better posterior mode. Additionally, when using different activation functions and datasets, the meta sampler continues to show better convergence speed and final performance. The meta sampler algorithm achieves faster convergence speed and similar accuracy as SGHMC in sequence modeling with Bayesian RNNs using polyphonic music datasets. The meta sampler algorithm outperforms SGLD and compares favorably with Adam and Santa optimizers in sequence modeling with Bayesian RNNs on polyphonic music datasets. It shows faster convergence than SGHMC and achieves better final performance on Muse dataset. The meta sampler algorithm outperforms SGLD and compares favorably with Adam and Santa optimizers in sequence modeling with Bayesian RNNs on polyphonic music datasets. It shows faster convergence than SGHMC and achieves better final performance on Muse dataset. Interestingly, the meta sampler's final results on Nott and JSB are slightly worse than other samplers, possibly due to the different dataset characteristics. Experiments on Bayesian MLPs, Bayesian CNNs, and Bayesian RNNs confirm the strong generalization of the trained sampler across datasets and network architectures. Future work will focus on further testing the meta sampler on different tasks and datasets. Future work will focus on improving designs for the sampler and meta-learning procedure, including exploring temperature variable augmentation and moving average estimation. Better loss functions will be proposed for faster training by reducing unrolling steps of the sampler. Additionally, the automated design of generic MCMC algorithms not derived from continuous Markov processes remains a challenge. Comparing momentum SGD and SGHMC, SGHMC is closely related to SGD with momentum, with the state space augmented with an additional momentum variable. The continuous-time dynamics of Hamiltonian Monte Carlo (HMC) are governed by a stochastic differential equation (SDE) with a friction coefficient matrix. The discretized update rule for HMC with a step-size \u03b7 involves replacing the covariance matrix with 2\u03b7(C - B), where B is the variance estimation of the gradients. Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) updates can be seen as injecting carefully controlled Gaussian noise into the SGD with momentum update equations. The hyperparameters of SGHMC and SGD-M can be chosen based on each other's experiences. In practice, advanced discretization schemes like Leapfrog and modified Euler are recommended for HMC simulation to prevent divergence. SGHMC implementation uses modified Euler discretization and a two-stage update of Euler integrator. Approximations are made for various terms in the update equations to simplify computations. The proposed finite difference method reduces running time drastically by requiring fewer back-propagations, especially for large neural networks. Time complexity is O(HD) for both forward pass and finite difference, with parallel computation on GPUs improving real-time speed. In comparison to SGHMC, the meta sampler spends roughly 1.5x more time in the MNIST experiment. The proposed Stein gradient estimator estimates the gradient on samples from an implicitly defined distribution, reducing running time significantly compared to SGHMC. Stein's identity is used to derive this estimator, which is based on a differentiable multivariate test function. The Stein gradient estimator for fast-decaying tails like Gaussian tails is proposed by inverting a Monte Carlo version of Stein's identity. The estimator can be obtained by minimizing a Monte Carlo estimate of the kernelized Stein discrepancy, with the choice of kernel playing a crucial role in performance improvement. Optimal kernels are often problem-specific and challenging to determine. Optimal kernels are difficult to obtain and problem-specific. Recent approaches involve composing a simple kernel on features from a deep neural network. However, these methods do not scale well for latent variables. The paper uses an RBF kernel for the gradient estimator, with potential for better performance with other kernels. The paper uses an RBF kernel for the gradient estimator, with potential for better performance with other kernels. The time complexity for meta sampler training is O(K^3) for cross-chain training, with the possibility of reducing computation costs through proper thinning schemes. Truncated back-propagate through time is applied to train the sampler, with cross-chain training encouraging fast convergence and low bias. In practice, thinning chains during in-chain training improves the accuracy of the Stein gradient estimator by spreading out samples. Parallel chain sub-sampling can also enhance gradient estimates by promoting diversity among samples. Different tasks and dimensions may require adjustments for energy function, momentum, and energy gradient scales, affecting meta sampler generalization. The meta sampler's generalization can be affected by different scales and magnitudes in training and test densities. To address this issue, pre-processing the inputs to the networks is proposed to align scales. The energy function scale is linear with the dimensionality of \u03b8 and the number of observations N, and can be approximated using mini-batches. Pre-processing the energy function is suggested to mitigate this issue. To align scales in the meta sampler's generalization, pre-processing the energy as DISPLAYFORM0 is proposed. The momentum and energy gradient magnitudes are normalized for training on a 10D Gaussian distribution. Noise is manually injected to mimic stochastic gradient. To align scales in the meta sampler's generalization, pre-processing the energy as DISPLAYFORM0 is proposed. Gaussian noise is manually injected to mimic stochastic gradient during training. The meta sampler uses a 1-hidden-layer MLP with 40 hidden units and a step size of 0.01. Training involves updating matrices with Adam optimizer and using cross-chain and in-chain losses. The Stein Gradient estimator employs an RBF kernel with bandwidth set to 0.5 times the median-heuristic estimated value. The Markov Chain is unrolled for 20 steps before manually stopping the gradient. In cross-chain training, Markov Chains are run for 20 steps before manually stopping the gradient. For in-chain training, initial 50 points are discarded for burn-in, and the chain is sub-sampled with a batch size of 5. Samples are thinned every 3 steps. 50 parallel Markov Chains are run for both training and evaluation. The test task involves drawing samples from a 20D correlated Gaussian with a specified mean and covariance matrix. Step size is set to 0.025 for both meta sampler and SGHMC. Stabilization techniques are applied to the meta sampler and friction matrix is selected for SGHMC. In the MNIST experiment, input pre-processing and scaling adjustments are made to the energy function and gradient. Offset and learning rate parameters are set as suggested in previous work. In the experiment, the meta sampler is trained on a smaller BNN with architecture 784-20-10 and ReLU activation function, then tested on a larger one with architecture 784-40-40-10. The per-batch learning rate is 0.007, and the sampler is trained for 100 epochs with each consisting of 7 sub-epochs. The sampler is re-initialized after each epoch for stabilization during evaluation. The meta sampler is stabilized in evaluation by adjusting the per-batch learning rate and clamping Q values. Different learning rates are used for SGHMC, SGLD, and PSGLD, tuned on MNIST validation data. The test network's activation function is modified to sigmoid. The meta sampler is trained on a ReLU network to classify images 0-4 and tested on a different network for images 5-9. The CIFAR-10 dataset contains 50,000 training images with 10 labels and 10,000 test images. The meta sampler is trained using a smaller CNN classifier with specific network architecture settings. The training sampler has a discretization step-size and scaling term adjusted accordingly. The per-batch learning rate and friction coefficient are defined for optimization methods. The meta sampler is trained using a smaller CNN classifier with specific network architecture settings. It uses a per-batch learning rate and friction coefficient for optimization. The f \u03c6 Q and f \u03c6 D are defined by 2-layer MLPs with 10 hidden units. The output of D f (z) is scaled up by 10 and its gradient input \u2207U (\u03b8) by 100. The energy input U (\u03b8) is scaled up to both f \u03c6 Q and f \u03c6 D by 5. The meta sampler is trained using 100 \"meta epoch\" with 5 data epoch and 500 batch size. Within each \"meta epoch\", computations are repeated for 10 times with 50 parallel chains for 50 iterations. The parameters are updated using Adam and gradient is manually stopped after 20 iterations.\u03b8 and p are re-initialized using replay techniques with probability 0.15 after finishing all sub-epoch. The sub-sample chain number for in-chain loss is set to 5. In Bayesian CNN experiments, the replay technique is used to train the meta sampler, which is particularly useful for complex datasets like CIFAR-10. The replay pool is updated after each sub-epoch with a constant size queue-like structure, allowing for both short-time and long-time horizon generalization. The meta sampler can continue with previous states, enhancing its adaptability. The meta sampler in Bayesian CNN experiments utilizes a replay technique to improve adaptability. It can observe burn-in and roughly-converged behavior, controlled by replay probability. The test CNN architecture includes two convolutional layers and one fully connected layer. The dimensionality of \u03b8 is 61,478. 20 parallel chains are run in test time, with training images split into training and validation sets. Samplers/optimizers are tuned on the validation set for 80 epochs and run for 200 data epochs in testing. In Bayesian CNN experiments, samplers/optimizers are tuned on the validation set for 80 epochs and run for 200 data epochs in testing. Different methods have specific per-batch rates and learning rates, with adjustments made to prevent overfitting. The test CNN architecture is similar to the one in NT but with different activation functions. Parameters for sampling methods are fixed, with only step sizes re-tuned using the same setup as in NT. The step sizes for optimization methods Adam and SGD-M are 0.002 and 0.03 respectively. The CIFAR-10 dataset is split based on labels for training and testing. The meta sampler is trained without access to test task data. The sampler is trained with scaling terms from NT but with a reduced step-size of 0.0005. The test CNN architecture and ReLU activation are the same as in NT. The step sizes for meta sampler, SGHMC, SGLD, and PSGLD are 0.0015, 0.005. Piano data is used for training, with batch-size 1 for estimating energy and gradient on a single sequence. The meta sampler is trained for 40 epochs with 7 sub-epochs using a batch-size of 1. The training and evaluation per-batch learning rate is set to 0.001. Various adjustments are made to prevent divergence and ensure dataset generalization. Hyperparameters are tuned based on the Piano validation set. The Piano architecture generalization does not tune hyper-parameters and uses the same settings as training. Data statistics show differences in dataset sizes and sequence lengths. The Nott dataset has a different energy scale, making generalization harder. The JSB dataset has short sequences, leading to potential overfitting. Some algorithms exhibit significant overfitting on JSB compared to other datasets. The JSB dataset shows overfitting behavior compared to other datasets. The samplers were run for 500 iterations with settings similar to MNIST experiments. Results compared optimization methods including momentum SGD and Adam, with the meta sampler and Adam showing the fastest convergence speed. Additional contour plots were provided for MNIST experiments."
}