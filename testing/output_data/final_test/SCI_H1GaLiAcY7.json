{
    "title": "H1GaLiAcY7",
    "content": "This paper introduces a novel approach to domain division for segmenting instances from different probabilistic distributions in recognition tasks like Open Set Learning and Generalized Zero-Shot Learning. It proposes a probabilistic method to estimate and fine-tune the decision boundary between seen and unseen classes, using a domain division algorithm to categorize testing instances into known, unknown, and uncertain domains. Statistical tools like bootstrapping and Kolmogorov-Smirnov Test are utilized for the first time in this context. The paper introduces tools like bootstrapping and Kolmogorov-Smirnov Test to uncover and fine-tune decision boundaries between different domains. It addresses the problem of separating instances from different distributions, particularly in Open Set Learning and Generalized Zero-Shot Learning tasks. The approach includes an uncertain domain to handle instances with unpredictable labels, achieving state-of-the-art performance in benchmarks. In Generalized Zero-Shot Learning (G-ZSL), the goal is to distinguish labels of instances from seen and unseen classes using semantic attributes as intermediate representations. Training classes are mapped to class label space (OSL) or semantic space (G-ZSL), with testing performed separately on known and unknown domains. In Generalized Zero-Shot Learning (G-ZSL), the goal is to distinguish labels of instances from seen and unseen classes using semantic attributes as intermediate representations. Testing is performed on separated domains to identify seen classes and the novel class (OSL), or both seen and unseen classes (G-ZSL). The key challenge is efficiently dealing with the novel class/unseen classes during testing, as predictors learned on training classes tend to be biased towards seen classes, leading to poor classification results for the novel class or unseen classes. The initial boundary of the known domain is estimated by bootstrapping and further divided by K-S Test to recognize instances in each domain. The distribution of pairwise intraclass and interclass distances is computed to visualize the distributions of testing instances. A large portion of unseen instances is predicted as known classes, suggesting the need to learn to separate domains by the distributions of instances. The problem addressed is the difficulty in distinguishing between seen and unseen classes using visual features alone. This leads to overlapping distributions and unreliable predictors for seen classes, impacting recognition algorithms. The performance of classifiers in each domain remains a challenge. The difficulty in distinguishing between seen and unseen classes using visual features impacts recognition algorithms. Introducing a novel domain - uncertain domain - helps divide the visual or semantic space into known, unknown, and uncertain domains for more accurate classification. Exploiting distribution information of seen and novel/unseen classes is proposed to efficiently learn patterns. The domain separation algorithm utilizes distribution information of seen and novel/unseen classes to efficiently learn to divide domains. It involves initial division by bootstrapping and fine-tuning with the Kolmogorov-Smirnov test. Bootstrapping estimates an initial boundary for known classes, while the K-S Test validates learned predictors in specific regions. The uncertain domain is introduced to validate trustworthy predictors in a specific region, addressing instances with hard-to-judge labels. A systematic framework separates domains by probabilistic distributions, utilizing bootstrapping and the Kolmogorov-Smirnov test to estimate and fine-tune boundaries. An uncertain domain is defined for instances that cannot be confidently classified as known or unknown. The importance of domain division is evaluated on zero-shot learning benchmarks, showing significant improvement over existing approaches. One-Class Classification (OCC), also known as unary classification, assumes training set has only positive samples of a specific class. Common OCC algorithms include One-class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF). OCSVM uses Support Vector Data Description (SVDD) to create a spherical boundary in feature space, minimizing outlier effects. LOF measures local deviation of instance density, identifying outliers in low-density areas. Open Set Learning (OSL) distinguishes between known and unknown classes, categorizing instances into seen classes or a single novel class. OSL lacks semantic prototypes for unseen classes, unlike OCC which builds classifiers using information from different seen classes. Zero-Shot Learning (ZSL) transfers knowledge from known classes to recognize novel instances. Generalized Zero-Shot Learning (G-ZSL) extends this to handle testing instances from both seen and unseen classes. Evaluation of G-ZSL in BID39 reveals that existing ZSL algorithms struggle when applied directly to G-ZSL, showing bias towards seen classes. The goal is to predict the class label of a test instance, with two tasks discussed: open set recognition and predicting class labels. The extreme values of confidence scores from a supervised classifier can be modeled using Extreme Value Theory (EVT), with the minimum score following a Weibull distribution. The extreme values of confidence scores from a supervised classifier can be modeled using Extreme Value Theory (EVT). The minimum score for class c follows a Weibull distribution, while the maximum score for instances not belonging to class c follows a reverse Weibull distribution. Parameters are estimated using Maximum Likelihood Estimator from training data. These distributions provide boundaries for each event. The probability of W-SVM introducing a threshold \u03b4 c to determine class membership can be calculated using Eq (1) and Eq (2). However, there are limitations in directly utilizing Eq (4) and Eq (5) for learning domain divisions, such as the potential lack of correlation between different classes and the difficulty in determining a fixed threshold \u03b4 for each class. The difficulty in determining a fixed threshold \u03b4 for each class is highlighted, along with the challenge of predicting class labels in the overlapped region. The W-SVM estimates confidence scores using a fixed threshold empirically predefined for any data distributions. In this paper, the boundary of the known domain is constructed via the bootstrap approach BID8, which estimates standard errors and confidence intervals when distributions are unknown. Bootstrapping is widely used for approximating sampling distributions of test statistics and estimators. Training sets are denoted for each class to determine if an instance is seen or unseen using a statistic calculation with a threshold. The statistic m c (x i ) is calculated with the threshold \u03b4 c estimated by the bootstrapping algorithm. Instances in known and unknown domains are categorized by supervised or zero-shot classifiers. Challenges include reliance on robust classifiers and the limitations of naive bootstrapping in approximating distributions. The estimated \u03b4 c may be too relaxed, leading to a boundary that extends into the unknown domain. This can result in false positives for unseen instances. To address this, a shrinking step is suggested to update the initial boundary of bootstrapping. The key idea is to validate the trustworthiness of the learned classifier. The Kolmogorov-Smirnov (K-S) test is a distribution free method for comparing confidence score distributions of training and testing instances. When the null hypothesis is accepted, it indicates that the classifier is trustworthy. If the null hypothesis is rejected, a new uncertain domain is introduced to include instances with uncertain class labels. The uncertain domain is introduced to include instances with uncertain class labels. The mapping function is learned on the known domain to predict if a testing instance belongs to seen classes or uncertain/unknown domains. In OSL, only seen class prototypes are known, and a new set can be dynamically constructed for unseen classes. The sample size is usually the same as the number of target classes. Different recognition algorithms can be applied in each domain. In the unknown and uncertain domains, a simple yet effective feature prototype embedding recognition algorithm is proposed. ZSL algorithms are used to map from feature space to semantic/attribute space. The domain division part is the main contribution, utilizing the simplest linear predictor for recognizing unseen classes. Feature prototypes are used to balance sample sizes among classes. In the unknown or uncertain domain, a linear predictor is used to predict attribute vectors. Feature prototype embedding is computed using semantic prototypes of classes. Experimental settings include OSL and G-ZSL validations. G-ZSL provides class labels for unseen classes. The model can be implemented with f-CLSWGAN for G-ZSL within a single domain. The study compares G-ZSL with various competitors using SVM with RBF kernel. The competitors include Attribute Baseline, W-SVM, One-class SVM, Binary SVM, OSDN, and LOF. The metric used is the F1-measure, which combines seen class accuracy and unseen prediction accuracy. The Attribute Baseline variant does not use domain division algorithm. The study compares G-ZSL with competitors using SVM with RBF kernel, showing significant performance gains for AwA, aPY, and ImageNet. The improvement is attributed to the newly introduced uncertain domain, distinguishing known and unknown instances. Results of Generalized Zero-Shot Learning experiments are compared in Tab. 2, with separate settings for seen and unseen classes. Our study evaluates G-ZSL performance against competitors using various methods like DAP, ConSE, and CMT. Results show that our harmonic mean metric outperforms all competitors on multiple datasets, especially on AwA and aPY, due to our domain division algorithm and f-CLSWGAN implementation. Our framework's key advantage lies in better dividing testing instances into known, uncertain, and unknown domains. In the known domain, we use a standard SVM classifier, while in unknown/uncertain domains, we embed feature prototypes into a semantic space to match the most likely class. This straightforward recognition method contributes to our good performance on G-ZSL, with the domain division algorithm playing a crucial role. Additionally, we note that other advanced algorithms can complement our framework for further performance improvement. Our domain division algorithm excels in separating testing instances into different domains, leading to superior recognition performance in G-ZSL compared to other state-of-the-art methods. The algorithm addresses the intrinsic difficulty of G-ZSL on large-scale datasets by effectively categorizing instances. Additionally, we observed that the ConSE BID22 prediction is biased towards known classes, a common issue in large datasets where unseen classes may not receive higher probabilities than seen classes. The study focuses on improving recognition performance in generalized zero-shot learning by addressing the bias towards known classes. A variant A framework with bootstrapping shows better results than a variant B without fine-tuning the threshold. This emphasizes the importance of determining the initial threshold by bootstrapping. The study compares variant A and variant B frameworks for generalized zero-shot learning. Variant A, which includes bootstrapping and fine-tuning the threshold, outperforms variant B in recognizing unknown classes. The two steps in the framework complement each other to achieve good performance in OSL and G-ZSL. The paper introduces variant C, utilizing W-SVM for OSL and their ZSL model for G-ZSL, showing significantly lower performance compared to their model. It focuses on dividing instances into known, unknown, and uncertain domains using bootstrapping and K-S Test, achieving remarkable results for recognition tasks."
}