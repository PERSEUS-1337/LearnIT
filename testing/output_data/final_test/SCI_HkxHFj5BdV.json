{
    "title": "HkxHFj5BdV",
    "content": "The paper proposes the strategy of parallel recurrent data augmentation to address the challenge of limited training data in applying generative adversarial networks (GAN) for image generation. This method enriches the training set by constructing sample images from GANs trained in parallel at consecutive epochs. Experimental results show that this approach improves image quality compared to traditional methods, with the source code and generated images to be made public after review. Generative Adversarial Networks (GAN) are powerful unsupervised learning models that have achieved success in learning high-dimensional distributions. The GAN model consists of a generator that translates random input into images and a discriminator that determines image authenticity. The training process involves optimizing these components to minimize the difference between generated and real image data distributions. A challenge in GAN training is the need for large amounts of labeled data to capture diverse image features. The paper proposes a method using recurrent image addition to diversify training data for GANs without model specifications. It aims to enhance data quality and address misrepresentation issues in deep learning models influenced by adversarial noise. The approach includes a novel K-fold parallel framework for improved image generation. The paper introduces a novel K-fold parallel framework to enhance training data for GANs without model specifications. It aims to improve data quality and prevent overfitting, demonstrating effectiveness through authenticity measures like Inception Score and Frechet Inception Distance. Previous research has focused on optimizing GAN structures and augmenting training data to address labeled data scarcity. Recent research on GANs has explored reparametrizing input noise using variational inference, but this approach has limitations. Distributed multi-discriminator models have shown potential for performance enhancement. Data augmentation methods, such as crop, mirror, rotation, and distortion, have been successful in image classification tasks. Automatic augmentation of training data is a recent development that aims to provide more variation in augmented images. Recent developments in data augmentation involve using controlled RNNs for automatic augmentation of training data, but the search algorithm's space complexity is still a limitation. Parallel Recurrent Data Augmentation (PRDA) involves recurrent image data construction through noise addition and parallel generation with fold division. Adversarial noise can significantly impact the performance of deep neural networks, leading to misclassification of images. This is attributed to the omission of latent features in new data generation due to over-dependency on limited training data. The strategy of recurrent data augmentation involves generating varied images from a limited training set by repeatedly modifying samples. This helps counter the deficiency in latent feature representation in GANs, resulting in higher quality generated images. Random noise is added to sampled images to create new ones for subsequent training, repeated until convergence. FIG0 illustrates the procedure. The addition of high dimensional normal random noise in GAN training retains original latent features without information loss. This noise addition makes the model more robust and is independent of the generative model type. A parallel data generation strategy inspired by K-fold cross validation is introduced for improved training efficiency. The algorithm introduces a parallel data generation strategy inspired by K-fold cross validation to prevent overfitting and enhance model robustness. This approach involves adding random noise to sample images generated by each generator, which are then fed back into the training sets of all generators. This method ensures that different generators have access to varied data pieces during training, improving training efficiency and model performance. In our experiments, training different GANs in parallel from different folds of data significantly improves the quality of the training set and generated images. We tested DC-GAN, BEGAN, and WGAN-GP on various datasets with and without data augmentation. Limited data simulations were done by selecting 5000 images from CIFAR-10, CelebA, and Places datasets to create reduced datasets. Experiments were conducted on CPU Intel(R) Core(R) CPU 8700-K (3.7GHz) and GPU GTX 1080, with 8 noised images added to the training set every 100 epochs. Our method utilizes parallel recurrent image augmentation to improve GAN training, producing coherent and diverse images earlier than unaugmented GANs. Evaluation using Inception Score (IS) and Frechet Inception Distance (FID) shows higher diversity and closer resemblance to real data. Our method employs parallel recurrent sample augmentation to enhance GAN training, resulting in improved image quality. Evaluation using Inception Score (IS) and Frechet Inception Distance (FID) demonstrates better performance of the model with higher IS and lower FID values. The study shows that recurrent sample augmentation significantly enhances the quality of synthetic images across various GAN models and datasets. Our strategy is simple to implement and agnostic to the specific type of GAN. We are exploring the relationship between our approach and other methods, such as reinforcement learning for image generation control. Additionally, we aim to apply our idea to other generative models like VAE and optimize it further with recent theoretical advances."
}