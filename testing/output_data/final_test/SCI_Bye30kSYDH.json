{
    "title": "Bye30kSYDH",
    "content": "Generative Adversarial Networks (GANs) are widely used for learning generative models. A new approach called PolyGAN proposes using high-order polynomials as universal function approximators in the generator. This method reduces the number of parameters and can be efficiently implemented with hierarchical neural networks. PolyGAN introduces a novel approach using high-order polynomials as function approximators in GAN generators, eliminating the need for activation functions. Experimental results show PolyGAN's superiority in modeling data distributions compared to existing methods. Hierarchical deep networks are efficient universal approximators for continuous compositional functions, but non-linear activation functions pose challenges in theoretical analysis. Some methods focus on linear models to rigorously analyze neural network dynamics, residual design principles, local extrema, and generalization error. In this paper, the use of high-order polynomials as universal function approximators for data generator functions in GANs is explored. This choice is motivated by the Stone-Weierstrass theorem, which states that every continuous function can be closely approximated by a polynomial function. The proposed model involves modeling the generator function with a high-order multivariate polynomial. The paper explores using high-order polynomials as universal function approximators for data generator functions in GANs. The generator function Gpzq is modeled by a high-order multivariate polynomial of the latent vector z, with parameters represented by high-order tensors. To address the issue of exploding parameters, polynomial parameters estimation is approached as a coupled tensor factorization, introducing two coupled canonical polyadic decompositions for hierarchical parameter interactions. The paper proposes using high-order polynomials as universal function approximators for data generator functions in GANs. The generator function is modeled by a high-order polynomial of the latent vector, with parameters represented by tensors. Two different hierarchical structures of neural network decoders are developed, involving only linear units, to generate samples with increasing detail. The approach involves casting polynomial parameters estimation as a coupled tensor factorization, resulting in different neural network architectures. The proposed PolyGAN utilizes high-order polynomials to approximate functions and improve upon existing GAN architectures like DC-GAN, SNGAN, and SAGAN. By incorporating activation functions, PolyGAN generates intricate signals and improves sample generation quality. PolyGAN utilizes polynomial expansion to generate detailed samples in GANs. Different polynomial models are introduced with tailored tensor factorizations for parameter estimation. Matrices and tensors are denoted by boldface and calligraphic letters respectively. The order of a tensor is defined as the number of indices needed to address its elements. The CP decomposition factorizes a tensor into rank-one tensors using the outer product of vectors. It involves the Khatri-Rao product, Hadamard product, and factor matrices. The CP decomposition factorizes a tensor into rank-one tensors using factor matrices. GANs consist of a generator G and a discriminator D, both modeled as deep neural networks. The generator in GANs is modeled as a deep neural network, with each generated pixel expanded as an Nth order polynomial in z. The parameters of the polynomial expansion are scalar \u03b2i and tensors W. The weights vary based on the order of approximation, forming vectors for n=1, matrices for n=2, and tensors for n\u22653. The vector-valued generator function is defined by stacking the parameters for all pixels. The vector-valued generator function in GANs is expressed as a polynomial expansion in z, with parameters \u03b2 and tensors W. The model is prone to overfitting due to the exponential growth of unknown parameters with the order of approximation. To reduce the number of parameters, it is assumed that the weights exhibit redundancy and the parameter tensors are of low-rank. To reduce the number of parameters, low-rank tensor decompositions can be used. A CP decomposition is applied to parameter tensors W rns, resulting in significantly fewer parameters. However, a hierarchical approach is needed to consider the image's structure. To capture interactions among parameters, coupled CP decompositions with shared factors are introduced. Model 1 proposes a coupled CP decomposition instead of individual factorization of parameter tensors. Coupled CP decomposition is proposed to jointly factorize all parameter tensors with a specific pattern of factor sharing. A third-order approximation is assumed, but a generalization to N-th order is provided in the appendix. The parameters tensors have a coupled CP decomposition with shared factors across all tensors, allowing for a reduction in the number of parameters. Coupled CP decomposition jointly factorizes parameter tensors with shared factors, reducing the number of parameters. The third-order approximation can be implemented as a neural network with incremental growth. Model 2 introduces a coupled nested CP decomposition for hierarchical factorization of polynomial parameters. Utilizing a joint hierarchical decomposition on polynomial parameters with learnable hyper-parameters for scaling factors. Third-order function approximation is considered, and all parameter tensors are factorized using nested CP decomposition with parameter sharing. Implementation in a hierarchical manner with a three-layer neural network is shown in Figure 3. Comparison between two models based on polynomial expansion is discussed. The comparison between the two models based on polynomial expansion reveals that while the Coupled CP decomposition has a simpler expression, the Coupled nested CP decomposition is related to standard architectures using hierarchical composition. Experimental results show that neither model outperforms the other in all datasets, performing similarly. The Coupled nested CP decomposition is used by default in the paper, with an experimental comparison included in Section G. The recent survey by Creswell et al. (2018) provides further information. Our method introduces a mathematically elaborate approach for a more precise approximation using polynomial expansion. Unlike previous works, we multiply noise with feature representations instead of concatenating them. Our work is closely related to StyleGAN (Karras et al., 2019), an improvement over ProGAN (Karras et al., 2018), known for compelling results on synthesized 2D images. The authors discuss the improvements of StyleGAN over ProGAN, drawing on arguments from the style transfer literature. They propose using features from images for conditional image translation, different from unsupervised image generation. The authors suggest that these improvements can be better explained through their proposed polynomial function approximation, showing a hierarchical decomposition with increasing detail. They demonstrate the improvements in StyleGAN using a well-tuned model and highlight that polynomial generation can be applied to various architectures to consistently enhance performance. The proposed polynomial expansion consistently improves performance in experiments on synthetic data and higher-dimensional signals. Experiments include 2D and 3D manifolds, synthesizing digits, and working with images of faces and natural scenes. The polynomial-based generator with non-linearities is shown to be as powerful as contemporary architectures. The polynomial-based generator with non-linearities is powerful in experiments on synthetic data and higher-dimensional signals, including 2D and 3D manifolds, digit synthesis, and image processing. It matches a sin x signal in a bounded domain using linear blocks without activation functions. In Figure 4, 2,000 random samples are synthesized to verify that PolyGAN accurately approximates low-dimensional distributions like univariate sinusoidal without non-linear activation functions. A new polynomial generator Gpzq: R128 \u00d1 R32x32 is devised using a fourth-order approximation with a residual block Sris and identity matrix Bris. This extends the linear generator to greyscale images, a novel approach not seen before. The identity matrix Bris and residual block Sris are used in the linear generator for digit generation on MNIST dataset. The discriminator and optimization procedure are similar to SNGAN, with one discriminator step per generator step. PolyGAN synthesizes plausible digits compared to other methods, utilizing labels for conditional batch training. PolyGAN utilizes class labels for conditional batch normalization in training a conditional GAN. The synthesized samples show improvement over unsupervised methods, with PolyGAN generating digits with varying thickness, style, and rotation. Data generation is approached as a polynomial expansion task, with high-order polynomials modeled using tensorial factors. Two tailored coupled decompositions are introduced to implement polynomial parameters through hierarchical neural networks, such as generators in a GAN setup. PolyGAN utilizes high-order polynomials in a GAN setup to synthesize images using linear blocks and non-linear activation functions. The approach links polynomials, tensor decompositions, and network architectures. The appendix includes Lemmas, Coupled CP decomposition, and 3D experiments. The Coupled CP decomposition is used for N th order expansion. Section D extends experiments to 3D manifolds, while Section E conducts additional experiments on image generation with linear blocks. Section F compares popular GAN architectures with polynomial equivalents for image generation. Section G compares two proposed decompositions on data distributions. The text discusses a simple case with two matrices, proving a special case with N greater than 2. It involves matrix products, Khatri-Rao definition, and Hadamard products in the context of matrix multiplication. The text discusses matrix products, Khatri-Rao definition, and Hadamard products in the context of matrix multiplication. It proves that a specific equation is equivalent to a three-layer neural network. In Claim 2 and Claim 3, it is proven that a specific equation is equivalent to a three-layer neural network. The polynomial generator can be transformed into a network architecture for third-order approximation, and the Coupled CP decomposition generalizes to the N th order approximation. The N th order approximation of a polynomial can be converted into a neural network structure using a decomposition method. This approach is proven through induction, with specific equations equivalent to neural networks for different orders of approximation. The N th order approximation of a polynomial can be converted into a neural network structure using a decomposition method. The induction proof shows that it holds for N`1 th order approximation. A superellipse with a parametric expression is implemented, showing a more complex distribution with four sharp edges. PolyGAN accurately models the data distribution in experiments derived analytically. In experiments derived analytically, PolyGAN successfully captures data distribution on various manifolds including Sin3D, Swiss roll, and Gabriel's Horn. PolyGAN outperforms 'Orig' and 'Concat' in visualizing data distribution, and learns to generate samples despite challenging curves. PolyGAN learns to generate diverse images of faces from the YaleB dataset, capturing extreme illuminations and rescaling them to 64x64. The method produces images with illuminations on different parts of the face, unlike 'Orig' and 'Concat' which only illuminate one side. The method PolyGAN generates diverse face images with extreme illuminations on different parts of the face, unlike 'Orig' and 'Concat' which only illuminate one side. It also fails to capture fine facial details. Additionally, the method is evaluated on natural images from CIFAR10 dataset. Our model, PolyGAN, outperforms 'Orig' and 'Concat' in Inception Score and Frechet Inception Distance metrics. It demonstrates flexibility by using DCGAN, SNGAN, and SAGAN architectures with polynomial expansion. Key differences from traditional approaches are presented in Algorithms 3 and 4. In addition to the baseline, an alternative approach called \"Concat\" is implemented by concatenating noise with feature representations, increasing the number of trainable parameters substantially. To reduce variance during GAN training, scores are averaged over 10 runs with different seeds using Inception Score (IS) and Frechet Inception Distance (FID) metrics. In an ablation study on Section F.2, experiments on unsupervised (Section F.3) and conditional image generation (Section F.4) are presented using CIFAR10 and Imagenet datasets. CIFAR10 includes 60,000 images of 32x32 resolution, while Imagenet has over one million training images and 50,000 validation images reshaped to 128x128 resolution. Baseline architectures include DCGAN and SNGAN, known for their strong performance in GANs. SNGAN is a powerful GAN with spectral normalization in the discriminator. SAGAN is a recent architecture using self-attention in GANs, achieving impressive results on Imagenet. Evaluation metrics include Inception Score (IS) and Frechet Inception Distance (FID) for quantitative assessment. Source code will be released for result reproduction. Both the Inception Score (IS) and Frechet Inception Distance (FID) are widely used metrics for evaluating generative models. IS measures the quality of generated samples based on conditional label distribution, while FID compares feature representations of real and generated images assuming Gaussian distributions. The Inception Score is computed for 5,000 generated samples per run, following methods in the literature. The FID metric is calculated using real and fake image representations N p\u00b5 r , C r q and N p\u00b5 f , C f q respectively. In the experiments, 10,000 real images and synthesized samples are used to compute mean and covariance. Affine transformations on input noise z are found beneficial before using it for Hadamard products. DCGAN and SNGAN networks use global transformations followed by RELU non-linearity. In the experiments, a global transformation with a RELU non-linearity is considered for image generation using SNGAN architecture. Two alternatives are evaluated: linear global transformation ('Ours-linear-global') and global transformation followed by a RELU non-linearity ('Ours-RELU-global'). Results show marginal improvements in both metrics with the latter approach. The study evaluates the impact of adding a non-linear activation function to the SNGAN architecture, showing marginal improvements in metrics. The noise vector z is split into chunks for injections, with the splitting technique leading to decreased scores in the task. Normalization techniques were scrutinized on the baseline 'Ours-RELU-global', with improvements shown in Table 7. Comparisons were made in Table 8 against the model with skip connection ('Ours-skip'). Results were verified in the conditional setting, showing improved IS score in Table 9. In Table 10, quantitative results comparing baseline and skip connection cases are presented for image generation without labels. DCGAN and resnet-based SNGAN architectures are used in CIFAR10. Table 11 summarizes IS/FID scores, with PolyGAN outperforming other methods. Class information can be utilized for conditional image synthesis using conditional batch normalization or class embeddings. The SAGAN method utilizes self-attention blocks to enhance the resnet-based generator. Despite efforts to be architecture and database agnostic, recent methods require extensive training time and computational resources. SAGAN typically needs multiple GPUs for weeks to achieve optimal results, but we ran it on a single GPU for 6 days with reduced batch size. Our approach's FID/IS scores compared to the baseline method are provided in Table 12. Our proposed method outperforms the baseline in terms of Inception Score and FID, as shown in Table 12. Experimental comparison of two models is conducted without non-linear activation functions, using polynomial expansions with linear blocks. Four experiments are performed, including Sinusoidal on 2D and Astroid data distributions. The comparison in Figure 13 demonstrates that both models can capture the data manifold effectively. The experiment conducted involves comparing two models on different data distributions (Astroid, Sin3D, Swiss roll) using images of digit samples. The models utilize Coupled CP decomposition with linear convolutions and a linear residual block. Activation functions are removed except for a single tanh in the generator's output for normalization."
}