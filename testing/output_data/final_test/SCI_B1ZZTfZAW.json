{
    "title": "B1ZZTfZAW",
    "content": "Generative Adversarial Networks (GANs) have been successful in producing realistic data. A Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) are proposed for generating real-valued time series, particularly in medical data. RGANs use recurrent neural networks (RNNs) in the generator and discriminator, while RCGANs are conditioned on auxiliary information. These models are tested on toy datasets, showing their ability to generate realistic time-series. Novel evaluation methods involve generating synthetic labeled training data and testing on real data, demonstrating the effectiveness of RCGANs. RGANs and RCGANs can generate realistic time-series data for supervised training, with minor performance degradation on real test data. This is shown in digit classification and training an early warning system on a medical dataset. Privacy concerns when using RCGANs for synthetic medical data are discussed, along with results from differentially private training. The availability of standard datasets has advanced learning systems in various tasks, but progress in medicine lags behind. The motivation for this work is to use generative adversarial networks (GANs) to create realistic synthetic medical data that can be shared without privacy concerns. This data can help in model comparisons, reproducibility, and scientific progress in the field of medicine. Generating realistic ICU situations using GANs can benefit medical training by providing diverse and realistic data for simulations in time-sensitive environments like Intensive Care Units. This approach can improve the training of doctors by simulating patient states and scenarios without relying on hand-engineered rules or physical props. The success of GANs in generating realistic images suggests their potential for generating time-series data, although limited work has been done in this area. Evaluation of GANs remains a challenge, often relying on visual assessment which is impractical for medical time series. Some studies have used convolutional GANs for video sequence generation and voice synthesis models evaluated by humans. The primary contributions of this work include generating multivariate real-valued sequences using adversarial training and recurrent neural networks, novel approaches for evaluating GANs, generating synthetic medical time series data, and empirical privacy analysis of GANs. Previous research has focused on image generation with GANs, but there is potential to combine approaches for generating multi-modal synthetic medical time-series data. The work focuses on generating multi-modal synthetic medical time-series data using GANs and recurrent neural networks. A novel approach is introduced for evaluating GANs, including a conditional version of Recurrent GANs. This approach allows for directing the data generation process by conditioning the model on additional information. The text discusses the use of Conditional GAN architectures in natural language processing and introduces novel approaches to evaluate GANs by generating synthetic data for training models. It also mentions the use of differentially private stochastic gradient descent to enhance privacy in generating data, especially for sensitive medical data. The text introduces the Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) models, which use recurrent neural networks to generate sequences of real-valued data. The models can also generate data subject to conditional inputs, enhancing privacy for sensitive medical data. The discriminator RNN in RGAN and RCGAN models classifies generated sequences as real or synthetic by minimizing cross-entropy with labels. The generator aims to deceive the discriminator into classifying its outputs as real. The generator in RCGAN aims to deceive the discriminator by minimizing cross-entropy with labels on generated sequences. The architecture for both discriminator and generator RNNs is LSTM BID16, with conditional information added to each RNN in the form of c n at each time-step to prevent discounting. In RCGAN, research on alternative GAN objectives like Wasserstein GAN does not easily apply. Enforcing Lipschitz constraint on RNNs is a topic for further study, possibly aided by unitary RNNs. Evaluating GAN performance is challenging, with metrics like Inception score used in the imaging domain. In this work, the Inception score BID31 is used for evaluation, and Mechanical Turk is utilized for distributing human labor. However, visually evaluating real-valued sequential data, such as ICU signals, can be challenging. The model is demonstrated with toy datasets first, followed by quantifiable methods to assess data quality. The generator LSTM Z generates synthetic signals with different random seeds at each temporal input. The RCGAN generates synthetic signals with an additional input that conditions the output. The success of a GAN is determined by its ability to learn the distribution of true data, evaluated through generated samples. Maximum mean discrepancy (MMD) is used as a training objective to compare statistics of samples from the GAN and true data distribution. Active research focuses on defining appropriate kernels for comparing time series data. Defining appropriate kernels for comparing time series data is an active research area. The generated and real samples are aligned by fixing the 'time' axis. Time series are treated as vectors for comparisons using the radial basis function (RBF) kernel. The kernel bandwidth \u03c3 is selected by maximizing the estimator of the t-statistic of the power of the MMD test. A mixed kernel is defined as a sum of RBF kernels with two components. The text discusses the use of a mixed kernel in GANs to optimize bandwidth and evaluate the output using the \"Train on Synthetic, Test on Real\" (TSTR) method. This method involves training a model on synthetic data generated by the GAN and testing it on real examples. The evaluation metric is ideal for sharing synthetic data, showcasing its usability. The text presents the pseudocode for the GAN evaluation strategy, including the TSTR method (Train on Synthetic, Test on Real) and the TRTS method (Train on Real, Test on Synthetic). TSTR involves training on synthetic data and testing on real data, while TRTS reverses this process by training on real data and testing on synthetic data using RCGAN. In experiments with synthetic data, the RGAN model generates realistic sequences, focusing on nonconditional models. By varying amplitudes and frequencies, datasets with nonlinear variations are created. Waves with frequencies in [1.0, 5.0] and amplitudes in [0.1, 0.9] are generated for visual inspection. The study involved generating waves with frequencies in [1.0, 5.0], amplitudes in [0.1, 0.9], and random phases between [\u2212\u03c0, \u03c0]. Despite no constraints on semantics in the latent space, altering frequency and phase of generated samples was possible by varying latent dimensions. Training a recurrent Variational Autoencoder (VAE) was attempted for comparison with RGAN, using a straightforward implementation with RNNs. After experimenting with replacing the encoder and decoder of a VAE with RNNs, the study found that the generated sine waves had inconsistent amplitudes and frequencies, performing worse than the RGAN. Further research is needed for this approach. Source code for the experiments is available in the mentioned git repository. The study compared scores of a convolutional neural network trained and tested on real data, synthetic data, and a combination of both. The model struggled to reproduce complex physiological signals, opting to learn arbitrary smooth signals using Gaussian processes with a RBF kernel. 30 equally-spaced samples were drawn from the GP. The study used a GP with zero-valued mean function to draw 30 equally-spaced samples from a multivariate normal distribution with an RBF kernel. The generated time series showed smoothness with local correlations, rapidly captured by the RGAN. The average likelihood of generated samples increased under the data distribution during training, although it did not account for sample diversity. Generating MNIST digits sequentially is a less common task, but can be achieved with RGAN by serializing each 28x28 digit into a 784-dimensional vector. This allows for visually assessable samples to be produced. The RGAN can generate MNIST digits in a sequential manner by treating each 28x28 image as a sequence of 28, 28-dimensional outputs. Two types of experiments are conducted with this dataset: one generating realistic digits and the other downsampling digits to 14x14 pixels for classification tasks using RCGAN and TSTR evaluations. The study evaluates the performance of a classifier trained on real data and tested on synthetic data generated by a GAN. Results show that the synthetic datasets are realistic enough to achieve high performance on real test data. The goal is to generate realistic medical datasets, focusing on ICU data using the Philips eICU database. The Philips eICU database contains data from 200,000 patients across 208 care units in the US. The focus is on four key variables: oxygen saturation, heart rate, respiratory rate, and mean arterial pressure, measured every five minutes and downsampled to one measurement every fifteen minutes. This approach speeds up training of the LSTM-based GAN while capturing relevant data dynamics. The study considers the beginning of a patient's ICU stay as a critical time in their care. After downsampling the data from the Philips eICU database, a cohort of 17,693 patients was obtained, focusing on the first 4 hours of their ICU stay. The most critical requirement was non-missing mean arterial pressure (MAP) values. Evaluating the performance of the ICU RCGAN using the TSTR method required a supervised task on the data. A supervised task in the ICU involves predicting whether a patient will become 'critical' in the near future. Critical thresholds for SpO2, HR, RR, and MAP are defined to generate binary labels based on data trends. The thresholds were selected by comparing rough healthy ranges with ICU patient data distributions. The study focused on generating synthetic data for ICU patients using a random forest model. Candidate values were selected for cutoffs to ensure task feasibility with real data. Labels were sampled from real data for the synthetic dataset to maintain label distribution consistency. The RCGAN was trained for 1000 epochs and evaluated using TSTR. Cross-validation was used to select the best synthetic dataset based on classifier performance. The study used cross-validation to select the best synthetic dataset for ICU patient data. Results showed that the GAN may be memorizing training data, raising privacy concerns for sensitive medical data. It is crucial to ensure that training data cannot be recovered by adversaries. The study raised privacy concerns as the GAN may be memorizing training data, making it crucial to ensure data is not recoverable by adversaries. Tests were conducted to evaluate the privacy properties of RGAN generated data, with a focus on preventing overfitting to the training data. The study evaluated the privacy properties of RGAN generated data to prevent overfitting. Performance of random forest classifier trained on synthetic data by differentially private GAN was tested on real data. Training data was selected based on performance on specific tasks. The study evaluated the privacy properties of RGAN generated data to prevent overfitting. Performance of random forest classifier trained on synthetic data by differentially private GAN was tested on real data. Nearest neighbors were generated by minimizing reconstruction error. The distribution of errors between training and test sets was compared using Kolmogorov-Smirnov two-sample test. RGAN generating sine waves had a p-value of 0.2 \u00b1 0.1. The study compared distribution of errors between training and test sets for different experiments. Results showed no significant difference in reconstruction errors, indicating no bias towards training set examples. The model may overfit if latent space is highly peaked around training examples, leading to similar generated samples along a smooth path until reaching another training example. The study tested the model by sampling pairs of training examples and interpolating between their latent points to generate samples. The generated samples showed incremental variation, indicating the model did not simply memorize the data. The MMD threesample test was used to compare the full set of generated samples with the test and training sets. The study used the MMD three-sample test to compare generated samples with test and training sets. Average p-values for different datasets ranged from 0.07 to 0.59, indicating the model did not memorize the training data. The study used the MMD three-sample test to compare generated samples with test and training sets, concluding that the synthetic samples do not look more similar to the training set than they do to the test set. Differential privacy was investigated for stronger guarantees of privacy for synthetic medical data. The study applied differential private stochastic gradient descent (DP-SGD) to ensure privacy in training a GAN. The algorithm operates by clipping the gradients to limit the impact of individual data points on the model. DP-SGD operates by clipping gradients and adding noise in batches to provide differential privacy. Privacy budget is 'spent' during training, with hyperparameters adjusted for acceptable privacy and realistic GAN samples. Results on MNIST and eICU tasks with RCGAN show accuracy levels achieved with varying levels of privacy. The results of training a GAN with privacy constraints on MNIST and eICU datasets are discussed. Despite lower accuracy compared to non-private GANs on MNIST, eICU tasks show high performance with differential privacy. Different hyperparameters were used for each dataset to balance privacy and sample quality. The differential-private GAN shows promising results in generating sequences for tasks involving extreme values, despite producing less realistic samples. The introduction of privacy-preserving noise allows for training downstream models, opening up new research directions at the intersection of privacy and GANs. We introduced a recurrent GAN architecture called RGAN for generating real-valued sequential data and a conditional variant RCGAN for generating synthetic datasets with labels. Novel solutions were presented for evaluation and privacy challenges. The 'TSTR technique' was used to evaluate model quality by training on synthetic data and testing on real data. Performance of models trained on synthetic data was comparable to real data in domains like medicine. With refinement of techniques, models could be developed on synthetic data for sensitive domains like medicine. Synthetic datasets could be used for benchmarking and do not pose major privacy concerns. Differential privacy can be used for stricter privacy guarantees with some loss to performance. Data from real eICU patients with added noise for privacy protection was compared. The data at its original sampling resolution is compared with downsampled data to one measurement every 15 minutes and 30 minutes. High-frequency fluctuations are lost through downsampling, but general trends and some variability are preserved in the 15 minute case. Patients selected randomly from the set with minimal missing data are representative of the cohort used to generate the training data. Samples from the generator trained on eICU data are from synthetic datasets used in TSTR experiments. The generator produces data in [\u22121, 1], and medically relevant values are obtained by applying the inverse of the scaling transformation used on the training data. The synthetic data, generated from the TSTR experiments in eICU, is scaled to [\u22121, 1] independently for each variable at each time-point. An outlier in mean arterial pressure at 135 minutes causes a downward spike in the data. The synthetic data is compared with the real data used for training, showing differences between the two datasets."
}