{
    "title": "Bk9nkMa4G",
    "content": "The real visual world has a long-tailed distribution with some classes being common and others rare. Convolutional neural networks struggle with long-tailed datasets, so a method using a Gaussian mixture model is proposed to balance class-priors and improve performance on rare classes. This approach is simple and effective, as demonstrated in experiments on publicly available datasets. Deep convolutional neural networks have shown impressive results in visual recognition tasks, but they often learn from artificially balanced datasets that do not reflect the real-world distribution. The real visual world follows a long-tailed distribution, with some classes being common and others rare. This imbalance poses a challenge for CNNs, leading to a proposed method using a Gaussian mixture model to balance class-priors and improve performance on rare classes. Recent efforts in visual recognition aim to address the challenge of learning from long-tailed datasets, where classes in the tail are underrepresented. Training models on such datasets often result in unsatisfactory performance, as classifiers tend to generalize well for common classes but struggle with rare ones. To improve performance, classifiers need to generalize effectively for all classes, including those in the tail. Various approaches such as penalizing optimization-learning problems and sampling-based methods have been proposed to tackle this issue. The proposed method aims to learn an embedding in which the distribution of the real visual world allows a simple Bayesian classifier to predict robustly given a long-tailed dataset. Long-tailed datasets have class-prior statistics that heavily skew towards classes in the head, biasing classifiers and reducing generalization for classes in the tail. To address this, a generative (Bayesian) classifier is built over a learned embedding to compute class-posterior probabilities. In an empirical Bayesian framework, posteriors are computed through class likelihoods and priors fit to the data using a Gaussian Mixture Model. A pipeline is introduced for jointly learning embeddings and Bayesian models. Bayesian models are suitable for long-tailed datasets as they ensure a balanced representation. The goal is to learn a feature embedding where class prior statistics do not skew class likelihoods, achieved through a Gaussian mixture model. The proposed approach utilizes a Gaussian Mixture Model (GMM) for clean factorization of class-likelihoods and priors in a Bayesian classification framework. By fixing covariance matrices and enforcing uniform priors, it ensures equal weight for rare and dominant classes, leading to accurate class posteriors. This method does not learn embeddings in the traditional Bayesian sense but focuses on producing balanced class likelihoods. The proposed approach learns a single discriminatively trained embedding for Bayesian classifiers using a Gaussian Mixture Model (GMM). This GMM allows for flexibility in evaluating long-tailed datasets by adjusting class-prior probabilities to balance out class-priors and improve generalization for classes in the tail. The proposed method uses a Bayesian classifier with a Gaussian Mixture Model to balance class-priors and improve classification performance for classes in the tail. It aims to address challenges in learning from long-tailed datasets and few-shot learning, showing better performance on tail classes compared to existing methods. The proposed approach for few-shot learning involves using a GMM model and class-centroid representations for incremental learning. Techniques like random oversampling and random undersampling are used to address imbalanced datasets by balancing the training set. An alternative approach for long-tailed datasets is MetaModelNet, a meta-learning algorithm that improves CNN model performance through transfer learning. MetaModelNet enhances CNN model performance by transferring parameter-evolution knowledge from data-rich classes to tail categories. This approach aims to learn an embedding for classifiers to generalize on long-tailed datasets, complementing sampling or transfer-learning methods. Another recent approach for few-shot learning involves learning a feature embedding from classes with the most samples and \"hallucinating\" samples for classes with few instances. The proposed approach aims to learn an embedding for generalization on long-tailed datasets, different from previous methods like iCaRL. It uses a generative model to learn the embedding, avoiding bias towards classes with abundant training instances. The proposed approach uses a generative model to learn an embedding for generalization on long-tailed datasets. It utilizes a GMM to minimize intra-class variation and improve discriminative properties without bias towards classes with abundant training instances. Unlike center-loss methods, the approach automatically minimizes intra-class variation by finding GMM parameters in the learned embedding through back-propagation. This differs from Prototypical Networks that estimate class centroids from a subset of the training set. The proposed approach utilizes a generative model to learn an embedding for long-tailed datasets, focusing on minimizing intra-class variation and improving discriminative properties. It differs from Prototypical Networks by using regular batching mechanisms and back-propagation for parameter updates, avoiding modifications to deep learning frameworks. The goal is to create an embedding that enables a simple Bayesian classifier to operate effectively on imbalanced datasets. The proposed approach aims to create an encoder for Bayesian classification on long-tailed datasets by learning a model that describes the data distribution. It involves encoding features for images and their class labels, using joint probability to describe the training set distribution. The likelihood function with parameters \u03b8 y describes the feature vectors distribution, while the joint probability function with encoder w and Bayesian parameters \u03b8 includes the likelihood. The objective is to jointly learn the encoder weights and Bayesian parameters for good classification performance on a training dataset of images and labels. The posterior probability for class y given a feature vector x is computed using Bayes rule with likelihood parameters and priors. The class posterior probability depends on the encoder parameters w and Bayesian parameters \u03b8. In order to learn parameters for good classification performance, the approach proposes maximizing the Bayesian class-posterior probability of true class labels using MLE estimates. The problem is reformulated as an unconstrained optimization with a penalty term to penalize violations of constraints. The optimization searches over feature encoder parameters and Bayesian parameters to maximize class posterior probabilities, with a regularization term to penalize deviations from MLE estimates. The likelihood models are crucial for determining parameters in the proposed approach. The proposed approach uses a multivariate Gaussian likelihood model and implicitly employs a Gaussian mixture model to represent the distribution of the training set. This choice brings benefits due to the intuitive parameters of the Gaussian (centroid \u00b5, covariance matrix \u03a3, and prior \u03c0) and its closed-form maximum-likelihood estimators. The use of a Gaussian mixture model not only simplifies the formulation but also improves generalization for classes in the tail. The proposed approach uses a Gaussian mixture model to represent the distribution of the training set, improving generalization for classes in the tail. A Bayesian embedding model is compared with a traditional softmax classifier, showing that easy examples of a class can be more informative for learning in the Bayesian framework. Estimating the centroid with a few examples using a Gaussian Mixture Model (GMM) is simple and effective. GMM allows for specific parameter control to balance class footprints in the embedded space. By fixing covariance matrices and class priors, the remaining parameters to estimate are class means. Deep-learning frameworks using mini batches transform the unconstrained problem into a more manageable form. Other probabilistic models, such as deep embeddings for rectified or binary features, may be more appropriate for certain cases. These models do not have closed form maximum likelihood estimates and may be challenging to formulate precisely. The GMM-based formulation has a direct relationship with softmax classifiers, indicating that the proposed approach fits linear models. The proposed approach fits linear classifiers with restricted biases, useful for easy implementation in deep learning frameworks. It requires fewer parameters to learn compared to classical CNN-softmax models. An intuitive comparison between GMMs and softmax classifiers can be made regarding parameter updates. Easy examples in softmax training do not generate model updates, while in GMMs, they change centroids, signaling learning. The experiments evaluated the learned embedding using the proposed method on long-tailed datasets, including small-scale datasets like MNIST and CIFAR 10, and medium-scale datasets like CIFAR 100 and Tiny ImageNet 1. The goal was to show that the proposed approach can be adapted to any CNN architecture. The experiments evaluated classifiers on various datasets like MNIST, CIFAR 10, CIFAR 100, and Tiny ImageNet. Different approaches were considered, including iCaRL, center loss, and plain softmax classifier, with a variation of iCaRL also explored. The experiments evaluated classifiers on datasets like MNIST, CIFAR 10, CIFAR 100, and Tiny ImageNet. Different approaches were considered, including iCaRL and variations of it. Prototypical networks were mentioned but not included in the experiments due to dataset requirements. MetaModelNet, a meta-learning algorithm, operates at the classifier-parameter level and complements the proposed method. An open-source project implemented various legacy architectures and preprocessing imaging techniques for the experiments. The experiments used various CNN architectures like LeNet, CifarNet, AllCNN, and VGG 16 on datasets such as MNIST, CIFAR 10, CIFAR 100, and Tiny ImageNet. The proposed approach was implemented with a fully connected layer and center loss, with hyperparameters estimated using a validation set for each dataset. The code will be released upon publication. The main motivation of this work is to learn from a realistic dataset representing the statistics of the real visual world, which is long-tailed. The performance evaluation of the visual recognition system in this setting needs to be discussed, as common evaluation methods may not be adequate. While a long-tailed testing set may favor a simple classifier biased towards common classes, achieving good performance for rare classes is still important in practical applications. In real-world applications like self-driving cars, it is crucial to evaluate systems on rare events, not just common ones. Average accuracy on long-tailed datasets may not accurately reflect performance on rare classes. Evaluating per-class accuracy can help, but it may lead to unreliable estimates for rare classes in the tail. In real-world applications like self-driving cars, it is important to evaluate systems on rare events, not just common ones. Average accuracy on long-tailed datasets may not accurately reflect performance on rare classes. A proposed evaluation approach addresses bias towards the head and intra-class variation in the tail by using different versions of long-tailed training sets and a balanced testing set. This helps account for unreliable estimates for rare classes in the tail. The experiments involved creating long-tailed datasets by adjusting the number of training instances for each class using an exponential distribution. This helped address bias towards common classes and intra-class variation in rare classes. The resultant long-tailed datasets were visualized in FIG2. The experiments evaluated the learned embedding using long-tailed datasets to measure classification improvement for tail classes compared to a regular softmax classifier. The proposed method achieved comparable accuracy overall while increasing performance for tail classes. The experiments computed deep features using a feature encoder for training and testing sets. Class centroids were calculated using long-tailed training data. Different methods were trained and tested on long-tailed datasets to measure classification improvements. The average class-accuracy was calculated for each method and compared to a softmax classifier. The experiments compared different methods, including iCaRL and Centerloss, with a softmax classifier on the MNIST dataset. Results showed that most methods performed similarly to the softmax classifier, except for the GMM method which underperformed for tail classes. The proposed and competing methods worked well on datasets with minor visual variations. On CIFAR 10, the proposed approach and competing methods showed comparable performance. The proposed approach and competing methods perform comparably to a softmax classifier for classes in the head, with an increase in relative performance for classes in the tail. The proposed approach achieved the highest average class-accuracy of 68% on the dataset. Results on CIFAR 100 show that the proposed method achieves comparable performance with a softmax classifier for classes in the head, while competing methods have a larger decrease in accuracy. The GMM method underperforms for classes in the tail. The proposed approach shows increased performance for classes in the tail compared to competing methods and a softmax classifier. Results on Tiny ImageNet also demonstrate this trend, with the GMM approach performing poorly for classes in the tail due to inadequate data for covariance estimates. TAB0 breaks down the average relative performance for classes in the head and tail, excluding the GMM approach. The experiments used a weighted average to emphasize the relative performance of classes with abundant training instances while decreasing the contribution of classes with scarce data. The weight for each class was calculated based on the number of training instances. This approach aimed to highlight the performance of classes in the tail while diminishing the performance of classes in the head. The proposed approach with regularizer improves classification accuracy on CIFAR 10 and CIFAR 100. It maintains performance for classes in the head and enhances performance for classes in the tail. The experiment compares the proposed method with a hyperparameter \u03bb = 0 to measure the benefits of the regularizer. The experiment with a regularizer on CIFAR 10 and CIFAR 100 showed improved classification performance. The regularizer aims to retain centroids close to batch-sample-mean centroids, resulting in better overall accuracy. The experiment on CIFAR 100 showed that a regularizer with \u03bb = 0.0001 consistently improved classification accuracy across all classes. The proposed method based on a Gaussian mixture model enhanced performance for classes in the tail, maintaining comparable accuracy overall. The work introduced an evaluation method for learning concepts from long-tailed datasets and demonstrated that class-centroid approaches generalize well for classes in the tail. The experiments used the same framework parameters for all methods, including an Adam optimizer and batch size of 32. The experiments used default parameters in TensorFlow Models for exponential-learning-rate decay, weight decay, and drop-out. Hyperparameters for center-loss were set at 0.5 for centroids learning rate and 0.001 for MNIST and CIFAR 10, 0.0001 for CIFAR 100 and Tiny ImageNet. The proposed method had hyperparameters set at 0.001 for MNIST and CIFAR 10, and 0.0001 for CIFAR 100 and Tiny ImageNet."
}