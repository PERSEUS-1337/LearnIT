{
    "title": "H1e_Qy_toX",
    "content": "Deep learning has limitations due to data availability, leading to the proposal of Consensus Networks (CNs) to address data sparsity. Transductive Consensus Networks (TCNs) extend CNs for semi-supervised learning by compressing input modalities into latent representations. TCNs aim for indistinguishable representations through adversarial training. Three variants of TCNs are studied, focusing on consensus and classification mechanisms. Latent representations are treated as probability distributions, with their similarities measured using negative relative Jensen-Shannon divergences. A stable consensus state is shown to benefit classification despite imperfections. TCNs outperform benchmark algorithms with 20 to 200 labeled samples on Bank Marketing and DementiaBank datasets. Deep learning excels at learning complex structures from large datasets, but acquiring labeled data can be challenging. Transductive learning utilizes unlabeled data structures to enhance classifier performance. Data can span multiple modalities, but many transductive algorithms do not leverage this. Co-training and tri-training use one classifier per modality to supervise each other. Consensus Networks (CNs) incorporate co-training for multi-modal datasets, showing promising results in detecting cognitive impairments from speech data. CNs consist of interpreters, a discriminator, and a classifier. However, CNs are limited by training data availability, leading to the development of Transductive Consensus Networks (TCNs). TCNs operate as consensus or classifier mechanisms, encouraging modality representations to align for improved predictions. The Transductive Consensus Networks (TCNs) consist of consensus and classifier mechanisms that align modality representations for better predictions. An ablation study compared TCN to its variants TCN-embed, TCN-svm, and TCN-AE, showing the importance of both mechanisms working together. The similarity between latent representations was analyzed using negative Jensen-Shannon divergences, revealing that a meaningful consensus state prefers suboptimal similarities. Experiments compared TCN to CN and other semi-supervised learning benchmarks. The Transductive Consensus Networks (TCNs) align modality representations for better predictions and outperform benchmarks with as few as 20 labeled points. Transductive SVMs (TSVMs) minimize hinge loss on unlabeled data and have shown good performance on datasets. Many semi-supervised learning algorithms use autoencoding or GAN approaches to learn low-dimensional representations. In semi-supervised learning, various approaches like denoising autoencoders, Ladder networks, and generative adversarial networks (GANs) are used to learn low-dimensional representations and improve model performance with limited labeled data.GANs employ a generator to produce data similar to real data, while Feature-matching GANs incorporate synthetic samples to enhance discriminator training. In semi-supervised learning, GANs use synthetic samples to improve model performance with limited labeled data. Categorical GANs optimize uncertainty in the absence of labels, while CNs and TCNs apply adversarial principles from GANs. Various models, like Parallel Consensus Networks, aim to make multiple components in the network agree with each other. BID13 proposed consensus optimization in GAN to alleviate adversity between generator and discriminator. Multi-modal learning involves utilizing multiple modalities or viewpoints to classify cognitive impairments. While some approaches focus on domain adaptation with multiple domains, our approach only handles data from one domain. Consensus Networks have been extended for semi-supervised learning in the context of multimodal data. Transductive Consensus Networks (TCNs) are proposed for multimodal supervised learning and extended for semi-supervised learning. Three variants are presented: TCN-embed, TCN-svm, and TCN-AE. The model aims to achieve high accuracies in predicting labels for unlabeled data points with multiple modalities. Each data point contains feature values from multiple modalities, and the structures of CNs involve interpreter networks compressing modalities into low-dimensional vectors. Transductive Consensus Networks (TCNs) aim to compress data samples from multiple modalities into low-dimensional vectors using interpreter networks. A consensus is reached by combining representations from different views of the same data sample. A discriminator network identifies the originating modality of each representation vector. To prevent superficial analysis, Consensus Networks include a 'noise modality' representation sampled from a normal distribution. The discrimination loss is defined as the cross entropy loss across all modalities. Consensus Networks (CNs) aim to compress data samples from multiple modalities into low-dimensional vectors using interpreter networks. The overall optimization goals for CN can be described as a supervised learning framework limited by the amount of labeled data, motivating a generalization to semi-supervised scenarios. CN training involves a classifier mechanism requiring labeled data and a consensus mechanism handling both labeled and unlabeled data. The consensus mechanism in Transductive Consensus Networks handles both labeled and unlabeled data. The optimization goals are broken down into three iterative steps: encouraging interpreters to produce indistinguishable representations, encouraging discriminators to recognize modal-specific information, and training the networks to make correct decisions. This approach builds a low-dimensional latent representation containing common knowledge across different modalities. Three modifications are made to the base TCN model to create different models: TCN-embed, TCN-svm, and TCN-AE. TCN-embed includes the same networks as TCN but is trained differently with a pretraining phase. TCN-svm removes the classifier network and uses supervised learning with an SVM. TCN-AE includes reconstructor networks for each modality to recover information. TCN-AE introduces reconstructor networks for each modality to recover input information, weakening the consensus mechanism in the model. This inhibition of consensus leads to inferior model performance, as shown in subsequent analysis. The effects of consensus and classification mechanisms are quantitatively measured by evaluating the similarities of representations in the hidden dimensions. The hidden dimensions of representations are evaluated by measuring relative JS divergences between pairs of representations derived from the same data sample. The similarity is calculated by averaging the negative of these divergences, with a maximum value of 0 indicating no JS divergence between any pair. The \"similarity\" value ranges from 0 to no theoretical lower bound. FIG3 displays 2D visualizations of representation vectors. Figure 5 shows how modality representations evolve during training. TCN and its variants are compared on Bank Marketing and DementiaBank datasets. Bank Marketing dataset predicts customer subscription to a term deposit via telephone. The dataset has 4,640 positive and 36,548 negative samples. To address imbalance, 5,000 negative samples are randomly sampled for balance. We balance imbalanced datasets by sampling 5,000 negative samples. Categorical features are converted into one-hot representations and divided into three modalities. DementiaBank dataset contains 240 positive and 233 negative samples with 413 linguistic features extracted. ReLU layers are used in interpreter networks for non-negative probability mass. The datasets used in the study have three modalities: basic information, statistical data, and employment-related features for the Bank Marketing dataset, and acoustic, syntactic, and lexical&semantic features for DementiaBank. The evaluation includes TCN and its variants against various benchmarks in multimodal semi-supervised learning and supervised learning. Fully connected networks with batch normalization layers are used for training with a batch size of 10. The neural network models are implemented using PyTorch and supervised learning benchmark algorithms (SVM, MLP) use scikit-learn. Adam optimizer with an initial learning rate of 0.001 is used for training. Optimization stops when the classification loss does not change significantly or after a certain number of steps. Iterative optimization may get trapped in local saddle points. The classification loss is monitored during training, and if it exceeds a certain threshold, the model is re-initialized with a new seed. Results show that TCN outperforms benchmarks on various datasets, with semi-supervised learning not always surpassing supervised algorithms. Different models like TSVM, CN, and TCN are compared in terms of performance. TCN outperforms benchmarks on various datasets, with semi-supervised learning not always surpassing supervised algorithms. Both consensus and classification mechanisms are beneficial to classifier performance, with iterative optimization crucial for deriving good representations. Visualization with T-SNE and similarity values show higher values correspond to distributions with higher symmetry. TCN models reach a consensus state with stable similarities, while TCN-svm quickly reaches agreements. TCN-AE fails to reach agreement due to the autoencoder blocking the consensus mechanism. The representations of three modalities form 'drumstick' shapes at step 30, showing the highest visual symmetry and similarity. Examples of similarity plots for DementiaBank and Bank Marketing datasets are shown in Figure 5. In this paper, Transductive Consensus Networks (TCNs) are introduced, extending consensus networks with semi-supervised learning. Two mechanisms of TCNs are identified: consensus and classifier mechanisms. Through an ablation study with three TCN variants, the importance of both mechanisms is demonstrated. The representations are treated as probability distributions, and their similarity is defined as negative relative JS divergences. While the consensus mechanism aims for high similarities, a perfect similarity between modality representations is not necessary for a good consensus state. Future research may explore building consensus networks using different types of neural networks. Building consensus networks using different types of neural networks may be considered. Exploring a more explainable metric to describe agreement is needed, as the current metric requires approximations. Optimizing against the similarity metric instead of using a discriminator could be worth investigating further."
}