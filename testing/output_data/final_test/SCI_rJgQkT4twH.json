{
    "title": "rJgQkT4twH",
    "content": "Semmelhack et al. (2014) achieved high accuracy in distinguishing zebrafish swim bouts using a Support Vector Machine (SVM). A new technique called Deep Taylor Decomposition improved transparency in Convolutional Neural Networks (CNNs) by generating heatmaps to highlight relevant input regions for predictions. The CNN focused on the tail's trunk steadiness, different from Semmelhack's manual features. Attention to experimental artifacts affected predictions, but after correction, the CNN outperformed the SVM by 6.12%. Our best CNN outperforms the SVM by 6.12%, achieving a classification accuracy of 96.32%. CNNs have proven to reach high accuracies in classification tasks on images and videos, reducing the need for manual feature engineering. The development of CNNs has enabled them to identify increasingly abstract features. The development of CNNs has enabled them to identify increasingly abstract features, thanks to larger training sets, computing resources, GPU training implementations, and better regularization techniques. However, CNNs have drawbacks such as a lack of trust in their classifications and missing interpretability of learned features. To address these issues, research has developed approaches to shed light on the inner workings of CNNs. This paper focuses on the use of CNNs in uncovering unintended correlations, known as \"Clever Hans\" predictions, which could have harmful consequences. It highlights zebrafish research as an applied domain for AI explainability, emphasizing the organism's genetic similarities to humans and its translucency for non-invasive observation. In this study, CNNs are adapted for analyzing zebrafish video recordings, showcasing the effectiveness of an AI explainability technique. The network is trained on optical flow to classify swim bouts, outperforming current bout classification methods. Heatmaps generated with the \"iNNvestigate\" toolbox reveal the areas of focus for the CNN during predictions, showing the network learns distinct features from manually created ones. Carreira & Zisserman (2017) identified different types of video architectures for AI explainability, including CNN + LSTM, 3D-CNN, Two-Stream, 3D-Fused Two-Stream, and Two-Stream 3D-CNN. These architectures vary in their use of 2D or 3D convolutions, optical flow, and information exchange between consecutive frames. Optical flow calculates pixel displacement between frames and various algorithms exist for flow calculation. Several algorithms for flow calculation exist, including TV-L1, Brox, and Farneback. Deep learning approaches like FlowNet have also been developed. Carreira & Zisserman (2017) demonstrated the benefits of transfer learning in video classifiers, showing that adding a temporal stream based on optical flow improves performance. AI explainability techniques for images can be categorized into attribution and feature visualization. The technique applied in this paper is called Deep Taylor, which focuses on attribution and feature visualization in AI explainability for images. It involves sensitivity analysis, producing relevance heatmaps, and measuring the influence of different image regions on CNN activations. The Deep Taylor Decomposition technique, derived from Layer-Wise Relevance Propagation, highlights relevant areas in images for correct classification by distributing relevance from output to input layers using specific rules. It provides a better approximation of relevance than Sensitivity Analysis and is included in the \"iNNvestigate\" toolbox by Alber et al. (2018). CNNs can be explained using direct feature visualization approaches like deconvolution networks and optimization approaches in the input domain. Specific samples can be selected to highly activate or suppress a particular unit, and irrelevant parts of the input image can be hidden. Zebrafish are a suitable model organism for various studies, including wound repair. Zebrafish are used as a model organism in various fields of study, including wound repair, visual processing in the brain, cancer research, and genetic modifications. In neuroscientific research, understanding behavior and behavioral changes in response to cerebral interventions is crucial. Researchers have identified a dedicated circuitry in the zebrafish brain that controls prey movements, involving a pathway from retinal ganglion cells to specific brain areas that produce characteristic motor output. Researchers have identified a dedicated circuitry in the zebrafish brain that controls prey movements. They trained a Two-Stream CNN using a dataset gathered for SVM training to distinguish prey and swim bouts in larval zebrafish. Data preparation involved extracting snippets from raw videos and performing augmentation. Heatmaps were computed to show regions of high relevance within frames. The study by Semmelhack et al. (2014) used high-speed cameras to capture fish behavior, distinguishing between spontaneous and prey bouts. Fish heads were embedded in agarose for stability, and videos were processed to focus on the bladder area. Gamma correction and binary thresholding were applied to isolate the bladder for analysis. After embedding fish heads in agarose for stability, videos were processed to focus on the bladder area. Each raw video contained bout events extracted as sequences of 150 frames, resulting in 1,214 video snippets. The pre-processing procedure was extended by setting squares of 85x85 pixels in the upper and lower left-hand corners of frames plain white to prevent classification shortcuts. Data augmentation involved working with batches of 32 videos with the original data randomly shuffled for gradient approximation during training. After embedding fish heads in agarose for stability, videos were processed to focus on the bladder area. Data augmentation involved subsampling, flipping, and cropping to create 174,816 augmented samples. Optical flow was computed after subsampling to generate differing augmented samples for gradient approximation during training. Subsampling randomly selected 86 frames out of 150, ensuring meaningful flow calculation. After subsampling 86 frames, optical flow was computed resulting in 85 flow frames stacked to 170 channels. The Farneb\u00e4ck algorithm was used to detect flow even with fast tail movement. 18 augmented batches were generated by randomly flipping vertically. A twostream network with adapted CNN-M-2048 network was used for spatial and temporal streams, capable of handling small sample sizes and learning quickly. The spatial stream had one gray-scale channel, while the temporal stream had 170 flow channels in the first layer. Predicted probabilities were obtained for each stream. The study utilized a two-stream network with spatial and temporal streams, where predicted probabilities were obtained and fused by averaging. The negative log-likelihood loss was computed for the joint log-probability of both streams. The dataset consisted of 38 files divided into training, validation, and test sets. Weights were initialized with pre-training on ImageNet for feature learning. In the study, a two-stream network was used with spatial and temporal streams, initialized with pre-training on ImageNet for feature learning. The weights for the input layer of the spatial stream were obtained by averaging the pretrained weights of 3 RGB-channels to get the weights for 1 grayscale-channel. For the temporal stream, the RGB-channels were copied 3 times to get 170 channels, with added random noise for diverse evolution during training. The output weights were averaged from 500 units to obtain weights for two output neurons, as the study dealt with 2 classes instead of 1,000 in ImageNet. The study utilized a two-stream network with spatial and temporal streams, initialized with pre-training on ImageNet for feature learning. The weights for the input layer were adjusted for the two output neurons, as the study focused on 2 classes instead of 1,000 in ImageNet. The training procedure involved using the Adam optimizer with tuned learning rate and weight decay, along with a gamma learning rate scheduler. Fine-tuning was crucial due to the different domain weights, with a hyperparameter search conducted before training on the full dataset. Relevance analysis with heatmaps was used to enhance transparency of the CNN. The study utilized a two-stream network with spatial and temporal streams, initialized with pre-training on ImageNet for feature learning. Relevance analysis with heatmaps was used to enhance transparency of the CNN. The AI explainability technique used feature visualization approaches and generated saliency maps and heatmaps. The analysis was simplified by splitting the network into individual streams, making the generation of heatmaps surprisingly simple. The study involved training a CNN on a small dataset to distinguish prey bouts of larval zebrafish from spontaneous swims. Heatmaps were generated by analyzing learned weights, with a hyperparameter search conducted for optimization. The process was simplified by setting a subsampling factor and utilizing pre-trained weights from ImageNet. The baseline SVM model was also evaluated for accuracy using cross-validation and a held-out test set. The study achieved a test accuracy of 96.32% with the final CNN, outperforming the baseline by 6.12%. Relevance heatmaps were used to visualize regions of focus during classification. Relevance averages were computed across samples and frames, providing insights into the features learned by the CNN. Other explainability techniques yielded similar results. The heatmaps from the CNN show that it can differentiate zebrafish movements based on their trunk steadiness, with a focus on the rostral part of the tail. The network pays attention to edges and the start of the trunk for positive classifications, indicating a calm trunk signifies a prey bout. The CNN can differentiate zebrafish movements based on trunk steadiness, with a focus on the rostral part of the tail. It can identify prey bouts based on a calm trunk. The network is able to differentiate zebrafish movements accurately, but also makes \"Clever Hans\" predictions based on unintended artifacts in the data. The CNN bases negative responses on motion in the top left corner, rather than tail appearance and motion. The CNN can differentiate zebrafish movements based on trunk steadiness and prey bouts. It focuses on the rostral part of the tail and can make accurate predictions. Negative responses are based on motion in the top left corner, not tail appearance. Heatmaps are vertically symmetric, except for a peculiar region in the top left corner. After removing artifacts, relevance is now entirely on the tail. Most relevance is concentrated on frames 7-46, with the first seven frames being of least importance. This suggests the network focuses on the most relevant frames. Our CNN can differentiate zebrafish movements based on tail features, achieving a test accuracy of 96.32%. The network's learned weights focus on discriminating tail features, different from previous SVM classification methods. Removing spurious correlations improved accuracy by 6.12% compared to Semmelhack et al. (2014). The CNN achieved better accuracy than the SVM used by Semmelhack et al. (2014) by focusing on discriminating features in the fish's trunk. The network's relevance heatmaps show a clear distinction between prey bouts and spontaneous movements based on the steadiness of the trunk. This interpretation aligns with existing research on prey bout kinematics. The CNN focuses on discriminating features in the fish's trunk for prey bouts, aligning with existing research on prey bout kinematics. The network has learned different features compared to previous studies, emphasizing the importance of tail control for precise swim movements. The CNN has learned different features related to tail control for swim movements, showing higher performance with a subset of frames. The agarose substance in the fish's head may have unintentionally influenced its motion during swim bouts. Future work involves exploring the potential of the spatial stream in achieving similar performance as the temporal stream in a more cost-effective manner. The spatial stream focuses on similar features as the temporal stream, hinting at the possibility of surpassing its performance with a sequence of frames. Additionally, CNNs could be utilized to study brain recovery in larval zebrafish at a cellular level. Future work could involve investigating brain recovery in larval zebrafish on a behavioral level by performing a lesion study on the optic tectum. CNNs could assess swim bouts of recovered fish to detect potential behavioral changes. Tail-fitting code was applied to compute points along the tail in videos, with insights from relevance heatmaps needed for distinguishing recovered fish from healthy ones. After pre-processing, tail-fitting code had issues with some video frames, resulting in 953 processed videos with 50.6% spontaneous and 49.4% prey bouts. No augmentation was done as it wouldn't benefit the SVM model. The dataset was split into 85% training and 15% test sets for feature extraction and model fitting. Using key features identified by Semmelhack et al. (2014), a grid-search was performed to tune SVM parameters for cross-validation accuracy. The study utilized 5-fold cross-validation for model training and evaluation. Various software packages were employed for data processing and analysis, including NumPy, Matplotlib, OpenCV, scikit-learn, PyTorch, TensorFlow, Keras, and iNNvestigate. Pre-processing aimed to center the fish's bladder on the left side. Pre-processing involved centering the fish's bladder on the left side of each frame by applying a binary threshold at value 3. Contours were used to identify the bladder, and consecutive 150-frame bouts of motion were extracted by analyzing pixel value changes in the tail. The algorithm detected motion in consecutive frames by analyzing pixel value changes in the tail. It set the start of an event after detecting motion for a certain number of frames, with a buffer of 15 frames before and 150 frames after. Overlapping videos were avoided to prevent train/test-contamination. Detected motions within 150 frames of a previous video were discarded. Data augmentation was parallelized with 38 workers to speed up optical flow calculation. A Dell PowerEdge R815 with four 16 core Opteron CPUs, 256 GB memory, and 4 TB HDD was used. HDF5-files were compressed with gzip-compression, outperforming lzf-compression by 1.76x in training times. PyTorch's Dataset module was implemented for multiprocessing in the training procedure. After implementing PyTorch's Dataset module for multiprocessing in the training procedure, the CNN weights were analyzed using the \"iNNvestigate\" toolbox. Despite challenges with compatibility, the weights were successfully transferred to enable relevance analysis with heatmaps. However, the toolbox encountered issues analyzing 1,578 out of 3,420 samples, resulting in empty outputs. After successfully transferring CNN weights for relevance analysis with heatmaps, 1,842 samples were further investigated. Saliency maps and Guided BackProp heatmaps were generated for comparison with the DTD technique, revealing similar insights with slightly fuzzier results. The analysis also uncovered the \"Clever Hans\" prediction, showcasing informative flow frames for true positives, true negatives, false positives, and false negatives. Spatial heatmaps of these samples were summarized in Figure S15. The analysis of heatmaps in Figure S13 revealed the \"Clever Hans\" feature of agarose motion in the top left corner. Negative classifications were sorted by confidence, showing that the CNN relied more on tail features for confident negative classifications. Tail features were found to be a better predictor than agarose motion."
}