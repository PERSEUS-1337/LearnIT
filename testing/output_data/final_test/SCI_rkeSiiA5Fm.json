{
    "title": "rkeSiiA5Fm",
    "content": "The paper presents a method for applying deep learning to 3D surfaces using spherical descriptors and alt-az anisotropic convolution on 2-sphere. Geodesic disk filters rotate on the 2-sphere to extract geometric features for various 3D shape analysis tasks, bridging the gap between 2D images and 3D shapes. The effectiveness of the proposed method is evaluated in non-rigid/rigid shape classification and shape retrieval applications. Recent research in computer vision and geometric processing communities focuses on applying deep convolutional neural networks to 3D shape analysis. Various methods convert 3D shapes into Euclidean grid structures to enable the use of conventional CNNs. These methods include treating a 3D shape as a voxel grid, using 2D renderings from multiple cameras, or projecting a 3D object onto geometric entities for analysis. The research focuses on using convolutional networks for non-Euclidean domains like manifolds or graphs, addressing the lack of shift-invariance on surfaces or graphs. By representing 3D shapes as functions on spheres, the problem of manifold surface convolution is transferred into spherical convolution for rotation invariance. Spherical descriptors of 3D shapes are compact and require a network of lower capacity. The study aims to analyze 3D geometric data using spherical convolution for classification or retrieval tasks. The research focuses on using spherical convolution for analyzing 3D geometric data, addressing shift-invariance on surfaces. Various parameterization methods like geodesic CNN and spherical parameterization are utilized for rotation invariance. Data augmentation is necessary for geometry images to account for inconsistent cut positions and orientations. Toric covers provide a seamless representation for genus-0 surfaces. Spherical convolution is used for analyzing 3D geometric data, addressing shift-invariance on surfaces. Researchers are exploring deep spherical convolutional neural networks for tasks such as molecular modeling, omnidirectional vision, and 3D shape recognition. BID32 discretized a spherical image using a lat-lon grid and flattened it through equirectangular projection. In this paper, an alt-az anisotropic spherical convolutional neural network (3 SCNN) is proposed for rigid and non-rigid shape analysis tasks. The method involves representing a 3D shape as a set of spherical images using spherical parameterization or projection. An alt-az anisotropic spherical convolutional neural network (3 SCNN) is proposed for shape analysis tasks. It uses an icosahedron based spherical grid for discrete representation and applies convolutions directly on the spherical shape. The network includes multiple sequential convolutions with ReLU and Spherical Pooling, producing high-level shape feature descriptors. Key contributions include theoretical analysis of convolutions on the 2-sphere and an efficient geodesic grid data structure for fast computation. The alt-az anisotropic spherical convolutional neural network (3 SCNN) utilizes a geodesic grid data structure for fast computation on the 2-sphere. The 2-sphere is a set of points in R3 with norm one, parametrized by spherical coordinates. Special regions like the polar cap region are defined on the 2-sphere. The rotations in three dimensions are represented by the special orthogonal group SO(3) as 3x3 matrices. The alt-az rotation in SO(3) is represented by a 3x3 matrix. It involves three independent parameters and can be reduced to a subset A with two parameters by fixing the third angle to zero. An alt-az rotation is a composition of altitude and azimuth rotations in SO(2). The effect of a general rotation on spherical functions is defined by the operator D R (\u03d5, \u03d1, \u03c9). The convolution operator on the 2-sphere in n-dimensional Euclidean space R n is given by a specific equation. The convolution on the 2-sphere involves two competing definitions: Type I - General anisotropic convolution, which uses full rotations in SO(3) for convolution, and Type II - Azimuthally isotropic convolution. The output function is defined on a 3-manifold SO(3) with three Euler angles. Type II spherical convolution on the 3-manifold SO(3) uses an azimuthally symmetric filter to output a function on S 2. It zeros angular variations from a filter, making it restrictive for pattern matching in spherical image processing. Alt-az spherical convolution is proposed to respect properties of standard convolutions in R 2. Alt-az anisotropic spherical convolution (a 3 SConv) is a type of spherical convolution that constrains the rotation of the filter within alt-az rotation set A. The filter spans altitude change by \u03d1 and azimuth change by \u03d5, and is convolved with the spherical signal f. A 3 SConv operator has desirable properties like domain consistency and azimuth rotation equivariance. It is not equivariant to arbitrary rotations in SO(3) but has equivariance property for azimuth rotations. Locally-supported geodesic disc filters are proposed for efficiency on the 2-sphere. Locally-supported geodesic disc filters are defined on the 2-sphere, with a 3 SCNN consisting of multiple layers including a local max pooling (LMP) layer and a global spherical max pooling (GMP) layer. The GMP layer in a 3 SCNN extracts salient features from an input spherical image, making the feature vector invariant to azimuth rotation. Data rotation augmentation is necessary for recognizing images in random orientations. Implementing spherical convolution with GMP layer can generalize to unseen orientations with rotation augmentation. Popular methods include projecting functions and filters onto Wigner D functions or spherical harmonics for convolution in the Fourier domain. Lack of locality support in spherical Fourier transform limits this method. The paper proposes an alternate method for spherical convolution using geodesic grid discretization, allowing for direct convolution on the sphere. This approach overcomes the memory inefficiency of filters defined on the whole spherical domain by subdividing five platonic polyhedra to approximate the sphere. Among these polyhedra, the icosahedron is most similar to the sphere. The icosahedron-based geodesic grid discretization is suitable for discrete spherical convolution due to its balanced triangulation. The grid vertices are determined by the subdivision frequency, with the stride of convolution or pooling layers needing to be a multiple of 2^n. The icosahedron is subdivided at frequencies 1, 2, 4, and 8 to show different levels of detail. The icosahedron-sphere grid is used for spherical convolution and pooling. A geodesic disc shape correlates with the grid and is discretized into a hexagonal grid for filters. A rectilinear data structure is used for efficient convolution and pooling operations. The icosahedron-based spherical mesh can be represented as a grid structure for these operations. The icosahedron-sphere grid is represented as a grid structure for spherical convolution and pooling operations. By rotating axes, five rectangular 2D patches store all vertices efficiently. Padding neighboring patches is crucial for convolution and pooling operations on the grid. Points on colored cut-lines have k-ring hexagon neighbors retrieved across matrix boundaries. The icosahedron-sphere grid allows for spherical convolution and pooling operations. To convert 3D shapes to functions on the 2-sphere, spherical projection and spherical parameterization methods are used. Spherical projection is suitable for rigid shapes, while spherical parameterization is used for non-rigid shapes. To handle deformable shapes, the authalic spherical parametrization method is used to obtain an area-preserving bijective spherical map. Intrinsic shape descriptors include Principal Curvatures, Average Geodesic Distance, and Heat kernel signature. Spherical functions are discretized using an icosahedron-sphere grid with a subdivision frequency of 32, generating five patches stacked one above the other. The input size to all networks is 165 \u00d7 65 \u00d7 K. The input size to all networks is 165 \u00d7 65 \u00d7 K, where K is the number of input channels. For the 12 valence-5 vertices in the icosahedron, a shared hexagon filter is applied by computing the center point twice. Empirical validation shows that the effect on a small number of vertices can be ignored. Experiments are conducted on SHREC'11 non-rigid shape classification using different types of spherical functions and modes of training with data augmentation. The network architecture includes five SConv-dropout-ReLU-LMP blocks with dropout for regularization. Global max pooling is used for feature pooling, followed by fully connected layers for classification. Different training methods with rotation augmentation are tested on 16 objects for training and 4 for testing. The network architecture includes SConv-dropout-ReLU-LMP blocks with global max pooling for feature pooling. Different training methods with rotation augmentation are tested on 16 objects for training and 4 for testing. The LMP layers allow rotation invariance, leading to good classification accuracy for Intrinsic-8 even without data augmentation. SO(2) augmentation outperforms other augmentation strategies. The geometry image method BID28 is similar to our approach, with a reported classification accuracy of 96.6% based on alt-az rotation augmentation. Our method outperforms the state-of-the-art by about 3% even with two principal curvature inputs. Experimenting on ModelNet10 and ModelNet40 databases, we test the equivariance/invariance property of our shape representations through different perturbations. In experiments testing rotation equivariance/invariance, a 3 SCNN with spherical functions SEF and NDF as input showed promising results. The network structure used was similar to SHREC'11, with 3 Sconv layers and 1024 features in the first fully connected layer for classification. Results in TAB1 compared classification accuracy for aligned training/testing data, with aligned data yielding the best performance. The learned representation in rotation equivariance/invariance testing showed best accuracy with alt-az rotation perturbation. Despite azimuthal rotation invariance, slight performance drop was observed, attributed to grid tessellation errors. Alt-az and SO(3) perturbations compensated for this, indicating network generalization to unseen orientations without data augmentation. Our model demonstrates strong empirical support for learning alt-az rotation invariant shape descriptors using alt-az spherical convolution operators. Evaluation on the SHREC'11 non-rigid dataset shows significant improvement in shape retrieval performance compared to state-of-the-art methods. Our approach outperforms all other methods in shape retrieval performance with 0.82 mAP. Using t-SNE, our learned descriptors successfully disentangle the original 3D object space and exhibit clustered behavior in the feature vector space. Shape retrieval experiments on ShapeNet Core55 show the quality of our learned shape descriptors for large scale rigid 3D object retrieval tasks. In the large scale rigid 3D object retrieval task, an SO(2) rotation augmentation is applied to the training data. The ModelNet40 architecture is used for SHREC'17 feature extraction, achieving 83% classification accuracy. The 1024 features from the first fully connected layer are used as shape descriptors for similarity calculation. Evaluation against competitors shows performance slightly below the best method. In this paper, a new convolutional neural network based on alt-az anisotropic spherical convolution operator is presented. The method offers multi-level feature extraction capabilities and fast computation on GPUs. The algorithm efficiently computes spherical convolution with locally-supported geodesic filters using an icosahedron-sphere grid. The proposed method utilizes alt-az anisotropic spherical convolution for shape classification and retrieval, demonstrating superior performance without excessive data augmentation or feature engineering. Rotation equivariance is achieved with general orientations, enhancing 3D shape recognition tasks. The network consists of one a 3 SConv and one GMP layer. A GMP layer's feature output activated at point\u00fb 0 (\u03b8 0 , \u03c6 0 ) corresponds to maximum correlation between filter h and input image f. Alt-az shift rotation causes no relative angular change of the geodesic disc centered at\u00fb o with respect to h's convolving. By augmenting f using SO(2) rotation about an arbitrary axis, any feature of f can always alt-az shift rotate to the same feature in one of f's augmented copies, even after SO(3) random rotation."
}