{
    "title": "B1gNfkrYvS",
    "content": "Pure CapsNets (P-CapsNets) are proposed as an improvement over CapsNets, with three key modifications: removing routing procedures, replacing convolutional layers, and packaging capsules into rank-3 tensors for efficiency. P-CapsNets outperform CapsNets with fewer parameters on MNIST&CIFAR10, achieving over 99% accuracy on MNIST with only 3888 parameters. Visualization of capsules and correlation matrices demonstrates potential future initialization methods. Adversarial robustness of P-CapsNets is explored compared to CNNs. Capsule Networks (CapsNets) have been found to efficiently encode spatial relationships among features compared to CNNs. Various routing procedures have been proposed to improve efficiency, but some may produce worse results than baseline algorithms. Adversarial robustness of Pure CapsNets (P-CapsNets) is explored in comparison to CNNs. In contrast to traditional CapsNets, P-CapsNets eliminate routing procedures and learn coupling coefficients implicitly during capsule transformation, addressing issues of scalability and efficiency. CapsNets often face challenges in setting optimal routing numbers for each layer, impacting performance and requiring extensive testing. P-CapsNets improve efficiency by replacing convolutional layers with capsule layers and using rank-3 tensors for input representation. Capsule convolution in P-CapsNets utilizes a 5D kernel to map a 5D tensor into another 5D tensor, offering a more general approach compared to traditional 3D convolution. Capsule convolution in P-CapsNets uses a 5D kernel to transform a 5D tensor into another 5D tensor, enhancing efficiency by replacing convolutional layers with capsule layers. CapsNets organize neurons as capsules to mimic biological neural systems, with a key design being the routing procedure to combine lower-level features into higher-level features for modeling hierarchical relationships. Improving routing procedures in CapsNets is crucial for modeling hierarchical relationships. Various approaches have been proposed, such as using weighted kernel density estimation to enhance routing efficiency. However, some routing procedures are heuristic and may perform worse than random assignment. Integrating routing procedures into the optimization process, treating them as regularizers, or approximating them with master and aide interaction can help ease the computational burden and improve performance. The proposed P-CapsNet model argues that routing procedures in CapsNets may be unnecessary and can be implicitly learned and optimized. The model focuses on packaging capsules into higher-rank tensors and eliminating the need for convolutional layers. The primary idea of routing procedures in CapsNets is to use part-whole relationships to vote for objects. The CapsNets model suggests that routing procedures may not be needed and can be learned implicitly. It focuses on grouping capsules into tensors and removing convolutional layers. The main concept of routing procedures is using part-whole relationships to vote for objects, with linear combinations on tensors. The model questions the necessity of separately learning coupling coefficients and weights, proposing to learn them together instead. The CapsNets model suggests that routing procedures may not be necessary and can be learned implicitly by optimizing the tensor to tensor mapping between capsule layers. By extending the basic operation to the 3D case and removing routing procedures, the model aims to preserve the good properties of CapsNets while reducing the computational cost. The strong modeling ability of CapsNets is believed to come from this tensor mapping, and routing procedures do not contribute significantly to optimization. The routing parameters in CapsNets only make up a small percentage of the total parameters, suggesting their limited benefit despite being a computational bottleneck. The dimension transformation step in CapsNets can be seen as a more general version of convolution, with capsules representing vectors and matrices. The dimension transformation step in CapsNets involves converting 8-dimensional tensors into 16-dimensional tensors using 4x4 matrices, reducing the total number of parameters by a factor of 15. The input/output vectors are packaged into matrices, resulting in a significant parameter reduction. This approach is similar to the one used by Hinton et al. (2018). In P-CapsNets, folding capsules into high-rank tensors reduces computational costs by minimizing parameter requirements for dimension transformation between layers. This approach enhances representativeness with fewer parameters compared to unfolded capsules. In P-CapsNets, folded capsules are more representative than unfolded ones. CapsNets combine convolutional and capsule layers to extract features. However, using only capsule layers in a \"pure\" CapsNet is argued to be more versatile. In P-CapsNets, folded capsules are more representative than unfolded ones. A \"pure\" CapsNet is built using only capsule layers, making three modifications over CapsNets. Routing procedures are removed, convolutional layers are replaced with capsule layers, and capsules and input/output are packaged as rank-3 tensors to save parameters. Loss and activation functions remain the same as in previous work. Squash function and margin loss function are used for classification. P-CapsNets model uses margin loss function for classification tasks, outperforming CapsNets with fewer parameters on MNIST and CIFAR10 datasets. It shows higher efficiency compared to other neural network models and achieves better performance than Matrix CapsNets with significantly fewer parameters. The P-CapsNets model outperforms other models with fewer parameters on MNIST and CIFAR10 datasets. It achieves high accuracy with minimal parameters compared to deep compressing models. The model also adopts data augmentation techniques for improved performance. P-CapsNets outperform routing-based CapsNets with fewer parameters on CIFAR10, except for Capsule-VAE. The structure of P-CapsNets#4 can be found in Appendix A. The P-CapsNets model uses a customized acceleration solution based on cuda and CAFFE to reduce communication times between CPUs and GPUs. Capsules in each layer are visualized as 7D tensors flattened into matrices for easier visualization. The reshaping process is applied to all layers for visualization purposes. The P-CapsNets model reshapes capsules into matrices for visualization. Correlation matrices are computed for convolutional layers and P-CapsNets, showing higher correlations in P-CapsNets. The study compares the correlations within kernels of P-CapsNets and standard CNNs, finding that P-CapsNets have lower correlations due to their feature extraction design. The results suggest a need to reconsider the initialization methods for CapsNets. The robustness of P-CapsNets is evaluated using FGSM attacking method, showing a generalization gap compared to CNN baseline. Visualizations of correlation matrices highlight the differences in feature extraction between the two models. At the end of training, P-CapsNets show smaller training/testing loss gaps compared to CNNs, indicating better generalization ability. However, P-CapsNets are more vulnerable to black-box adversarial attacks, with accuracy dropping significantly when epsilon increases. This vulnerability is highlighted through the FGSM attacking method, showing a stark difference in resistance compared to CNN models. P-CapsNets are more vulnerable to white-box and black-box adversarial attacks compared to CNNs, with accuracy decreasing sharply when attacked. This vulnerability may be due to the smaller size of the P-CapsNets model. P-CapsNets outperform CNN baseline with fewer parameters. Modifications include replacing convolutional layers with capsule layers, removing routing procedures, and packaging capsules into rank-3 tensors. P-CapsNets achieve better performance than other CapsNets variants and deep compressing models. Capsules in P-CapsNets can be seen as a general version of 3D convolutional layers, encoding spatial relationships efficiently. The P-CapsNets model outperforms CNN baseline with fewer parameters by replacing convolutional layers with capsule layers. The input for CapsNets#2 is gray-scale images reshaped into a 6D tensor to fit P-CapsNets. The first capsule layer is a 7D tensor representing kernel height, width, input/output capsule feature maps, and capsule dimensions. The following feature maps and filters are interpreted similarly. The P-CapsNets model replaces convolutional layers with capsule layers, outperforming CNN baseline with fewer parameters. The capsule layers have specific dimensions and strides for each P-CapsNets model. The input for the generative network is a 100-dimension vector filled with random numbers, which is then fed into a fully-connected layer with 3456 outputs. The fully-connected layer with 3456 outputs is followed by three deconvolutional layers with specific output sizes and kernel/stride configurations. A Leaky ReLU function and squash function are added after each capsule layer, with parameters initialized by MSRA. For MNIST, the learning rate decreases every 4000 steps by a factor of 0.5 during training, with a batch size of 128. For MNIST, the fully-connected layer with 3456 outputs is followed by three deconvolutional layers. Leaky ReLU and squash functions are added after each capsule layer. The learning rate decreases every 4000 steps by a factor of 0.5, with a batch size of 128. For CIFAR10, the batch size is 256, and the learning rate decreases every 10 thousand iterations by a factor of 0.5. Global Contrast Normalization and Zero Component Analysis are applied before training. The text chunk discusses the process of calculating mean images, covariance matrix, singular values, and vectors for a dataset. It also mentions the use of Equation 10 for image processing and the challenges of communication overhead in training processes. A parallel solution is proposed to minimize communication times, resulting in faster speeds compared to CPU-only mode. The solution is tested on two P-CaspNets models, showing at least a 4x speed improvement over CPU mode. The solution proposed in the text achieves at least 4x faster speed than the CPU mode for different batch sizes."
}