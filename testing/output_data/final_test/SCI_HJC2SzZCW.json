{
    "title": "HJC2SzZCW",
    "content": "Large over-parameterized neural networks generalize better than smaller ones, contradicting classical notions of function complexity. This study explores this tension through empirical analysis of complexity metrics and thousands of models across different architectures and datasets. Trained neural networks show robustness to input perturbations near training data manifold, correlated with generalization. Factors like full-batch training or random labels lead to higher sensitivity, while data augmentation and ReLU non-linearities result in more robust functions. Input-output Jacobian norm can predict generalization at individual test points. Deep learning success defies interpretation through existing computational complexity, numerical optimization, and statistical learning theory lenses. Neural networks are non-convex models with high capacity that train quickly and generalize effectively. Larger networks often generalize better, contrary to classical measures like VC dimension. This observation challenges Occam's razor and suggests that function complexity should be considered in relation to the input domain. In this work, the complexity of neural networks is analyzed through their capacity to distinguish inputs near datapoints, with a focus on sensitivity. The norm of the input-output Jacobian is found to correlate with generalization in various scenarios. Training 2160 networks on CIFAR10 shows that increasing model capacity can lead to overfitting, but models with maximum parameters often yield the best generalization. Train loss does not consistently correlate with generalization. This work analyzes neural network complexity through sensitivity to inputs near datapoints. The correlation between the norm of the input-output Jacobian and generalization is explored. Increasing model capacity can lead to overfitting, but models with maximum parameters often generalize best. Train loss does not consistently correlate with generalization. Sensitivity metrics for fully-connected neural networks are defined, and their relation to generalization is discussed. The study explores the behavior of trained neural networks on and off the data manifold through sensitivity analysis. It compares networks with different hyperparameters and examines the predictive sensitivity for individual test points using the Jacobian norm. The study analyzes the behavior of trained neural networks through sensitivity metrics, evaluating their correlation with generalization. It examines the complexity of fully-connected neural networks using sensitivity measures such as estimating linear regions and measuring input-output Jacobian norms. Prior works have also explored similar measures related to expressive power of neural networks. Neural networks use piecewise-linear activation functions to create complex decision boundaries. The number of linear regions in the input space determines the nonlinearity of the function. Previous studies have analyzed the number of linear regions in networks with random weights, but the evolution of this measure after training is not well understood. A related measure, the number of hidden unit transitions in input space, is examined for trained networks. The text discusses the importance of measuring function complexity in neural networks by studying their robustness to input perturbations. It highlights the limitations of using the number of parameters for model selection and suggests measuring output variation instead. The application of Occam's razor to neural networks is explored in the context of sensitivity analysis. The relevance of robustness, as measured by the input-output Jacobian, to generalization is supported by theoretical frameworks. The text discusses the importance of measuring function complexity in neural networks by studying their robustness to input perturbations. It highlights the correlation between metrics and generalization in a larger experimental setting. Various regularization techniques such as data augmentation, noise injection, weight decay, and max-pooling are related to sensitivity through extensive experiments. The text discusses the correlation between regularization techniques and neural network robustness, highlighting findings that challenge common intuition. It also explores the inductive bias towards robustness in stochastic mini-batch optimization compared to full-batch training. The perspective is novel, relating reduced sensitivity to inputs rather than parameters. The text explores the inductive bias of stochastic mini-batch optimization towards robustness in neural networks. It introduces weight-norm based complexity measures and evaluates the Frobenius norm of the Jacobian in large-scale settings. The text discusses sensitivity to inputs in neural networks, focusing on adversarial examples and measures of sensitivity for a fully-connected neural network without biases. It proposes two simple measures of sensitivity for the network with respect to its input. The text discusses sensitivity to inputs in neural networks, focusing on measures of sensitivity for a fully-connected neural network without biases. It proposes two simple measures of sensitivity for the network with respect to its input, using a piecewise-linear activation function like ReLU to split the input space into disjoint regions. Sensitivity is quantified by measuring how the output changes with input perturbations and the likelihood of region changes in response to input changes. The Frobenius norm of the class probabilities Jacobian is used as a local sensitivity measure, estimating the sensitivity of the function in specific regions without requiring labels for the input points. The text discusses sensitivity measures for neural networks without biases, focusing on the Frobenius norm of the class probabilities Jacobian as a local sensitivity measure. It explores how to detect changes in linear regions using piecewise-linear activations like ReLU. The text discusses detecting changes in linear regions of neural networks using piecewise-linear activations like ReLU. It involves encoding schemes to identify linear regions and sampling trajectories to count transitions and estimate sensitivity. By sampling trajectories around different points, sensitivity metrics are estimated as \"transitions\" or \"number of transitions.\" Trajectories are constructed through horizontal translations in pixel space to ensure proximity to the data manifold. The number of transitions can be qualitatively linked to the curvature of a function, with a piecewise-linear function having a constant first derivative except at transition boundaries. The curvature of a function can be expressed as a sum of equidistant samples on a trajectory, quantifying the change between linear regions. Estimating this on a densely sampled trajectory is computationally intensive, so transitions are counted instead. These sensitivity metrics track the first and second order terms of the Taylor expansion of the function, describing the learned function around the data. The study analyzes the performance of fully-connected neural networks with different hyperparameters and optimization procedures, focusing on models achieving 100% training accuracy. The investigation evaluates the behavior of trained neural networks near and away from training data by comparing sensitivity of the function along different trajectories in input space. The analysis is done by quantifying the change between linear regions and tracking the first and second order terms of the Taylor expansion of the function. The study evaluates fully-connected neural networks' performance near and away from training data by comparing sensitivity along different trajectories in input space. Three types of trajectories are analyzed: a random ellipse, an ellipse passing through three training points of different classes, and an ellipse through three training points of the same class. These trajectories help assess the behavior of the function on and off the data manifold. The study evaluates neural networks' performance near and away from training data by comparing sensitivity along different trajectories in input space. Functions exhibit more robust behavior around the training data, with training points lying in regions of low transition density. This empirical connection strengthens the understanding of sensitivity changes in response to approaching the data manifold. The study evaluates neural networks' performance near and away from training data, confirming the empirical connection between sensitivity and generalization. Neural networks implement more robust functions near the training data manifold. In the context of model selection, it is questioned whether a model with better generalization implements a less sensitive function. The study examines neural networks' performance near and away from training data, confirming the link between sensitivity and generalization. Sensitivity decreases near training data but remains consistent along random ellipses. Transition density behaves similarly, showing less stability when moving between different class points. Transition boundaries of the last layer become highly non-isotropic after training. After training, transition boundaries become highly non-isotropic, with training points in regions of lower transition density. Various machine learning approaches influence generalization, such as random labels, data augmentation, ReLUs, and full-batch training. Changes in generalization are linked to changes in sensitivity, as measured by the Jacobian norm. Improvement in generalization is consistently coupled with reduced sensitivity. Transitions correlate with generalization in all scenarios except for comparing. The plot in Figure 4 shows neural networks with different properties but same hyper-parameters and optimization procedure. All networks achieved 100% training accuracy on CIFAR10. The study includes experiments on random labels, data augmentation, and other settings. In a large-scale experiment, neural networks with varying properties but same hyper-parameters and optimization procedure were analyzed. The networks achieved 100% training accuracy on CIFAR10, with sensitivity and generalization values used to compare configurations visually. This study explored relationships between sensitivity and generalization in a realistic setting by sweeping over different architectural parameters. The study analyzed neural networks with varying properties but the same hyper-parameters and optimization procedure. It found a strong relationship between the Jacobian norm and generalization, as well as a correlation between sensitivity and generalization. The Jacobian norm was found to be predictive of generalization at individual points, with a non-linear relationship between Jacobian norm and cross-entropy loss. The study found a correlation between the Jacobian norm and generalization in neural networks. Points with high Jacobian norm values were mostly misclassified, indicating potential for active learning and confidence estimation in future research. The input-output Jacobian norm was shown to be predictive of generalization in various contexts. The input-output Jacobian is predictive of generalization and varies based on proximity to training data. A connection between cross-entropy loss and Jacobian norm was established, suggesting its relevance at individual test points. Future work may explore more complex architectures and machine learning tasks. The encoding of linear regions ensures distinct codes, but the likelihood of overlapping codes decreases exponentially with network width. The probability of arrangement drops exponentially with width and is ignored. The equality between discrete and continuous versions of t(x) becomes exact with high sampling density. Computational efficiency assumes no simultaneous neuron transitions. Trajectory in input space used to count transitions. Interpolation of horizontal translations results in a complex trajectory for estimating transition density. The text discusses a metric for comparing models based on transition density around data manifold. It also touches on Occam's razor and the preference for simpler models. The motivation of the work is explained in the context of model complexity and Bayesian interpretation. The text discusses the preference for simpler models based on the evidence being inversely proportional to the number of parameters. It also mentions Occam's razor for neural networks and the idea that models with fewer parameters have a higher class posterior. The text discusses the complexity of neural networks and how their ability to compute complex functions increases with size. It also mentions that the number of parameters in a model doesn't necessarily entail high complexity, and that weights of a neural network may correspond to its usable capacity. The text discusses how weights of a neural network may affect its usable capacity and the complexity of computing functions. It questions the validity of certain approximations in stochastic optimization for neural networks and highlights the nuanced differences in evidence ratios between networks based on datasets. The text discusses defining hypothesis classes based on sensitivity of the hypothesis and observing a non-uniform prior enabling model comparison. It suggests a prior in favor of robustness over sensitivity for better model performance. The correlation between sensitivity and generalization is explored, with a conjecture that large networks converge to less sensitive functions due to access to a larger space of robust solutions. The text discusses the relationship between large networks and robust solutions, suggesting that they have access to a larger space of solutions. Further investigation is needed to confirm this hypothesis. The analysis focuses on the relationship between Jacobian norm and cross-entropy loss at individual test points. The text discusses the relationship between Jacobian norm and cross-entropy loss at individual test points, establishing approximate bounds for the relationship. Equation 5 establishes the relationship between Jacobian norm and cross-entropy loss at individual test points. The Jacobian norm is bounded from below, assuming the maximum-entropy case. Reported values were evaluated on training and test sets, with trajectories sampled with 2^20 points. The error bar in the study is centered at the mean value and spans the standard error of the mean in each direction. Various factors such as weight initialization, training set shuffling, and data augmentation depend on the random seed used. Random zero-centered and data-fitted ellipses were generated for the study. A random data-fitted ellipse was generated by projecting three arbitrary input points onto a plane forming an equilateral triangle, and then projecting their circumcircle back into the input space. A 15-layer ReLU6-network of width 300 was trained on MNIST for 2 18 steps with various data augmentations. The sampling grid in input space was obtained by projecting three arbitrary input points into a plane, resulting in a triangle centered at 0 with vertices at a distance 0.8 from the origin. The networks were trained with data augmentation on various datasets using different configurations of width, depth, and activation functions. Data augmentation included random translation, flipping, and resulted in higher test accuracy compared to networks trained without augmentation. The study evaluated different depths and activation functions on 8 random seeds. 335671 networks were trained for 219 steps with random hyper-parameters. L-BFGS had a maximum of 2684 iterations."
}