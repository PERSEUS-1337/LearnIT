{
    "title": "SyqAPeWAZ",
    "content": "In recent years, Convolutional Neural Networks (CNN) have been extensively used for Superresolution (SR). This paper introduces a new algorithm that utilizes inverse problem and sparse representation solutions as a mathematical basis for CNN operations. The algorithm involves training two networks with different structures using low and high coherency image patches, resulting in faster performance without sacrificing quality. The increased demand for superresolution algorithms is driven by the need to display high-quality videos online with lower bandwidth, store videos and images efficiently for server optimization, and support 4K video display from Full HD broadcasts. SR algorithms aim to generate high-resolution images from low-resolution ones by modeling blurring effects, downsampling, and system noise. State-of-the-art algorithms for superresolution (SR) problem can be categorized as Dictionary learning based methods (DLB) and Deep learning based methods (DLM). DLB focuses on creating a compact dictionary for reconstructing high-resolution images, but can become heavy and slow as reconstruction performance increases. Recent advances in GPUs have increased the usage of these algorithms. Recent advances in GPUs have fueled the usage of convolutional neural networks (CNNs) for superresolution (SR) problems, surpassing Dictionary learning based methods in terms of speed and performance. State-of-the-art algorithms utilize Perceptual Loss (PL) to generate realistic images from low-resolution inputs, improving stability since their inception. Representation learning is described as capturing variations in input space in a lower dimensional manifold. Neurons in CNNs solve an Iterative Shrinkage Thresholding (IST) equation during training using a dictionary matrix from LR data, yielding representation vectors as filters. Filters act as both representations and dictionaries, showcasing Representation Dictionary Duality (RDD) concept. During training, CNN neurons solve an IST equation using LR data to create representation filters. These filters act as dictionaries for HR reconstruction. The paper proposes a new network structure for better detail recovery without compromising performance. Sections include related literature, analysis of CNNs, a new network for SR, and experimentation results. Proper prior regularization is crucial for high resolution image inversion. The regularization function, reg, promotes prior information from the desired output using different forms such as L 0 norm, Tikhonov regularization, and orthogonal decomposition. The regularized solution is obtained through a gradient descent method with Moreau proximity mapping, known as Proximal Landweber Iterations. BID4 proposed non-quadratic regularization constraints using an orthonormal basis to promote sparsity. A functional \u03c6 b,p is used for the problem, with iterations over basis functions to reach the global minimum solution. Neurons in a CNN architecture can reach the optimum solution based on this approach. Neurons in a CNN architecture can reach the optimum solution for the superresolution problem by solving eq. 7. Our work shows how a convolutional neural network learns image representation and reconstruction for SR inside network parameters, diverging from previous approaches. We combine inverse problem approaches and DL methods in a representation-dictionary duality concept, learning mappings from LR to HR images based on a dictionary. Sparse representation is utilized in dictionary learning based super-resolution (SR) algorithms. LR images are represented by an LR dictionary, and a representation vector is used for HR image reconstruction. The K-SVD algorithm is key in dictionary learning for sparse representation. Aharon et. al. proposed selecting atoms from a compact dictionary to reconstruct images. If the dimension of the image is less than the dictionary and it is full-rank, there are multiple solutions available. The L 0 norm is used to count non-zero entries in f. Compact dictionaries are introduced for sparse representation in super-resolution (SR) algorithms. The optimization of L 0 norm regularized equation is challenging, and a closed form solution may not be available. Lagrange multipliers can be used to solve the equation. During the learning phase, the dictionary D is initialized with random gaussian noise, and an iterative algorithm refines the dictionary while maintaining sparsity in representation vectors. Two dictionaries are used in BID20 for LR representation and HR reconstruction. The usage of L2 norm instead of L1 norm for faster computations has been proposed. Convolutional networks can also map between high and low resolution images. Rectified linear units have replaced major activation functions in neural network training, leading to easier learning of sparse representations. Sparse representation in neural networks has been shown to improve gradient backpropagation and representations during the forward pass. BID18 utilizes gradient information to separate image pixels based on strength, coherence, and angle. This separation helps in creating robust representation vectors against small input changes. BID5 established the early connection between CNNs and Sparse Representation, where the first layer outputs serve as representation vectors for patches. The SRCNN algorithm uses multiple layers to map low-resolution representations to high-resolution vectors and reconstruct HR images. While CNNs provide good superresolved image estimates, the connection between the inversion of observation models and CNN neuron activation is missing. This section aims to show the relationship between inverse problem solutions, sparse representation, and CNNs. During training, CNNs map LR input to HR images by convolving LR images with neuron filters. The resulting image is compared to a ground truth HR image, and errors are backpropagated. The convolution operation is carried out algebraically on LR superpatches divided into subpatches. The network produces a mapping from LR superpatch to HR image. The CNN training process involves mapping LR input to HR images by convolving LR images with neuron filters. The network produces a mapping from LR superpatch to HR image, with operations solving for the same equation. Modifications are made to the gradient descent learning process to address issues with the MSE gradient. During the testing phase, a new concept called representation-dictionary duality (RDD) is proposed. It suggests using the learned representation vectors as atoms of a dictionary for testing. The cost function minimized during CNN training yields a representation vector as the neuron filter, with the dictionary being matrix D L and the target being the HR image patch. During testing, the representation vectors from a layer of neurons become a dictionary (D R) for reconstructing the HR image. The concept of representation-dictionary duality (RDD) suggests using learned representation vectors as atoms of a dictionary for testing. This approach differs from previous proposals by considering each layer output as a structure that can be represented by a convolutional sparse coding (CDC) layer, which is essentially a CNN layer. In RDD, dictionaries and representations swap roles during training and testing, with inputs to each layer perceived as a dictionary for the next layer. During testing, the representation vectors from a layer of neurons become a dictionary (D R) for reconstructing the HR image. The neuron filters can be viewed as atoms of a dictionary, with the representation vector of the input image being the neuron outputs. ReLU operators provide the representation vector for the input image given the trained filter values collected under D R. During testing, the representation vectors from a layer of neurons become a dictionary (D R) for reconstructing the HR image. The neuron filters act as atoms of this dictionary, with the representation vector of the input image being the neuron outputs. In experimentation, it was shown that apparent features are only visible in the first layer with specific training sets containing coherent edges. Deeper layers build upon previous outputs, making it difficult to demonstrate in all layers. Training with a more general set may not reveal any patterns in learned filters, as this could lead to memorization, which is detrimental to neural networks. Theorem 1 from BID15 will be used to extend the understanding of single neurons to the entire network, considering a convolutional sparse coding structure where D l is the dictionary for the l th layer. The convolutional sparse coding structure uses dictionaries for each layer, with mutual coherence denoted by \u00b5(D i). The theorem demonstrates that a network of neurons can achieve the same results as a sparse coding algorithm. By recalling the Landweber equation, it is possible to convolve network filters to produce an end point filter, f L, when all neurons are activated. The convolutional sparse coding structure uses dictionaries for each layer to achieve results similar to a sparse coding algorithm. The reconstructed image quality is affected by the overcompleteness assumption violation, with larger areas for reconstruction proving useful. This insight helps determine the depth of a network for specific features, such as texture modeled as gaussian noise in superpatches. The D L matrix becomes linearly independent when the HR region contains only texture, allowing shallow networks to perform as well as deep networks on textured images. During testing, the same filters are used to construct the D L matrix, and the network's result is obtained without normalization. The error is not completely orthogonal to the LR images due to the iterative nature of equations, making the operation meaningful for learning complete representations. The network recovers HR details through inner products, emphasizing the importance of data recovery for training completeness. The network recovers HR details through inner products, training with different structures enables the constant evolution of neuron filters. Using a single training set for a single network complicates the training process. Proposing the usage of a double network SR (DNSR) for two different data sets, separated based on gradient information into low and high coherence sets. A shallower network with 10 layers is trained for low coherence data (texture), while a deeper network with 20 layers is trained for high coherence data (edge and corner information). This separation of neural networks is a novel approach for recovering different contents for super-resolution. The authors propose using skip connections in a shallow network to increase coherence of layer outputs. Skip layers are used to prevent gradient vanishing and propagate information between different network structures. Cross entropy loss is also utilized in addition to MSE loss for low coherence networks. The authors used cross entropy loss in addition to MSE loss for low coherence networks. Bicubically upsampled inputs were used as the only pre-processing step before neural networks. The aggregation of two separate networks was done in a post-processing block, with backprojection of results to upsampled input images. Training and testing operations were run on an Intel i7-4770K CPU Nvidia GeForce GTX 760 GPU computer. Training times were 16 hours for high coherence network and 8 hours for low coherence network, faster than state-of-the-art algorithms. The authors conducted experiments on separate training sets with high coherence data, showing that the learned filters in the first layer resemble the predominant features of the training set. Separate network training allows for recovery of details that may be lost during training. Barbara image details are clearly visible in low coherence network output. Using coherence, strength, and angle information to divide training data, two networks were chosen for practicality. The proposed network is faster than BID9 due to lighter networks and split training sets based on information content. Neurons can solve inverse problems optimally, and CNN layers act as sparse representation solvers. RDD improves texture recovery, with experiments showing better and faster results compared to state-of-the-art algorithms. Future plans include investigating a content-aware aggregation method. In the future, the plan is to investigate a content-aware aggregation method for better performance. Additionally, there are plans to optimize two networks jointly and improve the network structure for texture recovery. The initial upsampling step will be incorporated into the network to allow it to learn its own interpolation kernels."
}