{
    "title": "r1gKmmKULB",
    "content": "Holistically exploring animal communication is challenging due to signal complexity. New techniques project communicative repertoires into low dimensional spaces for studying perceptual and neural representations. An ongoing experiment focuses on songbird neural and perceptual representations of syllables, exploring the relationship between them and machine learning algorithms. Studying neural mechanisms in birdsong can inform machine sequence modeling. The curr_chunk discusses the need for more species-general approaches in modeling animal communication systems in neuroscience. It proposes a method based on generative modeling to explore and understand these systems more systematically. Recent advances in generative modeling have been successful in studying species like songbirds, primates, insects, cetaceans, and amphibians in various recording conditions. The method demonstrates that basal ganglia and frontal cortex structures maintain temporal information, with songbird temporal structure showing long-range dependencies. The experiment involves training a songbird to classify regions of a VAE-generated latent space of song to explore how sequential context is maintained in the songbird brain. The study aims to manipulate perception in a VAE-generated latent space of song by interpolating between syllables of European starling song and providing contextual information to shift the perception of classified stimuli. The experiment involves training a starling to classify syllables based on contextual cues, with the hypothesis that the perception of boundaries between stimuli changes based on the context. The initial results confirm this hypothesis. The initial behavioral results of the experiment confirmed our hypotheses. Additionally, acute information was gathered (Fig. 3 left)."
}