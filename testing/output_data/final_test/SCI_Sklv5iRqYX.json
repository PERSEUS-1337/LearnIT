{
    "title": "Sklv5iRqYX",
    "content": "This paper introduces MuLANN, a multi-domain adversarial learning approach for automated microscopy data with experimental bias. It includes a bound on average- and worst-domain risk, a new loss for semi-supervised learning, and experimental validation on image benchmarks and a bioimage dataset, Cell. Transfer learning is crucial for leveraging information across multiple datasets in life sciences laboratories, particularly in cases where data acquisition is expensive. Automated microscopy captures thousands of images of cultured cells under different experimental conditions, aiming to classify mechanisms affecting cellular processes based on cell image similarity. This approach can be viewed as a visual object recognition task. Microscopy image classification faces challenges due to experimental variations and limited labeled perturbations. Multi-domain learning aims to overcome these challenges by learning models across multiple datasets to achieve robustness and good class coverage. Multi-domain learning (MDL) aims to learn a model of minimal risk from datasets with distinct underlying distributions, contrasting with domain adaptation (DA) which focuses on learning a model with minimal risk on a target distribution by leveraging other sources. MDL leverages more information to allow better generalization and accommodate the specifics of each domain, leading to improved performance on new domains, known as domain generalization or zero-shot domain adaptation. Multi-domain learning (MDL) focuses on learning a model with minimal risk from datasets with distinct distributions. It extends domain adaptation (DA) by enabling knowledge transfer between domains, reducing the need for labeled examples. MDL guarantees the model's risk over all domains is upper bounded by the oracle risk and the sum of H-divergences. The proposed approach, MULANN, extends Domain Adversarial Neural Networks to handle class asymmetry in semi-supervised DA and MDL. Empirical validation shows MULANN outperforms state-of-the-art methods on image benchmarks and a bioimage benchmark. The curr_chunk discusses benchmarks BID52, BID35, and a novel bioimage benchmark CELL, emphasizing domain-dependent pre-processing. It introduces notation for input space X, classes Y, datasets S i, distribution D i, hypothesis space H, risks i (h), and oracle hypotheses h i. The text also touches on the semi-supervised setting and the interchangeability of \"domain\" and \"distribution\" in machine learning. Transfer learning methods have evolved to address concept drift, covariate shift, and distinct distributions or tasks. Shared and domain-specific parameters can be used in MDL, with domain-specific parameter usage learned through methods like domain-guided dropout or prior knowledge of domain relationships. Domain-guided dropout BID72 and prior knowledge about domain semantic relationships BID74 are utilized in early domain adaptation (DA) approaches. These approaches leverage source examples to learn on the target domain through various methods such as reweighting source datapoints BID41 BID26 BID24 and aligning source and target representations with PCA-based correlation alignment or subspace alignment BID21. In computer vision, image-to-image translation combined with generative adversarial networks is used for mapping examples between domains. The difficulty of DA depends on the distance between the source and target distribution, with many methods focusing on reducing this distance in the original input space X through techniques like importance sampling BID7. Neural networks are used to create latent spaces for source and target samples with minimal distance, achieved through generative adversarial mechanisms or task objective approximation. Various distances are utilized, such as Maximum Mean Discrepancy, L2 contrastive divergence, and Frobenius norm. Most domain adaptation methods assume source and target examples are from the same classes, as seen in benchmarks like OFFICE. Domain adaptation methods like OFFICE BID52 focus on adapting source and target examples from the same classes. However, partial domain adaptation methods like BID77 face challenges when dealing with semi-supervised MDL with non-identical domain class sets. These methods do not address the impact of unlabeled samples without labeled counterparts or the effect of extra labeled source classes on accuracy. Class asymmetry can significantly affect model performance if not considered. In the field of bioinformatics, there is a growing recognition of the importance of domain adaptation methods like BID55, BID73, and BID68 due to issues like concept drift and covariate shift in biological experiments. Batch effects in image-based screening data are typically addressed with normalization methods. While domain adaptation has been applied to improve image segmentation tasks, the use of Minimum Description Length (MDL) in Bioimage Informatics is novel. This work introduces the MULANN approach by extending domain adaptation theoretical results to the MDL case. The H-divergence is utilized to bound the domain adaptation risk, supporting the design of the MULANN approach. The H-divergence is used to define the distance between source and target in domain adaptation. It inspires an adversarial approach to DA by minimizing the H-divergence between source and target projections. The target risk is bounded by the empirical source risk, H-divergence, and oracle DA risk. MDL aims to minimize average risk over all domains, while DA aims to minimize target risk only. The MDL loss is a convex combination of domain risks, with an upper bound on the compound empirical risk. This bound ensures that a model can perform well on all domains if they are indistinguishable. In the 2-domain case, minimizing the convex combination of losses in proportion to samples minimizes the bound. The classifier imbalance is defined as the extent to which marginal distributions can be distinguished by a classifier, yielding an upper-bound on the risk imbalance. Minimizing H-divergences or using class-wise contrastive losses improves this upper bound. An alternative bound can be obtained by using the H\u2206H-divergence. The classifier imbalance can be bounded using the H\u2206H-divergence, which can lead to negative transfer in cases of class asymmetry between domains. Unlabeled samples from classes not present in other domains can deteriorate domain alignments, shuffling unlabeled samples more than labeled ones. In MULANN, a new discrimination task called Known Unknown Discrimination (KUD) addresses the limitation of domain alignment shuffling unlabeled samples more than labeled ones in cases of class asymmetry. KUD aims to rank unlabeled samples within each domain based on classification entropy, with a hyper-parameter p determining the top p% as \"most likely unknown\" to be discriminated from labeled samples. The KUD module works to repulse these unknown unlabeled samples from the labeled ones. The KUD module in MULANN repulses unknown unlabeled samples from labeled ones within each domain to resist global domain alignment effects. MULANN consists of 3+n modules, including a feature extractor, classifier, domain discriminator, and n KUD modules. All modules are learned simultaneously by minimizing loss functions involving hyper-parameters and domain discrimination. The experimental validation of MULANN in domain adaptation and multi-domain learning settings is reported on three image datasets, including DIGITS, Synthetic road signs, German traffic sign benchmark, and OFFICE in the DA setting, and the new CELL benchmark in the MDL setting. The MDL setting involves the new CELL benchmark with fluorescence microscopy images of cells in three domains: California, Texas, and England. There are 13 classes across the domains, with four domain shifts considered. MULANN is compared to DANN and MADA using pre-trained VGG-16 architecture for OFFICE and CELL datasets. The models are trained in Torch BID16 using stochastic gradient descent with momentum. No hyper-parameter grid-search is performed for OFFICE results. Semi-supervised setting involves using a fixed number of labeled images per class for different domains. Evaluation is performed on all target images from the unlabeled classes in DA and on all source and target classes in MDL. In MDL, evaluation is done on all source and target classes, including labeled and unlabeled samples. The goal is to assess MULANN performance compared to baselines and understand how the experimental setting affects model performance. Two experiments are conducted to evaluate the impact of using unlabeled images during training: fully transductive setting (FT) and non-fully transductive setting (NFT). The use of domain discriminator and KUD modules with labeled and unlabeled images is a key question. The MULANN model, incorporating a contrastive loss and soft label loss, outperforms previous methods on challenging tasks like D\u2192A, A\u2192D, or W\u2192A. Fully transductive results are superior to non-fully transductive ones. MADA performs similarly to DANN on DIGITS and RoadSigns but worse on OFFICE due to the increasing number of classes. MDL is a state-of-the-art method for quantifying changes in cell morphology using tailored approaches for fluorescence microscopy images. The profile of microscopy images is defined by extracting shape, intensity, and texture features from segmented cells. Classification is done using linear discriminant analysis and k-nearest neighbor. Different methods like CORAL and fine-tuning VGG-16 are compared to baselines in Table 2. DANN, MADA, and MULANN are also compared to baselines in terms of raw images and profile representations. The profile-based baseline generally outperforms the image-based baseline in terms of classification accuracy. Standard deviations are larger for CELL test results compared to OFFICE, RoadSigns, or DIGITS due to higher intra-class heterogeneity. MULANN and P+CORAL both show improvements in classification. MULANN and P+CORAL improve classification accuracy on unlabeled classes by reducing divergence between domain marginals. MULANN outperforms DANN and MADA, especially in three-domain cases. MULANN is designed to counter negative transfer caused by class asymmetry by repulsing labeled examples from unlabeled examples of extra classes. The impact of class/domain asymmetry is discussed, highlighting the presence of \"orphan\" classes unique to a single domain. The importance of underestimating rather than overestimating the parameter p is emphasized, as it can perturb the entropy ranking of unlabeled examples. The impact of orphan classes, known as class asymmetry, is examined in a 2-domain scenario. Different types of samples are considered, showing a decrease in accuracy when labeled orphan samples are added compared to the no-orphan scenario. In a 2-domain scenario, the impact of orphan classes on classification accuracy is examined. Labeled orphan samples lead to a decrease in accuracy compared to the no-orphan scenario. The shuffling of unlabeled samples between domains significantly affects accuracy, while the addition of unlabeled samples seen only by the discriminator has little impact on classification accuracy. This paper explores the impact of class asymmetry on transfer learning, showing that asymmetry in labeled class content can significantly affect model performance. It extends domain adversarial learning to multi-domain learning, introducing MULANN to address the effects of class asymmetry. MULANN introduces a new loss to resist the effects of the domain discriminator and improve performance in multi-domain learning. Results show superiority over DANN and MADA on various datasets, setting a new baseline for microscopy image analysis. Future work aims to integrate importance sampling techniques and preserve domain-specific behaviors during learning. In computer vision, image-to-image translation is a method of mapping examples from one domain to another. Pic2Pix uses a conditional GAN for supervised cases and enforces cycle consistency for unsupervised cases. Translation approaches do not directly address domain adaptation, but additional losses like DTN and GenToAdapt are used to overcome this limitation. Various domain transfer networks (DTN) utilize different loss functions in the latent space, such as auto-encoder-like loss in BID64, classifier loss in GenToAdapt BID53, and VAE loss in UNIT BID36. StarGAN BID15 combines image-to-image translation with a GAN, while ComboGAN BID1 learns two networks per domain. DIRT-T BID57 uses a conditional GAN and classifier in the latent space with additional losses enforcing the cluster assumption and virtual adversarial training. The use of multiple losses in deep learning, like DA and MDL, aims to create a smoother optimization landscape and stable representation. The H-divergence between two distributions D and D on domain X is defined for a binary hypothesis class H. The compound empirical error is bounded with probability at least 1 - \u03b4 for a sample S of size m containing samples from D i. BID5 use H-divergence for empirical validation despite limitations of H\u2206H divergence. The H-divergence is used for empirical validation in the context of a binary hypothesis class H. Propositions are made regarding the relationship between distributions D i, hypothesis class H, and the H-divergence. The dataset extracted from BID31 consists of 455 biologically active images in 11 classes on four 384-well plates in three channels. A visual quality control was implemented to remove images with only apoptotic cells and XRCC5-YFP channel. Quality control was implemented to remove images with only apoptotic cells, and XRCC5-YFP channel images were smoothed using a median filter of size 2. The dataset contains 1,077 biologically active images in 10 classes on ten 384-well plates in three channels: H2B-CFP, XRCC5-YFP, and cytoplasmic-mCherry. Cell culture, drug screening, and image acquisition involved retroviral transduction of marker plasmid \"pSeg\" to express H2B-CFP and cytoplasmic-mCherry tags in A549 human lung adenocarcinoma cells, and a CD-tagging approach to add an N-terminal YFP tag to endogenous XRCC5. Maintenance was in RPMI1640 media with 10% FBS, 2 mM glutamine. Cells were cultured in RPMI1640 media with 10% FBS, 2 mM glutamine, penicillin, and streptomycin. Prior to drug treatment, cells were seeded in a 384-well plate. After drug addition, cells were incubated for 48 hours at 37\u00b0C. Images were captured using a GE InCell Analyzer 2000, processed to correct illumination and remove background noise. Quality control was performed to exclude images with anomalies or apoptotic cells. YFP-XRCC5 channel images were smoothed for analysis. The dataset contains 879 biologically active images of MCF7 breast adenocarcinoma cells in 15 classes on 55 96-well plates, in 3 channels: Alexa Fluor 488 (Tubulin), Alexa Fluor 568 (Actin), and DAPI (nuclei). Classes with fewer than 15 images and absent from other datasets were not used, leaving 10 classes for analysis. Images were processed using ImageJ plugin and down-scaled 2 times for segmentation and feature extraction. The dataset contains 879 biologically active images of MCF7 breast adenocarcinoma cells in 15 classes on 55 96-well plates, in 3 channels. Object features were extracted, and biological activity was obtained. A visual quality control was implemented to remove images with anomalies and too few cells. Tubulin channel images were smoothed, and images not distinct from negative controls were excluded. Images from all domains were down-scaled and flattened to form RGB images, normalized for analysis. The dataset contains 879 biologically active images of MCF7 breast adenocarcinoma cells in 15 classes on 55 96-well plates, in 3 channels. Images were down-scaled and flattened to form RGB images, normalized by subtracting intensity values from negative controls. England, Texas, and California share images for cell nucleus and cytoplasm, with different proteins shown in the third channel. Experiments combining Texas and England, and California and England used only the first two channels. Profiles contain 443 features related to the first two channels and 202 features related to the third channel. Only the former features were used in experiments involving the England dataset. Shift Dom. 2 includes labeled classes Domain 2 and unlabeled classes E-C HDAC, Proteasome, Actin, Aurora DNA, MT, ER C-T DNA, HDAC, MT, ER, Aurora, mTOR, PLK Actin, Proteasome, Hsp90 T-E DNA, MT, Proteasome, Actin, ER Aurora, HDAC. In experiments involving the England dataset, a bottleneck fully connected layer is added after the last dense layer of VGG-16. Different learning rates are applied to weights and biases of \"from scratch\" layers compared to fine-tuned layers. Instance normalization is used on DIGITS, while global normalization is used on OFFICE and CELL datasets. Various hyper-parameter ranges were evaluated in cross-validation experiments. Visualization of common feature space in Webcam \u2192 Amazon classes is shown using tSNE in 3-DOMAIN RESULTS ON OFFICE. The common feature space in the example of Webcam \u2192 Amazon is better separated with MULANN, with unlabeled examples more grouped and closer to labeled points from the other domain."
}