{
    "title": "BkgqL0EtPH",
    "content": "The largest public ECG dataset of continuous raw signals for representation learning is released, with over 11k patients and 2 billion labelled beats. The goal is to enable semi-supervised ECG models and discover unknown subtypes of arrhythmia. Unsupervised representation learning task is proposed, with baselines for different feature extractors provided. Qualitative evaluations on PCA embeddings show potential for arrhythmia sub-type discovery. Detection of arrhythmia is currently done by experts, but supervised machine learning has shown success in certain types. The data-driven approach aims to detect ECG anomalies not fitting known arrhythmia types using a single-lead heart monitor device. The high-resolution, sampled data can improve current processing techniques and potentially detect anomalous events earlier. The study aims to improve automated arrhythmia detection by using representation learning on ECG data. The proposed semi-supervised challenge seeks to create representations that preserve information about heart function to predict major cardiac issues more effectively. The study is approved by the ethics institutional review boards at the university. ECG signals are collected by electrocardiograph machines with 10 electrodes, resulting in 12-lead ECG data. This data provides additional information about the heartbeat but has limitations in capturing rare events over time. Feature extraction for predicting outcomes beyond arrhythmia is a studied field that can benefit from learned feature extractors. The MIT-BIH dataset, created in 1979, was one of the first open datasets of ECG signals. It is still in use today with 47 subjects. Computer predictions during that time were found to be error-prone. Later, more specific datasets were created, such as the MIMIC-III Waveform Database containing records from 30,000 ICU patients. The ECG-ViEW II dataset aims to provide ECG records with clinical data. The MIT-BIH dataset, created in 1979, was one of the first open datasets of ECG signals with 47 subjects. More specific datasets like the MIMIC-III Waveform Database and ECG-ViEW II dataset were later created. Kim et al. (2017) provides a dataset of ECG records for 461,178 patients with beat information. The STAFF III Database (Pablo Mart\u00ednez et al., 2017) includes 104 patients with induced myocardial ischemia. Single-lead wearable devices now offer larger amounts of ECG data for machine learning. Rajpurkar et al. (2017) created an annotated training dataset of ECG signals for 30,000 patients. The curr_chunk discusses the potential risks of re-identification from anonymized ECG signal data and questions the reliability of using ECG as a method of authentication. It mentions previous studies claiming high performance but lacking controlled evaluation. The context provided in the prev_chunk talks about various datasets of ECG signals and annotated training datasets created for machine learning purposes. The curr_chunk explores alternative ways to sense cardiac motion, highlighting the limitations of using ECG as a biometric due to its indirect nature and lack of sufficient information. It emphasizes the need for careful handling of heartbeat data, as it can contain both health-related and personal identification information. Israel & Irvine (2012) mention that ECG must overcome several limitations before being used as a biometric, such as the requirement for a sufficient number of samples to identify an individual and the unique signal produced by varying environments and emotional states. The dataset processed from data provided by 11,000 patients who used the {DEVICENAME} TM device predominantly in Ontario, Canada. The majority of patients wore the device for one week, with the average age being 62.2\u00b117.4 years. The device is mostly used for third line exams, resulting in the majority of records exhibiting arrhythmias. The dataset analyzed includes records with arrhythmias from 11,000 patients using the {DEVICENAME} TM device in Ontario, Canada. Data collection was done in 2017 and 2018. {COMPANYNAME}'s team of 20 technologists analyzed the data using proprietary tools, with beat detection done automatically. Technologists reviewed the records for severity and analyzed beats and rhythms for full disclosure. The analysis was then approved by a senior. The data preparation process involves segmenting patient records into 70-minute segments for rhythm detection. 50 segments are randomly selected to reduce dataset size while maintaining patient representation. Labels are removed for 80% of patients in the training data, with half used for semi-supervised tasks and the other half for evaluation. Further details can be found in Table 1. The data is separated into different levels of hierarchy: Patient level (3-14 days), Segment level (approximately 1 hour), and Frame level (approximately 8 seconds). Each level captures specific features for analysis, such as patterns indicating disease at the segment level and beat/rhythm features at the frame level. Processing data with these hierarchy levels enhances arrhythmia identification. In this paper, the focus is on developing unsupervised representations of ECG signals to improve supervised tasks and identify unknown disease subtypes. The data is processed with hierarchy levels to enhance arrhythmia identification. The goal is to leverage grouping information for better results and evaluate the frame level embeddings for cardiologists' interpretation. Common unsupervised algorithms will be benchmarked in a semi-supervised setting for quantitative evaluation. The evaluation involves predicting beat and rhythm for each frame in a holdout set. The beat task is to classify normal beats or abnormal beats like PVC or PAC. Classifying a beat alone is challenging as abnormal beats may look similar to normal beats. The model needs to consider nearby beats for accurate classification. The second task is predicting the rhythm type for each frame. The classification method predicts the rhythm type for each frame, distinguishing between normal, atrial fibrillation (AFib), and atrial flutter based on input representation. AFib is characterized by irregular RR intervals and no distinct P waves, while flutter appears as a saw-tooth pattern of R waves. Recognizing these patterns requires context larger than a single beat, and the duration of AFib is controversial among cardiologists. The labels are annotated at the beat level, with only two types of labels provided for evaluation and classification. The evaluation method involves supervised classification to assess the effectiveness of extracted features in detecting beat-level anomalies and anomalous rhythm periods. The training data lacks beat annotation and labels, allowing for training of feature extraction methods. The evaluation process includes sampling frames, computing representations, training a classification method on 50% of the data, and evaluating on the remaining 50%. Two classification models are utilized for this purpose. The evaluation involved using two classification models: k-nearest neighbors (KNN) with k = 3 and an MLP model with 4 layers. The MLP model was trained for 10 epochs with Adam optimizer and dropout was applied to prevent overfitting. Baseline feature extraction methods included Principal Components Analysis (PCA), Fast Fourier Transform (FFT), and Periodogram for spectral density estimation. BioSPPy identifies beats using Carreiras et al. detection algorithm and computes mean and standard deviation. Autoencoder consists of 2 MLPs with a bottleneck representation of 100 dimensions. Model trained for 3 epochs with Adam optimizer. Evaluation in semi-supervised setting on known arrhythmia and rhythm labels. The study evaluates the quality of representations for identifying unknown disease subtypes using two models. Balanced accuracy is used due to class imbalance, with a maximum of 0.33 for predicting the same class for all samples. Performance on a semi-supervised task is assessed by predicting labels in the test set from a random subset of labels in the training set. The study evaluates the quality of representations for identifying unknown disease subtypes using two models. Balanced accuracy is used due to class imbalance, with a maximum of 0.33 for predicting the same class for all samples. Performance on a semi-supervised task is assessed by predicting labels in the test set from a random subset of labels in the training set. An analysis of specific clusters resulting from PCA features of 100 dimensions visualized with t-SNE shows that autoencoders do not perform as well as expected. PCA performs best for beat detection with KNN, while MLP is better at predicting using raw signal. Rhythm detection is challenging, possibly due to Periodogram and FFT capturing periodicity better than other methods. Vollmer et al. (2018) demonstrated success in a supervised setting, highlighting issues with using MLPs for classification in this task. The study highlights issues with using MLPs for classification tasks, especially in cases with limited data points. The variance in accuracy is higher with N = 1000, particularly in rhythm classification due to imbalanced classes. Using powerful parametric models like MLPs that excel only with higher instance counts may not be ideal for representation learning of ECG signals. Medical literature discusses various types of PVCs, including monomorphic, multimorphic, and multifocal. PVCs can be monomorphic or multimorphic, with different morphologies. In a multi-lead setting, PVCs from the right ventricle show a dominant S wave, while those from the left ventricle have a dominant R wave. t-SNE plots show two clusters of PVCs representing different arrhythmia morphologies. The correlation between two clusters for PVCs and their multimorphic aspect is of interest to medical researchers for further exploration. Various encoding methods show clustering related to PVC and PAC, with some exceptions. Machine learning is increasingly used for analyzing data from single-lead heart monitors like the {DEVICENAME} TM to learn more about arrhythmia and related heart diseases. Machine learning is widely used in the medical field to predict diagnoses based on expert labels. Supervised learning is helpful but limited by human knowledge. Representation learning can uncover complex features in body signals and potentially discover new diseases. Releasing datasets can aid in training models with fewer samples and identifying new patterns in diseases. We proposed an evaluation pipeline for learning a feature extractor and evaluating extracted features using known arrhythmia as a proxy. Baseline results for frame-level representations under different feature extraction methods were provided. Our data preparation allows for a three-level hierarchy - segment and patient level grouping of data. Future work can exploit this context to extract better representations and find more interesting structure in the representation space. The dataset can also serve as a benchmark in anomaly and outlier detection and hierarchical sequence modelling in machine learning."
}