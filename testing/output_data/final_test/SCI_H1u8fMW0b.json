{
    "title": "H1u8fMW0b",
    "content": "The active inference framework proposed by Friston (2010) is described from a machine-learning perspective, inspired by biology and auto-encoding principles. A cognitive architecture is outlined for implementing estimation-oriented control policies, with computer simulations demonstrating effectiveness through foveated data inspection. The control policy's pros and cons are analyzed, showing potential in processing compression. Optimizing future posterior entropy for action selection is effective, but offline calculation using saliency maps is more efficient, reducing processing costs without affecting recognition/compression rates. Oculo-motor activity is crucial for humans and animals. The oculo-motor activity, essential for human and animal behavior, involves high-speed eye movements called saccades that capture visual scenes. While current artificial vision relies on high-performance sensors and computing power for recognition, a more efficient approach inspired by animal vision could lead to more resource-efficient recognition methods. The example of animal vision highlights the use of active sensing devices for viewpoint selection in recognition algorithms. Optimizing sensor movements over time can enhance computer vision programs, complementing traditional pixel-based operations. This approach mimics the oculo-motor activity seen in human and animal behavior, offering a more efficient and resource-effective method for recognition tasks. A virtual sensing device acts as a filter to select important parts of a signal, crucial for fast reactions in robots and drones. In computer vision, high-resolution images require selective convolution to avoid unnecessary processing. Machine learning databases also benefit from intelligent data scanning to retain critical examples before learning. The concept of active vision and perception is essential in robotic literature, addressing multi-view image processing in BID2. The authors in BID2 discuss multi-view image processing, showing how certain object recognition problems become well-posed when multiple views are considered. The active inference paradigm, introduced in neuroscience, suggests that the brain counteracts surprising sensory events by building generative models to improve predictions over time. The active inference paradigm involves extracting statistical invariants from the environment to predict upcoming events efficiently through predictive coding. It links dictionary construction from data to optimal motor control, viewing motor control as a sampling process for estimating complex posterior distributions. This approach is rooted in probabilistic modeling in signal processing and control. The active inference paradigm involves designing a perception-driven controller to estimate underlying causes of sensory observations by maximizing state estimation accuracy. This controller aims to minimize uncertainty about the latent state vector z through optimal control strategies. The active inference paradigm involves designing a perception-driven controller to estimate underlying causes of sensory observations by maximizing state estimation accuracy. This controller aims to minimize uncertainty about the latent state vector z through optimal control strategies. Minimizing the entropy of the posterior through action is linked to reducing the variational free energy of the sensory scene. The control u is expected to decrease the entropy of \u03c1 at each step, with the optimal u determined by the generative model's most probable outcome. The generative model operates under a discrete Bayesian inference formalism, with predictions based on conditional distributions P(Z|u, z0) and P(X|z, u). The posterior distribution is updated using Bayes' rule. The active inference paradigm involves designing a perception-driven controller to estimate underlying causes of sensory observations by maximizing state estimation accuracy. The controller aims to minimize uncertainty about the latent state vector z through optimal control strategies. In practice, analytic calculations for predicting the next distribution of x's are out of reach, requiring estimation through sampling or maximum likelihood estimates. This process involves updating the posterior distribution over the z's based on the actual control u and observation x, leading to a new control u for the next decision step. The active inference paradigm involves designing a perception-driven controller to estimate underlying causes of sensory observations by maximizing state estimation accuracy. The final posterior estimate in the Partially Observed Markov Decision Process (POMDP) complies with entropy minimization principles to facilitate the estimation process. The active inference framework is scene understanding oriented, focusing on uncovering sensory patches through changing sensor orientation. The active vision framework simplifies the estimation process by focusing on collecting sensory patches through changing sensor orientation to refine the estimation of latent state z. Each saccade consolidates assumptions about z, which are retained and propagated until enough evidence is gathered. The framework assumes that changing sensor orientation does not affect the scene constituents and that no significant changes occur during exploration, leading to a simplified posterior estimation process. The active vision framework simplifies the estimation process by collecting sensory patches through changing sensor orientation to refine the latent state z. This leads to a simplified chaining of posterior estimation, issuing a final estimate P(Z|x 1:T, u 0:T-1, z 0). The active inference framework, rooted in auto-encoding theory and predictive coding, provides a roadmap for implementation in artificial devices, relying on generative and inference models, as well as a policy for optimal control. The active vision framework involves using optimal control to select different viewpoints over a static image, with generative and inference models trained for each viewpoint. This model-based approach is detailed in algorithms 1 and 2, with a significant addition being the use of a dynamic actions set. The algorithmic add-on in the active vision framework involves a dynamic actions set U for selecting new actions at each turn, implementing the inhibition of return principle. Another aspect is the use of a threshold H ref to stop the evidence accumulation process. This threshold parameter determines whether a conservative or optimistic approach is taken, balancing resource saving and coding accuracy. The proposed vision model involves learning local foveated views on images using a pyramid of 2D Haar wavelet coefficients at the center of sight. This allows for processing high spatial frequencies in the central vision and low spatial frequencies in the periphery simultaneously. The model also includes sequential saccadic scene exploration for grabbing high spatial frequency information where needed. The vision model involves learning local foveated views on images using a pyramid of 2D Haar wavelet coefficients. Each viewpoint corresponds to a set of 3 coordinates, with multiscale visual information available at each coordinate. A weak generative model is learned for each viewpoint. A weak generative model is learned for each coordinate (7, 7), (7, 8), (8, 7), and (8, 8) over 55,000 examples of the MNIST database. Each generative model is built over a parameter set \u0398 z,u = (\u03c1 z,u , \u00b5 z,u , \u03a3 z,u ) for each category z and gaze orientation u. The resulting weak generative models are mixtures of Bernoulli-gated Gaussians over the 10 MNIST labels. The saccade exploration algorithm is an adaptation of the inference model using Bayes rule. The saccade exploration algorithm uses a softmax function to calculate posterior probabilities based on wavelet coefficients. Each saccade is determined by coordinates (i, j) and subsequent saccades are based on selected coefficients. The process is illustrated with an example on an MNIST sample image. The saccade exploration algorithm uses a softmax function to calculate posterior probabilities based on wavelet coefficients. Saccades are determined by coordinates (i, j) and subsequent saccades are based on selected coefficients. The model provides realistic saccades that cover the full image range and point to regions with class-characteristic pixels. Image reconstruction after 4 saccades allows for visual recognition of a \"fuzzy\" three. The saccade exploration algorithm uses a softmax function to calculate posterior probabilities based on wavelet coefficients, determining saccades by coordinates. The observed trajectory illustrates the guess confirmation logic behind the active vision framework, where each saccade heads towards a region to confirm the current hypothesis. This confirmation bias may seem counter-intuitive, but heading towards class-confirming regions may provide more information, even if it invalidates the initial assumption. The saccade exploration algorithm uses a softmax function to calculate posterior probabilities based on wavelet coefficients for saccades trajectory over the original image. The reconstruction process involves progressive image reconstruction over the course of saccades, with different coefficients triplets and root coefficient for each saccade. Posterior update and entropy update are shown in function of the number of coefficients read-out steps. The scaling of the model is crucial for large images, and the policy relies on a two-steps ahead prediction. The policy relies on a two-steps ahead prediction that scales computationally efficiently, allowing for a single draw over the actions set given a context. Offline computations provide a saliency map over the visual predictions, with low-level features-based saliency maps being utilized. The policy relies on a two-steps ahead prediction for viewpoint selection based on saliency maps. Saliency-based policies define an optimal saccade pathway through the image, with viewpoint selection depending on the current guess and allowing for on-the-fly map switch if the guess is revised. Examples of saliency maps for different categories are provided, allowing for detailed analysis of class-specific locations. The saliency maps and saccades trajectories for different latent classes show class-specific locations in the central part of the images, providing key classification information. The locations are distinct between classes and saccades mainly focus on these informative areas. The model captures essential class-relevant information in the central part of images. The classification rates increase with a decreasing recognition threshold. Saliency-based policy and random exploration are compared to the original predictive policy. The model achieves near optimal recognition rates with decreasing recognition threshold. The number of saccades increases with decreasing recognition threshold, indicating recognition difficulty. The distribution of saccades is skewed, with few saccades in easy recognitions and more saccades in difficult recognitions. Predictive and saliency-based policies require less than 5 saccades for recognition in over 50% of cases, compared to about 15 saccades in random exploration. The model efficiently recognizes scenes with few Haar coefficients and saccades, achieving high data compression. Active vision optimization has been explored in computer vision, with direct policy learning proposed in 1991. The evidence accumulation framework, originating from BID3, has been further developed in BID16 and BID5. It aligns with the predictive coding framework (BID18) by using predictions to update the posterior based on prediction errors. The concept of multiple models for scene identification aligns with the weak classifiers evidence accumulation principle (BID20), extending to multi-view selection in object search and scene recognition (BID17). Our contribution suggests a view-selection problem approach in processing compression under the Free Energy/minimum description length setup. The contribution involves optimizing convolutional processing and active vision for two-steps-ahead prediction using a generative model. Offline calculation with class-specific saliency maps is more efficient for action selection, reducing processing costs significantly without affecting recognition/compression rates. This approach can be utilized for active information development."
}