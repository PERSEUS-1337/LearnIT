{
    "title": "r1zb29kus7",
    "content": "In recent years, 3D CNNs have been widely used in video analysis and action recognition, but their high computation and storage requirements limit their deployment on mobile devices. A new regularization-based pruning method is proposed in this paper to improve efficiency by assigning different regularization parameters to weight groups based on importance. Experimental results show that this method outperforms other popular techniques in the field. In BID0 BID1, authors utilize 3D CNNs for human action identification in videos, facing challenges due to high dimensions leading to increased computing and storage consumption. To address this, researchers propose methods like knowledge distillation, parameter quantization, matrix decomposition, and parameter pruning. This paper introduces a regularization-based pruning approach for 3D CNN acceleration, enhancing efficiency by assigning different regularization parameters to weight groups based on importance. The regularization parameters for weight groups in a 3D convolutional neural network are assigned based on importance criteria. The objective function for structured sparsity regularization includes loss on data and non-structured regularization. Different regularization parameters are used for different groups to achieve structured sparsity. The regularization parameters for weight groups in a 3D convolutional neural network are assigned based on importance criteria. Pruning of weight groups is done by increasing the regularization parameter \u03bb g, compressing weights to zero. Weight groups are pruned based on their importance using the L1 norm as a criterion. The goal is to prune RN g weight groups in the network, sorting them in ascending order of L1 norms to remove oscillation. The regularization parameters for weight groups in a 3D convolutional neural network are determined by sorting the weight groups in ascending order of L1 norms. The average rank is calculated to avoid rank oscillation during training iterations. The update of \u03bb g is based on a formula involving the average rank r and a hyperparameter A for convergence speed control. The regularization parameters are adjusted based on the rank to decrease L1 norms for lower ranks and increase them for higher ranks. To increase L1 norms and prune weight groups in a 3D convolutional neural network, regularization parameters are adjusted based on rank. Back-propagation is used to update weights after obtaining new regularization parameters. Experiments are conducted using Caffe, with a focus on compressing weights in convolutional layers for network acceleration. Comparison methods include Taylor Pruning (TP) and Filter Pruning (FP), with speedup ratios calculated based on GFLOPS reduction. The proposed method is applied to C3D, a network with 8 convolution layers. The proposed method is applied to C3D BID2, a network with 8 convolution layers, achieving better results than TP and FP with different speedup ratios. The method is also demonstrated on 3D-ResNet18 BID2, with 17 convolution layers, achieving an accuracy of 72.50% after fine-tuning on the UCF101 dataset. Our approach achieves 2\u00d7 acceleration with only a 0.91% increase in error compared to TP and FP methods. The proposed method imposes gradual regularization, leading to consistent lower losses during the pruning process. Different regularization parameters are assigned to weight groups based on importance estimation for 3D CNN acceleration. The proposed method achieves better performance than other popular methods by gradually pruning weight groups in the network based on importance estimation."
}