{
    "title": "r1glDHR76N",
    "content": "Referential games provide a learning environment for neural agents based on the functional use of language for communication. However, they do not address the fundamental constraint that language must be learnable by new learners and overcome a transmission bottleneck. In this study, a bottleneck is introduced in a referential game with a changing population of agents. Cultural transmission leads to improved language efficiency and communicative success. Co-evolving language and agents through genotypical evolution results in overall improvements. The study emphasizes the importance of cultural evolution and the architecture in language emergence studies. The complexity of human languages and their emergence remain open questions. The emergence of human languages and their complexity is still an open question. Cultural evolution plays a key role in language acquisition and transmission. Computational studies on language emergence focus on communication through referential games, neglecting the need for language survival between agents. In this work, a transmission bottleneck is introduced in a population of agents playing referential games to model cultural evolution. The shape of the bottleneck, determined by the biases of the agents' genotypical design, influences the types of language that may emerge. If the agents' genotypical design is not suitable for effective communication, they may converge to a language that is not easily learnable or not converge at all. The study focuses on the co-evolution of language in this context. In this work, the co-evolution of language and architecture is studied in referential games using the Language Transmission Engine to model cultural and genetic evolution in a population of agents. The best results are achieved when both types of evolution are included, allowing languages and agents to co-evolve. Previous research has focused on the emergence of language in artificial agents using logic, symbolic representations, and modern deep learning methods. In the exploration of language emergence, different training approaches and tasks have been proposed to encourage agents to learn and develop communication. Tasks are commonly set up in an end-to-end setting where reinforcement learning can be applied, often in a two-player referential game scenario. Studies show that structure and compositionality can arise in emerged languages, but 'natural' language needs specific restrictions to incentivize its development. The evolution of human language remains a complex and poorly understood topic, particularly regarding the relationship between genetic and cultural evolution processes. The relation between genetic and cultural evolution in language emergence is a key question. Cultural transmission enforces structure and compression in languages, balancing compressibility and expressivity. Studies support the importance of cultural evolution in language structure. In language learning studies, agents learn by observing output from previous generations. Cultural pressures can be simulated by pairing agents randomly to solve communicative games. Genetic evolution played a role in endowing humans with language capabilities. Pre-modern humans lacked complex language abilities. Neural Architectural Search (NAS) focuses on searching network architecture space, unlike traditional evolutionary techniques. NAS methods optimize neural architecture using gradient-based methods like SGD. Recent techniques like ENAS and DARTS bring a gradient-based approach to NAS. In this work, the DARTS search space is used to study language emergence in a referential game where one agent generates a message from an image for another agent to select the correct image from a set. The setup encourages the agents to develop a communication protocol for success. The Language Transmission Engine (LTE) introduces cultural and genetic evolution in a referential game where agents communicate to succeed. Agents are sender or receiver, and cultural evolution is modeled by periodically replacing agents with new ones. In the Language Transmission Engine (LTE), cultural and genetic evolution are introduced in a referential game where agents communicate to succeed. Three methods are experimented with to select agents for replacement: randomly, replacing the oldest agents, or replacing agents with the lowest fitness. This setup, called co-evolution, involves mutating successful agents and replacing the worst agents with variations of the best agents. The selection process and subsequent mutation or re-initialization step are referred to as culling. In biology, culling involves removing organisms to promote certain characteristics. The culling rate determines the proportion of agents selected for mutation. Mutations are based on the RNN cell search space DARTS, which includes recurrent cells with up to N nodes. Each node can take the output of preceding nodes and connections are modulated by activation functions. In the search for optimal architectures, mutations are made by randomly sampling architectures one edit step away from the previous one. Edit steps include changing connections, output operations, or adding a new node, with a node cap of N = 8. The DARTS search space is used for potential mutations, but new architectures are not sampled based on a selection criterion. In the search for optimal architectures, mutations are made by randomly sampling architectures one edit step away from the previous one. The fitness criterion used is based on task performance and the age of the youngest agent in the population. This criterion considers both task performance and the speed at which performance is reached. The LTE framework is tested on a compositionally defined image dataset with various selection mechanisms. The study uses a modified Shapes dataset with 2D objects of different shapes, colors, and sizes. Images are described symbolically and mapped to multiple variations. A CNN feature extractor is pre-trained for the images. The DARTS search space is used for co-evolution experiments, and an LSTM is used for cultural evolution approaches. For cultural evolution approaches, an LSTM BID9 is used for sender and receiver architectures with specific sizes and hyper-parameters. The models have a hidden size of 64 and an embedding layer of size 64, with a vocabulary size V of 4. The maximum sentence length is limited to 5. Gradients are back-propagated using the Straight-Through Gumbel-Softmax Estimator. Experiments are run with a fixed temperature of 1.2 and the Pytorch Adam optimizer with a learning rate of 0.001 and batch size of 1024. Multi-agent experiments use a population size of 16. The optimiser is reset for every batch in multi-agent experiments with a population size of 16 senders and receivers. The culling rate is set to 0.25, with culling every 5k iterations. Jaccard Similarity is used to measure language consistency, sampling 200 messages per input image for each sender-receiver pair. High Jaccard Similarity indicates similar token usage in messages emitted by different agents. The study analyzes message similarity among agents in a population of 16 senders and receivers. It measures language consistency using Jaccard Similarity and computes the average number of unique messages generated by each sender. Topographic similarity is also considered to assess the complexity of the language used by the agents. The topographic similarity measures the correlation between symbolic representations and messages sent by agents. Average population convergence estimates learning speed by calculating agents' performance from birth to the age of the youngest agent in the population. The average population convergence is calculated by averaging the performance of all agents from birth to the age of the youngest agent in the population. Average Agent Entropy is computed to measure the certainty of sender agents during generation. A detailed comparison of cultural and co-evolution setups is presented, with analysis of evolution metrics over time and testing of converged languages and architectures in a sender-receiver setup. In experiments comparing different approaches, the cu-age method outperforms others with over 95% accuracy. The average message entropy convergence speed is lowest in the co-evolution setup. All populations converge to a solution in the game, as shown in FIG2. The cu-best setup achieves the lowest entropy score in cultural evolution setups. Co-evolution results in lower convergence time and more alignment among agents. Jaccard Similarity and Average Proportion of Unique Matches are compared to show differences between cultural evolution and co-evolution. The level of structure of emerged languages is assessed. The co-evolution condition outperforms cultural only conditions in language emergence, with a simpler language that is structurally more similar to the input. The best sender architecture remains unchanged, while the receiver undergoes evolution steps. The receiver architecture evolves into a more complex form, unifying language throughout evolution. The population of senders starts with 11 unique messages but converges to only two. Experiments test the suitability of evolved languages and agents by monitoring accuracy and assessing if cultural and genetic evolution made languages easier to learn. The study compares the accuracy development of different cultural evolution modes and co-evolution methods. It includes experiments with LSTM and evolved receivers trained with frozen senders. Baselines are also compared, including receiver agents trained from scratch with different architectures. The study compares the accuracy development of different cultural evolution modes and co-evolution methods, including experiments with LSTM and evolved receivers trained with frozen senders. Results show that cultural evolution contributes to the learnability and suitability of emerging languages, with the cu-best accuracy converging quicker and higher than the cu-baseline-pretrained accuracy. The study shows that cultural evolution plays a crucial role in language learnability and accuracy development. Results indicate that the best sender's architecture leads to easier language learning in the cu-best setup. Additionally, genetic evolution benefits agents, with the co-evolution setup achieving the best accuracies. The difference between cu-baseline and co-baseline shows that evolved architectures perform much better than baseline models. However, genetic evolution alone is not sufficient, as shown by the comparison between co-baseline-pretrained and co-evolution setups. In this paper, a language transmission bottleneck is introduced in a referential game where new agents learn language by playing with experienced agents. Cultural and genetic evolution are enabled using a Language Transmission Engine to improve communication efficiency and linguistic structure. Genetic evolution proves to be crucial as agents perform best when paired with evolved languages and agents. In future research, the Language Transmission Engine will be applied to more complex tasks to enhance understanding of emerged languages and architectures. Other neuro-evolution techniques will also be explored on different search spaces."
}