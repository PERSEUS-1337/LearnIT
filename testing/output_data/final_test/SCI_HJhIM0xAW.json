{
    "title": "HJhIM0xAW",
    "content": "Retinal prostheses aim to stimulate retinal neurons to send artificial visual signals to the brain. A method is proposed to compute a meaningful distance between desired and achievable neural responses using recorded light responses of retinal ganglion cells. This metric accurately reflects the similarity of visual input in electrical stimulation experiments. The development of electronic devices to replace damaged neural circuits, such as retinal prostheses, has been a focus of neuroscience research. A key aspect is building encoding models to predict the spiking activity of retinal ganglion cells in response to visual input, which can improve prosthesis performance. The development of retinal prostheses relies on encoding models to predict retinal ganglion cell activity in response to visual input. However, current stimulation systems have limitations in creating specific neural activity patterns, restricting the range of achievable spike patterns. The goal of a prosthetics device is to select an optimal electrical stimulation pattern that matches the desired spike pattern, which may not always be feasible with current stimulation systems. Previous studies have focused on minimizing the number of unmatched spikes, but this approach is not necessarily optimal. The goal is to define a distance measure to identify the nearest feasible electrical stimulation pattern for retinal ganglion cells. The study proposes a neural response metric learned from firing patterns in neural populations to select optimal electrical stimulation patterns for a prosthetic device, aiming to match the desired spike pattern. The study introduces a neural response metric learned from RGC populations in non-human primate retina to select optimal electrical stimulation patterns for a prosthetic device. The metric captures the similarity between spike patterns and visual images, providing a meaningful representation of neural responses. The algorithmic framework for learning similarity measures in neural response space is described, using notations and conventions throughout the paper. The text discusses the representation of visual stimuli as matrices and the responses of cells as vectors. It introduces the concept of spike trains from neurons in response to dynamic stimuli and the binarized representation of population responses. The triplet-loss method aims to ensure that the anchor is closer to the positive response than the negative response with a margin. This approach has been widely used in various domains, including computer vision for tasks like face recognition and image retrieval. The focus is on improving metric learning by identifying negatives that can enhance the quality of the metric. Our method efficiently utilizes negatives in a batch and uses a simplified, softmax-based loss function to learn a function capturing invariances in spiking responses to repeated stimuli. The scoring function is seen as a similarity function or pseudometric, denoted by d(\u00b7, \u00b7), which needs to satisfy certain conditions. Experiments involve presenting repeats of the same visual stimuli to collect responses for analysis. The goal is to learn a metric that makes responses to the same stimulus closer than responses to different stimuli. Data is sliced into triplets of responses, with positive pairs being responses to the same stimulus and negative pairs to different stimuli. Sampling a common set of negatives for positive examples is a simpler strategy than mining hard negatives. The learning task involves sampling positive pairs of responses to the same stimulus and a common set of negative responses to different stimuli in batches of triplets. The goal is to find a pseudometric that ensures responses to the same stimulus are closer than responses to different stimuli. The learning task is formulated as empirical risk minimization with a surrogate loss function. In similarity learning, two parametric forms for distance and similarity functions were implemented. Parameters are learned by minimizing loss using Adagrad. A is projected onto positive semi-definite matrices space using singular value decomposition. The quadratic metric is not feasible for a real prosthetic device due to the lack of visually-evoked spiking activity data in a retinal prosthetic. The retina does not respond to light, limiting the quadratic model's ability to capture nonlinear visual processing. To address this, a nonlinear embedding based on a convolutional neural network (CNN) is introduced. This approach encodes cell spiking responses in an embedding space grouped by cell type and location, allowing for a generalized response metric for blind retinas. The response metric for blind retinas can be generalized without visually-evoked spiking activity. A hierarchical, convolutional network topology is used with 595K parameters across 7 layers to predict activity in unobserved retinas. The convolutional network employs batch normalization to accelerate training and learns a similarity and metric for responses. The convolutional network learns similarity and metric for responses by minimizing loss using Adam. Spiking responses from retinal ganglion cells were recorded using a 512 electrode array system. Different RGC types were identified with visual stimulation. Spike trains were discretized at 120 Hz frame rate for analysis. Multiple learned metrics are assessed for quality with respect to a baseline. The quality of learned metrics and embeddings is evaluated in a real electrical stimulation experiment using responses from retinal ganglion cells. The effectiveness of the metric is measured by determining if firing patterns are from the same visual stimulus. The analysis focuses on responses of OFF and ON parasol cells to a white noise stimulus clip, partitioned into training and testing sets. Various embedding models and baselines are assessed for their performance. In a real electrical stimulation experiment, learned embedding models are evaluated using retinal ganglion cell responses. The analysis compares firing patterns from the same visual stimulus at different time points. True positives occur when a metric correctly classifies a repeated stimulus, while false positives happen when a metric incorrectly identifies a random firing pattern as the same stimulus. The trade-off between false positives is illustrated in FIG3. The analysis in FIG3 shows the trade-off between false positive and true positive rates across different embedding models for neural population activity. More advanced models exhibit curves bending towards the upper-left, indicating better performance. A simple baseline model using Hamming distance performs the least accurately, while a quadratic metric with variable weights and interactions between neurons improves performance. Replacing the quadratic metric with a euclidean distance using a convolutional neural network further enhances performance. ROC analysis suggests that sophisticated embedding models capture global structure beyond a Hamming distance metric. The analysis in FIG3 demonstrates the performance of various learned methods for neural population activity, showing a trade-off between false positive and true positive rates. More advanced models outperform simpler ones, with a quadratic metric with variable weights and interactions between neurons showing improvement. Using a convolutional neural network with euclidean distance further enhances performance, capturing global structure beyond a Hamming distance metric. The evaluation includes precision and recall metrics for learned embeddings on a test dataset of visual stimuli. The results in FIG3 show that the convolutional metric outperforms quadratic and Hamming metrics in discriminating responses to different stimuli. Responses to the same visual stimulus cluster together in the embedding space, indicating the response metric's ability to distinguish stimuli. The learned response metric provides additional discriminative stimulus information beyond just identifying pairs of responses from the same stimulus. Further quantitative analysis will assess how well the response metric captures stimulus information. The study aims to measure how well the response metric captures stimulus information through stimulus reconstruction. Linear reconstruction is focused on due to its clear objective and information-rich results, although it may not capture nonlinearities. Subsequent analysis will explore quadratic and Hamming metrics, leaving nonlinear embedding for future research. Technical challenges in metric space analysis are noted. The study focuses on linear reconstruction of stimulus information from RGC responses to white noise sequences. Training data was collected from 13 RGCs to analyze response patterns. The similarity between decoded and target stimuli was examined using a learned quadratic metric. The spatial profile of the linearly decoded target response is shown in FIG4. The study examines linear reconstruction of stimulus information from RGC responses to white noise sequences using a learned metric. Firing patterns are ranked based on this metric, showing increasing decoding errors as patterns move farther from the target response. Mean squared error between linearly decoded stimuli and normalized metric distance between responses are plotted, demonstrating a systematic increase in decoding error. The study explores linear reconstruction of stimulus information from RGC responses using a learned metric. Decoding errors increase as responses move farther from the target, with the quadratic metric and Hamming distance showing similar trends. The reconstruction is based on static population response patterns, removing the time dimension by using temporal filters. Response metrics could enhance retinal prostheses by selecting optimal electrical stimulation patterns based on experimental data. The study focused on calibrating RGC responses to electrical stimulation patterns using a learned quadratic metric. Stimulation patterns with only one active electrode were evaluated by decoding the stimulus from elicited responses. The probability of firing for each cell was approximated with a sigmoid function, and the effectiveness of each stimulation pattern was assessed by the expected distance from the target firing pattern. The study calibrated RGC responses to electrical stimulation patterns using a learned quadratic metric. Stimulation patterns were ranked based on their expected distance to the target firing pattern. Linearly decoded visual stimuli were closer to the target when the stimulation was chosen via the learned response metric compared to the Hamming distance. The learned metric outperforms the Hamming distance in choosing stimulation patterns for RGC responses, with lower mean squared error on 33% of target responses. However, the learned metric may need to be reassessed over time due to changing stimulation patterns. Further analysis compares the performance of the learned metric to the Hamming distance when choosing the kth best current pattern. The learned metric outperforms the Hamming distance in selecting stimulation patterns for RGC responses, achieving lower MSE than the Hamming distance for the nearest k \u2264 10 stimulation patterns. This has implications for visual neuroscience by identifying similar symbols in the neural code of the retina and for retinal prosthesis technology to effectively transmit visual information. The present approach aims to develop a metric for visual stimulus similarity, different from previous spike train metrics. It learns the relative importance of cell identity from population firing patterns, serving as a foundation for encoding algorithms in retinal prostheses. The metric is learned using light evoked responses, with potential applications in blind estimation. The convolutional metric can be trained on healthy retinas and applied to blind retinas without light evoked responses. It shows promising results in generalizing to different cell populations and outperforms quadratic metrics. Additional techniques like recurrent neural networks may help extend the method to data with multiple cells and temporal responses. The convolutional metric, when trained on healthy retinas, can be applied to blind retinas without light evoked responses, showing promising results in generalizing to different cell populations and outperforming quadratic metrics. Techniques like recurrent neural networks may help extend the method to data with multiple cells and temporal responses. Responses can help compute distances between spiking patterns of unequal length, and boosting BID13 can combine efficiently learned metrics for spatially localized groups of cells. Triplet mining techniques and novel metrics with additional structure in population responses, such as noise correlation structure in RGCs, could also be explored for improved efficiency. The convolutional metric outperforms the quadratic metric at both global and local scales in terms of stimulating retinal prostheses. Current technology can only resolve information up to a certain scale, making capturing global structure crucial. The nearest feasible firing pattern achievable through electrical stimulation is at the 10th percentile of all possible firing patterns. This benchmark provides a valuable measure of performance. The network utilizes knowledge of receptive field locations and firing rates of individual cells to measure prosthesis performance. It embeds neuron responses into pathways grouped by cell type, focusing on ON and OFF parasols. Inputting spiking activity, the network uses convolutional layers to process the data. The network processes neuron responses through convolutional layers, shrinking spatial size while increasing filter channels. The final embedding vector represents the flattened last layer. RGC population responses are represented as vectors. Cells are mapped to grid locations, and RF estimates are obtained through convolution. Total activation for a cell is calculated by adding same-type cell activations. The network processes neuron responses through convolutional layers, combining information across multiple cell types. Activation maps for each cell type are calculated by adding same-type cell activations. Batch normalization and Adam optimizer are used for parameter updates. Linear decoding is used to reconstruct the stimulus from neural responses, showing comparable results to non-parametric decoding methods. The linear decoder shows similar spatial structure to the non-parametric decoder, with comparable mean-squared error. This suggests that the linear decoder is a reasonable approximation of the encoded stimulus. The relative mean-squared error between linear and non-parametric decoding is shown for different response patterns."
}