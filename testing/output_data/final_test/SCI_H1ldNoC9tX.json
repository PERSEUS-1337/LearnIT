{
    "title": "H1ldNoC9tX",
    "content": "Positive-unlabeled (PU) learning deals with learning a binary classifier from positive (P) and unlabeled (U) data, especially when negative (N) data labeling is challenging. This paper introduces a classification framework that incorporates biased negative (bN) data in PU learning, differentiating it from standard semi-supervised learning. An empirical risk minimization-based method is proposed to address this PUbN classification problem, resembling traditional example-reweighting algorithms but with weights computed using PU learning principles. An estimation error bound for the method is also derived. In PU learning, a method is proposed with an estimation error bound. The algorithm is effective in both PUbN and ordinary PU learning scenarios. PU learning is valuable in real-world problems like remote sensing and text classification. In this paper, the focus is on learning from P, U, and biased N (bN) data, termed PUbN learning. The challenge lies in collecting a fully representative N set, while labeling a small portion of N data is easier. The proposed approach extends PU learning to include a set of bN samples with a distribution different from the true N distribution. The paper discusses learning from P, U, and biased N (bN) data, known as PUbN learning. It extends PU learning to include bN samples with a different distribution from the true N distribution. Previous attempts at similar problems in text classification are mentioned, with different strategies used to handle bN data. Our work extends PU learning to include biased N (bN) data, training the classifier on P, U, and bN data simultaneously without domain-specific knowledge. We propose an algorithm combining PU learning and importance weighting to solve the PUbN classification problem, estimating the probability of an example being in P or bN set to assign instance-dependent weights to U data. The paper introduces a method for PUbN learning, extending PU learning by incorporating biased N (bN) data with instance-dependent weights. The method improves classification performance by effectively utilizing bN data during training, outperforming traditional PU learning. Additionally, the algorithm can be easily adapted to ordinary PU learning, achieving state-of-the-art results in various experiments. The algorithm presented in the paper improves classification performance by incorporating biased N data with instance-dependent weights, achieving state-of-the-art results in PU learning tasks. The approach differs from semi-supervised learning as it focuses on deducing a risk estimator using P, N, and U data, with potential benefits from adding regularization. Additionally, PUbN learning can be seen as a special case of dataset shift. The problem of PUbN learning is distinct from covariate shift, where reweighting training examples based on test density ratios may not be sufficient due to potential zero-labeled examples. It is important to note that neither PUbN learning nor covariate shift is a special case of the other. In this section, the formulations of PN, PU, and PNU classification are briefly reviewed, along with the problem of learning from P, U, and bN data. The goal of binary classification is to minimize the classification risk by finding a decision function g that minimizes the loss function \u2113. The zero-one loss is often substituted with surrogate losses like the sigmoid or logistic loss for ease of optimization. In standard supervised learning scenarios, the goal is to minimize the classification risk by finding a decision function that minimizes the loss function. Different loss functions like sigmoid or logistic loss are used for optimization. In PU classification, algorithms like S-EM are used to identify reliable data and build the final classifier. In PU classification, the biased support vector machine (Biased SVM) and unbiased risk estimator methods have been used to address the problem of overfitting in training data. The unbiased risk estimator aims to approximate the classification risk by minimizing the empirical risk. However, it was noted that overly flexible models can lead to negative risk values, indicating overfitting. To mitigate this issue, authors suggested minimizing the risk to prevent overfitting. The authors proposed a non-negative risk estimator for PU learning to address overfitting in the training data. Stochastic optimization was used, and gradient ascent was performed when the risk became negative for a mini-batch. In semi-supervised learning, the PNU risk estimator from BID35 leverages U data for risk estimation by combining PN and PU/NU risks. The PNU risk estimator is expressed as a linear combination of PN and PU risks for some \u03b3 \u2208 [0, 1]. The paper introduces the non-negative PNU (nnPNU) learning algorithm for PUbN learning, incorporating a latent random variable s into the joint distribution. The goal is to minimize classification risk by collecting a set of bN samples instead of ordinary N data. The algorithm aims to address the issue of labeled N data not fully representing the underlying N distribution. The proposed risk estimator for PUbN classification aims to minimize classification risk by using a special case of PU learning when no bN data are available. The method focuses on decomposing R \u2212 s=\u22121 (g) into three terms, approximated using data from X U , X P and X bN, with the choice of h and \u03b7 being crucial in capturing each term effectively. The decomposition of the risk estimator for PUbN classification involves approximating three terms using data from X U, X P, and X bN. The choice of h and \u03b7 is important in effectively capturing each term. \u03b7 acts as a hyperparameter controlling the importance of U data against P and bN data in evaluating R \u2212 s=\u22121 (g). The risk estimator for PUbN classification involves approximating terms using data from X U, X P, and X bN. The choice of h and \u03b7 is crucial in capturing each term effectively. Introducing \u03b7 helps avoid classifying all U data as N samples, improving classifier performance. The estimation error can be reduced by using labeled samples when U set is small. Substituting \u03c3 with its estimate and h with the same estimate yields an expression that depends on \u03b7 and \u03c3. The empirical version can be derived from data. The empirical version of Equation FORMULA14 is derived from data, allowing for the estimation of \u03c3 by training a probabilistic classifier to separate classes with s = +1 and s = \u22121. nnPU learning is applied with X P, X bN, and X U to minimize risk with respect to logistic loss and obtain \u03c3(x) using the sigmoid function. Other methods, such as least-squares fitting, can also be used for computing \u03c3. The approach proposed in BID18 for direct density ratio estimation can be adapted to solve the problem by establishing an estimation error bound for the method. The Rademacher complexity of the function class G for samples drawn from q(x) is defined, assuming it vanishes asymptotically as n \u2192 \u221e. Proper regularization ensures this for common choices of G. Additionally, assuming Lipschitz continuity for the function \u2113, the true risk minimizer and empirical risk minimizer are defined. The excess risk in the context of direct density ratio estimation involves estimation and approximation errors. The estimation error converges to zero under mild assumptions, with the excess risk decomposed into these two components. The value of \u03c3, estimated from data, depends on the algorithm and sample size used in the estimation process. In nnPU learning, the estimation error converges to zero with increasing sample size, but the approximation error remains fixed. To address this issue, one can use kernel-based methods with universal kernels or expand the function class with more samples in PU learning scenarios. The algorithm is naturally applicable to PU learning by ignoring terms related to bN data. PUbN\\N algorithm is a variant of the traditional two-step approach in PU learning, based on nnPU learning. It corrects bias by considering the posterior p(y = +1 | x) and uses an unbiased risk estimator for statistical consistency. The algorithm is more promising than others and experimentally investigated in this section. In this section, the proposed method is experimentally compared against baseline methods for training neural networks with stochastic optimization. Models are trained using AMSGrad BID33 optimizer and logistic loss. Hyperparameter tuning is done using a validation set composed of P, U, and bN data. The validation loss is computed using the PU risk estimator with the sigmoid loss for g. The proposed method is evaluated on three benchmark datasets: MNIST, CIFAR-10, and 20 Newsgroups, with experimental details in Appendix C. Two baseline methods are compared when X bN is given: nnPNU and PU\u2192PN. Sampling of bN data is done to train the classifiers. The proposed method, PUbN, compares favorably with nnPNU and PU\u2192PN in utilizing bN data to improve classification accuracy. Results show consistent performance gains across various scenarios, with PUbN reducing misclassification errors most of the time. The availability of bN data is shown to be beneficial for classification performance, with algorithm choice being crucial. The presence of bN data effectively helps in learning a better classifier, especially when considering specific cases like CIFAR-10 where labeling birds and frogs as negative data improves classification accuracy for mammals. This method, PUbN, outperforms other approaches in utilizing bN data for improved accuracy. The PUbN algorithm utilizes bN data to improve classification accuracy by separating high-level features in the learned representations. This two-step approach combines PU learning and importance weighting to train a binary classifier on P, U, and bN data. The proposed method combines PU learning and importance weighting to attribute appropriate weights to examples for evaluating classification risk using three sets of data. The approach leverages bN data to enhance classification performance on real-world datasets and achieves state-of-the-art results in PU learning. Equation (6) is obtained by replacing certain terms, and a lemma establishes a uniform deviation bound. The proof involves showing bounds for certain functions with probability at least 1 - \u03b4/3 using Rademacher variables and Lipschitz functions. Talagrad's concentration lemma is utilized to demonstrate the fixed set Xp. The text discusses minimizing the true risk R(g) by bounding the difference between R PUbN,\u03b7,\u03c3 (g) and R(g) using Rademacher variables and Lipschitz functions. The proof involves showing bounds for certain functions with probability at least 1 - \u03b4/3 and utilizing Talagrad's concentration lemma. The goal is to choose the model for \u03c3 to minimize the last term that does not depend on \u03c3. In the experiments, the model for \u03c3 is chosen to minimize the last term that does not depend on \u03c3. The validation loss of an estimation \u03c3 is defined, and \u03c3 is learned using nnPU for better comparison between methods. Multiclass classification datasets are used, with P and N classes defined for MNIST and CIFAR-10 datasets. In the experiments, the model for \u03c3 is chosen to minimize the last term that does not depend on \u03c3. The validation loss of an estimation \u03c3 is defined, and \u03c3 is learned using nnPU for better comparison between methods. Multiclass classification datasets are used, with P and N classes defined for MNIST and CIFAR-10 datasets. For the sake of diversity, another task is studied to distinguish mammals from non-mammals, with specific classes assigned to P and N. Different test set sizes are used for each dataset, along with varying training set sample sizes for P, N, and U examples. In experiments, datasets like CIFAR-10 and MNIST are used with varying training set sizes. Pre-trained ELMo word embeddings are borrowed for text classification. The ELMo model features are concatenated for each word and document, resulting in a 9216-dimensional vector. For MNIST, a standard ConvNet with ReLU is utilized. The model used for CIFAR-10 contains two 5x5 convolutional layers and one fully-connected layer, with max pooling after each convolutional layer. It is trained for 100 epochs with specific parameters selected using validation data. For 20 Newsgroups, a multilayer perceptron is trained with extracted features. For 20 Newsgroups, a multilayer perceptron with two hidden layers of 300 neurons is trained for 50 epochs using extracted features. The method designed for PUbN learning outperforms other baseline methods, achieving better performance than the nnPU algorithm. The proposed method is compared with unbiased PU (uPU) learning, showing significantly improved results. In experiments comparing PUbN learning with nnPU trained using logistic loss, PUbN still outperforms nnPU. The nnPU classifier's performance remains stable when using sigmoid loss instead of logistic loss. However, nnPU addresses the issue of overfitting observed in uPU by introducing a non-negative risk estimator. This correction prevents an increase in false negative rates but leads to more N samples being classified as P compared to uPU. The proposed algorithm nnPU achieves lower misclassification error compared to uPU by classifying more N samples as P. It aims to reduce false positive rates without misclassifying too many P samples as N. Experimental results show that on MNIST, nnPU achieves a similar false positive rate as uPU but a comparable false negative rate. The algorithm introduces \u03b7 to control the approximation of howR s=\u22121 (g) is from data, assuming \u03c1 = p(y = \u22121, s = +1) is given. Experiments are conducted to assess the influence of \u03b7 and \u03c4 on four learning tasks. The algorithm's performance is sensitive to the choice of \u03c4, with larger values leading to higher false negative rates and lower false positive rates. The trade-off between these measures is a classic problem in binary classification. When \u03c4 = 2, more U samples are involved in the computation of the risk, but this does not necessarily improve classifier performance. The algorithm's performance is sensitive to the choice of \u03c4, with larger values leading to higher false negative rates and lower false positive rates. There is a positive correlation between misclassification rate and validation loss, indicating that the optimal value of \u03b7 can be chosen without unbiased N data. Slight misspecification of \u03c1 does not significantly degrade classification performance. Misspecification of \u03c1 mainly affects the weights of each sample in computing R PUbN,\u03b7,\u03c3. Theorem 2 suggests that \u03c3 should be independent from the data used to compute R PUbN,\u03b7,\u03c3. The algorithm's performance is influenced by the choice of parameters \u03c3 and g, optimized using different sets of data. Results show that estimating \u03c3 from separate data does not significantly improve classification performance, even though it requires collecting more samples. The function \u03c3 should be smooth and not have abrupt changes between data points for accurate approximation. The nnPNU algorithm is defined in subsection 2.3, focusing on positive estimation of the N partial risk. An alternative version is proposed in which only a specific term is forced to be positive, leading to improved classification performance. This alternative version is tested in experiments in subsection 4.2, with results summarized in TAB4. The alternative version of nnPNU, denoted as nnPU+PN in TAB4, does not consistently outperform the original nnPNU. However, the proposed PUbN algorithm consistently shows superiority over nnPNU, regardless of its variant."
}