{
    "title": "S1eN99RioX",
    "content": "We study cross-lingual voice conversion in non-parallel speech corpora using a one-shot learning approach. By learning disentangled speaker-specific and context-specific representations with a Factorized Hierarchical Variational Autoencoder (FHVAE), we can convert an arbitrary source speaker's sentence to a target speaker's voice with just one target speaker training utterance. This universal model, trained on multi-language speech corpus, utilizes a one-hot language embedding for conditioning. The study explores cross-lingual voice conversion using a one-shot learning approach with a Factorized Hierarchical Variational Autoencoder (FHVAE). The model utilizes a one-hot language embedding for conditioning and achieves reasonable performance with even just one training utterance. The effectiveness of language conditioning, visualization of language and sex embeddings, and subjective test results are also discussed. The study investigates cross-lingual voice conversion using a Factorized Hierarchical Variational Autoencoder (FHVAE). The model utilizes language conditioning and shows clear separation between female and male embeddings. Speaker embeddings for different languages and genders are closer in VAE-CND compared to VAE-UNC. Phonetic context embedding Z1 is analyzed for English sentences, and perceptual tests are conducted to evaluate voice conversion performance. To evaluate voice conversion performance, two perceptual tests were conducted. The speaker similarity of converted utterances was assessed using a same-different speaker test where listeners indicated if two stimuli were spoken by the same or different speakers."
}