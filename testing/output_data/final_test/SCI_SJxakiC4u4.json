{
    "title": "SJxakiC4u4",
    "content": "The Unsupervised Continual Learning (UCL) problem involves learning salient representations from a changing stream of unlabeled data with varying object classes. A proposed solution is the Self-Taught Associative Memory (STAM) architecture, inspired by the mammalian brain, which uses Hebbian learning, online clustering, pattern detection, and top-down predictions. STAMs show promise in learning handwritten digits with minimal labeled examples per class, addressing the UCL problem without catastrophic forgetting. The Unsupervised Continual Learning (UCL) problem involves learning from a stream of unlabeled data with varying object classes. UCL is motivated by recent advances in Continual Learning (CL) but is completely unsupervised. The data stream includes instances of previously learned classes and occasionally new classes. Many CL methods involve \"replay\" of known classes, which is equivalent to observing instances of known classes. To evaluate if an architecture can solve the UCL problem, the time axis is partitioned into distinct learning phases. The UCL problem involves partitioning the time axis into distinct learning phases with unlabeled examples from a constant set of classes. Evaluation is done at the end of each phase with a simple classification task using a limited number of labeled instances per class. This approach differs from Semi-Supervised Learning methods as it only requires labeled data for evaluation, not during the learning phase. A neuro-inspired solution has been developed to address the UCL problem. The UCL problem is addressed using a neuro-inspired architecture called Self-Taught Associative Memory (STAM), which is a layered hierarchy of modules learning salient features through online clustering. Each feature is a cluster centroid, and the architecture involves forward, feedback, and lateral connections. The Self-Taught Associative Memory (STAM) architecture reconstructs output images based on centroids for each receptive field, with feedback connections controlling new centroid creation. STAMs learn online through novelty detection, forgetting outlier patterns, and top-down predictions. They are similar to Convolutional Neural Networks (CNNs) but learn in a Hebbian manner without task-specific optimization. STAM features are interpretable common patterns at different spatial resolutions, adapting to data distribution non-stationarities. The STAM architecture differs from previous clustering schemes by relying on online clustering, novelty detection, limited memory, and intrinsic dimensionality reduction. It consists of L layers with STAM modules processing receptive fields of input images. The RF size increases along the hierarchy. The STAM architecture consists of L layers with STAM modules processing receptive fields of input images. The RF size gradually increases along the hierarchy. Each STAM module selects the nearest centroid to its input based on Euclidean distance. The output of each layer is constructed by replacing the input RF with the corresponding centroid and averaging overlapping segments, resulting in a lower intrinsic dimensionality. The STAM architecture has L layers with modules processing receptive fields of input images. Centroids are updated in an online manner using a learning rate parameter \u03b1. Centroids are dynamically created based on a novelty detection algorithm, estimating mean distance \u00b5 and standard difference \u03c3 for each centroid. Inputs are flagged as \"novel\" based on their distance from the nearest centroid. The STAM architecture has L layers with modules processing receptive fields of input images. Centroids are updated in an online manner using a learning rate parameter \u03b1. Inputs are flagged as \"novel\" if their distance from the nearest centroid is significantly larger than the centroid's mean distance \u00b5 estimate. A new centroid is created when an input is flagged as novel, with a fixed number of centroids learned at each layer. If the input is flagged as novel but does not pass the \"novelty\" criterion, top-down connections are leveraged to differentiate between outliers and true novelties. The STAM architecture has L layers with modules processing receptive fields of input images. Centroids are updated in an online manner using a learning rate parameter \u03b1. Inputs flagged as novel at layer i do not create a new centroid if they do not pass the \"novelty\" criterion. A simple classifier can be used to evaluate the representations learned by the architecture, associating each output-layer centroid with a class based on allegiance to labeled input vectors. Centroids with weak allegiance to any class are removed. The STAM architecture updates centroids online using a learning rate parameter. Weak allegiance centroids are removed if their maximum allegiance is less than 70%. Input classification is based on distance to centroids and allegiance to classes. Learning phases include new classes from the MNIST dataset, with access to old and new unlabeled examples. Limited labeled data is introduced per class to evaluate classification accuracy. The study introduces a Convolutional AutoEncoder (CAE) and STAM architecture for classification tasks. The CAE is trained unsupervised on the MNIST dataset and used to create classifiers based on latent representations. Different classifiers, including nearest-neighbor and EQ8, are applied to the CAE latent representations. The STAM architecture is also utilized with online centroid updates and learning phases for new classes. Limited labeled data is used to evaluate classification accuracy. The STAM architecture is compared to CAE in two experiments on the MNIST dataset. The first experiment shows STAM has less catastrophic forgetting when reducing unlabeled data. The second experiment demonstrates that both STAM and CAE benefit from increasing the number of labeled examples per class. STAM and CAE both benefit from more labeled examples per class, but STAM can perform well with fewer labeled examples compared to CAE."
}