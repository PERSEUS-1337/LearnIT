{
    "title": "Hye00pVtPS",
    "content": "A patient's health information is often fragmented across different sources, making data centralization for analysis challenging due to privacy concerns and regulatory barriers. Federated learning allows machine learning on patient datasets from different care sites, but struggles with vertically separated data types across organizations. To address this, \"confederated machine learning\" enables model training on data separated by multiple degrees. Access to high-quality healthcare data is crucial for success in advancing medicine with machine learning. Valuable data is often distributed across isolated silos, creating operational and regulatory challenges. We use confederated learning to stratify elderly patients by their risk of falls using diagnoses, medication claims, and clinical lab test records. This approach addresses the issue of horizontally and vertically separated patient data. Federated learning involves distributed learning on horizontally separated data, where algorithms are sent to different data silos for training and models are aggregated for inference. This approach reduces data duplication and costs associated with data transfer, while increasing security and institutional autonomy. Machine learning on vertically separated data involves using split neurons to analyze different data types such as diagnostic, pharmacy, laboratory, and social services. To accelerate a scalable and collaborative rapid learning health system, a confederated machine learning method is proposed. This method trains machine learning models on data both horizontally and vertically separated by jointly learning a high-level representation from data distributed across silos. It does not require frequent information communication or state-of-the-art computational resources, making it practical for healthcare systems with limited resources. The proposed confederated machine learning method trains models on horizontally and vertically separated data silos without the need for frequent information exchange or advanced computing infrastructure. This approach is demonstrated by developing a model for accidental falls among individuals aged 65 and older, with significant incident rates and direct medical costs associated with falls in the US. The study focuses on using a confederated learning model to predict the risk of falls in elderly patients based on diagnosis data, medication claims, and clinical lab test records. This approach aims to compare centralized learning and traditional federated learning methods, specifically addressing horizontal and vertical data separation. The study uses claims data from a U.S. health plan to predict fall risk in elderly patients. Only beneficiaries over 65 with full medical and pharmacy coverage for 36 months were included. The study period is divided into observational, gap, and follow-up periods. Medicare Advantage program enrollees and individuals with fall-related diagnoses were excluded from the analysis. The predictive model uses claims data from a 12-month observation period to measure outcomes indicative of falls in a cohort of 119,335 beneficiaries. Input features include age, gender, diagnoses, medications, and lab tests. 8.9% of beneficiaries had at least one fall during the testing period. The Centers for Medicare and Medicaid used ICD-9 and ICD-10 codes to identify accidental falls. A total of 84 ICD-9 and 330 ICD-10 codes were used. Each individual in a specific state had diagnosis, medication, and lab test vectors, along with a binary fall label. Confederated learning involves a universal machine learning model designed for all data sites, with input features like claims for diagnoses, medications, and lab tests. The model outputs a binary variable indicating if a beneficiary had a fall during the follow-up period. Data for beneficiaries is separated by U.S. state of residence to simulate horizontal and vertical separation. In a distributed model training approach, simulated data is distributed across 102 nodes including clinic, pharmacy, and lab nodes. Each site receives binary target labels for falls during a 2-year follow-up period. A neural network model is designed with separate branches for medication and lab test data, merging into a high-level representation layer. The second hidden layer serves as a representation learning and integration layer, while the third layer acts as a classifier. The neural network model parameters are randomly initialized. The federated learning model is trained on 102 nodes with identical structures and parameters. Data availability indicators are used to activate specific data type components during training. The data availability indicators are used to activate specific data type components during training. Trained parameters are aggregated from all sites to update the model, allowing for joint learning from different data types and individuals. The updated model is then distributed to all 102 sites for global training. The approach involves jointly training a representation using different data types from various sources in a distributed manner without moving the original data. The goal is to minimize binary cross entropy for classification models without transferring data out of beneficiaries' residency or data silos. The objective function for the classification model is described, and parameters are randomly initialized and sent to pharmacies or labs for training. The model parameters are initialized as \u0398 0 and sent to pharmacies or labs in each state. The loss function is calculated using stochastic gradient descent to obtain parameters for diagnoses in clinics, pharmacies, and labs. Parameters are trained locally in each state and sent back. The model parameters are initialized as \u0398 0 and sent to pharmacies or labs in each state. Parameters are trained locally in each state using SGD and then sent back for aggregation by weighted averaging. Zero vectors are used as data type placeholders. Artificial neural networks in Keras are used for predicting fallst. The model in Keras 2.0 with tensorflow 1.7 backend uses Adam optimizer. It has three branches, each for a data type, with hidden layers of 256 neurons. Branches merge and connect to a hidden layer with 128 neurons before the output layer. ReLu is used for hidden layers and Sigmoid for the output layer. In confederated learning, 10 epochs are trained locally, stopping global cycles if no improvement for 3 cycles. Architecture and hyperparameters were determined by grid searching. Parameters for medication branch were frozen during training on clinical lab data. The model parameters for medication branch were frozen during training on clinical lab data. 20% of beneficiaries were reserved as test data, 20% as validation set, and 60% as training set. Data from each node were used for validation in federated learning. After hyperparameter tuning, both training and validation sets were used to train the model. Outputs from ensemble learning models were averaged for combined prediction. Performance evaluation included AUCROC and AUCPR due to imbalanced data. The study utilized a threshold based on the 5% quantile of predicted scores for true falls, favoring a screening strategy with tolerance for false positives. Performance metrics included PPV, NPV, AUCROC, and AUCPR. Machine learning interpretation was done using the DeepExplain package in Python. Experiments compared predictive models trained in centralized, federated, and model-separated settings. The study compared predictive models trained in centralized, federated, and model-separated settings. Performance metrics included PPV, NPV, AUCROC, and AUCPR. When training on aggregated data, the model achieved AUCROC of 0.70, AUCPR 0.21, PPV of 0.29, and NPV of 0.90. Confederated learning achieved comparable performance to centralized and federated learning in predicting falls, using vertically separated data with two degrees of separation. Ensemble learning improved performances in confederated representation with vertical and horizontal separation. Feature importance analysis revealed common variables in centralized and confederated models. Clinical screening process for falls involves questioning patients about previous falls and balance. A machine learning approach can stratify individuals by risk of fall using electronic health record data, without the need for costly and time-consuming clinical assessments. This confederated learning algorithm can train models on distributed health data without moving or aggregating it, making it a more efficient method compared to other approaches. The confederated learning approach can be extended to more degrees of separation, such as temporality, insurance plan, and healthcare provider. An example includes distributing a patient's diagnosis among different healthcare providers or pharmacies. The algorithm trains models on distributed health data without moving or aggregating it. In clinic node: Figure 4 shows two degrees of separation in data fragmentation across silos. Patient data is divided into three periods for predictive analysis of falls in follow-up period."
}