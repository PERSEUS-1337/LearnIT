{
    "title": "HJxJ2h4tPr",
    "content": "Generative deep learning has led to new Super-Resolution algorithms like Multi-frame Super-Resolution (MFSR) for satellite monitoring. HighRes-net is the first deep learning approach to MFSR, learning co-registration, fusion, up-sampling, and registration-at-the-loss tasks in an end-to-end fashion. It implicitly learns co-registration through a reference-frame channel and introduces a registered loss by aligning the SR output. Our approach utilizes ShiftNet to align the SR output to ground-truth, enhancing Earth observation data by super-resolving low-resolution signals. It won the European Space Agency's MFSR competition on satellite imagery. Multiple low-resolution images collectively contain more information due to shifts, rotations, and noise, making Multi-Frame Super-Resolution (MFSR) valuable for reconstructing high-resolution details. Single Image Super-Resolution (SISR) has gained attention in the last 5 years, with neural networks learning complex image priors. This paper introduces a deep-learning approach for Multi-Frame Super-Resolution (MFSR) to address challenges like co-registration and fusion of low-resolution images. It aims to leverage recent advances in neural network representations for MFSR, which is crucial for Earth observation data analysis and monitoring. The paper introduces a deep-learning approach for Multi-Frame Super-Resolution (MFSR) to address challenges like co-registration and fusion of low-resolution images. This is crucial for Earth observation data analysis and monitoring, as well as for informing policy and achieving accountability in human rights violations. The paper introduces a deep-learning approach for Multi-Frame Super-Resolution (MFSR) to address challenges like co-registration and fusion of low-resolution images. The proposed HighRes-net architecture learns to fuse multiple low-resolution frames with implicit co-registration, while ShiftNet aligns the super-resolved output for more accurate feedback. This technology is crucial for Earth observation data analysis, monitoring, and accountability in human rights violations. The paper introduces a deep-learning approach for Multi-Frame Super-Resolution (MFSR) to address challenges like co-registration and fusion of low-resolution images. The proposed architecture combines HighRes-net for fusion and ShiftNet for registration, enabling end-to-end learning. The approach outperformed baselines on real-world imagery from the PROBA-V satellite, winning the Kelvins competition on MFSR organized by ESA. ShiftNet is a differentiable registration component used for registered loss mechanism in end-to-end training. The text discusses the resolution of digital samples of natural phenomena based on Nyquist and Shannon's theories, illustrating aliasing conditions in sampling. The text discusses aliasing in sampling when the sampling rate falls below the Nyquist rate, leading to loss of frequency information. Shannon's sampling theory has been generalized for multiple interleaved sampling frames to go beyond the Nyquist limit. When an image is down-sampled to a lower resolution, high-frequency details are lost permanently. However, combining multiple low-resolution images allows for recovering the original scene at a higher resolution. The challenge in Multi-Frame Super-Resolution (MFSR) is de-aliasing high-frequency components from different low-resolution samples. Initial work on MFSR involved reconstructing a high-resolution image by fusing co-registered low-resolution images in the Fourier domain. Proper registration and fusion techniques are essential for successful MFSR. HighRes-Net is introduced as an end-to-end deep learning framework for Multi-Frame Super-Resolution (MFSR) settings, aiming to reveal high-frequency details in composite super-resolved images. Unlike Video and Stereo Super-Resolution methods, HighResnet focuses on super-resolving sets of low-res views instead of sequences, predicting a single image from an unordered set of inputs. In this work, the focus is on Multi-Frame Super-Resolution (MFSR) without assuming ordered low-res inputs. The goal is to reconstruct a single high-resolution image from multiple low-resolution views with unknown timestamps, addressing challenges like noise, blur, and geometric distortions. Unlike traditional methods, this approach does not require prior knowledge of motion models, blur kernels, or degradation processes. Optimization methods aim to enhance low-resolution images by minimizing errors between simulated and observed images. LR encodings are fused into a global representation, which is then upsampled to generate a superresolved image. ShiftNet learns to estimate shifts for improved reconstruction. Lanczos resampling is used for translation, along with additive noise and prior knowledge of natural images. In the context of enhancing low-resolution images, optimization methods utilize additive noise and prior knowledge to constrain parameter search space. Nonparametric strategies like patch-based methods and sparse coding are developed for high-resolution image reconstruction. This work focuses on super-resolving satellite imagery. In the context of enhancing low-resolution images, optimization methods utilize additive noise and prior knowledge to constrain parameter search space. This work focuses on super-resolving satellite imagery, with recent advancements in Super-Resolution including SISR for natural images and MFSR settings addressed in deep-learning frameworks. Various approaches such as sparse coding, recursion, and network design have been proposed for SISR and image deblurring. Benchmarking methods differ in upscaling techniques, network design, and learning strategies. Kawulok et al. (2019) introduced a shift-and-add method for super-resolution. HighRes-net is a neural network for multi-frame super-resolution in greyscale images, utilizing joint co-registration and fusion of low-resolution views. It consists of an encoder-decoder architecture and can be trained using high-resolution ground truth as supervision. HighRes-net is a neural network for multi-frame super-resolution in greyscale images, utilizing joint co-registration and fusion of low-resolution views. It consists of an encoder-decoder architecture and can be trained using high-resolution ground truth as supervision. The network involves encoding, fusion, and decoding steps to reconstruct high-resolution images from low-resolution views. The core assumption is that the collective low-resolution image set contains more information than any single low-resolution image alone. HighRes-net utilizes a shared representation for multiple low-resolution views to improve super-resolution performance. The reference image serves as an anchor for aligning and denoising views, enabling focus on high-frequency features. The embedding layer is shared across all views, enhancing the network's ability to reconstruct high-resolution images. HighRes-net computes embedded hidden states in parallel for low-resolution views, padding the imageset if needed. The hidden states are fused recursively, reducing the number of states at each fusion step. The fusion process aligns representations using shared and fusion blocks, enhancing super-resolution performance. HighRes-net aligns representations of low-resolution views using shared blocks and fusion layers to enhance super-resolution performance. The final encoded state contains information from all input views, reducing the number of parameters to learn. The architecture of HighRes-net includes conv2d and PreLU layers, with a focus on co-registering and fusing multiple low-resolution views into a single super-resolved image. ShiftNet-Lanczos is a neural network designed to address pixel and sub-pixel misalignments in super-resolution image generation when paired with HighRes-net. It helps HighRes-net learn to super-resolve by aligning images with sub-pixel translations, leading to improved results. ShiftNet predicts global translations for image pairs to achieve sub-pixel alignment. ShiftNet is a neural network adapted from HomographyNet, predicting 2 shift parameters for sub-pixel alignment of images. It is trained to work with HighRes-net for MFSR, using a Lanczos shift kernel for alignment. In image processing, filters like Lanczos are used for alignment to avoid artifacts. Lanczos filter performs best by reducing ringing and using a finite part of the sinc function. This is crucial for registration in super-resolution tasks. HighRes-Net and ShiftNet-Lanczos work together to improve image registration and super-resolution by aligning output with ground truth high-resolution images. ShiftNet predicts sub-pixel shifts to align images at a pixel level using Lanczos interpolation. This cooperative approach combines registration and super-resolution in an end-to-end learning framework. The joint training of ShiftNet and HighRes-Net aims to align images at a pixel level using Lanczos interpolation. The objective function includes a registered reconstruction loss and regularization of ShiftNet's output. The architecture is independent of the loss function choice. The PROBA-V satellite is equipped with separate cameras for image capture. The PROBA-V satellite dataset is the first publicly available dataset for MFSR with naturally occurring low-res and high-res pairs. Unlike most SR methods that use synthetic down-sampling, this dataset avoids biases induced by artificial down-sampling. The performance of the method is demonstrated using satellite imagery from the Proba-V Kelvin dataset. The Proba-V Kelvin dataset contains 1450 scenes with RED and NIR spectral bands from 74 Earth regions. Each scene has 1160 training and 290 testing images, with 100m resolution HR images and 300m resolution LR images. Each scene includes at least 9 low-res views with noisy quality maps indicating concealed pixels. The clearance scores are used to randomly sample from low-res views, with higher clearance views more likely to be selected to prevent overfitting. Quality maps can be used as binary masks to indicate noisy or occluded pixels in the low-res view, helping neural networks learn which parts are anomalous or missing. In satellite applications, segmentation methods are used to infer cloud masks when not available. For the PROBA-V dataset, masks are only used to inform the sampling scheme and prevent overfitting. The same hyperparameters were used across all experiments, with training taking less than 9 hours on a single NVIDIA V100 GPU. Superresolving an imageset of size 128x128 by a factor of 3 takes less than 0.2 seconds at test time. The best model, HighRes-Net trained with shiftNet-Lanczos, performed well in ESA's Kelvin competition. The best model, HighRes-Net trained jointly with shiftNet-Lanczos, consistently scored at the top of the leaderboard. Different baselines were discussed, including SRResNet and ACT baseline, with variations in training and testing methods. The curr_chunk discusses the Ensemble model of HighRes-net + shiftNet with K=16 and K=32 input views, using cPSNR as a quality metric. The cPSNR metric is normalized by the ESA baseline algorithm for comparison. The curr_chunk discusses the benefits of using sub-pixel registration as a training objective in the ShiftNet model for multi-frame super-resolution. An ablation study on labeled data shows that more low-resolution views improve reconstruction error up to 16 views. Registration is crucial for MFSR, and randomly sampling clear views can prevent overfitting. The PROBA-V satellite, launched by ESA, can benefit from MFSR for monitoring Earth's vegetation growth and water resources. Satellite imagery can enhance vision for scientific and monitoring applications, helping NGOs and non-profits monitor the environment and human rights. Low-resolution imagery is cost-effective and frequently updated, but adding fake details diminishes its value as evidence. Registration is important in both the loss and fusion stages, with potential for improvement through learning to sample reference frames and fuse multiple representations. Authenticity of details is crucial for credibility. HighRes-net is a deep learning approach for multi-frame superresolution, focusing on co-registration, fusion, up-sampling, and registration-at-the-loss. It aims to ensure authenticity of detail and quantify uncertainty in super-resolved images for real-world applications. Evaluation of super-resolved images and similarity metrics are key challenges in computer vision tasks. Fusion aligns low-resolution views through co-registration with the reference channel. ShiftNet-Lanczos registers and aligns super-resolved output with ground-truth. End-to-end cooperative setting improves training and test performance. Approach is fast to train, test, and low in memory-footprint. MFSR addresses the lack of detailed information in low-resolution satellite imagery. MFSR can enhance low-resolution satellite imagery for NGOs and non-profits supporting UN Sustainable Development Goals. Models trained on 64x64 patches with HighRes-net architecture. Used ADAM optimizer, trained on batches of 32 for 400 epochs. Learning rate decayed by 0.97 if validation loss plateaus. ShiftNet regularization with \u03bb = 0.000001. HighRes-net super-resolves scenes with 32 views in 5 steps, using less than 600K parameters. HighRes-net super-resolves scenes with 32 views in 5 steps, using less than 600K parameters. Doubling the number of frames improves training and validation scores. Registration at the loss stage enhances model performance. HighRes-net without ShiftNet-Lanczos shows a drop in performance. Registration aligns outputs with targets for sharper results. Implicit co-registration in HighRes-net improves super-resolution by pairing LR views with a reference frame, avoiding explicit computation of relative shifts. This strategy enhances model performance and sharpens output results. The choice of a reference frame impacts model performance, with the median reference being the most effective due to its robustness to outliers. Training and testing without a shared reference performed worse than the ESA baseline, highlighting the importance of co-registration. The ShiftNet architecture consists of 8 layers with the majority of parameters coming from the fc1 layer. Adding a MaxPool2d on top of specific layers further enhances the model's performance. ShiftNet's parameters are mostly from the fc1 layer. Adding MaxPool2d on certain layers reduces parameters. Permutation invariance is important for fusion models. Randomly shuffling inputs during training and sorting by clearance score can help. Sampling LR views with bias towards higher clearance scores is a good approach. The bias towards higher clearance scores in sampling LR views can be regulated by the score of LR i and \u03b2. A default model trained with \u03b2 = 50 showed that biasing towards higher clearances could be beneficial, as randomness prevents overfitting and diversity matters. \u03b2 = 50 performed better than \u03b2 = 0, suggesting that clouds also play a significant role."
}