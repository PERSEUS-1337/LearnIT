{
    "title": "SkxxIs0qY7",
    "content": "Cooperative Training (CoT) is proposed for training generative models that measure a tractable density for discrete data. CoT involves training a generator G and an auxiliary predictive mediator M to estimate a mixture density of the learned distribution G and the target distribution P. The goal is to minimize the Jensen-Shannon divergence estimated through M. CoT is a low-variance algorithm that does not require pre-training or high-variance algorithms like REINFORCE. It is theoretically proven to be superior for sample generation and likelihood prediction, outperforming previous algorithms in generative quality, diversity, predictive generalization ability, and computational cost. Generative models for discrete data, like natural language, are often optimized through Maximum Likelihood Estimation (MLE), leading to exposure bias. This bias arises because the model is trained on one distribution of inputs but tested on another, causing errors to accumulate. This discrepancy highlights the need for improved training methods in generative modeling tasks. Generative Adversarial Network (GAN) BID6 is an effective framework for training implicit density models for continuous data. GAN introduces a discriminator to distinguish generated samples from real ones, optimizing an estimated Jensen-Shannon divergence. GAN has shown promising results in unsupervised and semi-supervised learning tasks, leading to the development of adversarial networks. However, GAN is limited to modeling continuous variables and cannot generate discrete sequences like natural language. Cooperative Training (CoT) is a novel algorithm proposed to train likelihood-based generative models on discrete data. It aims to address the limitations of SeqGAN and its variants by directly optimizing the Jensen-Shannon divergence. Cooperative Training (CoT) is a novel algorithm that trains generative models on discrete data by optimizing the Jensen-Shannon divergence. It involves coordinating a generative module G and an auxiliary predictive module M, called mediator, to guide G cooperatively. The algorithm is derived directly from the definition of JSD and shows superior performance in generative ability, generalization, and computational efficiency compared to strong baselines in both synthetic and real-world scenarios. The training dataset or generated complete sequence depends on the context. Maximum likelihood estimation minimizes KL divergence between estimated and real distributions. MLE limitations include asymmetric KL divergence and suboptimal target distribution. The Jensen-Shannon divergence (JSD) is an ideal solution to optimize a symmetrized and smoothed version of KL divergence. However, directly optimizing JSD is considered an intractable problem due to the difficulty in evaluating and optimizing the equally interpolated distribution M. SeqGAN incorporates a generator and discriminator modules, trained alternately to optimize an adversarial target. The objectives of the generator and discriminator in SeqGAN are based on model-free reinforcement learning. SeqGAN, based on model-free reinforcement learning, struggles to converge well due to fake local optimals and vanishing gradient issues. Reshaping reward signals and using REINFORCE can alleviate some problems, but mode collapse still occurs, leading to a loss of diversity in generated samples. Cooperative Training (CoT) is proposed as a solution to optimize a well-estimated unbiased Jensen-Shannon Divergence (JSD) for sequential discrete data modeling. Unlike SeqGAN, which sacrifices diversity for generative quality, CoT aims to optimize JSD directly to address issues of distant data distributions and low-variance optimization. Cooperative Training (CoT) utilizes Algorithm 1 to optimize an unbiased Jensen-Shannon Divergence (JSD) for training models. Each iteration involves training a mediator M \u03c6 to estimate a mixture distribution of the generative distribution G \u03b8 and target latent distribution P = p data. The mediator is trained using Maximum Likelihood Estimation with balanced samples from training data and the generator, ensuring bias-free predictive purposes. The training techniques for optimizing Jensen-Shannon Divergence (JSD) involve training a mediator M \u03c6 to estimate a mixture distribution of generative distribution G \u03b8 and target latent distribution P = p data. The mediator is trained using Maximum Likelihood Estimation to ensure bias-free predictive purposes. The detailed derivations and recursive application of Lemma 2 for optimizing JSD can be found in the supplementary material. The gradient \u2207 \u03b8 J g (\u03b8) for training generator via Cooperative Training can be formulated as DISPLAYFORM7, ensuring practical effectiveness with finite discrete action space. The overlap of distributions G \u03b8 and M * is enlarged to minimize cross entropy, leading to successful training outcomes. The Cooperative Training objective is to minimize cross entropy between G and M * to increase distribution overlap and cover the action space. The optimization goal is to find the maximal entropy solution, with theoretical convergence guarantee. If the mediator M \u03c6 is optimal, training via Eq. (14) minimizes JSD(G P). Cooperative Training (CoT) aims to minimize JSD(P G \u03b8) by training the mediator to be optimal, leading to stability and theoretical guarantees. CoT is superior to methods like Scheduled Sampling and SeqGAN, as it ensures training convergence. Cooperative Training (CoT) guarantees training effectiveness and is computationally cheaper compared to methods like SeqGAN. It achieves unbiased unsupervised learning on sequential data without supervised approximation. The need to train a mediator instead of directly training a predictive model via MLE is explained by the efficient training objective. The efficient training objective requires obtaining the mixture density model M = 1 2 (P + G) and its decomposed form in each timestep. Directly estimating P and computing M = 1 2 (G + P) without the decomposed form renders M useless. The modelP may not work well on generated samples from G \u03b8, leading to instability in guiding the generator. Ablation study is provided in the appendix. In an ablation study, a synthetic Turing test is designed to evaluate the quality of samples from the generator using the negative log-likelihood NLL oracle from an oracle LSTM. The proposed algorithm shows state-of-the-art performance with the same network architecture, demonstrating little mode collapse. Computational efficiency is discussed, with CoT not achieving the best time cost per epoch compared to other methods. CoT is faster than previous RL-GAN approaches and has similar computational complexity as MLE. It shows hyperparameter robustness and less sensitivity to choices compared to SeqGAN. The study shows that CoT is faster than previous RL-GAN approaches and has similar computational complexity as MLE. It demonstrates hyperparameter robustness and less sensitivity to choices compared to SeqGAN. The balanced NLL can serve as a real-time training progress indicator for generative models. Zero-prior text generation is a good testbed for evaluating performance. In LeakGAN BID8, the EMNLP 2017 WMT News Section dataset is used with a maximal sentence length of 51. Two implementations of CoT are presented: CoT-basic and CoT-strong. Quality is evaluated using BLEU on a small batch of test data, while diversity is evaluated using Word Mover Distance. Results are shown in TAB4 and TAB5. Cooperative Training (CoT) achieves state-of-the-art performance in generative quality and diversity over all baselines with the same architecture-level capacity. CoT-strong, with a higher inverse temperature parameter, shows the best performance. CoT optimizes Jensen-Shannon Divergence, addressing the exposure bias problem in training models for sequential discrete data modeling tasks. Cooperative Training (CoT) demonstrates superior performance in generative quality and diversity compared to baseline models. CoT produces more diverse and meaningful samples than Leak-GAN and shows improved consistency compared to MLE. The optimal balance for CoT involves using the same learning rate and iteration numbers for the generator and mediator, with the mediator slightly stronger than the generator. In synthetic experiments, using a mediator with a hidden state size twice as large as the generator yields the best results. Sampling more batches from G \u03b8 and P is theoretically recommended. In Cooperative Training (CoT), sampling more batches from G \u03b8 and P for training the mediator in each iteration is recommended. Regularizations are necessary to prevent overfitting of the mediator, which can lead to divergence in terms of JSD(G \u03b8 P). Applying dropout techniques before the output layer of RNN can help alleviate this issue. Empirical results show that more training batches for the mediator in each iteration are beneficial, but further theoretical investigation is needed for better solutions. The argument focuses on plans to earn government impact, with work on the 2014 campaign and immigration officials. The method involves making up drink with willing payment, studying people on a streaming boat, and waiting for plant in federal fees. The housing market's value in tourism is highlighted, along with conflicts among major operators and interest. The curr_chunk discusses conflicts among major operators and interests, with mention of a missile for Britain and a running mate in Kansas. It also touches on the death of Aaron and the potential for radical controls in the future. Additionally, it briefly mentions possible derivatives of CoT equations. The curr_chunk discusses the mode-collapse problem in a model that estimates the target distribution, highlighting issues with unpredictable behaviors and failures in training. Results show that the model trained via Reverse KL may outperform CoT in weak metrics like BLEU but fails in learning some data patterns under stricter metrics like eWMD."
}