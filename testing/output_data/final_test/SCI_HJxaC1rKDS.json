{
    "title": "HJxaC1rKDS",
    "content": "In this paper, a novel method is proposed to address class-imbalanced training datasets in deep neural networks. By synthesizing less-frequent classes with adversarial examples of other classes, the method effectively learns generalizable features of minority classes. Experimental results show significant improvements in generalization for minority classes compared to other methods, surpassing state-of-the-art approaches for class-imbalanced classification in image and natural language processing datasets. Neural networks trained on large-scale datasets have led to breakthroughs in machine learning, particularly in tasks like image classification, object detection, and speech recognition. However, a common issue in large-scale training is the imbalance in data acquisition across labels, resulting in long-tailed label distributions. This imbalance makes training DNNs harder to generalize, especially when a class-balanced performance metric is needed. One approach to address this imbalance is to artificially re-balance the training objective. One approach to address the imbalance in data acquisition across labels is to re-balance the training objective artificially by re-weighting the loss function or re-sampling the dataset. These methods aim to balance the class-wise sample distribution, but they can lead to over-fitting on minority classes. To alleviate this issue, alternative weights such as the \"effective number\" of samples have been proposed. In the context of addressing class imbalance, re-weighting and re-sampling methods have been explored. SMOTE is a popular over-sampling method that can mitigate over-fitting. Recent research suggests that applying these methods later in training can be more effective for neural networks. Additionally, new regularization schemes and margin-based approaches have been proposed to prevent over-fitting in minority classes. Some studies also consider the class-imbalance issue in the frameworks of active learning and meta-learning. In this paper, a new method called Adversarial Minority Over-sampling (AMO) is proposed for generating minority samples. Unlike SMOTE, AMO uses adversarial examples from a baseline classifier trained on the imbalanced dataset. This approach aims to label minority class samples in a counter-intuitive way. The Adversarial Minority Over-sampling (AMO) method generates minority samples by labeling them in a counter-intuitive manner using adversarial examples. It effectively learns generalizable features in imbalanced learning by not overly relying on minority samples and leveraging richer information from majority samples. The method consists of three components to improve sampling quality: optimization objective for generating synthetic samples, sample rejection criteria favoring majority class generation, and optimal distribution based on rejection criteria. The proposed Adversarial Minority Over-sampling (AMO) method improves sampling quality by generating minority samples using adversarial examples. It significantly enhances balanced test accuracy across various imbalanced classification problems, surpassing state-of-the-art methods like LDAM. Additionally, joint training with LDAM further boosts balanced test accuracy. The text discusses the susceptibility of deep neural networks to adversarial examples, hindering their deployment in real-world safety-critical applications. The authors aim to shed new insight on understanding this phenomenon through their classification problem with imbalanced datasets. In class-imbalanced classification, the goal is to train a model that generalizes well under a uniform distribution compared to standard training. The method is based on over-sampling minority classes more frequently to balance the training objective. The proposed Adversarial Minority Over-sampling (AMO) method aims to create a balanced training dataset by adding adversarial examples, instead of using data augmentation on minority samples. This approach helps prevent over-fitting on minority classes in class-imbalanced datasets. The Adversarial Minority Over-sampling (AMO) method creates a balanced training dataset by adding adversarial examples from another classifier g, to prevent over-fitting on minority classes. AMO utilizes g to generate new minority samples for the target network f during training. The method introduces a hyperparameter \u03bb > 0 to translate a seed point x0 into x* for classification by g as class k. The generated sample x* is labeled as class k and used to train f on Dbal. The regularization term \u03bb \u00b7 fk0(x) reduces risk when x* is labeled to k, teaching minority classifiers of f new features significant to g. When g is an \"oracle\" classifier like humans, solving the problem requires transitioning the input from one class to another with 100% confidence. This process involves collecting more minority data to address class-imbalance issues. Neural network models often struggle to achieve this ideal behavior, resembling adversarial examples. However, the method still effectively improves the generalization of minority classes even in such cases. Our method effectively improves the generalization of minority classes, even in cases where the synthetic samples may contain some discriminative features of the original class. The quality of the synthetic minority samples is influenced by the quality of g, especially for g k0. The risk of unreliable generation becomes more severe when N k0 is small. To address the risk of unreliable generation of synthetic minority samples, a rejection criteria is proposed based on a hyperparameter \u03b2. The rejection probability is modeled exponentially to account for the impact of adding data points in larger datasets. This approach aims to improve the generalization of minority classes by ensuring the reliability of the generated samples. The rejection criteria for generating synthetic minority samples is based on a hyperparameter \u03b2, with the rejection probability modeled exponentially to address the impact of adding data points in larger datasets. The method focuses on maintaining loss balance by replacing rejected synthetic samples with minority points oversampled from the original dataset. Additionally, the design choice of selecting an initial seed point for each generation is crucial for the quality of the generation, with a sampling distribution chosen to maximize acceptance rate and diversity in class selection. The method focuses on maintaining loss balance by replacing rejected synthetic samples with minority points oversampled from the original dataset. Practical implementation involves using batch-wise resampling in training a neural network, with a sampling distribution chosen to maximize acceptance rate and diversity in class selection. The method focuses on maintaining loss balance by replacing rejected synthetic samples with minority points oversampled from the original dataset. In class k, a balanced mini-batch is obtained via standard re-sampling, and indices i are randomly selected for generation with probability. The generation is only performed for selected indices, with each yi acting as the target class k. Starting from a seed image x0, optimization is performed by gradient descent for a fixed number of iterations T. The result sample x* is accepted only if L(g; x*, k) is less than \u03b3 > 0 for stability. The overall procedure of AMO is summarized in Algorithm 1. The method is evaluated on various class-imbalanced classification tasks in visual recognition and natural language processing. The study demonstrates that minority synthesis through adversarial examples improves over-sampling efficiency, enhancing generalization in minority classes across various datasets. Ablation studies confirm the effectiveness of the approach, dividing classes into \"majority\" and \"minority\" based on frequency. The method uses deferred re-sampling and a specific parameter value, with results showing significant improvements compared to other re-sampling techniques. The study explores different techniques for improving minority class generalization, including deferred re-sampling, focal loss, and label-distribution-aware margin. Training details involve using SGD with momentum, ResNet-32 for 200 epochs on CIFAR-10/100 datasets, and following a specific learning rate schedule. In their study, Cui et al. (2019) used a specific learning rate schedule for fair comparison, including a linear warm-up strategy for the first 5 epochs. They trained a 2-layer fully connected network for 15 epochs with mini-batch 64 on Twitter and Reuters datasets. Additionally, they applied their method with a pre-trained classifier and deferred scheduling after standard ERM training. The study applied deferred scheduling after standard ERM training, choosing hyperparameters from a fixed set of candidates. CIFAR-10/100 datasets consist of 60,000 images, with long-tailed variants used to evaluate the method on various imbalance levels. Imbalance was simulated by controlling the imbalance ratio and reducing training sample sizes, while keeping the test dataset unchanged. Our method consistently improves test accuracy by a large margin across all tested baselines, with an example showing a 14.0% relative gain in test accuracy when N1/NK = 100 on CIFAR-10. The ERM method improves test accuracy by 14.0% compared to the LDAM+DRW baseline. It can further enhance accuracy when combined with the LDAM training scheme. The effectiveness of AMO is verified on real-world imbalanced datasets for NLP tasks like Twitter and Reuters datasets. The text discusses the imbalance issue in datasets used for text categorization tasks, specifically in the Reuters dataset. Despite efforts to address the imbalance, the problem persists in both training and test samples. The evaluation focuses on class-wise accuracy rather than standard test accuracy, with AMO showing the best performance among baseline methods. This highlights the algorithm's broader applicability beyond image classification. The study demonstrates the effectiveness of the algorithm on imbalanced datasets, particularly the Reuters dataset. Adversarial examples are used to label minority classes, enhancing the method's performance. The algorithm synthesizes a minority sample x* from a seed image x0. Ablating adversarial perturbations results in a significant reduction in accuracy compared to the original method. The regularization term \u03bb \u00b7 f k0 (x) is crucial for improving the quality of synthetic samples. Ablating \u03bb leads to a degradation in test accuracy. The proposed regularization method showed a degradation in test accuracy, validating its effectiveness. t-SNE embeddings were used to compare features learned from different training methods, with the Advserarial Minority Over-sampling (AMO) method showing more separable features. The Advserarial Minority Over-sampling (AMO) method aims to improve imbalanced learning by using adversarial perturbations as features. This approach could address over-fitting in minority classes with insufficient data, potentially opening new research directions in both imbalanced learning and adversarial examples."
}