{
    "title": "R42827",
    "content": "In considering budget issues, Congress has long been interested in the efficiency and effectiveness of federal programs, including foreign assistance. Foreign assistance evaluation is part of a government-wide effort to link program effectiveness to budgeting decisions and is a key element of recent foreign aid reforms. The 2010 Quadrennial Diplomacy and Development Review (QDDR) called for foreign aid budgets and programs to be based on outcomes achieved, not dollars spent, and for USAID to lead in monitoring and evaluation. The 2015 QDDR continued to emphasize evaluation, data use, and building agency evaluation capacity, with a focus on the Millennium Challenge Corporation (MCC) established in 2004. The Millennium Challenge Corporation (MCC) was established in 2004 to promote a new model of development assistance, emphasizing the importance of evaluation in foreign aid programs. This shift towards result-oriented development policies is driven by demands from Members of Congress, aid beneficiaries, and American taxpayers to assess the impact and effectiveness of foreign aid spending. The evolution of foreign aid evaluation has been influenced by political and fiscal circumstances since USAID's establishment in 1961. The issue of foreign aid funding has gained prominence due to increased funding levels and decreased evaluations, leading to questions about the knowledge basis for aid policy. Little is known about the impact of assistance programs, making it challenging for policymakers to develop effective strategies. This report focuses on U.S. bilateral assistance and the lack of understanding of prior aid success or failure. The report discusses the primary agencies responsible for U.S. foreign assistance - USAID, State Department, and MCC. It addresses past efforts to improve aid evaluation and current challenges. The evaluation policies of these agencies are overviewed, along with related issues for Congress. The Foreign Assistance Act of 1961 is highlighted as the legislation authorizing most modern foreign aid programs. The Foreign Assistance Act of 1961 aims to support developing countries in acquiring knowledge and resources for development, improving economic, political, and social institutions, alleviating poverty, promoting self-sustaining growth, respecting civil and economic rights, integrating into the global economy, and promoting good governance. Additional legislation has added more aid objectives over the years. The Foreign Assistance Act of 1961 aims to support developing countries in acquiring knowledge and resources for development, improving economic, political, and social institutions, alleviating poverty, promoting self-sustaining growth, respecting civil and economic rights, integrating into the global economy, and promoting good governance. Over the years, additional aid objectives have been added, such as combating drug trafficking, disaster relief, enhancing antiterrorism skills, and strengthening bilateral ties. U.S. foreign aid serves to fight poverty, enhance relationships, and protect security and commercial interests. The Marshall Plan (1948-1952) is a widely acclaimed successful aid program. The Marshall Plan (1948-1952) is praised for its role in post-World War II European reconstruction and fostering strong partnerships with the United States. Aid programs like the \"green revolution\" and global health initiatives have also made significant impacts, with success stories seen in Korea, Taiwan, and Botswana. Recent foreign assistance programs have helped combat public health crises like HIV/AIDS and shown a modest positive impact on economic growth rates. Critics argue that foreign aid programs have often been unsuccessful or harmful, citing examples of aid to corrupt governments in Africa and U.S. aid to anti-communist regimes in Latin America during the Cold War. Projects funded by donors, such as hospitals and schools, have been left unused in developing countries due to lack of resources or maintenance. Some critics believe that foreign aid can reduce government accountability and fuel corruption. Foreign aid may harm recipient government accountability, fuel corruption, damage export competitiveness, create dependence, and undermine taxation incentives. Successes and failures of aid programs are often not clearly evaluated, with aid objectives sometimes mixed with political and security goals. Evaluation practices are inconsistent, leading to a lack of evidence on the impact of foreign assistance programs. The evaluation of foreign assistance programs has historically been inconsistent and lacking in rigor, with a 2009 review highlighting the need for improvement. However, recent efforts by aid-implementing agencies, such as USAID, have shown notable improvements in evaluation practices since 2011. Monitoring and evaluation now focus on assessing impact, improving quality, and informing strategic decision-making. Performance monitoring involves tracking project inputs and outputs to determine if objectives are met. This oversight includes financial audits by agency Inspectors General to ensure funds are used as intended. Analysis of monitoring data helps explain program success or failure in meeting strategic objectives. Performance evaluation is essential to assess program effectiveness in meeting strategic objectives. While performance monitoring tracks inputs and outputs, impact evaluations focus on the impact of activities on development objectives. Impact evaluations go beyond tracking numbers to determine the actual improvement in skills or outcomes for the target group. Impact evaluations assess the impact of activities on development objectives by monitoring changes in targeted populations compared to control groups. Randomized controlled trials are ideally used to measure changes attributed to aid interventions. Impact evaluations are essential for determining the effectiveness of foreign assistance programs. Various methods, such as \"before and after\" data analysis, case studies, and mixed method designs, can be used for impact evaluation. However, these evaluations are more complex and resource-intensive than performance monitoring and evaluation. Agencies must balance the potential knowledge gained from impact evaluation with the additional resources required for such assessments. The practice of foreign assistance evaluation has evolved over time, with a focus on meeting program management needs, institutional learning, accountability, informing policymakers, and building local oversight and project design capacity. USAID played a significant role in the history of U.S. foreign assistance evaluation. The evolution of foreign assistance evaluation began with USAID implementing U.S. foreign assistance. Initially focused on large projects, evaluations shifted to smaller projects addressing basic needs. USAID established its Office of Evaluation in 1968, using the Logical Framework model for monitoring and evaluation. This approach, adopted by many agencies, utilized a matrix to identify project goals, results, and activities with corresponding indicators and verification methods. The LogFrame approach used by USAID for project evaluation was similar to current GPRA requirements but lacked in analyzing data for competing explanations or unintended consequences. While USAID was seen as a leader in evaluation policy, the quality of evaluations varied greatly. A 1970 handbook outlined an \"ideal\" evaluation design resembling a randomized controlled trial, but acknowledged challenges in achieving this. Decentralization over time led to shortcomings in the foreign assistance evaluation system. The decentralized foreign assistance evaluation system revealed shortcomings in meeting broader learning and policy needs. In response, USAID established the Center for Development Information and Evaluation (CDIE) in 1983 to improve information analysis and foster the use of development information. The Center for Development Information and Evaluation (CDIE) provided training on evaluation best practices to mission staff and made evaluation reports accessible to implementers. CDIE's work influenced USAID strategies and priorities, but there was a need to improve the quality and timeliness of evaluation reports. Statistical rigor in evaluation methods was not widely used at USAID due to skills, time, and expense constraints. Guidance encouraged the use of low-cost and timely evidence for project performance assessment. In the early 1990s, accountability for funds became a primary focus of aid evaluation at USAID. A 1990 GAO review highlighted difficulties in tracking aid funds usage, leading to a shift towards monitoring where aid money was going rather than measuring accomplishments. USAID responded with an Evaluation Initiative from 1990 to 1992, expanding CDIE's staff and budget to invest in rigorous evaluation designs and innovative methods for sector-wide results assessment. In the mid-1990s, USAID underwent reorganization which led to the elimination of the Office of Evaluation within CDIE and a shift towards \"rapid appraisal techniques\" as a compromise between formal and informal evaluation methods. The policy changed to only conduct evaluations when necessary, reducing the number of completed evaluations significantly. The number of completed evaluations at USAID dropped significantly from 425 in 1993 to around 138 in 1999 due to limited resources. Despite inconsistent guidance, some bureaus continued quality evaluation work. Foreign assistance levels increased after 2003 to support various initiatives, leading to a focus on accountability to Congress. In response to calls for accountability in aid expenditures, USAID Administrator Andrew Natsios implemented measures to improve evaluation practices within the agency. This included requiring evaluation plans in program designs, appointing monitoring and evaluation officers at each post, and allocating funds for evaluations and employee incentives. Additionally, in 2006, Secretary of State Condoleezza Rice established the Office of the Director of Foreign Assistance (F Bureau) to streamline U.S. bilateral assistance efforts and set standard performance indicators for measuring results. The F Bureau established standard performance indicators to measure the impact of foreign assistance funds. The data collected through the \"F process\" improved aid transparency, showing where funds are allocated by State and USAID. However, some believed the reporting demands interfered with evaluation work at USAID. The F Bureau implemented evaluation capacity reforms in response to congressional scrutiny of foreign aid. The HELP Commission highlighted concerns about the inadequacy of monitoring and evaluation processes, emphasizing the need for better project evaluation to enhance the effectiveness of taxpayer dollars. The HELP Commission recommended a unified foreign assistance policy, budgeting, and evaluation system within the State Department. They also suggested using control groups and randomization in evaluation strategies, exploring new evaluation methods, and building recipient governments' capacities for reliable data. This coincided with the establishment of the F Bureau and a renewed focus on aid effectiveness in the international donor community. Some aid professionals were disappointed with the F process for focusing on measuring outputs rather than impact and lacking rigorous evaluation methodologies. The Obama Administration initiated a Quadrennial Diplomacy and Development Review in 2009 to improve aid effectiveness, committing to focusing on outcomes and impact in foreign assistance. The first Quadrennial Diplomacy and Development Review (QDDR) led to significant changes at State and USAID, including the establishment of a new Office of Learning, Evaluation, and Research at USAID and the implementation of a new evaluation policy. The second QDDR in 2015 emphasized the need for training to enhance evaluation expertise and the importance of adding rigor to evaluations through better use of diagnostics and data analysis. Despite the adoption of evaluation policies by both State and USAID, some requirements, such as evaluating all large projects and allocating resources for evaluations, were not fully met. In January 2015, State revised its evaluation policy to be less directive and more suitable for various State activities. The new policy no longer requires evaluations for all large projects, mandates one evaluation per bureau per year, and eliminates evaluations at the post level. The Millennium Challenge Corporation is recognized for its rigorous evaluation policy in aid assessment. The Millennium Challenge Corporation (MCC) provides support for five-year development plans through \"compacts\" submitted by partner countries. MCC emphasizes impact evaluation, with a high proportion of completed evaluations being impact evaluations. However, the overall impact of MCC assistance remains unclear, with successful project implementation but limited evidence of progress towards raising household incomes. The evaluation emphasis on measuring impact and learning what works is not new, dating back to the 1970s. However, recent evaluations of U.S foreign aid programs show limited rigorous impact evaluation, with only 9% reporting on a comparison group and one using experimental design. This lack of critical information hinders the demonstration of results. A meta-evaluation from 2009-2012 showed improvements in 68% of quality factors in USAID projects, but most evaluations did not meet all 37 criteria. A second meta-evaluation for 2012-2016 is anticipated in 2017. Challenges in achieving ideal evaluation practices in the field are discussed. The challenges in achieving ideal evaluation practices in the field are discussed, including mixed objectives in the U.S. foreign assistance program. Aid programs often have strategic and development objectives, with political motivations sometimes overshadowing agricultural impacts. The Food for Peace program provides U.S. agricultural commodities to countries facing food insecurity, but requirements favoring U.S. agribusiness and shipping industries may reduce its hunger-alleviation impact by up to 40%. Evaluations examining strategic objectives in foreign aid are rare. Evaluation of foreign aid programs often overlook broader strategic objectives, focusing only on development impact. A Mercy Corp evaluation in Afghanistan found that youth employment programs increased support for political violence. Rigorous evaluations are costly in terms of funds and staff. The cost and resource constraints hinder the implementation of rigorous impact evaluations in foreign aid programs. Limited staff, budget, and competing priorities lead to the neglect of evaluation components in program planning. Competitive contracting further discourages investment in evaluation plans without enforced requirements. Limited resources and competing priorities hinder the implementation of rigorous impact evaluations in foreign aid programs. Ad hoc evaluations with limited scope often prevail due to lack of funding and trained personnel. The absence of enforced requirements leads to neglect of evaluation components in program planning. USAID has addressed the lack of trained evaluation personnel by training 1,600 staff since 2011 and recruiting monitoring and evaluation fellows. They also collaborate with other entities for aid evaluation and experts suggest collective evaluations to address resource limitations and allow for generalization of evaluation. Aid monitoring and evaluation efforts have focused on accountability of funds, driven by concerns about corruption and waste. Implementing agencies track where funds go and what they purchase, rather than the impact on development. The Foreign Assistance Framework was created to address stakeholders' demands for more data on aid spending. The focus of aid monitoring and evaluation has shifted towards accountability of funds, with efforts to track spending in various aid programs. However, there are methodological challenges in evaluating the impact of aid projects, as rigorous evaluation methods may not always be practical in complex environments. The evaluation of aid projects faces challenges in measuring impact, especially in complex environments. Metrics may be easier to establish for concrete objectives like reducing disease prevalence than for programs aimed at strengthening relationships. Rigorous methodology can limit program flexibility, as mid-course changes can compromise evaluation design. The evaluation of aid projects in complex environments can be challenging due to difficulties in attributing impact to specific interventions. USAID struggles to establish a link between its assistance and trends in Afghanistan's education sector, where many donors are active. Some aid professionals believe that rigorous impact evaluation methods, such as randomized control groups, limit community participation in project design and evaluation. Some argue that community participation in project planning and evaluation is more valuable in development than high-quality evaluation findings. Others believe that participatory methodologies can be biased and unethical to replicate programs without proper evaluation. Political pressures can lead to compressed timelines for aid strategies, affecting evaluation work. Political pressures in politically charged environments like Iraq, Afghanistan, and Pakistan have increased over the past 15 years, leading to a demand for quick results in aid programs. This rush for immediate impact has hindered the implementation of long-term goals, making it difficult to evaluate the real impact of aid. The Millennium Challenge Corporation (MCC) faced challenges in completing evaluations within limited timeframes during the compact implementation period. During MCC's first compacts in Cape Verde and Honduras, assistance feasibility was found to be compromised by program timeline changes. Evaluation models can lose value if timelines shift, as seen in Armenia where a delay affected the impact evaluation model. Long-term aid impacts are crucial but often go unevaluated. Efforts to increase recipient country control and coordination among aid donors aim to enhance sustainability of positive results. Efforts to enhance sustainability of positive results in aid projects include ensuring consistency with recipient priorities, building budget and project management capacity, and promoting donor coordination. USAID aims to direct more aid to governments and local organizations, but this may lead to diminished donor control and accountability concerns. Congress has expressed concerns about the evaluation of how U.S. funds contribute to outcomes in such contexts. The evaluation of foreign aid in challenging contexts, such as Afghanistan, raises concerns about corruption, mismanagement, and security obstacles. A significant portion of aid has been directed to countries facing security challenges, impacting the implementation and evaluation of aid projects. In challenging contexts like Afghanistan, security concerns have hindered development staff from verifying project sites or conducting necessary surveys. Reports have highlighted security issues in Iraq and Afghanistan, making it difficult for civilian agency personnel to oversee projects firsthand. Security concerns can also impact evaluation quality in less hostile environments. The evaluation of governance activities in Colombia in 2011 highlighted security challenges limiting the freedom to interview community members, potentially leading to sampling bias. In insecure regions, where U.S. foreign policy interests are high, policymakers must weigh the risk of not being able to evaluate aid interventions. Foreign assistance officials may avoid formal evaluations to prevent highlighting program shortcomings, showing a reluctance to conduct thorough assessments. Many agency staff are defensive about program evaluations, fearing career implications like loss of control, damage to reputation, or budget cuts. There is pressure to produce success stories over balanced evaluations, with a lack of incentives for learning through evaluations. Risk-taking and accepting failure are not seen as cultural norms at USAID or the State Department, but a shift in attitude may be underway. According to USAID Administrator Gayle Smith, there is a cultural shift towards learning from evaluations rather than just checking boxes. However, there is still reluctance within USAID to hold staff accountable for poor evaluation practices. Evaluations are often not used to inform policy due to lack of faith in their quality, irregular dissemination practices, and resistance to criticism. Time constraints also hinder aid implementers and policymakers from utilizing evaluation reports effectively. The 2009 survey of U.S. aid agencies highlighted challenges in making evaluation reports accessible to policymakers and agency leaders. The shift towards using contractors and partners for project implementation and evaluation may hinder learning processes. Congress showed interest in this issue with the Initiating Foreign Assistance Reform Act of 2009. In the 111th Congress, a bill was introduced by Representative Howard Berman to improve the use of evaluation data in future budgeting and planning of US foreign assistance programs. USAID found that 90% of evaluation findings had an impact on program decision-making, mainly for project design and modification. USAID requires that its Country Development Cooperation Strategies cite evidence for development hypothesis, with 60% citing evaluation reports in 2015. However, there is little evidence linking evaluations to higher-level policy decisions. The learning aspect of evaluation depends on agency culture and effective application relies on details of implementation, such as tailored evaluation questions and useful information presentation. Experts suggest that a meta-evaluation of microfinance programs is more beneficial than detailed analysis of individual projects. They argue for the development of evaluation meta-data at a cross-agency or whole-of-government level to determine the effectiveness of foreign assistance. Legislation like the Foreign Assistance Revitalization and Accountability Act of 2009 reflects this viewpoint. The Foreign Aid Transparency and Accountability Act of 2016 directs the President to establish guidelines for consistent evaluation of foreign assistance across federal agencies. Not all aid projects have broad learning potential, so knowing which evaluations could have the greatest policy implications is crucial for maximizing resources. Many USAID projects are not designed to be scaled up or replicated elsewhere, while some approaches may already be well proven. In some situations, a basic performance evaluation may suffice instead of a rigorous one. The USAID \"Decision Tree for Selecting the Evaluation Design\" advises staff to assess the need for evaluation and decline if timing is not right or if there are no unanswered questions. Different U.S. government agencies have varying evaluation policies. The Quadrennial Diplomacy and Development Review aims for USAID to lead in international development evaluation with a new policy to meet the demand for results data. The USAID, State Department, and MCC have updated their evaluation policies to meet the growing demand for results data. The policies emphasize performance evaluations for larger projects and experimental ones, with a focus on accessibility of information. The USAID and State Department evaluation policies prioritize accessibility of information and timely dissemination of reports. USAID's policy is more detailed, requiring specific features in evaluation reports and independent evaluators, while State's policy lacks these requirements. USAID also suggests allocating 3% of program funds for evaluation, a provision not found in the State policy. The State policy lacks a target allocation for program evaluation, in contrast to USAID's 3% target. USAID calls for impact evaluation whenever feasible, while the State policy expects it to be rare. MCC's policy requires independent evaluations for all compact projects with pre-established indicators and baselines. MCC also includes a \"lessons learned\" section in its reports and is aligning more closely with USAID's evaluation policy over time. The update to USAID's evaluation policy includes a section on institutional learning and aligns more closely with the MCC model for impact evaluations. The MCC policy has the strongest enforcement mechanism, requiring substantial compliance for quarterly disbursements. Differences in evaluation practices across State, USAID, and MCC reflect their unique experiences and priorities. The evaluation policies of USAID, MCC, and State reflect their unique experiences and priorities. USAID's diverse assistance portfolio may require a more flexible approach to evaluation compared to MCC's focus on economic growth. State's evaluation approach is influenced by its broader portfolio, including diplomatic and military activities. These policies aim to improve knowledge of foreign assistance effectiveness at the program level and increase transparency in the evaluation process. However, they do not establish a systemic approach to aid evaluation. The 2011 USAID policy shows similarities to earlier initiatives for aid evaluation, but it is uncertain if the new multiagency initiative will have a greater impact. A meta-evaluation of USAID evaluations from 2009 to 2012 revealed an increase in quantity and quality, yet most evaluations in 2012 did not meet standards. Momentum for foreign aid evaluation reform has been seen within the Administration. While some momentum for foreign aid evaluation reform has been seen within the Administration, Congress may have significant influence on this process by mandating or promoting specific evaluation approaches through legislation and controlling appropriations. Legislation introduced in the 112th and 113th Congresses focused on evaluating U.S. foreign assistance programs to improve effectiveness. The legislation introduced in the 112th and 113th Congresses aimed to improve the effectiveness of U.S. foreign assistance programs by establishing guidelines for measurable goals, performance metrics, and monitoring and evaluation plans. It also called for the creation of a website to provide detailed information on foreign assistance programs to the public. The legislation was reintroduced in the 114th Congress with modifications and was enacted into law in July 2016 as P.L. 114-191, potentially shaping aid evaluation practices in the future. The focus of proposals is on codifying evaluation requirements across federal agencies administering aid programs to enable better comparison and transparency. However, imposing uniformity may be challenging due to different agency objectives and systems. The proposals prioritize transparency and accountability over effectiveness, calling for rigorous methodologies like impact evaluation. Such cross-agency requirements aim to standardize aid management information but may not support comparative analysis of aid effectiveness. Increasing foreign aid evaluation quality requires resources, with evaluation costs often integrated into agency budgets. Congress can influence evaluation efforts through funding levels and legislative directives, potentially specifying funds for evaluation in appropriations legislation. Congress has long controlled foreign assistance by directing funds to specific sectors or projects through bill or report language. Improved evaluation practices could provide credible information on program effectiveness, allowing Congress to prioritize aid based on data. The primary U.S. agencies implementing foreign assistance have improved evaluation practices to address deficiencies. There is a consensus on the need for consistent performance evaluation and rigorous impact evaluation, although agencies vary in their capabilities. Past policies and reform efforts have been focused but not sustained. Reform efforts to improve U.S. foreign assistance evaluation have faced persistent challenges, with proposed reforms not yet enacted. Congress and the Administration are increasingly focused on results-based budgeting and rigorous aid evaluation practices, offering opportunities for sustained progress. The 114th Congress can influence evaluation through legislative proposals, appropriations, and oversight activities."
}