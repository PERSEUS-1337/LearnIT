{
    "title": "Skl8EkSFDr",
    "content": "Deep learning models have become increasingly larger and more complex, posing challenges in deployment due to their compute and memory requirements. While model compression techniques have been successful in tasks like image classification and language models, there is limited research on compressing generative adversarial networks (GANs). A new self-supervised compression technique is introduced in this paper, utilizing the trained discriminator to supervise the training of a compressed generator. This approach shows promising performance in achieving high degrees of sparsity, generalization to new tasks and models, and facilitating meaningful comparisons. Compression techniques have been applied to deep neural networks to reduce memory requirements and improve performance. Distillation can enhance the accuracy of a compressed network by utilizing information from the original network. In this work, the focus is on compressing the generative model of Generative Adversarial Networks (GANs) for more efficient deployment. Standard pruning techniques, with or without distillation, are explored to reduce the computational requirements of GANs while maintaining the generator's behavior. By modifying the loss function with a novel combination of the pre-trained discriminator and the original and compressed generators, we can achieve compelling compression rates with little change in the quality of the compressed generator's output. Filter pruning, a technique commonly used for accelerating image classification networks, is not easily applicable to GANs. Quantization and weight sharing methods like hashing and clustering can help compress GANs to save storage and bandwidth. Techniques such as using GANs for generating training data and distillation can maintain accuracy during compression. GANs can also guide the pruning process to optimize hyperparameters. Lin et al. (2019) and Wang et al. (2019a) use GANs and reinforcement learning for compression, focusing on the generator for efficient deployment. The discriminative model is crucial in training but not needed afterward. Compressed generators show poor performance in image-to-image translation tasks. Baseline approaches include standard pruning techniques and specialized methods for GANs. In the context of GAN compression, various techniques have been applied to different network architectures and generator compression. Standard pruning methods and GAN-specific compression techniques are compared, including manual pruning, fine-tuning, and distillation to improve performance. Distillation aims to extract knowledge for compressed networks from original ones. Targeted GAN compression involves methods beyond pruning, with adversarial training being one approach. This technique involves training a discriminator alongside the student network to distinguish between student and teacher models. Several techniques have been used to compress GANs, including distillation, LIT, QGAN, and selectively binarizing parts of both networks during training. These methods aim to reduce the size of the generator while maintaining a balance between the discriminator and generator. Their approach involves selectively binarizing parts of both networks during training on the Celeb-A generative task, up to 64x64 pixels. Experiments were conducted using StarGAN trained with the Distiller library for pruning, extending image-to-image translation capabilities to multiple domains within a single model using the CelebFaces Attributes dataset. The aim is facial attribute translation, generating new images with five domain attributes. The study involves generating new facial images with five domain attributes changed using different techniques, aiming for 50% sparsity. Despite efforts to optimize hyperparameters, standard approaches did not yield satisfactory results. Results show that existing methods produce inferior results compared to the original dense generator, with images from pruning and fine-tuning being hardly recognizable. The study aimed to generate new facial images with changed domain attributes using various techniques for 50% sparsity. Existing methods produced inferior results compared to the original dense generator, with images from pruning and fine-tuning being hardly recognizable as faces. Our proposed self-supervised GAN compression method produces natural, nearly indistinguishable images compared to the dense baseline, achieving similar quantitative scores. Past approaches failed on larger image-to-image tasks, while our method succeeded on both. Previous methods achieved a compression rate of 1.8\u00d7 by training a shallower network but did not perform well on network pruning. Loss curves were not always indicative of success, with some techniques showing poor results while others, like our approach, showed promising curves. The proposed self-supervised GAN compression method successfully compresses generative models for image tasks, achieving good performance despite standard pruning techniques failing to work effectively. The method produces nearly indistinguishable images compared to the dense baseline, with promising loss curves indicating success. GANs are evaluated subjectively with some quantitative metrics. Training is unstable and sensitive to hyperparameters. The energy of GAN input and output remains constant, but tasks like classification have less entropy. Reduced-information space allows for tolerance in classification models. Style-transfer and dataset synthesis tasks do not show energy reduction. During GAN training, maintaining high entropy is crucial to avoid mode collapse. Training a new discriminator to improve the compressed generator's performance leads to low-entropy solutions. This hinders its use in generative tasks and requires training the compressed network from scratch during distillation. The goal is to address these challenges in GAN training by ensuring the generative model generates samples similar to real ones, while the discriminative model distinguishes effectively. The discriminator in GAN training is trained to distinguish between real and synthesized samples. A well-trained generator can fool the discriminator into believing a generated sample is real. By using the discriminator as a judge, we can determine the quality of a compressed generator without human inspection. This approach addresses challenges in GAN training by ensuring similarity between generated and real samples. The discriminator in GAN training is crucial for evaluating the quality of a compressed generator. It ensures similarity between generated and real samples, avoiding mode collapse. The compressed generator adapts to fine changes induced by the discriminator, serving as a \"self-supervised\" compression method. The compressed generative model produces a fake map image, with generative loss values measured using consistent loss functions. The discriminative difference is also measured between corresponding discriminative losses using a weighted normalized Euclidean distance. This process is exemplified in the StarGAN task. The overall loss function in GAN compression involves generative and discriminative differences, with weight ratios and parameters adjusted accordingly. Promising results have been shown in prior methods, and further experiments are conducted to assess its applicability to different networks and tasks. In GAN compression, experiments are conducted to assess the method's applicability to various networks and tasks. The sparsity rate is gradually increased from 5% to 50% during self-supervised training using PyTorch and Distiller. The experiments use a V100 GPU with FP32 for matching public baselines. The experiments involve applying a compression method to different networks and tasks, with results summarized in Table 2. An additional 10% of epochs may be needed, but overhead was reduced to 1% in some cases while maintaining quality. Representative results for tasks like Image Synthesis and Domain Translation are included, with detailed outputs in the Appendix. For Image Synthesis, the compression method was applied to DCGAN to generate images from the MNIST dataset. In Domain Translation, the method was applied to pix2pix for synthesizing fake satellite images from label maps. In the experiment, a compression method is applied to various networks and tasks, including CycleGAN for style transfer, StarGAN for image-to-image translation, and SRGAN for super resolution. Results for bidirectional tasks like synthesizing fake satellite images and transferring styles are shown in figures. In the experiment, SRGAN was trained on the DIV2K dataset and evaluated using PSNR, SSIM, and FID scores. Results include filter-pruned generators and demonstrate self-supervised compression for various tasks and networks with different pruning granularities and rates. In the experiment, SRGAN was trained on the DIV2K dataset and evaluated using PSNR, SSIM, and FID scores. Results include filter-pruned generators and demonstrate self-supervised compression for various tasks and networks with different pruning granularities and rates. We can compress and remove filters, kernels, vectors, or individual elements. Finer-grained pruning leads to higher accuracy, but coarser granularities are easier for performance gains. Pruning tasks involved removing single elements and entire filters, reaching final sparsities of 25%, 50%, 75%, and 90%. Fine details faded with up to 90% fine-grained sparsity, while filter pruning caused color shifts and loss of details even at 25% sparsity. In this paper, a pre-trained discriminator is used for self-supervised compression of a generative adversarial network, showing effectiveness across various tasks. The compressed generators outperform baseline models in subjective and quantitative evaluations. Advantages include improved results, shorter compression time, and an end-to-end schedule without the need for objective metrics. A single optional hyperparameter is introduced, fixed at 0.5 for all experiments. The study explores the effectiveness of self-supervised GAN compression, highlighting that pruning whole filters may not be suitable for GAN applications. Fine-grained compression strategies show better results across various tasks, with SRGAN being an exception to filter-pruning's limitations. The study suggests that different models may tolerate varying levels of pruning, leaving room for future exploration. The study explores self-supervised GAN compression, emphasizing the effectiveness of fine-grained strategies over filter pruning. Future work will extend the method to new areas and network types by training a discriminator alongside teacher and student networks. Loss curves for comparative experiments are shown in Figure 9, while Figures 10-12 display outputs of StarGAN compressed using existing techniques and the proposed self-supervised method. Figure 13 and Figure 14 show image synthesis on the MNIST dataset using DCGAN with different levels of sparsity. The results display handwritten numbers generated by the original generator, the pruned generator with a self-supervised method, and the pruned generator with traditional knowledge distillation. The FID scores are also provided for evaluation. CycleGAN: zebra to horse and horse to zebra image-to-image translation with filter pruning to different sparsities. Baseline generator output compared to generated real photo style images at sparsities of 25%, 50%, 75%, 90%. Loss curves for comparative experiments shown in Figure 44."
}