{
    "title": "SyxBxCNFwr",
    "content": "We propose a new architecture called DRASIC for distributed image compression from multiple data sources. The system can train distributed encoders and a joint decoder on correlated data sources, outperforming separate codec training methods. Our method achieves compression close to a single codec trained with all data sources, following the Slepian-Wolf Theorem in Distributed Source Coding. It is also robust to missing data from some sources. The first data-driven DSC framework for general distributed code design with deep learning has been shown to be robust and scalable. Deep neural networks can achieve comparable results to classical image compression techniques. These models are based on autoencoder networks and quantization of bottleneck representations, often relying on entropy codec for further compression. Training multiple models with different regularization parameters separately is necessary to achieve different compression rates. In this work, a data-driven distributed compression framework is developed to handle nontrivial distribution of image sources with arbitrary correlations. The system transfers computation complexity from encoders to decoders, enabling low complexity encoders for various applications like multi-view video coding, sensor networks, and under-water image processing with restricted bandwidth and computational power. The distributed framework allows for robustness against noises or malfunctions in encoders, scalability for decoding at different compression levels, and efficient coding of correlated sources. It is particularly useful for video streaming applications. The question of whether distributed encoders can perform as well as a single encoder trained with all data sources together is addressed positively in the context of information theory. The Slepian-Wolf and Wyner-Ziv Theorems in information theory address the efficient compression of correlated data sources. Practical applications like DISCUS have emerged, transferring computation complexity from encoder to decoder for advantages in applications like multi-view video coding. Complexity encoders are advantageous in applications like multi-view video coding and sensor networks. A DNN architecture with distributed encoders and a joint decoder is proposed in this work. Distributed encoders can perform as well as a single encoder trained with all data sources. The DSC framework is data-driven and can be applied to distributed data with unknown correlation structure. The paper outlines previous related works, describes the proposed architecture for image compression, and elaborates on the Deep Distributed Source Coding framework. Experimental results and conclusions are presented in subsequent sections. The curr_chunk discusses the lack of systematic approaches for distributed code design in the presence of multiple data sources with correlations. It introduces a data-driven DSC architecture using neural network-based quantizers to exploit data source correlations. The methodology aims to approach the theoretical limit of lossy image compression, contrasting with classical codecs like JPEG. The curr_chunk discusses various codecs for image compression, including JPEG, JPEG2000, WebP, and BPG. It also mentions the use of autoencoders in deep neural network architectures for compression. Non-recurrent autoencoders use entropy codecs, while recurrent models introduce incremental binarized codes. The performance of nonrecurrent models heavily relies on the conditional. The curr_chunk discusses challenges in image compression, including the use of PixelCNN for nonrecurrent models and recurrent autoencoders for lower compression qualities. Variations like adversarial training, multi-scale compression, and GDN layers are also mentioned. Different approaches to quantization derivatives are explored, such as continuous relaxation and stochastic binarization. The methodology is inspired by information-theoretic results on DSC. The methodology discussed is inspired by information-theoretic results on DSC from the 1970s. The Slepian & Wolf Theorem shows that correlated data sources can be encoded separately and decoded jointly to achieve the same performance as joint encoding and decoding. Cover's work extends this to multiple correlated sources, while Wyner & Ziv's coding provides a rate-distortion curve for lossy cases. The achievable region for joint encoding and decoding of two data sources is illustrated in Fig. 3. The Slepian-Wolf Theorem demonstrates that correlated data sources can be separately encoded and jointly decoded to achieve optimal performance. Source coding with side information at the decoder is a widely used scheme in practice. DSC framework benefits low complexity video encoding by transferring complexity from the encoder to the decoder. Additionally, DSC has been shown to be applicable to still images and can be incorporated with Scalable Video Coding. Incorporating Scalable Video Coding with Distributed Source Coding (DSC) has shown feasibility in the problem setting. A recurrent autoencoder for scalable image compression is described, utilizing modules like Pixel (Un)Shuffle and Binarizer. The compression network includes an encoder, binarizer, and decoder with tanh activation function. Input images are encoded and transformed into (-1, 1) before binary codes are quantized and used for image reconstruction. Residual difference is computed between the original and reconstructed images. The residual difference between original input images and reconstructed output images is computed in a recurrent autoencoder for scalable image compression. The reconstructed images at each iteration are the sum of output reconstructions from previous and current iterations, modeled by recurrent models like ConvLSTM. Scalable codes allow for reconstruction at lower compression quality by using a subset of codes, beneficial for video streaming applications. The recurrent autoencoder improves compression quality by creating a correlated residual sequence. It uses Pixel UnShuffle modules for resizing feature maps efficiently. Compared to classical autoencoders, it can reconstruct images at lower compression qualities using a subset of generated codes. The recurrent autoencoder improves compression quality by creating a correlated residual sequence. It uses Pixel UnShuffle modules for resizing feature maps efficiently. The method proposed for upscaling is actually invertible, allowing for symmetric construction of encoder and decoder. Experimental results show that this architecture produces better results with fewer parameters compared to asymmetric architectures. The derivative of the quantization function is replaced with a smooth approximation in the backward pass of backpropagation. The identity function is chosen to replace derivatives based on discussions of alternative approaches. The identity function is used to replace derivatives that cannot be well defined. A stochastic form of binarization is used during training. The Distributed Recurrent Autoencoder for Scalable Image Compression (DRASIC) is illustrated, where each data source is encoded separately and decoded jointly. A data-driven approach is proposed to handle complex scenarios with unknown data source distributions and arbitrary correlations. Our proposal introduces a neural network-based Distributed Source Coding (DSC) where M distributed encoders encode data sources independently with the same model parameters. The joint training process optimizes the model so that a single decoder can decode from correlated sources without needing to synchronize codes from other sources. This approach allows the model to adapt the correlations among all sources, resulting in a distributed model that performs as well as encoding all data with a single encoder. Our model demonstrates the capability to compress natural and grayscale images using CIFAR10, Kodak, and MNIST datasets. Non-recurrent autoencoders outperform recurrent models on rate-distortion curves, emphasizing the scalability and high-quality reconstruction abilities of our approach. Our experiments show the feasibility of scalable distributed source coding in a data-driven setting using low quality images. The model uses Adam optimizer with a minibatch size of 100, learning rate of 0.001, and depth size D = 3. The model compresses images into binarized codes at each iteration, achieving compression rates from 0.125 to 2 BPP. L1 loss outperforms L2 and binary cross entropy loss. The symmetric recurrent autoencoder performs comparably to classical codecs and neural network-based codecs on compressing natural images, and significantly better on compressing handwritten grayscale images. The study demonstrates compressing distributed data sources by splitting data into correlated subsets. Experiments are conducted with different numbers of distributed sources using the MNIST dataset. Results are compared to a joint encoder-decoder model and a separate encoder-decoder model. Training data is split, but evaluation is done on all test data. The study explores compressing distributed data sources by splitting them into correlated subsets. Experimental results show moderate correlation among MNIST image pixels. The research involves training distributed encoders and a joint decoder to leverage these dependencies. Experimental studies cover the use of different numbers of distributed data sources with varying correlations, testing the robustness of the framework with fewer sources, and evaluating low complexity encoders trained with fewer iterations. The study examines compressing distributed data sources by splitting them into correlated subsets using distributed encoders labeled as 1, 2, ..., m. Results show that training distributed encoders and joint decoder can closely approach the theoretical limit, with performance decreasing slightly as the number of encoders grows. The gap between training codecs for each data source separately and using distributed encoders diminishes with more data availability and diverges as more bits are generated. Images split by random subsets outperform those split by class labels. The experiment demonstrates that the Deep DSC framework can achieve near-oracle performance without estimating correlations among data sources. Unlike classical DSC code design, the data-driven framework does not require synchronization of sources. Even if one encoder is functional, it can still benefit from dependencies with other sources due to trained model parameters. The experiment shows that distributed encoders outperform separately trained codecs and have narrower confidence bands. As the number of encoders increases, separately trained codecs have wider confidence bands due to overfitting. Distributed encoders maintain small confidence bands by capturing dependencies among data sources. The confidence bands widen with more iterations, as residual differences become less correlated. Low complexity encoders trained with fewer iterations also perform well. For m = 8, encoders 1 to 4 are trained with 16 iterations while encoders 5 to 8 are trained with 8 iterations. Half complexity encoders perform as well as full complexity encoders in the first 8 iterations, but their performance decreases after the eighth iteration without specifically training dependencies. The performance of half complexity encoders is worse after the eighth iteration compared to encoders trained in a distributed manner. A data-driven Distributed Source Coding framework called DRASIC was introduced for Scalable Image Compression. This method learns dependencies with neural network parameters instead of estimating correlations among data sources in advance. The framework is robust, allowing each distributed encoder to be used independently once trained and deployed. Our recurrent model efficiently reconstructs images at low compression quality, showing the feasibility of low complexity encoders in Distributed Source Coding. Future work includes improving compression quality with spatially adaptive weights and extending the network architecture for time-dependent data sources."
}