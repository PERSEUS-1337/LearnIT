{
    "title": "Hy8hkYeRb",
    "content": "The brain is seen as a prediction machine that learns to make better predictions about external stimuli by building a model of the world. Predictive coding is proposed as a way for the brain to create this model. An algorithm is described in this paper to build a deep generative model using predictive coding to infer latent representations from external stimuli, specifically using unsupervised learning on real-world images. The study focused on a deep generative model using unsupervised learning to infer latent representations from external stimuli. The model successfully generated latent representations for novel objects and preserved important details in reconstructions of the original images. Predictive coding is proposed as a way for the brain to create a model of the world and process visual information. Predictive coding models visual information processing as a hierarchical neural network with feedback conveying predictions and feedforward conveying errors. Studies have explored its biological plausibility and relation to other learning approaches, showing equivalence to biased competition models and similarities in weight changes with error-backpropagation. Predictive coding in training deep neural networks adheres to brain constraints and focuses on orientation selective receptive fields. Building deep neural network models of the brain for studying complex processes like attention and memory raises questions about complying with architectural constraints like retinotopic arrangement. Most current models use fully connected layers. In this paper, a systematic approach for training deep neural networks using predictive coding in a biologically plausible manner is presented. The architecture of these neural networks is inspired by convolutional neural networks but employs locally connected layers to comply with the retinotopic arrangement of receptive fields observed in sensory cortical areas. The approach proposed in this paper involves training deep neural networks using predictive coding with locally connected layers. It can be scaled for modeling sensory processing pathways and stimuli in any modality. The effectiveness of the approach was demonstrated by training a deep neural network on real-world images from the CIFAR-10 dataset in an unsupervised learning paradigm. The model was used to infer latent representations for new images of horses and ships. The paper discusses training deep neural networks using predictive coding to infer latent representations for new images of horses and ships. It demonstrates the model's ability to reconstruct real-world images while capturing important object features. The paper is organized into sections describing the architecture, results of studies, computational implications, and conclusions from experiments. The learning algorithm aims to infer latent representations for training images and other unseen images using a generative model. A neural network with (N + 1) layers is used, where the input layer presents training images. Neurons in each layer are arranged in a 3-dimensional block, connected through filters and strides to form the network structure. The architecture of the deep predictive coding neural network involves layers connected through filters and strides. Neurons in each layer project only to neurons in their receptive field, with information propagation direction differing from Convolutional Neural Networks. In a predictive coding network, information flows from layer N to layer 0, with error gradients propagating in the opposite direction. Neurons in each layer project to their receptive field through filters, with non-linear activation functions. In a predictive coding network, information flows from layer N to layer 0 with error gradients propagating in the opposite direction. Neurons in each layer project to their receptive field through filters with non-linear activation functions. The architecture results in overlapping receptive fields when the stride is less than the filter size. Neurons in layer l project to overlapping positions in layer (l-1), and the output of neurons in layer (l-1) is determined by computing the average of the projections made by layer l. This methodology is similar to unpooling in a deconvolution network to retain layer dimensions. The generative neural network model in this paper uses predictive coding to infer latent representations of input images by accurately predicting latent representations at the layer below. The predictive coding network uses Equation 3 to predict latent representations at the layer below. The total error (E) in Equation 4 includes prediction and regularization loss, minimizing prediction error at each layer by learning latent representations and synaptic weights simultaneously. The summation limits in Equation 4 are from 0 to N, excluding the topmost layer. The model minimizes prediction error by adjusting weights and latent representations in each layer of the network. The error function is expanded to include network architecture, and the gradient is used to update latent representations. Bottom-up and top-down learning rates, along with regularization, contribute to the adaptation process. The bottom-up and top-down learning rates help in learning sparse latent representations and provide numerical stability to the process. The gradient of the error function is used to update filters in the network, with updates depending on predictions and filters at specific positions. The update process for latent representations and filters involves applying \u03ba update steps on the latent representations first, alternating between computing error and updating latent representations before updating filters. This approach improves convergence rate, reducing the number of epochs needed for convergence. After \u03ba update steps, a single update step is used to update the filters. The learning process involves updating filters and latent representations using a single update step. The network's capabilities in inferring latent representations for images are studied, including reconstructing original images, inferring representations for translated images, and estimating representations for new images. A 5-layered neural network was trained on 1000 images of horses and ships from the CIFAR-10 dataset. The learning algorithm estimates latent representations for input images at each layer in the model. These representations are propagated from layer to layer, resulting in a reconstruction of the original image. The reconstructed images from the model are blurry compared to the originals, as shown in FIG2. The model reconstructs images that are blurry compared to the originals due to mean square error. To improve visual quality, l1-norm is suggested. To study translation invariance, images are shifted and presented to the model without re-learning filters. Latent representations for translated images are inferred at each layer in the network for reconstruction. The network can generate latent representations for translated images that capture input stimulus information. Latent representations for images outside the training set are inferred and used to reconstruct original images. The model can infer latent representations for images not used in training, such as frog, cars, truck, sparrow, due to the retinotopic arrangement of receptive fields in the network. This architecture captures granular regularities in real-world images, aiding in generating latent representations for unforeseen objects. The model can infer latent representations for various objects, generating abstract representations from input images. It achieves generalization with only 1000 training images, unlike most machine learning algorithms. Deep neural networks have enhanced image processing tasks like classification and segmentation. The advancements in image processing, such as classification and semantic segmentation, have been made possible by leveraging affordable computational power. However, as neural network architectures become more complex, the challenge of developing efficient learning algorithms becomes more prominent. While error-backpropagation is commonly used for training deep neural networks, its inherent limitation in parallelization has led to the proposal of a new extensively parallelizable learning algorithm. The learning algorithm proposed in this paper can be extensively parallelized, allowing for updating latent representations and filters at each layer in parallel. This approach is useful for speeding up the training of deep neural architectures and is similar to deconvolutional neural networks. Deconvolutional neural networks are used to learn latent representations for input images and for semantic segmentation. The problem of learning latent representations is complex, requiring optimization on auxiliary variables. Predictive coding offers an alternative solution to this issue. In Equation 6, the update term associated with td constraint guides the learning algorithm to create latent representations easily predicted by successive network layers, similar to auxiliary variables in deconvolutional neural networks. This method simplifies learning latent representations without the need for optimizing auxiliary variables, using predictive coding in deep neural networks for modeling cortical sensory hierarchies. The architecture respects the retinotopic arrangement of receptive fields in visual processing. The architecture respects the retinotopic arrangement of receptive fields in visual processing and can be used to build a deep generative model for data in any modality. Trained on a small dataset of 1000 images of horses and ships, the model can effectively infer latent representations for images of other objects like sparrows, cats, trucks, and cars, showcasing its ability to capture statistical regularities in real-world images. The generalization ability of the model surpasses existing algorithms that typically require larger datasets for better performance. The network in the architecture uses filters of dimension 5 \u00d7 5 and doubles the number of filters in each successive layer. Neurons in all layers use a linear activation function. Training parameters are set gradually to avoid large update steps causing learning problems. The training parameters for the network are adjusted gradually to prevent learning issues. Parameters such as bu, td, and p are increased during training. The losses are calculated using the l2-norm, which may lead to blurry reconstructions. Using the l1-norm could result in more visually appealing images. Results on generative modeling and translation invariance using the trained model are presented, showing images reconstructed by the generative model. The section presents results on generalization using a trained model, showing non-training images reconstructed by a generative model using latent representations. Images are arranged in a table with 2 columns, each cell containing a set of five images - the original image and 4 reconstructed images."
}