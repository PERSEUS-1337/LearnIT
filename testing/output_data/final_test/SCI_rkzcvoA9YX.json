{
    "title": "rkzcvoA9YX",
    "content": "Few-shot learning trains image classifiers with few examples per category, posing challenges for optimization algorithms. Distance-learning-based approaches embed images into a metric space and use nearest neighbor classifiers for new categories. The proposed model exploits object-level relation to learn image relation features, allowing for generalization to new categories without fine-tuning. Experimental results show that our approach outperforms state-of-the-art methods on benchmark datasets. Real-world data often follows power-law distributions, with limited examples for certain categories like local dishes or new products. Deep convolutional neural networks require a large amount of data, but fine-tuning with transferred knowledge still falls short due to the need for many iterations over numerous examples. Algorithms for adapting ConvNets to new categories require many iterations over examples. Two approaches are few-shot image classification: meta-learning-based methods like BID12 and embedding learning-based methods like BID17. Nearest neighbor search is used for classifying images from new categories without fine-tuning. In this paper, a new few-shot learning approach is proposed, inspired by human ability in few-shot learning. The approach emphasizes the importance of embedding functions for classification accuracy and similarity evaluation between images of unseen categories. The example of recognizing a Segway based on familiar components like wheels demonstrates the effectiveness of relationship-awareness in image analysis. The learning model in this study focuses on object-level information and relation extraction to distinguish images from different categories. It consists of a relation extraction network and a distance learning network, inspired by the relation network BID14. The training is conducted in episodes with few examples for each category, and after training, relation feature vectors are extracted for image classification. Few-shot image classification involves training image classifiers with few examples per category, useful for recognizing new categories like products. The approach in this study utilizes relation feature vectors to classify query images against labelled images from the test dataset using a nearest neighbour classifier. Extensive experiments show the superiority of this method in terms of classification accuracy. The related work includes meta learning and embedding learning approaches, with the use of ConvNets being common in few-shot image classifiers. Meta learning is a solution for optimizing ConvNets in few-shot image classification by training a meta learner to guide the optimization algorithms for fine-tuning the classifier. The meta learner is trained iteratively on episodes sampled from the training dataset with the same settings as the test scenario. After training, the meta learner improves optimization of the classifier for test episodes by learning good parameter initialization. Different approaches include Meta-SGD generating initialization and learning rate, BID12 using LSTM for fine-tuning updates, and embedding learning to project images into an embedding space for classification. Our approach leverages object relations to learn image relations, unlike previous methods that focus on comparing images within episodes. Relation network BID14 models object relations within images, achieving good performance in visual question answering by comparing pairs of objects through feature concatenation. In this paper, the relation network is adapted to extract object relations from different images to measure the relation between two images. Object-level relation helps determine image relation, and relation features are fed into a metric learning network for differentiating similar and dissimilar images in training episodes. For few-shot image classification, a support set of labeled images is given for C-way K-shot classification tasks. The task involves C-way K-shot classification, where images are classified into C categories using a support set and query set. To address the challenge of training an effective ConvNet with a small K, a metric learning based solution is used with a separate training dataset. This dataset has a different label space and the model is trained to measure image similarity. By leveraging object-level relations, the model can effectively classify support and query images for unseen categories. Our model for C-way K-shot classification utilizes a CNN for feature extraction, object relation learning, and image relation learning. Object-level relations persist across training and test images, even with disjoint label spaces. Nearest neighbor search is used as the classifier to avoid challenges with gradient-based optimization algorithms. The model enforces a sufficient margin between similar and dissimilar pairs for good classification. The model for C-way K-shot classification utilizes a CNN for feature extraction and object relation learning. The input consists of two images, p and q, which go through the same ConvNet to extract feature maps. These maps are then combined for comparison and object-level relation learning using another network g. The model for C-way K-shot classification utilizes a CNN for feature extraction and object relation learning. The input consists of two images, p and q, which go through the same ConvNet to extract feature maps. These maps are then combined for comparison and object-level relation learning using another network g. The extracted relation is between the query image p and the category q. For the case of K > 1, feature maps of images from the same category are averaged to get the category feature, used in Prototypical Network. The dataflow for the remaining steps is the same as for one-shot classification. The model is trained in episodes for C-way K-shot classification. Support set images are sampled for each episode, along with query images. Ground truth similarity is set based on whether images are from the same class. The model is trained to differentiate classes within the same episode. Our approach aims to improve few-shot learning by exploiting object-level relations. Experimental results on benchmark datasets like Omniglot and miniImageNet confirm the effectiveness of our method. The C-way K-shot classifier is trained by sampling classes and examples per class for each training episode. The experiments on two datasets are introduced in the following subsections. The network configuration is detailed in FIG2, with 'Conv' representing a block of 3 layers. Previous papers resized images to 28x28 or 20x20, resulting in small feature maps. To obtain larger feature maps for object relation modeling, input images are resized to 84x84, resulting in 64 feature maps of size 7x7. The network processes 2401 object relation features independently through a MLP model with hidden layers following RelationNet BID14. The output feature of each relation is of dimension 256. All features are summed into a single feature and fed into h to generate the similarity score. The experiments show that overfitting is not a problem even with no weight decay, possibly due to the effect of averaging object relation features similar to ensemble modeling. The approach is compared with existing methods. Our approach is compared with existing methods on various classification tasks, including 5-way 1-shot, 5-way 5-shot, 20-way 1-shot, and 20-way 5-shot. Results show that our approach outperforms others, with comparisons between meta-learning and metric-learning based approaches. Fine-tuning is necessary for meta-learning but not for metric-learning, which may affect performance. Our results are averaged over 600 test episodes with 95% confidence intervals and reported variances. Our approach outperforms existing methods for 3 out of 4 tasks, especially for 20-way tasks which are more difficult. To confirm our advantage, we compare against another dataset, miniImagenet BID17, with 100 classes and 600 examples each. No data augmentation is conducted. The network configuration for f and g is shown in FIG7, with f generating 64 feature maps of size 10x10. g processes the 10,000 combinations independently via a 4 layer MLP model. Four tasks are conducted for evaluation, including 5-way 1-shot. No data augmentation is conducted on miniImageNet. The evaluation of the model includes 5-way 1-shot, 5-way 5-shot, 20-way 1-shot, and 20-way 5-shot classification tasks. Results show significant improvement over existing methods, especially for 20-way tasks. The approach utilizes object-level relation to infer image relation by considering each 'pixel' on the feature map as an object in the input image. Our model captures object pairs from different locations, utilizing multiple local patches to determine image relations. Comparison with Learning2Compare shows improved accuracy for 5-way 1-shot and 5-way 5-shot tasks. The model compares the accuracy of 5-way 1-shot and 5-way 5-shot tasks, showing improvements with larger feature map sizes. Increasing object number enhances performance, indicating the importance of objects-level relation. The model aggregates local information for global reasoning, focusing on spatial local information but extensible to other types. Comparing feature maps from different images can generate local relation features. In this paper, the model focuses on zero-shot learning by comparing local text and image information. It avoids fine-tuning by training a general model to learn image relations from unseen categories. Object-level relation is utilized to infer image relations, showing persistence across training and test images. Our approach utilizes object-level relation to infer image relations, extracting features for similarity learning in few-shot image classification tasks, outperforming existing algorithms."
}