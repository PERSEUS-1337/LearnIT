{
    "title": "SJxSDxrKDr",
    "content": "The proposed method combines adversarial training and provable defenses to train neural networks. It involves a verifier certifying the network using convex relaxation while an adversary tries to find inputs that cause verification to fail. Experimental results show that this method achieves state-of-the-art accuracy (74.8%) and certified robustness (55.9%) on the CIFAR-10 dataset with a 2/255 L-infinity perturbation, surpassing previous results with a smaller network. Deep learning has led to the need for new training methods to create accurate and robust neural networks with guarantees. Adversarial training is a framework that enhances training with adversarial inputs to improve robustness. Madry et al. demonstrated that adversarial training can produce highly robust models against attacks. However, the method lacks guarantees when implemented practically. Recent work has focused on training neural networks to be certifiably robust under specific attacker threat models, but this comes at the cost of lower standard accuracy compared to adversarial training. This study aims to combine adversarial training techniques and provable defense methods to achieve high accuracy and certified robustness in neural networks. The study combines adversarial training techniques with provable defense methods to achieve high accuracy and certified robustness in neural networks. It introduces a new optimization procedure inspired by adversarial training, bridging the gap between adversarial training and provable defenses. The method uses convex relaxations to certify properties of the network and incorporates latent adversarial examples into the training scheme. The method combines adversarial training with provable defenses to achieve high accuracy and certified robustness in neural networks. It introduces layerwise adversarial training, bridging the gap between adversarial training and existing defense methods. Experimental results show promising outcomes on the CIFAR-10 dataset with 2/255 L \u221e perturbation. The method presented in this work achieves state-of-the-art accuracy and certified robustness on CIFAR-10 with 2/255 L \u221e perturbation. Future work could explore different convex relaxations. Previous work includes adversarial defenses and training models with projected gradient descent to be robust against attacks. The text discusses the robustness of defense mechanisms against adversarial attacks, with some approaches providing robustness guarantees but limited practical use due to low accuracy. Recent work has focused on certifying general neural networks using methods like SMT solvers, mixed-integer linear programs, abstract interpretation, and restricted polyhedra. Another approach involves replacing neural networks with a randomized classifier for probabilistic guarantees on robustness. This paper considers a general verification problem where the input is not limited to an Lp ball but an arbitrary convex set. In this work, a threat model is considered where an adversary can transform an input into any point within a convex set. The approach involves layerwise adversarial training to bridge the gap between standard adversarial training and provable defenses for neural networks. The goal is to certify a trained neural network model using convex relaxations. The text discusses certifying a neural network model using convex relaxations, highlighting the challenge of proving properties like robustness due to errors introduced by the relaxation process. The method involves replacing regions with convex relaxations, which may lead to failure in certifying desired properties. The text discusses training neural networks to minimize latent adversarial examples by optimizing through convex relaxations. Adversarial training and provable defenses are seen as different ends of the same spectrum, aiming to minimize loss in different convex regions. Adversarial training in layerwise fashion is proposed to eliminate latent adversarial examples from hidden layers and obtain a provable network. The initial phase involves finding inputs that maximize cross-entropy loss in C0(x) and updating parameters to minimize the loss using SGD, resulting in a robust model against multi-step adversaries. However, certification of this robustness often fails. The training method involves propagating the initial convex region through the network, finding a concrete point inside it, and updating parameters to minimize loss. This process aims to eliminate latent adversarial examples and create a provable network. Our training method involves updating network parameters to minimize loss without backpropagating through the convex relaxation in the first layer. By freezing the first layer and stopping backpropagation after the second layer update, the optimization problem becomes easier. This approach extends the robust optimization method and involves solving a min-max optimization problem at each step. Our approach involves solving a min-max optimization problem for each layer using projected gradient descent. We initialize batches with random sampling and update x in the direction of the loss gradient, projecting it back to the convex region. An efficient projection method is required for the specific convex relaxation used. The training algorithm is instantiated for a convex relaxation based on linear approximations. To certify neural networks, linear relaxations are used for convex regions represented by center vectors and affine transformations. The initial convex region is defined by a diagonal matrix. Propagation of convex regions through the network involves handling convolutional and fully connected layers by multiplying matrices A and a. ReLU activation is managed by applying a convex relaxation, allowing for the recursive computation of all convex regions. The matrix A can be computed without explicitly constructing it, and projection to linear convex regions is achieved using the training method described. Projection to linear convex regions is achieved by instantiating Algorithm 1 with a suitable projection operator \u03a0 C l (x). Instead of directly solving for x, we solve for e which uniquely determines x. The domain of e is a hyperrectangle [\u22121, 1] m l, making it easy to project to. Visualized in Figure 2, we project the red point x to the convex region C l (x) by first changing variables to obtain the blue point \u03a0(e), then transforming back to get the blue point \u03a0(x). The algorithm is modified to update coefficients and x values. Sparse representation is used to handle memory-intensive matrix A l. After updating coefficients and x values, the algorithm leverages the observation that non-zero elements in matrix A l+1 are determined by non-zero elements in its convolutional kernel in matrix A l. This optimization allows for precomputing positions of non-zero elements in A l+1 and computing their values through matrix multiplication, crucial for enabling efficient training. Future work includes optimizing the relaxation further and developing memory-friendly relaxations for scaling training to larger networks. Post-training, certification techniques are used to certify properties like robustness, enhancing certification performance without impacting training speed. The linear relaxation of ReLU used is parameterized by slopes \u03bb. During training, the slopes \u03bb of the linear relaxation of ReLU are chosen to minimize the area of the relaxation. However, during certification, \u03bb values can be optimized to minimize the maximum loss within the convex region. This optimization problem is computationally expensive during training but feasible during certification by approximating the solution using the Adam optimizer. The idea of learning the slope is similar to previous work, but here it stays in the primal formulation. During layerwise adversarial training, the network is trained to be certified on all regions C0(x), ..., Ck(x) by propagating bounds using convex relaxations. The exact bounds Sl(x) are computed using Mixed-Integer Linear Programming (MILP) solver to ensure correctness property is not violated. Linear constraints are used to represent the region Cl(x), enabling this approach. In the context of layerwise adversarial training, the network is trained to be certified on various regions by using convex relaxations and MILP encoding. The method includes tightening convex regions and evaluating on the CIFAR-10 dataset using Gurobi as a MILP solver. The implementation is in PyTorch with plans to release code and trained models. The neural network architecture consists of a 4-layer convolutional network with specific filter sizes, kernel sizes, and strides. Training involves batch size 50, L1 regularization, and optimization using Adam with a decreasing learning rate. Certification is performed using linear relaxations after training completes. The neural network architecture consists of a 4-layer convolutional network with specific filter sizes, kernel sizes, and strides. Training involves batch size 50, L1 regularization, and optimization using Adam with a decreasing learning rate. Certification is performed using linear relaxations after training completes. For image certification, linear relaxations are initially attempted, followed by MILP encoding if necessary. If certification fails, ReLU activation is encoded using additional binary variables. Results are compared to prior work on L \u221e perturbation 2/255, showing improvements. The neural network architecture, trained with specific techniques, outperforms existing approaches in terms of accuracy and robustness for perturbations of 2/255 and 8/255. Results are compared in Table 2, showing significant improvements over prior work. The new method presented achieves high accuracy compared to existing approaches but falls short in certified robustness. The 4-layer network lacks capacity for robustness, with empirical results not exceeding 34%. Future work may focus on improving memory efficiency for better results at 8/255 perturbations. The method presented combines techniques for training certified neural networks, achieving state-of-the-art accuracy and robustness on CIFAR-10. Future work includes scaling to larger networks with tight convex relaxations for efficient projection. The method combines techniques for training certified neural networks, achieving high accuracy and robustness on CIFAR-10. The relaxations proposed in previous studies are described using new notation to compute convex regions efficiently. The method combines techniques for training certified neural networks on CIFAR-10, achieving high accuracy and robustness. It explains the transformation of an element x i,j and computes lower and upper bounds. The ReLU function is defined with coefficients \u03bb i,j and \u00b5 i,j. The computation can be written in matrix form, and a new convex region C i+1 (x) is defined. Random projection approach is used to estimate bounds during training, applicable in both dual and primal frameworks. The method of random projections is used to estimate the L1 norm of each row in matrix A i efficiently. By sampling a standard Cauchy random matrix R, the estimation is calculated as ||A i || 1 \u2248 median(|A i R|). This approach avoids computing the entire matrix A i by substituting M 0 = A 0. In this section, additional results on SVHN and MNIST datasets are presented. The experiment on SVHN dataset involved using a convolutional network with 2 layers, followed by a fully connected layer with ReLU activation. Training involved starting with a perturbation 10% higher than the one being certified, decreasing by 5% per layer, and using L1 regularization factor 0.0001. Results showed higher accuracy and certified robustness compared to other networks. Our network demonstrated higher accuracy and certified robustness compared to other techniques for provable defense. In the experiment on the MNIST dataset, a convolutional network with 2 layers and ReLU activation was used, with perturbation starting at 10% higher than certified and decreasing by 5% per layer. Each layer was trained for 50 epochs with L1 regularization factor 0.00001. Results for perturbations of 0.1 and 0.3 showed comparable performance to state-of-the-art approaches. For perturbation 0.3, convolutional layers have filter sizes 32 and 128, and fully connected layer has 400 neurons. Certified robustness is somewhat lower than state-of-the-art due to imprecise estimates of lower and upper bounds via random projections. MNIST dataset may require exact propagation instead of estimates, but this increases runtime cost. L1-norm regularization induces sparsity in weights, leading to more stable ReLU units and tighter convex relaxation. In the i-th phase of training, a loss based on the volume of convex region C i+1 is introduced to tighten the relaxation and minimize the volume. For each neuron j in layer i + 1, a loss of the form max(0, \u2212l i+1,j ) max(0, u i+1,j ) is added to correspond to the area under ReLU relaxation. This approach aims to make the convex relaxation tighter."
}