{
    "title": "Hkg313AcFX",
    "content": "In this paper, the acceptance rate of the Metropolis-Hastings algorithm is proposed as a universal objective for learning to sample from a target distribution. This perspective unifies approaches like Markov Chain Monte Carlo (MCMC), Generative Adversarial Networks (GANs), and variational inference. The lower bound on the acceptance rate is derived and treated as the learning objective for explicit and implicit samplers. Empirical validation is done on Bayesian inference for neural networks and generative models for images. The Bayesian framework and deep learning have become increasingly interconnected, with Bayesian deep neural networks being used for uncertainty estimation and ensembling. Bayesian deep neural networks are utilized for estimating uncertainty, ensembling, and model compression. Deep neural networks can also enhance approximate inference in Bayesian models. Learning modern Bayesian neural networks involves inference in high-dimensional spaces by conditioning the weights of DNN on numerous objects. Approximate inference is typically done through sampling from the posterior with MCMC methods or approximating the posterior with VI methods. MCMC methods require careful hyperparameter tuning, especially for large datasets and high-dimensional problems. One way to address high dimensionality in Bayesian inference is through the design of proposal distributions, such as scaling the variance for the Metropolis-Hastings algorithm. More complex designs include adaptive updates of the proposal distribution. Another approach is the combination of adaptive direction sampling and the multiple-try Metropolis algorithm. Variational inference, while scalable, provides a biased estimate of the target distribution. The doubly stochastic procedure allows for application to large datasets and high dimensional spaces. Variational inference (VI) can handle large datasets and high dimensional spaces like neural network weights. The bias from variational approximation can be reduced with flexible approximations and resampling. Generative Adversarial Networks (GANs) offer a different approach to learning samplers efficiently. GANs, VI, and MCMC share the goal of \"learning to sample.\" This paper introduces a new perspective on learning to sample by optimizing parameters of explicit or implicit probabilistic models. The objective is inspired by the acceptance rate of the Metropolis-Hastings algorithm as a quality measure of the sampler. A lower bound on the acceptance rate is derived and maximized with respect to sampler parameters. The paper introduces a new perspective on learning to sample by optimizing parameters of probabilistic models. It derives a lower bound on the acceptance rate and maximizes it with respect to sampler parameters in the Metropolis-Hastings scheme. Two forms of the target distribution are considered: unnormalized density and a set of samples. The approach connects to Variational Inference (VI) in the density-based setting and to Generative Adversarial Networks (GANs) in the sample-based setting. The method is free from hyperparameters, directly optimizes the acceptance rate, and avoids minimax problems in the density-based setting. The paper introduces a novel perspective on learning to sample by optimizing the acceptance rate in the Metropolis-Hastings algorithm. It derives a lower bound on the acceptance rate for doubly stochastic optimization of the proposal distribution. The proposed algorithm is connected to variational inference and GANs for different forms of target distributions. The paper discusses optimizing the acceptance rate in the Metropolis-Hastings algorithm for sampling from target distribution p(x). The quality of the proposal distribution is measured by acceptance rate and mixing time, with the acceptance rate defining a semimetric in distribution space between p and q. The paper proposes maximizing a lower bound on the acceptance rate in the Metropolis-Hastings algorithm by expressing it in terms of total variation distance. This approach compares favorably to directly optimizing the acceptance rate, as shown in experiments. The optimization problem is formulated to maximize this lower bound, offering benefits in different settings. The paper demonstrates the benefits of optimizing the acceptance rate in the Metropolis-Hastings algorithm by maximizing a lower bound expressed in terms of total variation distance. This optimization problem is shown to be effective in two different settings - when the target distribution is given as unnormalized density or as a set of samples. The proposed algorithms can also be used for direct optimization of the acceptance rate. In the density-based setting, an explicit proposal distribution is used to compute the density ratio, while in the sample-based setting, the density ratio is approximated via adversarial training. In the density-based setting, the proposal is assumed to be an explicit probabilistic model that can be sampled from and evaluated at any point. During optimization of the acceptance rate, there may be issues with the proposal collapsing to a delta-function, especially with a Markov chain proposal. More details and empirical evidence are provided in the following sections. The paper discusses explicit probabilistic models as proposals in the density-based setting to avoid collapsing to a delta-function. Two types of explicit proposals are considered: simple parametric families and normalizing flows. Normalizing flows allow for expressive proposals and evaluation of density in the target distribution space. Invertible models like normalizing flows are suitable for independent proposals due to ergodicity. The objective of the optimization problem is to find the explicit form of the proposal. The paper discusses explicit probabilistic models as proposals in the density-based setting to avoid collapsing to a delta-function. Two types of explicit proposals are considered: simple parametric families and normalizing flows. Normalizing flows allow for expressive proposals and evaluation of density in the target distribution space. Invertible models like normalizing flows are suitable for independent proposals due to ergodicity. The optimization problem involves obtaining density ratios for proposal and target distributions, estimating loss, obtaining samples from the target distribution, and performing optimization steps using stochastic gradients. Algorithm 1 outlines the optimization procedure for the proposal distribution in density-based cases, which can also be used for direct optimization of the acceptance rate in Bayesian inference problems. The algorithm is applied for Bayesian inference, using minibatches of data during optimization of the lower bound. A discriminative model is considered for a dataset, with known likelihood and prior distribution. Predictive distribution is evaluated for object x_i, and samples from the posterior distribution are obtained using a proposal distribution and independent MH algorithm. The objective function is rewritten to minimize KL-divergence, split into two KL-divergences due to independent proposal usage. The optimization problem involves minimizing two KL-divergences, with the first one corresponding to variational inference and the second one depending on \u03c6. Unbiased estimation of the gradient is suggested using minibatches of data, along with techniques that utilize the independent MH algorithm with minibatches. This approach allows for using only minibatches of data during algorithm iterations, avoiding biased gradients in the direct optimization of the acceptance rate. In the direct optimization of the acceptance rate, the proposal is assumed to be an implicit probabilistic model, with the possibility of using a neural network as the proposal distribution. This approach helps exclude the delta-function from the solution space and prevents learning the identity mapping by utilizing neural networks with bottleneck and noisy layers. The text discusses using a discriminator network for density ratio estimation in Monte Carlo estimation of loss. The discriminator aims to distinguish between images from the true distribution and those generated by a proposal distribution. The optimal discriminator output is calculated, but in practice, there is no perfect discriminator, leading to variations in density ratio estimation. The text suggests using a special structure discriminator for density ratio estimation in Monte Carlo loss estimation. Algorithm 2 optimizes the proposal distribution using a convolutional neural network with softmax operation. This approach can also be used for direct optimization of the acceptance rate. In Appendix B.2, an intuition is provided for the struggles of direct optimization of acceptance rate due to vanishing gradients. Experiments in density-based and sample-based settings show the proposed procedure is effective for high dimensional target distributions. Code for replicating experiments will be available. Performance is demonstrated using synthetic 2d distributions like ring, mog2, mog6, and ring5. Effective Sample Size is used to measure sampler performance. Learning proposals is possible with unnormalized densities of target distributions in the density-based setting. In the density-based setting, distributions are given, and proposals are learned using the RealNVP model. Performance is compared with Markov chain proposals like A-NICE-MC and Hamiltonian Monte Carlo. Results show comparable performance with A-NICE-MC, but the focus is not on comparing with Markov chain proposals. Markov chain proposals use more information while generating samples, allowing for a more expressive stationary distribution. In the density-based setting, proposals are learned using the RealNVP model. Comparing two independent proposals: one maximizes acceptance rate, the other uses variational inference. Results show acceptance rate outperforms variational inference for all target distributions. Variational inference fails to cover all modes of mog6, unlike acceptance rate proposals. Densities of learned proposals and histograms are provided in the appendix. In Bayesian inference for neural network weights, the focus is on approximating the predictive distribution. The efficiency of optimizing the lower bound on acceptance rate is highlighted, raising questions about the effectiveness of the proposed objective compared to variational inference. The use of the Metropolis-Hastings correction on the learned proposal distribution is also questioned for improving predictive distribution estimation. The study involves a reduced LeNet-5 architecture for a classification task on MNIST dataset images. The study involves a challenging task of learning a complex distribution in an 8550-dimensional space using a fully-factorized Gaussian proposal distribution. Variational inference is utilized with different initializations, selecting the model with the best ELBO. Sampling from the posterior distribution is proposed using independent Metropolis-Hastings and the current proposal, starting with the mean as an initial point. The study uses a fully-factorized Gaussian proposal distribution to learn a complex distribution in an 8550-dimensional space. Independent Metropolis-Hastings algorithm is applied to estimate the predictive distribution, optimizing the acceptance rate for better estimation. Two ways of estimating predictive distribution are compared: performing MH correction after each epoch and taking samples without correction. The study compares the estimation of predictive distribution using MH correction and without it. The MH correction improves the estimation for variational inference but not for optimizing the acceptance rate lower bound. The goal is to compare the optimization of acceptance rate and lower bound efficiency in sample-based setting. In a sample-based setting, the study compares optimizing the acceptance rate and its lower bound efficiency. Questions include the benefits of lower bound optimization, mixing issues with learning Markov chain proposal, and improving sample visual quality with MH correction. DCGAN architecture is used for proposal and discriminator, applied to the MNIST dataset for two optimization problems. Samples are obtained either directly from the learned proposal or through the MH algorithm using the learned discriminator for density. The study compares optimizing acceptance rate and its lower bound efficiency in a sample-based setting using DCGAN architecture on the MNIST dataset. Samples are obtained directly from the learned proposal or through the MH algorithm with a learned discriminator for density ratio estimation, showing improved visual quality. The study compares optimizing acceptance rate and its lower bound efficiency in a sample-based setting using DCGAN architecture on the MNIST dataset. The proposal obtained via optimization shows different distributions of samples due to conditioning. Samples from the proposal exhibit the Markov property when conditioned on different points in the dataset. The paper proposes using the acceptance rate of the MH algorithm as a universal objective for learning to sample from a target distribution. It suggests a lower bound on the acceptance rate for better results and offers ways to improve by combining techniques from MCMC, GANs, and variational inference. The paper suggests using the acceptance rate of the MH algorithm as a universal objective for learning to sample from a target distribution. It proposes a lower bound on the acceptance rate and ways to improve by combining techniques from MCMC, GANs, and variational inference. Additionally, it discusses learning the Markov chain proposal in the density-based setting and using stochastic Hamiltonian Monte Carlo for loss estimation. Advanced techniques of density ratio estimation in a sample-based setting are also mentioned. Further exploration and rigorous treatment are needed for applying the MH algorithm to enhance generative models. The paper also delves into proving equalities involving random variables. The formula for the acceptance rate is derived by summing equations and rewriting it in terms of \u03be. The appendix proves that E \u03be |\u03be \u2212 1| is a semimetric in the space of distributions. An example where the triangle inequality does not hold is given, but a weaker inequality can be proven. Optimization of the proposal distribution is discussed, with a focus on the gaussian random-walk proposal. It is shown that the acceptance rate can approach 1 by choosing a small enough \u03c3. The issue of collapsing to the delta-function is not present in the independent proposal case. In the independent proposal, the issue of collapsing to the delta-function is not present. Sampling on a finite support is approximated with the independent Metropolis-Hastings algorithm. The optimization of the lower bound involves a truncated normal distribution and KL-divergence calculations. In the context of optimizing the lower bound with KL-divergence calculations, the derivative of the lower bound with respect to \u03c3 is shown to be negative, indicating that increasing \u03c3 can improve the loss without collapsing to a delta-function. The sample-based setting suggests that the loss function for the lower bound has better gradients than the acceptance rate. The loss function for the lower bound has better gradients than the acceptance rate. In the sample-based setting, a discriminator is used for density ratio estimation with a special structure. Gradients are evaluated using Monte Carlo estimations for each loss, and optimization is done for both acceptance rate and lower bound. Comparing equations 59 and 62 shows differences in optimization approaches. In the sample-based setting, a discriminator is used for density ratio estimation with a special structure. Gradients are evaluated using Monte Carlo estimations for each loss, and optimization is done for both acceptance rate and lower bound. Comparing equations 59 and 62 shows differences in optimization approaches for bimodal Gaussian target distribution and unimodal Gaussian proposal distribution. The output y is evaluated using a formula with arbitrary complex functions. 4 coupling layers with hidden dimensions of 256 are used. Synthetic distributions are considered, and the effective sample size formulation follows a specific method. The text discusses the empirical estimation of autocorrelation in sampling, truncating autocorrelations below 0.05 for large lags. It also explores maximizing the acceptance rate lower bound (ARLB) to increase the acceptance rate (AR), evaluating their correlation during optimization. Curves showing the acceptance rate and acceptance rate lower bound are presented in FIG9. In this section, levelplots of learned proposal densities and 2d histograms of samples from the MH algorithm using corresponding proposals are provided. Additional figures for Markov chain proposals are also shown, including samples from chains initialized with noise and after 10000 accepted samples. Samples are obtained using the MH algorithm with learned proposals and discriminators for density ratio estimation. Samples in the chain are obtained one by one from left to right starting with noise. After 10000 accepted samples, we use the MH algorithm with learned proposal and discriminator for density ratio estimation."
}