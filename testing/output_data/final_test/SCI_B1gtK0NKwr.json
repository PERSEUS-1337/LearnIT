{
    "title": "B1gtK0NKwr",
    "content": "The text presents a verification method for neural networks in perception tasks, ensuring correct outputs within a specified tolerance for all relevant inputs. By defining correctness relative to a state space and observation process, the technique provides tight error bounds for all inputs of interest. Neural networks lack correctness guarantees for all inputs of interest, with error bounds varying over state and input spaces. Robustness verification only ensures stability around local regions, not for all inputs, and does not guarantee correct outputs. Neural networks lack correctness guarantees for all inputs except the manually-labeled center point of each region. The first verification of neural networks for perception ensures correct output within a specified tolerance for every input of interest, defined relative to a state space and observation process. Feasible input space is defined as inputs that can be observed from the state space. The state of the world defines the ground truth output predicted by the network. Tiler is an algorithm for correctness verification of neural networks that covers state and input spaces with tiles to provide ground truth bounds for inputs. It generalizes the idea of evaluating network correctness on a single state to work with tiled spaces. The Tiler algorithm uses techniques from robustness verification literature to obtain network output bounds for input tiles, comparing them to ground truth to determine error bounds. Two case studies are presented, one involving a camera predicting offset and viewing angle in a world with a fixed road. The observation process involves mapping camera positions to images in a state space. Feasible input space consists of camera images observable from all camera positions of interest. State space is tiled using a grid on (\u03b4, \u03b8) to provide ground truth bounds. The observation process projects each state tile into image space, with bounding boxes computed for each input tile. Techniques from robustness verification are applied to obtain neural network output bounds, allowing for comparison of ground truth and network predictions to determine error bounds. The neural network is verified for accuracy across the state space of interest, with maximum error bounds identified. A case study involves classifying LiDAR measurements of signs into shapes, using state spaces and observation processes to specify correctness. The Tiler algorithm is the first systematic approach for global correctness specification of perception neural networks. It verifies that a neural network produces the correct output for every input of interest, with the ability to compute tighter correctness bounds for specific regions. A case study on predicting camera position and classifying sign shapes from LiDAR measurements demonstrates the first correctness verification for perception tasks. Researchers have developed techniques to verify the robustness of neural networks to adversarial attacks, aiming to ensure stability in the network's predictions within a selected input point's neighborhood. Various approaches include reachability analysis, abstract interpretation, bounding the local Lipschitz constant, formulating networks as constraints, solving optimization problems, and utilizing SMT/SAT solvers. Prior research on neural network testing focuses on constructing better test cases to expose problematic network behaviors, such as improving coverage on possible states of the network. Unlike prior research, this paper formalizes and attempts to verify that a neural network computes correct outputs within a specified tolerance for all inputs of interest. Coverage-guided fuzzing methods are presented for testing neural networks. The research presented in this paper verifies correctness for all inputs of interest in neural network testing, unlike prior research that focuses on constructing better test cases for coverage. The paper discusses methods for testing neural networks, including generating realistic test cases and using simulation for autonomous driving systems with deep learning perception. The text discusses the mapping of inputs to outputs in a neural network, where the input observation x corresponds to a state of the world s. The feasible input space X is defined as the inputs observable from the state space S, and the ground truth of the output y is determined by a function \u03bb. The paper focuses on verifying correctness for all inputs in neural network testing, rather than just improving test case coverage. The text discusses how a neural network computes an approximation of the ground truth mapping, which is determined implicitly by the input space X, state space S, and functions g and \u03bb. The error of the neural network is measured by the difference between the computed approximation and the ground truth. For regression, the error is measured by the absolute difference between predicted and actual values, while for classification, it is measured by a binary error indicator. The goal is correctness verification for all inputs in neural network testing. The text discusses correctness verification for neural networks by computing upper bounds on prediction errors with respect to the specification. An algorithm called Tiler is presented for regression settings, dividing the state space into tiles and computing error bounds. The algorithm for classification settings is similar. The text discusses methods for bounding neural network outputs over input regions. Various techniques have been developed, such as layer-by-layer reachability analysis and constrained optimization problems. Each method is tailored to specific network types and input regions. For each input tile, a bounding box is introduced that includes the tile and is supported by the solving method. The text discusses bounding neural network outputs over input regions using specific solving methods. Bounding boxes are computed for each tile to satisfy certain conditions. The network output bounds returned by the solver must also meet specific criteria. Error bounds are computed for each tile to give an upper bound on prediction error. The Tiler algorithm for regression computes error bounds for inputs generated from S i. A global error bound is calculated from individual error bounds {e i}. A local error bound for feasible inputs x \u2208X can also be computed. The algorithm specifies conditions for methods DI-VIDESTATESPACE, GETGROUNDTRUTHBOUND, and GETBOUNDINGBOX to ensure sound guarantees. The choice of SOLVER must be compatible with B i and f. The returned results from these methods are used to compute e local (x). The Tiler algorithm computes error bounds for inputs from S i, with global and local error bounds {e i} and {B i}. The complexity scales with the state space dimension, executing computations in parallel. It can handle noisy observations by producing hard guarantees or probabilistic guarantees with bounding boxes B i. This adjustment accounts for cases with unbounded noise like Gaussian noise. The Tiler algorithm provides error bounds for inputs from S i, with global and local error bounds {e i} and {B i}. It can handle noisy observations by producing hard guarantees or probabilistic guarantees with bounding boxes B i. The probability measure associated with the observation process gives the probability distribution of input x given state s, ensuring correctness of the neural network over the feasible input space X. To verify if a new observed input is within X, we use the bounding boxes {B i} as a proxy for X. The Tiler algorithm provides error bounds for inputs from S i, with global and local error bounds {e i} and {B i}. It can handle noisy observations by producing hard guarantees or probabilistic guarantees with bounding boxes B i. The probability measure associated with the observation process gives the probability distribution of input x given state s, ensuring correctness of the neural network over the feasible input space X. To verify if a new observed input is within X, we use the bounding boxes {B i} as a proxy for X. In the next step, we check if x * is contained in any of the B i ' s. Utilizing the network prediction and verified error bounds, we can prune the search space by discarding tiles that do not overlap with [y * \u2212 e global , y * + e global ] in the ground truth attribute. This approach speeds up the search process by focusing on the local region in the state space with ground truth attribute close to the prediction. In the first case study, the detection method and prediction-guided search are demonstrated. The world setup includes a road with a camera positioned at a fixed height above it, able to vary its horizontal offset and viewing angle. The camera position is defined by the offset \u03b4 and angle \u03b8 within specific ranges. The input to the neural network is the camera image, with the observation process being the camera imaging process. The imaging process involves shooting rays from each pixel through the camera focal point to determine the intensity of the intersection point with objects in the scene. The resulting images are 32\u00d732 gray scale images with intensities in [0, 255]. The neural network used has 2 convolutional layers with 16 and 32 filters, followed by a fully connected layer with 100 units, all using ReLU activation functions. The neural network used for image processing has 2 convolutional layers with 16 and 32 filters, followed by a fully connected layer with 100 units. The output layer consists of 2 nodes for predicting \u03b4 and \u03b8. Training is done on 130k images and validated on 1000 images. The network is trained with an l1-loss function using Adam. Error analysis is performed separately for \u03b4 and \u03b8 predictions to find upper bounds on prediction errors. Tiler is applied to construct tiles for the problem. Each cell in the grid is encapsulated with an l \u221e -norm ball to determine the range of possible pixel values. The resulting ball covers a 32\u00d732 pixel-wise range and is used to solve the ConvNet outputs' range through a mixed integer linear program approach. The study utilizes bound tightening to enhance efficiency, modifying MILP objectives for optimization. Four problems are solved for each l \u221e -norm ball, focusing on maximizing and minimizing output entries for \u03b4 and \u03b8. Experimental results show Tiler running with a cell size of 0.1, with the optimization step taking the most time. Global error bounds are computed, verifying network correctness within specified tolerances for feasible inputs. Visualizations of the error are presented. The study uses bound tightening to optimize MILP objectives for efficiency. Visualizations of error bounds are presented by plotting heatmaps over the (\u03b4, \u03b8) space. Cumulative distributions show that most of the state space has low error bounds, with only a small percentage having larger guarantees. For offset measurement, 99% of the state space has error less than 2.65. The study presents error bounds for offset measurements, with 99% of the state space having error less than 2.65. Empirical estimates of maximum errors are computed to evaluate the tightness of the bounds, providing a lower bound estimate of the global maximum error. The error bounds for angle and offset measurements are close to lower bound estimates derived from observed errors in the network. Heatmaps show regions with large error bounds correspond to areas where the network has large errors. Cumulative distributions reveal most of the state space has error gaps below specific thresholds, indicating potential improvements on the error bounds. Interval arithmetic is used in Tiler to compute error bounds by taking the maximum distance between points. Interval arithmetic is used in Tiler to compute error bounds by taking the maximum distance between the range of ground truths and network outputs. The tile size affects the error bounds, with finer tiles providing better bounds but potentially increasing computation time. The tile size in Tiler affects error bounds, with finer tiles offering better bounds but potentially increasing computation time. Total solving time varies with cell size, with smaller sizes leading to faster solving due to pre-solving on ReLU stability. Larger cell sizes result in slower solving as the number of unstable ReLUs increases, making optimization problems harder to solve. The input detector checks if new inputs are within bounding boxes and is tested with legal and corrupted inputs. The input detector is tested with legal inputs generated from the state space through the imaging process, corrupted inputs with per-pixel perturbations, and inputs from a new scene with a wider road and double centerline. The detector successfully flags illegal inputs, providing a 26\u00d7 speedup with prediction-guided search without compromising functionality. The world contains planar signs of different shapes (square, triangle, circle) detected by a LiDAR sensor input to a neural network. The LiDAR sensor used for shape classification has a working zone with varying distance and angle parameters. It emits laser beams with a maximum range of 300 units and Gaussian noise. The observation process is detailed in the appendix. The LiDAR sensor used for shape classification emits laser beams with a maximum range of 300 units and Gaussian noise. A CNN with 2 convolutional layers and 16 filters is used for processing distance measurements. The measurements are preprocessed and scaled before being input into the network. Training is done using 50k points from each class, with validation using 500 points from each class. State tiles are constructed in three shape subspaces with specific intervals for dimensions to obtain a grid with 5400 cells per shape. The LiDAR sensor emits laser beams with a maximum range of 300 units and Gaussian noise. A CNN with 2 convolutional layers and 16 filters processes distance measurements. State tiles are constructed in shape subspaces with specific intervals for dimensions to obtain a grid with 5400 cells per shape. The verification results are plotted as heatmaps over the state space, showing correctness over the majority of the space, especially when the shape is a triangle. The finer tiling with smaller cell sizes allows for verification of more regions in the state space. Some inputs within the bounding boxes lead to different class predictions by the network. By reducing tile sizes, the extra spaces in the bounding boxes are shrunk, reducing misclassifications. The network's vulnerability in misclassifying inputs is revealed when the tile size is reduced, shrinking the extra spaces in bounding boxes. The framework systematically identifies regions where the network is not robust, based on a state space and observation process. The approach is effective for state spaces with multiple attributes and camera or LiDAR observations, with potential for application in other problems. The technique targets specific regions of the input space to verify for problems with low dimensional state spaces. It allows for directed testing and identification of illegal inputs. Theorem 1 provides a local error bound for regression under certain conditions. The Tiler algorithm is used for classification settings, following the same steps as regression. For each S i, a ground truth bound C i \u2286 Y is computed. This bound satisfies Condition 4.2(b), ensuring that for any x \u2208 X, there exists X i such that x \u2208 X i and y \u2208 C i. This technique allows for directed testing and identification of illegal inputs in low dimensional state spaces. The Tiler algorithm ensures that for any x \u2208 X, there exists X i such that x \u2208 X i and y \u2208 C i. Condition 4.2(b) is formulated for discrete y, aiming to have state tiles with only 1 ground truth class each. The network output range is computed using a softmax layer with K output nodes, solving for the minimum difference between the ground truth class and other classes. The Tiler algorithm ensures that for any x \u2208 X, there exists X i such that x \u2208 X i and y \u2208 C i. Condition 4.2(b) is formulated for discrete y, aiming to have state tiles with only 1 ground truth class each. The network output range is computed using a softmax layer with K output nodes, solving for the minimum difference between the ground truth class and other classes. Given f, B i, and the ground truth class c i, appropriate solvers are used to compute error bounds for each class, ensuring network correctness. The Tiler algorithm guarantees correct network predictions for all x \u2208 X if global error e global = 0. This is proven by showing that if e global = 0, then f(x) = f(x) for all x \u2208 X. The algorithm involves steps 1 to 5 and computes e global from Equation 6. The scene in a Cartesian coordinate system includes a road in the xy-plane, with specific camera details such as height, focal length, and pixel dimensions for imaging. The camera process involves ray tracing to determine pixel intensity values. The camera process involves ray tracing to determine pixel intensity values by transforming pixel coordinates to camera coordinates using rotation and translation matrices. The transformation matrices convert focal coordinates to world coordinates. Intensity values of pixels are scaled and quantized to [0, 255] for the final image. In a road scene example, each tile in the input space is encapsulated with a l \u221e -norm ball for the MILP solver. The method presented computes a range for each pixel covering all possible values. Upper half pixels have sky intensity, while lower half pixels intersect with the road plane. The intersection point between the projection ray from a pixel and the road plane sweeps over a closed region as the camera position varies. The range of pixel values is determined by the range of intensities in that region, which can be efficiently computed by finding the span on x for the region. Critical points at the corners of the cell and edges help determine the range of intensities, giving the range of pixel values. The LiDAR sensor consists of a stick with a sign head on top, with three possible shapes: square, equilateral triangle, and circle. The sensor emits an array of laser beams and measures distances to objects. The beams are arranged in a 32x32 grid at a distance of 4.0 from the sensor center. The LiDAR sensor has a 32x32 grid at a distance of 4.0 from the center, with a maximum measurement range of 300.0. Distances beyond this range are measured as the maximum range. Gaussian noise affects the measured distance, and bounding boxes in Tiler are computed based on the sensor's position within a tile. The intersection point between the beam and the scene determines if it is on the sign or background. The LiDAR sensor's intersection point between the beam and the scene determines if it is on the sign or background. The distance of point p varies based on sensor position within the tile, with critical distances containing the maximum and minimum distances. An exception occurs at a specific distance, where the minimum distance of p can shift between sign and background. To address this, the intersection point between the beam and the sign plane is added to the list of critical distances. The training of neural networks in the case studies includes using Adam optimizer with a learning rate of 0.01 and early stopping based on validation set loss. Training is terminated if validation performance does not improve in 5 consecutive epochs, and the model from the epoch with the lowest validation set loss is selected."
}