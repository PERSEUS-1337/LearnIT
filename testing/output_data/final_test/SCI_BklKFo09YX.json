{
    "title": "BklKFo09YX",
    "content": "Designing molecules with desired properties is a challenge in drug development, requiring optimization of compound structures. Mol-CycleGAN is introduced to generate optimized compounds with a specific chemical scaffold. The model outperforms previous results in optimizing penalized logP of drug-like molecules, aiming to find new compounds that can modulate the activity of a target protein. In drug development, computer-aided drug design (CADD) utilizes in silico methods to leverage existing chemical, pharmacological, and biological knowledge. Recent advancements in deep learning have encouraged the application of computer methods at every stage of drug design pipelines, from searching for new compounds to optimizing their activity and simulating their interaction with target proteins. The focus is on hit-to-lead and lead optimization phases. The Mol-CycleGAN model is introduced to optimize drug-like molecules in the hit-to-lead and lead optimization phases of compound design. It generates molecules with desired properties while retaining their chemical scaffolds, aiding in multiparameter optimization. The Mol-CycleGAN model is the first to use CycleGAN architecture for molecule generation, focusing on structural transformations and molecular optimization. It outperforms previous models in optimizing penalized logP for drug-like molecules, a key property in drug design. The Mol-CycleGAN model utilizes CycleGAN architecture for molecule generation, surpassing previous models in optimizing penalized logP for drug-like molecules. Deep learning in drug design involves discriminative models for virtual screening and generative models for proposing novel molecules with desired properties. Various deep learning models, such as LSTM and VAE, have been applied in compound design, with some generating invalid SMILES. The introduction of grammars into models improved the success rate of valid SMILES generation. VAEs on molecular graphs and GANs have been used for de novo drug design, with some models using RL to generate molecules with specific properties. Mol-CycleGAN is a generative model designed to generate molecules with desired properties while retaining their chemical scaffolds. It can be used for optimizing active molecules towards a given property in compound design by learning from sets of molecules with or without the desired molecular property. The approach for molecule representation in compound design involves using the latent space obtained from Junction Tree Variational Autoencoder (JT-VAE), which is based on a graph structure of molecules and shows superior properties compared to SMILES-based VAEs. This allows for easier expression of essential chemical properties on graphs rather than linear SMILES representations. Our approach extends the CycleGAN framework to molecular embeddings created by JT-VAE. Each molecule is represented by a latent vector, and the cyclic component acts as regularization. The model can learn from both directions of the transformation, resulting in a more robust model. The model defines sets X and Y, introduces mapping functions G and F, and discriminators DX. The Mol-CycleGAN model extends the CycleGAN framework to molecular embeddings created by JT-VAE. It introduces mapping functions G and F, and discriminators DX and DY. After training, optimization of a molecule involves computing its latent space embedding, using the generating function to obtain the SMILES representation of the optimized molecule. The model uses an adversarial loss to ensure the generator generates samples close to the desired distribution. The Mol-CycleGAN model uses mapping functions G and F, along with discriminators DX and DY, to optimize molecules in the JT-VAE latent space. The cycle consistency loss reduces the space of possible mapping functions, ensuring the optimized molecule is close to the starting one. Identity mapping loss further refines this process, preventing the model from generating molecules far from the original in the latent space. Hyperparameters \u03bb1 and \u03bb2 are set to 0.3 and 0.1 respectively for all experiments. The Mol-CycleGAN model uses mapping functions to optimize molecules in the JT-VAE latent space. Experiments are conducted to test the model's ability to generate molecules with desired properties and structural modifications. Optimization process aims to improve studied properties and generate similar molecules. Parameters \u03bb1 and \u03bb2 control the balance between property improvement and molecule similarity. Testing includes tasks related to structural modifications and molecule optimization. In molecule optimization, the penalized logP is selected using the SA score to describe lipophilicity. The ZINC-250K dataset is used for experiments on structural transformations and constrained molecule optimization. The model aims to improve properties and generate similar molecules with a balance between property improvement and molecule similarity. In molecule optimization, experiments are conducted on structural transformations using the ZINC-250K dataset. Constrained molecule optimization involves optimizing penalized logP while maintaining molecule similarity. Unconstrained optimization is also performed to test the model's ability to transform molecules in both directions. The experiments focus on structural properties in molecule optimization using the ZINC-250K dataset. The task involves transforming molecules by modifying the presence of halogen moieties and the number of aromatic rings. Success rates vary between the two tasks, with changing the number of aromatic rings being more challenging than altering halogen moieties. The success rates in molecule optimization tasks differ between changing the presence of halogen moieties and the number of aromatic rings. The dataset used (ZINC-250K) shows that 64.9% of molecules do not have halogen moieties, while 35.1% do. The imbalance may explain the higher success rate in removing halogen moieties. The Tanimoto similarities between generated and starting molecules confirm their closeness. In molecule optimization tasks, the procedure aims to optimize the desired property while maintaining a high similarity between the original and generated molecules. This is crucial in drug discovery, where new drugs are developed from known molecules. The optimization process involves maximizing the penalized logP coefficient and using Tanimoto similarity with the Morgan fingerprint BID28 to define the similarity threshold. The results are compared with other methods (BID18 and BID35) to evaluate effectiveness. Each molecule is represented by latent space coordinates x in the optimization process. In molecule optimization tasks, the procedure involves optimizing the desired property while maintaining similarity between original and generated molecules. The optimization path in the JT-VAE latent space is defined by pairs of molecules. Starting from 800 molecules with the lowest penalized logP values, the method outperforms previous results in improving property values. Results are shown in TAB1, demonstrating success rates for different similarity constraints. Our model shows comparable success rates for \u03b4 values of 0 and 0.2, but lower rates for \u03b4 values of 0.4 and 0.6. While reinforcement learning can also improve penalized logP, resulting molecules may not be druglike. In our method, druglikeness is inherent in the latent space obtained from training on molecules from ZINC. The architecture is designed for constrained molecule optimization using a variational autoencoder trained on druglike molecules from ZINC. The generator is iteratively used on molecules being optimized, leading to a decrease in similarity between starting and optimized molecules. Sets X and Y are sampled from ZINC-250K, with Y being the top 20% of molecules based on penalized logP. Each molecule is fed into the generator to obtain an 'optimized' molecule, which becomes the new input for the next iteration. This process is repeated K times to generate a set of molecules. The iterative molecule optimization process starts with 800 molecules with low penalized logP values in ZINC-250K. Results show a shift towards higher logP values with each iteration, but the improvement decreases over time. The maximum logP values also increase, leading to non-druglike molecules after many iterations. After many iterations, molecules in the latent space move away from the prior distribution. The similarity between starting molecules and optimized ones decreases over time, becoming less similar than random molecules from ZINC-250K. Mol-CycleGAN is introduced as a model for de novo molecule generation. The proposed model for de novo molecule generation can learn transformation rules from sets of compounds with desired and undesired properties. It operates in a latent space trained by JT-VAE and can generate molecules with desired structural and physicochemical properties. The model outperforms previous results in druglike molecule optimization and future work will focus on multi-parameter optimization using StarGAN BID5. Testing on cases with small structural changes leading to drastic property changes is also planned. The model for de novo molecule generation can learn transformation rules from sets of compounds with desired properties. It uses the Adam optimizer with a learning rate of 0.0001 and batch normalization during training. Different experiments involve training the models for varying numbers of epochs and using specific network architectures. Generators and discriminators are built with specific layer sizes and units for different experiments. In experiments on halogen moieties and aromatic rings, sets X and Y are defined with specific molecule characteristics. The dataset used (ZINC-250K) shows the distribution of molecules with and without halogen moieties and the number of aromatic rings. For molecule optimization tasks, the distribution of penalized logP is plotted. The distribution of penalized logP in ZINC-250K and sets used for constrained molecule optimization is shown in Figure 8. X train and Y train are non-overlapping random samples split by the median, while X test consists of 800 molecules with the lowest penalized logP values."
}