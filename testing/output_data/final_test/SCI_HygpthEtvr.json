{
    "title": "HygpthEtvr",
    "content": "In this paper, the problem of training neural networks with specific structures using nonsmooth regularization and constraints is addressed. A convergent Prox-SGD algorithm is proposed for solving the constrained nonsmooth nonconvex optimization problem. The algorithm ensures that every limit point of the sequence generated is a stationary point. The Prox-SGD is tailored for training sparse and binary neural networks, with theoretical analysis supported by numerical tests. The problem of training neural networks under constraints and regularization is addressed in this paper. The optimization problem involves parameter vector x, training examples y, training loss f, regularization r, and constraint set X. Stochastic gradient descent (SGD) is used to solve the optimization problem by drawing a minibatch of training examples at each iteration. SGD can be accelerated by replacing the instantaneous gradient estimates. The convergence of stochastic gradient descent (SGD) with momentum was initially a challenge, but it was later proven for convex functions. For nonconvex functions, the convergence proof was provided in subsequent studies. Regularization functions like Tikhonov regularization are commonly used in machine learning to promote specific structures in optimal solutions. The Tikhonov regularization and 1-norm regularization are commonly used in machine learning to promote specific structures in optimal solutions. The 1-norm regularization encourages a sparse solution in neural networks to alleviate overfitting, accelerate training, and reduce complexity. However, analyzing these regularizations can be challenging due to the nonsmooth nature of some convex regularizers like the 1-norm. In current implementations of Tensorflow, the gradient of |x| is set to 0 when x = 0, leading to slow convergence in the stochastic subgradient descent method. Regularization techniques like magnitude pruning and variational dropout are used to promote specific structures in neural networks. Explicit constraints, such as setting bounds on weights, offer an alternative to regularization but may pose challenges for stochastic gradient algorithms. Constraints do not necessarily keep weights close to their initial values, unlike regularization methods. The set X represents these explicit constraints, adding complexity to weight updates in stochastic gradient algorithms. In this paper, a convergent proximal-type stochastic gradient algorithm (Prox-SGD) is proposed to train neural networks under nonsmooth regularization and constraints. The algorithm utilizes momentum for convergence analysis, ensuring that every limit point generated by Prox-SGD is a stationary point of the nonsmooth nonconvex problem. This contrasts with unconstrained optimization, where the convergence of SGD methods is well understood. The convergence rate of Prox-SGD is not derived in the current work and requires further investigation. Two applications are considered: training a SNN with 1-regularization and training a BNN with binary weights. The loss function is augmented with a penalty term to enforce weights to be either +1 or -1. The Prox-SGD algorithm is described for solving a regularized optimization problem with constraints on x and a. By relaxing integer variables to be continuous, a BNN can be obtained with interpretability and flexibility. The algorithm ensures efficient training of accurate models for neural networks. The algorithm aims to find a stationary point of a convex and compact function using gradient descent. To handle large datasets, the gradient is estimated using minibatches. An aggregate gradient (momentum) is formed recursively to update the solution iteratively. The algorithm uses gradient descent with momentum to find a stationary point of a convex and compact function. It incorporates a quadratic regularization term to ensure strong convexity. The update direction refines the weight vector iteratively, ensuring feasibility in a convex set. The algorithm utilizes gradient descent with momentum to find a stationary point of a convex function. It includes a quadratic regularization term for strong convexity and updates the weight vector iteratively to maintain feasibility in a convex set. The steps are summarized in Algorithm 1, known as Prox-SGD, which can be interpreted as a regularization function. The proposed framework interprets existing SGD algorithms with and without momentum. For example, setting \u03c1(t) = 1 in Algorithm 1 corresponds to no momentum in SGD. In ADAM, setting \u03c1(t) = \u03c1 and (t) = /(1 \u2212 \u03c1 t ) in Algorithm 1 represents the learning rates. The convergence conditions proposed are sufficient for existing algorithms. The approximation subproblem (7) is solved using a generic solver as x(t) is unique due to strong convexity. Some important special cases in optimization can be efficiently solved. The soft-thresholding operator is used when X = R^n and r(x) = \u00b5x1. Block sparsity is promoted with 2-regularization when x is divided into blocks. Bound constraints can be handled by solving an approximation subproblem and projecting the optimal point onto the interval. Quadratic constraint functions have semi-analytical expressions for x. The text discusses the update of weights by solving an approximation subproblem in optimization. It explains the relationship between the objective function, weights, and trajectory generated by Prox-SGD. The optimization process involves the optimality of x(t) and the Lipschitz continuity of \u2207f(x). The momentum in Prox-SGD is crucial for convergence, ensuring the aggregate gradient converges to the true gradient. The update rule decreases the objective value after each iteration, supported by Jensen's inequality and a decaying step size. The Prox-SGD algorithm with momentum ensures convergence by decreasing the objective value with each iteration. The convergence analysis relies on bounded second moment assumptions and decreasing step sizes. The detailed proof is included in the paper's appendix. The Prox-SGD algorithm with momentum ensures convergence by decreasing the objective value with each iteration. The momentum converges to the true gradient, guaranteeing convergence. The quadratic gain in the approximation subproblem should be lower bounded for theoretical convergence. Different definitions of the gain lead to varying empirical convergence speed and generalization performance. The Prox-SGD algorithm with momentum ensures convergence by decreasing the objective value with each iteration. The technical assumptions in Theorem 1 may not always be fully satisfied by neural networks in practice. Numerical experiments are conducted to test the algorithm's practical performance and hyperparameter choices. Various algorithms are compared, and the merit of regularization and constraints is illustrated. Hyperparameters are chosen based on recommendations or a search. The quadratic gain in Prox-SGD is updated similarly to ADAM for fair comparison. The Prox-SGD algorithm updates the quadratic gain \u03c4 (t) similarly to ADAM with \u03b2 = 0.999. For multiclass classification on CIFAR-10 dataset, a CNN with 6 convolutional layers and batch normalization is used. Parameters are set as \u03c1 = 0.1, \u03b2 = 0.999, and = 0.001. Regularization is incorporated using 1-norm. The Prox-SGD updates \u03c4 (t) and \u03c1(t) decrease over iterations. The Prox-SGD algorithm updates \u03c4 (t) and \u03c1(t) decrease over iterations. In an experiment with four algorithms, Prox-SGD outperforms ADAM, AMSGrad, and ADABound in terms of achieved loss value. The accuracy achieved by these algorithms is comparable. Sparsity of the trained model is measured by the cumulative distribution function (CDF) of weights' value. In an experiment comparing Prox-SGD with other algorithms, Prox-SGD shows superior performance in achieving loss value and sparsity of weights. The proposed Prox-SGD with soft-thresholding proximal mapping has a clear advantage over other stochastic subgradient-based algorithms, as shown in the evaluation with a larger and more complex network and dataset. The DenseNet family's deepest topology is a state-of-the-art network for image classification tasks. Prox-SGD, ADAM, and SGD with momentum are used for training, with hyperparameters optimized through grid-search. Prox-SGD outperforms other algorithms in generating a SNN. In experiments comparing Prox-SGD, ADAM, and SGD with momentum for training a SNN, Prox-SGD is shown to be more efficient in generating a sparser neural network. Different initial learning rates for Prox-SGD affect training loss and test accuracy, with most rates leading to sparser networks compared to ADAM and SGD with momentum. This sparsity is attributed to the use of nonsmooth 1-norm regularization in Prox-SGD. The experiment evaluates the Prox-SGD algorithm for training a 6-layer DNN on the MNIST dataset with tanh activation function. The algorithm shows increased training time compared to SGD and ADAM, but achieves higher sparsity. The setup allows for a focused evaluation of the proposed method on a simple dataset. The experiment evaluates the Prox-SGD algorithm for training a 6-layer DNN on the MNIST dataset with tanh activation function. The proposed model and training algorithm involve customizing Algorithm 1 to the problem, with closed-form expressions for x(t) and a(t). The training loss and test accuracy of the BNN are compared to a standard full-precision DNN. The BNN imposes regularization and constraints, leading to worse training loss compared to full-precision DNN. However, test accuracy difference is small. The proposed formulation effectively promotes binary weights, with most weights being -1 or 1. Binarizing weights after training results in minimal performance loss (98% vs 95% accuracy). In contrast, full-precision DNN weights are smoothly distributed in [-2, 2]. The proposed Prox-SGD algorithm converges faster and achieves better training loss and test accuracy compared to previous algorithms. The computation time is similar, and the performance improvement is attributed to regularization and constraints. The search for a proper regularization parameter is worthwhile. In this paper, Prox-SGD, a proximal-type stochastic gradient descent algorithm with momentum, is proposed for constrained optimization problems with regularization. The algorithm shows improved performance in training SNN and BNN by promoting structures in the learned network. Incorporating regularization and constraints leads to a more accurate and interpretable model, with efficient training ensured by the Prox-SGD algorithm. Numerical tests demonstrate its superiority over state-of-the-art algorithms in terms of convergence speed and achieved training loss. The text discusses the Prox-SGD algorithm for constrained optimization problems with regularization, showing improved performance in training neural networks. The algorithm outperforms state-of-the-art algorithms in terms of convergence speed and training loss. The proof of Theorem 1 is provided, demonstrating the technical conditions satisfied by the problem at hand. Lemma 1 states the existence of a constant L such that the limit of a certain expression approaches 0 with probability 1. The proof involves assumptions and optimizations leading to the desired Lipschitz property. The text discusses the analysis of a function U(x) involving inequalities and probabilities to show that the limit of x(t) - x(t) approaches 0 with probability 1. Contradiction is used to demonstrate that the limit must be 0. The text focuses on the realization of x(t) - x(t) > 0 with a positive probability, along with various limits and inequalities involving x(t) and e(t1, t2). It shows the existence of a \u03b4 > 0 where x(t) oscillates between 2\u03b4 and \u03b4 infinitely, leading to specific properties for an infinite set of indexes T. The analysis also includes bounds and inequalities for x(t) and x(t+1) in relation to e(t, t+1). The text discusses inequalities involving x(t) and e(t, t+1), showing the existence of a \u03b4 > 0 where x(t) oscillates between 2\u03b4 and \u03b4 infinitely for an infinite set of indexes T. It also demonstrates the contradiction between (33) and the convergence of {U(x(t))}."
}