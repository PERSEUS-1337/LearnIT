{
    "title": "BkA7gfZAb",
    "content": "Methods that align distributions by minimizing an adversarial distance have shown impressive results, but are challenging to optimize with gradient descent. Turning the adversarial min-max problem into an optimization problem by using its dual improves alignment quality. Empirical results suggest that using the dual formulation for linear discriminators leads to more stable convergence compared to primal min-max GAN-like and MMD objectives. Testing this hypothesis on aligning point clouds and domain adaptation on digits yielded promising results. Generative Adversarial Networks (GANs) align distributions by learning a parametric representation and differentiating between true and artificially obtained samples. GANs have achieved impressive results in various applications such as generative modeling of images, image super-resolution, and image-to-image translation. Adversarial methods like GANs have shown promise in aligning data distributions but are difficult to optimize due to theoretical problems with loss functions leading to instability and saturation during training. The min-max nature of adversarial methods poses a major barrier to stable optimization. In the context of adversarial methods like GANs, the distance between data distributions is defined as the maximal difference between values of test functions. This distance is minimized by optimizing the likelihood of a neural network classifier. However, solving min-max problems using gradient descent is challenging, leading to instability. To address this issue, the possibility of replacing the maximization part of the problem with a dual minimization approach is explored. The text discusses a dual minimization approach for the adversarial alignment problem, making it easier to solve via gradient descent. Connections are made to existing objectives like Maximum Mean Discrepancy. The method is evaluated on synthetic and real-image datasets for domain adaptation, showing improved performance compared to primal methods. The text explores a dual formulation of the adversarial alignment objective for linear and kernelized linear discriminators, showing improved stability and alignment quality compared to the primal formulation. Experimental results on synthetic and real datasets demonstrate better convergence and higher target classification accuracy in domain adaptation scenarios. Generative adversarial methods for learning neural networks have gained popularity for modeling high dimensional data, such as generating realistic images. Various formulations like Wasserstein GANs and Conditional GANs have been proposed. These methods are also used for unsupervised domain adaptation, aiming to align feature representations across different data distributions. Several models in domain adaptation use adversarial objectives to align feature representations between source and target domains. This can be achieved through generative alignment in pixel-space or by translating images to create artistic effects. Some approaches perform unsupervised alignment without paired images, while others propose alternative losses for distribution matching. Several distribution matching methods have been proposed in the literature for generative modeling, including Maximum Mean Discrepancy and f-discrepancy. Iterative reweighting procedures have been shown to improve accuracy in the presence of domain shift. Statistical distances used for distribution alignment typically fall into f-divergences or integral probability metrics categories. Gradient descent may fail in simple min-max problems, illustrated by a saddle point example with a unique solution. Using the gradient vector field leads to circular trajectories, preventing convergence to the true solution. Neither block coordinate descent nor learning rate schedules improve gradient descent performance on this problem. Alternative descent schemes have not been successful in adversarial distribution alignment. A new formulation of the adversarial objective for distribution alignment is proposed, applied to domain adaptation scenarios. Given sets of points sampled from different distributions, the goal is to align the distributions. The goal is to align distributions by matching points sampled from them. A matching function is learned to minimize the statistical distance between the distributions. The regular adversarial approach involves finding a classifier that discriminates points from each distribution, with the distance between them determined by the classifier's likelihood. Linear classifiers or neural networks are commonly used for this purpose. In this work, linear classifiers like logistic regression are used to align distributions by minimizing the distance between them. The distance is defined as the maximum likelihood of the logistic classifier parametrized by w. The duality derivation follows from the sharp upper-bound of the log-sigmoid, allowing for the computation of the optimal weight w. The text discusses the optimization problem of bias in linear classifiers by minimizing the distance between distributions A and B. It introduces a minimization problem involving pairwise similarities between points from A and B, with a constraint on alpha sums. The objective function is denoted as d D (\u03b1, A, B) and provides a tight upper bound on the likelihood of the discriminator, allowing for the minimization of the distance between distributions. The text discusses the optimization problem of bias in linear classifiers by minimizing the distance between distributions A and B. It introduces a minimization problem involving pairwise similarities between points from A and B, with a constraint on alpha sums. The resulting smooth optimization problem consists of minimization over \u03b1 to improve classification scores and over \u03b8 to move points towards the decision boundary. The dual formulation of the adversarial objective has a relationship to another alignment objective involving the integral probability metric between distributions p and q with a given function family H. The Maximum Mean Discrepancy (MMD) is a distance measure between means of vectors from two distributions embedded into a reproducing kernel Hilbert space. An empirical estimator of MMD combines inner and outer similarities between samples, converging to zero with increasing sample size. The adversarial logistic distance is an iteratively reweighted empirical estimator of MMD. The optimization procedure in Eq. FORMULA5 involves iteratively reweighted empirical estimation of the MMD distance. It consists of two alternating minimization steps: adjusting sample weights to minimize regularized weighted MMD, and minimizing weighted MMD distance by changing the matching function. High weights are assigned to mutually close subsets of A and B, which are support vectors of the optimal domain classifier. This procedure is similar to the Iteratively Reweighted Least Squares Algorithm for logistic regression. The proposed method aims to bring support vectors of the optimal domain classifier closer together, with computational complexity growing quadratically due to kernelization. Batched GPU implementation performed well compared to MMD and primal methods, especially in unsupervised domain adaptation scenarios where the classifier needs to be updated for different domains without labeled samples. The goal is to adapt a classifier to a new domain without labeled samples from that domain. Ben-David et al. (2007) showed that the target risk can be bounded by the source risk and a complexity term involving dataset size. The target risk can be minimized by reducing the discrepancy between source and target distributions. Estimation of this discrepancy is challenging and often replaced with more computationally feasible statistical distances. The proposed dual minimization adversarial objective converges to an optimum, even in the kernelized version. The accuracy of learned discriminators may drift over time, but the distance between covariance matrices remains stable. The proposed dual minimization adversarial objective converges to a stable solution for point cloud alignment, even in the kernelized version. The approach can be applied to scenarios with adversarial objectives using logistic regression domain classifiers. In Section 6, the focus is on classification tasks with multi-layer neural networks, comparing it to the standard min-max adversarial formulation. The proposed approach compares the standard min-max adversarial objective with a min-min formulation for point cloud matching. The goal is to match points from two clouds on a two-dimensional plane with no restrictions on transformations. The logistic adversarial distance is minimized in primal space, and the negative adversarial distance is maximized using the dual of the logistic classifier. The optimization of distances given by the dual versions of domain classifiers (linear and kernelized) outperformed the linear classifier in the primal form. Results were sensitive to the learning rate in the primal case, leading to unstable solutions. In contrast, both dual versions successfully converged to solutions matching the two point clouds visually and in terms of means and covariances. The dual approach in optimization problems outperformed the linear classifier in the primal form. The decision boundary in the dual space moves with the data points, leading to more stable solutions. Weights of the discriminator may change drastically to keep up with moved points, leading to training instability. The decision boundary in the linear primal discriminator starts \"spinning\" around aligned point clouds. Dual classifiers converge to solutions assigning each point with 0.5 probability of belonging to two domains. The proposed dual objective was evaluated on a visual domain adaptation task using an SVHN-MNIST dataset pair. The study utilized a Dual objective approach for domain adaptation, focusing on improving test accuracy by training the source network on source data and optimizing the target network to align feature representations. Various primal objectives were tested and compared to the Dual objective, with technical details provided in the Supplementary Section 9.2. The study restricted the discriminator hypothesis space to linear classifiers to examine the stability of the objective structure. They varied learning rates and regularization parameters for each model and ran experiments for 50 epochs to observe long-term behavior. In unsupervised domain adaptation, validation of stopping criteria is not possible due to the lack of target labels. The study evaluated the stability of models in unsupervised domain adaptation by observing their behavior over multiple training epochs. The Dual objective model showed better convergence to satisfactory solutions under various learning rate and hyperparameter combinations compared to other methods. The study found that the Dual objective model performed well under different learning rates, showing better stability compared to other methods like WGAN, MMD, and ADDA. The Dual method led to more stable optimization without the need for choosing optimal hyperparameters and stopping criteria. Our paper presents a general framework for alignment in kernel logistic regression, where the quadratic form can be rewritten as a Frobenius inner product of a kernel matrix Q with a symmetric rank 1 alignment matrix S. The goal is to maximize the agreement between the alignment and similarity matrices, replacing \"adversity\" with \"cooperation\" in the dual maximization problem. Different alignment matrix parameterizations and regularizers can be chosen, akin to having a neural network discriminator in the adversarial problem or a Wasserstein. The paper proposes a stable \"cooperative\" problem reformulation for alignment in kernel logistic regression, utilizing a dual of the discriminator objective to improve distribution alignment stability. The approach does not involve a new adversarial objective or lead to a min-max problem, but instead focuses on iteratively-reweighted alignment matrix fitting. The proposed dual optimization objective improves distribution alignment stability in kernel logistic regression. Results show better performance than the saddle point objective, with promising potential for reformulating other statistical distances in adversarial settings. Dual objective outperforms WGAN, MMD, and ADDA in real-image classification datasets. The proportion of runs that outperformed the source baseline after 40 epochs were: 52.3% for Dual, 21.5% for WGAN, 17.1% for MMD, and 6.9% for ADDA. The hyperparameter space explored involved finding optimal parameters through cross-validation and combining them into a set, which was then expanded by adding various combinations. The experiments involved inflating H with different combinations of parameters and training discriminators for five epochs before domain adaptation. Kernel density estimates were obtained with specific settings, and algorithms used greyscale images resized to 28x28. Restrictions on \u03b1 were imposed, and hyperparameters for the Dual method ensured these restrictions were met. The dual algorithm was implemented in mini-batch fashion by extracting slices of \u03b1. The algorithm was implemented in mini-batch fashion by extracting slices of \u03b1 corresponding to points processed in each batch. Different learning rates and weight decay parameters were used for updating the target network and discriminator. Various combinations were tested, but changing the values of \u03bb did not significantly alter the results."
}