{
    "title": "HJenmmF8Ir",
    "content": "A key goal in neuroscience is to understand brain mechanisms of cognitive functions by studying brain states dynamics using fMRI. Graph convolutional networks were applied to decode brain activity over short time windows in a task fMRI dataset, predicting cognitive states from fMRI time series. Using graph convolutional networks (GCN), cognitive states were annotated in the Human Connectome Project (HCP) database with high accuracy. The HCP task battery activates specialized functional networks, making the GCN annotation a potential base model for transfer learning applications. Functional magnetic resonance imaging (fMRI) allows for precise mapping of neural substrates involved in human cognition. An emerging topic in the literature is the identification of \"brain states\" using multi-voxel pattern analysis (MVPA) to map neural substrates of human cognition. A GCN architecture was proposed to annotate human brain activity on a cognitive battery of 21 task states, utilizing fMRI volumes to generate task-specific graph representations for prediction. Using fMRI volumes as input, a GCN architecture predicts cognitive labels with high accuracy compared to support vector machines. The project utilizes block-design task fMRI data from the Human Connectome Project, mapping fMRI time series onto a standard surface template. The data includes seven cognitive tasks and 23 different cognitive states. The study evaluated decoding models for 23 cognitive states, excluding gambling conditions due to lower performance. Graph signal processing mapped brain signals onto a network structure, showing promising results for cognitive task prediction. The study utilized a multimodal cortical parcellation to analyze connections between brain regions based on resting-state functional connectivity. Graph signal processing involved spectral analysis using the graph Laplacian to predict cognitive task performance. The graph Fourier transform is defined using the graph Laplacian matrix and eigenvalues to represent modes. Graph convolutional neural networks (GCN) merge spectral graph theory with deep learning techniques, with Kipf et al. introducing a simplified version of GCN. The output of a graph convolution layer is a linear combination of graph modes across the spectrum of the Laplacian matrix. The parameters learned on layer l with F income channels/filters are shared among all nodes. Graph convolution only considers direct neighbors in the graph. Multiple GCN layers propagate brain activity information among k th -order neighborhood. The first GCN layer treats fMRI volumes as multiple channels, learning spatio-temporal convolution kernels during model training. The fMRI decoding model utilizes a brain state annotation model with 6 GCN layers and 32 graph filters at each layer. It takes short series of fMRI data as input, generates high-level graph representations, and predicts cognitive labels through multi-class classification. The GCN model implementation is based on Tensorflow 1.12.0, trained for 100 epochs with Adam optimizer. The study utilized a brain state annotation model with 6 GCN layers and 32 graph filters to predict cognitive labels from fMRI data. The dataset was split into training, validation, and test sets, with the best model achieving an average test accuracy of 89.83% across 21 task conditions. The study achieved an average test accuracy of 89.83% using a brain state annotation model with 6 GCN layers and 32 graph filters to predict cognitive labels from fMRI data. Each cognitive domain had a recall accuracy >91%, with language and motor tasks showing the highest precision and recall scores. However, relational processing and working memory tasks had lower performance, with some misclassifications between them. The emotion and relational processing conditions were misidentified as working memory tasks due to task stimuli similarity. Misclassifications were found within the same cognitive domain, particularly between 0-back and 2-back conditions in working memory tasks. Brain decoding accuracy was high for face and place working memory stimuli. The study found a strong association between prediction accuracy of GCN annotation and median reaction time within scanner. Participants reacted faster to the matching condition than relational processing in a relational processing task. GCN achieved higher prediction accuracy for matching than relational processing. The analysis was performed on 200 subjects from the test set. The performance of deep GCN showed a substantial improvement over traditional machine learning tools like multi-class support vector machines classification. The study compared the performance of support vector machines classification (SVC) with a linear kernel to a deep GCN model in classifying cognitive states using fMRI data. The results showed that GCN outperformed SVC-linear in accuracy and training time. Saliency maps were used to analyze the features learned by the GCN model. The saliency map showed significant contributions in predicting cognitive states, with shared features between story and mathematics conditions related to auditory processing. Specific features were unique to each condition, such as anterior involvement in story processing and posterior involvement in mathematical processing. The saliency map revealed that temporal regions were significant for mathematics, while perisylvian language-related regions were not relevant for the motor task. Primary motor and somatosensory cortex were highlighted for different movements, with no clear somatotopic organization. Category-specific features were identified in the medial primary motor cortex for foot movement and lateral orbitofrontal cortex for tongue movement. The saliency map highlighted specific regions in the brain for different tasks, such as the primary motor cortex for foot movement and lateral orbitofrontal cortex for tongue movement. In the ventral visual stream, distinct areas were activated for image recognition tasks, with place stimuli activating medial temporal areas and face stimuli activating lateral temporal regions. This aligns with known neural representations for face and place images in fusiform face area and parahippocampal place area, respectively. The findings suggest that the GCN model has learned biologically meaningful features."
}