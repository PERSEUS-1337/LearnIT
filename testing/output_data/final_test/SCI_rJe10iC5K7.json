{
    "title": "rJe10iC5K7",
    "content": "In this paper, a novel formulation called Parts, Structure, and Dynamics (PSD) model is proposed to learn hierarchical object representation and dynamics from unlabeled videos. The model recognizes object parts, predicts hierarchy, and models system dynamics. Experiments show the PSD model's effectiveness in segmenting object parts, building hierarchical structures, and capturing motion distributions. Researchers in cognitive science have found that humans, including infants, perceive objects as integrated moving entities, forming the concept of objects internally. This process is unsupervised and hierarchical, leading to the recognition of object parts and their hierarchical structure. The Gestalt theory in psychology supports this holistic perception, explaining scenes as a whole rather than in isolation. This perception provides interpretable and disentangled concepts. Recent research in unsupervised and generative deep representation learning aims to build machines that can reason about object motion, predict future events, and imagine counterfactuals. The focus is on developing artificial systems that can learn interpretable, hierarchical representations with system dynamics solely from raw visual data. Existing models have made progress in explaining multiple objects in a scene and learning interpretable representations, but there is a need for a formulation that can produce a structured, hierarchical object representation while also characterizing system dynamics. In this paper, a novel formulation called Parts, Structure, and Dynamics (PSD) is proposed to learn an interpretable, hierarchical object representation and scene dynamics by predicting the future from unlabeled videos. The model recognizes object parts, builds their hierarchy, and models motion distribution for future frame synthesis without human annotations. The Parts, Structure, and Dynamics (PSD) model is a hierarchical descriptor that can be trained within a neural network to predict system dynamics and future frames. It successfully learns object concepts, segmentations, hierarchical structures, and motion distributions from real-world RGB images with minimal input requirements. Our PSD model effectively learns object concepts, segmentations, and motion distributions from real-world RGB images with minimal input frames. It differs from previous research by not only explaining observations but also building a dynamics model for future prediction. In this paper, a model is proposed to segment objects from videos, infer their hierarchical structure, and capture each part's dynamics for synthesizing future frames. The focus is on physical scene understanding and predicting the immediate future of dynamic scenes. Researchers aim to learn physical object representations from raw observations to improve generalization. Our model aims to learn physical object representations from raw observations to improve generalization by simultaneously discovering the hierarchical structure of object parts. It draws insights from classical computer vision research on layered motion representations and advances beyond existing work on future state prediction in dynamic scenes. Our model aims to discover the hierarchical structure of object parts purely from visual observations, without prior knowledge. It learns to segment object parts and capture their motions, aiming to find a segment decomposition where each segment corresponds to an object part with distinct motion. The model assumes that these object parts form a hierarchical tree structure. The model aims to identify object components and learn the hierarchical tree structure to explain object motion effectively. By decomposing complex object motions into simple local motion components, it can capture the distinct motions of each object part. The model aims to decompose complex object motions into simple local components to reduce the description length of the motion map. It introduces a design with an information bottleneck for compact, disentangled representations and learns by predicting future motions and synthesizing frames without manual annotations. The Parts, Structure, and Dynamics (PSD) model decomposes input frames into multiple feature maps to model different object components' movements. Our model decomposes input frames into multiple feature maps using an image encoder, performs convolutions on these feature maps with separate kernels, synthesizes local motions of object components, recovers global motions, and computes overall motion. It then synthesizes the next frame using an image decoder. The model can be viewed as a conditional variational autoencoder, utilizing a motion encoder during training and sampling latent representations during testing. During testing, the model samples the representation z from a multivariate Gaussian distribution. The hyperparameter d is set to 32, determining the maximum number of objects the model can handle. The variational loss in training encourages using as few dimensions in the latent representation z as possible. The motion encoder takes flow field between frames as input, with 7 convolutional layers. The output is a latent motion representation z sampled from a Gaussian distribution. The kernel decoder decodes z to convolutional kernels. The image encoder uses convolutional layers with specific channel and kernel sizes, followed by upsampling to generate a 128x128 feature map. The cross convolution layer applies learned convolutional kernels to the feature maps in a channel-wise manner. The motion decoder applies depthwise separable convolutions to estimate x-axis and y-axis motions separately, resulting in a d-channel transformed feature map. The structural descriptor recovers global motions from local motions and hierarchical tree structure using a structural matrix. The overall motion is computed using binary indicators to determine ancestry relationships. The image decoder synthesizes future frames based on the predicted motion. The objective function includes pixel-wise reconstruction and variational components with weighting factors. The variational loss encourages the model to use fewer dimensions in the latent representation, while the structural loss promotes learning a hierarchical tree structure for efficient motion representation. The structural loss is applied to local motion fields as a regularization, resulting in small values. In PyTorch, a PSD model is implemented for synthesizing future frames and learning hierarchical structure on digits. The optimization is done using ADAM with fixed learning rate and mini-batch size. A two-stage optimization schema is proposed, first learning a disentangled representation and then a hierarchical one. The model is encouraged to learn a disentangled representation in the first stage by adjusting \u03b2 values, and in the second stage, it learns the hierarchical representation. In the second stage, the model is trained to learn a hierarchical representation by fixing the weights of motion encoder and kernel decoder, setting \u03b2 to 0, initializing the structural matrix S, and optimizing it with the image encoder and motion decoder jointly. The model is evaluated on shapes, digits, Atari games, and real-world human motions. Shapes dataset includes circles, triangles, and squares with random visual appearance for training and testing. Circles move diagonally, while triangles and squares have two sub-movements. The movements of shapes consist of two sub-movements: moving together in circles and moving in their own directions (triangles horizontally, squares vertically). The complex global motions are broken down into simpler local motions for easier representation. An additional dataset with nine different shapes is created, grouped into square and parallelograms, circle and triangles, trapezoids, and pentagon. Shapes within the same group have intrinsic relations, while shapes in different groups are independent. Each shape has its own unique motion direction. The additional dataset includes shapes like squares, parallelograms, circles, triangles, trapezoids, and pentagons. Shapes within the same group have intrinsic relations, while shapes in different groups are independent. The digits dataset consists of hand-written digits divided into two groups based on numbers. Each group has a specific structure for the movements of the digits. The model is trained to synthesize future frames, segment objects, and discover relationships between them. It captures different motion patterns for each object and synthesizes multiple possible future frames. The latent representation is observed to have extremely sparse dimensionality, with three dimensions learning meaningful representations. The model learns meaningful representations in three dimensions, corresponding to specific shapes. On the digits dataset, there are six dimensions representing different digits. The feature map for each dimension acts as a segmentation mask for an object. Model performance is evaluated based on object segmentation using IoU. Comparison is made with NEM and R-NEM methods. Our PSD model outperforms two baselines by learning appearance priors of objects and grouping object parts based on their movement. Unlike R-NEM, which focuses on temporal reasoning, our model can be applied to static images and is effective even with videos containing only two frames. Our PSD model demonstrates superior performance compared to R-NEM and Neural Relational Inference (NRI) by effectively recognizing multiple objects with similar motion patterns. The hierarchical structure of dimensions is revealed through binarizing the structural matrix. The NRI model by BID29 infers interaction graphs from objects' feature vectors. Hierarchical tree structures are visualized, showing the model's ability to discover underlying relationships. The PSD model outperforms baselines in understanding system dynamics and relationships among shapes. Evaluation on Atari games, specifically Basketball, showcases the model's capabilities. The PSD model analyzes the Basketball game from Atari 2600, creating a dataset for training and testing. It identifies three dimensions in the latent representation, focusing on the offensive player with the ball, the ball itself, and the defensive player. A hierarchical tree structure is constructed to show the relationships between these dimensions. Our PSD model analyzes the relationship between the ball and players in a basketball game. It is evaluated on two real-world human motion datasets with complex visual perception. The datasets include a human exercise dataset with 50,000 training pairs and 500 testing pairs, and a yoga dataset with 4,720 training pairs and 526 testing pairs. The model can predict multiple future frames accurately. Our PSD model predicts multiple future frames accurately by analyzing the relationship between the ball and players in a basketball game. The model outperforms 3DcVAE in predicting future frames with fewer artifacts. Additionally, the model successfully segments human body parts in feature maps, showing distinct dimensions for different body parts. Our PSD model outperforms baselines in part segmentation, discovering hierarchical structures among body parts. The model accurately predicts future frames in a basketball game, showing distinct dimensions for different body parts. Our model introduces a novel formulation to discover object parts, hierarchical structure, and system dynamics from unlabeled videos. It uses a layered image representation and structural descriptor for part segmentation, structure recovery, and motion prediction. Experiments show its effectiveness on real and synthetic datasets. The motion distributions of different shapes are demonstrated in FIG3, comparing ground truth with model predictions. Our model utilizes temporal reasoning to group pixels into objects based on appearance prior, learning from object movements. Results show that using longer videos with 20 frames as input significantly improves object recognition compared to using only one or two frames. R-NEM performs better on occluded objects with long trajectories, where each object is visible without occlusion in at least one frame. Quantitative results show improved object segmentation with longer videos as input, particularly for occluded objects with long trajectories."
}