{
    "title": "SFIxZr3RRpr",
    "content": "Word alignments are crucial for tasks like statistical and neural machine translation (NMT) and annotation projection. While most approaches require parallel training data, we propose word alignment methods that rely on multilingual word embeddings instead. These embeddings, both static and contextualized, are created from monolingual data only, outperforming traditional statistical aligners even in scenarios with abundant parallel data. For example, contextualized embeddings achieve a word alignment F1 that is more than 5% higher than eflomal for a set of 100k parallel sentences. Word alignments are crucial for tasks like statistical and neural machine translation (NMT) and annotation projection. Various word alignment methods, including statistical aligners like IBM models and their successors, as well as the use of attention matrices for soft word alignments in NMT, have been widely used. These methods have been successfully applied in typological analysis, annotation projection, and creating multilingual embeddings. Recent unsupervised multilingual embedding algorithms provide high-quality static and contextualized embeddings using only monolingual data. The key idea is to leverage these embeddings for word alignments without relying on parallel data, which is advantageous in low-resource and domain-specific settings. This approach addresses the challenge of scarce parallel data, offering a solution for scenarios where mining parallel data is difficult. The text discusses the challenges of word alignments in low-resource settings without parallel data. It proposes new alignment methods based on embedding similarities and post-processing algorithms. The study shows that multilingual BERT outperforms statistical aligners like eflomal and highlights the preference for subword processing in alignments. Source code will be published upon acceptance. The text introduces methods for extracting alignments from similarity matrices using embedding vectors. It discusses approaches like Argmax and Match to improve alignment accuracy. These methods aim to address the limitations of finding local optima in word alignments. In the context of extracting alignments from similarity matrices using embedding vectors, the problem involves finding a maximum-weight maximal matching in a bipartite weighted graph. Known algorithms can solve this in polynomial time. Distortion correction is essential for alignments based on non-contextualized embeddings, where high distortion is penalized by scaling the similarity matrix with a hyperparameter \u03ba. To scale the matrix between [(1 \u2212 \u03ba), 1], a locality-preserving prior is imposed. Alignment edges are removed when the normalized entropy of the similarity distribution exceeds a threshold \u03c4. Traditional word alignment models create forward and backward alignments, which are then symmetrized. The grow-diagfinal-and (GDFA) and intersection methods were compared and GDFA was chosen for the study. Subword segmentations like BPE/wordpiece are also investigated. The study investigates subword segmentations such as BPE/wordpiece and uses various gold alignments for different language pairs in different domains. Additional parallel training data consistent with the target domain is selected, and the effect of adding more or less training data is shown. mBERT is pretrained on Wikipedia, and fastText embeddings are trained on Wikipedia as well. Evaluation measures are also mentioned. The study evaluates different models using precision, recall, F1, and alignment error rate. mBERT consistently performs the best, while fastText outperforms fast-align in some cases. Eflomal has high precision and is competitive for ENG-FRA. With more training data, fast-align and eflomal improve, but mBERT outperforms both with 10^6 parallel sentences. FastText becomes competitive with fewer than 1000 parallel sentences. Overall, mBERT-based alignments outperform state-of-the-art aligners without needing parallel training data. In Table 1, subword processing benefits aligners like fast-align, GIZA++, and eflomal, but harms fastText. VecMap is used to match word distributions across languages, with subword matching being harder. Different alignment and postprocessing methods are compared in Table 4, with Argmax generally yielding higher precision and Match having higher recall. Adding a distortion prior improves performance for static embeddings. Null-word processing increases precision but does not increase F1 score. The processing increases precision for aligners like fast-align, GIZA++, and eflomal, but does not improve F1 score. mBERT's contextualized representations already match well across languages, with layer 8 yielding the best performance. Various word aligners, such as fastalign and GIZA++, are based on IBM models. Our method aligns based on parallel text instead of using these models. Our method aligns based on embeddings induced from monolingual data, not requiring parallel data like previous models. It outperforms statistical word aligners and achieves a 5% higher alignment F1 for a set of 100k parallel sentences compared to eflomal. Contextualized embeddings achieve a 5% higher alignment F1 compared to eflomal. Evaluation measures are computed using predicted alignment edges A and gold standard edges S. Symmetrization methods like intersection and GDFA are compared, with GDFA performing better in terms of F1. Intersection has higher precision while GDFA has higher recall, making it preferable for annotation projection and GDFA for statistical machine translation. In Table 4, analogous numbers from Table 1 show Distortion is crucial for fastText but not for mBERT. Adding Null is beneficial, especially for mBERT. Customized hyperparameters were used, with \u03ba introduced in Figure 3. Distortion helps performance, with \u03ba = 0.5 chosen in the main paper. In the main paper, a high value of \u03c4 is used for null-word post-processing to improve performance. Different values of \u03c4 are tested, with \u03c4 = 1 showing no change in performance. Precision increases and recall decreases with decreasing \u03c4. \u03c4 = 0.999 for fastText and \u03c4 = 0.9995 for mBERT are used. Code and data overview will be published upon acceptance. Table 6 provides data details and download links."
}