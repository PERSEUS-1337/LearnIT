{
    "title": "HyeGBj09Fm",
    "content": "We propose a novel approach for deformation-aware neural networks that learn the weighting and synthesis of dense volumetric deformation fields specifically targeting the space-time representation of physical surfaces from liquid simulations. Our algorithm captures complex phenomena in two stages: a first neural network computes a weighting function for pre-computed deformations, while a second network generates a deformation field for refining the surface. Demonstrating effectiveness with examples of flowing liquids, our method enables rapid representation of topology changes. Our representation allows for rapid generation of implicit surfaces for flowing liquids with topology changes. A mobile application has been implemented to showcase real-time interactions with complex liquid effects using this approach. Learning physical functions is a growing area of interest in research, with applications in various fields such as computer vision and robotic control. The availability of model equations for physics problems allows for the creation of reliable ground truth data for training, if sufficient computational resources are allocated. In this work, a novel approach is presented to capture parametrized spaces of liquid behavior using space-time deformations. A 3D input surface is represented as a four-dimensional signed-distance function (SDF) and deformed in both space and time to achieve desired physical behavior. The process involves precomputed deformations, a weighting function, and dense deformation field synthesis to address the non-linear nature of the problem. Neural networks are used to solve the parameter weighting problem and deformation synthesis, incorporating non-linear effects of weighted deformations into loss functions. Emphasis is placed on aligning deformations correctly, with a generative model for deformation fields relying on a known parametrization. This approach differs from other models by training with a known input range and dimensionality. Our approach utilizes a novel deformation-aware neural network to efficiently represent space-time surfaces with complex behavior. We demonstrate its performance with a mobile device implementation that generates liquid simulations interactively, achieving speed up factors of more than 2000. The implementation generates liquid simulations interactively using a deformation-aware neural network. Various deep learning works have been proposed to learn physical models from videos, target specific settings like robotic interactions, sliding objects, and predict forces for image-space motions. Researchers have also shown the stability of stacked objects can be inferred from single images. Our method focuses on generating liquid simulations using a deformation-aware neural network, working directly with three-dimensional data sets over time. Previous works have targeted learning object properties from interactions with liquids and automated experiments with reinforcement learning. Our approach specifically addresses surfaces deforming based on physical principles, allowing us to generate accurate results with specialized loss functions. Our method focuses on generating complex physical effects in 3D over time using a generative approach. Unlike other methods, we focus on 4D volumes of physics data instead of localized windows at single instances of time. Our work also shares similarities with methods for optical flow inference and image correspondences. Our method learns deformations and their weighting in an unsupervised manner, similar to spatial transformer networks and unsupervised optical flow approaches. Instead of aligning two data sets, we aim to represent larger spaces of deformations parametrically. We define a simulation parameter space for Navier-Stokes boundary value problems with a liquid-gas interface, treating the interface over time as a space-time surface. The text discusses space-time surfaces defined over a region of N-dimensional simulation parameters \u03b1, normalized to [0, 1] N. Implicit functions \u03c6(\u03b1) are used to represent specific instances, with \u03c6(\u03b1, x) = 0 defining the surfaces our generative model should capture. \u03c6 and \u03c8 are four-dimensional signed distance functions, with \u03c6 \u03b1 representing constant reference surfaces. The continuous formulation is presented before discretizing functions on Cartesian grids. Deforming Implicit Surfaces: Representing the set \u03c6 \u03b1 is challenging due to bifurcations and discretization artifacts, leading to noisy and chaotic behavior. To simplify, we approximate \u03c6 \u03b1 by deforming a single initial surface using N sequential pre-computed deformations scaled by weight parameters \u03b2 i. Deforming Implicit Surfaces: The initial surface is deformed using N sequential pre-computed deformations scaled by weight parameters \u03b2 i \u2208 [0, 1]. The deformed surfaces are aligned with each other using an alignment method from previous work. Each deformation relies on a spatial configuration from the previous deformation, requiring alignment adjustments. The final deformation is computed by aligning the accumulated deformations. The final deformation is computed by aligning accumulated deformations to represent the full set of target implicit surfaces. Two neural networks, denoted as f p and f d, approximate optimal weighting for each deformation and compute a final refinement deformation. These functions depend only on the simulation parameters space \u03b1. The problem is split into f p and f d, with pre-computed deformations for rough deformations and a generative CNN for refining the solution. Equations for training and applying deformations are explained, with a helper function D(x i , \u03b1) for deforming sets. Our work focuses on minimizing the L2 distance between deformed and target implicit surfaces by computing deformations weighting and synthesizing refinement fields using neural networks. The non-linearity of deformations is addressed by approximating functions with NNs, where f_p is represented by a parameter network for \u03b2 computation and a deformation network for w generation. Training involves encoding deformation effects in the loss function. Training neural networks involves encoding the effect of deformations in the loss functions to make the training process aware of their influence. The objective function measures the similarity between a known reference surface and the approximated result for a parameter value. The numerical equivalent of the continuous L2 loss is used, approximating the spatial integral via a sum over sample points. The challenge lies in computing reliable gradients for D to handle deformations effectively. The challenge in training neural networks involves computing reliable gradients for handling deformations effectively. By inferring \u03b2 and using a trained NN with specific loss functions, we can adjust deformation weights and generate deformations based on \u03b2. The goal of the deformation network is to compute refinement deformations. The deformation network f d computes the refinement deformation w based on \u03b1, capturing the interior of the parameter space. The refinement deformation is applied to the initial surface \u03c8 0 deformed by the set of \u03b2 i u i. Fine discretization is used for implicit surfaces like \u03c8, while lower resolutions are used for w. The gradient of the deformation loss is computed using the indicator function \u03c7 j (x) for a single deformation vector w j of w. The gradient derivation for deformation learning is an extension of STNs for dense, weighted fields and semi-Lagrangian advection methods. The parameter network combines and weights known deformation fields, while the deformation network generates offsets for cell centers to sample deformed images. Training details include fully connected layers with ReLU activation functions and de-convolution layers. Weight decay and L2 regularization are also applied. In practice, weight decay and L2 regularization are used in the deformation network to ensure smoothness. The loss function includes regularization parameters to prevent overly large loss values far from the surface. The tanh() function is applied to SDF values to emphasize the surface region. Boundary conditions are carefully considered to avoid artificial minima and maxima in the loss function during training. SDF values are extrapolated to maintain non-zero gradients at the domain sides. To train both networks, stochastic gradient descent with an ADAM optimizer and a learning rate of 10^-3 is used. Training is done separately for both networks, typically with 1000 steps for one and around 9000 steps for the other. Training data is generated from liquid simulations using the FLIP method. Two networks work together to capture complex behavior of the fluid space-time surface. The method is evaluated using a two-dimensional parameter space with implicit surfaces from a liquid simulation. The method involves training two networks using stochastic gradient descent with an ADAM optimizer. Training data is generated from liquid simulations using the FLIP method. The networks aim to capture complex behavior of the fluid space-time surface in a two-dimensional parameter space with implicit surfaces. The trained parameter network reduces loss to 59.4% of the initial value, leading to an improvement in approximating the target surface. The inferred deformation of the deformation network reduces the surface loss to 26.6% of its initial value, compared to 44.8% with weighted deformations. An ablation study shows the progression from undeformed surface loss to using only the parameter network, to deformations for a flat surface, to the full algorithm. The NN deformation successfully reconstructs the two arms in the center of the surface, which pre-computed deformations cannot capture. The trained model successfully learns to recover large-scale surface motion and match target surfaces closely, even recovering thin features. Regularization over varying target surfaces leads to an averaged result, with some misalignments visible in the deformed surfaces. The deformation network is trained to recover targets from a flat initial surface without pre-computed deformations, making it a challenging case. The regularization over varying target surfaces results in an averaged solution for deformation. The deformation network is trained to recover targets from a flat initial surface without pre-computed deformations, resulting in a reduction of the surface loss to 30%. Despite some loss of small scale features, the network reconstructs impact location and size accurately. Introducing a regular initial surface further improves performance, with a loss reduction to 22.2%. The deformation network reduces the surface loss to 22.2% of the baseline value, allowing for efficient synthesis of simulation results. The method yields highly reduced representations that can be visualized in an Android application, with the ability to add curvature-based shading and particle effects in real-time. The Android application allows users to release liquid drops at varying positions and sizes, with network evaluation taking 69ms on average. Rendering the implicit surface has an average frame rate of 50 fps. The original simulation for the liquid drop setup took 530 seconds on average. Our app generates liquid animations 2000 times faster than regular simulations, representing over 1700 input simulations in less than 30MB of storage. A setup captures a continuous flow around obstacles, showcasing different flow behaviors for the liquid. The data set consists of 1331 SDFs with an output resolution of 50 4, leading to significant reductions in surface loss. The final residual loss is 31.3% after applying the learned deformation, resulting in a frame rate of 30 fps on average. The approach has limitations such as assuming similarity in target surfaces and not utilizing certain information. The method presented involves generating space-time surfaces using deformation-aware neural networks. Future work could incorporate additional constraints like conservation laws to improve results. The L2 based loss used can lead to smooth results, but approaches like GANs may enhance the outcomes. The method shows significant improvements in surface reconstruction accuracy. Our method demonstrates significant improvements in surface reconstruction accuracy using deformation-aware neural networks. It can capture complex surface behavior and has potential applications beyond liquid surfaces, such as object collections or moving characters. Future extensions could involve inferring deformations for input sets without existing parametrization. This supplemental document details aligning multiple deformation fields and presents gradients for parameter and deformation networks, along with additional results. The text discusses deforming a single input surface to match instances of different deformations. It aims to use a single deformation for each dimension of the parameter space. The approach involves applying pre-computed deformations sequentially, but there are drawbacks to this method. The approach involves applying pre-computed deformations sequentially, but drawbacks include accumulation of deformation errors and performance issues due to multiple advection steps. The approach involves combining deformations with independent control over horizontal position and drop size by adjusting \u03b2 1 and \u03b2 2. An alternative method aligns deformation fields to the final position, accumulating them through addition for a single-step application. This eliminates errors and performance issues associated with multiple advection steps. The approach combines deformations with independent control over position and size by adjusting \u03b2 values. Deformations are aligned to the final position, accumulated through addition for a single-step application, correcting for errors and performance issues. The final deformation field v fin (x, \u03b2) is obtained by summing deformations with independent control over position and size. The deformation is transported to x using v inv through an inverse semi-Lagrangian step. Multiple values are normalized and filled in iteratively to ensure all cells in the target deformation grid receive a contribution. The final deformation field v fin (x, \u03b2) is calculated by summing deformations with independent control over position and size. The deformed SDF is then calculated with a regular advection step, applying the final, aligned deformation. This method respects partially applied deformations and precomputes aligned deformations u * (x). The final result is obtained by summing up all deformations in v sum and v inv, applying one forward-advection step to compute v fin, and deforming the input SDF using semi-Lagrangian advection. Our method corrects the deformation field v sum by transforming it into v fin, which acts on the correct spatial locations. This allows for the intended result to be computed successfully, as shown in the final image. The algorithm for aligning deformations serves as the starting point for learning the weights \u03b2, followed by adjusting the resulting surface with an additional deformation field generated by a trained model. The algorithm corrects the deformation field by transforming it into v fin, aligning deformations to learn weights \u03b2, and adjusting the surface with a trained model's deformation field. Gradients are derived for learning the weighting and refinement deformation to minimize the L2 loss between the final deformed surface and reference surfaces. The parameter network computes \u03b2(\u03b1) to minimize the equation, requiring gradients with respect to network weights \u03b8 i. The algorithm corrects the deformation field by transforming it into v fin, aligning deformations to learn weights \u03b2, and adjusting the surface with a trained model's deformation field. Gradients are derived for learning the weighting and refinement deformation to minimize the L2 loss between the final deformed surface and reference surfaces. The gradient of Eq. (12) with respect to the deformation parameter \u03b2 i is calculated by differentiating Eq. (11) with respect to \u03b2 i. The derivative of the network output \u03b2 i with respect to a specific network weight \u03b8 l ij is easily calculated with backpropagation. The correct way to derive the change in v fin (x, \u03b2) is by taking the total derivative of v sum (x, \u03b2) = v fin (x + v inv (x, \u03b2), \u03b2) with respect to \u03b2 i. The Jacobian in the equation has small entries due to the smooth nature of the deformations v fin, and does not significantly improve the gradient. After finding that the Jacobian does not significantly improve the gradient, we set it to zero. This allows us to estimate the change in deformation fields for changes in deformation parameters using a forward-advection algorithm. By assembling the gradient, we can train the parameter network with back-propagation to approximate \u03c6 \u03b1 with a set of given end-point deformations. The method proposes generating an additional space-time deformation field that changes with simulation parameters to increase variation. A neural network with four-dimensional deconvolution layers is used to model this function, allowing for more expressive capabilities to influence the final deformed surface. The parameter network learns how to apply multiple long-range, non-linear deformation fields, while the deformation network generates a dense space-time deformation field. The deformation network, utilizing de-convolutional layers, generates dense deformation fields to refine the final surface based on simulation parameters. The network learns to accommodate the nonlinear behavior of the surface after applying weighted deformations, with the output being four-component vectors at a specified resolution. The SDF resolution and deformation resolution can differ, allowing for reduced weights and computations during training. The deformation network generates dense deformation fields to refine the final surface based on simulation parameters. Each four-dimensional vector of the deformation acts on a region of the SDF, with the deformation field represented as DISPLAYFORM2. The gradient of the loss-function is calculated with respect to the network weights, and the derivative is obtained by summation over the affected region. The algorithm for training the deformation network involves deforming input SDF gradients with the inferred deformation field to calculate loss gradients accurately. For evaluation, two-dimensional SDFs from simulations of a drop falling into a basin are used, with simulation parameters determining the size and initial position of the drop. A single frame at t = 30 is extracted for training the networks described in section 3. The training process involves sampling the parameter domain with a grid, using 2156 training samples with 100 for validation. Validation and training loss are shown in Fig. 14, with the process converging to a stable solution. Deformation training shows lower loss due to increased expressive capabilities. The solution is verified to converge after 36000 additional steps. Using a simpler approximation for forward advection is not recommended due to strong non-linearity. The deformation network approach is compared to other algorithms for non-linear dimensionality reduction, such as PCA. While PCA with reduced basis yields a similar reduction in memory footprint, it fails to capture details of the parameter space behavior. The deformation network method provides a more detailed and accurate representation, as shown in Fig. 5. The deformation network method provides a more detailed and accurate representation of the parameter space behavior compared to PCA with reduced basis. The surfaces obtained with the deformation weights adapt to changes in the interior of the parameter space, but do not capture every detail of the references. The solution is regularized by the varying reference surfaces in small neighborhoods, resulting in an averaged behavior learned by the networks. The deformation network method offers a detailed representation of the parameter space, capturing intricate details that PCA with reduced basis cannot. The method adapts to changes in the parameter space interior but does not fully replicate the reference surfaces. The solution is regularized by varying reference surfaces in small neighborhoods, leading to an averaged behavior learned by the networks. In the 2D parameter space of FIG1, surfaces reconstructed with PCA, weighted deformations, and the full method with a deformation network are compared, highlighting the superior reconstruction capabilities of the full method. The deformation network method provides a detailed representation of the parameter space, capturing intricate details that PCA with reduced basis cannot replicate. It adapts to changes in the parameter space but does not fully replicate the reference surfaces. The method is regularized by varying reference surfaces in small neighborhoods, leading to an averaged behavior learned by the networks. In training data, simulations are run with a spatial resolution of 100^3 to generate reference SDFs. The introduction of the deformation network helps represent the target surface across the parameter range, showing advantages over direct interpolation of SDF datasets. The algorithm requires a single full-resolution SDF, three half-resolution deformations, and neural network weights, encoding the full behavior with less storage than two full SDFs. The direct SDF interpolation method requires more storage than the deformation network approach. It leads to undesirable artifacts such as ghosting and loss of detail, producing smoothed and repeated copies instead of the desired result. The deformation network method captures intricate details in the parameter space and adapts to changes, providing a more detailed representation of the target surface. The video demonstrates the impact of a larger number of pre-computed deformations on quality. However, minimal changes were observed in a setup with closely matching surfaces. Another test setup explores obstacle boundary conditions parametrized with \u03b1. Additional examples show the influence of the deformation network on surfaces at different time steps. The final surfaces based on inferred deformation fields closely match the target surface, unlike direct SDF interpolation which leads to loss of shape and splash detail, as well as ghosting artifacts. The liquid flows around a divider obstacle in a U-shaped manner, with higher resolution used for space-time SDFs and deformation network output. Performance details can be found in the table. The setup allows users to adjust stair heights and wall width dynamically, with deformations computed in the background. The changing obstacle conditions result in varying liquid streams over the steps. Screens from the mobile application show different flows based on divider positions."
}