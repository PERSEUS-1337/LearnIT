{
    "title": "Syg-YfWCW",
    "content": "Knowledge bases (KB), whether automatically or manually constructed, are often incomplete. Many valid facts can be inferred by synthesizing existing information. A popular approach for KB completion involves inferring new relations through combinatory reasoning over information connecting entities. Previous models focused on predicting missing relations or evaluating proposed triples using random paths or learned paths. A new algorithm, MINERVA, tackles the challenging task of answering questions where only one entity is known, addressing the impracticality of random walks in a setting with unknown destinations and numerous paths from a start. MINERVA is a neural reinforcement learning approach for navigating knowledge bases based on input queries. It competes well with current state-of-the-art methods on seven datasets. Automated reasoning on large, incomplete knowledge bases presents challenges and opportunities for inferring new facts. The focus of automated reasoning approaches has been to learn reasoning paths in knowledge bases, such as answering questions about who Malala Yousafzai shared her Nobel Peace Prize with. Symbolic logical rules have been integrated with machine learning, but distributed vector representations have become more popular for learning entity and relation embeddings. Neural multi-hop models address the limitations of tensor factorization and neural methods in capturing chains of reasoning expressed by KB paths. These models operate on KB paths embedded in vector space, but rely on a set of paths gathered through random walks, independent of the query relation. The paper presents a method using reinforcement learning to efficiently search a knowledge graph for answer-providing paths based on input questions. The RL agent, MINERVA, learns to navigate the graph by choosing labeled relation edges to reach the correct answer node, maximizing expected rewards. This approach eliminates the need for precomputed paths and offers many advantages. MINERVA, an RL-based formulation, can answer complex questions by navigating a knowledge graph without pretraining. It efficiently searches a small neighborhood around the query entity, providing interpretable provenance for its predictions. MINERVA is an RL-based model for query answering on knowledge graphs, trained using policy gradients. It outperforms other methods like Neural Theorem Provers and embedding-based models on benchmark datasets. MINERVA can also handle partially structured natural language queries and has been tested on the WikiMovies dataset. MINERVA outperforms DeepPath on the NELL-995 dataset for query answering tasks. The task is formally defined as querying a knowledge base (KB) with entities (E) and binary relations (R). A knowledge graph (G) is constructed from the KB, where entities are nodes and relations are labeled edges. The graph is a directed labeled multigraph (V, E, R) with inverse relations added for each edge. In this work, a query answering model is presented that efficiently traverses a knowledge graph to find answers, eliminating the need for exhaustive computation. The model addresses the tasks of fact prediction and query answering in knowledge bases by adding inverse relations to edges and predicting the truth of facts. This approach aims to overcome the computational overhead associated with evaluating all candidate answer entities, especially in large knowledge bases with millions of entities. The query answering model efficiently traverses a knowledge graph to find answers, eliminating the need for exhaustive computation. It addresses fact prediction and query answering tasks in knowledge bases by using a deterministic partially observed Markov decision process on the graph. The model is trained using policy gradients and REINFORCE with control variates. The knowledge graph derived from the KB is used to specify a deterministic partially observed Markov decision process. The state space consists of valid combinations representing query, answer, and exploration location. The agent observes its current location and query, but not the answer. Actions are determined based on the state of the environment. The set of possible actions from a state consists of all outgoing edges from a vertex in the graph. Agents can choose which edge to take based on the label and destination vertex. The computation graph is unrolled up to a fixed number of time steps, with a special 'NO OP' action allowing the agent to stay at a node. This design helps in answering questions more efficiently and allows the agent to remain at an 'answer node' once reached. The agent can choose actions based on edges in the graph, with a special 'NO OP' action to stay at a node. The environment transitions deterministically by updating the state to a new vertex. Rewards are only given at the end if the current location is the correct answer. To solve the deterministic partially observable Markov decision process, a randomized non-stationary history-dependent policy is designed using LSTM. The agent encodes history as a continuous vector and updates the history embedding based on LSTM dynamics. The policy network uses LSTM to encode history as a continuous vector and make decisions based on available actions and query relations. The network is a two-layer feedforward network with ReLU nonlinearity. The policy network is a two-layer feedforward network with ReLU nonlinearity that takes in history representation and query relation embedding to output a probability distribution over possible actions. The decision probabilities lie on a simplex of size |A S t | and the procedure is invariant to the order of edges. The parameters of the LSTM, weights, biases, and embedding matrices form the parameters of the policy network. The goal is to find parameters that maximize the expected reward. To maximize the expected reward, parameters are optimized using REINFORCE. The first expectation is based on the training dataset's empirical average, while the second is approximated through multiple rollouts. A moving average of cumulative discounted reward is used as a baseline for variance reduction. MINERVA is competitive for query answering on small and large KBs, superior to path-based models, capable of handling natural language queries, reasoning over long chains, and robust to train with faster inference time. The reasoning capability is tested by answering queries of the form (e 1 , r, ?). MINERVA is compared with state-of-the-art models for query answering on KBs, focusing on answering queries of the form (e 1 , r, ?). The ranking procedure differs from fact checking in a KB, requiring a re-run of previous implementations. Beam search with a width of 50 is used for inference, ranking entities based on the probability of the trajectory taken by the model. MINERVA is compared with state-of-the-art models for query answering on KBs using standard metrics like HITS@1,3,10 and MRR. Comparison includes DistMult, ComplEx, ConvE, Neural Theorem Provers, and NeuralLP. Results are shown in Table 3 for KINSHIP and UMLS datasets. The COUNTRIES dataset contains countries, regions, and subregions as entities and is designed to test logical rule learning and reasoning capabilities of link prediction models. Queries are of the form LocatedIn(c, ?) with answers as regions. Tasks S1-3 require reasoning steps of increasing length and difficulty. The UMLS dataset consists of biomedical concepts and relations like treats and diagnoses. The KINSHIP dataset also contains entities and relations. The KINSHIP dataset contains kinship relationships among members of the Alyawarra tribe from Central Australia. MINERVA compares favorably or outperforms baseline models on most tasks, except for task S2 of COUNTRIES where NTP-\u03bb and ConvE outperform it. Task S3 shows the most prominent gains. Embedding based methods perform better than logical rule learning methods on small KB datasets like Kinship and UMLS. ComplEx and DistMult outperform logical rule learning methods like NTP, NeuralLP, and MINERVA on small datasets like Kinship and UMLS. MINERVA performs well on Kinship but does not show significant improvement when initialized with pre-trained embeddings of ComplEx. MINERVA is then evaluated on larger KG datasets - WN18RR, FB15K-237, and NELL-995, with WN18RR and FB15K-237 datasets being more challenging due to the removal of test leakage sources. The NELL-995 dataset released by BID53 has separate graphs for each query relation, with some test triples removed to make the datasets more challenging. Analysis of query relations on FB15K-237 shows that embedding-based methods outperform MINERVA and NeuralLP due to significant differences in query relation types. Analysis of query relations on FB15K-237 dataset categorized query relations into different types such as (M)any to 1, 1 to M, or 1 to 1 relations. The model is evaluated based on its ability to predict the one target entity in the query triple, even though MINERVA sometimes outputs end points of paths as target entities without a direct path from the source entity. In FB15K-237 dataset, query relations are classified as 1-to-M or M-to-1 based on the ratio of tail to head entities. The validation set shows 54% of queries are 1-to-M and 26% are M-to-1. In contrast, NELL-995 has 27% 1-to-M and 36% M-to-1. The high percentage of 1-to-M relations in FB15K-237 affects MINERVA's performance. The frequency of unique path types in different datasets varies significantly. For example, in NELL-995, over 1000 path types occur more than 1000 times, while WN18RR has only 11 different relation types. FB15K-237 exhibits a different pattern with fewer path types occurring more than 1000 times. In NELL-995, there are over 1000 path types occurring more than 1000 times, while FB15K-237 shows a decrease in repeated path types as the threshold increases. MINERVA struggles to learn generalizable path types due to the lack of frequently repeating paths. Neural multi-hop models like BID30 and BID47 operate on KB paths between entity pairs, requiring knowledge of the target entity for pre-computation, except for BID17 which uses random walks to predict the target entity. The model combines approaches from BID30 and BID47 by sampling random paths between source and target entities, encoding them with an LSTM, and using a feed forward network to score possible target entities. The performance of this model is shown in the PATH-BASELINE column of table 4. MINERVA outperforms the baseline model significantly by effectively reducing the search space and focusing on relevant paths to answer queries. Comparing with DeepPath, which uses RL to pick paths, MINERVA shows superior performance in ranking answer entities against negative examples. MINERVA improves search space efficiency and focuses on relevant paths for query answering. It outperforms DeepPath by training one model for all query relations, leveraging correlations and more data. If MINERVA fails to reach entities, it falls back to random ordering. Queries in KBs are structured as triples, but MINERVA is extended to handle natural language queries. MINERVA is extended to handle natural language queries using the WikiMovies dataset, which contains questions in natural language. A simple question encoder is used to compute the vector representation of the query relation, without using pretrained embeddings. The experiment results are compared with those reported in TAB7, showing promising progress towards multihop reasoning. MINERVA is a promising model for multihop reasoning using KBs to answer natural language questions. It can learn long reasoning chains and is tested on a synthetic grid world dataset. The KB consists of atomic triples for navigation tasks, and MINERVA shows robustness to queries requiring longer paths compared to Neural LP. MINERVA is robust to queries requiring longer paths, showing minimal performance degradation even for the longest path in the dataset. It converges to a higher score faster than DistMult during training, with higher performance from the early stages due to its efficient strategy of searching in the neighborhood of the source entity. At test time, embedding-based methods like ConvE, ComplEx, and DistMult rank all entities in the graph. MINERVA is efficient at inference time by searching for answer entities in its local neighborhood, with inference time depending on the degree distribution of the graph. The average inference time for MINERVA follows a power law degree distribution, with a median inference time of O(1) for all values of \u03b1. This is independent of the size of entities in the graph. On the WN18RR test dataset, MINERVA's wall clock inference time is 63s. MINERVA is efficient at inference time, with a wall clock inference time of 63s on the WN18RR test dataset. On the NELL-995 test set, MINERVA's inference time is 35s compared to 115s for a GPU implementation of DistMult. Query-based decision making is utilized, where the agent conditions on the query relation to make decisions. Model robustness is also highlighted, with reported mean and standard deviation scores across multiple runs. The MINERVA model shows efficiency in inference time and robustness in decision-making. It can easily achieve high scores across runs with low deviations. The model's ability to recover from incorrect decisions is demonstrated through inverse relations. While traditional methods for reasoning with knowledge bases fall short in capturing complex patterns, multi-hop link prediction approaches address these limitations by following inference paths in KBs. BID22 filters paths based on constraints to end at target entities within a maximum length. Our approach eliminates pre-computed paths and efficiently searches the graph based on input query relation. ILP BID29 learns general purpose predicate rules from examples and background knowledge. Early ILP work like FOIL BID36, PROGOL BID28 are rule-based or require negative examples, hard to find in KBs. Statistical relational learning methods combine machine learning and logic but operate on symbols rather than vectors. Prior work treats inference as search over natural language space. WikiNav and Wikispeedia involve navigating graphs using natural language. BID0 propose natural logic inference as a search from a query to a valid premise. Neural Theorem Provers (NTP) and Neural LP are methods for learning logical rules through gradient-based learning. NTPs use Prolog's backward chaining inference method on vectors, while Neural LP uses operators from TensorLog for rule learning. NTPs face challenges with large computation graphs due to soft-matching, resorting to heuristics for tractability. The efficacy of NTPs on large knowledge bases is still unproven. MINERVA, a differential rule learning system, utilizes a LSTM controller with a differentiable memory component for end-to-end training. It outperforms other methods like DeepPath and RL approaches by not requiring prior knowledge of the target entity for path finding in knowledge bases. DeepPath and MINERVA are compared in their approach to query answering on the NELL dataset. MINERVA utilizes a LSTM controller with a differentiable memory component, while DeepPath uses fixed pretrained embeddings for entities and relations. MINERVA outperforms DeepPath in their experimental setting. Additionally, MINERVA is similar to methods for learning structured prediction based on imitating a reference policy, but in the context of automated reasoning on knowledge bases, it is unclear what a good reference policy would be. A new approach to automated reasoning on knowledge bases using knowledge graphs representation, training an agent to navigate to the answer node based on the input query. Achieving state-of-the-art results on knowledge base completion tasks without pretraining or supervision. Future research includes exploring more advanced RL techniques and working directly on textual queries and documents. Experimental details include using a 3-layer LSTM with hidden size of 400 and Adam BID20 optimizer. In experiments, hyper parameters \u03b2 and \u03bb were tuned for the model using Adam BID20 optimizer. Best hyper parameters for all datasets were listed in table 11. NELL dataset included additional tasks not compared against DeepPath, but MINERVA results were reported."
}