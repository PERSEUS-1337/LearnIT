{
    "title": "S1q_Cz-Cb",
    "content": "The novel approach presented involves training neural abstract architectures with (partial) supervision over interpretable components. The concept of a differential neural computational machine (\u2202NCM) is introduced, showing that existing architectures like NTMs and NRAMs can benefit from additional supervision. Experimental evaluation with NTM and NRAM architectures demonstrates improved convergence and generalization compared to training with only input-output examples. In this work, the focus is on providing additional supervision for interpretable components in neural abstract machines to bias learning towards the desired solution. The concept of partial trace supervision is introduced to offer more detailed information during training beyond input-output examples. The concept of a differential neural computational machine (\u2202NCM) is introduced to provide more detailed information during learning beyond input-output examples. Common architectures like Neural Turing Machines (NTMs) and Neural Random Access Machines (NRAMs) can be framed as \u2202NCMs, while other machines like the Neural Program Interpreter (NPI) require large amounts of supervision and cannot be instantiated as an \u2202NCM. The \u2202NCM abstraction is a useful tool for understanding neural abstract machines with additional supervision. \u2202NCM loss functions capture partial trace information for NTMs and NRAMs, improving convergence, generalization, and interpretability. Experimental results show significant benefits of additional supervision in training tasks like Flip3rd. An NTM is trained to solve tasks like Flip3rd, with the goal of generalizing well. However, without richer supervision, it can easily overfit to the training set, leading to chaotic and erratic behavior in reads and writes. This is illustrated in figures showing overfitting and erratic NTM behavior. The NTM exhibits erratic behavior in reads and writes, particularly from the third bit with a smaller weight. A more interpretable model is needed to guide training towards desired behavior. Introducing partial trace information on read heads biases learning towards the desired NTM model. This approach is illustrated using the concept of a neural computational machine (NCM) that mimics classic computational machines. Our approach for supervision with partial trace information applies to all neural architectures expressible as NCMs, delineating end-to-end differentiable architectures (NTM, NRAM) from those that require trace information. An NCM consists of a processor, a controller, and a loss function, with the processor executing commands on memories and producing feedback, while the controller decides actions based on inputs. The controller \u03ba in a neural architecture (NCM) decides machine operations based on inputs, feedback, and internal state. It can depend on parameters in W, such as neural network weights. The loss function Le measures how close a machine's execution trace is to a desired behavior set E, guiding training with differentiability conditions. The loss surface is continuous and piecewise differentiable with respect to weights for all examples and inputs. The machine's execution begins with an input sequence and initial values of controller state, memory, and processor feedback. Traces record values at each time step, and differentiability conditions do not imply continuity or differentiability of NCM functions. Differentiable neural computational machines (\u2202NCM) have continuous and piecewise differentiable parameters, allowing for training with trace information without specifying corresponding values in examples. NTMs and NRAMs can be instantiated as \u2202NCMs, with NTM having access to a memory of cells and real numbers. The NTM has read and write heads that compute expected values and make decisions on erasing and adding fractions to cells. The write head stores the tape after modifications, and the controller determines head movement and outputs values. The variables of the NTM fall into different classes in terms of NCMs. The Neural Random Access Machine (NRAM) has variables that change over time according to specific equations. The NRAM includes a memory with variable size and a register file with a constant number of registers storing probability vectors. The controller reads the probability assigned to 0 by a register at each time step. The NRAM performs computation using a fixed sequence of modules that manipulate memory with probability vectors. The controller organizes these modules into a circuit at each time step, encoded by probability distributions in matrices a, b, and c. The NRAM uses matrices a, b, and c to specify values for memory registers at each time step. The loss function of the NRAM is more complex than that of the NTM, incorporating termination probabilities and log likelihood calculations. Supervision during training can aid in convergence by biasing the minimization of the NRAM's loss function. The NRAM uses matrices to specify memory values at each time step, with a complex loss function incorporating termination probabilities. Additional bias can guide the NRAM towards good solutions, improve interpretability, and enhance generalization. This bias is implemented by encoding specific commands into extra loss terms, illustrated with an example of biasing learning with an NTM for a copying task. The NRAM uses matrices to specify memory values at each time step, with a complex loss function incorporating termination probabilities. Additional bias can guide the NRAM towards good solutions, improve interpretability, and enhance generalization. This bias is implemented by encoding specific commands into extra loss terms, illustrated with an example of biasing learning with an NTM for a copying task. The machine's output {y t } 2l 1, where the last input x l from the first half is a special value indicating that the first half ended. Starting with both heads at position 1, the most direct solution is to consecutively store the input to the tape during the first half of the execution, and then recall the stored values during the second half. In such a solution, we expect the head positions to be. To incorporate this information into the training, we add loss terms that measure the cross-entropy (H) between p(t) and w t as well as between q(t) and r t. Importantly, we need not add terms for every time-step, but instead we can consider only the corner cases where heads change direction: H(p(t), w t) + H(q(t), r t). We now describe the general shape of the extra loss terms for arbitrary NCMs. Since, typically, we can interpret only the memory and the processor in terms of well-understood operations, we will consider loss terms only for the memory state. The generic loss function for NCM traces includes four loss functions for memory state and communication flow between controller and processor. Each part has hints indicating time step, example, and weight to account for importance and confidence. Subtraces contain hints for specific input-output examples. The subtrace in NTMs includes hints for a subset of states traced during execution, with a net loss calculated by adding original loss and weighted losses for hints. Loss terms are included for memory state only, with tape values interpreted based on an internal encoding. Loss is applied to a decoded version of a tape cell to avoid negative training effects from forcing a specific encoding. The decoder in NTMs improves convergence by providing consistency in representations. An auxiliary network is trained with the NTM to decode memory cells. Hints with unit weight guide NRAMs in constructing circuits. Loss is applied based on the controller's connection choices. In experiments, assigning higher weight to hints at earlier timesteps is crucial for training convergence. The machine's behavior at later timesteps depends on its early behavior, making it necessary to fix early behavior for later correctness. The NCM can be applied to various architectures like LSTM networks or End-To-End Differentiable Memory Networks. Any neural network with interpretable intermediate states and additional hints in the dataset is a good candidate for this approach. The dataset with additional hints is suitable for the NCM supervision method applied to NTM and NRAM architectures. The study evaluates the impact of trace supervision on convergence, interpretability, and generalization. The research explores the amount of supervision required for training these models, with findings detailed in the appendix. The experiments show the importance of early timestep hints for training convergence and the successful generalization of NTM models. The study evaluates the impact of trace supervision on NTM and NRAM architectures, showing improved generalization with various hint types. RepeatFlip3d task saw the largest improvement with corner hints, reaching a 40% success rate. In an experiment evaluating trace supervision on NTM and NRAM architectures, corner hints led to an eight-fold increase in success rate, reaching 40%. RepeatCopyTwice task achieved 100% success with hints. Varying the global \u03bb parameter and providing hints for a fraction of examples showed efficacy depending on these parameters. Training with traces 50% of the time generally improved performance compared to the best method. In an experiment evaluating trace supervision on NTM and NRAM architectures, corner hints significantly improved success rates. Training with trace supervision led to more interpretable behaviors and sharper head positions/tape values. Certain tasks like Swap and Increment occasionally generalized perfectly, while others like Permute, ListK, and Merge were not extensively tested. The study showed that increasing supervision with hints improved the quality of trained models significantly. Even with noise in the input, generalization was not hindered. Adding hints improved generalization in tasks like Permute, even when noise was introduced. The study demonstrated that incorporating partial trace information into the training of neural abstract machines improved learning efficiency for tasks like Increment. The \u2202NCM architecture was introduced to capture these machines, and experimental results showed its effectiveness in guiding the learning process. The study showed that using partial trace information improved learning efficiency for tasks like Increment in neural abstract machines. The NTM controller includes networks operating on variables like controller state and read address, while the NRAM controller operates on variables like register inputs and memory tape. Architectural differences from the original NTM were implemented in the experiments. The study implemented architectural differences in the NTM controller, such as using tanh activation and softmax output. Experiments were conducted on five tasks for sequence manipulation, including two new tasks. Various loss combinations were tested, and training performance per task was observed. The corner setup focused on important cases, differing from the address setup. In the study, the NTM controller's architectural differences were explored, with experiments conducted on five sequence manipulation tasks. The corner setup focused on key cases, adjusting supervision levels for performance evaluation. The NTM's generalization was measured based on accuracy on testing examples. The study tested sequence manipulation tasks using a feed-forward controller with varying units. Training sequences ranged from 1 to 5, while testing sequences went up to 20 in length. For specific tasks, training sequences were up to 16, with testing sequences reaching a maximum length of 32. The model used a two-layer feed-forward controller with ReLU activation function, noise parameter \u03b7 = 0.3, and curriculum learning. Training stopped once a specified difficulty level was reached. The study tested sequence manipulation tasks using a feed-forward controller with varying units. Training sequences ranged from 1 to 5, while testing sequences went up to 20 in length. For specific tasks, training sequences were up to 16, with testing sequences reaching a maximum length of 32. The model used a two-layer feed-forward controller with ReLU activation function, noise parameter \u03b7 = 0.3, and curriculum learning. Training stopped once a specified difficulty level was reached. The training iteration trains with 50 examples of the randomly sampled difficulty, stopping after 5000 samples regardless of convergence. The tasks and supervision methods are detailed in appendices, with the system implemented using PyTorch and specific input sequences described. The study tested sequence manipulation tasks using a feed-forward controller with varying units. Training sequences ranged from 1 to 5, while testing sequences went up to 20 in length. For specific tasks, training sequences were up to 16, with testing sequences reaching a maximum length of 32. The model used a two-layer feed-forward controller with ReLU activation function, noise parameter \u03b7 = 0.3, and curriculum learning. Training stopped once a specified difficulty level was reached. The training iteration trains with 50 examples of the randomly sampled difficulty, stopping after 5000 samples regardless of convergence. The tasks and supervision methods are detailed in appendices, with the system implemented using PyTorch and specific input sequences described.\n\nTasks included RepeatCopyTwice, DyckWords, and Flip3rd. RepeatCopyTwice involves copying the input sequence twice, DyckWords requires identifying balanced parentheses sequences, and Flip3rd flips the 3rd bit in a sequence of bits. These tasks were designed to test the model's ability to manipulate sequences effectively. The task Flip3rd involves flipping the 3rd bit in a sequence of bits. The input is a sequence of bits, and the desired output is the same sequence with every 3rd bit flipped. The model provides hints for memory at each timestep, including read and write head addresses. In experiments with NRAM, important timesteps are determined based on tasks. Tasks chosen were those NRAM struggles to generalize on. Tasks included Swap, Increment, and Permute, each with specific instructions. The NRAM experiments focused on specific tasks such as Swap, Increment, and Permute, each with unique instructions. The tasks involved manipulating arrays and linked lists to generate desired outputs. The number of timesteps required varied based on the complexity of the problem instance. The NRAM experiments focused on specific tasks like Swap, Increment, and Permute, involving manipulating arrays and linked lists. Subtraces types provide hints based on hand-coded circuits for different timesteps and modules. The execution details revealed in a Subtrace are controlled by the first dimension listed in the tables. In tasks Copy, RepeatCopyTwice, and DyckWords, NTM generalizes without supervision, converging to interpretable algorithms. addr+val traces designed to match this algorithm increase generalization frequency by at least 45%. Providing supervision reflecting NTM's natural behavior improves learning robustness. Training with read supervision outperforms baseline and other supervision types in tasks Flip3rd and RepeatFlip3d. Corner supervision in RepeatFlip3d achieves highest improvement, diminishing local minima occurrence in loss function. The trace can reduce local minima in the loss function. Varying the frequency of extra subtrace supervision affects model robustness. Different tasks show different optimal trace frequencies for generalization. The type of trace that works best varies per task, with a trace that can greatly improve performance even when provided only 1% of the time. Different tasks require different levels of supervision for optimal performance. Experimental results show that while neither the DNGPU nor the NRAM can generalize perfectly, the simpler NRAM architecture performs better with fewer errors. The NRAM architecture, parametrized by straight-line partial programs chosen by register states, runs in a loop executing the selected program. Programs are in a simple imperative language with assignments to local variables. The final program statement modifies machine registers using variables, machine registers, or holes as values, supplied by the NRAM controller during execution. The NRAM architecture runs programs chosen by register states, with values supplied by the controller during execution. Programs are in an imperative language with assignments to variables and machine registers. An example program for the Increment task is provided, where the controller is guided to read, add, and store values in memory. An alternative approach is to have the controller produce values only for unspecified parts of the program. The NRAM architecture runs programs chosen by register states, with values supplied by the controller during execution. Programs are in an imperative language with assignments to variables and machine registers. An example program for the Increment task is provided, where the controller is guided to read, add, and store values in memory. An alternative approach taken by \u2202Forth BID0 involves expressing programs in a variant of Forth programming language, allowing for less syntactic constraints but requiring specification of time steps for arguments in all possible executions. Register states are described using symbols like \"0\", \"! 0\", and \"-\" to represent different values. The NRAM architecture executes programs based on register states and values provided by the controller. Programs involve assignments to variables and machine registers. An example program for the Increment task is given, where values are read, added, and stored in memory. Register states are represented using symbols like \"0\", \"! 0\", and \"-\"."
}