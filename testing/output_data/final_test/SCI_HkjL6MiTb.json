{
    "title": "HkjL6MiTb",
    "content": "Survival Analysis in the presence of competing risks is a challenging problem in various fields. The Siamese Survival Prognosis Network is a novel Deep Neural Network designed to learn from data with multiple adverse events. It issues pairwise concordant time-dependent risks, optimizing event times' distribution parameters effectively. Our architecture directly optimizes the C-discrimination index for survival analysis with competing risks, showing consistent performance improvements on medical datasets. Survival analysis analyzes time to adverse events, while competing risks distinguish between multiple events. The application of survival analysis is vast, with a focus on medicine where competing risk analysis is crucial. Competing risk analysis is crucial in medicine, especially for an aging population with multiple comorbidities. It allows for analyzing the time to the first observed event and the type of event. Deep learning has shown advantages over statistical methods in survival analysis, with the Cox proportional hazards model being a basic statistical model. One limitation of Cox PH model is that its time dependent risk function is the product of a linear covariate function and a time dependent function. BID15 replaced the linear covariate function with a feed-forward neural network for performance improvements in survival analysis. Existing competing risks models do not scale well to large datasets with many patients and covariates, so a deep learning architecture is proposed to address this challenge. Designing a deep learning architecture for survival analysis with competing risks is challenging due to the need to optimize the time-dependent discrimination index. Previous works have shown that directly optimizing the AUC can lead to better generalization performance. In this study, a novel Siamese feed-forward neural network is developed for survival analysis with competing risks. The Siamese feed-forward neural network BID3 is designed to optimize concordance and the time-dependent discrimination index BID2 for survival analysis with competing risks. It estimates risks in a relative fashion, jointly estimating risks for all causes to generate a shared representation capturing the data's latent structure. The architecture compares different risks for competing events at different times to arrange them in a concordant fashion. Our architecture aims to maximize the gap between output risks among different inputs by introducing a continuous approximation of the time-dependent discrimination function. Training a neural network only over observed survival times may lead to poor out-of-sample performance. To improve generalization capabilities and address nonidentifiability issues, a loss term is added to the algorithm's function. This forces the survival curve of the patient with longer survival time to be lower than the curve of the patient with shorter survival time. By generating concordant risks instead of true cause-specific survival curves, the nonidentifiability problem is avoided. This approach shows modest yet statistically significant improvements. In survival analysis with competing risks, modest yet statistically significant improvements were reported over state-of-the-art methods on both synthetic and real medical data. The focus is on healthcare where even minor gains can potentially save lives. For instance, a small performance improvement of 0.1% in a dataset of 72809 patients could have life-saving implications. The dataset comprises time-to-event information about subjects who may experience different events, including being censored or developing specific conditions like cardiac disease. In survival analysis with competing risks, the Cumulative Incidence Function (CIF) is computed to determine the probability of a specific event occurring before a certain time, based on subject covariates. The CIF evaluates the risk of experiencing an event at a given point in time. In survival analysis, the incidence function at a certain point represents the risk of an event before a specified time. The goal is to develop a neural network for competing risks survival analysis, deciding on the loss function and network architecture. The time-dependent discrimination index is commonly used to evaluate models. Previous works have shown that approximating the AUC and training a classifier leads to better generalization performance. These ideas will be applied to construct an approximation of the time-dependent discrimination index for training the neural network. The time-dependent discrimination index is used to evaluate models in survival analysis. It involves comparing the risks of subjects experiencing an event before a specified time. The index for a certain cause is the probability that a model correctly orders the risks of comparable pairs of subjects. The discrimination index in survival analysis compares risks of subjects for a specific cause. An estimator is used to calculate this index, with the numerator depending on the model. The simplified equation is used to construct the loss function for a neural network in the next section, which describes the network architecture and proposed loss functions for training. The neural network in Figure 1 consists of fully connected hidden layers with SELU activation. Neurons in the last hidden layer estimate the probability of a cause occurring in a time interval for a given subject. The output is a vector of probabilities. The cumulative incidence function for each cause at a specific time is computed. The loss function for training the network includes discrimination, accuracy, and a loss term. The metric in equation (6) cannot be directly used for training due to its discontinuity. The neural network uses a scaled sigmoid function to approximate the indicator function for training, ensuring better network performance. The scaling parameter \u03b1 determines the sensitivity to discrimination, with higher values leading to stricter discrimination penalties. Accuracy is defined using a scaled sigmoid function with parameter \u03ba, penalizing prediction errors. The neural network uses a scaled sigmoid function with a parameter \u03ba to optimize risk values for different time intervals. The loss term ensures minimal risk for right subjects before the event time of left subjects in comparable pairs. The neural network optimizes risk values for different time intervals using a scaled sigmoid function with a parameter \u03ba. The loss term ensures minimal risk for right subjects before the event time of left subjects in comparable pairs. The network is trained with inverse propensity weights to adjust for event and time interval imbalances, and regularized using SELU dropout. The loss function involves pairwise comparisons, making the training similar to a Siamese network. Hyper-parameter optimization, competing risk, and survival analysis experiments are discussed, with comparisons against the Cox PH model for single event problems. In risk and survival analysis experiments, comparisons were made against various models including Cox PH model, Fine-Gray model, and Competing Random Forest. The cause-specific extension of single event models was also discussed, with optimization done using 5-fold cross validation. The method referred to as SSPN was used, with a 60-20-20 division for training, validation, and testing sets. The study used a 60-20-20 division for training, validation, and testing sets. A standard grid search determined the optimal values for batch size, hidden layers, width of hidden layers, and dropout rate. The training sets consisted of patient pairs, with a batch size of pairs sampled with replacement. Validation performance was measured every 1000 training iterations, with a stopping criterion based on lack of improvement in the last x evaluations. Training sets typically contained tens of million pairs with patients appearing multiple times. The study used a 60-20-20 division for training, validation, and testing sets with patient pairs. Empirical results were achieved after 100K iterations with Tensorflow on 8-core Xeon E3-1240 with 32GB Ram. SELU activation and dropout showed superiority over ReLU. ReLU also performed well but less than SELU. SELU weight initialization, Adam optimizer, and decaying learning rate were used. The study used SELU activation and dropout which outperformed ReLU in 100K iterations with Tensorflow on 8-core Xeon E3-1240 with 32GB Ram. The model also utilized Adam optimizer and decaying learning rate for optimization. The results showed significant performance gains for frequent breast cancer events compared to infrequent CVD events. Additionally, a synthetic dataset was created to further demonstrate the method's performance. The study developed a model using SELU activation and dropout, outperforming ReLU in 100K iterations with Tensorflow on 8-core Xeon E3-1240 with 32GB Ram. The model utilized Adam optimizer and decaying learning rate for optimization, showing significant performance gains for frequent breast cancer events compared to infrequent CVD events. A synthetic dataset was created to demonstrate the method's performance. The model parameters were learned from time-to-event data while handling right censoring, with consistent performance gains observed. Competing risks settings are common in medicine, such as cardiovascular diseases, cancer, and geriatric populations with multiple diseases. Our novel deep learning architecture, based on the Siamese network, estimates personalized risk scores from time-to-event data with competing risks. It captures complex non-linear representations, outperforming existing methods by flexibly describing non-proportional hazard rates and interactions between covariates and survival times in diseases with heterogeneous phenotypes."
}