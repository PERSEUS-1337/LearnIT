{
    "title": "rkgHY0NYwr",
    "content": "The paper presents an approach to learn recomposable motor primitives from diverse manipulation demonstrations. It aims to overcome challenges in discovering primitives by jointly learning and recomposing them. The method constraints primitive decomposition and simplicity to learn a diverse set of motor primitives and a coherent latent representation. The learned primitives capture semantically meaningful aspects. The paper discusses learning primitives from manipulation demonstrations to efficiently solve robotic tasks like reaching and pushing. Current learning-based approaches can only perform tasks they were trained for, unlike humans who can effortlessly perform various manipulation skills. The paper explores learning motor programs from diverse robot demonstration data to create unified manipulation systems. By identifying commonalities in primitive actions across tasks, such as picking or pushing objects, the system can accelerate learning for various tasks. This approach aims to move away from task-centric learning towards a more unified manipulation system. The concept of motor programs, originating from Lashley and further developed by Keele and Schmidt, focuses on sequences of movements and muscle commands. Schmidt introduced the idea of 'generalized' motor programs that can abstract movement patterns. This work aims to discover shared motor programs across tasks to achieve diverse objectives efficiently. The concept of motor programs focuses on sequences of movements and muscle commands, aiming to discover shared motor programs across tasks to achieve diverse objectives efficiently. This approach allows for the quick acquisition of new skills by learning a set of desired motor programs to compose. Previous approaches have used manually defined primitives, but there have been attempts to simultaneously learn skills and underlying primitives. Learning both the desired skill and underlying primitives simultaneously is challenging, leading to narrow task restrictions. To overcome this, instead of learning primitives from scratch for a specific task, motor programs can be discovered using demonstrations of various skills like pouring, grasping, and opening. An approach is presented to discover movement primitives from unstructured robot demonstrations without parsing or segmentation labels. This task involves learning the space of primitives and understanding the demonstrations' content. Our approach involves learning a primitive space from diverse skills demonstrations and parsing them into high-level sequences of primitives. These motor programs are semantically meaningful and can be adapted and composed for specific tasks, including solving robotic tasks using reinforcement learning. Our work involves learning a primitive space from diverse skills demonstrations and parsing them into high-level sequences of primitives. This approach enables solving robotic tasks using reinforcement learning, achieving faster training compared to low-level control space methods. Our work is the first to learn the space of primitives without requiring segmentation annotation, allowing for a diverse set of demonstrations spanning multiple tasks. Learning from demonstrations involves techniques such as cloning demonstrated behavior, fitting parametric models, and segmenting demonstrations to learn a diverse set of composable and reusable motor programs for performing various tasks. This approach enables solving robotic tasks using reinforcement learning without requiring segmentation annotation. Learning and Sequencing Motion Primitives: Works have learned motion primitives from demonstrations using predetermined representations like Dynamic Movement Primitives (DMPs). Some have approached the problem from an optimization perspective. The question then arises on how to sequence learned skills for downstream tasks. Various approaches have been taken to answer this question, such as building a layered approach to adapt, select, and sequence DMPs. However, the predetermined representations of primitives used in these works can be restrictive, hindering the learning of expressive motions and adapting them to generic downstream tasks. The text discusses moving away from fixed representations of motion primitives and instead learning representations along with the primitives themselves using latent variable models. Several recent works have focused on learning latent representations of trajectories, such as SeCTAR and CompILE frameworks. These frameworks aim to learn variable length trajectory segments and use latent variables to represent them for hierarchical reinforcement learning. The text discusses learning continuous latent variable representations of trajectory segments in hierarchical reinforcement learning. The Options framework learns temporal abstractions over sequences of actions, with recent works managing to jointly learn internal option policies and a policy over those options using a reward function as feedback. The Option-Critic framework employs a policy-gradient formulation of options to achieve this. The text discusses learning hierarchical task representations in Learning from Demonstrations (LfD). Recent works have focused on inferring hierarchical structures of tasks performed in demonstrations, representing tasks as programs or task graphs. Unlike prior works, the approach aims to learn abstractions from a given set of demonstrations in a high-dimensional domain. The text discusses learning hierarchical task representations in Learning from Demonstrations (LfD) by inferring hierarchical structures of tasks from demonstrations. Prior works represent tasks as programs or task graphs, while the approach aims to learn abstractions directly from unstructured demonstrations in an unsupervised manner. The text discusses learning hierarchical task representations in Learning from Demonstrations (LfD) by inferring hierarchical structures of tasks from unstructured demonstrations in an unsupervised manner. It defines a motor program as a movement pattern that can be executed without sensory feedback, aiming to learn the space of movement patterns across tasks. The approach involves a 'motor program network' mapping elements to corresponding movement patterns. The text discusses learning hierarchical task representations in Learning from Demonstrations (LfD) by inferring hierarchical structures of tasks from unstructured demonstrations in an unsupervised manner. It defines a motor program as a movement pattern that can be executed without sensory feedback, aiming to learn the space of movement patterns across tasks. The approach involves a 'motor program network' mapping elements to corresponding movement patterns. To learn motor programs from unlabelled demonstrations, a mapping A is also learned to understand the demonstrated trajectories in terms of composition of motor programs. The text discusses inferring hierarchical structures of tasks from unstructured demonstrations in an unsupervised manner. It involves learning the space of movement patterns across tasks through a mapping A that abstracts trajectories into motor programs. The central insight is to jointly learn motor programs and abstractions by ensuring that the inferred motor programs faithfully recreate the original demonstration. Our approach involves using an abstraction network to predict latent codes from an input demonstration trajectory, which are then decoded into sub-trajectories using a motor program network. The discrepancy between the observed and recomposed demonstrations is penalized using a pairwise matching cost computed via dynamic time warping. This approach provides a robust cost measure that handles different prediction lengths. The discrepancy measure between trajectories is defined using a matching cost for the optimal path among all valid paths. A smoothness loss is incorporated to penalize large state changes between primitives in the recomposed trajectory. The overall objective includes a reconstruction objective and handling different prediction lengths. The motor program network and abstraction network are implemented as neural networks, with the motor program network being a 4-layer LSTM and the abstraction network using the Transformer architecture. The Transformer architecture is found to be superior to LSTMs for processing long trajectories. The Transformer architecture is preferred over LSTMs for processing long trajectories. The abstraction network predicts primitives and continuation probabilities, using REINFORCE to learn prediction of probabilities. The objective is to jointly learn motor programs and understand demonstration trajectories. The framework aims to bias learning towards desirable solutions by enforcing simplicity and parsimony of motor programs in addition to recomposing demonstrations. The framework enforces simplicity and parsimony of motor programs by penalizing the number of motor primitives used and initializing the motor primitive network with a pretrained autoencoder on random planner trajectories. The study aims to evaluate the effectiveness of learning motor primitives from kinesthetic demonstrations using the MIME dataset. The research focuses on discovering a meaningful representation of motor programs and assessing their utility in solving reinforcement learning tasks. The study evaluates learning motor primitives from kinesthetic demonstrations using the MIME dataset, focusing on a 16-dimensional input and prediction space derived from Baxter joint angle trajectories. The dataset includes tasks such as pouring, pushing, and bottle opening, with a train set of 5900 demonstrations, a validation set of 1600 trajectories, and a test set of 850 trajectories. Additionally, a set of 60 test trajectories is manually annotated to evaluate the learned motor programs. The study evaluates learning motor primitives from kinesthetic demonstrations using the MIME dataset, focusing on a 16-dimensional input and prediction space derived from Baxter joint angle trajectories. To evaluate the learned motor programs, a set of 60 test trajectories is manually annotated with temporal segmentation annotations and semantic labels of 10 primitives. The quality of the learned abstractions is assessed by visualizing the latent representation space of motor primitives learned by the model using a set of 500 unseen trajectories. The study visualizes latent variables in a 2-D space using T-SNE and observes clusters of movement sequences based on relative motions. These clusters correlate with traditional robot manipulation skills. More visualizations can be found at the provided website. The study visualizes latent variables in a 2-D space using T-SNE to observe clusters of movement sequences based on relative motions. The model learns smooth mappings and discovers primitives like reaching, twisting, and grasping in an unsupervised manner without explicit temporal segmentation or semantic labels. The abstractions focus on the trend of motion rather than distinguishing between left or right-handed movements. The study visualizes latent variables in a 2-D space using T-SNE to observe clusters of movement sequences based on relative motions. The model learns smooth mappings and discovers primitives like reaching, twisting, and grasping in an unsupervised manner. Executing learned primitives on a real Baxter robot shows that the model biases towards feasible and smooth motions, aligning with original demonstrations. The study visualizes latent variables in a 2-D space using T-SNE to observe clusters of movement sequences based on relative motions. The model learns smooth mappings and discovers primitives like reaching, twisting, and grasping in an unsupervised manner. Executing learned primitives on a real Baxter robot shows that the model biases towards feasible and smooth motions, aligning with original demonstrations. The predicted abstractions induce a partitioning of the demonstrated trajectory, tested for consistency across different demonstrations from the same task. Visualizations of induced segmentations and motor programs for the \"Drop Object\" task are compared with ground truth semantic labels. Semantic annotations are transferred from demonstrations to predicted primitives through alignment of recomposed trajectories. Our model transfers semantic segmentations from annotated demonstrations to predicted primitives, achieving 58% label accuracy on held-out trajectories. In comparison, a supervised LSTM baseline achieves 54% accuracy. The ability to transfer semantic segmentations across demonstrations demonstrates the consistency of our abstractions. Our model can transfer semantic segmentations across demonstrations, showing its ability to understand commonalities and reason about motor programs shared across tasks. The model predicts 4 motor programs - reaching, grasping, placing, and returning - consistent with true annotations and the expected sequence of primitives for the \"Drop Box\" task. The model predicts 4 motor programs - reaching, grasping, placing, and returning - consistent with true annotations and the expected sequence of primitives for the \"Drop Box\" task. RL training curves show the impact of motor programs on success rates in robotic tasks. Motor programs can be composed to solve downstream tasks in a hierarchical reinforcement learning setup. The motor program network and joint velocity controller serve as an abstraction of low-level control on the robot. Training a policy with motor programs is much more efficient than training with direct low-level actions. For sparse reaching, the motor program policy learns in 50 queries, a 2 orders of magnitude speedup. For sparse pushing, the policy learns in 1000 queries, a 2X speedup. Executing a motor program corresponds to 50 low-level control steps. Executing motor programs corresponds to 50 low-level control steps, leading to significant efficiency in environment interactions. An unsupervised approach has been presented to discover motor programs from robot demonstrations, resulting in a coherent and diverse latent space of primitives. These learned primitives are semantically meaningful and useful for efficiently learning downstream tasks in simulation, with potential applications in real-world robotic tasks. The text discusses leveraging learned motor programs for continual learning in robotic tasks. Visualizations of primitives being executed on a real robot are provided, with additional details available on a website. The experiments involve hierarchical reinforcement learning for policy learning. For hierarchical reinforcement learning experiments, policy learning is conducted on sparse reward tasks involving a simulated Baxter Robot. Tasks include reaching and pushing, with rewards given based on proximity to the goal. Motor program policy and baseline control policy are trained using Proximal Policy Optimization. Motor program policy outputs latent representation z, which expands into a trajectory controlled by a PD velocity controller. The baseline control policy directly outputs velocity control action."
}