{
    "title": "HyxgBerKwB",
    "content": "Proteins play a crucial role in biological processes, with their 3D structure determining their function. Experimental identification of protein structures can be time-consuming and expensive. Computational methods like GraphQA offer an alternative by modeling protein folding, providing efficient and reliable results. Proteins are essential for biological functions, with their 3D structure determining their function. Experimental methods for identifying protein structures are costly and time-consuming. Computational approaches like GraphQA offer efficient and reliable modeling of protein folding. This work focuses on Quality Assessment (QA) of computationally-derived protein models to estimate their accuracy and refine them based on their quality. Computational techniques have been developed for protein structure prediction due to the limitations of experimental procedures. Quality Assessment (QA) for protein models has gained attention from the machine learning community, despite lagging behind computational protein folding and design. Bioinformatics has made significant progress in QA over the past decade, utilizing various techniques including artificial neural networks and deep learning methods. This work focuses on tackling QA with Graph methods. In this work, Graph Convolutional Networks are used for Quality Assessment in protein models, showing significant improvements over previous methods. GRAPHQA predicts local and global scores by passing messages among residues with chemical bond or spatial proximity. Protein Quality Assessment methods are evaluated in CASP, with current techniques categorized into single-model and consensus methods. Recent advancements in protein quality assessment methods include single-model approaches such as 3DCNN, Ornate, ProQ3D, and ProQ4, as well as VoroMQA which takes a statistical approach. These methods have shown promising results in CASP13, with VoroMQA and ProQ3D being among the top performers. Graph Convolutional Networks (GCNs) have also been utilized to enhance representation learning in protein quality assessment. Graph Convolutional Networks (GCNs) have been successfully applied in various domains such as physics, visual scene understanding, and natural language understanding. They have proven effective in tasks related to molecular representation learning, protein interface prediction, chemical property prediction, drug-drug interaction, drug-target interaction, molecular optimization, and generation of proteins, molecules, and drugs. This work is the first to apply Graph Convolutional Networks (GCNs) to protein quality assessment, showcasing improved results over state-of-the-art methods like ProQ4. Novel representation techniques capture sequential and 3D structural features of proteins, leading to enhanced computational efficiency and performance in multiple datasets and scoring regimes. The GRAPHQA architecture utilizes Graph Convolutional Networks (GCN) to optimize local and global scores for protein quality assessment. Proteins are represented as graphs, with residues or amino acids forming the primary structure. The method is analyzed through ablation studies to understand the significance of different components like architecture, loss, and features. The primary structure of a protein is represented by a sequence of amino acid residues. Interactions between residues and the environment determine the protein's folding into complex spatial structures. Different approaches like RNN, 1D-CNN, and 3D-CNN are used to model proteins, with some focusing on sequence and others on spatial structure. Graph-based learning is proposed as a method to combine both aspects effectively. Graph-based learning can model both sequential and geometric structures of proteins, accommodating different lengths and spatial extents while being invariant to rotations and translations. Proteins can be represented as linear graphs, with nodes as amino acids and edges connecting consecutive residues. This representation includes interactions between non-consecutive residues, forming a rich depiction of the protein's structure. The protein graph representation encodes the protein's structure with residues, bonds, and contacts. Additional features like residue and relationship attributes can be encoded as nodes and edges. This attribution preserves sequence information and 3D geometry while being invariant to rotation. Protein graphs explicitly represent both sequential and spatial information. Protein graphs encode sequential and spatial structure, are rotation invariant, and used in computational folding methods to generate decoy conformations for target proteins. Quality Assessment (QA) steps help identify decoys that best represent the native structure, with global and local scoring algorithms used for ranking and identifying incorrect parts of decoys. GRAPHQA is a graph-based QA neural network that predicts local and global scores for protein structures using existing datasets. It minimizes the need for feature and model engineering by training on two scoring algorithms: Global Distance Test Total Score and Local Distance Difference Test. This approach is crucial in scenarios where the native structure is unavailable, such as in drug development. GRAPHQA is a graph convolutional network that predicts local and global scores for protein structures. It uses Mean Squared Error (MSE) losses to match the quality score, allowing for easier inspection and potential improvement of folding methods. The network operates on protein graphs using a message-passing algorithm and a graph layer that updates node/edge/global features. The GRAPHQA architecture utilizes a graph convolutional network to update node/edge/global features and structure, enabling information propagation through multiple graph layers. This allows for learning quality-related features at various scales, from secondary structures to larger domain structures. The network is divided into three stages, with an encoder increasing dimensions of node and edge features at the input. The GRAPHQA architecture utilizes a graph convolutional network to update features and structure, enabling information propagation through multiple layers. The encoder increases dimensions of node and edge features at the input, followed by message-passing layers operating on the encoded graph. Update functions consist of Linear-Dropout-ReLU transformations, with aggregation functions using average pooling. The readout layer outputs quality scores by applying Linear-Sigmoid operations. The dataset used includes scored decoys from past editions of CASP, resulting in a dataset of \u223c100k decoys. The GRAPHQA architecture utilizes a graph convolutional network for information propagation. The dataset consists of \u223c100k scored decoys from CASP 7-10, split into training and validation sets. CASP 11 and 12 are reserved for testing against top-scoring methods. Evaluation metrics include RMSE and Pearson correlation coefficients for GDT TS and LDDT scores at global and local levels. The node attributes of a protein graph P represent the identity, statistical, and structural features of the residues. Residue identity is encoded using a one-of-22 amino acid encoding, along with residue-level statistics computed using Multiple Sequence Alignment (MSA). Additionally, spatial information including dihedral angles, surface accessibility, and secondary structure type is included. The protein graph P's node attributes encode residue identity, statistics from Multiple Sequence Alignment (MSA), and structural features. The connectivity structure includes spatial and sequential distances as an 8D feature vector, with spatial distance encoded using a radial basis function and sequential distance represented by a separation encoding. The MSE losses in equation 2 are weighted as L tot. GRAPHQA is a fast training method using Adam Optimizer with L2 regularization. It outperforms LSTM and 3D-CNN methods, with 35 epochs taking around 2 hours on an NVIDIA 2080Ti GPU. Comparison with other methods like ProQ3D and ProQ4 is done based on model parameters and performance on validation set. In ProQ4, a 1D-CNN predicts LDDT scores from protein sequences, pretrained on protein secondary structures and fine-tuned on CASP 9-10. Results reported on CASP 11 and CASP 12. 3DCNN trains on atomic densities to rank decoys in CASP 7-10 based on GDT TS scores, using only atomic structure and type. Ornate applies a 3D approach to predict local CAD-scores. AngularQA uses an LSTM network to predict GDT TS scores by feeding a sequence-like representation of protein structures. VoroMQA and RWplus are statistical potential methods that offer an alternative to machine-learning based approaches. GRAPHQA's performance is compared with other methods on CASP 11 and 12, with graphical representations of true vs. predicted scores provided. GRAPHQA and ProQ4 are the only methods that co-optimize for local and global predictions. GRAPHQA outperforms ProQ3D and ProQ4 at the residue level, while also ranking decoys based on overall quality better than other state-of-the-art methods. Hand-engineered features like MSA and DSSP are discussed in ablation studies. In ablation studies, GRAPHQA RAW, a variant relying solely on one-hot encoding of amino acid identity, outperforms representation-learning methods. The analysis delves into how different components contribute to performance, including optimization, architecture, and protein feature selection. Studies are conducted on CASP 11 with results reported as mean and standard deviation of 10 runs. The interplay between local and global predictions is investigated. In this study, the interplay between local and global predictions is explored. Co-optimizing for both levels shows benefits at the global level, where models trained to predict both local and global scores outperform those trained only on global scores. However, at the local level, co-optimization does not seem to improve performance. The study also examines the effects of network depth and cutoff value on model performance. The architecture's connectivity and message propagation are influenced by the number of contacts in the graph. Sparse graphs require more message-passing layers for a holistic view compared to denser representations. Removing the global pathway exposes the trade-off between depth and connectivity. Without the global pathway, global predictions are computed by aggregating node features from the last message-passing layer. The RMSE obtained by networks of different depth on protein graphs constructed with various cutoff values shows that a shallow 3-layer architecture needs more densely-connected inputs compared to a 9-layer network for similar performance. Local predictions are more affected by factors like receptive field size, with node and edge features improving both local and global scoring. DSSP features are slightly more relevant for LDDT predictions. The design of GRAPHQA benefits LDDT predictions with progressively richer edge features. It is suitable for scoring and identifying refinement opportunities in decoy structures. Unlike LDDT, GRAPHQA is fully differentiable and can explain factors influencing low scores, providing feedback for structure prediction. Sensitivity Analysis is used to explain predictions of a differentiable function by measuring how input variations affect the output. GRAPHQA captures quality-related dependencies in residues' neighborhood and further apart in the sequence. It can potentially improve contact maps based on global predictions. Applying graph convolutional networks to protein quality assessment, GRAPHQA's global predictions could enhance contact maps for protein modeling. The network's gradients show potential for guiding models towards native structures, offering a coarse feedback mechanism. This approach combines various benefits of previous quality assessment methods, leveraging the natural graph representation of proteins. Through extensive experiments, significant improvements were demonstrated in Quality Assessment using sequential and 3D structure modeling, local and global scoring, and computational efficiency. Future directions could include richer geometric representations and raw atomic representations for learning-based Quality Assessment. Global Distance Test Total Score (GDT TS) is a key metric used in assessing protein structures. The Quality Assessment process involves aligning a decoy to the experimental structure and computing the fraction of residues within a certain distance from the native structure. This is done using the Local Distance Difference Test (LDDT), which compares the local neighborhood of every residue in the decoy and native structure. The percentage of shared contacts determines the quality of each residue. The LDDT scoring compares residue neighborhoods in decoys and native structures. It excludes short sequences and canceled targets from CASP 7-13. The cutoff value d max affects graph connectivity, with lower values leading to sparser graphs and longer paths between nodes. Higher values result in denser graphs with shorter paths. The GRAPHQA architecture represents protein structures as graphs, with nodes as residues and edges connecting interacting amino acid pairs. Features are encoded in node and edge feature vectors, with a global bias term added for non-localized information. Message passing is used for optimization on the validation set. The GRAPHQA architecture represents protein structures as graphs, with nodes as residues and edges connecting interacting amino acid pairs. Message passing updates edge and node feature vectors using functions of adjacent nodes, edges, and global attributes. Aggregation functions are used to update all edges, nodes, and the global feature vector. Linear-Dropout-ReLU functions are used for intermediate updates, and average pooling is used for aggregation functions. The GRAPHQA architecture processes nodes and edges independently, with message passing enabled for core layers to expand neighborhoods. Neurons in message-passing layers decrease from input to output, following a linear interpolation. A guided grid search is performed for hyperparameters, with the final model chosen based on validation set performance. The values for d max, \u03c3, and L were chosen based on specific criteria. An architecture with BatchNorm layers did not show improvement. Additional studies were conducted on feature representation and model generalization. The study evaluates different representations of spatial distance in graph feature vectors, including Absent, Scalar, and RBF encodings. Results show that the rich representation of RBF kernels slightly improves LDDT and GDT TS scoring performances on CASP 11. The study evaluates different encodings for spatial distance in graph feature vectors, including Absent, Scalar, and Categorical. Results show that using categorical encoding leads to higher global scoring performance on CASP 11. In this study, the natural environment of proteins affects predictive performances. Targets from CASP 11 and 12 are classified as transmembrane or soluble and scored using GRAPHQA. Transmembrane proteins expose non-polar residues to the cellular membrane, while soluble proteins present polar amino acids to the surrounding solvent. The study compares predictive performances between the two sets to evaluate the model's protein representation flexibility. GRAPHQA performs better on soluble proteins but also scores transmembrane proteins. In this study, GRAPHQA scores transmembrane proteins to an acceptable degree. Various metrics like RMSE and correlation coefficients are used to evaluate the model's performance on both transmembrane and soluble proteins. High correlation coefficients can be misleading, so per-model and per-target versions should also be considered. The study evaluates GRAPHQA's performance on transmembrane proteins using correlation coefficients for residue-level and decoy-level scores. Per-model coefficients assess ranking quality, while per-target coefficients evaluate overall performance across all targets. The study evaluates GRAPHQA's performance on transmembrane proteins using correlation coefficients for residue-level and decoy-level scores. Per-target correlation coefficients estimate the network's ability to rank decoys by quality, with a focus on GDT TS: First Rank Loss (FRL) to measure the ability to select the best decoy for each target. FRL is subject to noise as it only considers top-1 decoys. NDCG is considered a superior metric compared to FRL for Quality Assessment in the QA literature. NDCG provides a better perspective on the decoys retrieved by a QA method by considering the relevance of all decoys, not just the best one. The Discounted Cumulative Gain at k (NDCG@k) is computed by considering the top-k decoys ranked by predicted global scores. It is obtained by dividing the Cumulative Gain at k (DCG@k) by the ideal DCG@k, resulting in a Normalized Discounted Cumulative Gain NDCG@k \u2208 [0, 1]. Additional results for datasets, dataset splits, methods, and metrics are presented for CASP 11, CASP 12, CASP 13, and CAMEO. In the following pages are datasets like CASP 11, CASP 12, CASP 13, and CAMEO. CASP 11 and 12 datasets have stage 1 with 20 randomly selected decoys per target, and stage 2 with the top-150 decoys per target. Some papers report results on the dataset as a whole, or on stage 1 and stage 2 splits. Metrics computed on stage 1 are considered noisy and ignored, while metrics on stage 2 and the whole dataset are equally valid. If multiple values are reported for the same method and dataset pair, only the best one is considered. The model fails to score decoys of target T060 despite multiple values reported for the same method and dataset pair. The model fails to score decoys of target T060, suspecting errors in the preprocessing pipeline that may have led to misleading features. CASP 13 has limited targets available for public evaluation with fully characterized decoy structures. The evaluation on publicly available targets for GRAPHQA shows performances in line with CASP 11 and 12 results. GDT scores for various targets can be downloaded from the website. The evaluation on publicly available targets for GRAPHQA shows performances in line with CASP 11 and 12 results. GDT scores for various targets can be downloaded from the website. Protein structures include 2N00_A, 2N03_A, 2N0P_A, 2N1D_A, 2RTT_A, 3WCG_D, 3WD6_D, 3WDX_B, 3WE5_B, 3WE9_A, 3WFX_B, 3WGQ_B, 3WH9_B, 3WJ1_A, and 3WJ2_D."
}