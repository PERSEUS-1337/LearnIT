{
    "title": "HJlTpCEKvS",
    "content": "Many computer vision applications benefit from multi-task learning, where a neural network is trained to solve multiple tasks simultaneously. This approach saves computation at inference time by evaluating only one network. However, task objectives can compete, leading to inferior performance. A framework is proposed to assign tasks to different neural networks based on cooperation and competition, offering a time-accuracy trade-off and better accuracy with less inference time compared to a single large multi-task network or many single-task networks. Many applications, like robotics and autonomous vehicles, use multi-task learning to reduce inference time and computational complexity for various visual tasks. Tasks are solved simultaneously with a single neural network, aiming for improved prediction accuracy, data efficiency, and reduced training time. However, the quality of predictions can suffer due to complex learning objectives and competition among tasks. Multi-task performance can suffer when objectives compete, leading to crosstalk. Smaller independent networks often outperform in such cases. However, when task objectives don't interfere much, joint training can maintain or improve performance. Transfer relationships don't predict multi-task relationships well. The study aims to improve prediction accuracy under a limited inference time budget by assigning competing tasks separately. The study aims to improve prediction accuracy by assigning tasks to separate or the same networks based on competition levels. A computational framework is developed to optimize task grouping for maximum performance under a computational budget. The study developed a framework to optimize task grouping for maximum performance under a computational budget. It suggests grouping tasks to achieve the lowest total loss, with the inclusion of an additional task potentially improving the accuracy of other tasks. This task grouping outperforms other feasible options, such as learning all tasks in one large network or using dedicated smaller networks. The paper outlines a framework for systematically assigning tasks to networks to optimize prediction accuracy within a limited inference-time budget. It emphasizes the importance of selecting the best task grouping for improved performance and discusses the benefits and limitations of multi-task learning. The authors discuss multi-task learning techniques, focusing on hard and soft parameter sharing. They aim to understand task relationships and find compatible task groupings. An example of hard parameter sharing in computer vision is UberNet, which addresses 7 computer vision problems. Their goal is to reduce the computational cost of training. The authors focus on reducing computational cost in hard parameter sharing for multi-task learning. Various works also utilize hard parameter sharing, while other approaches aim to dynamically adjust task weights during training. Additionally, task interaction in NLP is studied in another work. In soft or partial parameter sharing for NLP tasks, models are tied together by information sharing or requiring similar parameters. Examples include deep dependency parser design for languages with limited data and Cross-stitch Networks for two tasks. Cross-stitch Networks (Misra et al. (2016)) use 'cross-stitch units' between separate networks for two tasks to reduce task interference. Unlike other methods, they do not attempt to discover good task groups or reduce inference time. Transfer learning, on the other hand, adapts a model from a source task to a target task without seeking benefits for the source tasks or reducing inference time. Neural Architecture Search (NAS) involves searching for deep learning architectures that perform well, similar to our work which focuses on searching for optimal task groupings. Taskonomy and other related works have studied task relationships for transfer learning, introducing datasets and analyzing task connections. In contrast to transfer learning approaches like Taskonomy, our focus is on multi-task learning and finding the best task-network assignment for overall loss optimization. We aim to select candidate networks for our solution and prioritize structural similarities between tasks at all levels. Our goal is to minimize overall loss on a set of tasks within a limited inference time budget by selecting a set of neural networks that collectively solve all tasks. The solution should have the lowest loss and cost under the budget. To determine task relationships, a candidate set of networks is created with all possible groupings of tasks. This includes single-task networks and networks with varying computational costs. The goal is to select a subset of fully-trained networks from the initial candidate set that collectively solve all tasks within a limited budget. The goal is to select a subset of networks from a candidate set that collectively solve all tasks within a limited budget. Solving this problem is NP-hard, but various techniques exist to optimally solve it. A branch-and-bound-like algorithm is used to find optimal solutions, but other methods like binary integer programming could also be used. Most multi-task learning works involve fewer than 4 unique task types. The text discusses techniques for reducing training time in selecting networks for solving multiple tasks within a limited budget. It involves predicting network performance without full training, aiming to mimic results of complete search with less time. The text discusses techniques for reducing training time by predicting network performance early on, allowing for faster selection of networks for multiple tasks within a limited budget. This approach shows a high correlation between validation loss after a partial data pass and final test loss, enabling decent results with reduced training time and GPU hours. The Early Stopping Approximation (ESA) technique allows for predicting network performance early on, showing a correlation between early and final performance. By averaging first-order networks' accuracies, the accuracy of higher-order networks can be predicted with low error rates. This strategy enables the prediction of network performance with three or more tasks efficiently. The Higher Order Approximation (HOA) strategy predicts the performance of networks with three or more tasks by training two or fewer task networks first. This approach saves training time by 50% compared to early stopping approximation, but with a prediction quality penalty. The technique requires training a quadratic number of networks instead of an exponential number, making it more efficient for a large number of tasks. The results of the HOA strategy are presented in Section 5 using the Taskonomy dataset. The dataset used for the study is the largest multi-task vision dataset, obtained from 3D scans of 600 buildings. It consists of 4,076,375 examples divided into training, validation, and test sets. The framework is task-agnostic and includes tasks like Semantic Segmentation, Depth Estimation, Surface Normal Prediction, Keypoint Detection, and Edge Detection. Different loss functions were used for these tasks, and the network architecture is specified. The proposed framework can work with any network architecture, using a modified Xception encoder with 17 layers and 512 channels. All maxpooling layers were replaced by 2x2 convolution layers. The inference time is measured in Standard Network Time (SNT) units, with about 4 ms per image on a single Nvidia device. The decoders in the framework were designed to be lightweight with specific layers and parameters. Training was done using PyTorch with acceleration. A total of 36 networks were trained for optimization, including full-sized encoders and standard decoders. Additionally, smaller networks were trained for baselines and analysis but not used for network selection. In order to produce smaller models, the number of channels in every layer of the encoder was reduced. The training loss used was the mean of the losses for the tasks. Networks were trained with an initial learning rate of 0.2, reduced by half when the training loss stopped decreasing. Validation loss determined when training stopped, typically after 4-8 passes through the dataset. The network with the highest validation loss was saved for selection. Performance scores were calculated on the validation set, with solutions evaluated on the test set. Inference time budgets ranged from 1 to 5, evaluated at 0.5 increments. Results were compared with conventional methods. We compared our results with conventional methods and two multi-task methods in the literature. Sener & Koltun (2018) under-weighted the Semantic Segmentation task, leading to poor performance. GradNorm (Chen et al. (2018b)) also showed slightly worse results than classical MTL. These techniques can be used in conjunction for better solutions. Our study compared different task grouping techniques with two control baselines, 'Random' and 'Pessimal,' to highlight the importance of selecting tasks wisely. The results showed that our methods consistently outperformed the traditional baselines across various computational budgets. Our study compared task grouping techniques with control baselines to show the importance of task selection. The optimal method outperformed traditional strategies at a budget of 1 SNT, but multiple networks performed better at budgets > 1.5. When budget is 5 SNT, five networks were used, with three trained on three tasks each and two on one task each. Multi-task learning was best for tasks s, d, and e, while tasks n and k were better solved individually. Our study compared task grouping techniques with control baselines to show the importance of task selection. The optimal method outperformed traditional strategies at a budget of 1 SNT, but multiple networks performed better at budgets > 1.5. When budget is 5 SNT, five networks were used, with three trained on three tasks each and two on one task each. Multi-task learning was best for tasks s, d, and e, while tasks n and k were better solved individually. Our results suggest that good task groupings for one architecture are likely to be good in another, though to a lesser extent. Task affinities seem to be somewhat architecture-dependent, so for the very best results, task selection must be run for each architecture choice. Figure 4 allows qualitative comparison between our methods and our baselines, showing clear visual issues with each of our baselines that are not present in our methods. The data generated by the evaluation allows for analysis of task interactions in a multi-task setting and comparison with research in transfer learning. Task affinities for multi-task learning were determined by averaging relationships between tasks, with Surface Normal Prediction and 2D Edge Detection showing the highest affinity. Depth Estimation and Surface Normal Prediction did not score highly on this similarity metric. The study found that 3D tasks like Depth Estimation and Surface Normal Prediction, as well as 2D tasks, did not score highly in terms of similarity metrics for multi-task learning. Surprisingly, the relationship between transfer learning affinities and multi-task affinities was negatively correlated in a high-data scenario, suggesting that training dissimilar tasks together might be more beneficial for providing stronger regularization. Further research is needed to explore this correlation and its implications. The study explores task compatibility in multi-task learning, providing an algorithm to determine which tasks should be trained jointly or separately. Two strategies are offered to address training time costs, with methods outperforming single-task and other multi-task networks. The analysis compares task interactions in a multi-task setting with previous transfer learning results. A network selection algorithm is introduced for candidate networks with associated costs. Algorithm 1 selects the best subset of networks based on performance scores and cost, considering a time budget constraint. It recursively explores solutions and eliminates branches that do not lead to optimal results. The process ends when the budget is depleted, resulting in an empty set of candidate networks. The algorithm selects the best networks based on performance and cost within a time budget constraint. It uses a sorting heuristic to improve the current solution and always produces an optimal result. Better sorting heuristics reduce running time by pruning parts of the search space. Experimental results show quick solving times for variants of problems with 5 tasks and 36 networks. The BETTER() function is application-specific, preferring networks with the lowest total loss across tasks. The BETTER() function encodes performance requirements for tasks, ensuring no sacrifice in one task for another. Network selection was tested on 4-task subsets, showing generalization across task sets. Depth and Normals were found to not cooperate, contrary to previous literature. Results with nearly 4 million training instances differ from those with fewer instances. Reducing training instances to 100k showed changes in task affinities. Table 9 shows the test set performance of 31 networks on each task they solve, highlighting the impact of training data on task affinities."
}