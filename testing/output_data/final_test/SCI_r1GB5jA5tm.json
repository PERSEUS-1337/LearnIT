{
    "title": "r1GB5jA5tm",
    "content": "This paper introduces ASAL, a pool-based active learning method that selects high entropy samples by searching for similar samples in the pool. ASAL outperforms traditional uncertainty sampling in terms of runtime complexity and reliability of annotations. Experimental results show ASAL's superiority over similar methods and random sampling. The discussion section analyzes ASAL's performance and challenges in outperforming random selection, making it the first adversarial active learning technique for multi-class problems using deep convolutional classifiers. The goal of active learning algorithms is to train a model efficiently with as few labeled samples as possible. Pool-based active learning focuses on selecting samples from an unlabeled pool for annotation, allowing for an ideal evaluation environment. This method enables the training of a fully supervised model to establish a performance upper bound on the dataset. Active learning algorithms aim to approximate the performance of a fully supervised model with minimal labeled samples, surpassing random sampling. Uncertainty sampling is a key strategy that selects informative samples based on the model's uncertainty. However, the linear run-time complexity makes scanning large unlabelled datasets impractical. The proposed Adversarial Sampling for Active Learning (ASAL) aims to approximate uncertainty sampling performance with sub-linear run-time complexity. Experiments were conducted using different benchmarks and CNN classifiers with various feature sets. Related work on pool-based uncertainty sampling in active learning is also reviewed. The text discusses different strategies for selecting new training samples in active learning, such as uncertainty sampling and minimum-distance sampling. These strategies aim to identify samples that the classifier is uncertain about, with the goal of improving classifier performance. Jain et al. (2010) propose hashing-based methods to accelerate minimum distance sampling. Jain et al. (2010) propose hashing-based methods to accelerate minimum distance sampling by selecting new samples in sub-linear time. These methods are limited to SVMs with fixed feature maps, as the position of samples becomes obsolete if the feature map changes. Zhu & Bento (2017) introduce Generative Adversarial Active Learning (GAAL) using a GAN to generate synthetic samples in each AL cycle. Generative Adversarial Active Learning (GAAL) uses a GAN to generate synthetic samples in each AL cycle. Zhu & Bento (2017) replace pool samples with the trained generator in the minimal distance optimization problem, resulting in a synthetic image close to the separating hyper-plane. GAAL has been tested on subsets of MNIST and CIFAR-10 using linear SVMs and DCGANs, but performs worse than random sampling due to sampling bias and poor quality of synthetic samples. ASAL proposes a new approach for active learning that addresses the challenges of bias and poor quality synthetic samples. It uses information entropy for uncertainty scoring, CNN classifiers, and Wasserstein GANs for sample generation. A sample matching method is used to avoid annotating synthetic images, and feature maps are computed for fast nearest neighbor retrieval. Two uncertainty query strategies are introduced for efficient active learning. In this section, two uncertainty query strategies are introduced for active learning: minimum distance and maximum entropy sampling. The strategies are based on the assumption that the model is least certain for samples near the decision boundary. Minimal distance sampling using SVM involves selecting samples close to the separating hyper-plane defined by w and b. Maximum entropy sampling computes the information content in each sample for the current classifier. The classifier is uncertain for samples with high entropy, which are crucial for improving the classifier. ASAL adapts the sample generation idea for active learning. ASAL adapts the sample generation idea for active learning by using multiple classes and information entropy to measure uncertainty. The proposed ASAL includes a trained classifier, a sample generator, a feature extractor, and an oracle for annotating new samples. Adversarial sample generation and sample matching methods are introduced instead of selecting uncertain samples from the pool. The generator in ASAL produces indistinguishable samples from real ones by mapping latent space variables to images. By including the generator in the optimization problem, new samples are visually similar to existing ones. The problem is solved in two steps: minimizing the objective with gradient descent and using the generator to create synthetic samples. This approach has a constant run-time complexity independent of the sample pool size. The sample matching method aims to retrieve the most similar sample from a pool for a given synthetic sample. It requires representative features, a distance measure, and a fast nearest neighbor method. Ideal features group samples with similar entropy close together in feature space. However, updating the model changes the entropy and structure, leading to a linear run-time complexity. To improve efficiency, fixed features for sample matching are needed. The features for sample matching should be representative, diverse, and allow discrimination between different samples. Raw pixel values differentiate samples but are limited for similar images. Auto-encoders provide more representative features and a compressed set of core features. Features extracted from the discriminator in GAN training are also studied. The features used for sample matching in GAN training are expected to be representative and allow for computing sample properties. Euclidean distance is used to measure similarity in feature space, with a k-d tree for efficient nearest neighbor selection. Principal Component Analysis is employed to reduce dimensionality. Two datasets, MNIST and CIFAR-10, are used for experiments. The MNIST dataset contains ten digits 0 to 9 with 28x28 grayscale pixels. CIFAR-10 has 50k training and 10k validation 32x32 color images. Two class datasets are created for comparison. ASAL performance is evaluated against fully supervised and random sampling methods. ASAL performance is evaluated against traditional pool-based maximum entropy sampling methods with sub-linear run-time complexity. Three versions of ASAL are examined using different sets of features. The feature space is reduced to 50 dimensions using PCA, as larger dimensions only increase runtime without improving accuracy. New samples are synthesized using the Adam optimizer and 100 gradient steps to minimize negative entropy in the latent space variable. Multiple latent space variables are optimized simultaneously in one batch with random initialization. Samples are drawn from the pool without replacement, without using data augmentation, and all models are trained from scratch in each active learning experiment. We train all models from scratch in each active learning cycle without using data augmentation. Experiments are conducted with different random seeds, and training iterations for GANs are reported in the appendix. Default parameters from previous studies are used, and details on auto-encoder architectures are provided in the appendix. Additional insights such as label distribution and entropy of new samples are also included. Binary digit classification involves training a linear model with cross entropy loss for 10 epochs using the Adam optimizer with a batch size of 10. The Wasserstein GAN is trained with gradient penalty to synthesize only digits 5 & 7. ASAL outperforms random sampling, selecting samples with higher entropy. Zhu & Bento (2017) report worse performance than random sampling on MNIST -two classes. Their GAAL with DCGAN is re-implemented for a fairer comparison. Our re-implementation of GAAL with DCGAN performs similarly to random sampling and shows less sampling bias than reported by Zhu & Bento (2017). Both methods perform better with Wasserstein GANs compared to DCGAN, with ASAL outperforming GAAL, especially with Wasserstein GAN. However, using Wasserstein GAN leads to less stable performance for GAAL than ASAL. Additional results can be found in the appendix. In binary classification on CIFAR-10, active learning strategies are run with a budget of 1000 samples using a Wasserstein GAN. ASAL-Autoencoder outperforms random sampling and achieves similar results to exhaustive uncertainty sampling. For ten digit classification, LeNet is used with cross entropy, trained for 10 epochs with Adam optimizer. Initial dataset contains 10 samples per class, adding 50 samples per cycle until 10k samples are reached. The study uses active learning strategies with a budget of 1000 samples on CIFAR-10. They synthesize samples for all ten classes using a Wasserstein GAN with gradient penalty. The proposed ASAL strategies show improved performance compared to random sampling. The All-CNN model is utilized for classification, achieving close to state-of-the-art results with a reported error rate of 9.08%. Stochastic gradient descent is used with a constant momentum of 0.9 and a learning rate of 0.01, decayed by a factor of 10 at the 130th and 140th epoch. The model is trained for 150 epochs with a batch size of 128 without data augmentation. The study uses active learning strategies with a budget of 1000 samples on CIFAR-10, synthesizing samples for all ten classes using a Wasserstein GAN with gradient penalty. The All-CNN model contains \u223c1.4 million parameters and requires larger initial training sets. 100 randomly selected images per class are included, with 1000 samples added every AL cycle until reaching a budget of 30k samples. A residual Wasserstein GAN with gradient penalty and soft consistency term is used, achieving an Inception score of 7.8 without and 8.3 with the soft consistency term. The results for different ASALs using the residual GAN are shown in FIG1. The study uses active learning strategies with a budget of 1000 samples on CIFAR-10, synthesizing samples for all ten classes using a Wasserstein GAN with gradient penalty. The residual GAN achieves the highest Inception score. ASAL outperforms random sampling and approximates exhaustive uncertainty sampling on three out of four benchmarks. Compared to GAAL, ASAL enables annotating real samples and handles multiple classes efficiently. ASAL outperforms random sampling, handles multiple class problems, and uses CNN based classifiers. It allows updating feature maps in each AL cycle with sub-linear run-time complexity. Training a GAN and potentially an autoencoder beforehand is required for extremely large data sets. ASAL allows selecting samples from the pool that were not used to train the GAN. ASAL favors large datasets with similar samples for GAN training, while small datasets with diverse samples align GANs to data distribution. However, ASAL fails to select similar samples with high entropy, especially in small, diverse datasets like CIFAR-10. The CIFAR-10 dataset is more diverse than MNIST but has the same number of samples. Synthetic images still appear unrealistic, making it challenging to identify similar real samples. Poor performance is attributed to using low-level features for comparison. Achieving state-of-the-art results on CIFAR-10 required a much deeper network compared to other experiments. ASAL tends to focus on low-level features for finding similar samples, rather than considering more complex properties that characterize classes. ASAL focuses on low-level features to find similar samples, rather than complex class properties. It generates samples for uncertain classes but may fail to retrieve matches for specific categories. ASAL-Autoencoder shows similar accuracy to exhaustive uncertainty sampling on CIFAR-10. Lower entropy samples may be more effective for training the classifier. The proposed pool-based active learning method, ASAL, utilizes sample generation and matching to train the classifier effectively. The success of ASAL depends on various factors such as data set structure, quality of the trained GAN, and relevance of features used for comparison. ASAL outperforms random sample selection and approximates exhaustive uncertainty sampling in most cases. ASAL, a pool-based active learning method, outperforms random sample selection and approximates exhaustive uncertainty sampling in most cases. Its sub-linear run-time complexity makes it suitable for large datasets. Future research directions include exploring high-level features for sample matching and designing other scores for sample generation to measure diversity. In the study, a Wasserstein GAN with gradient penalty and an auto-encoder for ASAL were trained using a Nvidia GeForce GTX TITAN X GPU. The GAN had 100k training iterations taking 25 hours, while the auto-encoder had 50k iterations taking 1.6 hours. The models used the Adam optimizer with a learning rate of 0.0001 and batch size 64. Sample matching was done with PCA reducing features to 50. For classification, a CNN was used with the Adam optimizer, a learning rate of 0.001, and a batch size of 50, trained for 30 epochs. Active learning started with 100 labelled samples, adding ten new samples in each cycle. The study involved training a Wasserstein GAN with gradient penalty and an auto-encoder for ASAL on a Nvidia GeForce GTX TITAN X GPU. The GAN had 100k training iterations over 25 hours, while the auto-encoder had 50k iterations over 1.6 hours. Sample matching was done with PCA reducing features to 50. For classification, a CNN was used with specific optimizer settings and batch sizes. The results showed that ASAL outperformed random sampling and approached the accuracy of maximum entropy sampling while requiring less time for sample selection. The study utilized a data set with 160k samples to compare timings of maximal entropy sampling and ASAL. ASAL reduces memory consumption by requiring only 50 features per image. A Nvidia GeForce GTX TITAN X GPU was used for all timings. ASAL has sub-linear run-time complexity for selecting new samples but requires pre-processing steps such as training the GAN and auto-encoder. The study compared timings of maximal entropy sampling and ASAL using a data set with 160k samples. ASAL reduces memory consumption and has sub-linear run-time complexity for selecting new samples. Pre-processing steps include training the GAN and auto-encoder. ASAL is more efficient for selecting new samples than maximal entropy sampling, especially for small data sets or running active learning for a few samples. The study compared the efficiency of ASAL and maximal entropy sampling for selecting new samples. ASAL is more efficient but requires pre-processing time. Auto-encoder settings for MNIST include three convolution layers in the encoder and three deconvolution layers in the decoder. Training is done for 40 epochs with a batch size of 100 using the Adam optimizer. The Encoder for CIFAR-10 consists of three layers with convolution, batch normalization, activation, and max pooling. The number of compressed features is 256. The decoder includes a convolution layer, followed by three deconvolution layers. The auto-encoder is trained for 100 epochs with a batch size of 128 using the Adam optimizer. The study explores the use of Adam optimizer with a learning rate of 0.001 for CIFAR-10 datasets with two and ten classes. It compares label distribution for uncertainty sampling using maximum entropy and random sampling for MNIST datasets with two classes. The results show that uncertainty sampling leads to a training set with imbalanced label distribution compared to random sampling. Test accuracy on MNIST datasets with two classes is evaluated for different sampling methods and ASALs using various GANs, uncertainty measures, and loss functions. ASAL with WGAN-GP demonstrates superior performance. ASAL with WGAN-GP outperforms ASAL using DCGAN in terms of performance. Maximum entropy sampling and cross entropy loss lead to a setup that approaches the fully-supervised model with the fewest samples. ASAL using WGAN-GP reaches a label distribution similar to the true label distribution in the pool, while ASAL using DCGAN leads to an imbalanced training set with more digit 7 images than digit 5. Figure 12 shows that ASAL selects high-entropy images for training MNIST with different GANs and loss functions. Maximum entropy sampling results in smaller classifier entropy compared to minimum distance sampling. Instead of manual annotation, similar images are selected from the pool for labeling. The study compares manual class annotations of generated images with matched images using three strategies. 1300 generated samples for each GAN are annotated manually and matched with corresponding labels from a pool. Accuracy is computed for each class independently, with higher agreement for ASAL strategies using WGAN-GP than DCGAN. The study compares manual class annotations of generated images with matched images using three strategies. ASAL strategies using WGAN-GP show higher agreement than DCGAN. Matching based on gray values achieves the highest agreement. ASAL allows selecting similar images from the pool for comparison with manual annotations. WGAN-GP outperforms DCGAN in agreement for MNIST -two classes. ASAL selects images with higher entropy than random sampling, with WGAN-GP leading to a larger gap that shrinks as the training set increases. Label distribution for uncertainty sampling using maximum entropy, random sampling, and active learning with different matching strategies and GANs for MNIST -ten classes is shown. Active learning strategies using different GANs for MNIST - ten classes show varying label distribution in the training set. Random sampling converges to the true label distribution, while maximum entropy sampling results in a higher ratio of certain digits. ASAL with WGAN-GP selects certain digits more frequently, while ASAL with DCGAN leads to a training set with 30% images of the digit 1. Training on MNIST and testing on USPS shows that GAAL outperforms fully supervised models. ASAL up-samples USPS images for testing on MNIST, achieving a test accuracy of 0.91. ASAL outperforms aggressive uncertainty and random sampling. For MNIST, uncertainty sampling excels, but ASAL-Auto and ASAL-Disc show better training performance for WGAN-GP. The test accuracy of a fully supervised model on USPS and MNIST datasets is compared using different sampling strategies, GANs, uncertainty measures, and loss functions. Uncertainty sampling performs poorly compared to random sampling and ASAL, which tend to generalize better. Maximum entropy sampling for ten classes outperforms other methods. The study compares different sampling strategies, GANs, uncertainty measures, and loss functions on USPS and MNIST datasets. Binary classification outperforms other methods, with LeNet showing good generalization. Active learning strategies using WGAN-GP and ASAL-Disc. exceed random sampling quality. ASAL with DCGAN performs similarly to random sampling. CIFAR-10 label distribution is not indicated due to an equal number of samples per class in the validation set. Training sets converge to true label distribution, with uncertainty sampling strategies frequently containing the most samples. The uncertainty sampling strategies in the training set frequently contain images labeled as horses. The average entropy of selected images for CIFAR-10 with two classes using different GANs shows minimal difference between random sampling and the proposed method. However, ASAL selects images with higher entropy than random sampling at the beginning. For CIFAR-10 with ten classes, there is hardly any difference in entropy between random sampling and ASAL. Only at the start does random sampling retrieve samples with slightly higher entropy. Maximum entropy sampling in active learning for CIFAR-10 classes selects most common classes like cat, dog, bird, and deer to improve classification quality over random sampling. The classes common in training sets are less frequent in uncertainty sampling data sets, with frog being a common class in many setups but not in uncertainty sampling. Generated images using WGAN-GP for CIFAR-10 classes show moderate quality. Most generated images show moderate quality with high visual distance and mismatched labels. Classifier trained on initial set used for maximum entropy sample generation. Comparison of random and uncertain MNIST samples show visually appealing random samples and frequent digit 7 generation by DCGAN. Comparison of random and uncertain samples for MNIST and CIFAR-10 datasets using different GANs. Random samples are visually more appealing and easier to identify labels. Residual GANs produce more visually appealing samples compared to other GANs. Residual GANs generate visually appealing samples, with random images being easier to identify labels compared to uncertain images. Annotating with high confidence remains challenging."
}