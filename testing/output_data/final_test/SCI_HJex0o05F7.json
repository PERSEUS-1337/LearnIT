{
    "title": "HJex0o05F7",
    "content": "This work introduces a method for active anomaly detection that enhances existing deep learning solutions for unsupervised anomaly detection. It emphasizes the importance of assuming a prior on anomalies for performance guarantees. Active anomaly detection offers the potential for improved results compared to unsupervised methods, with similar costs. The approach involves adding a new layer to deep learning models for unsupervised anomaly detection, demonstrating its effectiveness on synthetic and real datasets. Anomaly detection aims to identify rare instances that deviate from the majority patterns, with a focus on practical utility. From a business perspective, the focus is on finding \"useful anomalies\" rather than just rare instances. Various studies have explored solutions for anomaly detection using extreme value theory, robust statistics, and graph theory. Unsupervised anomaly detection is challenging due to the lack of information on rare instances, leading to the use of models with implicit priors or heuristics to assign anomaly scores. Active anomaly detection, as an alternative approach, has shown promising results in recent works. In recent works, active anomaly detection has shown promising results. A new layer called Universal Anomaly Inference (UAI) is proposed to transform unsupervised anomaly detection models based on deep learning into active models. This layer utilizes learned latent representations and anomaly scores to train a classifier on labeled instances. Extensive experiments are presented to analyze the performance of the systems. Our algorithm improves state of the art results in several datasets without hyperparameter tuning. We visualize our models' learned latent representations and compare them to unsupervised models. An outlier is defined as an observation that deviates markedly from others, while normal data instances occur in high probability regions. An outlier is an observation that deviates markedly from others, while normal data instances occur in high probability regions of a stochastic model. Anomalies occur in low probability regions. The data instances are generated from probability density functions, with normal instances generated from one function and anomalous instances from another. The full dataset is composed of both normal and anomalous instances, sampled from a probability distribution. The probability of a data point being anomalous is represented by a small constant \u03bb. Anomalous instances can be known a priori or not. Anomaly detection systems are categorized into supervised, semi-supervised, and unsupervised types. Unsupervised anomaly detection focuses on identifying anomalous instances in a dataset containing both normal and anomalous instances. In unsupervised anomaly detection, the goal is to find a subset of anomalous instances from a full set of points X. The full distribution is a mixture of distributions, making it difficult to learn individual distributions accurately. General mixture models are unidentifiable, and without a prior on the anomalies' probability distribution, no information can be gained on the anomalous distribution from the full distribution. This differs from the usual unidentifiability of mixture models, as all valid distributions of anomalies are equally probable. Unsupervised anomaly detection requires a prior on the anomalies distribution. An example is shown in FIG1 with synthetic data clustered in four separable clusters. Detecting anomalies in low density points is challenging without additional information. Using a high capacity model would detect low density points as anomalous. The choice of algorithm imposes a prior on detected anomalies, as highlighted in Theorem 1. In practical examples like clinical data, distinguishing between anomalies and 'uninteresting' low probability points is crucial. Training a parameterized model to capture the full data distribution is a common strategy in unsupervised anomaly detection. Training a parameterized model to capture the full data distribution is a common strategy in unsupervised anomaly detection. An anomaly score is defined based on the probability of a point, but there are limitations to this approach, such as poor approximation of normal distribution, clustering of anomalous items, and lack of information about anomalous items without additional assumptions. Verification by human experts is often necessary due to uncertain performance. An unsupervised anomaly detection system is limited in its reliability, often requiring human experts to verify results. Active learning strategies involving expert feedback can improve the system's robustness, especially in cases of extremely unbalanced datasets. This approach can potentially reduce the need for labeled data exponentially compared to supervised settings. Active anomaly detection methods are advocated for due to their advantages and promising results. In unsupervised anomaly detection, elements in a dataset are ranked for the highest recall/precision within a certain budget. Active anomaly detection involves selecting anomalies in small parts and waiting for expert feedback before continuing, iteratively auditing the most probable elements. The Universal Anomaly Inference (UAI) layer is developed to improve anomaly detection in deep learning systems by incorporating expert feedback to select anomalies iteratively. This layer utilizes a latent representation layer and anomaly score to determine an item's anomaly probability, based on the simpler statistical structure of learned representations. The UAI layer simplifies anomaly detection by using a logistic regression classifier. The network with a UAI layer is referred to as UaiNets. The UAI layer is tested on a Denoising AutoEncoder and a Classifier architecture. The UAI layer simplifies anomaly detection by using a logistic regression classifier in UaiNets. The algorithm's performance is tested on synthetic data and real anomaly detection datasets in various settings. The experiments aim to demonstrate the model's ability to work with different anomaly definitions and architectures, showing robustness to different types of anomalies. The experiments involved using the MNIST dataset to create different sets with varying levels of anomalies. Anomalies were defined by changing the labels of certain digits to different classes. The third set of experiments focused on testing a different type of anomaly by training a weak MLP classifier on MNIST. In creating the dataset, a weak MLP classifier was trained on MNIST to identify anomalies. Anomalies made up 3.3% of the dataset. Another experiment used PCA to reduce MNIST images to 2 dimensions and selected anomalies with the largest reconstruction error, making up 5% of the dataset. Results showed the algorithm's robustness to different types of anomalies compared to unsupervised models. The Class model performs well on MNIST 0 and MNIST 0-2 datasets but not on MNIST hard and MNIST pca, indicating it is better at finding clustered anomalies. On the other hand, the DAE model excels at detecting low density anomalies in MNIST pca and MNIST hard but struggles with MNIST 0 and MNIST 0-2. Both UaiNets show robustness across all datasets, even on challenging ones for their underlying models. Cardiotocography (CTG); Credit Card; Covtype; Mammography (MMG); Shuttle (Lichman, 2013; Dheeru & Taniskidou, 2017; Pozzolo et al., 2015; Woods et al., 1993). The algorithm DAE uai outperforms other baselines on 11 datasets, even when trained in an active anomaly detection setting. DAE shows poor results across all datasets analyzed, while DAE uai consistently performs better than LODA-AAD and Tree-AAD. Our method shows better results than LODA-AAD and Tree-AAD in an active setting, especially on datasets with a low proportion of anomalies. The active algorithms are more robust and can be applied in a mixture of semi-supervised and unsupervised anomaly detection scenarios. Our model, a mixture of semi-supervised and unsupervised anomaly detection, was evaluated on a dataset with known anomalies and new instances. An experiment was conducted using DAE uai and LODA-AAD on KDDCUP-Rev, showing results in FIG4. The evaluation included 20 new types of anomalies, with the recall calculated for both seen and unseen anomalies. In FIG4, the right y axis displays anomalies detected in the training set for a specific budget, while the left y axis shows recall for the test dataset. DAGMM is less effective on the test set compared to DAE, which excels at detecting new classes. DAE uai outperforms LODA-AAD in detecting known anomalies and maintaining recall for new classes. Classical outlier detection methods like LOF and OC-SVM are still widely used despite recent algorithm advancements. Recent work on anomaly detection focuses on statistical properties of \"normal\" data to identify anomalies. Various methods such as Benford's Law, Extreme Value Theory, spatially contextualized data, and graph data analysis have been utilized. Energy-based models and GANs have also been successful in anomaly detection, but autoencoders remain popular. Zhou & Paffenroth (2017) propose a method to train robust autoencoders inspired by robust statistics. Yang et al. (2017) focus on clustering and train autoencoders to generate latent representations. In anomaly detection, recent work has focused on statistical properties of \"normal\" data. Yang et al. (2017) train autoencoders for clustering and generate latent representations friendly for k-means. DAGMM (Zong et al., 2018) uses deep autoencoders for novelty detection in a semi-supervised manner. Active anomaly detection, though under-explored, has seen interesting work like Pelleg & Moore (2005) proposing an active learning strategy for rare-category detection. Abe et al. (2006) reduce outlier detection to classification. In anomaly detection, recent work has focused on statistical properties of \"normal\" data. Abe et al. (2006) reduces outlier detection to classification using artificially generated examples and active learning. G\u00f6rnitz et al. (2013) proposed a Semi-Supervised Anomaly Detection method based on Support Vector Data Description. Veeramachaneni et al. (2016) combine unsupervised and supervised learning for active selection of items to be labeled. Similar prior works include Das et al. (2016) with an algorithm applicable to ensemble methods. Our work introduces the Universal Anomaly Inference (UAI) architecture, which can enhance any deep learning-based anomaly detection system for active anomaly detection. Unlike previous works, we emphasize the importance of priors in unsupervised anomaly detection. The UAI layers have a time complexity of O(1) per iteration, making it efficient for handling labeled instances. Universal Anomaly Inference (UAI) enhances deep learning-based anomaly detection systems for active anomaly detection. It can produce similar/better results than state-of-the-art methods even on simple architectures like a DAE. The approach is not claimed to be better than semi-supervised baselines but offers a new method that can be built upon them. This is the first work to apply deep learning to active anomaly detection. The study applies deep learning to active anomaly detection, utilizing the strengths of deep learning algorithms to create an end-to-end architecture that learns representations from both the full dataset and labeled instances. Future directions include using UAI layers' confidence to choose between using its scores or the unsupervised model's anomaly score for auditing, testing new architectures for UAI layers, analyzing the robustness of UaiNets to labeling mistakes, and enhancing model interpretability for auditors. The experiments detailed the model architectures used for DAE and Class models, synthetic MNIST datasets, hyper-parameters, and datasets for real anomaly detection. The algorithm was tested on different anomaly detection models, including a Denoising AutoEncoder (DAE). The curr_chunk discusses the use of a decoder in anomaly detection, where the reconstruction error is used as an anomaly score. A DAE uai network is created by adding a UAI layer on top of the DAE. This architecture is illustrated in a figure. Another approach involves training a classifier to predict labeled data in a dataset. In anomaly detection, a DAE network with a UAI layer is used for reconstruction error as an anomaly score. A classifier is trained to predict labeled data in a dataset using cross-entropy as an approximation of probability distribution. The architecture includes a feed forward neural network with hidden layers and sizes. TensorFlow is used for experiments with specific hyperparameters. For active learning models, the DAE/Class model is pre-trained for 5000 optimization steps, labeling k = 10 items at a time, and further training for 100 iterations after each labeling call. To address the cold start issue, the base anomaly score of the DAE/Class model is used for the first 10 select_top calls, switching to UAI for subsequent labeling decisions. Detailed statistics on synthetic MNIST datasets are provided in TAB2, with different datasets simulating anomalies in sparse clusters or regions of the data space. The experiments follow suggested dataset processing methods. The KDDCUP, Thyroid, and Arrhythmia datasets were processed similarly to previous studies for comparison. KDDCUP contains 34 continuous and 7 categorical features, Thyroid dataset has three classes with hyperfunction treated as anomaly, and Arrhythmia dataset is also used. The KDDCUP-Rev dataset contains a minority of \"normal\" instances, with \"attack\" instances making up 20% of the dataset. An algorithm is compared against Denoising Autoencoders and DAGMM for anomaly detection. The curr_chunk discusses different methods for semi-supervised anomaly detection, including using deep autoencoders to learn a latent representation and incorporating active anomaly detection frameworks. These methods aim to improve anomaly detection performance without the need for a validation/test set. The curr_chunk presents the best hyper-parameter configurations for the proposed algorithm, focusing on the robustness of the approach. Changes in hyper-parameters are made for datasets with fewer anomalies, such as setting k = 3 instances at a time. Results for DAGMM follow the procedures described in (Zong et al., 2018) and are trained in a semisupervised setting. LODA-AAD and Tree-AAD results were also included in the analysis. In a semisupervised setting, LODA-AAD and Tree-AAD results were obtained using the authors' code and the same steps as DAE. Detailed results for synthetic and real anomaly detection datasets, along with Fashion-MNIST experiments, are presented. Results for small budgets on MNIST experiments show a cold start for UaiNets, but they improve over time. Future work could involve measuring their performance further. In future work, measuring the confidence in UaiNet's prediction to dynamically choose between anomaly scores could solve the cold start problem. A detailed comparison of experiments on various datasets is presented, including comparisons to OC-SVM, DCN, and PAE. In comparison to OC-SVM, PAE, DCN, and other models, DSEBM-e and DSEBM-r are anomaly detection systems based on energy based models. DSEBM-e uses a data instance's energy to detect anomalies, while DSEBM-r uses reconstruction error. Results from various models were compared, with DAGMM results from the authors and their own implementation. Our proposed method outperforms LODA-AAD and Tree-AAD on multiple datasets, showing comparable results to state-of-the-art DAGMM but with lower standard deviation. Experiments on synthetic anomaly detection datasets based on Fashion-MNIST are also presented. Experiments on synthetic anomaly detection datasets based on Fashion-MNIST show similar trends to MNIST, with anomalies harder to identify. UaiNets are more robust than underlying networks. UaiNets are shown to be more robust than underlying networks in detecting anomalies across different datasets. The evolution of hidden representations and anomaly scores through training is analyzed, along with the impact of the number of audited anomalies. Visualizations of learned representations and anomaly scores are presented as labels are fed into the network through active learning. The evolution of hidden representations and anomaly scores is analyzed for UaiNets, showing improved anomaly detection compared to underlying networks. Visualizations demonstrate the separability of anomalies and normal data instances with a few labeled instances, highlighting the importance of gradient flow in network performance. The experiments show how the DAE uai network's anomaly detection improves with access to more expert labels. With just a few labels, it outperforms its underlying network, detecting 80,000 anomalies with high precision using only 3,000 labeled instances in KDDCUP. The DAE uai network's anomaly detection improves with more expert labels. It outperforms the underlying network, detecting anomalies with high precision using few labeled instances. Gifs showing choice evolution will be available with the final publication. The proof involves finding residual hyperplanes for probability distributions p1 and p2 when given a third distribution p+ as a weighted mixture. By analyzing limits as \u03bb approaches 0 and 1, small and large residual hyperplanes can be determined for p1 and p2 respectively. The proof involves determining residual hyperplanes for probability distributions p1 and p2 when given a third distribution p+ as a weighted mixture. By analyzing limits as \u03bb approaches 0 and 1, small and large residual hyperplanes can be determined for p1 and p2 respectively. For a small number of anomalies \u03bb \u2248 0, the knowledge that p full = p gives us no further knowledge on the distribution of p anom. The proof establishes upper and lower bounds on the maximum distance between probability distributions p1 and p+ based on the value of \u03bb. For small values of \u03bb, the distribution of p anom does not provide additional information when p full = p. The upper bound on the distance measures \u03b4(p+, p1) and ||p+ - p1|| is given by \u03b4(p+, p1) \u2264 1/2 log(1/(1-\u03bb)) and ||p+ - p1|| \u2264 2 log(1/(1-\u03bb)), which is a tight bound for \u03bb \u2248 0. Theorem 3 provides a lower bound on the maximum distance between probability distributions p1 and p+ when given a third distribution p+ composed of a weighted mixture of p1 and p2. The maximum distance measures are \u03b4(p+, p1) and ||p+ - p1||, with a tight bound for \u03bb \u2248 1. The proof provides a lower bound on the maximum distance between probability distributions p1 and p+ when p+ is a weighted mixture of p1 and p2, with a tight bound for \u03bb \u2248 1. The proof involves expanding distance equations and maximizing the superior distance between distributions."
}