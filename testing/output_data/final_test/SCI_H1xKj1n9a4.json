{
    "title": "H1xKj1n9a4",
    "content": "Deep neural networks (DNNs) are inspired by the human brain and research has explored their connection. Previous work shows DNNs trained with neural responses from the brain can achieve human-level performance in image recognition tasks. A neuro-AI interface is introduced to use human neural responses to assist AI systems in solving complex tasks. This concept is applied to improving generative adversarial networks (GANs). The fundamental problem in generative adversarial networks (GANs) is designing an evaluation metric for image quality. Deep neural networks (DNNs) have shown state-of-the-art results in various fields, matching or surpassing human abilities. CNNs are compared to the human visual system due to their hierarchical processing similarities. The use of CNNs in understanding sensory cortical processing and neural dynamics in the brain is explored. Research on the interaction between CNNs and neural dynamics is limited, with a growing interest in generative adversarial networks (GANs) in deep learning. Generative adversarial networks (GANs) have been widely used in various domains such as computer vision, natural language processing, and speech synthesis. GANs are preferred over other generative models for their ability to handle sharp density functions, generate desired samples efficiently, and eliminate bias. Despite their success in image generation, image translation, super-resolution, and completion, GANs still face challenges like mode collapse, training difficulty, and evaluation complexity. Generative adversarial networks (GANs) face challenges in achieving Nash equilibrium during training and evaluating the dissimilarity between real and generated distributions. While computational aspects have been extensively researched to mitigate these issues, limited literature exists on evaluating GANs based on human perceptions. Developing a more meaningful evaluation metric is crucial for refining and designing better GANs. Evaluation metrics like Inception Score (IS), Kernel Maximum Mean Discrepancy (MMD), and Fr\u00e9chet Inception Distance (FID) have limitations. They do not align with human perceptual judgments of GAN models, require large sample sizes for evaluation, and cannot rank individual GAN-generated images by quality. Human perception is considered more robust to adversarial images compared to machine learning systems. The within GAN variances are crucial as they provide insight into the variability of the GAN. A CNN matched with neural data from the inferior temporal cortex has shown high performance in object recognition tasks. A neuro-AI interface system is described, where human neural responses are used to assist AI systems in solving complex real-world problems. This interface is utilized to address the challenge of designing proper evaluation metrics for GANs. The study demonstrates the use of neural responses from EEG signals to train a CNN model for predicting Neuroscore. Neuroscore is calculated based on the P300 event-related potential present in EEG signals. Three different CNN models are tested using this framework. Neuroscore is calculated based on P300 event-related potential in EEG signals, which reflects human perceptual judgment of images. CNNs can predict neural responses in the inferior temporal cortex for image recognition tasks. Temporal cortex performs well in image recognition tasks. Using DNNs for predicting neural responses offers benefits such as closer information processing to the human brain system. Neural signals reflect human perception, and interfacing between neural responses and DNNs can be more efficient than traditional methods. The use of CNNs to predict neural responses from non-invasive BCI is an unexplored area in the literature. EEG measurement offers advantages such as simplicity and painlessness compared to invasive methods. EEG measurement, despite advantages like simplicity and painlessness, faces challenges such as low signal quality and spatial resolution. Advanced machine learning technologies have made source localization and reconstruction feasible for EEG signals. Previous work has shown the efficacy of using spatial filtering approaches for reconstructing P300 source ERP signals. The use of DNNs to predict Neuroscore when neural information is available is proposed to generalize the use of Neuroscore. The proposed neuro-AI interface aims to generalize the use of Neuroscore by interfacing neural responses with AI systems, specifically using a CNN to predict Neuroscore from images generated by GAN models. The interface includes processing images through the brain to produce P300 source signals, training a CNN with EEG signals, and using fully connected layers to predict the P300 source signal response. The model predicts single trial P300 source signal in 400-600 ms response from image input using Mobilenet V2, Inception V3, and Shallow network. Pretrained parameters are used up to FC 1, and training is done from FC 1 to FC 4. The brain system is more complex than demonstrated in this work. Our framework extends to be more biologically plausible, incorporating windowed single trial P300 source signal and EEG information in training. The training strategy involves two stages: learning from image to P300 source signal, and learning from P300 source signal to P300 amplitude. Loss1 and loss2 metrics are defined for model evaluation. EEG is added to find a mapping function from images to P300 signal. We incorporated EEG into the model to map images to single trial P300 source signals. The performance of models with and without EEG was compared during training. Two stage loss functions were defined for evaluating the models. Training without EEG involved minimizing loss 2 directly, while training with EEG information followed a specific algorithm outlined in Algorithm 1. Including EEG information during the training stage improves the performance of CNN models in predicting the Neuroscore. Models with EEG outperform those without EEG, with smaller errors and variances. Statistic tests confirm the significance of EEG inclusion, with Inception-EEG, Mobilenet-EEG, and Shallow-EEG ranked in performance order. Including EEG information during training improves CNN model performance in predicting Neuroscore. Inception-EEG, Mobilenet-EEG, and Shallow-EEG rank highest. Randomized EEG signals increase errors significantly for all models, showing the importance of EEG information in training. Models with EEG have stronger correlation between predicted and real Neuroscore. EEG inclusion leads to more separable clusters in model training. The study demonstrates that including EEG information during training improves CNN model performance in predicting Neuroscore. Neuro-AI interface is introduced to interact CNNs with neural signals, showing that models with EEG rank higher and have stronger correlation between predicted and real Neuroscore. Three deep network architectures are explored, highlighting the importance of including neural responses during training for evaluating the quality of images produced by GANs. The study shows that including neural responses during training improves the accuracy of the neuro-AI interface. The averaged reconstructed P300 signal distinguishes between different image categories, as shown in FIG1. The study found a strong negative correlation between Neuroscore and BE accuracy for GANs, with PROGAN performing the best, followed by DCGAN and BEGAN. Traditional evaluation metrics were consistent with human judgment. Traditional evaluation metrics do not align with human judgment of GAN performance, as they cannot measure image quality like Inception Score. Neuroscore, proposed as a more human-consistent metric, can evaluate individual image quality, unlike traditional metrics that require large samples. Neuroscore, a novel metric for evaluating GANs, offers a more human-consistent approach by directly reflecting human perception. It requires a smaller sample size and correlates with image quality better than traditional metrics like Inception Score. The predicted P300 amplitude can observe variations within GANs and is still correlated with real Neuroscore when RFACE images are added. The Neuroscore metric evaluates GANs based on human perception, correlating with image quality better than traditional metrics. The model ranks image types as PROGAN>RFACE>BEGAN>DCGAN, consistent with direct Neuroscore measurements. EEG recording during training may limit generalizing Neuroscore, but using a dry electrode EEG system like BID8 can simplify data acquisition. GANs also allow for synthesizing EEG data (BID12) with applications in brain-machine interface research."
}