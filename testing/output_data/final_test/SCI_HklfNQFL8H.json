{
    "title": "HklfNQFL8H",
    "content": "Developing biologically plausible learning rules for deep neural networks is crucial for bridging deep learning and neuroscience. Meta-learning is used in this work to discover networks that learn with feedback connections and local, biologically motivated rules. These networks effectively perform online credit assignment in multi-layer architectures, outperforming a gradient-based meta-learning algorithm. The model in this study outperforms a gradient-based meta-learning algorithm for continual learning on regression and classification benchmarks. It represents a step towards biologically plausible learning mechanisms that can overcome the limitations of gradient descent-based learning. There is debate over how well backpropagation, commonly used in deep learning, resembles biological learning algorithms. The proposed learning paradigm introduces feedback connections in deep neural networks to address the credit assignment problem in a biologically plausible manner. It involves updating feedforward weights using local plasticity rules and employing meta-learning for optimization. Incorporating feedback connections in deep neural networks addresses the credit assignment problem using local plasticity rules and meta-learning for optimization. Research shows that meta-learned deep networks can update weights effectively in early layers, with feedback and local learning rules outperforming gradient descent on challenging few-shot and continual learning tasks. Alternative algorithms like random feedback weights and target propagation have been explored, but they do not scale well to difficult tasks like ImageNet classification. Backpropagation-based deep learning struggles with tasks like ImageNet classification and falls short of human and animal learning. Meta-learning, specifically gradient-based meta-learning, aims to address these issues by optimizing network initialization for quick learning from few examples of new tasks. In batch learning, the approach can implement any batch learning algorithm. It has been extended to continual learning with inner-loop optimization involving online gradient steps on nonstationary data distribution. Research has explored inner-loop updates based on Hebbian learning rules instead of gradient descent. However, these methods do not fully address the credit assignment problem. Recent work has also looked into meta-learning algorithms for learning feedback weights using node perturbation and RL algorithms. In our model, a neural network processes input data, receives a target signal, and updates its activations through a feedback function. Synaptic plasticity occurs based on a local learning rule adjusting synaptic weights. Plasticity may be limited to the final network layers in some experiments. This model allows for direct updating of neural activations. The post-feedback case involves updating neural activations directly with feedback, leading to Hebbian-style plasticity. This approach avoids disrupting feedforward computation but may be challenging to implement. Possible biological implementations include segregated dendrites or feedback through neuromodulatory signals. Oja's learning rule is used in simulations with linear feedback connections and ReLU nonlinearity for positive-valued feedback activations. In a neural network, the output of a layer is set to ReLU with feedback matrix, where the strength of feedback is controlled by \u03b2. \u03b2 = 0 represents unsupervised Hebbian learning, while \u03b2 = 1 represents supervised learning. Meta-learning is used to effectively train the network by simulating learning episodes, testing inputs, and backpropagating through the learning procedure. Meta-learned parameters include initial weights and feedback. Plastic weights change during the network's lifetime, while meta-learned quantities are optimized over many lifetimes. Learning signals propagate through a feedback pathway in backpropagation. The proposed method involves evolving feedforward weights through Hebbian plasticity, optimizing feedback pathways and initial weights over lifetimes. Error signals are injected directly into layers without derivative computations. The learning algorithm can approximate any learning algorithm with wide and deep neural networks. The learning algorithm involves mapping training examples to predicted outputs using deep ReLU networks. The feedforward and feedback functions are optimized through Hebb's rule or Oja's rule, allowing weight updates to encode training data losslessly. This method can approximate any learning algorithm with wide and deep neural networks. In online continual learning, feedback weights play a crucial role in approximating target functions. Experimental evaluation on regression and classification tasks using specific network architectures shows the effectiveness of this approach. The regression task involves sampling sine functions with varying parameters in each training episode. During meta-training, the network learns to output y for new x inputs based on sine functions presented in episodes. The dataset is split into meta-training and meta-testing classes, with k examples from each class presented in an episode. Feedback weights to earlier layers are meta-learned, and evaluation occurs on unseen classes. Meta-training is performed for 40,000 episodes. The study evaluates a method by comparing its performance to a gradient-based meta-learner with the same architecture. They vary the number of plastic layers in the network and conduct ablation experiments to understand the significance of learned feedback weights. The experiments include disallowing feedback altogether and clamping all \u03b2 parameters to 1. The study compares the performance of meta-learned feedback and local plasticity to a gradient-based meta-learner with the same architecture. Feedback, in addition to local plasticity, is found to be necessary for learning, with feedback to earlier layers improving performance. Networks with a mix of unsupervised Hebbian and supervised feedback-modulated learning outperform those with fixed \u03b2 values at 1. The study shows that a combination of unsupervised Hebbian and supervised feedback-modulated learning is beneficial. The correlation between weight updates in the feedback network and gradient descent updates increases from early to late layers but remains weak. This suggests that the meta-learned feedback network learns differently from gradient-based learners. The work demonstrates that meta-learning can optimize neural networks for online learning using local plasticity rules and feedback connections. The present work focuses on scaling meta-training networks for longer lifetimes and exploring alternatives like evolutionary algorithms. Future work aims to increase biological plausibility by enabling feedforward and feedback passes to run in parallel. This requires ensuring that they do not interfere destructively. The meta-learning procedure optimizes for precise feedforward and feedback weight initialization, aiming to reflect stochasticity in synapse development. Applying meta-learning to biological learning systems could lead to the emergence of new learning circuits. Sufficiently wide and deep neural networks with supervised feedback and local learning rules can approximate any learning algorithm. The network receives a target signal from a supervisor, undergoes synaptic plasticity based on neural activations, and uses local learning rules. It aims to approximate a target function using feedforward and feedback functions. The update of synaptic weights follows Hebb's or Oja's learning rules. The network is a deep neural network with ReLU nonlinearities and ensures nonnegativity. The deep neural network has 2N + 2 layers with ReLU nonlinearities. The activations of the intermediate 2N layers are kept nonnegative, allowing them to be treated as linear. The model is simplified with an initial neural network \u03c6(\u00b7; \u03b8 ft ), linear weight matrices, and an output neural network f out (\u00b7; \u03b8 out ). The weights of layer W j i are updated based on the activations x j i and diagonal matrices. Proofs for Hebb's rule and Oja's rule are conducted in parallel, with an indicator variable distinguishing between the two rules. The learning rule for the deep neural network involves setting specific matrices and constants, specifying a feedforward architecture with plasticity in certain layers. Feedback-induced activations play a role in updating the weight matrices, while certain layers remain nonplastic. Feedback propagation and plasticity are not present in the feature extractor or output network. The learning rule for the deep neural network involves setting specific matrices and constants, specifying a feedforward architecture with plasticity in certain layers. Feedback-induced activations play a role in updating the weight matrices, while certain layers remain nonplastic. Feedforward propagation is affected only by the weight matrices, and plasticity updates modify the weight matrices. The goal is to choose matrices and functions to describe the values of input-output pairs. The learning rule for the deep neural network involves setting specific matrices and constants for a feedforward architecture with plasticity in certain layers. Feedback-induced activations update weight matrices, while some layers remain nonplastic. The goal is to choose matrices and functions to describe input-output pairs.\u03c6 is a universal function approximator with specific forms for \u03d5(y) and discr(x), satisfying nonnegative outputs. B j,l and G j,l are defined as 1 \u00d7 J matrices with specific values. The learning rule for the deep neural network involves setting specific matrices and constants for a feedforward architecture with plasticity in certain layers. Feedback-induced activations update weight matrices, while some layers remain nonplastic. The goal is to choose matrices and functions to describe input-output pairs.\u03c6 is a universal function approximator with specific forms for \u03d5(y) and discr(x), satisfying nonnegative outputs. B j,l and G j,l are defined as 1 \u00d7 J matrices with specific values. The J matrix contains ones in the j and l positions and zeroes elsewhere, ensuring invertibility. G j,l maps \u03d5(y) to a vector consisting of J 2 d-dimensional vectors, with \u03d5(y) appearing in the J * j + l position. The approximation in the equalities is due to terms included to ensure invertibility. The claim is made that z k \u2248 v(discr(y k ), {j + J * l, l + J * j}) under certain conditions. The learning rule for the deep neural network involves setting specific matrices and constants for a feedforward architecture with plasticity in certain layers. Feedback-induced activations update weight matrices, while some layers remain nonplastic. The goal is to choose matrices and functions to describe input-output pairs.\u03c6 is a universal function approximator with specific forms for \u03d5(y) and discr(x), satisfying nonnegative outputs. B j,l and G j,l are defined as 1 \u00d7 J matrices with specific values. The J matrix contains ones in the j and l positions and zeroes elsewhere, ensuring invertibility. G j,l maps \u03d5(y) to a vector consisting of J 2 d-dimensional vectors, with \u03d5(y) appearing in the J * j + l position. The approximation in the equalities is due to terms included to ensure invertibility. The claim is made that z k \u2248 v(discr(y k ), {j + J * l, l + J * j}) under certain conditions. Except for slots specified by set A set to a, {(x, y) k } and x can be decoded accurately from z. B 0 contains an identity matrix in its last J-dimensional block, allowing x to be decoded from z with arbitrary accuracy. By subtracting B 0 \u03c6(x ) from z and multiplying by 1 \u03b1, an unaltered version of K k=1z k can be obtained. Decoding K k=1z k involves inferring the discretization of x k by checking nonzero values in specific slots and adjusting accordingly. The vector z k can be decoded to arbitrary accuracy from the set {(x, y) k } and x using the function f out. This function performs a decoding procedure and approximates f target to arbitrary precision."
}