{
    "title": "SyxytxBFDr",
    "content": "Lyceum is a high-performance computational ecosystem for robot learning, built on Julia and MuJoCo. It is significantly faster than other popular abstractions like OpenAI\u2019s Gym and DeepMind\u2019s dm-control, reducing training time for reinforcement learning algorithms. Lyceum supports real-time model predictive control with physics simulators, has a straightforward API, and enables parallel computation across multiple cores or machines. More information can be found at: https://sites.google.com/view/lyceum-anon. The advancement of robotic control has been greatly influenced by the growth of computational infrastructure, including GPU computing and automatic-differentiation tools like TensorFlow and PyTorch. These tools, along with physics simulators like MuJoCo and frameworks like OpenAI's Gym and DeepMind's dm_control, have revolutionized algorithms such as Reinforcement Learning and Model-Predictive Control. Simulation to real-world transfer has emerged as a promising paradigm in robotic control. Transfer learning in robotic control has shown promise, with robust control policies trained in simulation successfully transferring to the real world. However, many algorithms are computationally inefficient and struggle to scale to complex domains, requiring hours to days of compute time for training. For instance, OpenAI's Dactyl project needed 50 hours of training across multiple CPU cores and GPUs, a luxury only available to a few labs. RL algorithms are sensitive to hyper-parameter choices and often require reward shaping. Many reinforcement learning algorithms are sensitive to hyper-parameter choices and require reward shaping, leading to lengthy learning processes. This computational bottleneck hinders progress in deploying solutions in the real world and limits hardware results compared to the number of proposed algorithms. Reducing experiment turnaround time is crucial for scaling up to harder tasks and making resource-intensive algorithms accessible to research labs. Existing frameworks like Gym and dm_control are too slow for real-time model predictive control due to computational restrictions. This leads to planning algorithms being run offline without feedback, hindering stochastic control. To address this, Lyceum, a computational ecosystem using Julia and MuJoCo, aims to enable faster training of policies with RL algorithms and facilitate real-time MPC for complex robotic tasks. Lyceum, a computational ecosystem utilizing Julia and MuJoCo, offers faster RL and MPC algorithms compared to Gym and dm_control. This speedup allows researchers to tackle harder problems without increased computational costs and enables real-time MPC planning through a simulator. The research focuses on using MuJoCo as a physics simulator for robot learning, enabling quick generation of robotic scenes and prototype RL solutions. The framework in Julia combines high-level language programming with the speed of low-level languages like C, with potential for extension to other simulators like Bullet and DART. The mainstream adoption of MuJoCo for robot learning has increased in the past few years due to the introduction of computational ecosystems like OpenAI's gym and DeepMind's dm_control. These ecosystems provide python bindings for MuJoCo, enabling easy access to physics-based environments and prototype algorithms. However, the flexibility of these ecosystems comes at the cost of computational efficiency, as they are slow and inefficient due to poor parallelization capabilities of Python. Several attempts have been made to improve Python-based frameworks by adding JIT compilation, but they only support a subset of the language and do not match Julia's performance. A framework similar to Gym for distributed computing still faces performance issues. In contrast, our work aims to enhance computational ecosystems using Julia and integrates MuJoCo with zero overhead. Our framework, Lyceum, supports various algorithms and environments for robotic control with reinforcement learning (RL) and model predictive control (MPC). It integrates existing computational ecosystems like OpenAI Baselines, MJRL, Soft-Learning, and RL-lab, along with environments such as Hand Manipulation Suite, Door Gym, and Surreal Robosuite. Lyceum includes popular robotics algorithms like PPO and Natural Policy Gradient for RL, as well as MPC algorithms like \"Model Predictive Path Integral.\" Future plans involve adding more algorithms and advances to the ecosystem to support unique computational considerations in designing robotic control with RL and MPC. Robotic control with RL and MPC requires unique computational considerations. RL algorithms, like policy gradient methods, show impressive results but are sensitive to hyperparameters and reward shaping. These tasks often need human intervention for refinement, making experiment turnaround times critical. Experiment turnaround times are critical for robotic control with RL and MPC, as they are limited by the speed of serial operations within each thread. Real-time MPC algorithms like MPPI, POLO, and iLQR can benefit from parallelization. Computation of actions must happen within the control loop time period, often requiring locally available compute for robotic hardware to match strict time constraints. Lyceum ecosystem includes Julia packages for efficient robotic control with high-level programming language features. It consists of Lyceum.jl for environment and controller interfaces, LyceumAI.jl for control algorithms, MuJoCo.jl for physics simulation, and LyceumMuJoCo.jl for environment abstraction. Julia, developed in 2012 at MIT, focuses on technical computing. Julia, developed in 2012 at MIT, is a dynamic, high-level programming language with a REPL interface and JIT compilation capabilities. It allows researchers in robotics and RL to quickly express ideas in code while maintaining high performance at runtime. Julia's core philosophy is that users' code should be as powerful and fast as the core language itself. Julia empowers users to create tools like Lyceum without low-level knowledge, benefiting algorithmic development by expanding available operations. It extends broadcasting to all functions, combining multiple operations into a single loop. Julia enables users to efficiently apply multiple operations to data structures by combining them into a single loop. This flexibility eliminates the need to worry about specific vectorized functions or waiting for library implementations. Additionally, Julia's ecosystem allows for seamless interaction with Python through packages like PyCall.jl, providing access to a wide range of tools and libraries. Julia researchers can tap into tools and libraries like MuJoCo.jl, R, and C++ for calling C. Julia supports distributed and shared-memory multi-threading for parallelizing code easily. Lyceum also supports parallel computation. These features make writing performant and generic code easy. Julia's rich ecosystem of open-source packages like Lyceum simplifies writing performant and generic code. The built-in package manager handles over 3000 packages, preventing dependency issues. Lyceum.jl provides utilities for data logging, multi-threading, and controller benchmarking. It also includes interface definitions for implementing functionalities similar to popular Python frameworks like Gym. The interface discussed implements features similar to Python frameworks Gym and dm_control but with key differences: 1. Ability to get/set simulator state for model-based methods like MPC. 2. Optional in-place functions to reduce memory usage. 3. Optional evaluation metric for task completion reward optimization. Users are encouraged to implement their own environments, a crucial aspect of robotics. The interface discussed allows users to implement their own environments for robotics research. Sensible defaults are provided for most of the API, with only a subset of functions needing to be overridden for custom behavior. Users can choose between in-place and out-of-place operations for convenience or performance. This separation of interface and implementation allows for flexibility in using different simulators and back-ends. The MuJoCo.jl package provides a low-level Julia wrapper for MuJoCo, with a one-to-one correspondence to MuJoCo's C interface. LyceumMuJoCo.jl builds on top of MuJoCo.jl to implement the AbstractEnv API, offering environments like CartPole, Swimmer, Ant, and more from OpenAI Gym, along with new environments. One such new environment involves reconfiguration planning with movable and target objects. The reconfiguration planning domain involves movable obstacles and goal configurations, with challenges like reward under-specification, sequential manipulation, and variable number of objects. Additionally, a locomotion environment requires an agent to navigate rough terrain represented as height maps. The environments in the reconfiguration planning domain involve movable obstacles and goal configurations, with challenges like reward under-specification, sequential manipulation, and variable number of objects. A locomotion environment requires an agent to navigate rough terrain, hills, and terraces, represented as height maps. These environments are procedurally-generated and support multi-threading, with LyceumAI.jl offering algorithms for robotic control leveraging Julia's performance and multi-threading abilities. The experiments and benchmarks aim to assess Julia's facilitation of high-performance programming in robotics and RL domains. In the robotics and RL domains, experiments are conducted to compare the performance of Julia with Gym and dm_control. Different models are considered, including CartPole, Ant, a reconfiguration environment using HERB, and Humanoid. Experiments are performed on a 16-core Intel i9-7960X with the CPU governor pinned at 1.2GHz to prevent dynamic scaling or thermal throttling. Parallel computing support is implemented using Python's multiprocessing library. The first task explores the parallel scaling performance of LyceumMuJoCo.jl against Gym, dm_control, and a native C implementation. The performance of LyceumMuJoCo.jl is compared against Gym, dm_control, and a native C implementation using a OpenMP thread pool. 1024 samples are collected in parallel with 1 through 16 threads using the humanoid.xml model. The relative sampling performance is compared for each model with 16 fixed threads. The real-time factor is examined using Julia MPPI and Python Gym implementations for each model, where a factor of 1 indicates the controller runs at the same speed as the simulator. The controller runs twice as fast as the simulator, with data collected at 1.2GHz scaled up to 3.3GHz for a more realistic presentation. Benchmark results show varying scaling efficiencies between Gym, DMC, Lyceum, and a native C implementation using OpenMP. Python implementation is found to be largely IO-bound due to inter-process communication overhead and waiting on locks. The distributed Python implementations are mostly IO-bound, with Lyceum and native C outperforming Gym and dm_control in sampling throughput. The performance difference between Ant, CartPole, HERB, and Humanoid environments ranges from 14x to 286x. Lyceum and C scale linearly with threads, while Gym and dm_control plateau around 10 threads, indicating potential limitations in utilizing higher core count CPUs. The comparison between our framework and OpenAI Baseline's implementation of Proximal Policy Optimization (PPO) in OpenAI Gym environments shows similar training curves for Swimmer and Hopper, but lagging behind for Humanoid. The difference is attributed to additional features in OpenAI Baseline's core PPO algorithm, resulting in shorter training times. Lyceum, a new computational ecosystem for robot learning in Julia, offers rapid prototyping and high performance with Flux.jl. It provides 10-20X speedups compared to OpenAI gym and dm_control, enabling faster experimental times for RL algorithms and real-time model predictive control. Future plans include porting over OpenAI's baselines and environments like hand manipulation suite and DoorGym."
}