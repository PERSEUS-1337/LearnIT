{
    "title": "Bke7MANKvS",
    "content": "Deep artificial neural networks can achieve a small difference between training and test accuracies on identically distributed sets, but may struggle with underrepresented or unrepresented subsets during inference. To address this, a classification algorithm is reformulated as a search for a source code mapping input features to classes. A necessary condition for generalization is derived using information distance, leading to an optimization problem for learning a more general classification function. To improve classification function generalization, input features are extended by concatenating encodings and training the classifier on the extended features. Using channel codes in image classification enhances sample set representation. Through experiments, models trained on encoded input features show increased robustness to common corruptions and adversarial perturbations compared to models trained on uncoded input. Deep learning classifiers generalize better when trained on encoded input features, improving robustness to corruptions and adversarial perturbations. The traditional approach to generalization error may fail when training and test sets are not representative of the empirical sample set, leading to unreliable decisions. This raises concerns about the robustness, fairness, and safety of the learned classification function. To ensure deep learning classifiers generalize effectively, algorithmic information theory proposes using Kolmogorov complexity as a measure of information content. By utilizing the information distance metric and coding theory, a necessary and sufficient condition for generalization can be derived. This involves extending input features to improve the classification function's robustness and reliability in real-world settings. In this work, the focus is on how well a learned classification function generalizes with respect to the true classification function. The goal is to minimize the generalization error by measuring the difference between training error and inference error on the empirical sample set. Robustness to common corruptions and adversarial robustness are used as metrics to evaluate generalization on corrupted or perturbed samples. The normalized information distance is a universal cognitive similarity metric used to find a condition for generalization in deep learning. Learning algorithms detect dominating input features through this metric, which minorizes other distances. A learning algorithm is formulated as a search for a source code based on training examples, with the learned classification function acting as a lossy compressor. The learned classification function acts as a lossy compressor, discarding some information, making input features irrecoverable from the class label. The normalized information distance is used to ensure generalization by comparing true and learned source codes. A compression-based similarity metric is employed to approximate this theoretical construct. The normalized compression distance is used to derive a condition on the compressed size of the learned source code for identifying encodings that help in learning a more general source code. Input codes are used to generate relations between input features in order to ensure the learned classifier is more general. Channel codes are applied to input features for CIFAR-10 image classification using a 4-D 5-PAM trellis-coded modulation. The use of a 4-D 5-PAM trellis-coded modulation scheme enables the deep neural network to learn from encoded input features, reducing generalization error. Experiments show that models trained on encoded features are more robust to noise and adversarial perturbations compared to models trained on uncoded features. The design of the input code plays a crucial role in classification tasks. Designing efficient input codes for deep neural networks (DNNs) is crucial for achieving generalization in classification tasks. Merely increasing the number of input channels does not improve robustness to noise or adversarial perturbations. The literature on generalization focuses on minimizing the generalization error, but does not address generalizing to input samples not representative of training and test sets. In this subsection, the work compares domain-generalization, domain-adaptation, and data augmentation techniques to highlight their differences. Unlike domain generalization, which aims to generalize to unknown domains by training on samples from different domains, this work does not require drawing training samples from a different domain. Encoding the training set enables a DNN to learn different relations between features that it could not learn from the uncoded training set alone. The curr_chunk discusses different approaches in domain adaptation and adversarial training to achieve generalization and robustness, highlighting the differences from the approach presented in the previous paragraph. It emphasizes the avoidance of accessing new samples during an adaptation phase for generalization to the empirical sample set. In contrast to generating new samples for diversity, this work extends input features with encodings to enhance DNN learning without the need for adversarially perturbed training samples in each epoch. Adversarially trained DNNs may not generalize well to all perturbation methods, emphasizing the importance of a theoretically-grounded approach. The goal is to minimize generalization error in classification tasks by deriving conditions for good generalization and framing it as an optimization problem. This approach involves computing the absolute information content of objects to determine the better classifier. The appropriate tool for determining the information content of objects in classification tasks is Kolmogorov complexity, which refers to objects in isolation. This is crucial as using Shannon entropy to quantify information requires objects to be treated as part of a set with a probability distribution. The Kolmogorov complexity of input features, model, and outputs of a DNN is studied to ensure generalization. A distance function is needed to measure similarity between objects for comparing learned classification functions. This function must satisfy metric (in)equalities to be meaningful in the context of generalization. The normalized information distance between objects a and b is a universal cognitive similarity metric that minorizes all other normalized admissible distances. It ensures that objects close in effective similarity are also close according to the normalized information distance. The intuition behind normalizing the information distance is that larger objects differing by a small amount are closer than smaller objects differing by the same. The normalized information distance between objects ensures that objects close in effective similarity are also close according to the normalized information distance. A deep learning classifier distills useful information for its classification task from input features by learning a classification function. The true output function of a learning algorithm is a source code for a random variable X, which compresses input samples. A DNN generalizes well by deciding which input features are relevant for classification. The source code of a learning algorithm is a lossy compressor when the complexity of an input sample is larger than the class it is mapped to. The Kolmogorov complexity of input samples in a deep learning classifier is compared to the number of bits needed to represent the class. A DNN learns a source code that generalizes well with respect to the true source code. Source codes aim for efficient data representation, whether for transmission or storage, retaining necessary information for a given task. A neural network can be seen as a source code that encodes input features for its classification task. By viewing a learning algorithm as a search for a source code, theoretical results from algorithmic information theory and coding theory can be utilized in deep learning. Exploiting the duality of a source code and a channel code allows for learning a more efficient classification function for input features. A deep learning classifier is a non-uniquely decodable source code, making it impossible to derive a condition for generalization based on the normalized information distance between input features and output. The normalized information distance can only determine generalization between a learned source code and the true source code. The normalized information distance is used to determine if learned source codeC 0 is more general than learned source codeC 1 with respect to the true source code C. Minimizing the normalized information distance between the true source code and learned source codeC helps reduce generalization error in classification tasks. Theorem 1 formulates the optimization objective for generalization in a learning algorithm for classification tasks. It states that minimizing the Kolmogorov complexity of the program that computes the transition between learned and true source code helps reduce generalization error. The goal is to increase the complexity of the learned source code without exceeding the complexity of the true source code. The goal is to increase the complexity of the learned source code without exceeding the complexity of the true source code, as simpler classifiers generally generalize better. The learning algorithm aims to learn the true source code to achieve optimal performance metrics for its classification task. The model's fit is determined by its ability to memorize training samples, with overfitting or underfitting assessed on cross-validation or test sets. The goal is to increase the complexity of the learned source code without exceeding the complexity of the true source code. The model's fit is determined by its ability to memorize training samples, with overfitting or underfitting assessed on cross-validation or test sets. The complexity of the learned source code is increased by generating encodings of input features to capture relations not learned well from the original. The encodings E i capture relations between features not learned well from the original features, enhancing the learning algorithm to understand a more complex source code. Theorem 2 states that for a classification task, a more general suboptimal code C E is learned from the concatenation of x S and E i (x S). Successful DNN architectures have the capacity to memorize available input samples. The source code aims to efficiently represent input data by increasing Kolmogorov complexity. In a communication system, source code compresses input before transmission over a channel. The goal is to achieve channel capacity. Theorem 2 discusses a learning system with input and source codes for generalization. The learning system aims to generalize the composition of input and source codes efficiently. The \"physical channel\" precedes the source code, reducing the empirical sample set to available input samples. Common corruptions and adversarial perturbations are applied to the input samples. It is crucial for the learning algorithm to compress features while retaining useful information for classification tasks. Extending input features with encodings can help achieve this goal. Extending input features with encodings can capture relations useful for classification tasks. The classification task remains unchanged when input features are extended. The encoder is a new layer in the model designed from an encoder and an uncoded model. Normalized information distance, based on Kolmogorov complexity, is used to analyze learned source code from encoded input samples. The normalized compression distance approximates the normalized information distance to determine the generalization of source codes with respect to the true source code C. This allows for the minimization of D I (C,C E) in computable forms, providing theoretical results. Equations 2 and 4 specify the distances between the true source code and a learned source code, aiding in deriving theoretical results. The compressed size of a learned source code is larger than that of the true source code when using input codes for generalization. If a suboptimal source code is found, the optimization problem for generalization is to minimize the difference between the two source codes. The compressed size of the learned source code must be maximized to learn the most general source code for the classification task. The source code learned from encoded input samples can capture relations between features not represented by the input samples, enabling a classifier to make better class decisions. The input features are processed using a 4-D 5-PAM TCM scheme to generate multiple encodings. The features are flattened into 2x2 patches and ordered in a clockwise direction to focus on local relations. The CIFAR-10 dataset features are represented by eight bits, and the convolutional encoder produces one extra bit from each feature. The input features are processed using a 4-D 5-PAM TCM scheme to generate multiple encodings. The encodings convey different views of the input features to help model relations for image classification. The encodings are not treated as new input but appended to the original features. The encodings are appended to input features to enable the classifier to learn a complex source code for classification. This approach is key to achieving generalization in deep learning. Designing a channel code for a given classification task is a future research direction. Using channel codes on input features results in learning a more general representation. In experiments on CIFAR-10 and CIFAR-10-C datasets, encoded models show increased robustness to corruptions and perturbations. Various models are trained and modified with encoders, using arbitrary encodings. Test accuracies and training setups are detailed in the appendix. Increasing the number of encodings can reduce generalization error but increases run time. Encoding training and test samples is a one-time process, unlike adversarial training. Designing efficient input codes for classification tasks is a future research direction. No other method achieves robustness to both common corruptions and adversarial perturbations. The experiments conducted on CIFAR-10-C and CIFAR-10 datasets show robustness to common corruptions like Gaussian noise, shot noise, impulse noise, and speckle noise. Increasing the number of encodings concatenated to input features enhances robustness to various types of noise levels. When subjected to impulse noise severity level 4, the uncoded VGG-11 model shows more test errors than the VGG-11 model with 32 encodings. The encoded VGG-11 model with 32 encodings achieves the highest inference accuracy against shot noise severity level 5 on the CIFAR-10-C dataset. Additional experimental results on Gaussian noise are also presented. Robustness to adversarial perturbations is tested on the CIFAR-10 dataset using the white-box PGD attack. Experiments on CIFAR-10 dataset using white-box PGD attack and transfer attacks from uncoded VGG-16 and ResNet-18 models to evaluate adversarial robustness of encoded VGG-16 models. Encoder in encoded VGG-16 models is a new layer in neural network architecture, changing its outputs affects model's performance. Different numbers of encodings used in CIFAR-10 experiments. In CIFAR-10 experiments, increasing the number of encodings improved robustness to adversarial perturbations. The approach presented does not rely solely on adversarial training and can be combined with other methods for greater robustness. The framework provided helps in defining and understanding generalization in deep learning. The study explores generalization in deep learning by analyzing the difference between training and inference errors. It suggests that a complex classification function is necessary for better performance. Concatenating encodings of input features with the original inputs improves generalization by enabling the classifier to learn relationships between features. Experiments show that models trained on encoded input features are more robust to corruptions and adversarial perturbations. Increasing the number of encodings can help minimize generalization errors. To achieve reliability in machine learning, learning a general classification function with minimal encodings is crucial. The true output function is equivalent to the source code for the random variable X, ensuring no information loss. If the complexity of an input sample exceeds the bits needed to describe its class, information is lost. Increasing the number of encodings can help minimize errors in generalization. The normalized information distance is a universal cognitive similarity metric that minorizes all other distances with a negligible error term. In a real-world setting, the learning algorithm sees input samples drawn from a subset of the empirical sample space, ensuring that the learned source code is more similar to the true source code. The true source code C contains all possible relations between input features for classification, while the learned source code C only captures a subset of these relations. The Kolmogorov complexity of the true source code is greater than that of the learned source code. Generalization of the learned source code with respect to the true source code is an optimization problem. When X n S is concatenated with uncoded input samples x S, it increases the Kolmogorov complexity of the learned source code C E. This occurs when a neural network can memorize input samples. The complexity of C E is larger when encodings contain information not represented by uncoded samples. The true source code C contains all possible relations between input features, while C E captures only a subset of these relations. The Kolmogorov complexity of the true source code C bounds the relations between input features. A high-capacity neural network can memorize input samples without encodings E i. However, useful encodings increase the complexity of the learned source code. The conditional Kolmogorov complexities are larger when the information in encodings is not represented in the input samples. The source code learned from concatenation {xS, Ei(xS)} is more general than the source code learned from xS. The normalized compression distance can approximate the normalized information distance for practical purposes. A high-capacity neural network can memorize input samples, leading to larger compressed sizes of true source code compared to learned source code. The inference accuracy is defined as the classification accuracy measured on a subset of the empirical sample set Xn, which may be subjected to common corruptions or adversarial perturbations and may be out of distribution of the training set. The inference accuracy is defined as classification accuracy on a subset of the sample set Xn, which may be corrupted or out of distribution. Generalization error is the difference between training error and inference error on perturbed samples. Generalization error is defined as the difference between training error and inference error on perturbed samples. A learned classification function is considered more general with decreasing generalization error. Source codes for random variables aim for efficient data representation. Channel codes can be designed independently for efficient communication. The Kolmogorov complexity K U (x) of a string x with respect to a universal computer U is defined as the shortest description length of x over all descriptions interpreted by computer U. Encoded CIFAR-10 images convey different views of the input. Refer to textbooks for detailed understanding of source codes and Kolmogorov complexity. The encoded CIFAR-10 images convey different views of the input features, aiding the source code model in learning relations useful for image classification. Models are trained in PyTorch with 16 random initializations over 450 epochs. Gaussian noise is applied to test the robustness of VGG-11 models. The signal-to-noise ratio is defined, and the impact of increasing the number of features is shown in Figure 6. Increasing the number of encodings concatenated to input features improves robustness to Gaussian noise in CIFAR-10 test set. VGG-11 model with 32 encodings at 12 dB SNR has 61.15% accuracy compared to 21.49% for uncoded model. Larger encoded models do not always provide more robustness to common corruptions like Gaussian noise. Results of experiments on CIFAR-10-C dataset corrupted by speckle noise and black-box boundary attacks are shown in Figure 7. The encoded VGG-11 model with 32 encodings shows increased robustness to speckle noise and black-box boundary attacks on the CIFAR-10 dataset. It outperforms uncoded models in terms of accuracy against boundary attacks and achieves the highest accuracy against shot noise compared to other models on the CIFAR-10-C dataset. The encoded VGG-11 model with 32 encodings demonstrates improved robustness against common corruptions and adversarial perturbations on the CIFAR-10 dataset. It achieves high accuracy against Gaussian noise and outperforms other defenses in terms of inference accuracy. Increasing the number of encodings may further enhance the model's robustness. Increasing the number of input channels of the uncoded VGG-11 and VGG-16 models was studied to observe the impact on robustness. Experiments were conducted on encoded models using identical encodings, showing that increasing the number of encoders improved robustness against common corruptions and adversarial perturbations. Increasing the number of input channels in the uncoded VGG-11 and VGG-16 models did not improve robustness to Gaussian noise or white-box PGD attacks. Symbol-to-bit mapping was done using a matrix to convert 5-PAM symbols into 12 bits. Symbol-to-bit mapping converts 5-PAM symbols into 3 bits by drawing bits from specific rows and columns of a matrix. These bits are concatenated to determine the value of the corresponding feature in the encoded sample."
}