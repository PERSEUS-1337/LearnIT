{
    "title": "B1gznX3q8S",
    "content": "Limited angle CT reconstruction is an under-determined linear inverse problem that requires appropriate regularization techniques to be solved. Pre-trained generative adversarial networks (GANs) can clean noisy, artifact-laden reconstructions by projecting onto the inferred image manifold. A robust version of GAN prior, based on corruption mimicking, significantly improves reconstruction quality. This approach operates directly in the image space, is scanner agnostic, and works over a wide range of sensing scenarios. Limited angle CT reconstruction faces challenges in scenarios with few-view or limited-angle settings, where traditional regularization schemes may not be sufficient. These scenarios arise in applications requiring x-ray dosage control, cost reduction, or structural limitations. Suitable regularization schemes can help produce artifact-free reconstructions, but may not be effective in extreme cases. In recent years, there has been a surge in research interest in using deep learning for challenging inverse problems like CT reconstruction. These networks learn to model CT image manifolds, leading to higher fidelity reconstruction compared to traditional methods like Filtered Backprojection or Regularized Least Squares. However, reconstruction networks trained on one scanner may not be effective for others due to variations in sinogram data statistics. In recent years, there has been a surge in research interest in using deep learning for challenging inverse problems like CT reconstruction. These networks learn to model CT image manifolds, leading to higher fidelity reconstruction compared to traditional methods like Filtered Backprojection or Regularized Least Squares. However, reconstruction networks trained on one scanner may not be effective for others due to variations in sinogram data statistics. Furthermore, access to sinogram data could be restricted, leading to the need for image-domain methods. This work focuses on the limited-angle scenario, using generative adversarial networks (GANs) as image manifold priors for reconstruction without requiring sinograms or scanner-specific representations. Using a training set of clean CT images, reconstructions are generated by projecting an initial seed reconstruction onto the image manifold, known as the GAN prior. This process involves sampling from the GAN's latent space to find an artifact-free image resembling the seed image. Conventional methods like projected gradient descent perform poorly with noisy or artifact-ridden initial estimates, leading to the utilization of corruption mimicking techniques from MimicGAN for improved results. The proposed technique, known as corruption mimicking in MimicGAN, uses a shallow CNN and PGD to achieve robustness in noisy seed reconstruction. It alternates between estimating unknown corruption and finding clean solutions until convergence, operating in an artifact-agnostic manner. It can clean images from various distortions and reduces to PGD when the CNN is replaced by an identity function. The study focuses on parallel beam and fan beam types. The study focuses on parallel beam and fan beam types of scanners for CT reconstruction. The reconstruction problem is formulated as X * = arg min X A(X) \u2212 y + R(X), where X is the image, y is the projection, and A is the x-ray projection operator. A regularization function R(X) is used to reduce possible solutions. A full 180\u00b0 scan is needed for a faithful reconstruction of X. In this paper, the use of generative adversarial networks (GANs) is advocated to reconstruct objects from a full 180\u00b0 scan. The approach involves using a pre-trained generator to solve the problem of A(G(z)) \u2212 y, where X * = G(z * ) is obtained through stochastic gradient descent. This method, known as a GAN prior or manifold prior, aims to preserve the original structure of the object during reconstruction. In this work, a modification of the GAN prior is proposed to improve reconstruction quality, especially in scenarios with heavily distorted images. The initial estimate X RLS is obtained using regularized least squares, which significantly impacts the final estimate's quality. The process of Corruption Mimicking aims to improve the quality of projection onto the manifold under various corruptions by estimating both the unknown global optima X* and distortion function f simultaneously using a shallow neural network. This involves solving an equation using alternating optimization and constraining f to be shallow with 2 convolutional layers and a masking layer. The Robust GAN prior includes ReLU activations, a masking layer, and a shortcut connection to encourage learning identity. This technique is corruption-agnostic and effective for CT reconstruction of MNIST and Fashion-MNIST datasets. The method operates directly in the image space, making it applicable to various scanner types. The proposed method operates in the image space and uses the regularized least squares algorithm for image recovery. Limited-angle scenario is emulated by providing a partial sinogram. Experimental settings involve training a DCGAN on datasets and choosing specific hyperparameters for corruption-mimicking. Performance is observed to be robust across different settings. The robust GAN prior is compared against the standard GAN prior without corruption-mimicking. Latent space optimization is run for approximately 2500 iterations, showing significant improvements in reconstruction quality for MNIST and Fashion-MNIST datasets. A performance boost of 4-5 dB on MNIST and 0.5-1 dB on Fashion-MNIST is achieved with the robust GAN prior. PSNR and SSIM may not always correlate with perceptual metrics. The text discusses improving reconstruction quality using a robust GAN prior over a standard GAN projection by computing error in the discriminator feature space for perceptual quality. The approach involves projecting onto the image manifold using corruption mimicking to enhance RLS reconstructions."
}