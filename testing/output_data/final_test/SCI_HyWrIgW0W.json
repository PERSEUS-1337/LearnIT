{
    "title": "HyWrIgW0W",
    "content": "Stochastic gradient descent (SGD) minimizes an average potential over the posterior distribution of weights with an entropic regularization term, performing variational inference for a different loss than the one used for gradients. SGD trajectories for deep networks do not behave like Brownian motion but resemble closed loops with deterministic components due to non-isotropic gradient noise. The covariance matrix of mini-batch gradients for deep networks has a rank as small as 1% of its dimension. Extensive empirical validation of these claims is provided in the appendix. Stochastic gradient descent (SGD) implicitly performs variational inference, with a steady-state distribution over weights estimated by SGD. The potential \u03a6(x) is related to the loss function f(x) and is a function of the architecture and dataset. SGD performs variational inference with a uniform prior, using a different loss than back-propagation gradients. The implicit potential \u03a6(x) is equal to the chosen loss f(x) only if mini-batch gradient noise is isotropic, which is not the case for deep networks. Gradient noise in deep networks is highly non-isotropic, leading SGD to discover locations where \u2207\u03a6(x) = 0, not where \u2207f(x) = 0. The most likely locations of SGD are not the local minima or saddle points of the original loss, and trajectories have a deterministic component instead of Brownian motion near critical points when mini-batch noise is non-isotropic. Stochastic gradient descent (SGD) trajectories near critical points exhibit deterministic components causing loops in weight space. Fourier analysis detects these loops. SGD with non-isotropic noise can converge to stable limit cycles around saddle points. SGD updates weights in a compact subset to ensure appropriate boundary conditions for steady-state densities. The variance of mini-batch gradients is independent of learning rate and batch size. Isotropic diffusion occurs when D(x) is a scalar multiple of identity, while non-isotropic diffusion depends on the weights x. Continuous-time SGD is described by a stochastic differential equation with Brownian motion. The steady-state distribution of weights evolves according to the Fokker-Planck equation. The Fokker-Planck equation describes the evolution of the steady-state distribution of weights, denoted by \u03c1 ss (x). The potential \u03a6(x) is implicitly defined using \u03c1 ss and depends on the full-gradient and diffusion matrix. The steady-state distribution exists and is unique, satisfying certain conditions. The Fokker-Planck equation describes the evolution of the steady-state distribution of weights, denoted by \u03c1 ss (x). The potential \u03a6(x) is implicitly defined using \u03c1 ss and depends on the full-gradient and diffusion matrix. The steady-state distribution exists and is unique, satisfying certain conditions. The steady-state solution of the equation can be expressed in terms of the potential using a normalizing constant Z(\u03b2). This allows for an easy derivation of the steady-state distribution by rewriting the gradient term in terms of the diffusion matrix and a gradient term \u2207\u03a6(x). Additionally, an assumption is made regarding the conservative nature of the force j(x) in the system. The Fokker-Planck equation models a system exchanging energy with an external environment through temperature. The second law of thermodynamics is satisfied, ensuring entropy never decreases. The main result is that SGD performs variational inference, decreasing monotonically towards zero at steady-state. SGD implicitly minimizes a combination of energetic and entropic terms, converging to zero at steady-state. The implicit bias of SGD favors solutions that maximize entropy. The potential term in the equation is crucial, with Lemma 6 showing that it equals the original loss under isotropic diffusion. The original loss itself is proven in Appendix F.2, with Lemma 7 stating that most likely trajectories of SGD are limit cycles. The force j(x) introduces a deterministic component in SGD dynamics. The condition \u2207 \u00b7 j(x) = 0 implies that trajectories traverse closed paths in weight space. Theorem 5 applies for a general D(x) and is equivalent to the JKO functional in optimal transportation if the diffusion matrix is isotropic. Appendix D provides an overview using the heat equation as an example. Corollary 8 shows that the energetic term contains f(x). The JKO functional in optimal transport, as shown in Theorem 5 and Corollary 8, allows for modifying the functional F(\u03c1) in a interpretable manner. The evidence lower bound for the dataset \u039e involves the cross-entropy of the estimated steady-state and the variational prior. SGD performs variational optimization with a uniform prior, corresponding to a loss function with a uniform prior. SGD minimizes a potential \u03a6(x) instead of the original loss f(x) in ELBO, which is different if the diffusion matrix D is non-isotropic. SGD implicitly contains an information bottleneck principle in representation learning, leading to invariant representations. ELBO conflicts with SGD in practice, requiring steps of SGD to minimize the energetic term and estimate the KL-divergence term with a factored Gaussian prior. The approach of using SGD to minimize the energetic term conflicts with enforcing a uniform prior through the KL-divergence term. Researchers have resorted to artificially adjusting the strength of the KL-divergence term using a scalar pre-factor. The potential \u03a6(x) is independent of the optimization process and is determined by the dataset and architecture. The learning rate and mini-batch size play a crucial role in determining the strength of the entropic regularization term. If the learning rate approaches zero, the implicit regularization of SGD diminishes. This highlights the importance of not setting the learning rate too small for effective regularization of SGD. To maintain entropic regularization in SGD, the learning rate should scale linearly with batch size. Sampling with replacement is better for regularization than without replacement, as it reduces the entropic regularization as batch size approaches the total dataset size. Theorem 5 states that sampling with replacement provides better regularization than sampling without replacement, especially with large batch sizes. The diffusion matrix D(x) for deep networks is non-isotropic with a low rank. Trajectories of SGD show periodic components, confirming predictions. Experiments were conducted on three networks, showing a significant fraction of almost-zero eigenvalues in the diffusion matrix. The variance of noise in SGD is largely independent of the weights. The eigenspectra of the diffusion matrix show non-isotropic behavior, with larger eigenvalues for datasets with more variety. CIFAR-100, with 10\u00d7 more classes than CIFAR-10, is a much harder dataset. The eigenvalues in CIFAR-100 are larger and more diverse compared to CIFAR-10, indicating increased gradient diversity with more classes. Input augmentation boosts mini-batch gradient diversity, as shown by higher eigenvalue standard-deviation in CIFAR-100. The diffusion matrix for CIFAR-100 has larger eigenvalues, is more non-isotropic, and has a higher rank, suggesting increased gradient diversity with more classes. Augmenting input data increases mean and variance of eigenvalues while maintaining rank. Based on the diversity of the dataset, it is proposed that the inverse temperature should scale linearly with the mean of the eigenvalues of D. This helps to keep the noise in SGD constant across different hyperparameters. Variance in the eigenspectrum can inform architecture search, as seen in comparisons between different networks and datasets. Data-augmentation creates a larger variance in the eigenspectrum, indicating that the rank of the diffusion matrix and the variance of the eigenspectrum affect architecture performance. The mean of the eigenvalues can be controlled using learning rate and batch size, useful for automated architecture search. Computational power is required for this task, and auto-correlation of weights is shown in FIG3. Both Figs. 3a and 3b display the mean and standard deviation of weight index i, indicating a similar frequency spectrum for all weights. Comparing with white noise FFT and Brownian motion auto-correlation, it shows that SGD trajectories are not Brownian motion. Training a smaller version of small-fc on down-sampled MNIST images for 10^5 epochs, snapshots of weights are stored after each epoch to observe trajectory in weight space. Low-frequency periodic components in SGD trajectories are noted. After observing the trajectory of weights in weight space during training, it is noted that SGD trajectories exhibit low-frequency periodic components. The presence of these modes indicates a periodic dynamics of the force j(x), which spreads into all dimensions of x due to the non-linear nature of j(x). The FFT analysis shows high-frequency modes dominated by colored noise, with significant correlation between iterates even at large lags. This suggests that the SGD process is not following a Brownian motion pattern as expected near critical points. The trajectory of weights in weight space during training shows low-frequency periodic components in SGD trajectories, indicating a non-Brownian motion pattern. The gradient magnitude in deep networks remains large, with the full gradient computed over the dataset not decreasing significantly with epochs. The presence of a non-zero j(x) keeps SGD away from critical points, as shown in Theorem 22. The potential \u03a6(x) is explicitly formulated in this section. The explicit formula for the potential \u03a6(x) is provided in this section, along with a discussion on generalization implications. The analysis is split into two cases: a local analysis near critical points where linearization is used, and the general case where local rotation and scaling cannot be applied. An example from BID39 is used to illustrate these cases. The force field in Fig. 4a has locations where \u2207 f (x) = 0 due to j(x) = 0. In Fig. 4b with \u03bb = 0.5, the locations have shifted slightly as predicted. Fig. 4c shows SGD converging to limit cycles around the saddle point, demonstrating solutions obtained may differ from local minima. Example 19 discusses constructing different gradients leading to the same potential \u03a6. The gradient field f(x) is discussed with x=0 as a critical point, which can be a local minimum, maximum, or saddle point. The gradient is linearized around the origin using a fixed matrix F (the Hessian). The matrix F can be decomposed into symmetric and anti-symmetric parts to get D and Q. This linearization is explored when the critical point is a local minimum, suggesting dynamics near a critical point up to the first order. Near a critical point, the effect of j(x) is to rotate the gradient field and move the critical points. The deviation of the critical points \u2207\u03a6 from those of the original loss \u2207 f is discussed in the context of A-type stochastic integration, which is used in non-equilibrium studies in physics and biology for computing steady-state distributions easily. The main result of the section shows that the most likely locations of SGD are not the critical points of the loss function. The Ito SDE is equivalent to the A-type SDE with the same steady-state distribution. The potential \u03a6(x) can be computed in terms of the gradient \u2207 f (x) and the diffusion matrix D(x), and does not depend on \u03b2. The Ito SDE and A-type SDE FORMULA1 have the same Fokker-Planck equations due to their shared steady-state distributions. SGD may spend significant time away from critical points, even converging around saddle points. Lemma 20 and Theorem 22 show unique definitions of \u03c1 ss and potential \u03a6 in terms of original quantities. Theorem 22 uniquely defines the potential \u03a6(x) and steady-state \u03c1 ss (x) in terms of the original quantities \u2207 f (x) and diffusion matrix D(x). The presence of a non-zero divergence in Q(x) is due to a non-isotropic D(x), even if D is constant. This non-isotropic property can lead to a lack of a function \u03a6(x) such that \u2207\u03a6(x) = D \u22121 \u2207 f (x) at all x. The diffusion matrix remains constant in deep networks, but out-of-equilibrium effects are observed with small batch sizes or high learning rates. Non-equilibrium behavior in SGD is essential for good generalization performance in high-dimensional models like deep networks. As the implicit entropic regularization in SGD diminishes, good generalization performance is typically achieved, especially for deep networks. The authors found that solutions of discrete learning problems that generalize well belong to dense clusters in the weight space. They proposed a loss called \"local entropy\" to easily find these solutions. This idea has been successful in deep learning by modifying SGD to seek solutions in \"wide minima\" with low curvature, leading to improvements in generalization performance and convergence rate. Local entropy is a smoothed version of the original loss using a Gaussian kernel. For large values of the kernel variance, the new loss makes the original local minima exponentially less likely. The concept of local entropy in deep learning modifies SGD to converge around wide saddle points, leading to good generalization. This out-of-equilibrium behavior of SGD on deep networks contributes to its strong generalization capabilities. SGD in deep networks constructs a new potential \u03a6 for variational inference, acting as an implicit regularizer. The architecture's gradient noise properties lead to generalization and acceleration, with noise aiding in navigating non-convex losses and training deep networks effectively. The text discusses the importance of noise in deep networks for optimization. It highlights the effectiveness of noise tied to the architecture, such as dropout or small mini-batches, in contrast to external gradient noise. The study also explores gradient diversity and its impact on batch size in distributed optimization, as well as the use of Markov Chain Monte Carlo methods for sampling in negative log-likelihood scenarios. The potential \u03a6 is computed using techniques from physics, showing that simple algorithms like SGLD benefit from acceleration. The continuous-time analysis in the paper reveals general principles governing SGD, which is popular but deep networks are typically trained with discrete-time updates. Closing this gap is a future direction, with SGD converging quickly under typical conditions. The research was supported by various organizations. The authors denote g k as the gradient of a function, and g as the average gradient. They discuss computing a specific formula and show independence between random vectors. The inverse temperature is adjusted, and an indicator variable is defined. The authors introduce an indicator random variable for sampled examples in a batch. They discuss computing a formula involving entropy production and probability current, based on previous works. The rate of entropy increase is derived, ensuring a non-negative term for equilibrium. The Fokker-Planck equation can be expressed in terms of the probability current, showing that the conservative force is only non-zero when detailed balance is broken. The condition \u2207 \u00b7 j(x) = 0 leads to non-negative entropy generation. Jordan, Kinderleherer, and Otto's work is referenced for certain partial properties of the force. Certain partial differential equations can be viewed as arising from a variational principle, performing steepest descent with respect to functionals of their state distribution. The heat equation can be interpreted as steepest descent for the Dirichlet energy functional or as the gradient flow of negative Shannon entropy in the Wasserstein metric. This equivalence allows for the interpretation and modification of the functional that PDEs like the heat equation implicitly minimize. The heat equation describes the probability density of Brownian motion, maximizing entropy and minimizing total-variation. The entropic regularization point-of-view is useful for understanding SGD in machine learning. Three networks are considered on MNIST and CIFAR datasets, including a smaller version of LeNet with batch normalization and dropout. The curr_chunk discusses different network architectures used for training on MNIST and CIFAR datasets, including a fully-connected network with 64 hidden units, a smaller version with 16 hidden units called tiny-fc, and a smaller version of a fully-convolutional network with 12 and 24 output channels. The networks are trained using SGD with appropriate learning rate annealing and Nesterov's momentum. No data augmentation is used, and data is pre-processed using global contrast normalization with ZCA for CIFAR-10. The curr_chunk discusses the evaluation of D(x) using networks with 20,000 weights and architectural intricacies like convolutions, dropout, and batch-normalization. It shows that the KL-divergence is non-negative and reaches its minimum at \u03c1 = \u03c1 ss. The Fokker-Planck equation achieves its steady-state with the first variation BID50 DISPLAYFORM0. The expression in (11) follows after writing log \u03c1 ss = \u2212\u03b2 \u03a6 \u2212 log Z(\u03b2). The text discusses the Fokker-Planck equation under boundary conditions, with a focus on the matrix dot product and covariance matrix. It also explores the operators of the Fokker-Planck operator and their effects on the equation's solutions. The Liouville equation describes the density of a deterministic dynamics, conserving F(\u03c1) and following trajectories under steady-state distribution \u03c1 ss \u221d e \u2212\u03b2 \u03a6. The original SDE is transformed into a new SDE where S and A are parts of G \u22121, leading to \u2207 f (x) = G \u2207\u03a6(x). The modified SDE is expressed as a second-order Langevin system with a velocity variable p, position variable q, and mass m. The Fokker-Planck equation is computed in BID63 to find the steady-state distribution, known as the Klein-Kramer's equation, where position and momentum variables are decoupled. The zero-mass limit is obtained by exploiting the anti-symmetric matrix property of Q. The steady-state distribution in the Fokker-Planck equation is uniquely determined by a Fokker-Planck equation, which is the same as equation (A16). The critical points of \u03a6 differ from the original loss function f by a term involving the anti-symmetric matrix Q."
}