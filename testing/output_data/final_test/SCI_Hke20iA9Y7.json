{
    "title": "Hke20iA9Y7",
    "content": "Learning similarity functions over large corpora using neural network embedding models is a costly process due to the quadratic growth in sample size with corpus size during training. Our approach proposes efficient methods to train neural network embedding models for learning similarity functions without sampling unobserved pairs. By adding a global quadratic penalty and computing the gradient using estimates of Gramians, we achieve significant improvements in training time and generalization performance compared to sampling methods. In natural language processing, x represents a context (e.g. a bag of words), y represents a candidate word, and the target similarity measures the likelihood to observe y in context x. In recommender systems, x represents a user query, y represents a candidate item, and the target similarity is a measure of relevance of item y to query x. Other applications include image similarity and network embedding models. Learning similarity functions involves training an embedding representation of each item to map items with high similarity to close vectors in the embedding space. In natural language processing and recommender systems, learning similarity functions involves training embeddings to map similar items close in the embedding space. Considering unobserved pairs improves embedding quality by adding a repulsive force between all embeddings. This approach is computationally challenging due to the quadratic terms in the corpus size. In this paper, new methods are developed to efficiently estimate the repulsive term in similarity functions without sampling unobserved pairs. The approach is inspired by matrix factorization models and aims to address the computational burden of the repulsive term by optimizing over Gramians. The paper proposes new methods to efficiently estimate the repulsive term in similarity functions without sampling unobserved pairs by optimizing over Gramians, inspired by matrix factorization models. The paper introduces new methods for efficiently estimating the repulsive term in similarity functions by optimizing over Gramians in the non-linear case. These methods maintain stochastic estimates of Gram matrices and use variance reduction schemes to improve accuracy, showing superior scalability compared to traditional sampling approaches on large corpora. The functions u and v map parameter vector \u03b8 and feature vectors x, y to embeddings in R^k. The model output is the dot product of the embeddings. Low-rank matrix factorization is a special case, with linear embedding functions. A non-linear model is illustrated with feed-forward neural networks. The training set T consists of feature vectors x_i, y_i, and target similarity s_i. Notation is made compact with u_i(\u03b8), v_i(\u03b8) representing u(\u03b8, x_i), v(\u03b8, y_i). A low-similarity prior p_ij is assumed for all pairs (i, j). The objective function involves a loss term on observed data and a penalty term on deviations from a prior. Existing methods use sampling to approximate the penalty term, but sampling quality degrades with larger corpora. This issue can be mitigated by increasing sample size, but it is not scalable to very large datasets. The penalty term in the objective function involves the inner product of Gram matrices, which reduces computational complexity compared to the double sum approach. The Gramian formulation has lower complexity due to the smaller dimension of the embedding space. The Gramian formulation has lower computational complexity than the double sum approach, making it core to certain optimization methods. However, it has not been used in training non-linear models due to the challenge of recomputing Gramians. The next section explores leveraging the Gramian formulation in the non-linear case by rewriting the objective function in terms of Gramians. The next section explores leveraging the Gramian formulation in the non-linear case by rewriting the objective function in terms of Gramians. The gradient of g(\u03b8) can be approximated by the gradient of a certain term, which is an unbiased estimate of \u2207g(\u03b8). Different methods for computing Gramian estimates\u011c u ,\u011c v are proposed and their tradeoffs are discussed. The text discusses different methods for estimating Gramians \u011c u ,\u011c v and their tradeoffs. It introduces a method inspired by the stochastic average gradient (SAG) method to reduce variance in gradient estimates. The method involves maintaining a cache of individual gradients to estimate the full gradient. The text introduces a method inspired by the stochastic average gradient (SAG) method to estimate Gramians \u011c u ,\u011c v with reduced variance in gradient estimates. The method involves updating model parameters using SGD and choosing \u03b2 = 1 or \u03b2 = 1/n for trade-offs. Maintaining the Gramian incurs a per-iteration cost. The method introduced updates Gramian estimates with reduced variance in gradient estimates. The per-iteration cost is manageable due to the small embedding dimension k. Memory cost is O(nk), making it less expensive than original SAG(A) methods. However, for very large n, a different method is proposed to avoid prohibitively expensive memory costs. The second method reformulates the problem as a two-player game, where the first player optimizes model parameters and the second player optimizes Gramian estimates. Stochastic first-order dynamics can be applied using Algorithm 2 with SGD and constant learning rate for updates. The updates of the Gramian estimates have a simple form, performing a convex combination between the current estimate and a rank-1 PSD matrix. This ensures the estimates remain in S k + without the need for projection. The per-iteration cost is O(k^2) and memory cost is O(k^2) for storing the Gramians. The method can be interpreted as computing an online estimate of the Gramian by averaging rank-1 terms with decaying weights, known as Stochastic Online Gramian. Averaging reduces variance but introduces bias, with the hyper-parameter \u03b1 balancing bias and variance. The hyper-parameter \u03b1 balances bias and variance in Gramian estimates. Lower \u03b1 values decrease variance but increase bias. Candidate sampling methods can be reinterpreted using the Gramian formulation. The double sum of sampled pairs can be approximated by a transformation, leading to decreased computational complexity in large batch regimes. This method involves computing two batch-estimates of Gramians, which is more cost-effective when the batch size is larger than the embedding dimension. In large batch sizes, SOGram and SAGram have an advantage as they use more embeddings to estimate Gramians. Large-scale experiments on Wikipedia dataset are conducted to learn intra-site links between pages represented by feature vectors. The text discusses the representation of categories in a bag-of-words format for pages on Wikipedia in different languages. Experiments are conducted on subsets of the Wikipedia graph for Simple English, French, and English. Non-linear embedding models are trained using a two-tower neural network structure for source and destination page features. The model uses concatenated embeddings mapped through hidden layers with ReLU activations. Input embeddings are shared between networks with dimensions of 50 for simple, 100 for fr, and 120 for en. Training methods include squared error loss optimization using SAGram, SOGram, and SGD with candidate sampling. Parameters for experiments include learning rate \u03b7 = 0.01, penalty coefficient \u03bb = 10, and batch size 1024. The model parameter update involves sampling baselines and implementing them using the Gramian formulation for efficiency. Different baseline methods are used for sampling, including uniform, linear, and sqrt, each with their own sampling probabilities. The quality of the Gramian estimates is evaluated using each method in the first set of experiments. In an experiment on Wikipedia simple dataset, the estimation error of different methods in tracking true Gramians was evaluated. Both variants of SAGram performed the best, with SOGram also yielding better estimates than the baselines. Importance sampling methods outperformed uniform sampling. Increasing batch size from 128 to 1024 improved estimate quality for all methods. In Appendix E, a formal connection between Gramian and gradient estimation errors is made. The bias-variance tradeoff of SOGram with different learning rates is evaluated in FIG3. Higher learning rates result in higher variance throughout the trajectory, while lower rates reduce variance but introduce bias, especially in early iterations. The impact of Gramian estimation quality on training speed and generalization is compared to sampling baselines on each dataset. SAGram is not used due to memory constraints for large corpus sizes. The models are trained with a fixed time budget for different languages. Mean average precision is estimated every 5 minutes. SOGram shows faster training and better validation performance compared to sampling baselines. Significant improvements are seen on larger corpora. Improvements of 9-15% on fr and 9-19% on en were observed with SOGram using linear importance sampling. SOGram also significantly impacts training speed, taking only a small fraction of the total budget to exceed baseline performance. Additional numerical results in Appendix E evaluate the impact of parameters like batch size and learning rates, showing larger improvements with smaller batches. The Gramian formulation used in training non-linear embedding models improves gradient estimates by applying variance reduction techniques to the Gram matrices. This approach leads to significant impacts on training time and generalization quality, especially for problems with large vocabulary sizes. Future work could explore applying this formulation to other applications such as word-analogy tasks. The text discusses extending the formulation to a larger family of penalty functions and provides a proof for Proposition 3 using conditional expectations and filtration. The text discusses the proof of Proposition 5, showing the first bound (11) and the second inequality using conditional expectations and filtration. In this section, a low-rank matrix prior is introduced for a pair (i, j) represented by the dot product of two vectors. This prior can be obtained by training a simple low-rank matrix approximation of the target similarity matrix. The penalty term is adjusted accordingly, and weighted embedding matrices are defined. The low-rank matrix prior is introduced for a pair (i, j) by defining weighted embedding matrices H u, H v. Updates for H u, H v are added in the generalized versions of SAGram and SOGram algorithms. The matrices are not symmetric, so their estimates are not projected. Algorithm 3, SAGram with low-rank prior, includes an initialization phase for training data and low-rank priors. The low-rank matrix prior is utilized in Algorithm 4, SOGram with low-rank prior, to update weighted embedding estimates and model parameters. It also discusses adapting algorithms for non-uniform weights in the penalty term. The weight matrix in the context of non-uniform weights is discussed, specifically focusing on the case of a rank-one weight matrix. The weight matrix is described as the sum of a sparse and low-rank matrix to provide a concise representation. The weight matrix is described as the sum of a sparse and low-rank matrix. SAGram and SOGram can be generalized to this case, where the sparse part is optimized explicitly and the low-rank part is optimized using weighted Gramians. Different interpretations of the Gramian inner-product g(\u03b8) are discussed, with the gradient of g(\u03b8) moving u i away from regions of the embedding space with high values. The negative gradient moves embeddings away from high-density regions to prevent dissimilar items from being placed close together in the embedding space. Visualizations show how the distribution of inner products changes with increasing t, with observed pairs remaining close to 1. The distribution of inner products changes with different values of \u03bb, affecting the model's ability to place embeddings of unrelated items near each other. Lower \u03bb values result in a flatter distribution, while higher values lead to over-regularization and decreased performance. The authors introduce Global Orthogonal Regularization as a method to spread out embeddings for better generalization. They propose matching the second moment of each embedding distribution with that of the uniform distribution using a penalty term. This method can be optimized using candidate sampling and Gramian transformations. The authors introduce Global Orthogonal Regularization to improve generalization by matching the second moment of each embedding distribution with that of the uniform distribution. This method does not require the model output to be the dot-product of two embedding functions. Experimental results show better estimates of Gramians, with a close relationship between gradient estimation quality and Gramian error. The authors introduce Global Orthogonal Regularization to improve generalization by matching the second moment of each embedding distribution with that of the uniform distribution. Experimental results show better estimates of Gramians, with a close relationship between gradient estimation quality and Gramian error. Comparing different baselines methods, uniform sampling performs better than sqrt despite having a worse Gramian estimate. The sampling distribution affects both the quality of the Gramian estimates and the frequency at which item embeddings are updated, impacting the MAP. Additionally, the effect of the Gramian learning rate \u03b1 on the quality of Gramian estimates and generalization performance is evaluated. The study evaluates the impact of the Gramian learning rate \u03b1 on the quality of Gramian estimates and generalization performance. Lower \u03b1 leads to slower progress initially but better final performance, influenced by the bias-variance tradeoff. Approximating Gramians due to large vocabulary size shows similar results to simpler experiments, with estimation error decreasing as training progresses. The study explores the impact of learning rate \u03b7 on Gramian estimates and performance. Lower \u03b7 results in faster error decay, affecting the bias-variance tradeoff. Experimenting with different hyperparameters, the final validation MAP is reported for batch sizes 128 and 512. The final validation MAP in TAB6 for batch sizes 128 and 512 shows that SOGram with learning rate \u03b1 = 0.001 consistently performs the best. Smaller batch sizes result in a larger relative improvement compared to the baseline. The performance is more robust to batch size and learning rate choices with SOGram methods compared to the baseline on a regression task using the MovieLens dataset. The MovieLens dataset contains movie ratings from users, split into training and validation sets. The dataset has 72K users, 10K movies, and 10M ratings. A two-tower neural network model is trained with input layers, hidden layers, and output embedding dimension k=35. The left tower uses a one-hot encoding of a user id, while the right tower uses one-hot encodings of a movie id, release year, and genres. The model is trained using a squared loss with different values of \u03b1 and sampling as a baseline. Results show that SOGram with \u03b1 = 0.1 achieved the best validation mean average precision, despite its poor performance on the training set. This indicates that better estimation of g(\u03b8) leads to better regularization. Better estimation of g(\u03b8) leads to improved regularization and training speed. SOGram with \u03b1 = 0.1 outperforms the sampling baseline in validation performance in under 1 hour compared to 6 hours."
}