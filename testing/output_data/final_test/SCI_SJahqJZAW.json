{
    "title": "SJahqJZAW",
    "content": "Training generative adversarial networks in high dimensions is unstable due to the data distribution being concentrated in a small fraction of the space. To address this issue, the proposal is to train a single generator against multiple discriminators, each looking at a different low-dimensional projection of the data. This approach ensures that the generator receives meaningful gradients throughout training, leading to better sample generation. Generative adversarial networks (GANs) enable neural networks to generate high-quality image samples by training a generator against a discriminator. The generator produces samples from a target distribution using a noise vector, while the discriminator differentiates real data from generated data through adversarial training. This approach improves sample quality compared to traditional training with a single discriminator. Generative adversarial networks (GANs) can produce realistic data samples and model ambiguity in regression tasks. Conditional GANs are useful for tasks like in-painting and super-resolution. GANs can also be used for unsupervised learning by generating mappings between different domains. Training GANs to generate high-dimensional data like large images is challenging due to the generator's tendency to diverge and collapse modes. To address this, researchers propose training a single generator against multiple discriminators, each receiving lower-dimensional projections as input. This approach provides stable gradients to the generator throughout training. The approach of training a single generator against an array of discriminators, each looking at different low-dimensional projections of the data, aims to provide stable gradients and address the instability in GAN training. Various techniques such as explicit factorization of tasks, specific architecture choices, and additional supervision have been proposed to improve the quality of generated samples. The approach involves training a generator against multiple discriminators, each viewing different low-dimensional projections of the data. This method aims to provide stable gradients and improve the quality of generated samples in GAN training. Researchers have found this approach to be surprisingly effective in practice, producing higher-quality samples compared to generators trained against a single discriminator. Researchers have explored various approaches to enhance the stability of GANs for training on higher dimensional images. Energy based GAN and Wasserstein GAN show improvements by optimizing different distances and regularizing the discriminator. Other methods such as modifying the objective function and semi-supervised learning have also been proposed to improve training stability. These methods aim to improve gradient quality and provide additional supervision to the generator. In our framework, each discriminator is trained on a low-dimensional projection of the data to prevent perfect rejection of generated samples. We do not directly combine discriminator outputs but compute losses individually and average them. This approach draws from the idea of combining simple classifiers, benefiting from regularization effects. In our framework, we aim to maintain a flow of gradients from individual discriminators to the generator in high dimensions for stable GAN training. GANs traditionally consist of a generator G that learns to generate samples from a data distribution P x through adversarial training against a single discriminator D. The optimization is carried out using stochastic gradient descent with alternating updates. Training GANs involves using stochastic gradient descent (SGD) with alternating updates to the generator and discriminator. Instability is common, especially with high-dimensional data. The goal is for the generator to match the data distribution perfectly, but in practice, the discriminator often dominates, leading to deteriorating generator quality. Training must be stopped early to prevent this. The instability in training GANs is due to limited support in natural data distributions, making it hard for the generator to learn quickly. To address this, a single generator can be trained against multiple discriminators operating on different low-dimensional linear projections. To address the instability in training GANs, a single generator can be trained against multiple discriminators operating on different low-dimensional linear projections. Each discriminator aims to maximize accuracy in detecting generated samples from its own projection, while the generator aims to fool all discriminators simultaneously. This approach is effective when dealing with images, requiring both the generator and discriminator to have convolutional architectures. In order to improve the stability of training GANs, convolutional architectures are preferred for discriminators. Projection matrices are chosen to create \"image-like\" data using strided convolutions with random filters. Filter sizes larger than the stride are used to promote mixing of input coordinates. This approach aims to enhance training stability while maintaining consistency. Our approach aims to improve training stability in GANs by using low-dimensional projections for each discriminator Dk. This allows for meaningful gradients to the generator, while maintaining consistency in the training process. Our approach improves training stability in GANs by using low-dimensional projections for each discriminator Dk, enabling meaningful gradients to the generator while maintaining consistency in training. The modified version of Theorem 1 in BID12 is considered, showing the optimal {Dk} for fixed G. Training stability is illustrated through the evolution of generator loss against a single discriminator (DC-GAN) and multiple discriminators (K = 48). Our approach improves training stability in GANs by using low-dimensional projections for each discriminator Dk, enabling meaningful gradients to the generator while maintaining consistency in training. The discriminator saturates to rejecting generated samples with high confidence, but our approach keeps the loss lower, providing meaningful gradients to the generator. The generator quickly improves sample quality throughout training, unlike traditional settings where quality deteriorates. Each discriminator adds a constraint on the generator to match different marginals of the true distribution. Our approach improves training stability in GANs by using low-dimensional projections for each discriminator Dk. By matching a high number of marginals, the generator learns to match the full joint distribution of real data in Rd. Experiments show higher stability during training and higher quality samples compared to traditional methods. The dataset used is celebrity faces collected by BID17. The study uses a dataset of celebrity faces collected by BID17 and DC-GAN architectures for the generator and discriminator. Two modifications to the DC-GAN implementation improve results, including using different batches of generated samples. The generator produces better quality samples with finer detail and fewer distortions, especially when trained with higher projections. The study improves DC-GAN results by training the generator with higher projections, resulting in better quality samples with fewer distortions. Batch normalization is used in the generator but not in the discriminator, and a new approach involves training a generator against multiple discriminators operating on single-channel 32 \u00d7 32 projected images. The study enhances DC-GAN results by training the generator with higher projections for better quality samples. Batch normalization is used in the generator, and a new approach involves training a generator against multiple discriminators operating on single-channel 32 \u00d7 32 projected images. The architecture of the generator and discriminator is similar, with the discriminator in the lower resolution setting having one less layer. Generator gradients are computed using Adam with specific parameters, and stability during training is analyzed. The study improves DC-GAN results by training the generator with higher projections for better quality samples. It compares the generator training loss between traditional DC-GAN with a single discriminator and the proposed framework with 48 discriminators. The generator losses increase through training after decreasing initially, with DC-GAN's loss remaining higher than the proposed framework. Samples generated show smooth interpolation between various facial attributes. The study compares traditional DC-GAN with a single discriminator to a framework with 48 discriminators. The generator in the proposed framework continually improves throughout training, producing higher-quality samples than DC-GAN. The framework shows consistency in learning the data distribution quickly and generating better samples even in early iterations. Our approach with 48 discriminators produces higher-quality face images with fewer distortions compared to traditional DC-GAN. Varying the number of discriminators affects sample quality, with a projection ratio of 12 leading to subtle high-frequency noise in generator samples. Increasing the number of discriminators improves sample quality but also increases training time significantly. For example, using 48 discriminators results in high-quality samples but requires 11.2s per training iteration, compared to 0.6s for a traditional DC-GAN with a single discriminator. Once trained, all generators produce samples at the same speed. The latent space embedding quality is explored by generating samples through linear interpolation between noise vectors. The generator in the study is shown to smoothly interpolate between semantically meaningful face attributes like gender, age, and expression. Results on training a generator on a subset of the Imagenet-1K database with canine images are also presented. The generator in the study uses a higher 200-dimensional noise vector and a larger feature vector to create 128x128 resolution images. 12 discriminators are used with additional layers for higher resolution. The generated images are sharp but not globally plausible photographs. In this paper, a new framework for training GANs for high-dimensional outputs is proposed. Multiple discriminators on random low-dimensional projections of the data are used to stabilize training, ensuring the generator learns the true data distribution. This approach leads to more stable training and higher-quality samples. Future work will explore training with a larger set of discriminators. In this section, the benefits of using multiple discriminators with modified objectives in GAN training are discussed. The theoretical results show that random projections can improve stability and ensure consistency of training. The assumptions made on the distribution of x help understand how a random low-dimensional projection affects the volume of the distribution's support. Theorem A.1 states that for a mixture of Gaussians with well-separated components, the projection of the support occupies a higher fraction of the volume of the range projection, aiding in stability during GAN training. Theorem A.1 shows that for well-separated Gaussian mixtures, the projected support occupies a higher volume fraction, enhancing stability in GAN training. The projection of the support overlaps with supp(P x ) and is not rejected by the discriminator. The columns of the projection matrix W can be assumed to be orthonormal, leading to a square invertible matrix A transforming W to W \u2032, which is orthonormal. For individual Gaussian distribution P x = N (x|\u00b5, \u03a3), the ratio of supports with respect to a threshold \u01eb does not decrease with projection. The volume ratio of a single Gaussian increases with small \u01eb. The volume ratio of a single Gaussian increases with projection if det(W T \u03a3W) > det(\u03a3). When all eigenvalues are strictly positive, the volume ratio either stays the same or increases. A coordinate transform is considered where det(\u03a3 W \u2032) < 1, showing the volume ratio enhancement. The volume ratio of a Gaussian mixture increases with projection, as shown by the proof of Theorem 3.1. The support volume ratio of PWTx is strictly greater than that of Px, with at least one term being strictly greater in the mixture distribution. The proof of Theorem 3.1 in BID12 shows that the volume ratio of PWTx is strictly greater than that of Px. By setting a point y in the support of Dk to 0, we can rewrite V(Dk, G) using Kullback Leibler divergence. With enough random projections K, the distribution P g of generated samples will closely match the true distribution Px. Theorem A.2 states that for compact distributions P x and P g with support radius B, the residual function R = Px - Pg will have a Lipschitz constant L R with high probability. Theorem A.2 states that the residual function R = Px - Pg will have a Lipschitz constant L R with high probability, capturing how much two probability densities can differ if they match along K marginals of dimension m. The error decays with increasing number of discriminators K, suggesting that the residual can take larger values if it is not smooth, impacting the error between the true and generator distribution. The residual function R captures the difference between two distributions, satisfying certain properties. The proof shows that for discrete distributions, if R is Lipschitz, the error between the true and generator distribution decreases. The residual function R captures the difference between two distributions, showing that the error decreases if R is Lipschitz. The distributionsP W T k x andP W T k g are equal up to an additive factor of \u01eb on the \u01eb-net, with |R(x)| \u2264 O(\u01eb) for any x."
}