{
    "title": "B1g-SnUaUN",
    "content": "We propose a study on the stability of few-shot learning algorithms by varying hyper-parameters and optimization schemes while controlling the random seed. The methodology involves testing for statistical differences in model performances across replications. Results from three papers, Matching Nets, Prototypical Networks, and TADAM, are analyzed on the miniImagenet dataset in a 5-ways, 5-shots learning setting. The selected implementations show stability across random seed and repeats. The model captures variations in the data with random effects Zb, representing individual deviations from group-level fixed effects. The model includes an intercept A, parameters vector \u03b2, and one hot vector Experiment i. Random effects alpha 0j and alpha 1k are associated with observations from random seeds and repeats. Nuisance parameters are regrouped in seeds for implementation, except for differences due to parallelism on CPU and GPU. The trend of large-scale compute-intensive ML experiments has raised concerns in the community regarding the use of random number generators and data generation processes. Some implementations involve calling a random number generator before generating episodes data, leading to changes in the generator's state. Others generate data in advance or on the fly for each episode, resulting in different states of the random number generator being involved in the process. Training may also start at different states of the random number generator, affecting the sequences of random numbers used."
}