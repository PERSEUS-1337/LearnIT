{
    "title": "BklhsgSFvB",
    "content": "Multi-task learning is successful in modeling related tasks with labeled datasets, improving performance significantly. Existing works assume tasks are related, limiting real-world applications. A novel framework, Learning To Transfer Via Modelling Multi-level Task Dependency, constructs attention-based relationships among tasks to guide knowledge transfer and improve model performance. The effectiveness of multi-task learning in improving model performance is demonstrated through experiments on public datasets. Various multi-task learning mechanisms have been proposed and proven successful in different fields, such as natural language processing, computer vision, and chemical study. Despite its success, applying multi-task learning to discrete data like graphs and text remains a challenge. When applying multi-task learning to discrete data like graphs and text, current frameworks often assume a general task dependency that may not hold true in real-world problems. Different data samples and sub-structures within a sample can have varying task dependencies, requiring a more nuanced approach to leverage task-specific information effectively. In this work, a novel framework called 'Learning to Transfer via ModellIng mulTi-level Task dEpeNdency' (L2T-MITTEN) is proposed to accurately learn task dependency at both general and data-specific levels. The framework utilizes a parameterized weighted dependency graph for general task dependency and a position-wise mutual attention mechanism for data-specific task dependency. By iteratively enhancing task performance and extracting high-quality dependency structures, the framework can reveal hidden knowledge in datasets. The novel framework 'Learning to Transfer via ModellIng mulTi-level Task dEpeNdency' (L2T-MITTEN) aims to learn task dependency at general and data-specific levels. It introduces a universal representation space to reduce space complexity and outperforms other multi-task methods in tasks like graph classification, node classification, and text classification. Additionally, L2T-MITTEN can extract interpretable task dependency structures from real-world datasets. The work introduces a novel multi-task learning framework to learn general and data-specific task dependencies, reducing space complexity and showing effectiveness on real-world datasets. Existing multi-task learning methods can be categorized by hard or soft parameter sharing. The parameter sharing in the bottom network reduces the parameters needed for learning, preventing overfitting. However, shared-bottom layers may face optimization conflicts with unrelated tasks. Adjusting task weights dynamically during training can help alleviate this issue. Sener & Koltun (2018) and Dy & Krause (2018) propose optimization methods for multi-task learning. Guo & Farooq (2018) suggest using Mixture-of-Experts to combine different experts for task dependencies. Soft parameter sharing models (Lon, 2015; Ish, 2016; Dai et al., 2015; Yan, 2017) focus on task-specific parameters to reduce annotation effort. In (2015), efforts are made to reduce annotation requirements for dependency parser trees by combining networks with L2 normalization. Ish (2016) introduces a Cross-Stitch model for task-specific representations, while Yan (2017) uses tensor factorization to share common knowledge across network layers. Recent works have explored parameter sharing in deep learning networks to capture task dependency. Zamir et al. (2018) compute an affinity matrix among tasks, Lan et al. (2017) use a sigmoid gated interaction module, and Liu et al. (2018) utilize a shared network with an attention mechanism to determine feature importance. Our framework L2T-MITTEN aims to learn task dependency at both general and data-specific levels, assembling multi-task representations from different task-specific encoders. Multi-task learning involves training models for multiple tasks with shared parameters to improve overall performance by sharing information among related tasks. The overall architecture of our multi-task learning framework (L2T-MITTEN) involves transferring task-specific representations among different tasks using Task-specific Encoders, Transfer Block, and Readout Block components. Unlike hard parameter sharing methods, our framework keeps each feature encoder separate to efficiently extract task-specific knowledge. The L2T-MITTEN framework involves transferring task-specific representations among different tasks using Task-specific Encoders, Transfer Block, and Readout Block components. The Transfer Block transfers task-specific representations from source to target tasks using a transfer function for each task pair. The Readout Block consists of separate readout modules for specific data. Detailed architecture for different tasks can be found in Appendix B. The L2T-MITTEN framework involves transferring task-specific representations among different tasks using a universal representation space to reduce the number of transfer functions needed. By decomposing the transfer function, the space complexity is reduced from O(T^2) to O(T), allowing for efficient transfer of representations between tasks. The Transfer Block assembles transferred representations with multi-level task dependency using a position-wise mutual attention mechanism. A parameterized weighted dependency graph models the general task dependency, reducing the negative influence of irrelevant tasks. Transferable weights between task pairs are learned to optimize transfer efficiency. The Transfer Block utilizes a position-wise mutual attention mechanism to model data-specific task dependency efficiently. It considers mutual attention between representations of the same data sample under different tasks, using query and key projection matrices to calculate position-wise mutual attention. The Hadamard product is used instead of matrix multiplication to allow sub-structures in a data sample to interact with counterparts under other tasks. The Transfer Block uses a position-wise mutual attention mechanism to model data-specific task dependency efficiently. It calculates mutual attention between representations of the same data sample under different tasks using query and key projection matrices. The final assembled representation is obtained by scaling data-specific task dependency with general task dependency and calculating the weighted sum of transferred representations based on multi-level task dependency. Our proposed L2T-MITTEN approach is evaluated against classical and SOTA methods in graph and text domains. We use multitask GCN for graph-level and node-level classification, and RNN for text classification. Visualization and analysis on hidden dependency structure are provided. Codes and datasets will be released. For graph-level classification, Tox21 and SIDER datasets are used. Tox21 measures toxicity of chemical compounds on 12 different targets, while SIDER is a Side Effect Resource dataset. The SIDER dataset contains qualitative drug side-effects measurements for 1427 drugs on 27 side-effects. Each drug is treated as a graph for predicting if it induces a side effect. DBLP and BlogCatalog datasets are used for node-level classification, where authors are represented by nodes linked if they co-authored papers. The BlogCatalog dataset consists of bloggers represented as nodes with links between friends and categorized interests. TMDb dataset includes information on 4803 movies with plots as input and genres as labels for text classification tasks. The L2T-MITTEN approach is compared with classical and SOTA approaches for text-level classification tasks. Single-task method involves training a network for each task separately. Classical multi-task methods include Shared-Bottom and Cross-Stitch frameworks for learning shared and task-specific representations. The \"cross-stitch\" unit uses a k \u00d7 k trainable matrix to transfer and fuse representation among tasks. MMoE adopts a Multi-gate Mixture-of-Expert structure with bottom networks and gating networks. All baseline models share the same encoder and readout block for each task. The datasets are partitioned into training/testing sets and evaluated under different settings. Models are trained using the ADAM optimizer for 100 epochs. Results show that multi-task methods outperform single-task methods, with the proposed L2T-MITTEN approach performing well compared to classical and SOTA methods. Our proposed L2T-MITTEN approach outperforms classical and SOTA methods in most tasks, especially under deficient labeled training data settings. It leverages the data structure to guide task transfer. In real-world datasets like DBLP, our model significantly outperforms other methods, highlighting the importance of considering multi-level dependencies. Single-Task achieves the second-best result, indicating task irrelevance in some datasets. Our multi-level task dependency is effective in preventing irrelevant task influence. Experiments on the TMDb text classification dataset show our approach achieving the best results. Our directed task dependency graph effectively prevents negative knowledge transfer among tasks with few labels. Visualization of the learned multi-level task dependency structure using DBLP as an example shows conferences from the same domain are likely to be in the same sub-tree. Authors form clusters based on the learned data-specific task dependency matrix. Our approach, L2T-MITTEN, utilizes a positionwise mutual attention mechanism to capture task dependency at multiple levels. It transfers task-specific representations efficiently and guides inference based on the learned task dependency. Experimental settings include scenarios with sufficient, imbalanced, or deficient training data. Our method, L2T-MITTEN, uses a positionwise mutual attention mechanism to capture task dependency at multiple levels. Experimental results show its superiority over classical and SOTA baselines. The framework can extract task dependency structures and reveal hidden knowledge of tasks and datasets. The architecture includes graph convolutional layers in the Encoder Block and set-to-set global pooling for graph-level tasks in the Readout Block. The text model utilizes LSTM architecture in the Encoder Block and dot-product attention in the Readout Block to obtain text-level representation for classification. The attention mechanism calculates attention weights for each word to generate the text-level representation."
}