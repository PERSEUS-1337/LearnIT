{
    "title": "BJzmzn0ctX",
    "content": "Reasoning over text and Knowledge Bases (KBs) is a challenge for Artificial Intelligence, with applications in machine reading, dialogue, and question answering. Neural Theorem Provers (NTPs) address issues in transducing text to logical forms by using a continuous relaxation of Prolog\u2019s backward chaining algorithm. Neighbourhood-approximated Neural Theorem Provers (NaNTPs) are proposed as extensions to NTPs. Neural Theorem Provers (NaNTPs) are extensions to NTPs that reduce time and space complexity, improve rule learning with an attention mechanism, and enable reasoning over KB facts and textual mentions. NaNTPs perform similarly to NTPs but at a lower cost, achieving competitive results on large-scale datasets like WN18, WN18RR, and FB15k-237 while providing explanations for predictions and extracting interpretable rules. The main focus in Artificial Intelligence is building systems that exhibit intelligent behavior, particularly in Natural Language Understanding (NLU) and Machine Reading (MR) to extract meaningful knowledge from text and actively reason with it. This enables the synthesis of new knowledge and the ability to verify and update assertions through automated reasoning using Natural Language Processing (NLP) tools. Automated reasoning in text requires NLP tools to extract knowledge and compile it into KBs. However, compiled KBs are often incomplete and noisy, hindering deductive reasoning. NaNTPs architecture includes a faster inference mechanism and dedicated encoders for KB facts and text. Previous MR literature has addressed this issue using various frameworks, but methods like Natural Logic and Semantic Parsing have limitations. Combining neural models and symbolic reasoning can overcome limitations in automated reasoning. Neural models require significant annotated data but struggle to generalize without enough training data. Symbolic models can generalize well with few examples but are brittle in noisy or ambiguous situations. The combination of both can leverage their strengths and weaknesses for more accurate predictions. Recent work in neuro-symbolic systems has made progress in learning neural representations that allow for comparison of symbols based on semantics, maintaining interpretability and generalization. Neural models are robust to noise and ambiguity but prone to overfitting and lack interpretability, while symbolic models struggle in noisy or ambiguous situations. Neuro-symbolic systems, like NTPs, combine the strengths of both approaches by using differentiable deductive reasoning based on Prolog's backward chaining algorithm. This paper proposes an efficient method to reduce the time and space complexity of Neural Theorem Provers (NTPs) for reasoning over large knowledge bases and natural language corpora. NTPs allow learning interpretable rules and provide explanations for reasoning outcomes. The paper proposes a method to reduce the time and space complexity of Neural Theorem Provers (NTPs) by using an attention mechanism and embedding predicates and textual patterns in a shared space. NTPs recursively build a neural network to enumerate proof states for proving a goal over the knowledge base, relying on the Unification, OR, and AND modules. The Unification Module in Neural Theorem Provers (NTPs) matches atoms by comparing their embeddings with a similarity function, enabling matching symbols with similar semantics. The unify \u03b8 (H, G, S) operator creates a neural network module that compares embedding representations with a Radial Basis Function (RBF) kernel. The Unification Module in Neural Theorem Provers (NTPs) uses a Radial Basis Function (RBF) kernel to update variable bindings and calculate proof scores. The resulting proof state is expanded with the and module, which recursively proves sub-goals for a rule body by substituting variables with constants and invoking the or module. The Unification Module in Neural Theorem Provers (NTPs) uses a Radial Basis Function (RBF) kernel to update variable bindings and calculate proof scores. The resulting proof state is expanded with the and module, which recursively proves sub-goals for a rule body by substituting variables with constants and invoking the or module. NTPs select the proof path with the maximum proof score by training embeddings of predicates and constants through cross-entropy loss optimization. Negative examples are sampled from positive ones by corrupting entities. NTPs can also learn interpretable rules from data. The Unification Module in Neural Theorem Provers (NTPs) uses a Radial Basis Function (RBF) kernel to update variable bindings and calculate proof scores. In Section 2, deductive reasoning is discussed, focusing on finding the fact in a knowledge base (KB) that yields the maximum unification score with a given query. The computational bottleneck lies in the or operator when dealing with large KBs like Freebase and Google Knowledge Graph. The unification score is determined by the similarity of representations in a Euclidean space using embeddings. The Unification Module in Neural Theorem Provers (NTPs) uses a Radial Basis Function (RBF) kernel to update variable bindings and calculate proof scores. The computational bottleneck arises when computing the similarity between the goal G and every fact F in the knowledge base (KB), which is computationally prohibitive. The paper proposes a method to exactly compute the most similar fact F in the KB to the goal G by considering a subset of proof scores containing the largest one. The paper proposes a method to restrict the search for the most similar fact F in the knowledge base (KB) to a local neighborhood of the goal G, reducing the number of comparisons needed for computing the final proof score. This idea can also be extended to rules by selecting only rules where the head is closer to the goal. However, finding the exact neighborhood in a Euclidean space is costly due to the curse of dimensionality. In this work, the Hierarchical Navigable Small World (HNSW) graph-based incremental ANNS structure is used for identifying the neighborhood of a goal in high dimensional data. The HNSW graph offers better logarithmic complexity scaling during neighborhood search compared to other approaches. In this work, the HNSW graph-based incremental ANNS structure is used for identifying the neighborhood of a goal in high dimensional data with O(log |P|) time complexity. The model constructs the HNSW graph-based indexing structure during instantiation and updates the index every b batches during training. The or operator is redefined to constrain unification with ANNS to only facts and rule heads in the local neighborhood N K (G). The proposed method introduces an attention mechanism for efficient parameter learning in models with a large number of parameters. By using trainable attention weights, the model can improve parameter efficiency by introducing fewer parameters for each rule. This approach allows for joint reasoning over knowledge bases and natural language corpora using NaNTPs. In this section, we demonstrate the use of NaNTPs for joint reasoning over knowledge bases (KBs) and natural language corpora. The KB K consists of facts, rules, and mentions, where a fact includes a predicate symbol and arguments. Mentions are textual patterns linking entities in the KB. These mentions are represented alongside facts and rules in K by treating each textual pattern as a new predicate and embedding it in a d-dimensional space. For example, a sentence like \"United Kingdom borders with Ireland\" is translated into a mention in K. The encode \u03b8 module encodes textual surface patterns by mapping tokens to a k-dimensional embedding space. It uses a token embedding matrix to create a pattern matrix, which is then processed by an end-to-end differentiable encoder to produce a textual surface pattern embedding vector \u03b8 t. The encoder encodes textual surface patterns using token embedding vectors. Differentiable architectures like RNNs can be used, but a simple averaging model is chosen for efficiency. Research aims to enhance neural network architectures with external memory to improve generalization and reasoning abilities. Improving neural network generalization and extrapolation abilities involves designing architectures capable of learning reusable programs and using enriched supervision signals like program traces. Differentiable interpreters compile declarative or procedural knowledge into neural network architectures, allowing for strong inductive biases. However, a major issue with differentiable interpreters is their limitations. This work explores the computational complexity of differentiable interpreters and their limitations for larger-scale learning problems. It is related to previous works on sparsifying read operations in memory networks and jointly embedding KB facts and textual mentions. Additionally, it is connected to path encoding models and rule induction approaches for knowledge base completion. Experiments on benchmark datasets like Countries are reported. The study reports experiments on benchmark datasets such as Countries, Nations, UMLS, and Kinship, following the same evaluation protocols. Results are also reported on larger datasets like WN18, WN18RR, and FB15k-237. The natural language reading component is evaluated using FB15k-237.E dataset. Baselines include comparisons with NTPs, DistMult, and ComplEx for identifying missing facts in knowledge bases. Neural Link Predictors are used to identify missing facts in large knowledge bases like WordNet and FreeBase. DistMult and ComplEx compute likelihoods of facts by embedding entities and relation types in a d-dimensional space. The scoring function is based on these embeddings and is learned by minimizing a KB reconstruction error. The model's complexity for scoring a triple is O(log |K|) instead of O(1) like in DistMult and ComplEx. Hyperparameters like embedding size and training epochs are fixed for evaluation on NaNTPs. Neural Link Predictors (NaNTPs) were evaluated by training ComplEx and DistMult with fixed hyperparameters. Experiments on the Countries dataset showed that encoding mentions using an encoder yielded better AUC-PR values than simply adding them to the knowledge base. Evaluation performance of NaNTP and NTP was compared on benchmark datasets to verify correctness of the approximation. Results from benchmark datasets show that NaNTP outperforms NTP consistently. NaNTP's run-time performance is compared to NTP in terms of time and memory during training, with varying ANNS approximation values to assess computational demands. The results demonstrate that NaNTP is significantly more time and memory efficient compared to NTP, with speedups of an order of magnitude for smaller datasets and more than two orders of magnitude for larger datasets. NaNTP consistently achieves higher speedups with increased dataset size and is more memory efficient, making it applicable to larger datasets even with textual surface forms. The study evaluated different strategies for integrating textual surface patterns in NTPs by replacing training set triples with human-generated textual mentions. Two ways of integrating mentions were evaluated: adding them as facts to the KB or parsing them with an encoder. Results showed that the proposed encoding module consistently improved ranking accuracy compared to simply adding mentions as facts, especially when a large number of facts were missing. The study evaluated strategies for integrating textual surface patterns in NTPs by replacing training set triples with human-generated mentions. NaNTPs efficiently learn rules involving logic atoms and textual mentions, providing human-readable explanations for predictions. Link prediction results show NaNTPs' capability to learn rules by analyzing proof paths. NaNTPs can learn rules like has_part(X, Y) :- part_of(Y, X) and hyponym(X, Y) :- hypernym(Y, X). It can provide alternative explanations based on entity representations, such as explaining CONGO is part of AFRICA by leveraging similarity. Using attention for rule learning improves NaNTP's accuracy on benchmark datasets and WordNet. Using attention for rule learning improves ranking accuracy on benchmark datasets and WordNet. For example, Hits@10 increases from 83.2% to 93.7% in WN18 and from 25% to 43.2% in WN18RR. This shows that Neural Link Predictors still have lower Hits@10 than 95% on WN18, indicating that WN18 results are comparable to other models. Using attention for rule learning improves ranking accuracy on benchmark datasets and WordNet. MRR increases significantly in WN18 and WN18RR due to attention reducing the number of parameters required. However, attention did not improve ranking accuracy in FB15k-237 due to the dataset's high relational nature. NTPs combine rule-based and neural models but struggle with reasoning over large KBs and natural language. This paper proposes NaNTPs to address this limitation. In this paper, NaNTPs are introduced as a solution to scaling issues of NTPs by utilizing ANNS and attention. NaNTPs offer significant speedups and memory efficiency while maintaining predictive accuracy. They can be applied to mixed KB and natural language data by embedding logic atoms and textual mentions in a joint space. Although slightly lower in performance compared to Neural Link Predictors on large datasets, NaNTPs are interpretable and provide explanations for their reasoning at scale. In this paper, NaNTPs are introduced as a solution to scaling issues of NTPs by utilizing ANNS and attention. NaNTPs offer significant speedups and memory efficiency while maintaining predictive accuracy. They can be applied to mixed KB and natural language data by embedding logic atoms and textual mentions in a joint space. The modules constituting NTPs involve backward chaining and discrete unification, with a focus on comparing embedding representations for symbol matching. The unify operator updates a substitution set S and creates a neural network for comparing vector representations. The unify operator updates a substitution set S and creates a neural network for comparing vector representations of non-variable symbols in two sequences of terms. It takes two atoms represented as lists of terms and an upstream proof state, returning a new proof state S. The unify operator updates a substitution set S by comparing vector representations of non-variable symbols in two sequences of terms. It takes two atoms represented as lists of terms and an upstream proof state, returning a new proof state S. The or module unifies a goal with all facts and rules in a knowledge base, attempting to prove the atoms in the body of a rule by invoking the and module. The and module recursively proves sub-goals in the body of a rule by using the or module. It has a signature L \u00d7 N \u00d7 S \u2192 S N, where L is the domain of lists of atoms, and N is the number of possible output proof states. The module is implemented as DISPLAYFORM0 with an auxiliary function substitute for applying substitutions to variables in an atom. Recursion is defined in line 3, where the first sub-goal is proven by instantiating an or module and using resulting proof states to prove remaining sub-goals with an and module. NTPs define the success score of proving a goal using a KB with parameters \u03b8 as: ntp DISPLAYFORM0, with d as the maximum proof depth and an initial proof state of (\u2205, 1) denoting an empty substitution. The model is trained using Leave-One-Out cross-entropy loss, generating positive and negative examples by corrupting positive ones. Experiments are conducted on datasets like Countries, testing reasoning capabilities of neural link prediction models. The dataset includes 244 countries, 5 regions, 23 sub-regions, and 1158 facts about country neighborhoods and locations. Results are reported in terms of AUC-PR, MRR, and HITS@m. The dataset includes 244 countries, split into training, validation, and test sets. Three task datasets are created (S1, S2, S3) to predict locatedIn(c, r) for test countries and regions. Training atoms in the KB vary for each task. The dataset includes 244 countries split into training, validation, and test sets. Three task datasets (S1, S2, S3) are created to predict locatedIn(c, r) for test countries and regions. Training atoms in the KB vary for each task. In S1, ground atoms locatedIn(c, r) are removed for test countries, but sub-region information can still be inferred using transitivity rules. In S2, ground atoms locatedIn(c, s) are removed, and country locations in the test set need to be inferred from neighboring countries. Additionally, in S2, ground atoms locatedIn(c, r) are removed for countries from the training set that have neighbors in the validation or test sets. The dataset consists of 244 countries split into training, validation, and test sets. Three task datasets (S1, S2, S3) are created to predict locatedIn(c, r) for test countries and regions. Training atoms in the KB vary for each task, with mentions outlined in Table 4. UMLS and Nations datasets are also considered. Each dataset is split into training, development, and test facts, with an 80%/10%/10% ratio. Evaluation involves corrupting test facts' arguments in all possible ways to generate new facts not in the original KB. The dataset includes countries split into training, validation, and test sets. Various task datasets are created to predict relationships for test countries and regions. The impact of using mentions is evaluated using different datasets like WordNet and FB15k-237.E. The FB15k-237.E dataset is augmented with textual relations extracted from the ClueWeb12 corpus and Freebase mention annotations. After pruning, there are 2.7 million unique textual relations added to the KB. The dataset's basic statistics are provided in TAB4, and ablation studies on the impact of attention are quantified in TAB5 and TAB6. The impact of using ANNS as a heuristic was analyzed through additional experiments on baseline datasets. ANNS was compared to exact nearest neighbors search and random neighbor selection, with results outlined in TAB7. Random neighbor selection yielded worse ranking results compared to ANNS, except for Nations where results were unexpectedly higher possibly due to the small number of entities. ANNS is a better choice than random neighbor selection for heuristic, as it provides close ranking results to Exact NNS but is much faster. Limiting the neighborhood size to k=1 due to the high computational demand of Exact NNS experiments."
}