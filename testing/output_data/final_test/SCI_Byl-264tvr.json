{
    "title": "Byl-264tvr",
    "content": "MOHART is a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm that incorporates relational reasoning by accounting for permutation invariance. It outperforms baselines with multi-headed self-attention, improving tracking and prediction in challenging scenarios like ego-motion, occlusions, and crowded scenes. This approach is the first fully end-to-end multi-object tracking from vision applied to real-world data. The curr_chunk discusses the need for class-agnostic algorithms for tracking multiple objects in real-world environments, highlighting the limitations of tracking-by-detection methods. These methods rely on pre-trained deep CNNs like YOLO for object detection and linking across frames, but struggle with objects from unseen categories. Hierarchical attentive recurrent tracking (HART) is a novel method for single-object tracking that can track arbitrary objects indicated by the user. It efficiently processes relevant parts of an image using spatial attention and integrates object detection, feature extraction, and motion modeling into one network. Unlike tracking-by-detection methods, HART allows for end-to-end learning to discover complex visual and spatio-temporal patterns in videos. MOHART is a class-agnostic tracker with complex relational reasoning capabilities, utilizing a multi-headed self-attention module. It infers the latent state of tracked objects in parallel and uses self-attention to inform per-object states about other objects, preventing performance loss under self-occlusions or camera motion. The model is trained end-to-end, enabling it to handle faulty or missing sensor inputs efficiently. MOHART is a tracker that estimates object states for tracking and predicting future trajectories. It can be trained for both tasks simultaneously, improving learning efficiency. Unlike previous methods, our approach combines trajectory prediction and object tracking for better results. Our method uses a self-attention module for tracking multiple objects with relational reasoning. MOHART uses self-attention for tracking multiple objects with relational reasoning, outperforming other approaches. It shows consistent performance improvement in tracking and trajectory prediction compared to HART. Vision-based tracking typically follows a tracking-by-detection paradigm, linking detections from different frames for coherent trajectories using motion models and appearance. MOHART is not competitive in scenarios with high-quality detections available for each frame. End-to-end tracking approaches tracking in a holistic manner, with challenges in non-differentiable image crop extraction. HART is an end-to-end tracker with soft spatial-attention using a 2D grid of Gaussians instead of a hard bounding-box. It shows promising performance on the real-world KITTI dataset and has been extended to incorporate depth information from RGBD cameras. Gordon et al. propose a simplified approach where the crop corresponds to the scaled up previous bounding-box, but it does not allow the model to learn where to look. Successful implementations of end-to-end approaches for multi-object tracking beyond SQAIR are limited. Pedestrian trajectory prediction has a long history in computer vision and robotics. Initial research focused on social forces and hand-crafted features, while recent approaches incorporate context information like positions of other pedestrians. Social-LSTM uses LSTM to predict trajectories and employs attention mechanisms for relevant information retrieval. Our work differs from previous methods by not relying on ground truth tracklets. Instead, we work directly with visual input to track pedestrians, model interactions, and predict future motions. This approach can be compared to Visual Interaction Networks (VIN), which encode frames into state vectors and use recurrent neural networks for interaction modeling. The model architecture described in fig. 1 combines scene segmentation and relational reasoning using the Hierarchical Attentive Recurrent Tracking (HART) algorithm. This algorithm is extended to track multiple objects and facilitate relational reasoning through multiheaded attention. Additionally, the method can be applied to trajectory prediction. HART is an attention-based recurrent algorithm that efficiently tracks single objects in a video by using a spatial attention mechanism to extract a glimpse corresponding to the object of interest. It decreases computation by processing only relevant image crops. The relational reasoning module in MOHART utilizes multi-headed self-attention to compute interactions between objects, enhancing object representations with visual features and positional encoding. The HART algorithm tracks single objects in videos using a spatial attention mechanism to extract relevant image crops. It utilizes multi-headed self-attention for relational reasoning and can predict complex motion patterns based on past object history. This approach reduces the need for analyzing large regions-of-interest compared to CNN-based methods. The HART algorithm uses a spatial attention mechanism to track single objects in videos. It predicts bounding-box estimates and attention parameters for each time-step, measuring performance with intersection-over-union (IoU). While capable of tracking arbitrary objects, HART is limited to one object at a time and struggles with occlusions, ego-motion, and object interactions due to lack of communication between instances. The HART algorithm tracks single objects in videos using a spatial attention mechanism but struggles with occlusions, ego-motion, and object interactions. An extension of HART introduces multi-object support by applying HART to multiple objects in parallel with shared parameters. Each HART instance is referred to as a tracker, and a presence variable is used to mark object interactions and mask the loss function. Communication between trackers is enabled by augmenting HART. The HART algorithm is extended to support multiple objects by introducing a glimpse extraction step with a CNN and spatial attention parameters. This allows for interactions between objects without depending on their order. The HART algorithm is extended to support multiple objects by introducing a glimpse extraction step with a CNN and spatial attention parameters. This method should be permutation-equivariant, using the multi-head self-attention block to account for higher-order interactions between set elements when computing their representations. The SAB allows trackers to query each other about attributes like distance between objects, direction of movement, or relation to the camera. MOHART extends the HART algorithm to support multiple objects by utilizing a multi-head self-attention block for querying different attributes and aggregating features. The SAB produces output vectors for each input, which are then concatenated and processed further with separate LSTMs. MOHART is trained end-to-end and maintains a hidden state for object motion information, allowing for predicting future trajectories easily. The model in MOHART learns to predict future trajectories by utilizing a multi-head self-attention block for querying different attributes and aggregating features. It incorporates a recurrent module that exchanges information by concatenating representations of objects and feeding them into the model. This approach allows for universal function approximation but does not impose permutation invariance. The MOHART model utilizes a multi-head self-attention block for predicting future trajectories by exchanging information through object representations. It achieves a 76% IoU in making accurate predictions, outperforming HART which only achieves a 47% IoU. The MOHART model, utilizing multi-head self-attention, achieves 76% IoU in predicting future trajectories. Attention scores correlate with interaction strength between objects and walls, showing understanding of motion patterns. HART as a single-object tracker captures complex motion patterns effectively. In the second experiment, randomness is introduced, making the scenario unsolvable for a single object tracker without relational reasoning. MOHART, using self-attention for relational reasoning, accurately captures interactions between objects with different identities. In the comparison of augmenting HART with different relational reasoning modules, simple max-pooling outperforms MLP (\u2206IoU \u223c 17%) due to the permutation invariance of the problem. Increasing randomness in re-assigning identities emphasizes the importance of relational reasoning for dynamic force fields. In a comparison of augmenting HART with different relational reasoning modules, simple max-pooling outperforms MLP due to permutation invariance. Self-attention solves relational reasoning tasks more accurately, despite potential performance loss for all models. In a deterministic environment, tracking does not always benefit from relational reasoning, even with long-range interactions. A static force field can be inferred from a small number of observations. MOHART shows improvements over HART in real-world datasets, indicating the capability of performing complex relational reasoning. MOHART consistently outperforms HART in various scenarios, especially in scenes with ego-motion, crowded environments, and faulty sensor inputs. Experiments were conducted on different datasets, including MOTChallenge, UA-DETRAC, and Stanford Drone. High framerate scenes were subsampled to increase challenge. Training and architecture details can be found in the appendices. The model learns to adapt and improve through end-to-end training. MOHART learns to track object locations using its internal motion model when no new observations are available. It is initialized with ground truth bounding boxes and predicts them for 30 time steps, measuring performance with intersection over union (IoU). The algorithm is tested on datasets with camera blackout simulations to study its ability to recognize lack of new information. MOHART is tested on datasets with camera blackout simulations to recognize lack of new information. It achieves 68.5% IoU on the MOTChallenge dataset, showing impressive performance with minimal training data. The algorithm gains performance when considering ego-motion data, as movements of objects due to ego-motion are correlated and benefit from relational reasoning. The MOHART algorithm shows impressive performance on the MOT-Challenge dataset, especially in camera blackout scenarios where it relies on internal motion models and relational reasoning to track objects. The dataset's density of objects allows for learning interactions, with qualitative tracking results shown in fig. 5 and Appendix E. Tracking performance on the UA-DETRAC dataset also benefits from relational reasoning. The MOHART algorithm performs well on the MOT-Challenge dataset, utilizing relational reasoning for tracking objects, especially in camera blackout scenarios. On the UA-DETRAC dataset, relational reasoning is beneficial for tracking in crowded scenes. The Stanford drone dataset presents a different challenge with crowded scenes and small object sizes, designed for trajectory prediction tasks. The MOHART algorithm shows improved performance on the MOTChallenge dataset compared to UA-DETRAC. It outperforms HART in prediction experiments and captures complex interactions for precise predictions using visual information and relational reasoning. The experiments show that relational reasoning's benefit depends on the data nature. In a deterministic world, it is less important than in a stochastic environment. The MOTChallenge dataset, with crowded scenes and occlusions, shows the highest gains from relational reasoning. Ground truth bounding boxes are only available for training datasets in the benchmark suite for multi-object tracking. Users are encouraged to upload their tracking models using bounding box proposals from an external object detector. The training data is divided into training and test sequences for different analyses. Additional sequences are added to the MOTChallenge 2017 dataset to compensate for smaller training data. The UA-DETRAC dataset is split into training and test sequences, while the Stanford Drone dataset uses videos for training and testing. Architecture details are optimized for HART performance. The architecture details for optimizing HART performance on MOTChallenge dataset include a presence variable for object tracking, a three-layer convolutional network with specific parameters, and a maximum of 5 objects tracked for UA-DETRAC and MOTChallenge datasets, and 10 for the Stanford drone dataset. The architecture for optimizing HART performance on MOTChallenge dataset includes a 128-dimensional output layer with an elu activation, LSTM with a hidden state size of 128, and a self-attention unit in MOHART. Real-world experiments involve feeding hidden states from the previous LSTM state as input. RMSProp optimizer with momentum set to 0.9 and learning rate 5 * 10 \u22126 is used. Models were trained for 100,000 iterations with batch size 10 on MOTChallenge and UA-DETRAC datasets. Reported IoU is exponentially smoothed over iterations for lower variance. In the Stanford Drone dataset, the batch size was increased to 32 for faster model training to 50,000 iterations. In a toy domain experiment, HART is used to predict the future location of circles with repulsive forces. Despite the complexity of the task, a single object tracker achieves 95% IoU accuracy over 15 time steps, showcasing the effectiveness of end-to-end tracking. The effectiveness of end-to-end tracking is demonstrated by achieving 95% IoU accuracy over 15 time steps. MOHART outperforms HART in predicting future locations and generating robust bounding boxes for tracking tasks. The model captures complex motion patterns and learns to fall back on its internal motion model when no observation is available. The model, MOHART, outperforms HART in capturing complex motion patterns by utilizing visual information and relational reasoning. It shows strong performance on the UA-DETRAC dataset due to its ability to estimate velocities of multiple cars simultaneously. MOHART was tested on three real-world datasets and performed well in various setups, including handling faulty sensor inputs. MOHART can handle faulty sensor inputs by automatically capturing and adjusting to errors, such as black frames in images. It uses LSTM to maintain bounding boxes and quickly readjusts when proper sensor input is restored. This approach works well in scenarios with occlusion and ego-motion, as shown in Figures 9 and 5. Relational reasoning proves particularly beneficial in these situations. The experiments demonstrate the benefits of relational reasoning in predicting future trajectories, particularly in challenging scenarios with occlusion and missing sensor input. The Camera blackout experiment on a pedestrian street scene from the MOTChallenge dataset showcases MOHART's capabilities in handling such situations."
}