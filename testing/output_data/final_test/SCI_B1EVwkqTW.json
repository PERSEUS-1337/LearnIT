{
    "title": "B1EVwkqTW",
    "content": "In this work, metric-learning techniques are extended with Support Vector Machines (SVM) to improve few-shot learning. An end-to-end learning framework for training adaptive kernel SVMs is presented, eliminating the need to choose a correct kernel and features. The one-shot learning problem is redefined for audio signals and tested on vision and speech tasks using Omniglot and TIMIT datasets. The algorithm using Omniglot dataset improved accuracy from 98.1% to 98.5% on the one-shot vision task. Deep learning has shown outstanding results in various areas but requires large datasets and significant computational resources. Techniques for learning on small datasets are not accurate enough. Humans can learn from few examples, leading to the one-shot learning task. The discovery of one-shot learning task BID6 involves learning each class from only one example. Few-shot learning or k-shot learning generalizes this concept by learning from k samples per class. Deep learning tackles data-poor problems through transfer learning, where parameters are optimized on related data-rich problems and fine-tuned on given data. One-shot learning, although data-poor, requires a similar approach to transfer learning for good representation. Standard machine learning tools are then used on the learned features to classify one-shot samples. The paper discusses the use of Support Vector Machine (SVM) as a parameterless model for classifying one-shot samples. It introduces the Siamese kernel SVM model and describes the experimental setup for vision and auditory tasks. While k-nearest neighbors algorithm is a common solution for one-shot learning, SVM is preferred when training data is limited due to its efficiency without requiring complex feature engineering. Support Vector Machines are used for few-shot learning with limited training data. Siamese network BID1 calculates pairwise similarities between data points for one-shot learning. The architecture uses two instances of a feedforward network to determine sample similarity. Siamese networks can be used for classification tasks with learned representations. The Convolutional Siamese Net BID16 uses binary cross-entropy as a loss function and convolutional network for feature learning. The Triplet network BID10 compares data to negative and positive samples simultaneously using three feedforward networks. The Matching Network BID26 is an end-to-end k-nearest neighbors algorithm. The Siamese network extension compares samples to classes' data points to determine similarity. Other successful methods include Memory-Augmented Neural Network and meta-learning with LSTM-based meta-learner. Linear SVM is used for binary classification in the given labeled data. Linear SVMs are trained using constrained optimization to minimize Equation 1, where w provides maximal margin between classes. Slack variables \u03bei create a soft margin penalizing data points inside. The C coefficient controls regularization amount. SVMs are kernel machines, requiring only a positive-definite kernel for training. The dual form allows optimization in kernel space, resulting in a nonlinear decision boundary. Only the kernel function is needed during training. The dual form of SVM optimization leads to a sparse solution with lower computational cost for fewer training points than features. SVMs can be extended to multiclass classification using the one-vs-rest method. Siamese networks were originally designed for verification tasks involving pairs of samples. Siamese networks are used for verification tasks with pairs of samples, aiming to predict if two instances belong to the same class. The network consists of two instances with weight sharing, learning a similarity metric between them. The network's structure involves a feedforward network for representation learning, with the similarity calculation being either predefined or learned during training. Siamese networks are required to be symmetric and consistent, ensuring that the result is the same regardless of the input order. Siamese networks are used for verification tasks with pairs of samples to predict if they belong to the same class. Weight sharing ensures consistent projection of inputs in the vector space. The network learns a similarity matrix for all possible pairs of samples, which can be used for classification. The similarity can be transformed into distance for a k-NN classifier, making it popular for one-shot learning. SVMs can also utilize the similarity matrix for classification. The verification architecture of Siamese networks involves training on pairs of samples to determine if they are from the same class. Data preprocessing is similar to Siamese networks, with equal numbers of positive and negative samples generated. The SVM layer in the architecture includes a feature difference calculation using the L1 norm. The paper uses L1 norm for comparing n-th and m-th samples in equation 3. The SVM uses \u03a6 i n,m as input, and employs a popular version of linear SVMs called L2-SVM which minimizes squared hinge loss. The L2-SVM loss variant is considered the best, with the loss function in equation 4 where y n,m is the label of the pair. Linear SVMs perform best when data points in the feature space are separable by a hyperplane. Increasing the feature space dimension can improve performance, especially with a large number of classes. Using a nonlinear kernel like Radial Basis Function (RBF) in the SVM layer can result in infinite dimensions. However, this approach can be computationally expensive due to the need for the dual form of Support Vector Machine optimization. The complexity of gradient calculations for deep models with a large number of training samples can be significant, with computational complexity of O(m^2). The complexity of calculating loss values for one epoch in the Siamese architecture is O(n^4), making it difficult to train on large datasets. The number of parameters in the SVM Layer is tied to the number of samples, limiting the model to the dataset. Linear SVM solutions are investigated due to this issue. K-shot learning involves verification learning for representation learning on an isolated dataset, followed by few-shot learning for new classes. The new classes in few-shot learning are learned by a linear multiclass SVM using the representation provided by g \u0398. The SVM learns the optimal representation with the same C parameter as the squared hinge loss function. The neural network acts as an adaptive kernel for the SVM, exploring the possibility of a nonlinear kernel in the learning phase. The output of the g \u0398 function cannot be directly used in a nonlinear SVM, so kernel space optimization is preferred. The verification network's output can be transformed into a valid kernel function, generating the Gram matrix for optimization. The Gram matrix is generated by the verification network's output for each pair, allowing SVMs to learn in kernel space without features. This end-to-end neural SVM model has an adaptive kernel and is used in experiments on datasets like Omniglot BID17. The dataset consists of 1623 characters from 50 different alphabets, collected via Amazon's Mechanical Turk. The evaluation method follows the BID26 paper, with models' accuracies shown in TAB0. Characters were mixed independently for training, validation, and testing in n-way k-shot learning. The model used is a Convolutional Siamese Network with regularization. The Convolutional Siamese Network model in the study uses dropout layers with 0.1 rates and SVM's C parameter for regularization is set at 0.2. Training is done for a maximum of 200 epochs with Adam optimizer and early stopping based on accuracy. Fine-tuning with k-shot learning data may lead to overfitting. Fine-tuning involves training for 10 epochs using data generated as described in Section 3.3. This approach is not applicable for one-shot learning scenarios. In Section 3.3, one-shot learning is not feasible as the same class pairs do not exist. To address this, pairs are created from original images and their augmented versions. The concept of one-shot learning is ambiguous in audio data, leading to the introduction of k-sec learning where training data is k seconds long. The optimal value of the hyperparameter w len depends on the task. Data points are w len seconds long with partial overlap, but training and evaluation points must not overlap. Few seconds classification is crucial in real-world applications due to the challenge of collecting large amounts of speaker data. In real-world applications, collecting extensive speaker data for robust classification is challenging. Two scenarios are explored: real-time speaker recognition with k as 1 second, and offline recognition with k as 5 seconds. The TIMIT BID7 dataset, originally for speech-to-text tasks, is suitable for speaker identification. It includes 630 native speakers with 6300 sentences, each speaker speaking for about 30 seconds. The training set comprises 462 speakers, distinct from the evaluation set. The TIMIT dataset is partitioned into training and evaluation sets with distinct speakers. This makes it unsuitable for classical classification but ideal for k-sec learning. Two baseline models are introduced for this task, one using handcrafted features with SVM ensembles. Audio data is converted to spectrograms for neural models. The first classifier uses handcrafted features with ensembles of SVMs, optimized for different lengths of training data. The second model utilizes a neural network with convolutional layers and a fully connected layer, pretrained and fine-tuned for the chosen classes with transfer learning. Different window lengths for different tasks can also be implemented. The neural SVM model's feature extractor in FIG4 includes Batch Normalization and dropout layers for faster convergence and regularization. The model is trained for 200 epochs with Adam optimizer and C value set to 15. Optimizing sliding window length significantly improves accuracy. Spectrogram generation creates 64x64 pixel images representing audio segments. Sliding window with 0.05 sec step size is used for evaluation. The proposed method uses a sliding window with different step sizes for training and evaluation sets due to computational complexity. Results show that classical machine learning algorithms struggle with the task, but the proposed Siamese kernel SVM outperforms baselines by combining SVM generalization with Siamese networks' one-shot learning abilities. The model aims to perform well on limited data and achieves state-of-the-art performance on few-shot learning tasks. The paper introduces the concept of k-sec learning for audio and video recognition tasks, achieving the best results with parameterless models like SVMs. It also establishes a baseline on the TIMIT dataset and encourages measuring one-shot learning models' accuracy across different domains."
}