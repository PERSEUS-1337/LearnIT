{
    "title": "SkxSv6VFvS",
    "content": "Recent works on deformation modeling aim to spatially reconfigure data to improve semantic recognition by adapting the effective receptive field (ERF) directly during runtime. Deformable Kernels (DKs) are introduced as novel convolutional operators to handle object deformations efficiently. Our method involves resampling the original kernel space to recover object deformations, using Deformable Kernels (DKs) as replacements for rigid kernels. Empirical studies show our approach outperforms prior methods and works independently from them. The diversity in object appearance is attributed to variations in semantics and deformations. Semantics involve high-level abstraction of perception, while deformation is tied to specific data. Humans and modern convolutional networks make abstractions through local connectivity and weight sharing. However, convolutional networks encode semantics and deformation together inefficiently. Deformable Kernels (DKs) are proposed as replacements for rigid kernels to recover object deformations. The ability to adapt at runtime is crucial for vision researchers. Deformable Convolution, which uses free-form sampling grids, aims to improve semantic recognition by adapting receptive fields. However, it does not measure the actual impact of input pixels. Deformable Kernels (DKs) resample kernels to adapt kernel spaces while leaving data untouched. They aim to tune the effective receptive field (ERF) for specific data and tasks at runtime, introducing a novel convolutional operator for deformation modeling. Deformable Kernels (DKs) introduce novel convolutional operators for deformation modeling by adapting kernel spaces to interact with the ERF during inference. DKs learn free-form offsets on kernel coordinates to deform the original kernel space towards specific data modalities, achieving empirical results coherent with theoretical justifications. Deformable Kernels (DKs) are evaluated with standard base models on image classification and object detection, outperforming prior works that adapt during runtime. DKs work orthogonally and complementarily with previous techniques in deformation modeling, focusing on learning geometric transformations in 2D image space without regard to 3D. This approach involves crafting geometric invariances into networks and recomposing data. Deformable Kernels (DKs) learn to sample in kernel space to adapt effective receptive fields (ERF) directly, complementing prior works in deformation modeling for 2D image space. This approach focuses on crafting geometric invariances into networks without affecting theoretical receptive fields. Dynamic inference adapts the model or individual operators to the observed data by computing sampling grids from input point clouds. This approach differs from self-attention by adapting convolutional kernels at runtime, similar to Dynamic Filters, Selective Kernels, and Conditional Convolutions. These methods learn and infer customized kernel spaces with respect to the data, enhancing efficiency and effectiveness. Dynamic Filters, Conditional Convolutions, and Selective Kernels are methods that generate new filters or linear combinations of filters. Our work focuses on adapting the Effective Receptive Field (ERF) directly, unlike other approaches that transform kernel spaces. We introduce dynamic inference of ERFs, starting with preliminaries on convolutions and formulating a theoretical framework for analysis. Our work introduces Deformable Kernels (DKs) as a novel approach to analyzing Effective Receptive Fields (ERFs). We present two instantiations of DKs - global and local DKs, and differentiate them from Deformable Convolutions. By stacking kernels in a linear convolutional network, we can imagine the theoretical receptive field as the cumulative coverage of kernels at each output unit on the input image. Theoretical receptive fields in a network are visualized as accumulative coverage of kernels at each output unit on the input image. The effective receptive field (ERF) measures the impact of input pixels on output locations, influenced by stacked convolutions and non-linear activations. The ERF is defined as a partial derivative field of the output with respect to the input data. The ERF in linear convolution networks is a Gaussian-like soft attention map that grows with network depth and kernel size. Empirical results validate this idea under various network complexities. Our analysis focuses on predicting ERF changes with perturbations in computation, considering a linear convolutional network without unit activations. In linear convolutional networks, the effective receptive field (ERF) is related to data and kernel sampling locations. By replacing a kernel with a 1x1 kernel, the ERF value changes. The ERF grows with network depth and kernel size, validated empirically. The effective receptive field (ERF) in convolutional networks is influenced by data and kernel sampling locations. By using 1x1 kernels, the ERF can change, growing with network depth and kernel size. The ERF becomes data-dependent due to a coefficient tied to input coordinates, kernel sampling locations, and input data. This coefficient \"gates\" the contribution of input pixels to the output, making the ERF \"porous\" with irregularly inactive or gated pixel units. The effective receptive field (ERF) in convolutional networks is influenced by data and kernel sampling locations, making it \"porous\" with irregularly inactive pixel units. This phenomenon is controlled by data sampling location and kernel values, leading to linear computations compatible with any linear sampling operators. Deformable Kernels (DKs) are designed based on resampling the kernel with learned offsets, defining the DK and ERF values. This operation allows for sub-pixel precision in sampling. Deformable Kernels (DKs) allow for sub-pixel sampling in the kernel space using bilinear interpolation. The size of the original kernel space, known as the \"scope size\" of DKs, can impact sampling performance. DKs have no constraint on the original kernel space size, enabling the use of large kernels like 9x9 with minimal computational overhead. However, using large kernels can increase the number of learning parameters, which may pose challenges in practice. Deformable Kernels (DKs) allow for sub-pixel sampling in the kernel space using bilinear interpolation. In our implementation, we utilize depthwise convolutions to minimize the increase in parameters with scope size. We have two variants of DKs - global DK and local DKs, each with a kernel offset generator G. The global G includes a global average pooling layer and a fully-connected layer to generate offset vectors applied to convolutions. For local DKs, G is implemented differently. Deformable Kernels (DKs) allow for sub-pixel sampling in the kernel space using bilinear interpolation. Global DK adapts kernel space between different images, while local DKs can adapt to specific image patches for better locality and freedom to adjust kernel spaces. Deformable Kernels (DKs) learn adaptive offsets for sampling the kernel space to model deformation, similar to Deformable Convolutions. DKs aim to unify and distinguish from Deformable Convolutions by recomposing input images for better semantic recognition and explaining the sampling of the Effective Receptive Field (ERF). Deformable Kernels (DKs) are designed to learn adaptive offsets for sampling the kernel space to model deformation, distinct from Deformable Convolutions. The collaboration between Deformable Kernels and Deformable Convolutions is found to be powerful in practice, showing strong compatibility. The operators are implemented in PyTorch and CUDA for image classification and object detection tasks, with necessary details provided for result reproduction. In PyTorch and CUDA, Deformable Kernels are implemented for image classification and object detection tasks. Depthwise convolutions are utilized for computational efficiency, with ResNet-50 and MobileNet-V2 chosen as base models. ResNet-50-DW is defined by replacing 3x3 convolutions with depthwise convolutions and doubling intermediate channel dimensions. The ResNet-50-DW model is a reasonable base model compared to the original ResNet-50, with similar performance on tasks. During training, weight decay is set to 4 \u00d7 10 \u22125 for depthwise models. The learning rate multiplier for DK operators is 10 \u22122 for ResNet-50-DW and 10 \u22121 for MobileNet-V2. Strong baselines include Conditional Convolutions and Deformable Convolutions for dynamics inference and deformation modeling, respectively. Fair comparisons are made by reimplementing and reproducing their results. We retrain our networks on the ImageNet 2012 dataset using SGD for 90 epochs with momentum 0.9 and batch size 256. The learning rate warms up from zero to 10^-1 within the first 5 epochs. A cosine training schedule is applied, and data augmentations such as scale and aspect ratio augmentation are used. Model performance is evaluated on the ImageNet 2012 validation set with images resized to 256 pixels on the shorter side and centrally cropped to 224x224 for recognition accuracy measurement. Our study focuses on the impact of scope size on the performance of DKs in ResNet-50-DW. Results show that a scope size of 4x4 yields the largest gain in accuracy. Increasing scope size may improve interpolation but also leads to sparse gradient flows. Default scope size for DKs is set at 4x4. The study focuses on the impact of scope size on the performance of DKs in ResNet-50-DW. Results show that a scope size of 4x4 yields the largest gain in accuracy. Comparing global DK with local DK, the local variants consistently perform better, showing a +0.5 gap on both base models. Adding more DKs still helps, especially for MobileNet-V2. Results comparing DKs with Conditional Convolutions and Deformable Convolutions are recorded in Table 2, showing DKs perform comparably on ResNet-V2 and outperform Deformable Convolutions on MobileNet-V2 by +0.9. The study examines the impact of DKs on ResNet-50-DW, showing that a scope size of 4x4 yields the largest accuracy gain. Local DKs outperform global DKs, with consistent performance improvements. Results also demonstrate that DKs perform comparably on ResNet-V2 and outperform Deformable Convolutions on MobileNet-V2 by +0.9. Additionally, combining DKs with other operators leads to even larger performance gains. Following standard protocol, training and evaluation are conducted on 120k images in the train-val split and 20k images in the test-dev split. Evaluation includes measuring mean average precision (mAP) and shattered scores for objects of different sizes. Comparisons show that while DKs fall short compared to Deformable Convolution, combining them still improves performance. Results indicate that using local DKs leads to an improvement in mAP, especially when replacing both 1x1 and 3x3 rigid kernels. This trend is more pronounced in MobileNet-v2 models. Additionally, local DKs are shown to be more effective than global DKs. Results confirm the effectiveness of local Dynamic Kernels (DKs) over global DKs, aligning with the expectation that local DKs model locality better. While DKs outperform Deformable Convolutions in image classification, they fall short in object detection. Combining DKs with previous methods consistently boosts performance across all techniques. This aligns with findings in image classification, prompting further investigation into what DKs learn and their compatibility with existing methods. In image classification, local Dynamic Kernels (DKs) are found to be more effective than global DKs and outperform Deformable Convolutions. Combining DKs with previous methods consistently improves performance. DKs learn kernel sampling offsets that correlate strongly with object scales rather than semantics, complementing existing operators. Deformable Convolutions and DKs adapt effective receptive fields in convolutional networks for object deformation. Combining both operators yields consistent improvements and compatibility with previous methods. DKs learn kernel sampling offsets that correlate with object scales, complementing existing operators. Deformable Convolutions and DKs improve receptive fields in convolutional networks for object deformation. DKs use kernel offsets generated by a lightweight generator to sample new kernels for convolution. The forward and backward passes of DKs are detailed, with a focus on local DK implementation. Global DK implementation is also discussed. The forward pass of local DK involves resampling a new kernel using a bilinear operator B with kernel offsets. The backward pass includes gradients to the previous layer's data, the current layer's full scope kernel, and the kernel offset generator. The third type of gradient determines where to sample kernel values. The text discusses the computation of partial derivatives for output items in the context of a network architecture comparison between ResNet-50 and ResNet-50-DW. The ResNet-50-DW model utilizes depthwise convolutions with 128 input channels for computational efficiency in Deformable Kernels. The comparison between ResNet-50 and ResNet-50-DW shows that the latter introduces depthwise convolutions for faster computation of local Deformable Kernels. The ResNet-50-DW model maintains similar capacity and performance as its non-depthwise counterpart, making it suitable for experiments. Additionally, MobileNet-V2 remains unchanged in the experiments. The method enhances Effective Receptive Fields (ERFs) to focus more on object semantics rather than geometric configurations."
}