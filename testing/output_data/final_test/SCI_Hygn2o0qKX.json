{
    "title": "Hygn2o0qKX",
    "content": "The ability of overparameterized deep networks to generalize well is attributed to stochastic gradient descent (SGD) finding solutions in flat, wide minima in the training loss, making the network output resilient to small random noise. In this work, a general PAC-Bayesian framework is presented that provides a bound on deterministic and uncompressed neural networks. The framework leverages interactions between weight matrices to ensure wide training and test loss minima, with a focus on pre-activation values not being too small on training data. In a PAC-Bayesian framework, a generalization guarantee is provided for deterministic and uncompressed neural networks. This guarantee does not scale with the product of spectral norms of weight matrices, allowing deep neural networks to generalize well despite having millions of parameters and being trained on relatively few samples. This observation has sparked research into understanding the properties of stochastic gradient descent training that enable these networks to achieve state-of-the-art generalization error on real-world tasks. In this paper, the authors revisit the PAC-Bayesian analysis of deep networks and provide a general framework for stochastic gradient descent training that allows deep networks to generalize well. The focus is on bounds that utilize the noise-resilience of deep networks on training data, without exponential dependence on depth. The authors revisit the PAC-Bayesian analysis of deep networks, presenting a framework for utilizing noise-resilience in training data to provide a bound on the original network. This general framework is specialized for deep ReLU networks, offering a generalization bound that does not scale exponentially with depth. The authors present a framework for utilizing noise-resilience in training data to provide a generalization bound for deep ReLU networks. The bound does not scale exponentially with depth and captures interactions between weight matrices. The authors propose a novel approach to generalize noise-resilience of deep networks from training to test data, deriving a bound that does not scale with spectral norms. The flatness/width of the training loss at the minimum found by SGD is crucial for understanding generalization behavior. The network is noise-resilient and can handle parameter perturbations. Generalization guarantees for SGD on deeper networks have strong exponential dependence on depth, scaling with spectral or Frobenius norms of weight matrices. The generalization bounds for deeper networks have exponential dependence on depth due to worst-case approximation of weight matrix interactions, with spectral norms scaling as 2 or 3 and Frobenius norms scaling with \u221aH. The spectral and Frobenius norms of weight matrices in deep networks tend to align with expected values, around 2 and \u221aH respectively. Prior approaches have used noise-resilience to derive bounds that capture interactions between weight matrices more realistically, leading to a generalization bound on the compressed network. Incorporating noise-resilience in training data can lead to a generalization bound on the compressed network, but it does not apply to the original network. Revisiting the idea, the PAC-Bayesian framework is used to provide generalization bounds for a stochastic classifier. Our work introduces a general PAC-Bayesian framework for deriving generalization bounds by leveraging the noise resilience of deep networks. This approach can be applied to deep networks and extends the PAC-Bayesian bound to provide a standard generalization guarantee on deterministic classifiers. Our approach leverages the noise resilience of deep networks to derive generalization bounds for classifiers. By satisfying specific conditions related to weight interactions, we ensure noise resilience on both training and test data, leading to a generalization guarantee on the test loss of the network. Our framework derives a generalization bound on the test loss of the original network by applying specific conditions to ReLU based feedforward networks. This approach ensures noise resilience on both training and test data, leading to a generalization guarantee on the test loss. The framework establishes conditions for noise resilience in ReLU based feedforward networks to derive a generalization bound on the test loss. The assumption is that pre-activation values are sufficiently large on training data to prevent unit flipping under parameter perturbations. This contrasts with BID0 Neyshabur et al. (2017) which also requires similar assumptions but allows for some units to flip under noise. In this section, a general PAC-Bayesian framework is presented that utilizes noise-resilience of the network to convert a generalization bound on the stochastic classifier to a bound on the deterministic classifier. The notation and definitions for the framework are also provided for a K-class learning task with labeled datapoints drawn from an underlying distribution. The PAC-Bayesian framework allows for deriving generalization bounds for a stochastic classifier by using parameters sampled from a Gaussian distribution. The framework involves a random variable W in the parameter space learned from training data S, with a prior distribution P chosen independently. The PAC-Bayesian framework provides a generalization bound for a stochastic classifier using parameters sampled from a Gaussian distribution. The prior distribution P is chosen independently of the training data, and the classifier's error is bounded with probability 1-\u03b4 over the training set S of m samples. The weights W learned from the training data are centered at a Gaussian with covariance \u03c3^2I, and the prior distribution P is also a Gaussian with covariance \u03c3^2I centered at the random initialization of the network. This adjustment results in a smaller KL-divergence and saves a \u221aH factor in the bound. In the PAC-Bayesian framework, a standard generalization bound on a deterministic classifier W can be replaced by considering the perturbation suffered by the train and test loss under Gaussian perturbation of the parameters. To tightly bound these terms, the network needs to be noise-resilient on both training and test data. Introducing an additional set for the margin of the classifier on the input can help in this process. The text discusses the importance of noise-resilient properties in deep networks for accurate classification. It introduces a constraint where sets of properties depend on each other, ensuring that perturbations do not affect classification accuracy. This constraint is crucial for deep networks to maintain robustness under random parameter perturbations. The text introduces a constraint where properties in deep networks depend on each other to ensure robustness against perturbations. It formalizes this requirement using expressions that bound perturbations in properties based on parameter variance. The constraint applies to inputs that satisfy specific conditions and requires a small probability term for all such inputs. The constraint introduced in the text ensures robustness against perturbations in deep networks by bounding perturbations in properties based on parameter variance. It requires a small probability term for inputs that satisfy specific conditions. Theorem 3.1 provides a 'margin-based' generalization guarantee for deep networks, ensuring robustness against perturbations. The constraint bounds perturbations in properties based on parameter variance, with conditions that must be satisfied for training data. The crux of the proof lies in generalizing conditions from training data to test data, proving noise-resilience. Theorem C.1 converts a PACBayesian bound on a stochastic classifier to a generalization bound on a deterministic classifier. Our technique converts a PAC-Bayesian bound on a stochastic classifier to a generalization bound on a deterministic classifier. It is more powerful than other approaches in leveraging noise-resilience, relying on a tighter output perturbation bound. This difference is critical in bounding the generalization error. Our framework applies to feedforward fully connected ReLU networks of depth D and width H, deriving a generalization bound that does not scale with the product of spectral norms of weight matrices. The ReLU activation function is denoted by \u03c6(\u22c5). The network is parameterized by DISPLAYFORM0, with Jacobians denoted by DISPLAYFORM1. The text discusses conditions for noise-resilient training data in feedforward fully connected ReLU networks. It introduces the Jacobian matrix and defines properties related to hidden layer norms and pre-activation values. These conditions are similar to those explored in previous studies and are formalized in Equation 1. The text introduces properties related to hidden layer norms and pre-activation values in feedforward fully connected ReLU networks. It proves guarantees under random perturbations of parameters and shows that perturbations in output and input-dependent properties can be bounded. The generalization bound scales with the bounds on these properties satisfied on the training data. The text discusses the generalization bound of feedforward fully connected ReLU networks, showing that it does not depend on the product of spectral norms of weight matrices. The bound is proven to have an explicit dependence on the depth of the network, with terms varying for networks of different depths. The text discusses the generalization bound of feedforward fully connected ReLU networks, showing that it does not depend on the product of spectral norms of weight matrices. The bottleneck in the bound is B preact, which scales inversely with the smallest absolute pre-activation value of the network. The magnitude of pre-activation values can vary, with some hidden units having arbitrarily small values. Two variations of B preact are plotted: 5%-B preact and median-B preact, showing different calculations based on pre-activation values. The text discusses the generalization bound of feedforward fully connected ReLU networks, focusing on the smallest absolute pre-activation values for each input. The overall bound and existing bounds vary with depth, with the new bound showing better performance as depth increases. When D = 28, the new bound outperforms existing bounds. Hypothetical variations using different pre-activation values also show significant improvements compared to the actual bound. The text discusses the generalization bound of feedforward fully connected ReLU networks, focusing on the smallest absolute pre-activation values for each input. The new bound with 5%-B preact performs better for larger depths, indicating potential for tighter guarantees even with smaller D values. Various generalization bounds are compared, showing improvements with the new bound and hypothetical variations using different pre-activation values. The text discusses modifications to generalization bounds for feedforward fully connected ReLU networks, emphasizing the importance of pre-activation values. The new bounds show potential for tighter guarantees with smaller D values, compared to other bounds. The dependence on pre-activation values is noted as a limitation in characterizing noise-resilience. The text discusses improving generalization bounds for feedforward fully connected ReLU networks by focusing on pre-activation values. Future work could explore more realistic conditions for noise resilience. In this work, a novel PAC-Bayesian framework is introduced to leverage noise-resilience in deep neural networks on training data. The approach aims to generalize noise-resilience from training to test data, deriving a generalization bound on the original uncompressed network. The focus is on ReLU based networks, with a bound that captures interactions between weight matrices. Future work aims to remove strong assumptions on magnitude dependencies. In this work, a PAC-Bayesian framework is introduced to leverage noise-resilience in deep neural networks on training data. The focus is on ReLU based networks with a bound that captures interactions between weight matrices. The approach aims to generalize noise-resilience from training to test data, deriving a generalization bound on the original uncompressed network. Future work aims to remove strong assumptions on magnitude dependencies. Symbols are used to denote matrices and vectors for easier mathematical statements. The parameters of the network are denoted by symbol W, representing weight matrices. The Jacobian corresponds to the pre-activation values of different layers. Each row in the Jacobian represents a unit in a layer, and each column corresponds to a unit in another layer. Random initialization of the network is denoted by Z. The PAC-Bayesian analysis uses weight matrices U drawn from an underlying distribution over data. In PAC-Bayesian analysis, weight matrices U are sampled independently from a Gaussian distribution. U d represents the first d randomly sampled weight matrices, and W + U d denotes a network with perturbed weight matrices. W[+U d] represents a network with frozen hidden units. Standard results are presented in this section, using symbols \u2227, \u2228, and \u00ac to denote intersection, union, and complement of events. In this section, standard results are presented for noise resilience analysis. Lemma B.1 states bounds for independent random variables sampled from a Gaussian distribution. Lemma B.2 discusses properties of a matrix sampled from a Gaussian distribution. The text discusses bounds on the spectral norm of a matrix with Gaussian entries and the KL divergence of Gaussians. It also introduces a PAC-Bayesian theorem for analyzing generalization in a framework. The text introduces a generalization bound on the expected loss of a distribution of classifiers compared to a deterministic classifier. It discusses a more general generalization bound than standard bounds, focusing on interactions between weights in the network. The text discusses the noise resilience of a network with parameters W for a given data point (x, y) based on input-dependent properties and margins. It defines noise resilience and probability of not being noise-resilient at a data point, emphasizing the network's robustness to noise. The text discusses noise resilience of a network with parameters W for data points (x, y) in a dataset S. It emphasizes the network's robustness to noise and how the approach differs from previous methods in bounding noise-resilience requirements for generalization guarantees. The text discusses the noise-resilience requirement for a stochastic classifier compared to a deterministic classifier. It highlights the milder condition for noise resilience and the need for \u00b5 D and \u00b5 S to be O(1 \u221a m) for a generalization guarantee. The difference in defining favorable perturbations for the classifier is also discussed. In our analysis, we focus on perturbations that are unfavorable for the classifier after fixing the datapoint. This differs from earlier works where perturbations were considered unfavorable if they significantly affected the classifier output on some datapoint from the distribution domain. Our approach allows for a more optimistic analysis of perturbations, particularly Gaussian perturbations. We aim for less than 1 \u221a m mass of perturbations to be unfavorable on a given datapoint, which is a stronger noise resilience condition compared to previous bounds. In our analysis, we focus on perturbations that are unfavorable for the classifier after fixing the datapoint. This differs from earlier works where perturbations were considered unfavorable if they significantly affected the classifier output on some datapoint from the distribution domain. Our approach allows for a more optimistic analysis of perturbations, particularly Gaussian perturbations. We aim for less than 1 \u221a m mass of perturbations to be unfavorable on a given datapoint, which is a stronger noise resilience condition compared to previous bounds. While in previous bounds, there can be as much as 1 2 probability mass of perturbations that are unfavorable. This will only weaken our generalization bound by a ln \u221a m factor in comparison to previous bounds (while saving other significant factors). In our analysis, we focus on bounding the test loss of the stochastic classifier by relating it to the deterministic classifier. We cleverly choose the distribution Q based on S, selecting it to be a Gaussian perturbation of the deterministic classifier W. Our goal is to bound the loss for W using a margin-based variation, and then relate it to the expected loss of the stochastic classifier. This allows us to analyze the noise resilience of the classifiers under perturbations. The text discusses splitting the expected loss of the deterministic classifier into noise-resilient datapoints and the rest. It introduces events N(W, x, y) and U(W, x, y) to analyze the stochastic classifier's loss on the noise-resilient part of the distribution. The text discusses lower bounding the stochastic classifier's loss on noise-resilient datapoints by replacing it with a deterministic classifier. It highlights the high probability of favorable perturbations for datapoints drawn from a specific distribution. The text discusses upper bounding the expected loss of a deterministic classifier on noise-resilient datapoints, which can be used to bound the deterministic classifier's loss on the whole distribution. The text discusses upper bounding the stochastic classifier's train loss using PAC-Bayesian bound, then transitioning to analyzing the deterministic classifier's train loss on noise-resilient datapoints. The text discusses upper bounding the stochastic classifier's train loss using PAC-Bayesian bound and then transitions to analyzing the deterministic classifier's train loss on noise-resilient datapoints. The analysis involves splitting over noise-resilient points and perturbations to derive upper bounds on the equations. The text presents a proof for abstract generalization guarantee based on a recursive inequality for all r \u2264 R. The proof relies on Theorem C.1 to bound the proportion of test data failing to satisfy conditions based on training data proportions. The proof relies on Theorem C.1 to bound the proportion of test data failing to satisfy conditions based on training data proportions. The quantities \u03bc S and \u03bc D represent the proportion of training and test data where properties are not noise-resilient. The generalization error is also considered. By applying the PAC-Bayes-based guarantee from Theorem C.1, it is shown that the noise-resilience requirement holds on all possible inputs, leading to the conclusion that \u03bc S and \u03bc D are zero. This establishes the recursion statement for the base case and for arbitrary r \u2264 R. The proof relies on Theorem C.1 to bound the proportion of test data failing to satisfy conditions based on training data proportions. The quantities \u03bc S and \u03bc D represent the proportion of training and test data where properties are not noise-resilient. The generalization error is also considered. By applying the PAC-Bayes-based guarantee from Theorem C.1, it is shown that the noise-resilience requirement holds on all possible inputs, leading to the conclusion that \u03bc S and \u03bc D are zero. This establishes the recursion statement for the base case and for arbitrary r \u2264 R. The network is noise-resilient as per Equation 3 in Theorem C.1 for any input that satisfies the r\u22121 conditions approximately. This claim can be used to prove Equation 8, bounding the proportion of bad points on the test data. The proof relies on Theorem C.1 to bound the proportion of test data failing to satisfy conditions based on training data proportions. The quantities \u03bc S and \u03bc D represent the proportion of training and test data where properties are not noise-resilient. By applying the PAC-Bayes-based guarantee from Theorem C.1, it is shown that the noise-resilience requirement holds on all possible inputs, leading to the conclusion that \u03bc S and \u03bc D are zero. This establishes the recursion statement for the base case and for arbitrary r \u2264 R. The network is noise-resilient as per Equation 3 in Theorem C.1 for any input that satisfies the r\u22121 conditions approximately. This claim can be used to prove Equation 8, bounding the proportion of bad points on the test data. The upper bound on the proportion of parameter perturbations is derived through a series of mathematical steps, ensuring noise-resilience conditions are met for various input-dependent properties. The margin-based bound is derived by applying a recursion on the right side of the equation, quantifying the noise resilience of a network in different aspects. Each bound fixes an input point and states a property of the network with high probability over parameter perturbations. The bounds in the perturbation of network properties are based on the magnitude of preceding properties and how they respond to perturbations, rather than the spectral norm of weight matrices. In formulating our lemma statement, we introduce a notation for tolerance parameters to quantify perturbations in network properties. The notation includes a set of positive tolerance values denoted by \u0108, with elements representing specific perturbation levels in different layers of the network. The perturbation of weights in layer d had minimal impact within tolerance levels. The event ensures that perturbations do not change the activation states of the network. The perturbation bounds are defined based on preactivation levels and specific subsets of properties. The perturbation of weights in layer d had minimal impact within tolerance levels. The event ensures that perturbations do not change the activation states of the network. The perturbation bounds are defined based on preactivation levels and specific subsets of properties. For any perturbation U of the matrices W, let UNCHANGED-ACTS d (W + U, x) denote the event that none of the activation states of the first d layers change on perturbation. Our results are styled similar to the equations required by Equation 2 presented in the main paper, bounding the probability that a perturbation affects a property while preceding properties remain unperturbed within a certain tolerance level. The perturbation of weights in layer d had minimal impact within tolerance levels. The spectral norm of Y d \u2032\u2032 is at most the products of the Gaussian perturbations. The spectral norm of Y d \u2032\u2032 is bounded by the products of the spectral norms of three matrices. Using Lemma B.3, the spectral norm of U d \u2032\u2032 can be bounded by \u03c3 2H ln 2D\u0124 \u03b4 with high probability. The spectral norm of the Jacobian is upper bounded by W d for a ReLU network. With probability 1 \u2212\u03b4 over the draws of U d , Equation 14 can be upper bounded. The spectral norm of Y d \u2032\u2032 is bounded by the products of three matrices. Using Lemma B.3, the spectral norm of U d \u2032\u2032 can be bounded by \u03c3 2H ln 2D\u0124 \u03b4 with high probability. The spectral norm of the Jacobian is upper bounded by W d for a ReLU network. The result of the lemma is obtained by a similar argument as in the case of the perturbation bound on the output of each layer. The main result for this section is a generalization bound on a class of networks based on norm bounds on the training data. The constraint in Equation 2 requires small perturbations in properties grouped together. Lemma E.1 provides perturbation bounds and dependencies between properties, allowing them to be ordered accordingly. Properties are traversed from layer 0 to D, grouping spectral norms and row 2 norms of Jacobians as dictated by the lemma. Next, we will group the row 2 norms of the Jacobians of layer d, followed by a singleton set of the layer output's 2 norm. We will then group the pre-activations of layer d, and consider the margin-based property for the output layer. The number of sets created is at most 4D, each set needing to satisfy specific perturbation bounds. The proof continues by showing that the chosen parameter perturbation in the PAC-Bayesian analysis satisfies the required constraints. By instantiating Lemma E.1 with the chosen \u03c3 value, it is confirmed that the perturbation bounds can be upper bounded by the specified constants. The focus is then on demonstrating that a constraint holds for the row 2 norms of the Jacobians. This approach applies to other properties as well. The proof shows that norm bounds on properties up to layer d-1 translate to constraints on Equation 2. If norm bounds hold for a specific x, the goal is to prove the rest of the constraint in Equation 2. It is argued that if PERT-BOUND holds, then UNCHANGED-ACTS also holds for layer d-1 pre-activation values. The preactivation values of layer d-1 do not change their activation state under perturbation, leading to an inequality in Lemma E.1 when \u03c3 = \u03c3 \u22c6. The Jacobian for layer d is an identity matrix, thus not affecting the analysis. In this section, the authors provide a detailed demonstration of how the terms in their bound depend on the depth/width of the network. They conduct experiments using SGD with a learning rate of 0.1 and mini-batch size of 64 on a subset of 4096 random training examples from the MNIST dataset. Training stops when at least 0.99 of the data is classified perfectly with a margin of \u03b3 class = 10. For networks of depth D = 28, they use Adam with a learning rate of 10^-5 until the network achieves an accuracy of 0.95 on the training dataset. All logarithmic transformations in their plots are to the base 10. In this section, the authors demonstrate how the norm-bounds on the input-dependent properties of the network do not scale as large as the product of spectral norms. They present a slightly looser bound for the experiments, which is based on a modified noise-resilience analysis. This bound does not depend on the product of spectral norms and has a similar overall dependence on the depth. The authors discuss the bound on the perturbation of the Jacobian row 2 norm and how it differs from previous works. They highlight similarities in noise resilience conditions with prior studies. The authors highlight similarities in noise resilience conditions with prior studies, focusing on the interactions between activated weight matrices in the network during training. Two main types of conditions are assumed to bound noise propagation and activation state flipping in the network."
}