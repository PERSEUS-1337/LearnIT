{
    "title": "r1fO8oC9Y7",
    "content": "Semantic parsing is constrained by limited training data, so a General-to-Detailed Neural Network (GDNN) with Cross-Domain Sketch (CDS) is proposed. The General Network extracts CDS for utterances in different domains using an encoder-decoder model, while the Detailed Network generates detailed target parts for specific domain utterances. Experiments show that CDS improves semantic parsing performance in converting user requests into meaning representation language (MRL) by adding constraints to the target. The effectiveness of Cross-Domain Sketch (CDS) in semantic parsing tasks is demonstrated through experiments, showing improved performance in converting user requests into meaning representation language (MRL). This approach adds constraints to the target decoding process, enhancing the ability to represent complex requests in a logic form. The amount of annotated data impacts parsing, making it challenging to annotate in logic forms like Alexa MRL. Multi-task learning and transfer learning have shown benefits in sharing information across domains, improving performance and generalization. However, the reasons behind the success of multi-task learning and the shared tasks are still not fully understood. NLP studies suggest that commonalities in sentences, such as syntax and morphology, can be shared among domains. This work aims to address the lack of discussion and quantification of these commonalities. In this work, the lack of discussion and quantification of commonalities in sentences across domains is addressed by defining cross-domain commonalities explicitly as cross-domain sketch (CDS). A two-level encoder-decoder is constructed using CDS as a middle coarse layer, with a General Network extracting CDS for every utterance in all domains. This approach aims to improve performance and generalization by sharing information across domains. The work introduces Cross-Domain Sketch (CDS) as a way to extract commonalities across domains, enhancing performance and generalization. CDS is incorporated as a middle layer in a neural network, allowing for multi-task learning and improving decoding with advanced attention. CDS is a cross-domain extraction that aids in fine process decoding. Traditional SLU factors language understanding into domain classification, intent prediction, and slot filling, but has limited expression skills. MRL has been introduced to overcome these limitations by using a compositional graph-based approach. Meaning representation language (MRL) is a compositional graph-based semantic representation that allows for more complex requests. MRL, based on a large-scale ontology, is stronger in expression compared to fixed and flat SLU representations. Mapping natural language into MRL is treated as a sequence-to-sequence problem, with advancements in the sequence-to-sequence network with attention mechanism improving performance. Recent advancements in sequence-to-sequence models include improvements such as attention sparsity and the incorporation of a copy mechanism for rare words. Researchers have also focused on enhancing syntax information interpretation, recursive bottom-up encoding, simultaneous generation of target sequences and syntax trees, and constrained decoding processes. Various approaches like using recurrent networks for encoding and decoding, employing grammar constraints, and transitioning from high-level to low-level utterance understanding have been explored. Multi-task learning techniques are used to improve performance in semantic parsing tasks, especially in MRL format. Different approaches like sharing parameters among tasks and dividing the representation network have been explored. BID15 focuses on sharing network parameters for multi-task learning, particularly for human language expressions and task-oriented requests. The text discusses the extraction of crossdomain sketches (CDS) in a canonical way for human language expressions, focusing on action-level and attribute-level commonalities. The approach involves converting logic forms into CDS to deal with structural complexities more effectively. The text discusses extracting cross-domain sketches (CDS) from natural language expressions using a rule-based method. Attributes are converted into domain-independent parts, such as object type and location. The network architecture includes a two-level encoder-decoder for generating CDS, which can be applied across different domains in a multi-task setup. The text discusses a process for generating cross-domain sketches (CDS) from natural language expressions using a two-level encoder-decoder network architecture. The process is domain-dependent and involves encoding the CDS and utterance to decode the target result. The conditional probability is calculated based on the input utterance, CDS, and final logic form. The General Network encodes the utterance with bi-directional LSTM and decodes the CDS using unidirectional LSTM with attention to the utterance in all domains. The Detailed Network, specific to a domain, encodes the CDS and utterance. The Detailed Network encodes CDS and utterance using bi-directional LSTM, decodes the final target with advanced attention. The neural encoder is similar to NMT model, mapping words into vectors and using LSTM units to learn word representations. Two types of utterance encoders are constructed for General and Detailed Networks to extract different information. The Detailed Network encodes CDS and utterance using bi-directional LSTM, decodes the final target with advanced attention. Two types of utterance encoders are constructed for General and Detailed Networks to extract different information for different purposes. The General Network obtains cross-domain sketch conditioned on utterance using an encoder-decoder network. The Detailed Network encodes utterances and CDS using bi-directional LSTM. The decoder utilizes a unidirectional recurrent neural network to predict words. Attention is computed between decoding hidden state and encoding sequence. After decoding CDS words, an encoder is used to represent their meaning with a bi-directional LSTM. The decoder in the Detailed Network uses a unidirectional recurrent neural network to predict words based on attention to both encoded utterances and cross-domain sketches. The training objective is to optimize the prediction of target words using the training corpus. During inference, the cross-domain sketch is obtained first before decoding the target words. The training objective is to optimize the prediction of target words using the training corpus. In the inference process, a cross-domain sketch is obtained first before decoding the target words using greedy search. Existing semantic parsing datasets have limitations in interpreting the effectiveness of cross-domain sketch due to small dataset sizes. The Snips dataset, based on MRL format, collects users' requests from a personal voice assistant with 7 intent types and 72 slot labels. Based on the format (intent-slot), the dataset is pre-processed into MRL format with intent as domain/task and sharing CDS among them. The details are shown in Target SearchAction. Utterance is the user's request in natural language. Cross-domain sketch (CDS) has two levels. Tensorflow with LuongAttention and copy mechanism is used. Encoder and decoder both use one-layer LSTM. Learning rate is applied. In experiments with multi-task learning setup, different architectures are applied, including one-to-one, one-to-many, and one-to-shareMany. Results are shown in Table 4, demonstrating the role of cross-domain sketch (CDS) in guiding the decoding process. The models share encoder and decoder parameters, with variations in task independence. In joint learning experiments, one-to-one outperforms one-to-many and one-to-shareMany due to dataset size and task similarity. Incorporating cross-domain sketch (CDS) improves performance in general-to-detailed neural network (GDNN) models. Attribute-level CDS enhances performance more than action-level CDS, providing more task-sharing information. Separate encoding for utterances is more effective than sharing the same encoder, as different encoders focus differently on utterances. Table 4 shows the multi-task results of different models, including Single Seq2Seq and Joint Seq2Seq with various mechanisms. The results include GDNN models with different levels of CDS and utterance encoding mechanisms. The GDNN models with Attribute-level CDS and separate encoding outperform others, with a maximum accuracy of 78.1%. In comparison to traditional intent classification and slot filling models, Seq2Seq performs worse due to its complexity and training difficulty. However, using Cross-Domain Similarity (CDS) significantly improves performance by extracting commonalities among tasks. CDS helps in making multi-task learning more specific, leading to better results in the experiments. CDS adds constraints to the final target decoding process, providing more information compared to direct joint Seq2Seq. Experiments show that Seq2Seq achieves comparable results to IC SF model for generating CDS from utterance, indicating that incorporating CDS improves performance by adding constraints to the decoding process. In this paper, the concept of cross-domain sketch (CDS) is proposed to extract shared information across domains, utilizing commonalities like syntactic and phrasal similarity in human expressions. A general-to-detailed neural network (GDNN) is presented for converting utterances into a logic form based on meaning representation language (MRL) form. The general network uses an encoder-decoder model to obtain CDS in a multi-task setup. The study introduces the concept of cross-domain sketch (CDS) to extract shared information across domains using an encoder-decoder model in a multi-task setup. The detailed network generates domain-specific targets by utilizing utterance and CDS simultaneously through an attention mechanism. The effectiveness of CDS and multi-task learning is demonstrated in experiments, showing its ability to generalize over various tasks. Future work aims to refine the CDS definition, expand its ontology to other domains, and explore more effective methods like constraint decoding to enhance its role."
}