{
    "title": "S1gc4XF8Lr",
    "content": "Neural activity in response to repeated stimuli is variable. Data from the Allen Brain Observatory shows that responses follow log-normal or Gaussian distributions, similar to deep neural networks. A population coupling model reveals non-Gaussian distributions in activity fluctuations. Cortex noise aligns better with in-clip stimulus variations, aiding generalization. The high trial-to-trial variability in neural codes has been studied in relation to attention and other behavioral variables. Cortical noise is non-Gaussian and may help build general representations from a small number of exemplars. This noise is better captured by long-tailed distributions or mixtures of Gaussians, as shown in experiments using two-photon calcium imaging and electrophysiological recordings. Using two-photon calcium imaging and electrophysiological recordings, a population coupling model was used to predict single neuron activity. Neural subspace measures showed that cortical noise aligns with stimulus variations. The study analyzed excitatory cells during a \"natural movie one\" stimulus presented 10 times over 3 sessions, resulting in 11,428 cells analyzed. Cells with low trial-to-trial correlation were excluded, and a minimum correlation threshold of 0.1 was applied for analysis. The study analyzed neural responses to stimuli using calcium imaging and electrophysiological recordings. Cells were split into 1s epochs, and the mean change in calcium fluorescence response was calculated. The majority of cells showed log-normal or Gaussian distributions, with some exhibiting dropout-like patterns. A similar analysis was done on units from a neural network trained on CIFAR-10, revealing the use of dropout as a Bayesian approximation. The study analyzed neural responses to stimuli using calcium imaging and electrophysiological recordings. Cells showed log-normal or Gaussian distributions, with some exhibiting dropout-like patterns. Two-component Gaussian mixtures can capture network responses with dropout. Eye movements can drive variability in primate neurons, but mice in head-fixed experiments had stable eye positions. The study found that eye positions were stable during the experiment, with no significant correlation between eye position and neural activity. Differences in response distributions were not attributed to eye movements. Gaze position could be used as an additional signal in predictive models of neural responses. The study conducted in vivo recordings in the visual cortex of awake, head-fixed mice using Neuropixels probes. Spike data was acquired with a 30-kHz sampling rate and processed with filters before spike sorting. Spike times and waveforms were extracted using Kilosort2. Noise waveforms were filtered out using a random forest classifier trained on the data. After filtering noise waveforms with a random forest classifier, 936 units were packaged into Neurodata Without Borders format for analysis. State-dependent changes in neural activity were controlled for using a population coupling model. Majority of cells were better fit by log-normal distributions or Gaussian mixtures for trial-to-trial variability analysis. Mimicking in-class exemplar changes, 10 nonoverlapping 200 ms sections were randomly chosen from 11 movie clips. The neural activity for each of the 11 movie clips is analyzed by defining signal, noise, exemplar coding subspace, clip coding subspace, and clip variance subspace based on spike counts and averages over trials. The noise subspace is defined as the set of neurons with noise larger than its standard deviation. Measures allow us to measure alignment between subspaces. Distance measure quantifies alignment, with smaller distances being more aligned. Noise for an exemplar in clip k 1 should lie in the clip k 1 variance subspace. This allows noise to move along representations of different exemplars in the same clip for generalization. The distance between noise subspace for exemplars in clip k 1 is smaller compared to clip k 2 variance subspace, indicating better alignment with in-clip variations. Noise aligns with clip coding and exemplar coding subspaces. Analysis conducted on mice and visual areas with at least 20 reliable neurons showed statistically significant differences in alignment. Random shuffling of exemplar identity showed no differences, suggesting greater alignment between clip variance subspace and noise subspace for exemplars in the same clip. The paper discusses the use of dropout as a regularization technique to prevent model overfitting and reduce feature coadaptation. It explores non-Gaussian distributions in neural responses and how trial-to-trial noise aligns with different neural subspaces. Future research will focus on how subspace-aligned noise can help deep neural networks generalize better from fewer examples. In the paper, trial-to-trial noise aligns better within the same clip than across different clips. Research on biological noise structure can aid in training neural networks for improved generalization. Various noise distributions were fitted using different models, with Poisson and negative binomial distributions used for electrophysiological data. The Akaike information criterion was employed for model selection. We used a bootstrap parametric cross-fitting test with N = 10,000 samples to determine the significance of the two-component Gaussian mixture model fits. For cells best fit by the two-component Gaussian mixture, we performed an additional test to determine whether their response distributions were dropout-like. Cells with z-scores less than two were counted as having dropout-like response distributions. We isolated each neuron and clustered the activity of the other neurons into 100 clusters using agglomerative clustering. We clustered neuron activity into 100 clusters using agglomerative clustering with Pearson correlation coefficient. Neurons were used as predictors for single-trial activity, fitting a generalized linear model. Single-trial activities were split for training and testing, with residuals calculated for each neuron. Gaussian mixture models were used to quantify neural responses across trials. We fitted Gaussian mixture models with one or two components to neural response distributions using the scikit-learn package. A bootstrap parametric cross-fitting test with 10,000 samples determined the significance of the two component model fits. Comparison with convolutional neural networks was also performed using a simple network trained on the CIFAR-10 image dataset. The analysis was conducted on a set of 118 natural images in the Allen Brain Observatory. The study analyzed neural responses to natural images using a convolutional neural network with dropout during evaluation. The bimodal distribution in neural responses was captured by the network. Response reliability was quantified at the population level using mean trial-to-trial correlation of neural activity. The study analyzed neural responses to natural images using a convolutional neural network with dropout during evaluation. Response reliability was quantified at the population level using mean trial-to-trial correlation of neural activity, with a mean reliability of 0.11 across sessions. Cells with dropout-like response distributions were identified using Gaussian mixture models. Additional analyses were conducted to determine the fraction of cells with dropout-like response distributions across visual areas, layers, and transgenic mouse lines. The study found a high and relatively constant fraction of cells with dropout-like distributions, with the lowest fraction in superficial layers. Consistent results were observed across all Cre-lines, which labeled excitatory cells in different cortical areas. The study found a high fraction of cells with dropout-like response distributions across visual areas and layers in transgenic mouse lines. Consistent results were observed across all Cre-lines, selectively labeling excitatory cells in different cortical areas and layers. Cumulative distributions for similarity metrics using data aggregated across areas for two mice showed statistically significant differences. Figure 10 shows cumulative distributions for similarity metrics using data aggregated across areas for mouse 3, comparing various subspaces with noise subspace N j,k,n. All observed differences are statistically significant (KS test, p < 0.05)."
}