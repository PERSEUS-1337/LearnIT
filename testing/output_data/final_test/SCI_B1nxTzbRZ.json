{
    "title": "B1nxTzbRZ",
    "content": "In this paper, a defogger model is introduced to predict future hidden information from partial observations in the context of forward modeling using convolutional neural networks and long short-term memory networks. The model is evaluated on human games of StarCraft: Brood War, outperforming rule-based baselines and producing sensible future game states. The focus is on joint state estimation and next-state prediction in partially observable environments with complex dynamics, specifically in the real-time strategy game StarCraft. Forward modeling is crucial for predicting future events in such environments. Modeling is essential for reactive control and long-term planning, with researchers focusing on algorithms for future prediction in video and robotic planning. Forward modeling faces challenges in dealing with uncertainty due to partial information. In RTS games like StarCraft, players must manage an economy and units on a grid, facing limitations like the \"fog of war\" and complex interactions among agents. In this paper, the task is to uncover hidden information and predict the next state in a complex environment where agents interact. A StarCraft Defogger is presented to predict game features at different levels of granularity, such as opponent buildings and army density. The goal is to learn a forward model of the environment using observational data. In this paper, a deep architecture of stacked long short-term memory cells is proposed to predict the full state of the environment at different spatial resolutions. Trained on a large dataset of human replays, the model significantly outperforms rule-based baselines on several metrics. The goal is to infer hidden information from partial observations in order to make use of the inferred values directly or to decide what subsequent information to gather. This is achieved through a forward model that leverages the spatio-temporal structure of the game StarCraft. The text discusses leveraging the spatio-temporal structure of the game StarCraft to infer hidden information from partial observations. Research on imperfect information games like StarCraft and Poker has led to AI advancements. Forward models are used for video frame prediction and feature space prediction. In control theory, various methods were proposed for optimal filtering of stochastic systems. Forward models are used in deep reinforcement algorithms for games like Atari and StarCraft to estimate combat outcomes and plan in games like Sokoban and MiniPacman. \"Defogging\" aims to recover the whole state from partial observations in imperfect information games like RTS games. Defogging in Real-Time Strategy games involves deriving the full game state from partial player observations, posing challenges in remembering all shown information. This task differs from classical settings where only diffusion or branching moments are known. In Real-Time Strategy games, defogging requires remembering all shown information, reasoning about memory, applying inference steps, leveraging observation correlations, avoiding overfitting, and dealing with computational burdens. Abstractions are needed for model training and evaluation to make the task tractable. Defogging in Real-Time Strategy games involves estimating opponent states efficiently to reduce computational costs and gather information effectively. Human players exhibit theory of mind, enabling a game theoretic approach. Algorithmic defoggers could support a strategic view of RTS games. Our approach for the defogging problem in RTS games involves using an encoder-decoder architecture to estimate opponent states. We focus on reconstructing a coarse representation of the opponent's state, including the number of units and their types and locations on the map. This is achieved by splitting the map into grid cells and computing unit counts and unit type presence in each cell. Two types of loss functions are considered for parameter estimation. The approach for the defogging problem in RTS games involves using an encoder-decoder architecture to estimate opponent states by considering two types of loss functions for parameter estimation. The model encodes input data with a ConvNet, applies temporal inference and memory with recurrent neural networks, and decodes the output with another ConvNet. Regression and classification heads are then applied to the decoded vectors before 2D spatial pooling for classification. In practice, the state space is downsampled into unit counts per type in evenly spaced blocks. Different models use spatially sum-pooled tiles of varying sizes. The feature map includes time and unit information for both own and enemy units. To produce coarse frame predictions in a game state, frames are combined instead of skipped to capture key information during scouting. Units are featurized by their last seen location in a set of frames, downsampled with a step of s frames. The opponent faction and map layout are essential for predicting unit types accurately. The map layout and faction are crucial for predicting unit types accurately. A ConvNet is used to process map-specific features like walkability, buildability, and starting locations. Various models were considered, and a search through model space was conducted to find the most effective ones, using random hyperparameter search and manual guided searches. The study conducted random and grid searches to optimize hyperparameters for models predicting unit types accurately based on map features. Grid sizes of 32x32 and 64x64 were tested, with time skips of 5 and 30 seconds. The dataset was fixed to predict minutes 3 to 11 to focus on the most interesting parts of the game openings. Various model specifications were explored, including vanilla ConvNets. Different model specifications were explored, including vanilla ConvNets and conv-lstm encoders with recurrent connections. The encoder recurrent layer was tiled one after the other, with downsampling and replicated recurrent layers. The decoder was always another ConvNet with hyperparameters and activation functions similar to the encoder, without LSTMs. Padding was set to half the kernel size for producing one output tile per layer. In the search for optimal hyperparameters, various options were explored including different optimizers, loss functions, activation functions, and model architectures. Gated convolutions performed well, while residual blocks did not show improvement. Adam optimizer was found to be more robust and faster converging than SGD. The conv-lstm model was identified as the most robust across different tasks. The conv-lstm model was found to be the most robust across tasks, outperforming simpler models due to its ability to handle long term dependencies. The pooling layer in simpler models caused information loss, making them less effective. The striding model and conv-only model were also sensitive to hyperparameters. Results were reported with different loss functions and model architectures, with the conv-lstm model showing promising results with varying depths. The study implemented conv-lstm models with varying depths for analyzing StarCraft: Brood War games. Different metrics were used to measure model performance on strategy and tactics prediction tasks. The dataset included 65k human games at a high skill level, and the models were implemented in PyTorch using TorchCraft BID16. In strategy and tactics prediction for StarCraft: Brood War games, the focus is on predicting opponent buildings and enemy unit locations. The challenge lies in defining the fog of war for predicting hidden enemy units. To minimize miscounts of hidden units, four metrics are used, with all but one measured per type per tile. In strategy and tactics prediction for StarCraft: Brood War games, the focus is on predicting opponent buildings and enemy unit locations. Four metrics are used to measure existence of opponent buildings, hidden units, opponent units, and absolute difference in enemy unit counts. These metrics are cross validated per model. The absolute difference metric is calculated on true positives of the model by subtracting the best baseline from each model score. The lowest best baselines are displayed to compare the models, with more negative values indicating better performance than baseline. Different baselines are used for each model to provide an order of magnitude comparison. The models are validated against hard-coded baselines similar to those used in StarCraft: Brood War competitions. Our models are compared against four different baselines in StarCraft: Brood War competitions - Input, Perfect Memory (PM), Perfect Memory + rules (PM+R), and Previous Seen (PS). These baselines rely on past information and game rules to predict unit locations. Our models aim to outperform these baselines by learning a correlation model on the units. Our models aim to outperform baselines in StarCraft competitions by learning a correlation model on units and buildings type, remembering past information, and understanding unit movement dynamics. Scores are reported on different grid sizes and time steps. Model predictions show the ability to predict opponent unit locations and remember opponent base and army locations. The model predicts opponent unit locations and remembers opponent base and army locations by obtaining existence thresholds from regression output and finetuning the probability of predicting global opponent building existence. The best thresholds are reported on the test set based on validation set results, with most models showing higher recall than the baseline. Our models excel in predicting opponent buildings 30 seconds in the future, especially on unit prediction. Understanding game dynamics and player strategies is crucial for accurate unit prediction. Coarser grid sizes make unit movement prediction easier, with better results when predicting closer in time. We achieve a 24% improvement in F1 for hidden opponent units 15 seconds ahead on a grid size of 32, and a 19% improvement in predicting all opponent units. Our models show higher precision and beat baselines significantly in all unit prediction tasks. Predicting opponent units 15 seconds in the future with a grid size of 32 is most useful for tactical movements. Predicting at a grid size of 64 is harder due to visibility issues. Our models demonstrate better memory usage and are able to remember and \"forget\" objects based on their visibility and previous positions. Our models outperform baselines significantly in all unit prediction tasks, with fewer mispredictions compared to baselines. The baselines show poor performance in regression tasks compared to classification, with mispredictions adding up over the length of the game. The L1 score over true positives is used to compare outputs of our models to baselines. Our models outperform baselines significantly in all unit prediction tasks, with fewer mispredictions. The absolute difference metric is measured on true positives only, subtracting the best baseline. More negative values indicate better performance than baseline."
}