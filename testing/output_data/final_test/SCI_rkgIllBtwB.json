{
    "title": "rkgIllBtwB",
    "content": "Among deep generative models, flow-based models, or \\emph{flow}s, are known for providing tractable likelihood. Flows are considered robust against out-of-distribution inputs, but there have been observations that flows trained on FashionMNIST assign higher likelihoods to OoD samples from MNIST. This raises concerns about the robustness of flows' likelihood. The correlation between flows' likelihood and image semantics is explored in this paper using Glow and pixelCNN models. Surprisingly, there is a weak correlation between flows' likelihoods and image semantics, as trivial transformations can heavily affect predictive likelihoods. The predictive likelihoods of flows can be influenced by semantic-invariant transformations (SITs), such as image pixel translation, random noise perturbation, and latent factors zeroing. These findings suggest that flows' likelihoods do not accurately reflect high-level image semantics, cautioning against using them for out-of-distribution sample detection. Deep generative models have shown success in image and natural language generation. Generative adversarial networks (GANs) and variational auto-encoders (VAEs) are two types of generative models used in image and natural language generation. GANs do not require an explicit likelihood function and are trained through a minimax game between the discriminator and generator. VAEs are optimized by maximizing a lower bound of the data log-likelihood. Flow-based models differ from GANs and VAEs by providing exact log-likelihood evaluation through transformations to approximate complex distributions. Flow-based models use neural networks to approximate complex distributions by efficiently computing the log-determinant of their Jacobian. Previous works focus on designing flexible transformations for tighter log-likelihoods and generating realistic samples. Flows are believed to detect out-of-distribution samples but have been observed to fail in doing so, such as assigning higher likelihoods to MNIST samples in FashionMNIST-trained flows. The reasons behind this counter-intuitive behavior are still unclear. In this paper, the correlation between flows' likelihoods and image semantics is empirically explored for out-of-distribution (OoD) detection. A concept of semantic-invariant transformation (SIT) is introduced to maintain high-level image semantics. Two flow-based models, Glow and pixelCNN, are evaluated on MNIST and FashionMNIST datasets under different SITs. The study evaluates image datasets MNIST and FashionMNIST using semantic-invariant transformations (SITs) like image translation, random noise perturbation, and latent factors zeroing. It shows weak correlation between predictive likelihoods of target models and image semantics, with small pixel translations and perturbing random noises leading to significant likelihood decreases. The latent variables in invertible flows like Glow are gaussianized and standardized, with block contributions to log-likelihood being constant and independent of inputs. The study highlights that small pixel-level modifications on test images, such as image translation and random noise perturbation, can significantly decrease the likelihood of target models. Invertible flows like Glow have constant block contributions to log-likelihood, but these transformations may lead to inconsistencies in likelihoods on test samples. This raises concerns about using flows for downstream tasks requiring metrics reflecting image semantics, such as Out-of-Distribution (OoD) detection. Flow-based models are generative models constructed by transforming a simple base distribution with invertible functions. Research on flows is active, focusing on designing efficient invertible transformations for high-dimensional data like images. This paper specifically examines flow-based generative models on images and their likelihood behaviors. Flow-based generative models on images can be categorized based on the granularity of transformation layers. Affine coupling, as seen in Real NVP, uses a lower triangular matrix for efficient computation. Additive coupling, like in NICE, is a simpler version that is volume-preserving with a constant log-determinant Jacobian. Glow enhances Real NVP by replacing shuffling permutation with invertible convolution. Coupling flows offer equally efficient likelihood evaluation and sampling. Autoregressive flow serves as the foundation for autoregressive flow models. Autoregressive transformations model joint probability efficiently by conditioning on previous observations. PixelCNN uses masked convolutional layers for parallelization, enabling faster likelihood evaluation. Flows like PixelCNN can be combined with other generative models for generation. Variants of PixelCNN, such as PixelGAN and PixelVAE, are used for modeling audio, video, and text. PixelCNN combined with attention is applied to few-shot autoregressive density estimation. Autoregressive models like MADE, IAF, and MAF are used for general-purpose density estimation. IAF and MAF are flow-based generative models with different computational trade-offs. IAF focuses on efficient sampling to improve VAE's approximate posterior, while MAF is a powerful density estimator using multiple MADEs. Semantic-Invariant Transformation (SIT) aims to preserve image semantics through various transformations like image translation and noise perturbation. Translation invariance is a key property in learning image representations for downstream tasks. The study evaluates the impact of image translations on the likelihoods of flows, showing that even small translations can significantly affect the likelihood of Glow. The evaluation is based on bits-per-dim (BPD), where lower BPD indicates higher likelihood. The results demonstrate the importance of considering translation invariance in image representations. The study evaluates the impact of image translations on the likelihoods of flows, showing that even small translations can significantly affect the likelihood of Glow due to differences in architecture. Glow relies on multi-scale modeling with coupling transformation layers, while PixelCNN is robust to pixel translation. Glow's squeeze operation at higher scale levels trades spatial sizes for channel sizes, leading to different spatial partitions with 1-pixel translation. The likelihoods of flows can be significantly affected by image translations, with Glow being sensitive to small translations due to its multi-scale modeling approach. In contrast, PixelCNN is robust to pixel translation. Likelihood-based models for OoD detection may assign higher likelihoods to OoD samples than in-distribution samples, potentially due to similarities in dataset statistics. Counter-intuitive likelihood assignments occur in in-distribution datasets, where images with class label 1 consistently have higher likelihoods. This challenges the assumption that higher likelihood indicates in-distribution samples, suggesting differences in pixel-level statistics play a role. In in-distribution datasets, counter-intuitive likelihood comparisons exist not only between in-distribution and OoD samples, but also within in-distribution samples from different classes. Theis et al. (2015) found that a 1-pixel shift in images could lead to different nearest neighbors from the training set, demonstrating a gap between pixel-level metrics and human perception. Real-valued uniform noise is added to dequantize image pixels, and random perturbations can be added to only the backgrounds of test images using a proper mask. Unit Gaussian noises are used in evaluations with a scaling factor of 0.001. In evaluations, unit Gaussian noises with a scaling factor of 0.001 are used. Adding small noises drastically reduces samples' likelihoods, especially in PixelCNN due to its pixel-wise modeling. Even when noises are added only to backgrounds, similar results are observed. Different types of noises were tested, all showing that models do not differentiate between object and background pixels. The Glow architecture consists of modules at different scale levels, starting with a squeeze operation followed by step flow blocks. These blocks include actnorm, invertible 1x1 convolutional layer, and coupling layer. The log-determinants of actnorm and 1x1 convolutional layer are input-independent. The additive coupling layer is volume-preserving with a log-determinant of 0. The Glow architecture includes modules at different scale levels, with additive coupling layers being volume-preserving and input-independent. Affine coupling layers have a small impact on performance. The intermediary tensor is split and processed to reduce computation and memory usage. The cumulative log-determinant of flow blocks remains constant within a scale-level in Glow using additive couplings. The latent variables z of input images in Glow influence log-likelihood. Affine coupling layers in Glow are minimally affected by varying latent variables. Samples with higher likelihoods can be generated by manipulating latent variables. The last latent factor z L heavily influences the semantic object of a test image. The latent variables in Glow influence log-likelihood, with the last latent factor heavily impacting the semantic object of test images. Zeroing the first latent factor results in the maximum increment of likelihoods. Small perturbations, including SITs and adversarial examples, can decrease testing accuracies of classifiers to some extent. Likelihood-based generative models can assign higher likelihoods to out-of-distribution samples, making them vulnerable to adversarial attacks. Discriminative classifiers are known to be easily fooled by specific image transformations, while generative models aim to model every pixel of an image for robustness. However, likelihood modeling in high-dimensional space can lead to unexpected results. Nalisnick et al. (2018) found that the change-of-variable theorem applies to both flows and VAEs, regardless of volume preservation. Ren (2019) discovered that image likelihood is influenced by irrelevant background pixels, proposing a remedy with a likelihood ratio. This raises questions about the correlation between likelihood ratio and high-level semantics. The paper explores the correlation between likelihood of flow-based generative models and image semantics, showing weak correlation. This raises concerns about using likelihood-based generative models for downstream tasks like OoD samples detection. The likelihood of flow-based generative models may not closely relate to image semantics, raising concerns for OoD samples detection. Flows' predictive likelihood is based on joint probabilities of image pixels, making them susceptible to small pixel-level modifications that can significantly decrease image likelihoods. The likelihood of flow-based generative models may not closely relate to image semantics, raising concerns for OoD samples detection. Flows' predictive likelihood is based on joint probabilities of image pixels, making them susceptible to small pixel-level modifications that can significantly decrease image likelihoods. For downstream tasks, modeling likelihood in a semantic space or with perceptual metrics rather than raw pixels is suggested. Implementations of Glow and PixelCNN in Pytorch 1.0 are used, with modifications from PixenCNN++ incorporated. Unconditional and conditional versions of Glow are implemented, with conditional Glow results reported in experiments. In experiments, Glow with a multi-scale architecture and 5 levels achieves lower BPDs by resizing images to 32\u00d732. Pretrained models for MNIST are provided. PixelCNN, unlike Glow, treats pixels as intensity levels and may have dangling levels when resizing to 32\u00d732. Image translation experiments show BPD decreases with 1 or 2-pixel translations on PixelCNN(32\u00d732)."
}