{
    "title": "rJx1Na4Fwr",
    "content": "In this paper, the MACER algorithm is introduced as a method to train robust models without adversarial training, outperforming existing l2-defenses. MACER focuses on maximizing the Certified Radius for attack-free training, making it faster and easier to optimize. Experimental results demonstrate its effectiveness on various datasets with modern neural networks, achieving larger certified radius with less training time compared to adversarial training algorithms. Modern neural network classifiers can achieve high accuracy on image classification tasks but are vulnerable to small adversarial perturbations. These perturbations can cause the network to misclassify an image with high confidence. Various defense methods, including adversarial training, have been proposed to improve the robustness of neural networks against such attacks. During training, methods learn adversarial examples with attack iterations to update model parameters. However, this approach is limited to specific attack methods and slow due to expensive iterations. Another approach involves training robust models by maximizing certified radius from robust certification methods. These methods compute a \"safe radius\" for a classifier at a given input to guarantee unchanged predictions within a neighboring radius. In this work, a scalable method is proposed to train robust deep neural networks by leveraging randomized smoothing techniques. The method aims to maximize the certified radius of the smoothed classifier to improve robustness without relying on expensive attack iterations. The proposed method, MACER, aims to train robust models by directly maximizing the certified radius without relying on expensive attack iterations. This approach is different from adversarial training and ensures numerical stability while considering both classification accuracy and robustness. MACER is a method that trains robust models by maximizing the certified radius without using attack strategies. It is faster than adversarial training and can be applied to any network size. Empirical evaluations show that MACER outperforms state-of-the-art algorithms on various tasks like Cifar-10, ImageNet, MNIST, and SVHN. It is also faster than adversarial training, with a 39% reduction in training time on ImageNet. In the context of training robust models, adversarial examples pose a significant challenge to neural networks. Various methods have been proposed to construct adversarial examples, both in white-box and black-box settings. Adversarial training has emerged as a successful method to improve network robustness against such examples. Adversarial training, proposed by Szegedy et al. (2013) and Goodfellow et al. (2015), improves model robustness by adding adversarial examples to the training set. Madry et al. (2017) formulated adversarial training as a min-max optimization problem, showing its effectiveness with PGD attack. Zhang et al. (2019b) decomposed robust error for better performance. Despite good empirical results, models from adversarial training lack certified error guarantees. Speed issues with PGD-based training have led to proposed acceleration methods like replaying adversarial examples multiple times in one iteration. Several defense algorithms have been proposed in recent years, but many are vulnerable to \"gradient masking\" attacks. It is crucial to assess the provable robustness of a network. Robustness certification algorithms aim to determine a \"safe radius\" for a classifier f and input point x, ensuring f(x) = f(x + \u03b4) for any \u03b4 \u2264 r. Various techniques such as convex polytope, abstract interpretation, and recursive propagation algorithms have been developed for this purpose. Recently, researchers have introduced a new class of certification methods called randomized smoothing, which utilizes randomization for defense. This method involves adding Gaussian random noise to the input or intermediate layers to compute a certified guarantee on small perturbations using differential privacy. In this paper, a new algorithm is proposed to train on certified error bounds for Gaussian smoothed models, aiming to reduce the certified error and enhance provable adversarial robustness. Previous works have focused on deriving tight lower bounds for neural networks to improve model robustness. The certified radius, denoted as CR(f \u03b8 ; x, y), is a lower bound of R(f \u03b8 ; x, y) for neural networks. It guarantees an upper bound on the 0/1 robust classification error, known as 0/1 certified robust error. This error is defined based on the certified radius reaching a certain threshold, serving as a performance metric for provable robustness. The randomized smoothing technique is utilized in this work to enhance model robustness. In this work, the randomized smoothing technique is used to obtain the certified radius of deep neural networks. The smoothed classifier g \u03b8 returns the label most likely to be predicted by f \u03b8 when sampled from a Gaussian distribution. The theorem by Cohen et al. (2019) provides an analytic form of the certified radius for provable robustness. The certified radius of a deep neural network can be estimated by sampling Gaussian noises, allowing for robust model learning. Previous works decompose the error to minimize robust classification errors, where a positive error occurs if the classifier misclassifies or is not robust enough. The classifier aims to be both correct and robust, with the error decomposed into classification and robustness errors. Surrogate losses are used to minimize these errors, ensuring they are upper bounds of the original error functions. The classifier aims to be correct and robust, with errors decomposed into classification and robustness errors. Surrogate losses are used to minimize these errors, ensuring they are upper bounds of the original error functions. The classification loss is the cross-entropy loss, while the robustness loss is the hinge loss on the certified radius. The hinge loss on the certified radius is used because it satisfies the surrogate condition and is numerically stable. The differentiability of the robustness surrogate loss requires differentiability of CR(g \u03b8 ; x, y). The randomized smoothing certified radius does not meet condition (C2), leading to the introduction of soft randomized smoothing. The certified radius's sub-differentiability with respect to \u03b8 depends on the differentiability of E \u03b7 1 {f \u03b8 (x+\u03b7)=y}. The expectation is theoretically differentiable but needs to be estimated practically using Monte Carlo sampling Gaussian noise. Soft randomized smoothing (Soft-RS) is used to address the non-differentiability issue in the estimation of the certified radius for neural networks. The soft smoothed classifier g \u03b8 is defined for a neural network z \u03b8 with a softmax last layer. The certified radius for provable robustness is calculated using the c.d.f. of the standard Gaussian distribution. This technique is an improvement over the original randomized smoothing method. Our method uses Soft-RS to obtain a certified radius that is differentiable in practice, meeting condition (C2) in the algorithmic design. Soft-RS is a differentiable approximation of Hard-RS, with the certified radius converging to the Hard-RS radius as \u03b2 approaches infinity. The Soft-RS method provides a differentiable certified radius that converges to the Hard-RS radius as \u03b2 approaches infinity. Appendix A outlines Soft-RS certification procedures using the Hoeffding or empirical Bernstein bound. Addressing numerical stability, optimizing the robustness loss (13) maximizes the robust radius without exploding gradients. The hinge loss ensures samples have non-zero robustness loss within a certain range. The MACER algorithm is presented, where expectations are approximated with Monte Carlo sampling and training involves minimizing a loss function. The algorithm includes hyperparameters like \u03b3 and \u03b2, and updates \u03b8 using first-order optimization methods. Adversarial training is compared to the mini-max game approach of MACER. The MACER algorithm optimizes the model update loop iteratively, running faster than adversarial training by not requiring additional back propagations for generating adversarial examples. Its objective function combines classification and robustness losses, similar to ALP and TRADES, with a trade-off factor \u03bb. However, MACER's robustness term is independent of a specific adversarial example, distinguishing it from ALP and TRADES. The algorithm is empirically evaluated on various tasks. The MACER algorithm is evaluated on different tasks, studying the impact of hyperparameters on model performance. Models are trained for specific epochs with defined parameters for each task. Different values of \u03bb are found to affect robust accuracy against noise levels. The MACER algorithm is compared with two previous works on ImageNet using specific parameters for training models. Baselines include training smoothed networks with cross-entropy loss and adversarial training for improved robustness. Certification of test set accuracy is reported based on the fraction of the test set that can be certified to be robust at a certain radius. The average certified radius (ACR) is used as a metric to compare models on Cifar-10 and ImageNet. Results for MNIST and SVHN can be found in Appendix C.2. Performance of different models on Cifar-10 is shown in Table 1, with radius-accuracy curves displayed in Figure 1. The area under the curve equals the ACR of the model, demonstrating the effectiveness of the proposed method. The proposed method consistently achieves higher certified test set accuracy compared to previous methods. Our model performs differently from Salman et al. when noise level is high. Experimental results on ImageNet also support the effectiveness of our algorithm. MACER trains faster without adversarial attacks, outperforming Salman et al. in terms of training speed. Empirically comparing MACER with Salman et al. (2019) on training time and total hours, MACER achieves higher performance in less time. Using one NVIDIA P100 GPU for Cifar-10 and four for ImageNet, MACER achieves ACR=0.544 in 117.90 hours, while Salman et al. (2019) achieves ACR=0.528 in 193.10 hours. Even when run for only 150 epochs, MACER still outperforms SmoothAdv and is 4 times faster. In this section, the effect of different hyperparameters in MACER is examined on Cifar-10 with \u03c3 = 0.25 or 0.50. Results for \u03c3 = 0.25 are shown in Figure 3. Increasing Gaussian samples (k) leads to better performance. The trade-off effect of \u03bb is demonstrated in the radius-accuracy curves. \u03b3, the hyperparameter in the hinge loss, affects the approximated certified test set accuracy. In MACER, the hyperparameter \u03b3 affects the certified test set accuracy at large radii. Increasing \u03b3 improves robust accuracy, acting as a trade-off between accuracy and robustness. A larger \u03b2 leads to better results, with the potential for training stability if applied only to the robustness loss. MACER is proposed as an attack-free robust training method that maximizes the certified radius of a smoothed classifier. MACER outperforms previous l2-defenses, trains faster, and suggests adversarial training is not necessary for robust training. Using unlabeled data can improve adversarially robust generalization. MACER will be extended to the semisupervised setting. Theoretical analysis and certification procedures for Soft-RS are provided, based on lemma and confidence lower bounds. The text discusses the certification procedure for Soft-RS using Hoeffding's inequality to calculate confidence lower bounds. Algorithm 2 outlines the process, showing that Hard-RS provides a larger robust radius bound compared to Soft-RS. The empirical Bernstein bound is tighter than the Hoeffding bound but looser than the Clopper-Pearson bound. The text discusses certification for Soft-RS using Hoeffding's inequality. Algorithm 2 shows Hard-RS has a larger robust radius bound. The empirical Bernstein bound is tighter than Hoeffding's but looser than Clopper-Pearson. Various models are compared in tables for Cifar-10 and ImageNet datasets. Table 8 shows the performance of MACER on Cifar-10 after 150 epochs, compared to SmoothAdv and MACER (440 epochs). Learning rate decayed at epochs 60 and 120. Experimental settings detailed in Table 9, with results in Tables 10-13."
}