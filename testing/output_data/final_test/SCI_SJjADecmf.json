{
    "title": "SJjADecmf",
    "content": "The fault diagnosis in modern communication systems is traditionally considered difficult for a purely data-driven machine learning approach due to the system's complexity. This paper proposes using labeled data from fault archives, unlabeled records from a live system, and simulated data to train a multi-headed neural network for transfer learning. The network consists of generators, discriminators, and a classifier to improve fault diagnosis accuracy. The multi-headed network is trained using an alternative approach for transfer learning, updating weights and refreshing layers. It achieves comparable accuracy in classifying TCP streams without expert features. This solution simplifies the work for operation engineers and provides a protocol-independent quick solution in telecommunications networks. The two linked nodes send messages in packets with headers to ensure correctness. Malfunctions in devices can cause issues in the network, such as packet loss or timeouts. Suspicious streams are sent for offline analysis, posing a challenge for automatic diagnosis. The primary challenge of automatic diagnosis in modern communication systems is the difficulty in formalizing all the logic for artificial intelligence. Constructing specific features from raw bytes to determine latent states of protocols can simplify subsequent classification tasks. For example, Transmission Control Protocol (TCP) relies on sequence numbers for packet order, which can be represented as large integers for machine learning models. Critical control bits may be hidden among irrelevant bits like checksum codes, adding noise for models. The challenge in automatic diagnosis in modern communication systems lies in formalizing AI logic and extracting specific features from raw data. The scarcity of labeled samples and the need for automation hinder the effectiveness of traditional and deep learning approaches in fault detection. In this paper, a generative model is used to extract features from two different data sources: labeled simulation data and unlabeled genuine data. The approach combines three data sources to address the small-sample problem in a simulation environment. The model consists of multiple simple Generative Adversarial Networks (GANs) components trained in an alternative optimization approach. The paper introduces a generative approach to solve the small-sample problem in a simulation environment by extending GANs to multiple players. It focuses on packet sequence classification in communication networks and discusses previous work in network anomaly detection. The model and algorithm details are presented, followed by experimental results and conclusions. Before 2012, popular machine learning methods were covered, but after that, the focus shifted to deep learning. The development of these methods has been centered on automation and model capabilities. BID4 trained neural networks on labeled data for anomaly detection, while BID0 explored the use of Self Organizing Map (SOM) in unsupervised scenarios. BID2 utilized online learning for quick adaptation to new attack samples, and BID11 employed self-taught learning to enrich datasets from unlabeled live streams. The enhancement of feature space for embedding is evident in both simple K-Nearest-Neighbors and neural network models. Various approaches have been used, such as PCA, Wavelet, Recurrent Neural Network (RNN), and self-taught learning with generative neural networks for semi-supervised and transfer learning. These methods have shown improvements in accuracy and classification results. The use of generative neural networks in semi-supervised and transfer learning is a novel approach. By employing a triple-player formulation, the model becomes more stable during training and can reflect relationships between multiple random variables. This method enhances the training process by addressing multi-class classification and enabling distribution estimation over all possible outputs. In the context of generative neural networks, BID8 and BID5 addressed mode collapse in GANs by training multiple generators and discriminators, respectively. The packet stream is a sequence of attributed events with timestamps and key-value pairs. Anomalies are classified into K classes, including one for normality. Anomalies can only occur on one side of communication to simplify the problem. Two individual models can be trained for both sides, with records from the client side removed. Timestamps are ignored, only the ascending index is kept. Dummy packets are inserted to denote timeouts between items. The number of dummy packets indicates periods of inactivity on the opposite side. The number of dummy packets inserted in packets is informative for models as it shows periods of inactivity on the opposite side. Different levels of feature engineering involve raw bytes, numerical values, and latent states defined in protocols. At level 1, a binary sequence is unreadable for humans. At level 2, it becomes a data structure without defined semantics. The array of structures can be organized into a multi-dimensional vector. At level 3, states are parsed out, leading to a categorical vector representation. NN can process all levels, but discrete values at level 3 require extra effort. A simplified FSM for a sender in TCP transmission involves shuttling between Ready and Listen states, with error handling for data transmission and acknowledgment packets. In TCP transmission, packet loss triggers a timeout for data resend. The N-dimensional sequence Y is generated by applying function G on vector z. Anomalies are switched by categorical variable c with parameters \u03b8. Adversary approach guides G training by minimizing distance between distributions p(Y, c) and observed p(Y, c) using binary discriminator Dr. Function Gs transforms Y. The text discusses the functions Gs and Ds in transforming data in a simulation world, along with the layout of building blocks in the solution. It mentions the sources of noise in the process and the optimization goal involving coefficients \u03bbs and \u03bbc. The text discusses the neural components and connections in Fig. 2, with information sinks connecting data sources and loss function parts. The graph G is connected, directed, and acyclic, allowing for a gradient descent approach in optimization heuristics. The trained G will be frozen for secondary training to provide the classifier C with consistent data. The neural components in Fig. 2 consist of various modules, including input, LSTM, fully connected, and classification layers. The generators G and Gs are built differently, while the discriminator D shares a common structure with Ds and Du. The discrete state sequence at feature level 3 can be mapped to continuous vectors globally. At feature level 3, discrete values can be mapped to continuous vectors globally using Word2vec during preprocessing. A heuristic guides the optimization process of G, as described in Algo. 1. During training iterations, the loss function contributing most is updated using gradient descent. RMSprop is preferred for components with recurrent layers. The real labeled data collected from fault cases at a wireless telecom site include 4 categories of problematic TCP streams. Historical records show unevenly distributed samples from these categories. Unlabeled data from the same site, with 2000 samples, is used for training but may not contain valid anomalies. The simulation in labs generates 5 types of anomalies with 400 records each, showing errors in uplink and downlink packets, throughput limits, and checksum errors. Synthetic data has fixed sequence lengths of 500, and data preprocessing on TCP headers involves compressing attributes into different states based on latent TCP states and raw binary records. The performance of a multi-class problem is evaluated using accuracy metrics, ranking possible causes based on model output. Two variations of accuracy are measured, emphasizing performance on minor classes. 3-fold cross-validation is used on real labeled data, with assistance from other datasets. The program is based on Keras 2 and a GAN library. The program utilizes Keras 2 and a GAN library for the train partition in each fold. It implements a one-to-many recurrent layer as many-to-many, with noise dimension X set to 20 and LSTM hidden dimension as 10. Various factors are combined into a model based on feature levels and data sources. Two referential models are provided for comparison in Tab. 1, including a dummy model and a simulation data model. The performance of the classifier is enhanced by deliberately amplifying anomalies and evenly distributing classes. Group 4\u223c5 shows that simulation data significantly improves accuracy by adding typical anomalies, while unlabeled data contributes slightly. Weighted accuracy improves significantly, more than twice that of a dummy model. Features play a crucial role, with level 3 outperforming level 1 and level 2 approximating the best performance with massive data. Loss evolution of 3 discriminators is shown in FIG2, and the classifier is depicted in FIG2. The loss curves of GANs' components converge to horizontal limits with fluctuations, but overall loss remains stable. Simulated data has smaller variances due to balanced distribution, while real data is imbalanced. Training stops at iteration 10^4, G is trained to obtain C with steady loss convergence. Semi-supervised and transfer learning requirements are implemented. The integrated semi-supervised and transfer learning approach using cooperative or adversarial neural blocks has shown effectiveness in packet flow classification. It suggests that complex machine learning tasks can be mapped into connected networks for optimization over an entire graph. Future work may explore applying this method to larger tasks and analyzing equilibrium existence in optimization processes."
}