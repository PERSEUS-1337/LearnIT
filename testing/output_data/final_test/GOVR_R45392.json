{
    "title": "R45392",
    "content": "The integration of robotics and autonomous systems (RAS) with artificial intelligence (AI) has the potential to revolutionize warfare by reducing risks to soldiers and Marines. AI offers broad applicability in military operations, improving supply lines, training, and intelligence gathering. Its effectiveness in combat operations is particularly promising, representing the next logical step in modern battlefield digitization and mechanization. The Department of Defense and the Services are pursuing robotics and artificial intelligence for various military applications, with a focus on the ethical considerations of authorizing machines to make lethal combat decisions. Discussions on the appropriateness, circumstances, responsibility for mistakes, and limitations of autonomous systems must guide future unmanned aircraft systems capabilities. The U.S. military is pursuing robotics and artificial intelligence for military applications, including unmanned aircraft systems. There is a proliferation of these technologies internationally, posing a potential threat to U.S. forces. Congress may need to address how the U.S. will respond to foreign advances in robotics and AI. The concept of Robotic and Autonomous Systems (RAS) encompasses integrated sensing, planning, and decision-making for machines capable of independent actions. RAS combines robotic and autonomous elements to perform tasks that typically require human intelligence. In the 115th Congress, bills defined AI and categorized AI systems based on rational thinking and human-like behavior. The John S. McCain National Defense Authorization Act for Fiscal Year 2019 includes a broad definition of AI as systems that can perform tasks independently, learn from experience, and exhibit human-like perception, cognition, and physical action. Artificial Intelligence (AI) encompasses systems designed to think or act like humans, including cognitive architectures, neural networks, and machine learning techniques. AI systems can be tailored to specific tasks (narrow AI) or designed to act rationally and achieve goals using various capabilities. The distinction between narrow and general AI is crucial in understanding the abilities of AI systems. Machine learning is a type of AI that allows systems to learn and improve from experience without explicit programming. It focuses on developing computer programs that can access data, learn from it, and make decisions based on patterns. The goal is for computers to learn automatically without human intervention. The curr_chunk discusses human-supervised autonomous weapon systems that can select and engage targets without further human input after activation. It also mentions the impact of RAS and AI on society and the workplace, citing a 2017 study by the International Bar Association's Global Employment Institute. The study highlights how modern information technologies and AI have influenced the world of work in the 21st century. The future world of work is uncertain due to advancements in technology like robots, intelligent systems, and algorithms. Questions arise about the role of humans in the workforce, potential mass unemployment, and the impact on the global labor market. The current legal framework may need to adapt to the changing industry landscape. The Fourth Industrial Revolution, driven by advancements in technology like robots and AI, will significantly impact the global labor market. Economic structures, job profiles, and working relationships will undergo major changes. Legislators are struggling to keep up with the rapid pace of technological advancements, leading to a growing gap between reality and the legal framework. Education systems and societies also face the challenge of adapting to the new demands of the evolving technology. The Fourth Industrial Revolution, driven by advancements in technology like robots and AI, will impact the global labor market. CPS refers to network connections between humans, machines, products, objects, and ICT systems. Over 50 billion connected machines are expected worldwide in the next five years. AI in the service sector distinguishes the fourth industrial revolution. Examples include 'smart factories', driverless cars, delivery drones, and 3D printers producing complex items without human intervention. The Fourth Industrial Revolution, driven by technology advancements like robots and AI, will impact the global labor market. Examples include networking platforms like Facebook, Uber, and Airbnb, as well as car sharing services. Studies show a twentyfold growth in the sector due to sharing services. The U.S. military, particularly the Army and Marine Corps, are directed to invest in autonomy, artificial intelligence, and machine learning for competitive advantages. The Army and Marines are directed to pursue robotics and artificial intelligence (AI) to gain competitive military advantages. The shift in focus from counterinsurgency to strategic competition with revisionist powers like China and Russia has led to an emphasis on developing RAS and AI technologies. Russia is aiming to shape the world according to their authoritarian model, gaining veto power over other nations' decisions. The Army is focusing on preparing for conventional ground combat through modernization, including autonomous systems, artificial intelligence, and robotics. Other countries are also advancing in autonomy technology, surpassing the United States. The future of autonomous weapons is influenced by conversations in U.S. research labs and other nations' advancements in autonomy technology. Secretary of the Army Mark Esper highlighted the importance of being the first in robotics and AI for battlefield advantage. RAS and AI are predicted to change the nature of work and workforce design, with potential military applications in transportation, logistics, manufacturing, healthcare, and engineering. The military and ground forces can readily adapt technologies from health care and engineering, which would likely face little international opposition as they do not fall into the category of autonomous weapons. Studies on the impact of AI and automation on the workforce show that predicting these impacts is challenging, even for experts in the field. According to a study by Pew Research Center, 48% of experts predict that AI and robots will displace more jobs than they create by 2025, while 52% predict the opposite. The range of methodologies used in these studies makes comparisons difficult, raising questions about the impact on civilian and military workers. These questions include whether AI and robots will replace certain skills or entire jobs, and what new roles these technologies will fill. If skills are automated, employees may have opportunities to upgrade their skills, but if entire jobs are eliminated, employers may be hesitant to maintain their workforce and invest in re-skilling employees. The pace of innovation and adoption of AI and RAS technologies may significantly impact the workforce and labor policies. These technologies are developing rapidly, with the ability to replace both physical and cognitive labor. Concerns have been raised about automation displacing middle-class workers, but the implementation of AI systems on existing hardware could lead to more disruptive changes in the labor market. The widespread adoption of AI and RAS systems may outpace changes to labor policies, leading to a shortage of experts in the workforce. This could impact both public and private sectors, with implications for military organizations as well. New technologies may automate tasks currently performed by soldiers, similar to how civilian business leaders are using automation and AI to shift human workers to different roles. The adoption of new technologies like robotics, AI, and human augmentation will drive the creation of new military personnel models and ground force structures. This could lead to fewer soldiers and Marines, impacting the defense budget in various areas such as military compensation, logistics, construction, and healthcare. Advances in technology have also provided military planners with real-time data, cutting through the \"fog of war.\" The existing analyst community faces challenges with a high volume of data, leading to backlogs for translators and image interpreters. Analysts must integrate data from various platforms and sensors to ensure accurate situational awareness. Workstations have multiple screens with different tools, applications, and databases from different vendors, making it difficult for sailors to master all functions. Automated systems and AI can assist military analysts in processing large data sets. The speed of machines surpasses human processing capabilities, posing a challenge for decision-makers in time-sensitive military situations. The increasing capabilities of automated systems and AI in military operations are acknowledged, with experts recognizing the limitations of human control. As technology advances, machines are becoming faster and more autonomous, leading to the prediction that future military superpowers will rely heavily on autonomous capabilities. These advancements can be particularly valuable in scenarios where human intervention is insufficient, such as dealing with unmanned vehicles or hypersonic weapons. It is expected that military forces will adopt selected RAS and AI technologies from the private sector to enhance their effectiveness in logistics, data analysis, and training. RAS and AI technologies will be adopted by militaries to enhance institutional and operational effectiveness, improving troop performance and unit capabilities. AI can be used for planning, decision support, and automated weapon systems for protection against various threats. These technologies also have potential in reducing physical risks to soldiers and Marines in missions like explosive ordnance disposal and obstacle breaching. In high-risk military operations like explosive ordnance disposal, route clearance, and CBRN reconnaissance, RAS and AI technologies are expected to limit troop exposure to hazards. A future combat battlegroup may consist of as few as 250-300 human soldiers and several thousand robotic systems. This shift could potentially reduce the size of artillery and combat engineer units by hundreds of personnel, allowing for redeployment into other areas. The Army is considering replacing the M-2 Bradley-series infantry fighting vehicle with an Optionally-Manned Fighting Vehicle (OMFV) that can be operated remotely. This could raise concerns about vulnerability if the remote control fails. RAS and AI technologies have various applications in training and educating troops, leading to improved efficiency and potential cost savings. The Army is exploring the use of RAS and AI technologies for various applications, including military warehouse and depot functions, logistics automation, predicting equipment failures, and treating wounded soldiers. These technologies offer the potential for increased efficiency, cost savings, and freeing up personnel for other tasks. The Army is considering using RAS and AI for various applications, including treating wounded soldiers. Potential operational concepts include saturating an area with autonomous systems to detect and target adversaries, and using autonomous systems to attack enemy capabilities before introducing ground forces. Defensive countermeasures may also be necessary against adversaries using RAS and AI. The use of RAS and AI in military operations could render current military platforms obsolete and change how soldiers are recruited, trained, and retained. This shift may displace lower-ranking soldiers and require a reevaluation of traditional career structures in the Army and Marine Corps. Additionally, it could lead to increased competition with the private sector for skilled recruits and potentially result in fewer opportunities in the U.S. The use of RAS and AI in military operations may displace lower-ranking soldiers and require a reevaluation of traditional career structures in the Army and Marine Corps. Potential adversaries could aggressively develop autonomous weapons, leading to the need for the Army and Marines to develop new systems and tactics. The Chinese government and Russian President have expressed ambitions in artificial intelligence. Armed robots are being deployed by various countries, including South Korea, Israel, Russia, and Shiite militias in Iraq. This poses a threat that the Army and Marines may need to counter with new systems and tactics. Shiite militias in Iraq, criminal groups, and nations like Russia are utilizing armed ground robots and unmanned aerial vehicles for military purposes. Russia aims to have 30% of its combat power consist of remotely controlled and autonomous robotic platforms by 2030. The Vikhr unmanned ground combat vehicle (UCGV) is based on the BMP-3 infantry fighting vehicle (IFV) and is armed with a 30mm automatic cannon, a 7.62mm machine gun, and anti-tank guided missiles. It can be reconfigured with various weapons, including an anti-aircraft cannon, heavy machine gun, naval automatic cannon, surface-to-air missiles, and flame throwers. The Vikhr can also integrate foreign artillery systems and carry mini unmanned aerial vehicles for surveillance. Russia has developed the Vikhr unmanned ground combat vehicle (UCGV) based on the BMP-3 infantry fighting vehicle, armed with a 30mm automatic cannon, a 7.62mm machine gun, and anti-tank guided missiles. The Uran-9 is a smaller robotic tank with various weapons, including a 30mm cannon, ATGMs, surface-to-air missiles, and a machine gun, and can be remotely controlled up to 3 kilometers. Russia tested the Uran-9 in Syria for mine clearing and force protection operations. The Russian Ministry of Defense is actively pursuing AI development. The PLA in China is focused on developing AI for military purposes, aiming to reshape warfare with intelligentized systems. Lt. Gen. Liu Guozhi emphasizes the need to embrace disruptive technology to avoid being disrupted, leading to a military revolution. The PLA in China is focused on developing AI for military purposes, aiming to reshape warfare with intelligentized systems. The CMC Joint Staff Department has called for leveraging AI in planning, decision support, and operational command. China has developed unmanned systems with stealth, swarming, and hypersonic capabilities for military applications, including a persistent presence in disputed waters or territories. This poses a multifaceted challenge to the U.S. military. China's national goal is to acquire foreign technology for military advancement, including AI and UAV technology. This poses challenges for the U.S. military due to the presence of foreign nationals in academic institutions. South Korea has developed the Samsung SGR-A1 robot sentry for border defense, which faced criticism for its autonomous capabilities. South Korea's SGR-A1 robot sentry, costing $200,000 each, is deployed in the Korean DMZ with machine guns or grenade launchers, equipped with cameras and radar for intruder detection. The Brimstone missile, used by the Royal Air Force, can be laser-guided or operate in a \"fire and forget\" mode, targeting ground vehicles or boats. Saudi Arabia has acquired the Brimstone missile for military use. The Brimstone missile, used by the Royal Air Force and acquired by Saudi Arabia, is an exportable, semi-autonomous weapon system that may require countermeasures by U.S. ground forces. Army and Marine efforts in robotics and artificial intelligence are governed by various policies and organizations, including the Office of the Secretary of Defense's Unmanned Systems Integrated Roadmap. The DOD's strategic vision for unmanned systems aims to reduce duplicative efforts, enable collaboration, and capitalize on technology advancements. The OSD's Unmanned Systems Integrated Roadmap focuses on interoperability, autonomy, secure networks, and human-machine collaboration, addressing cyber operations, information assurance, electromagnetic spectrum, and electronic warfare. The Joint Concept for Robotic and Autonomous Systems (JCRAS) outlines integrated human-RAS employment by the Joint Force by 2035. The DOD's 2016 JCRAS outlines the future use of integrated human-RAS teams by 2035, emphasizing human responsibility in military actions. DOD Directive 3000.09, Change 1, May 8, 2017, establishes policies for autonomous and semi-autonomous functions in weapon systems to minimize unintended engagements. The DOD's directive on autonomous weapon systems emphasizes human judgment over the use of force, restricting the development of fully autonomous systems. General Paul Selva advocated for keeping this restriction to uphold values in war. The 2018 Department of Defense Artificial Intelligence Strategy focuses on integrating AI while maintaining military advantage. The Department of Defense established the Joint Artificial Intelligence Center (JAIC) in June 2018 to deliver AI-enabled capabilities to the Joint Force. The Army has multiple organizations involved in Robotics and AI efforts, with key management roles at the Army level and major command level. Army Futures Command (AFC) was stood up in July 2018 to establish unity of command and effort. The Army established the Army Futures Command (AFC) to consolidate the modernization process. AFC will play a major role in managing the Army's Robotics and Artificial Intelligence (AI) efforts. The Army also created the Army Artificial Intelligence Task Force under AFC to lead AI efforts and support DOD projects, primarily based at Carnegie Mellon University. The task force aims to achieve initial operating capability at Carnegie Mellon University in early November 2018. The Marine Corps is involved in Robotics and Autonomous Systems (RAS) and Artificial Intelligence (AI) efforts, with different organizations handling various aspects. The Marine Corps Combat Development and Integration Command (CDIC) develops concepts, the Marine Corps Warfighting Laboratory focuses on scientific and technological development, and the Marine Corps Systems Command (MCSC) handles acquisition. The Army also has its Robotics and Autonomous Systems Strategy, aiming to increase situational awareness through advancements in RAS for surveillance and reconnaissance in challenging terrains. The Marine Corps is involved in Robotics and Autonomous Systems (RAS) and Artificial Intelligence (AI) efforts. RAS aim to increase standoff distances, lighten soldiers' workloads, facilitate decision-making, and enhance logistics distribution. Investments in Anti-Access/Area Denial (A2/AD) capabilities allow future enemies to engage Army forces earlier and at greater distances, threatening movement. Future ground forces integrate joint, interorganizational, and multinational capabilities to achieve military objectives through forward presence and resilient battle formations. Army forces utilize Rapidly Advancing Systems (RAS) to extend the depth of operations, improve maneuverability, and protect soldiers from hazardous situations in congested and contested environments. RAS technologies enhance survivability by providing greater standoff distance from enemy threats and reducing risks during convoy operations. While the Army's RAS Strategy does not have specific strategic objectives for Artificial Intelligence (AI), it suggests a potential future role for AI in enhancing military capabilities. AI is revolutionizing computer systems by enabling them to perform tasks that typically require human intelligence. It will significantly enhance Rapidly Advancing Systems (RAS) by improving independent operation capabilities, such as off-road driving and data analysis for simplified decision-making. AI will also contribute to faster and improved decision-making in various areas, including strategic indications, countering propaganda, and supporting operational decisions. The Army's RAS Strategy aims to enhance decision-making, employ mixed manned/unmanned formations, and improve defensive missions. Near-term priorities include increasing situational awareness, lightening physical loads, improving sustainment, facilitating movement, and enhancing force protection. Mid-term priorities focus on increasing situational awareness. The Marines' RAS and AI Strategy, outlined in the Marine Corps Robotic and Autonomy Strategy (MCRAS), aims to increase situational awareness, lighten cognitive and physical burdens, improve sustainment, facilitate movement and maneuver, and protect the force. Priorities include advanced RAS capabilities, exoskeletons, automated convoy operations, unmanned combat vehicles, and advanced payloads. Far-term goals involve persistent reconnaissance, autonomous aerial cargo delivery, and advancements in unmanned combat vehicles. Limited research and development funding is allocated for these priorities. The Marines' AI strategy aims to improve decision-making by identifying strategic indications, countering propaganda, supporting decision-making, enabling manned-unmanned formations, and enhancing mission execution through big data analysis. Their priorities include increasing situational awareness, lightening the Marine burden, improving sustainment, facilitating movement, and protecting the force with advanced RAS capabilities, exoskeletons, automated convoy operations, unmanned combat vehicles, and manned-unmanned teaming. The development of autonomous robotic ground systems for tactical navigation is a significant challenge that needs to be overcome for effective battlefield deployment. Autonomous unmanned aerial vehicle (UAV) navigation is relatively straightforward compared to ground navigation, as UAVs operate based on maps, radars, and GPS coordinates. The navigation of driverless cars is more complex than that of UAVs, as cars need to track nearby vehicles, pedestrians, and cyclists in real-time to make decisions. This is done through sensors like LIDAR, radars, and computer vision, creating a more advanced world model for the car to operate in. The car's computer constantly computes possible intersections and predicts traffic behavior to make decisions. Driverless car development began in 2004 with a DARPA program, leading to slow progress initially. However, a decade later, the industry is close to commercializing driverless cars globally due to significant R&D investment and competition for the automotive market. In contrast, military autonomous vehicle development has seen little advancement, particularly in overcoming challenges like tactical cross-country navigation and vehicle detection. The SMET is an unmanned robotic vehicle designed to provide logistical support to Army and Marine Corps units. It will operate in unmanned and optionally manned modes, carry up to 1,000 lb, travel over 60 miles in 72 hours, and generate power for equipment. The target cost for the SMET is $100,000 per system, and it is largely based on commercial off-the-shelf technology. The SMET is an unmanned robotic vehicle designed to provide logistical support to Army and Marine Corps units. It can carry troops, food, water, ammunition, supplies, and weapons. The SMET is expandable and can conduct route clearance, breaching operations, reconnaissance, and serve as a semi- or fully autonomous weapon system. Four vendors were selected for a technology demonstration in FY2019 with 64 SMETs to be evaluated by two Brigade Combat Teams. The Army plans to transition the SMET to a Program of Record by FY2020, with the first units receiving the vehicles by FY2021. The Leader-Follower Technology for Tactical Wheeled Vehicles aims to link unmanned vehicles to a manned vehicle for convoy operations, reducing soldier exposure to risk. The Tank Automotive Research, Development and Engineering Center is involved in these efforts. The Army is working on Leader-Follower Technology for Tactical Wheeled Vehicles to reduce soldier exposure to risk during convoy operations. Industry partners include Robotic Research LLC, Oshkosh Defense, Lockheed Martin, and DCS Corporation. Plans include a year-long operational demonstration in late FY2019 with 60 systems deployed to two Palletized Load System Truck Companies. If successful, production is expected to be completed by FY2027 for the Next Generation Combat Vehicle (NGCV) to replace the M-2 Bradley. The Army plans to develop Robotic Combat Vehicles to serve as \"wingmen\" for the Next Generation Combat Vehicle (NGCV), with soldiers controlling the RCVs from stations in the NGCV. The Army aims to improve AI so that a single soldier can control \"a squadron of robots.\" Initial set of six experimental NGCV prototypes are planned, including two manned NGCVs. The Army plans to develop six experimental NGCV prototypes, including two manned NGCVs and four RCVs, for delivery by the end of FY2019. Soldier testing is scheduled for FY2020, with a company-sized element testing planned from FY2023 to FY2024. Uptake Technologies was awarded a $1 million contract to build AI software for the M-2 Bradley to predict component failures and improve maintenance operations. Uptake Technologies will install software on 32 M-2 Bradleys at Ft. Hood, TX to predict future repairs and optimize maintenance timing. The software aims to prevent unnecessary maintenance work, potentially expanding to the entire Bradley fleet and other combat vehicle fleets. Army officials are cautious as these industrial machine-learning technologies have not been fully tested on military vehicles. The Marine RV (M) is a custom-built platform with AI capabilities for various missions. The Marines are exploring a Fully Autonomous First Wave Concept for amphibious assaults to address enemy A2/AD capabilities. This concept could reduce the need for Marines in high-risk operations and decrease logistical support requirements. Integrating robotics, autonomous systems, and AI into military units raises personnel-related issues that may interest Congress. The integration of robotics, autonomous systems, and AI in military units raises personnel-related issues for Congress. The use of RAS and AI may lead to changes in unit organization and manning, potentially reducing manpower in some areas while increasing it in others. Unmanned aircraft usage has shown to increase manning requirements, highlighting the autonomy paradox where autonomous systems change problems rather than solve them. The integration of robotics, autonomous systems, and AI in military units raises personnel-related issues for Congress. Unmanned aircraft usage has shown to increase manning requirements, highlighting the autonomy paradox where autonomous systems change problems rather than solve them. The introduction of RAS and AI brings a greater need for military personnel with advanced technical knowledge. National security leaders may want to retain manpower to provide certain capabilities in the event RAS and AI systems are degraded or inadequate for a given mission or requirement. The military's integration of robotics, autonomous systems, and AI raises personnel-related issues for Congress. As the military incorporates RAS and AI, the need for personnel with advanced technical knowledge will increase. Recruiting and retaining individuals with expertise in RAS and AI will be crucial for designing, acquiring, programming, testing, and maintaining these systems. Recruiting and retaining individuals with high cognitive ability and advanced technical training for roles in the military may be challenging due to competition from the private sector. Training servicemembers on using and maintaining RAS and AI systems will require significant time and expenses, with ongoing training needed for new systems and upgrades. The armed forces provide military skill training through a network of schools and training sites, but this may not be the best way to maintain proficiency in RAS and AI systems. Career paths in the military are well-defined, starting at lower ranks and progressing to higher grades with a focus on technical skill, leadership, and compensation. The military may need to consider a different career path model for individuals with expertise in RAS and AI, such as higher entry level grades or a technical career track. Periodic assignments outside of the military, like in the private sector or academia, could also help maintain expertise in these areas. The military medical community's career path model, which brings officers in at a higher grade based on technical training, is seen as a potential example to follow. The military is considering a different career path model for RAS and AI experts, similar to the medical community's model. There is a legal and ethical debate over autonomous weapons systems, with some arguing for their development if they meet international law requirements. The legal and ethical debate over autonomous weapons systems revolves around the need for meaningful human control to ensure compliance with international law. Opponents call for a treaty banning such weapons or a moratorium on their development, while proponents argue that they could enhance compliance with the Law of Armed Conflict (LOAC). The Article 36 legal review process is recommended for evaluating the ethical use of autonomous weapons systems. The legal and ethical debate over autonomous weapons systems focuses on the principles of distinction and proportionality in armed conflict. Concerns arise regarding the ability of autonomous systems to adhere to these principles and the accountability for noncompliant behavior. The API defines military objectives as objects that contribute to military action, while civilian objects are those that do not. Constant reassessment is necessary as the nature of an object may change. Objects used for civilian purposes should not be targeted unless used for military purposes. The API also prohibits targeting facilities essential for civilian survival or causing environmental harm. The API and customary international law dictate rules for targeting individuals in armed conflict. Combatants are lawful targets, but even they are protected if wounded or surrender. Civilians can only be targeted if they directly participate in hostilities. The principle of proportionality requires balancing military advantage with potential harm to civilians and civilian objects during an attack. Judgments on proportionality are made at the start of an attack, taking into account fluid battlefield conditions. The law of armed conflict prohibits the use of weapons causing excessive civilian harm, such as chemical and biological weapons. Proportionality in attacks requires balancing military advantage with potential civilian harm. Creating an algorithm for proportionality assessment is doubted by some. API Article 36 mandates testing new weapons to ensure compliance with the law of war, specifically regarding their indiscriminate nature and potential for causing unnecessary harm. Autonomous weapons systems must be able to distinguish targets to avoid causing excessive civilian harm or environmental damage. Autonomous weapons systems must distinguish targets and ensure proportionate attacks. Some argue that autonomous systems meeting targeting criteria can pass Article 36 review. Scientists warn of challenges in distinguishing civilians from combatants. Compliance with bans on superfluous damage can be achieved by avoiding prohibited payloads. The Department of Defense directive on autonomous weapons systems emphasizes the importance of human judgment in their use. It requires evaluation and testing to ensure they function as intended, complete engagements in a timely manner, and are robust to prevent unintended engagements or loss of control. The Department of Defense directive on autonomous weapons systems emphasizes the need for effective human-machine interface, clear procedures for operators, and traceable feedback on system status. Critics question the level of human judgment in the use of force, while some worry that autonomous systems could increase the likelihood of armed conflict by minimizing risks to human soldiers. Some argue that robots in warfare may minimize risks to troops, but opponents believe human emotions like empathy are necessary for ethical war-fighting. Proponents argue that human emotions can lead to adverse consequences on the battlefield. Some skeptics of automated weapon systems argue that robots may lead to adverse consequences on the battlefield, as they are not subject to human errors or emotions. Concerns include \"automation bias\" and the dehumanization of killing. Notable futurists like Elon Musk and Steven Hawking have warned about the dangers of AI surpassing nuclear weapons. Organized groups are increasingly concerned with lethal autonomous weapon systems (LAWS). In April 2017, DOD established the Algorithmic Warfare Cross-Functional Team for Project Maven, using AI to extract objects from UAV imagery. This AI technology aims to identify targets faster, reducing collateral damage and civilian casualties. Google is among the companies involved in this project. Google's involvement in Project Maven, a military surveillance technology project using AI for drone operations, sparked ethical concerns among employees. Some resigned in protest, and others demanded a policy against building warfare technology. Google will not renew its contract with DOD for Project Maven in 2019. The Campaign to Stop Killer Robots advocates for a ban on autonomous weapon systems, citing ethical concerns. The Campaign to Stop Killer Robots advocates for a preemptive ban on autonomous weapon systems, citing ethical concerns and the risk of violating international humanitarian law. The campaign is inspired by the success of the International Campaign to Ban Landmines and aims to emulate its NGO strategy. The United Nations Convention on Conventional Weapons has discussed the issue. The United Nations Convention on Conventional Weapons (CCW) met to discuss lethal autonomous weapons, affirming that international humanitarian law applies to all weapon systems. Despite attempts to negotiate an annex to the CCW, there was opposition from Russia. However, there was agreement on the need for meaningful human control over autonomous weapons systems. On September 12, 2018, the European Parliament passed a resolution urging an international ban on weapon systems without human control over target selection. France and Germany do not support a total prohibition of autonomous weapons. Lack of trust from Warfighters and the public hinders the development and use of autonomous unmanned systems by the Department of Defense. The lack of trust in autonomous unmanned systems is highlighted by international efforts to consider policies prohibiting their deployment with lethal capabilities. Technological shortcomings in AI's ethical thinking may limit public trust in military-developed autonomous systems. It is crucial to maintain human authority, accountability, and command and control as unmanned systems are increasingly deployed. The discussion on the ethics and legality of LAWS will impact the development of such systems for battlefield use by the Army and Marines. The Army and Marines develop LAWS for battlefield use, following DOD Directive 3000.09 which mandates human judgment over autonomous weapon systems. Operators must adhere to laws of war, treaties, safety rules, and ROE. The directive was updated in May 2017 with administrative changes. The DOD Directive 3000.09 mandates human judgment over autonomous weapon systems, with a substantive update expected in late 2017. Currently, DOD does not have autonomous weapon systems operating independently of human input. Concerns have been raised about the need for an international treaty to restrict the development and deployment of such systems. The UN Office in Geneva hosted meetings on lethal autonomous weapon systems in 2014-2016. The CCW established a Group of Governmental Experts to discuss LAWS in 2017. A second meeting is planned for August 2018. If restrictions on autonomous weapon systems are implemented, it could limit the development and use of such systems by the U.S. The DOD Directive 3000.09 mandates human judgment over autonomous weapons, with concerns raised about the need for an international treaty to restrict their development and deployment. The DOD is considering future development of LAWS despite current directives requiring human involvement. Analysts warn of potential risks if humans blindly trust technology, citing past incidents like the USS Vincennes shooting down a civilian aircraft. Congress is actively involved in discussions on RAS and AI, with concerns about the impact of losing American leadership in AI. The potential loss of American leadership in AI could lead to risks in ensuring ethical use of AI in weapons systems by nation-states. Authoritarian regimes like Russia and China may not prioritize ethical considerations in AI warfare. Congress is discussing RAS and AI policies, including examining foreign military efforts and their impact on U.S. ground forces. The emphasis on armed robots highlights differences in U.S. concepts of operations, where unmanned systems mainly support intelligence and reconnaissance. The Russian military is considering using unmanned ground vehicles for actual fighting alongside human forces, potentially changing the nature of war. This could impact how the U.S. organizes ground forces and develops weapon systems. The development of RAS and AI for the military is emphasized, but understanding foreign military capabilities in this area is also important. The importance of understanding foreign military efforts in robotic and artificial intelligence technologies is crucial for the U.S. military to prevent strategic surprises. Leaders in the field warn about the dangers of fully autonomous weapon systems, where machines could make life-and-death decisions in warfare. Adversaries are likely to exploit these technologies for operational advantages, leading to a potential shift towards automated combat. The possibility of other nations aggressively pursuing fully autonomous weapons systems raises the question of whether the United States should do the same. The evolution of weapons like hypersonic weapons could lead to the development of fully autonomous weapon systems for defensive purposes. Despite the Department of Defense's emphasis on a \"man in the loop\" capability for robotic autonomous systems, the U.S. military may feel compelled to develop fully autonomous weapon systems in response to advanced enemy systems. The development of robotic autonomous systems and artificial intelligence for ground forces is outlined in various strategies. The development of technologies to counter foreign use of RAS and AI against U.S. ground forces is crucial. Foreign advancements in AI and RAS could impact U.S. ground forces, necessitating effective countermeasures. Private sector innovations in AI and RAS are also contributing to these developments. Many cutting-edge innovations in AI and RAS are happening in the private sector, which could be utilized by U.S. ground forces. Engaging with the private sector raises policy considerations for the Army, Marine Corps, and DOD. Policymakers may need to expand support for entities like the Defense Innovative Unit to assist the military in adopting emerging technologies. Developing service incentives or recruitment models to attract AI and RAS experts could also be considered. Security challenges exist when DOD and the Services engage with academic institutions and the private sector. The DOD and Services are engaging with academic institutions and the private sector regarding foreign national students and employees who may pose security risks. There are concerns about how academia and private industry view the morality of military RAS and AI use. Some institutions may choose to \"opt out\" of working with DOD on technologies they find counter to their values. Experts suggest that a productive relationship could be fostered by DOD approaching AI development ethically and safely. The JAIC memorandum includes these principles to accelerate the delivery of AI-enabled capabilities. The Center aims to speed up AI-enabled capabilities delivery, with potential congressional concerns on personnel issues as RAS and AI are integrated into the military. Congress may inquire about the rapid integration of RAS and AI, impact on occupational specialties, desired human backup levels, required skills for military services, and academic backgrounds needed for RAS and AI integration. The armed forces are exploring ways to integrate RAS and AI systems, focusing on recruiting and retaining individuals with essential academic and work history backgrounds. They are considering special pay authorities to incentivize targeted skill sets and assignments, as well as nonmonetary incentives to attract individuals with these skills. Additionally, they are evaluating the competitiveness of the armed forces in attracting individuals with advanced technical skills and considering modifying eligibility criteria to make military service more appealing to those with the necessary skills. The armed forces are exploring ways to integrate RAS and AI systems by recruiting and retaining individuals with essential technical skills. Considerations include training servicemembers on RAS and AI, developing a career path model for experts, and potentially involving private-sector or academic assignments. The integration of RAS and AI systems in the military raises questions about career paths, leadership roles, technical expertise, and legal/ethical considerations. Policymakers may soon need to decide on the development of fully autonomous lethal weapon systems. The Administration and Congress must address the legality and morality of developing lethal autonomous weapon systems (LAWS). Ethical discussions and policy decisions are crucial to guide the development of unmanned aircraft systems capabilities. Congress has an opportunity to define its role in the U.S. governmental debate on LAWS. The U.S. government is debating the development and use of lethal autonomous weapon systems (LAWS). Policy decisions and international regulations may limit the ability to use such systems in the future. The United States can choose to play an active, passive, or no formal role in regulating LAWS. The U.S. government is considering the regulation of lethal autonomous weapon systems (LAWS), with policymakers in the Administration and Congress deciding on the level of U.S. involvement in international regulatory processes."
}