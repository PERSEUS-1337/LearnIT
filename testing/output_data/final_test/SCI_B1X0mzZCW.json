{
    "title": "B1X0mzZCW",
    "content": "Training deep neural networks can be challenging due to the need for many training samples and the varying quality of training labels. A trade-off exists between learning from a small amount of high-quality data or a large amount of weakly-labeled data. \"Fidelity-weighted learning\" (FWL) is proposed as a semi-supervised approach to address this issue by modulating parameter updates based on label-quality confidence. Fidelity-weighted learning (FWL) modulates parameter updates based on label-quality confidence, evaluated on two tasks in information retrieval and natural language processing. Outperforming state-of-the-art methods, FWL integrates strong and weak labels effectively, leading to better data representations. The challenge of integrating small quantities of high-quality labeled data with large quantities of unlabeled data is a key focus in semi-supervised learning. In semi-supervised learning, weak annotators can provide additional noisy supervision, but it is unclear how to effectively use this weakly-labeled data to train a stronger classifier. Machine learning systems often encounter data samples of varying quality, such as expert-labeled images mixed with crowd-sourced data or intentionally perturbed labels for privacy reasons. In semi-supervised learning, weak annotators can provide noisy supervision. To train a stronger classifier, one approach is to expand the training set with weakly-labeled data. Another method involves pretraining on weak data, fine-tuning on true function observations, and adjusting for label confidence. Fine-tune student on labels generated by teacher, considering confidence. Propose Fidelity-Weighted Learning (FWL) for Bayesian semi-supervised approach to leverage true labels and confidence-weighted weakly-labeled samples for fine-tuning based on label quality. Control use of weak supervision by modeling inaccuracies introduced by weak annotator. The proposed approach involves a student module learning data representation and a teacher module correcting label inaccuracies. The teacher generates new labeled data from unlabeled data to improve the student's performance. The FWL approach corrects student mistakes and improves data representation, outperforming baselines in various tasks. Analysis includes bias-variance trade-off and learning rate considerations, with connections to Vapnik's LUPI framework. FWL is compared to related work, with main conclusions drawn in Section 6. The FWL approach for semi-supervised learning utilizes weak supervision from a weak annotator and a small set of high-quality labeled samples. The weak annotator generates noisy labels for unlabeled data, creating a weak dataset for training. This approach aims to learn the true target function despite the inaccuracies of the weak annotator. The FWL approach combines weak supervision from a weak annotator with a small set of high-quality labeled samples. It involves training a student on weakly-annotated data and then training a teacher on strong data to provide soft labels for unlabeled samples. The student is trained on the soft dataset with a modulated step-size based on the teacher's quality estimates. The setup includes a neural network as the student and a Bayesian function approximator as the teacher. The training process involves three phases summarized in Algorithm 1 and FIG0. Step 1 includes pre-training the student on weak labels generated by a weak annotator to learn a task-dependent data representation. The student function is a neural network with two parts: one for data representation and the other for prediction. The student is trained on all samples of the weak dataset to approximate expert knowledge through representation learning. The training process involves three phases: Step 1 pre-trains the student on weak labels from a weak annotator to learn a task-dependent data representation. The student function, a neural network, is trained on all weak dataset samples to approximate expert knowledge through representation learning. In Step 2, the teacher is trained on strong data and generates a soft dataset using a Gaussian process to capture label uncertainty. The learned student representation is used to compensate for the lack of data in the strong dataset. The teacher compensates for the lack of data in the strong dataset by utilizing weakly annotated data. A Gaussian process is trained on samples from the weak dataset to learn posterior mean and covariance, generating soft labels with associated uncertainties. The soft dataset is created using the posterior GP, input samples from both weak and strong datasets, and predicted labels. The soft labels are transformed to the suitable output space using a function g(.), such as softmax for classification tasks. The teacher compensates for the lack of data in the strong dataset by utilizing weakly annotated data. A Gaussian process is trained on samples from the weak dataset to learn posterior mean and covariance, generating soft labels with associated uncertainties. The soft dataset is created using the posterior GP, input samples from both weak and strong datasets, and predicted labels. In tasks where a vector of variances is provided by the GP, an aggregating function is used to generate uncertainty values for each sample. Multiple GPs trained on different data regions lead to better exploration of the data space. The clustered GP algorithm outperformed a single GP, as detailed in Appendix A. Fine-tune the student network weights on the soft dataset while considering teacher-confidence in parameter updates. The student network is fine-tuned using samples from the soft dataset, where the uncertainty of each sample is mapped to a confidence value to determine the step size for parameter updates. Teacher-confidence in labels modulates the magnitude of each update, with high confidence leading to larger step sizes. For data points where the teacher is not confident, the training steps of the student are down-weighted, keeping the student function as trained on weak data. The student network is fine-tuned using samples from the soft dataset, with the total learning rate being a function of label uncertainty. The learning rate is modulated by the teacher's confidence in labels, impacting the step size for parameter updates. The proposed method, DISPLAYFORM2, adjusts the learning rate based on the reliability of soft labels. A hyper-parameter \u03b2 controls how much the student network relies on the teacher's knowledge. A small \u03b2 leads to more trust in teacher labels, while a large \u03b2 results in less influence from the teacher. This approach is applied to various tasks like document ranking and sentiment classification using neural networks. The proposed method, DISPLAYFORM2, adjusts the learning rate based on soft label reliability. It is applied to tasks like document ranking and sentiment classification using neural networks implemented in TensorFlow. GPflow is used for developing GP modules. Performance is evaluated against various baselines for both tasks. The proposed method, DISPLAYFORM2, adjusts the learning rate based on soft label reliability for tasks like document ranking and sentiment classification. The FWL model involves training a student on weakly labeled data and fine-tuning with teacher-labeled examples using confidence scores. The true function to learn is y = sin(x) and the weak function is y = 2sinc(x). The results for each task are detailed in the appendix. The task involves obtaining a good estimate of the true function y = sin(x) using a small set of noisy observations and a weak annotator function y = 2sinc(x). Two experiments are considered: 1. Training a neural network on weak data and fine-tuning on strong data. 2. Implementing a teacher-student framework using the proposed FWL approach. The FWL approach in a teacher-student framework improves approximation of the true hidden function. The student's RMSE on test points after training on weak data, fine-tuning on true observations, and incorporating soft labels and confidence information from the teacher were 0.8406, 0.5451, and 0.4143 (best) respectively. Details of the experiments are provided in Appendices C and E. The ranking model in the student BID12 architecture addresses the challenge of learning relevance between queries and documents. It uses a pairwise neural ranker for regression, mapping data samples to probabilities of document ranking. The network's first layer learns representations for input samples. The student architecture uses a neural ranker to learn relevance between queries and documents. It learns embeddings for words and composes them based on global importance to generate query/document embeddings. The representation layer is followed by a fully connected network to predict ranking probabilities. The teacher is implemented using a clustered GP algorithm, and the weak annotator is BM25. Data with weak and true labels are described, along with the setup of document ranking experiments. Cross-validation is conducted on the strong data. FWL significantly boosts performance in ranking tasks over all datasets. Training the student on weak annotations leads to better results than training on strong supervision. Alternating between strong and weak data during training shows little improvement. Fine-tuning can further enhance results. Fine-tuning the neural network with weakly labeled data leads to better results compared to unsupervised or self-supervised methods. Pretraining the student on weakly labeled data is crucial for performance improvement. Using teacher-generated labels for fine-tuning without considering confidence scores also enhances results. Including estimated label quality from the teacher further boosts performance. In sentiment classification, the student model is a convolutional network that maps input sentences to dense vectors for predicting sentiment. The architecture includes embedding and convolutional layers followed by feed-forward layers and a softmax output layer. Fine-tuning with estimated label quality from the teacher improves overall performance. The student model architecture for sentiment classification includes embedding and convolutional layers, with fine-tuning using estimated label quality from the teacher. The weak annotator method estimates sentiment distribution for each sentence based on sentiment labels of its terms. The best performing approach is the proposed FWL, with NN S showing acceptable performance. Sampling from weak and strong data improves results, and pretraining on weak labels before fine-tuning on true labels further enhances performance. Pretraining on weak labels and fine-tuning on true labels improves performance. Weighting gradient updates from weak labels during pretraining and fine-tuning with true labels (NN W \u03c9 \u2192S) is effective. Learning representation in an unsupervised task-independent fashion does not yield good results. Fine-tuning NN S based on labels generated by GP works better than standard fine-tuning. Using FWL with confidence consideration outperforms convolution-based models on sentiment classification tasks. Pretraining on weak labels and fine-tuning on true labels improves performance, with \u03b2 being a key hyperparameter. Experimenting with different values of \u03b2 showed that \u03b2 = 1 gives the best results for sentiment classification and ranking tasks. Additionally, performance was analyzed on a toy problem with varying numbers of observations from the true function. In experiments with different values of \u03b2, it was found that setting \u03b2 = 1 yielded optimal results for sentiment classification and ranking tasks. The rate of learning for the student varied as the amount of training data changed, with \u03b2 acting as a key hyperparameter to control the bias-variance trade-off in extreme cases. The experiments involved using varying amounts of strong and weak data. Results showed that the student learns faster with a teacher present. However, with very little weak data, the student struggles to learn effectively. Obtaining weakly labeled data is easier than strong data in reality. In FWL, weak annotators provide weak supervision for unlabelled data, impacting the model's performance in document ranking tasks. Different weak annotators, such as BM25, vector space models with BTO and TF-IDF weighting schemas, and BM25+RM3, are compared to study their effects on FWL performance. The performance of FWL in document ranking tasks depends on the quality of the weak annotator used, such as BM25, vector space models with TF-IDF weighting, and BM25+RM3. FWL provides confidence scores based on the certainty of generated labels, with better weak annotator performance resulting in less improvement by FWL. In document ranking tasks, the performance of FWL depends on the quality of the weak annotator used. FWL provides confidence scores based on label certainty, which can bias the sampling procedure of mini-batches for training the student model. This setup involves normalizing confidence scores over training samples to determine sampling probabilities, improving performance without considering the original confidence. The performance of FWL s in document ranking and sentiment classification tasks is illustrated in Figure 8. Compared to FWL, FWL s shows rapid improvement initially but slows down later. There is a bias in FWL s towards sampling data points with high confidence scores from D s. The performance of FWL s gets closer to FWL after many epochs, with a tendency for more exploitation than exploration due to skewness in confidence distribution. FWL explores input space and controls updates based on sample merit, positioning it relative to related work on learning from imperfect labels. Learning from weak data involves using function BID12, which relies on a knowledge base to devise noisy labels. This approach is useful for encoding domain expertise or cheaper supervision from lay annotators, especially in structured learning where obtaining strong labels is expensive. Different forms of weak supervision, such as indirect supervision and response-based supervision, are employed to update model parameters. Constraint-based supervision is another form of weak supervision used in learning from weak labels. In the proposed FWL model, weak supervision is utilized to provide imperfect labels for unlabeled data, requiring a small amount of data with strong labels. This places the model in the semi-supervised category. Various approaches like self-training, pseudo-labeling, and Co-training are used to augment the training set with unlabeled data. Some research also explores self-supervised feature learning to leverage different data types. Self-supervised feature learning utilizes freely available labelings within the data to learn general-purpose features, which are then used in supervised tasks like object classification. Unlabeled data can be used to learn the data distribution through pre-training weights and supervised fine-tuning. Some methods incorporate unsupervised encoding at multiple levels with a supervised signal, while noise cleansing techniques aim to remove mislabeled samples. Weak or noisy labels can also be leveraged in the learning process. Our proposed FWL leverages weak or noisy labels by inferring better labels and providing certainty information for training neural networks effectively. Methods using generative models or extra layers aim to correct weak labels and improve training outcomes. In this paper, fidelity-weighted learning (FWL) is introduced as a new student-teacher framework for semi-supervised learning with weakly labeled data. FWL accelerates training and outperforms other semi-supervised methods in document ranking and sentiment classification tasks. Additional details are provided in the appendices to maintain focus on the main idea of FWL. The paper introduces fidelity-weighted learning (FWL) as a student-teacher framework for semi-supervised learning with weakly labeled data. Multiple Gaussian processes (GPs) are suggested to explore the data space effectively. The Sparse Gaussian Process implemented in GPflow introduces inducing points and stochastic methods for scalability in large datasets. Increasing the number of inducing points in the Sparse Gaussian Process algorithm improves accuracy on test datasets, but impacts scalability. The algorithm may struggle to explore the entire data space effectively due to sparse distribution in high-dimensional embedding space. PCA is also used to address this issue. The use of clustered Gaussian Processes (GP) with a large number of inducing points is explored to better exploit the structure of datasets. This approach aims to address the limitations of sparse distribution in high-dimensional embedding space and improve model performance. Clustered GP is considered as the engineering side of the work, serving as a tool to provide confidence measures. The algorithm involves allocating K teachers to the dataset, with each GP seeing a subset of the data. A clustering method is used to find centroids of K clusters, with each cluster assigned a GP trained by samples belonging to it. The clustered GP assigns each cluster a GP trained by samples belonging to that cluster. Clusters are trained in parallel to speed up the process. The algorithm involves running K-means with K clusters over all samples to find centroids, with each cluster assigned a GP trained by samples belonging to it. The algorithm involves assigning each cluster a Gaussian process trained on samples from that cluster. A teacher model is used to evaluate soft labels and uncertainty for samples, necessary for the next step. The student model proposed in a previous study is used for the ranking task. The algorithm involves using a Gaussian process for each cluster, with a teacher model providing soft labels and uncertainty for samples. The student model from a previous study is utilized for ranking tasks. The function \u03c8 is defined with embedding, weighting, and compositionality functions to improve information retrieval. In experiments, the embedding function \u03b5 is initialized with word2vec embeddings pre-trained on Google News and the weighting function \u03c9 with IDF. A fully connected feed-forward network with hidden layers follows the representation layer, computing predictions using a softmax output. The network employs cross entropy loss on a batch of data samples. The sentiment classification task utilizes a convolutional model. The sentiment classification task utilizes a convolutional model with an embedding function that maps input sentences to vectors. The network applies filters to generate feature maps, which are then used to produce a feature vector for prediction. The convolutional model for sentiment classification utilizes filters to generate feature maps from input sentences, which are then aggregated into a feature map matrix. The model also includes a bias vector and applies a non-linear activation function before passing the output to a max pooling layer. The embedding matrix is initialized with word2vec embeddings pretrained on tweets, followed by a feed-forward layer with softmax as the output layer. The model uses softmax for output with cross entropy loss and Gaussian Process as the teacher. Soft labels are generated by passing the GP mean through a function like softmax or sigmoid. Different aggregation functions are used based on the task, such as mean of variances for sentiment classification with three classes. In sentiment classification, linear combinations of different kernels are used for different tasks. Gaussian process regression is used with specific kernels for document ranking and sentiment classification tasks. The length scale and noise level parameters are empirically determined for the kernels used in the classification tasks. In sentiment classification, Gaussian process regression is used with specific kernels for document ranking and sentiment classification tasks. The number of clusters in the clustered GP algorithm is set to 50 for the ranking task and 30 for the sentiment classification task. The weak annotator for document ranking is BM25, while for sentiment classification, a lexicon-based method is used with SentiWordNet03 to assign probabilities for each token. In sentiment classification, Gaussian process regression is utilized with specific kernels for document ranking and sentiment classification tasks. The weak annotator for document ranking is BM25, while for sentiment classification, a lexicon-based method is used with SentiWordNet03 to assign probabilities for each token. In the toy problem experiments, soft labels from the weak annotator outperformed single hard labels. The neural network used has 3 layers with 128 neurons each, employing tanh as the nonlinearity for intermediate layers and a linear output layer. The optimizer is Adam with an initial learning rate of 0.001. The teacher in the toy problem fits only one GP on all data points without clustering. In the experiments, different values for \u03b2 were tested during fine-tuning. Two standard TREC collections were used for ad-hoc retrieval: Robust04 with 500k news articles and ClueWeb09 with over 50 million English documents. The experiments involved filtering out spam documents using the Waterloo spam scorer. Query sets with human-labeled judgments were used for the Robust04 and ClueWeb collections. A query set was created using unique queries from AOL query logs. Standard pre-processing was applied to filter out navigational queries. After filtering out navigational queries and non-alphanumeric characters, 6.15 million queries were collected for Robust04 and 6.87 million for ClueWeb. The weakly labeled training set Dw was prepared by selecting the top 1,000 retrieved documents using BM25 for each query from the training query set Q. A 3-fold cross-validation was conducted for evaluating the model, with hyper-parameters tuned using batched GP bandits. The study used the acquisition function BID15 and fixed the student's optimal parameters for experiments. The student's hidden layers were chosen from {64,128,256,512}, with learning rates from {10^-3,10^-5} and dropout parameters from {0.0,0.2,0.5}. Different embedding sizes of {300,500} were considered, with a batch size of 128. ReLU was used as a non-linear activation function, Adam optimizer for training, and dropout as a regularization technique. At inference time, the top 2,000 retrieved documents using BM25 were re-ranked. The model was tested on twitter sentiment classification datasets from SemEval-15 Task 10B. The sentiment classification of SemEval-15 Task 10B BID51 involved using datasets from SemEval-13 and SemEval-14 for training and validation. True labels were used for training, while weak labels were created using a large corpus of 50M tweets. Hyper-parameters were tuned for the student model using batched GP bandits. The study focused on tuning hyperparameters for the classifier model using batched GP bandits with an expected improvement acquisition function. Parameters such as the size and number of hidden layers, convolutional layers, feature maps, filter width, learning rate, dropout parameter, embedding sizes, and batch size were varied. ReLU was used as a non-linear activation function, Adam optimizer for training, and dropout as a regularizer. The work also connected with Vapnik's learning using privileged information. Vapnik's learning using privileged information (LUPI) utilizes additional information provided by an intelligent teacher to enhance the learning process for a semi-supervised learning algorithm. The theory of LUPI explores how to leverage this teaching signal to improve learning algorithms beyond normal features. The theory of learning using privileged information (LUPI) enhances learning algorithms by incorporating additional information from an intelligent teacher. Statistical learning theory provides a bound for test error, influenced by the separability of classes, with a learning rate determined by the VC dimension of the function space. The difference in learning rates between separable and non-separable problems is significant, requiring a larger dataset for non-separable problems to achieve the same error bound. The paper proposes a teacher-student framework for semi-supervised learning, inspired by the theory of learning using privileged information (LUPI). The framework involves training the student network on weakly labeled data first, then training the teacher on truly labeled data to provide additional information for learning. Multiple teachers are introduced to offer privileged information tailored to the student's current knowledge state. The teacher-student framework in semi-supervised learning, based on LUPI theory, involves specialized teachers correcting student's knowledge in specific data regions. Privileged information accelerates learning, as shown in FIG6. Test error varies with sample size, with the model performing best when |Ds| is informative about |Dw|. The theory of LUPI was initially developed for this purpose. The theory of LUPI, developed for knowledge transfer, involves using a large network for training and a smaller network at test time. Dark knowledge and LUPI can be unified under generalized distillation, where machines teach machines by transferring knowledge. The framework extends LUPI by introducing a trainable teacher to correct the student's knowledge using privileged information about label uncertainty. Our framework extends LUPI by introducing a trainable Bayesian teacher that provides posterior uncertainty of labels, mutual representation between student and teacher, and the ability to incorporate multiple teachers for scalability. Proposed a scalable method to introduce multiple specialized teachers for different regions of the data space."
}