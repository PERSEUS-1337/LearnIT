{
    "title": "r1etIqwjiX",
    "content": "Spoken term detection (STD) involves determining the presence and location of a specific word or phrase in speech. Algorithms aim to rank utterances with the term higher than those without it. A new approach proposes setting an absolute detection threshold for all terms using a calibrated loss function, enhancing system robustness and accuracy rates. The new approach in spoken term detection sets a single threshold for all terms using a calibrated loss function, improving accuracy rates in a weakly supervised setting. Experiments on various corpora showed higher Area Under Curve (AUC) and accuracy rates with the fixed threshold. During inference, a detection threshold is chosen to determine the point from which a score would be considered positive or negative in an STD system. The threshold choice balances between false negatives and false positives, impacting system performance measured by the ROC curve and AUC. The detection threshold in an STD system is crucial for balancing false positives and false negatives. Different methods, such as using the ROC curve or ATWV score, have been employed to select the threshold. A new approach proposed in this paper embeds the threshold adjustment within a learning algorithm, ensuring a fixed threshold for all terms. The proposed algorithm aims to assign higher scores to positive speech inputs than negative ones, with a focus on setting a global threshold for all terms. This involves introducing a new loss function to train the ranking function and adjust the decoding function accordingly. The new loss function proposed trains the ranking function to separate positive and negative instances by fixing a threshold. It extends the hinge loss to penalize misdetected instances, improving system robustness. This loss function is an upper bound to the ranking loss function, minimizing it leads to minimizing ranking errors or maximizing the AUC. In the STD task, the goal is to determine if a term is uttered in a speech utterance. The speech signal is represented by a sequence of acoustic feature vectors. A term can be presented as a sequence of phonemes or an acoustic segment. Scalars are denoted with lower case Latin letters, vectors with bold face letters, and sequences with a bar. The number of frames in the speech signal is not fixed. A term is a word or short phrase presented to the system either as phonemes or an acoustic segment. In the context of speech signal processing, a spoken term detector aims to determine if a specific term was pronounced in a given speech segment. This detector function, denoted as f, compares a confidence score to a threshold \u03b8 to make this determination. Adjustments to the threshold may be necessary for different terms after decoding. The goal is to propose a new method to learn a spoken term detector with a fixed threshold for all terms. The function f is derived from a training set of examples containing speech segments and term representations. The function should be able to detect any term, not just those seen in training. Two implementations are discussed: one with a structured prediction model using fully supervised training data and the other with a deep learning model using weakly supervised training data. The text discusses the need to learn a function f to detect a term in speech segments with varying confidence levels. It introduces sets of speech segments where the term is articulated and not articulated, aiming to determine the probability and expectation of detecting the term. The text discusses adjusting a function to detect a term in speech segments with varying confidence levels. It aims to maximize accuracy by finding parameters that minimize error, measured by a predefined threshold. The goal is to find parameters that maximize accuracy for a given threshold. To minimize error in detecting speech segments, a surrogate loss function is used as a convex upper-bound to the error function. The function must have a confidence level greater than \u03b8 + 1 for positive segments and less than \u03b8 - 1 for negative segments. Two algorithmic implementations are presented to minimize the derived loss function. The text discusses the minimization of a loss function to reduce error in detecting speech segments. It introduces a construction based on discriminative keyword spotting and spoken term detection, defining the alignment between phoneme sequences and speech signals in a fully-supervised setting. The detection function is composed of a predefined set of features. The detection function f in our work is composed of a predefined set of feature functions that analyze speech utterances for alignment confidence. The feature functions consider phoneme sequences and candidate alignment sequences to determine alignment accuracy. The threshold value for each term is believed to depend on phonetic content and duration. This allows the function to learn subtle differences from the data. The function f aims to learn a spoken term detector by analyzing acoustic features and phoneme sequences. It uses a set of 4 feature functions to determine alignment confidence and predict the existence of a term in an utterance. The function maximizes a weighted sum of scores based on importance weights that should be learned. The function f uses feature functions to analyze acoustic features and phoneme sequences to predict the existence of a term in an utterance. It maximizes a weighted sum of scores to determine alignment confidence. The Viterbi algorithm is used to find the optimal time segment for the keyword in the speech signal. The model parameters are found by minimizing a loss function, and the Passive-Aggressive algorithm is used for optimization. The Passive-Aggressive algorithm BID5 BID15 is used to find the parameters w by updating them iteratively based on training examples. The algorithm aims to minimize the loss of each example while keeping the weight vector close to the previous iteration's value. The optimization problem includes a complexity-accuracy trade-off parameter C and a non-negative slack variable \u03be. The constraint ensures that the projection of the utterance onto w is greater than a threshold \u03b8 + 1. The PA-ACC algorithm is an online algorithm that maximizes accuracy by updating parameters iteratively based on training examples. It includes a complexity-accuracy trade-off parameter C and a non-negative slack variable \u03be. The optimization problem ensures the projection of the utterance onto w is greater than a threshold \u03b8 + 1. The algorithm introduces a more elaborate solution than the ranking loss of BID15, with details on implementation available in BID8. In the weakly supervised setting, a Siamese network model is trained with a ranking loss function using deep networks. The network is trained to minimize or maximize the similarity between speech segments where the same term is pronounced. Each training example consists of a triplet of speech segments, with the goal of training the network to recognize the presence or absence of a specific term in the segments. The Siamese network model is trained with a ranking loss function using deep networks to compare speech segments. The goal is to recognize the presence or absence of a specific term in the segments by comparing a triplet of speech segments. The network minimizes the loss function for the weakly supervised case. The study compares different loss functions for weakly supervised speech recognition. Experimental results show the effectiveness of the proposed calibrated loss function BID6 compared to standard approaches. Experiments were conducted on structured prediction models with fully supervised training sets and deep network models with weakly supervised data. The study compared loss functions for weakly supervised speech recognition using conversational speech data from Switchboard. Experiments were conducted on the TIMIT corpus with training and validation sets randomly chosen from the TIMIT training set. The test set consisted of 80 benchmark terms from BID15, with 20 utterances for each term taken from the TIMIT test set. The study evaluated the PA-ACC algorithm on TIMIT test utterances, measuring performance with AUC and accuracy. Two options were tested: averaging final weight vector or using the best from validation set, and normalizing new feature functions by phoneme sequence length. Results of AUC and Acc \u03b8 rates are shown in Table 1, with \u03b8 set to 0 during training. The PA-ACC algorithm was evaluated on TIMIT test utterances, showing improved detection rates with AUC almost always at 1. Results were better than BID15 due to new feature functions. Best Acc 0 results on validation set were when features were not normalized and final weight vector was selected, while on the test set, best results were with normalized features and average weight vector. Further research on feature functions is recommended. Further research on feature functions is recommended and should be extended to a larger dataset. The performance of the algorithm was compared against two other algorithms: PA-AUC and an HMM-based spoken term detection algorithm. Results for all algorithms are reported in TAB1. The AUC and Acc \u03b8 values are reported in TAB1. Different thresholds were selected for PA-AUC and HMM algorithms. Interestingly, PA-ACC's AUC is as high or higher than PA-AUC. The model trained on TIMIT was evaluated on the WSJ corpus, showing close performance between Acc \u03b8 and AUC. The model trained with the proposed loss function showed higher accuracy rates and better separation between positive and negative speech utterances. Another set of experiments focused on deep networks trained on weakly supervised data using a ranking loss. The term weak supervision refers to supervision given in the form of known word pairs. The data used for training the Siamese convolutional neural networks was extracted from the Switchboard corpus of English conversational telephone speech. It consisted of about 10k word tokens from BID11 BID12, with word segments of at least 5 characters and 0.5 seconds in duration. The architecture of each network included 1-D convolution with 96 filters over 9 frames. Testing was done using an 11k-token set from BID11 BID12. The Siamese convolutional neural networks were trained using ADADELTA and the ranking loss with cosine similarity as the similarity function. Different margin values were used for the ranking loss and the Acc \u03b8 loss functions. The new loss function introduced in this work improves AUC and Acc \u03b8 values for training epochs. It is based on a discriminative structured prediction model using the Passive-Aggressive algorithm, suitable for weakly supervised deep network models. Our new loss function improves AUC and accuracy values for training weakly supervised deep network models, outperforming previous works' results."
}