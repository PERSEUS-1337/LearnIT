{
    "title": "Skx82ySYPH",
    "content": "Identifying salient points in images is crucial for visual odometry, Structure-from-Motion, or SLAM algorithms. IO-Net introduces a novel proxy task for self-supervision of keypoint detection, description, and matching. KeyPointNet is a keypoint-network architecture designed for robust keypoint detection and description. The network is designed for local keypoint aggregation to improve keypoint descriptor performance. Efficient sub-pixel convolutions are used to upsample descriptor feature-maps. The self-supervised keypoint learning method enhances feature matching and homography estimation. Keypoint detection and matching are essential for tasks like SLAM and object detection. Key points can be detected and re-identified in various scenarios, requiring invariance to lighting, viewpoint changes, scale, etc. Handcrafted image features like SIFT or ORB have limitations compared to learned alternatives. Deep learning has revolutionized computer vision applications, but supervision and expensive labels are often needed. Supervising interest point detection is challenging as human annotators struggle to identify salient regions and key descriptors. Self-supervised learning methods have gained popularity for tasks like depth regression, tracking, and representation learning. A novel proxy task called IO-Net is introduced for self-supervision of keypoint detection, description, and matching. This methodology jointly trains a keypoint detector and its associated descriptor, utilizing a neurally-guided outlier-rejection scheme to generate optimal inlier sets from corresponding point-pairs. The KeyPointNet architecture introduces modifications to improve keypoint matching by allowing keypoint locations outside cell boundaries and enhancing descriptor fidelity through sub-pixel convolutions. Extensive experiments demonstrate the effectiveness of the proposed architecture. The proposed architecture in the curr_chunk establishes state-of-the-art performance for self-supervised keypoint detection, description, and matching. Recent advancements in deep learning-based methods have led to improved performance in image feature detection beyond handcrafted methods. The curr_chunk discusses various methods for robust feature point detection and description, including LIFT, LF-Net, Quad-networks, and SuperPoint. These methods utilize different approaches such as end-to-end learning pipelines, differentiable networks, and unsupervised learning schemes to estimate features that are robust to viewpoint and illumination differences. UnsuperPoint (Christiansen et al., 2019) introduced a fast deep learning keypoint detector and descriptor that requires only one round of training in a self-supervised manner. It shares computation in detection and description modules, using a siamese network to learn descriptors. Simple homography adaptation and non-spatial image augmentations are employed to create 2D synthetic views for training the self-supervised keypoint estimation model, solving data association between views. In contrast to UnsuperPoint (Christiansen et al., 2019) which predicts keypoints within cells, a new method improves matching performance by handling keypoint detection across cell boundaries. Self-Improving Visual Odometry (DeTone et al., 2018a) estimates 2D keypoints and descriptors, but lacks full differentiability for end-to-end training. Our proposed framework for self-supervised keypoint detector and descriptor learning incorporates an end-to-end differentiable outlier-rejection mechanism (IO-Net) to refine keypoint descriptions. The KeyPointNet architecture is optimized with explicit loss on target outputs, while the IO-Net provides indirect supervisory signals by propagating gradients from matching input point-pairs. In this work, a function is trained to output keypoints, descriptors, and scores from an input image. The learning framework is self-supervised, using source and target images related by a known homography transformation. The function C, inspired by Neural Guided Sample Consensus methods, computes the probability that a point-pair belongs to an inlier set. It is used at training time to select consistent inliers and encourage gradient flow through point-pairs. The model K, parametrized by \u03b8 K, is defined in this context. The model K is an encoder-decoder network with VGG-style blocks to reduce image resolution. It predicts keypoints, descriptors, and scores in a low-resolution space. Each pixel corresponds to an 8x8 cell in the original image. The decoder has separate heads for keypoints, descriptors, and scores. Batch normalization and leakyReLU activation are applied in convolutional layers. The IO-Net is a 1D CNN following a structure from Brachmann & Rother (2019). The model K is an encoder-decoder network with VGG-style blocks predicting keypoints, descriptors, and scores in a low-resolution space. It follows a structure from Brachmann & Rother (2019) with 4 default setting residual blocks. Keypoint locations are optimized using a self-supervised loss formulation enforcing consistency across different views of the same scene. The proposed formulation allows keypoints to be aggregated across cell boundaries by mapping relative cell coordinates to image coordinates. This enables the network to predict keypoints outside cell boundaries, improving matching effectiveness. In this study, the authors quantify the contribution of a fast upsampling step in improving the performance of their keypoint detector. They design the network to predict localization from the cell center, allowing keypoints to be outside the border for better matching. The addition of this step greatly enhances the quality of the descriptors, as shown in the ablative analysis. Metric learning is employed for training the descriptors, utilizing contrastive loss. The study focuses on improving keypoint detector performance by using fast upsampling and designing the network to predict localization from the cell center. They enhance descriptor quality through metric learning with a per-pixel triplet loss and nested hardest sample mining. This approach minimizes the distance between anchor and positive descriptors while maximizing the distance between anchor and negative samples. The study enhances descriptor quality through metric learning with per-pixel triplet loss and nested hardest sample mining, maximizing distance between anchor and negative samples. The third head of the decoder outputs scores for reliable keypoints, ensuring consistent scores and learning that good keypoints have low feature point distance. The study focuses on enhancing descriptor quality through metric learning and nested hardest sample mining to maximize distance between anchor and negative samples. It emphasizes that good keypoints have low feature point distance by minimizing squared distance between scores for each keypoint-pair. Keypoint and descriptor learning are closely linked with outlier rejection, with keypoints associated based on descriptor distance. The study enhances descriptor quality through metric learning and nested hardest sample mining to maximize distance between anchor and negative samples. Key points with the lowest predicted scores are used for training, accelerating convergence and generating a richer supervisory signal. Keypoint pairs are associated based on reprojected distance, with an IO-Net determining inlier or outlier probability. The loss function incorporates the output of the IO-Net and Euclidean distance threshold. Gradients are backpropagated to input samples for further training. The outlier rejection task in this study is related to neural network based RANSAC methods, but differs in that it does not require random sampling and consensus steps due to known ground truth homography transform. The outlier network is used to generate a supervisory signal for input point-pairs rather than rejecting outliers. The final training objective optimized with weights balancing different losses using the COCO dataset. The method is self-supervised and evaluated on image sequences from the HPatches dataset for fair comparison with other methods. The method is self-supervised and evaluated on image sequences from the HPatches dataset. Results are reported averaged over the dataset without applying Non-Maxima Suppression. Evaluation metrics include Repeatability, Localization Error, Matching Score, and Homography Accuracy with thresholds of 1, 3, and 5 pixels. The networks are implemented in PyTorch using the ADAM optimizer with specific training parameters. We set weights for training loss to balance different terms. Parameters like \u03c3, margin, and relaxation criteria are defined. Outlier rejection network is trained on lowest 300 scoring pairs. Various method variants are evaluated on 240x320 resolution images. The evaluation of different method variants (V0-V4) shows improvements in matching performance by enabling cross border detection and descriptor upsampling. V1 achieves better Repeatability and Matching Score by avoiding the border effect, while V2 further enhances matching performance without degrading Repeatability. Additionally, V3, trained without descriptor loss, also shows improvements in matching performance. The proxy task of inlier-outlier prediction improves keypoint and descriptor learning. The model under V4 achieves strong generalization performance across various metrics. Runtime performance on a desktop with Nvidia Titan Xp GPU shows high FPS. Comparison with state-of-the-art and traditional methods on different image resolutions is conducted. Our proposed method outperforms traditional and learned feature detectors in repeatability and homography estimation accuracy. UnsuperPoint performs better in lower resolution images, while our method excels in higher resolutions. Key points are extracted in each view during testing. During testing, keypoints are extracted in each view, with our method outperforming others in repeatability and homography estimation accuracy. Our method excels in higher resolution images, while UnsuperPoint performs better in lower resolutions. Self-supervised learning methods provide keypoints with higher matching scores and better homography estimation compared to traditional handcrafted features like SIFT. Our method excels in repeatability and homography estimation accuracy during testing, outperforming other learning-based methods. The best performing model is trained using supervision from the outlier rejection network, showing that the auxiliary task can generate high-quality supervisory signals for descriptor training. The proposed learning scheme for training a keypoint detector and descriptor in a self-supervised fashion utilizes a proxy network to generate supervisory signals from outlier rejection, effectively propagating distinguishable descriptors. The proposed method utilizes an improved network structure to achieve competitive results in homography estimation. Evaluation metrics include Repeatability, Localization Error, and Matching Score, all calculated with a correctness distance threshold of 3. Repeatability measures correctly associated points after warping, Localization Error averages the distance between warped and associated points, and Matching Score indicates the success rate of retrieving correctly associated points. The homography accuracy is determined by the success rate of estimating homographies through reciprocal descriptor matching. OpenCV's findHomography method with RANSAC is used, with experiments showing better performance on the illumination subset compared to the viewpoint subset. Additional experiments report mean and standard deviation across 10 runs with varying RANSAC seeds. Our method shows better homography performance on the illumination subset compared to the viewpoint subset due to extreme rotations. Evaluation includes different splits of the HPatches dataset and comparison with SIFT and ORB on various sequences, with our method consistently outperforming ORB but performing worse than SIFT on sequences with extreme rotations. Our method outperforms ORB but performs worse than SIFT on sequences with extreme rotations. We achieve better results on the graffiti sequence and successfully match features under strong illumination, rotation, and perspective transformation. Our method's performance on the Bark, Boat, and Graffiti sequences of HPatches is detailed in Table 5. The performance of our method on the Bark, Boat, and Graffiti sequences of the HPatches dataset is analyzed. Evaluation of homography variance due to RANSAC is done with 10 runs using different random seeds. The IO-Net diagram consists of 4 residual blocks and performs binary inlier-outlier classification based on keypoint pair and descriptor distance."
}