{
    "title": "SkloDjAqYm",
    "content": "Neuronal assemblies, defined as subsets of neurons with coordinated activation patterns, are key to neural representations. LeMoNADe is a new method for finding motifs in calcium imaging videos, bypassing spike extraction. It uses variational autoencoders with a discrete stochastic node, showing promising results on simulated data. In real brain slice videos, LeMoNADe uncovers potential motifs for hypothesis generation. LeMoNADe uncovers candidate motifs in calcium imaging videos, aiding in neuronal assembly detection and hypothesis generation. The existence and importance of these patterns are still debated, but LeMoNADe shows promise in identifying them without the need for spike extraction. LeMoNADe is a new method for identifying neuronal assemblies directly from calcium imaging data without the need for pre-processing steps like cell identification and spike time extraction. Previous methods require a spike time matrix as input, which involves extracting individual cells and discrete spike times from the data. LeMoNADe is a novel method for identifying neuronal assemblies from calcium imaging data, bypassing the need for pre-processing steps like cell identification and spike time extraction. Despite challenges like low signal-to-noise ratios and errors in segmentation, modern recording technologies and advanced regularization techniques have improved the performance of existing methods. However, manual annotation and correction of segmentation output still require significant time and effort. LeMoNADe (Learned Motif and Neuronal Assembly Detection) is a VAE-based framework designed to identify repeating firing motifs in calcium imaging data. It uses Bernoulli priors for sparse motif activations and employs BinConcrete relaxation for gradient descent techniques. The LeMoNADe framework utilizes a \u03b2-coefficient in the loss function for data regularization and a training scheme for efficient video processing. It performs comparably to a state-of-the-art motif detection method on synthetic datasets and identifies motifs in microscopy data. The method is implemented in PyTorch and is available on GitHub. Variational Autoencoders (VAEs) are a popular unsupervised generative deep learning method introduced by Kingma & Welling in 2014. Variational Autoencoders (VAEs) are a popular unsupervised generative deep learning method introduced by Kingma & Welling in 2014. Recent modifications aim to create a more interpretable latent space, such as adjusting the loss term or structuring the latent space. VAEs have been successfully applied to video sequences, enabling tasks like disentangled representation manipulation in cartoon video clips and hierarchical representation learning in video data. Johnson et al. (2016) utilized a latent switching linear dynamical system model with a structured variational autoencoder to segment and categorize mouse behavior from raw depth videos. The model by Johnson et al. (2016) is not suitable for identifying motifs in calcium imaging data due to limitations in capturing long-term temporal dependencies and handling overlapping motifs. A more relevant approach is described in BID2 for detecting motifs in video data using a convolutional neural network. The approach in BID2 combines a convolutional autoencoder with regularization terms to detect patterns in video data. However, this method is not applicable to detecting neuronal assemblies in calcium imaging data due to spatially stationary cells. Various methods for cell segmentation and signal extraction from calcium imaging data have been proposed, including non-negative matrix factorization and clustering techniques. Recent approaches in the analysis of calcium imaging data include the use of deep learning techniques such as convolutional neural networks (CNNs) and variational autoencoders (VAEs) combined with different models for spike time extraction. Despite the advancements, the extraction of cells and spike times can still be laborious and require manual annotation, with limited accuracy due to the quality of calcium recordings. Some methods are tailored for two-photon microscopy, while few can handle low signal-to-noise ratio (SNR) and large background. Methods for analyzing calcium imaging data include deep learning techniques like CNNs and VAEs for spike time extraction. Challenges include low SNR and large background fluctuations in single-photon and microendoscopic imaging. Neuronal assembly detection involves identifying joint spike events across multiple neurons using methods like PCA, ICA, and unitary event analysis. Higher-order correlations and sequential spiking motifs can be identified with advanced statistical tests. The identification of cell assemblies with arbitrary spatio-temporal structure has been addressed recently using advanced statistical tests. One method involves merging units into larger groups based on joint spike count probabilities across different time lags. Another method uses sparse convolutional coding for reconstructing spike matrix as a convolution of spatio-temporal motifs and their activations in time. An extension of this method uses group sparsity regularization to identify the correct number of motifs. The proposed VAE framework, LeMoNADe, is designed for unsupervised detection of repeating motifs with temporal structure in video data. It reconstructs data as a convolution of motifs and their activation time points, with latent variables containing motif activations. This method can identify assemblies with complex temporal firing patterns, unlike previous approaches. The proposed generative model in combination with the VAE allows for direct extraction of temporal motifs and their activations while considering the sparse nature of neuronal assemblies. The dataset consists of a single video as an additive mixture of repeating motifs. Latent random variables are drawn to indicate motif presence at each time frame. Variational parameters are learned by minimizing the KL-divergence between approximate and true posterior distributions. The ELBO optimization in VAE involves computing gradients for variational and generative parameters using a reparameterization trick to handle dependencies. Sampling from Bernoulli distributions introduces discrete stochastic nodes requiring differentiable reparameterizations. More details on VAE can be found in Kingma & Welling (2014). The BinConcrete distribution is a continuous relaxation of the Bernoulli distribution with a temperature parameter \u03bb. It can be reparameterized using the Gumbel-softmax trick, which is differentiable. This allows for a reparameterized lower bound in VAE optimization. The reparameterized lower bound in VAE optimization involves a negative reconstruction error and KL-divergence acting as a regularizer on the approximate posterior. A \u03b2-coefficient can be added to vary the constraint on the latent space, leading to the minimization of a loss function with mean-squared error and the \u03b2-coefficient. The \u03b2-coefficient \u03b2 KL is added to the loss function to adapt better to specific datasets and recording methods. The encoder network uses convolutional layers with 2D filters on each frame of the video, followed by a final convolutional layer with 3D filters. Padding in the temporal domain ensures correct motif capture. The encoder parameters \u03b1 are used for reparametrization to obtain activations z, which are then fed to the decoder. The decoder, with a single deconvolution layer, reconstructs data x as an additive mixture of filters. Training is done on small subsets of video frames to reduce computational cost without affecting performance. The algorithm efficiently analyzes videos of arbitrary length without affecting performance. Automated tools are necessary for detecting neuronal assemblies, with no ground truth available for identifying spatio-temporal motifs in real neurophysiological spike data. Quantitative accuracies are reported using synthetically generated datasets. The study focuses on identifying neuronal activity from calcium imaging data by including neuronal assemblies with temporal firing structure. Synthetic data with varying ratios of spurious spikes was used to simulate noise. The proposed method is the first to detect video motifs with temporal structure directly in calcium imaging data, with the SCC algorithm as a baseline for comparison. The SCC algorithm identifies motifs with temporal structure in spike trains or calcium transients. Calcium transients of individual cells are extracted for dataset application. The algorithm outputs a matrix showing firing behavior over time within motifs. Performance is measured by cosine similarity between ground truth and detected motifs. Ground truth motifs may not extend across all frames, allowing for slight frame shifts in discovered motifs. The discovered motifs can be shifted by a few frames to capture all relevant parts. The similarity for motifs was computed with all possible temporal shifts. The algorithms were tested on 200 synthetic datasets with the correct number of motifs. If the number of motifs is overestimated, LeMoNADe still identifies the correct motifs. The temporal extent of the motifs was set to F = 31 to capture longer patterns. The cosine similarity of motifs found by LeMoNADe and SCC is compared in the presence of noise. LeMoNADe performs as well as SCC in detecting motifs and is stable. A bootstrap test was conducted to verify the results, showing that both methods perform significantly above chance. The full BS distributions and 95%-tile for each noise level are shown in appendix C.3. An exemplary result from a synthetic dataset with 10% noise and ground truth motifs correctly identified with a small temporal shift. The temporal structure of the found motifs matches the ground truth, as shown in figure 5a. The average similarities between LeMoNADe (lime green) and SCC (blue) motifs and ground truth were analyzed for noise levels ranging from 0% to 90% spurious spikes. Both methods performed well up to 70% noise, with LeMoNADe showing similar stability to SCC. Results from organotypic hippocampal slice cultures were also examined. The datasets were obtained from organotypic hippocampal slice cultures prepared from 7-9-day-old Wistar rats. Neurons in CA3 were imaged for 6.5 (dataset 1) and 5 minutes (dataset 2) in the presence of carbachol. The fluorescent Ca 2+ sensor, GCaMP6f, was delivered to the neurons using an adeno-associated virus. See appendix D.1 for more details on dataset generation. The hippocampal slice culture datasets were analyzed using a proposed method with specific parameter settings. The analysis took less than two hours on a Ti 1080 GPU, and the results showed motifs with repeated activation over the recording period. The analysis of hippocampal slice culture datasets revealed motifs with repeated activation over the recording period, including temporal structure. Artefacts and background fluctuations were identified, with the potential for falsely detecting single events with high neuronal activation as motifs. Neuropil activation was present in the motifs, but not necessarily used as a defining feature by the VAE. Dendritic/axonal structures visible in motif videos can be removed through post-processing steps. The proposed method for detecting neuronal assemblies operates directly on calcium imaging data, extracting motifs as short, repeating image sequences. This approach eliminates the need for extracting individual cells and spike times from raw data. The method's performance in identifying motifs is comparable to state-of-the-art methods that require cell extraction. Repeating firing patterns were successfully identified in hippocampal slice culture datasets, demonstrating the method's effectiveness. The method for detecting neuronal assemblies in calcium imaging data can identify repeating firing patterns in hippocampal slice culture datasets. Future work includes adding post-processing steps and exploring the use of latent dimensions to separate artefacts from motifs. The method may also be applicable to other functional imaging modalities like human fMRI or voltage-sensitive dyes. Variational autoencoder (VAE) models are used to generate latent variables in the data. The text discusses the generation of samples using a latent variable z and a conditional distribution p \u03b8 * (x | z) with unknown parameters. An approximate posterior inference of the latent variables z is sought, which is usually intractable but can be approximated using a recognition model q \u03c6 (z | x). The goal is to learn both the recognition model parameters \u03c6 and the generative model parameters \u03b8 through minimizing a certain function. The text discusses learning variational parameters \u03c6 to minimize the KL-divergence between approximate and true posterior. The lower bound L(p, q; x) is optimized by computing gradients w.r.t. both \u03c6 and generative parameters \u03b8. Gradients w.r.t. \u03b8 can be easily computed using Monte Carlo sampling, while the reparameterization trick is used for gradients w.r.t. \u03c6. The reparameterization trick involves transforming a noise variable \u03b5 to compute gradients w.r.t. variational parameters \u03c6. This allows for optimization of the lower bound L(p, q; x) by minimizing the KL-divergence between approximate and true posterior distributions. The encoder network architecture includes convolutional layers with 2D filters to extract features from video frames. The encoder network uses 3D filters on feature maps of the whole video to capture motifs properly. The BinConcrete relaxation reparameterizes Bernoulli distributions for sampling. The encoder network uses 3D filters on feature maps of the whole video to capture motifs properly. The first M feature maps outputted by the encoder contain unnormalized probabilities \u03b1 for all m and t. Scaling the activations with the \u03b1 1 -values predicted from the encoder network improved algorithm results. The decoder consists of a single deconvolution layer with M filters containing the motifs. Sizes of inputs and outputs are detailed in table 1. Algorithm 1 summarizes the reparametrization and updates for creating artificial sequences with varying cell shapes and neuronal assemblies with temporal firing structure. Transients were modelled with exponential decay, and convergence was achieved through parameter updates until real data was obtained. Algorithm 1 summarizes the reparametrization and updates for creating artificial sequences with varying cell shapes and neuronal assemblies with temporal firing structure. An assembly can perform multiple spikes in a randomly chosen but fixed motif of temporal length up to 30 frames. The assembly activity is modelled as a Poisson process with a mean of 0.15 spikes/second and a refractory period. Gaussian background noise and spurious spikes not belonging to any motif were added to simulate real calcium imaging videos. The performance of the algorithms is measured by computing the cosine similarity between datasets. The performance of algorithms is evaluated by computing cosine similarity between found motifs and ground truth motifs. Found motifs may not be in the same order or time as ground truth motifs, so similarity is calculated with all possible temporal shifts. The similarity between a found motif and ground truth motifs is defined by a formula involving dot product and vectorization of motifs. The shift operator moves motifs forward in time while maintaining size and filling missing values with zeros. The performance of algorithms is evaluated by computing cosine similarity between found motifs and ground truth motifs. Statistical methods for testing cell assemblies have advanced in recent years, using sophisticated parametric, model-based bootstraps to retain the full statistical structure of the original data. The study used sophisticated bootstraps to evaluate algorithm performance in finding motifs, with a focus on repeating motifs. A bootstrap-based test procedure was employed to establish a null hypothesis for motif similarities. The results were compared to ground truth motifs, showing significant differences in similarity between random patterns and those with repeating motifs. The study utilized bootstraps to assess algorithm performance in detecting motifs, focusing on repeating motifs. A null hypothesis for motif similarities was established using a bootstrap-based test procedure. The results indicated significant differences in similarity between random patterns and those with repeating motifs. The 95% significance threshold of the BS distribution was shown as a vertical red line, with convolution of calcium transients but without repeating motifs. The motif-less H0 datasets were processed by LeMoNADe in the same manner as motif-containing datasets. Random samples were drawn from each BS dataset, and similarities between found motifs and random samples were computed. This procedure was repeated for datasets with different noise levels. Figure 7 displays the BS distributions and similarities between motifs found with LeMoNADe on datasets containing motifs. Organotypic hippocampal slice cultures were prepared from 7-9-day-old Wistar rats using adeno-associated virus encoding GCaMP6f. The study utilized bootstraps to assess algorithm performance in detecting motifs, showing significant differences in similarity between random patterns and those with repeating motifs. The 95% significance threshold of the BS distribution was displayed, with the average of similarities on motif-containing datasets higher than the threshold. The hippocampal slice cultures were maintained on Biopore membranes in a culture medium consisting of essential components. The culture medium was replaced regularly, and artificial cerebrospinal fluid was used for imaging. The recording solution had a specific pH and gas mixture saturation. The recording temperature was controlled at 32 \u00b1 1\u00b0C. Imaging of CA3 region of the hippocampus was performed on day 29 with 20x magnification (dataset 1) and on day 30 with 10x magnification (dataset 2) in vitro (23 days post viral infection) from slices maintained in submerged chamber. Constant bath wash of carbachol was done to enhance neuronal activity. Motif 0 showed temporal structure beyond spiking synchrony in both datasets. Fluorescence imaging was conducted on day 30 with 10x magnification (dataset 2) in vitro. The images were cropped and downsampled for efficient analysis. Synchronous firing patterns were compared to show temporal structure in motifs found in the datasets. The synchronous firing patterns of motifs were computed and compared between datasets using LeMoNADe and SCC methods. Results showed high similarity in the extracted calcium traces, indicating LeMoNADe's performance on real data. LeMoNADe is easy to apply for motif detection in neuronal spike data, with only a few parameters needing adjustment. SCC, on the other hand, requires more parameters due to the spike matrix extraction. Experimental parameter settings are shown in TAB5. Synthetic data experiments with different motif estimations (underestimated, correct, and overestimated) were conducted to demonstrate the effects. The study conducted synthetic data experiments to demonstrate the effects of different motif estimations (underestimated, correct, and overestimated). The results showed that when the number of motifs is underestimated, only one true motif is captured, while overestimation leads to correct motifs being identified along with surplus filters filled with copies of true motifs and background noise. Real dataset analysis also showed that limiting the number of motifs allows the model to learn the most explanatory motifs first. When the number of motifs is increased, the motif shown in figure 11a becomes more prominent in the data. Adding more filters helps to reduce background noise, with the second filter in FIG4 explaining a significant portion of the dataset but not representing a neuronal assembly. Overestimating the number of motifs can help capture true motifs and some background noise, especially when the correct number is unknown in real datasets. In future work, a post-processing step or group sparsity regularization could be used to eliminate additional copies of motifs automatically. Background noise can be easily identified and separated from actual motifs. If the motif length is underestimated, only the most important parts of the motifs will be captured, while overestimating the length may result in time shifts. In experiments, it is recommended to overestimate motif length for better results. Different values of parameter \u00e3 affect the sparsity of activations, with smaller values often leading to cleaner motifs. Experimenting with different values of \u00e3 for each dataset is advised. Changing the value of \u03b2 KL is another option for regulation. In experiments, different values of \u00e3 and \u03b2 KL can regulate sparsity of activations. Default values of \u00e3 = 0.1, \u03bb 1 = 0.6, and \u03bb 2 = 0.5 work well in most cases. Varying \u00e3 and \u03b2 KL in experiments on real dataset 2 showed similar motifs with temporal shifts and order shuffling. Smaller \u00e3 values result in background noise in surplus filters. When varying the values of \u00e3 and \u03b2 KL in experiments, smaller \u00e3 values lead to background noise in surplus filters, while larger values show copies of the motif. Changing \u00e3 by more than one order of magnitude results in significantly different outcomes where the motif is no longer detected. Fine-tuning \u00e3 is not necessary, as varying the order of magnitude is sufficient to find a regime where motifs appear in the results. Similar effects can be observed when varying \u03b2 KL, with changes within an order of magnitude showing similar patterns. When varying the values of \u03b2 KL, smaller values result in surplus filters filled with copies of the motif, while larger values lead to background noise. Tuning either \u00e3 or \u03b2 KL is sufficient to achieve good results in motif detection. Found motifs for M = 1 and M = 3 in different frames. Found motifs for M = 2 and M = 3 in various frames. The reconstructed videos from the found motifs can be accessed at the provided link, showing the convolved activations in either TIFF or MP4 format. The videos correspond to datasets with different frame rates and include RGB superposition of values from three motifs. The reconstructed videos from the found motifs can be accessed at the provided link, showing RGB superposition of values from three motifs. Additionally, videos from a synthetic dataset with 50% spurious spikes are also available."
}