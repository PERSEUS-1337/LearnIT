{
    "title": "Syjha0gAZ",
    "content": "The problem of multiset prediction is addressed in this paper by proposing a novel multiset loss function. The goal is to train a predictor that maps an input to a multiset with no known order among items. The proposed loss function is evaluated on synthetic and real datasets, showing its effectiveness over other baseline loss functions. The problem of multiset prediction involves learning a mapping from an input to a multiset of items without a predefined order. This problem is relevant in various fields such as high-energy physics and computer vision. In multiset prediction, the learner is presented with an input and its associated multiset of items, without any further annotations about their relationship. The problem of multiset prediction involves learning a mapping from an input to a multiset of items without a predefined order. This problem is unique from other well-studied problems like sequence prediction or classification due to the lack of known order among items and the exponential growth in possible multisets. In this paper, multiset prediction is viewed as a sequential decision-making process, aiming to find a policy that predicts one item at a time while evaluating the aggregate multiset outcome. An oracle policy is proposed that assigns non-zero probabilities only to prediction sequences resulting exactly in the target multiset given an input. The text discusses the problem of multiset prediction and introduces an oracle policy that optimally predicts the target multiset given an input. It also proposes a novel multiset loss to minimize the KL divergence between the oracle policy and a parametrized policy. The comparison with other baselines is also mentioned. The paper introduces a novel multiset loss for multiset prediction, outperforming other baseline losses in experiments on different datasets. It defines multiset prediction as a generalization of classification, where the target is a multiset of classes. Multiset prediction is a generalization of classification, mapping an input x to a multiset Y = y1,...,y|Y|, where yk \u2208 C. Key properties include arbitrary input vectors, no predefined order in Y, varying Y size, and possible multiple appearances of items from class set C in Y. Evaluation metrics like F1 score and exact match are used. Variants of multiset prediction have been extensively studied, differing from the defined problem. The text discusses the challenges of transforming a class set into a set of all possible multisets for multiset prediction. The exponential growth in the number of possible multisets makes training a multi-class classifier infeasible in practice. For example, the COCO Medium dataset has roughly 20 thousand elements in the transformed set, while the dataset only contains around 40. Ranking involves learning a mapping from input x and an item c \u2208 C to its score s(x, c), sorting all items in the class set by score to determine rank. Top-K items are selected to convert ranking into set prediction. Unlike multiset prediction, ranking cannot handle multiple occurrences of an item in the target set. Aggregated Distribution Matching converts the target multiset into a different form. In contrast to ranking, which sorts items by score, multiset prediction converts the target multiset into a distribution by computing item frequencies. This approach minimizes divergence between the distribution and the model's predictive distribution, useful when p(y|x) differs significantly from p(y). Sequence prediction involves mapping inputs to sequences of classes, seen in tasks like machine translation and speech recognition. In contrast to ranking, multiset prediction involves converting the target multiset into a distribution by computing item frequencies. This approach minimizes divergence between the distribution and the model's predictive distribution. Sequence prediction maps inputs to sequences of classes, as seen in tasks like machine translation and speech recognition. The proposed multiset loss function is motivated by treating the multiset prediction problem as a sequential decision-making process with a policy \u03c0. The policy \u03c0 \u03b8 predicts the next class based on previous predictions and input x. A free label multiset Y t is defined as the remaining items to be predicted. An oracle policy \u03c0* outputs a distribution evenly distributed over items in Y t. The oracle is optimal for precision and recall given any prefix \u0177 <t. The oracle policy is optimal for precision and recall, ensuring only correct items are selected. Sampling from this policy guarantees no incorrect predictions, assigning zero probability to non-permutation sequences. The oracle policy dictates which items from the class set must be chosen at each time step. The oracle policy ensures optimal selection of items from the class set at each time step. To minimize the KL divergence between the oracle policy and a parametrized policy, a per-step loss function is defined. This loss function aims to optimize decision-making based on predictions and entropy considerations. To optimize decision-making based on predictions and entropy considerations, a per-step loss function is proposed to minimize the loss for a specific state defined by the input x and prefix \u0177 <t. This loss function is computed at each time step t and summed up to obtain the final loss. The goal is to maximize F1 and exact match by minimizing the multiset loss function. The proposed approach aims to minimize the multiset loss function to maximize F1 and exact match. Using a parametrized policy instead of an oracle policy linearly bounds the error with respect to the target multiset size. Three strategies for executing the parametrized policy are tested empirically: greedy search, stochastic sampling, and evaluating the learned policy by greedily selecting each item. The proposed loss function for multiset prediction assumes knowledge of the target multiset size, which is a significant limitation addressed by introducing two different strategies. The proposed approach aims to minimize the multiset loss function to maximize F1 and exact match. Two methods are introduced to relax the constraint of knowing the target multiset size: a termination policy trained in a supervised way and introducing a special item called END to signal the end of predicting items in the multiset. The proposed approach introduces multiple loss functions for multiset prediction, including a multiset loss function and three baseline loss functions. It involves matching the target multiset to an aggregated distribution using a parametrized policy. Learning aims to minimize the divergence between the predicted and target distributions. In this paper, two types of divergences are tested for minimizing the divergence between aggregated distributions: Lp distances and KL divergence. However, minimizing this divergence does not always lead to the optimal policy, as it may assign non-zero probability to incorrect predictions due to the invariance of the aggregated distribution to the order of predictions. Empirical analysis shows that learned policies often behave differently from the optimal oracle policy. The paper explores minimizing divergence between aggregated distributions using Lp distances and KL divergence. Learned policies often differ from the optimal oracle policy, as seen in the increasing entropy of action distribution over time. A one-step predictor is proposed, but lacks modeling dependencies among items in the predicted multiset, resulting in lower prediction accuracy. The paper discusses the issue of lower prediction accuracy due to the lack of modeling dependencies among items in the predicted multiset. It introduces a new approach that explicitly defines an order in advance to improve prediction accuracy. The sequence loss function in function r aims to maximize the conditional log-probability of the sequence S given x. However, it has drawbacks as it does not consider the behavior of the policy \u03c0 \u03b8 and requires a pre-specified rank function r, leading to varying performance based on the choice. An input-dependent rank function can be devised when the input x has a known structure, improving prediction accuracy. An input-dependent rank function can be devised for image inputs with bounding box annotations. Two rank functions, spatial and area, assign ranks based on object size in the input image. These functions are tested against a random rank function in experiments. The approach relies on a reward function designed for multiset prediction, aiming to maximize rewards over predictions from a policy. The loss function includes a term for negative entropy to encourage exploration during training. REINFORCE is used to minimize the loss function, optimizing return when precision and recall are maximal. The proposed approach for multiset prediction involves reinforcement learning, which is challenging due to the large state and action spaces. The multiset loss function is evaluated against various baseline functions, focusing on image-based multiset prediction using synthetic datasets like MNIST Multi. The MNIST Multi dataset consists of 4 variations with different numbers of classes and pixel sizes. Each dataset has 70,000 training examples and 10,000 test examples. The MS COCO dataset contains natural images with varying object sizes and shapes, with instances ranging from 1 to 91 per image. Two variants, COCO Easy and COCO Medium, are created with different numbers of classes and training examples for studying loss functions. The COCO Easy and COCO Medium variants of the dataset include images with large and common objects, filtering out rare classes. Fine-grained annotation is not used except for creating rank functions. A validation set is created with 15% of training examples, and separate test sets are formed using the same filters applied to the validation set. The test sets for COCO Easy and COCO Medium are created by applying filters to the validation set. The model architecture includes convolutional layers and a convolutional LSTM layer for MNIST Multi, while a ResNet-34 is used as a feature extractor for MS COCO. The termination policy approach is used for predicting variable-sized multisets in all experiments. The performance of the sequence prediction loss function depends on the choice of a rank function when evaluating a trained policy. Different rank functions are tested on MNIST Multi and COCO Easy validation sets, showing that the accuracy varies based on the rank function used. The choice of rank function significantly impacts the performance of the sequence prediction loss function. Random rank function outperformed area-based and spatial rank functions on MNIST Multi and COCO Easy datasets. This highlights the importance of an order-invariant multiset loss function. Experiments comparing greedy decoding, stochastic sampling, and oracle sampling strategies show that greedy decoding and stochastic sampling perform better than oracle sampling on both datasets. The proposed multiset loss function, using greedy decoding, outperforms other baseline loss functions on MNIST Multi variants. This is consistent with the theory and highlights the importance of an order-invariant approach. The proposed multiset loss function outperforms other baseline loss functions on MNIST Multi variants. In contrast, the reinforcement learning based approach closely follows but performance drops with increasing items in a target multiset. Variance of policy gradient grows with episode length. Sequence prediction and aggregate distribution matching show similar behavior. One-step variant of aggregate distribution matching struggles to train decent models, especially in terms of exact match. On COCO Easy, with only two objects to predict, aggregated distribution matching and sequence loss functions are competitive with the proposed multiset loss. Other loss functions significantly underperform. The proposed multiset loss function outperforms other baseline loss functions on COCO Medium, showing a substantial performance gap. The oracle policy defined in the previous section ensures a decrease in entropy of the predictive distribution over time. The policy learned based on the proposed multiset loss closely follows the oracle policy in terms of per-step entropy. The entropy decreases as predictions are made, concentrating probability mass on smaller free label sets. The variance is small, indicating a uniform application of this strategy. The policy trained with reinforcement learning maintains relatively low entropy, with a decreasing trend in the second half, possibly due to the greedy nature of policy gradient. The policy found by aggregated distribution matching has a high entropy that grows as more predictions are made, leading to suboptimal behavior in distinguishing correct and incorrect sequences. This is believed to be due to the inability to differentiate between policies with increasing and decreasing entropies. The policy learned a rank function implicitly, relying on it fully, resulting in lower performance in aggregate distribution matching. The paper rigorously defined the problem of multiset prediction, proposing an approach from sequential decision making. An oracle policy was shown to be optimal, introducing a new loss function called multiset loss for training a parametrized policy. Experiments on MNIST Multi and MS COCO variants datasets demonstrated the effectiveness of the proposed loss. The proposed multiset loss function has shown effectiveness over other loss functions in various domains, including high-energy physics. Precision is defined as the ratio of correctly predicted elements to the number of predicted elements in multisets. Recall is the ratio of correctly predicted elements to the total number of elements. The proposed multiset loss function has shown effectiveness over other loss functions in various domains, including high-energy physics. Recall is defined as the ratio of correctly predicted elements to the total number of elements. The network architecture includes convolutional and LSTM layers, with details provided for each dataset. Preprocessing differs for MNIST Multi and MS COCO datasets. The model is trained end-to-end, with input images resized to 600x600. Adam BID7 is used with a fixed learning rate of 0.001. MNIST Multi had a batch size of 64, while COCO had 32. The multiset loss can be used with a feedforward model as well. The proposed loss can be used in a feedforward model by encoding previous labels in the input and running the model for a determined number of steps. This approach involves additional feature engineering compared to recurrent models."
}