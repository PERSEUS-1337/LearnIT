{
    "title": "BJl_a2VYPH",
    "content": "There has been a growing interest in designing adversarial attacks for NLP tasks, with very few works on adversarial defenses. A novel defense method called Synonym Encoding Method (SEM) is proposed to defend against synonym substitution based attacks. SEM inserts an encoder before the input layer of the model to eliminate adversarial perturbations. Extensive experiments show that SEM can efficiently defend against these attacks with minimal impact on accuracy for benign examples. Improved Genetic Algorithm (IGA) is a strong attack method designed to achieve higher success rates in adversarial attacks on Deep Neural Networks (DNNs) for both computer vision and Natural Language Processing (NLP) tasks. DNNs have shown vulnerability to adversarial examples, posing a threat to their safe applications, such as evading spam filters with adversarial spam emails. The text discusses the challenges of creating adversarial examples in NLP, inspired by methods used in computer vision. Existing perturbation-based methods for images cannot be directly applied to texts due to their discrete nature, making it difficult to generate text adversarial examples that are barely perceptible to humans. Current attacks in NLP involve modifying word characters. The text discusses challenges in creating adversarial examples in NLP by modifying word characters, adding or removing words, replacing words, and substituting words with synonyms. Synonym substitution is difficult to detect and defend against, as it satisfies lexical, grammatical, and semantic constraints. Currently, there is no defense method specifically designed for synonym substitution attacks. The proposed defense mechanism, Synonym Encoding Method (SEM), encodes synonyms to a unique code to ensure that all neighbors of a benign example have the same label. By clustering synonyms based on Euclidean Distance and inserting an encoder before the input layer of a deep model, SEM effectively defends against synonym substitution attacks in text classification. Experimental results show that SEM maintains efficiency and accuracy on benign data while defending against adversarial attacks. The proposed defense mechanism, Synonym Encoding Method (SEM), effectively defends against synonym substitution attacks in text classification by encoding synonyms to a unique code. It is the first method to do so and maintains efficiency and accuracy on benign data. Additionally, an Improved Genetic Algorithm (IGA) is introduced as a more efficient attack method compared to GA, degrading classification accuracy significantly with a lower word substitution rate. The curr_chunk discusses the concept of natural language adversarial examples in text classification, focusing on synonym substitution based adversarial attack methods. It introduces the idea of a distance metric to evaluate the dissimilarity between benign and adversarial examples. The curr_chunk provides an overview of three popular synonym substitution-based adversarial attack methods: Greedy Search Algorithm (GSA) and Genetic Algorithm (GA). GSA uses a greedy search algorithm to substitute words with synonyms while maintaining semantic and syntactic similarity. GA is a population-based algorithm that replaces words with synonyms to generate semantically and syntactically similar adversarial examples. The Genetic Algorithm (GA) utilizes three operators: Mutate, Sample, and Crossover to generate adversarial examples by substituting words with synonyms while maintaining syntax constraints. The algorithm terminates when an adversarial example is found or the maximum iteration limit is reached. Probability Weighted Word Saliency (PWWS) introduces a new synonym substitution method. Probability Weighted Word Saliency (PWWS) is a new synonym substitution method that considers word saliency and classification confidence. It calculates the saliency of each word in a text and substitutes words with their optimal synonyms to find adversarial examples. This method is a rare defense against text adversarial attacks. The proposed text defense method, Synonym Encoding Method (SEM), aims to defend against synonym substitution based adversarial attacks by incorporating adversarial training strategies. The method considers the input space and neighborhood of data points to enhance model robustness. The existence of adversarial examples in models can be defended by training a classifier with more labeled data. While infinite labeled data would ensure robustness, it is impractical due to cost constraints. Wong & Kolter (2018) suggest constructing a convex outer bound to guarantee robustness against adversarial attacks. In response to the challenge of defending against adversarial attacks, Wong & Kolter (2018) propose a method involving a convex outer bound to ensure all data points with the same label. They use a linear-programming based upper bound on the robust loss, but scalability is an issue due to complexity. In contrast, a new approach is suggested in this work to create a smooth classification mapping without requiring extra data or model modifications. The proposed method, Synonym Encoding Method, aims to locate neighbors of an input by substituting words with synonyms to find synonymous sentences. This approach leverages the discrete token nature of words in NLP tasks to easily identify almost all neighbors of an input text. The method assumes that closer sentence meanings result in closer distances in the input space, allowing for the clustering of synonyms to construct a mapping for locating neighbors. The Synonym Encoding Method (SEM) clusters synonyms to allocate unique tokens for each cluster, enabling the substitution of words with synonyms. Current text adversarial attacks have constraints on word substitution, leading to local minimums. To address this, an Improved Genetic Algorithm (IGA) allows for multiple substitutions of words in the same position, traversing all synonyms regardless of the number of synonyms available. The Improved Genetic Algorithm (IGA) allows for multiple substitutions of words in the same position to traverse all synonyms, ensuring robustness of neural networks. Compared to existing attacks, IGA demonstrates better attack performance in improving neural network robustness. In the experiments, the Improved Genetic Algorithm (IGA) shows superior attack performance compared to existing methods. Three datasets - IMDB, AG's News, and Yahoo! Answers - are used to evaluate the efficacy of SEM. In text classification experiments, various models such as CNNs, RNNs, LSTM, and Bi-LSTM are used with an embedding dimension of 300. The CNN architecture is replicated from Kim (2014) with three convolutional layers, while LSTM has three layers with 300 units each. Bi-LSTM includes a bi-directional LSTM layer. Adversarial training is used as a baseline method due to the inefficiency of text adversarial attacks. In text classification experiments, various models like CNNs, RNNs, LSTM, and Bi-LSTM are utilized with an embedding dimension of 300. Adversarial training is employed as a baseline method due to the inefficiency of text adversarial attacks. The experiments involve using PWWS to generate 10% adversarial examples of the training set and re-training the model with these examples. Evaluation of the SEM method is done by generating adversarial examples with or without defense and analyzing the efficacy of attack and defense methods. Under no attack, adversarial training (AT) improves model accuracy by augmenting training data. The defense method SEM performs close to normal training (NT). However, under four attacks, NT and AT experience significant accuracy drops. NT accuracy degrades by over 75%, 42%, and 40% on different datasets. AT is ineffective against attacks like PWWS and IGA, only slightly improving accuracy. In contrast, SEM greatly enhances model robustness against all attacks, outperforming AT. The ability of defense methods like SEM to prevent the transferability of adversarial examples is crucial. Adversarial examples in NLP exhibit good transferability, making it important to resist such attacks. Testing adversarial examples on different models showed that SEM had the highest classification accuracy. Comparing IGA with GA in text attacks, various aspects including attack efficacy, transferability, and human evaluation were considered. Attack efficacy is compared between IGA and GA in text attacks. IGA consistently achieves the lowest classification accuracy under normal and adversarial training, outperforming GA in most cases. Additionally, IGA yields a lower word substitution rate than GA on most models. Transferability of adversarial examples generated by IGA remains stable, similar to those generated by other methods. IGA maintains similar transferability to GA in generating adversarial examples. Human evaluation on IMDB with 35 volunteers shows that perturbations in IGA's examples are hard for humans to perceive, with a 93.7% accuracy on benign examples. IGA achieves the highest attack success rate compared to previous synonym substitution based attacks, with lower word replacement rates than GA. Adversarial examples by IGA are slightly harder for humans to distinguish and maintain transferability. A novel defense method called Synonym Encoding Method (SEM) is proposed to defend against adversarial attacks. The Synonym Encoding Method (SEM) is introduced as a text defense method to protect against adversarial attacks in text classification tasks. It efficiently defends against attacks and reduces the transferability of adversarial examples while maintaining classification accuracy on benign data. Additionally, an Improved Genetic Attack (IGA) is proposed as a new text attack method, achieving higher success rates compared to existing attacks and maintaining transferability of adversarial examples. The IGA algorithm is detailed, highlighting its differences from the Genetic Attack (GA) method. The Improved Genetic Algorithm (IGA) introduces new operators for text mutation, initialization, and population diversity compared to the Genetic Attack (GA) method. It aims to minimize the adversarial loss function while generating adversarial examples. The Improved Genetic Algorithm (IGA) introduces new operators for text mutation, initialization, and population diversity compared to the Genetic Attack (GA) method. It aims to minimize the adversarial loss function while generating adversarial examples. IGA allows for word replacement without falling into local minimum, and simulates biological crossover by concatenating text fragments from two parents. The selection of the next generation is similar to GA but with different offspring due to unique mutation and crossover methods. Different hyper-parameters of SEM are tested on three models on IMDB with or without adversarial attacks, showing a slight decrease in classification accuracy with increasing hyper-parameter values on benign data. The classification accuracy of models decreases slightly with increasing hyper-parameter values, indicating the need for fewer words to train the model. However, SEM maintains semantic invariance, defending against attacks and reaching peak accuracy at a hyper-parameter value of 0.5. This value is chosen as a good trade-off between accuracy for benign and adversarial examples. The generated adversarial examples using GA and IGA on IMDB data are compared in Table 5 to Table 6. IGA substitutes fewer words than GA in normal training. Reviews range from calling a film the worst ever seen to praising it as a unique masterpiece by a talented director. The film received mixed reviews, with some calling it the harshest they've ever seen while others found it enjoyable with a well-written storyline and emotional ending. The film received mixed reviews, with some finding it enjoyable with a well-written storyline and emotional ending, while others considered it the worst film they have ever seen. The film is described as the hardest and least terrifying ever seen, with a unique masterpiece made by a skilled filmmaker. It is recommended for its humor, provoking storyline, and emotional ending. The film is described as the hardest and least terrifying ever seen, with a unique masterpiece made by a skilled filmmaker. It is recommended for its humor, provoking storyline, and emotional ending. The movie received mixed reviews, with some praising it as a warm and enjoyable experience, while others criticized it as the worst film they have ever seen. The film is described as the hardest and least scary ever seen, with a unique masterpiece made by a skilled filmmaker. It is recommended for its humor, provoking storyline, and emotional ending. Some praised it as a warm and enjoyable experience, while others criticized it as the worst film they have ever seen. The film is described as the hardest and least scary ever seen, with a unique masterpiece made by a skilled filmmaker. It is recommended for its humor, provoking storyline, and emotional ending. The director is praised for his art of filmmaking."
}