{
    "title": "rkeiQlBFPB",
    "content": "Learning an efficient update rule from data that promotes rapid learning of new tasks from the same distribution is a challenge in meta-learning. Previous approaches involve training neural networks to produce updates or learning better initializations for gradient-based update rules. However, these methods have limitations such as non-converging behavior or scalability issues. To address these challenges, we propose Warped Gradient Descent (WarpGrad), which combines these approaches to improve efficiency in meta-learning. WarpGrad meta-learns an efficiently parameterised preconditioning matrix to facilitate gradient descent across task distributions. It uses warp-layers between task-learner layers, which are meta-learned without backpropagation. This approach is computationally efficient, scalable, and effective in various learning settings. Memory-based methods using recurrent neural networks can represent any learning rule but lack an inductive bias, making them hard to train and generalize. Gradient-based approaches meta-learn a shared initialization for task adaptation, offering more robustness and efficiency in learning settings. Warped Gradient Descent (WarpGrad) is a novel framework that meta-learns an update rule to precondition gradients during task training, combining insights from memory-based methods with the inductive bias of gradient-based meta-learners. This approach aims to improve few-shot learning by controlling gradient descent more directly. WarpGrad is a framework that meta-learns an update rule to precondition gradients during task training, improving few-shot learning by controlling gradient descent more directly. It embeds WarpGrad preconditioning in task-learners by interleaving warp-layers between each task-learner's layers, modulating layer activations and gradients to facilitate task learning. The gradient preconditioning is defined point-wise in parameter space and can be seen as a recurrent operator of order 1, enabling knowledge transfer in a joint parameter search space. WarpGrad is a framework that embeds gradient preconditioning in task-learners using a warp layer, allowing for data-dependent non-linearity. It surpasses baseline meta-learners on few-shot learning tasks and extends to standard supervised settings. WarpGrad outperforms other meta-learners in various learning settings, including reinforcement learning and continual learning. It belongs to optimisation-based meta-learners that parameterise an update rule with meta-parameters. WarpGrad, a meta-learner, outperforms others in learning settings like reinforcement learning and continual learning by optimizing for steepest descent directions in task adaptation. The Meta-SGD, Meta-Curvature, and T-Nets methods optimize for meta-parameters by backpropagating through the gradient descent process. However, these methods are limited to few-shot learning due to computational expenses, gradient issues, and credit assignment problems. The goal is to develop a meta-learner that overcomes these limitations by departing from backpropagation to the initialization and focusing on learning to precondition gradients. The text discusses the development of a meta-learner that focuses on learning to precondition gradients to overcome limitations in few-shot learning methods. It introduces a preconditioned gradient descent rule and explores disentangling the geometry from the task-learner using non-linear preconditioning. The text introduces a method called WarpGrad that uses warp-layers as universal function approximators to improve gradient descent in few-shot learning. It aims to disentangle the geometry from the task-learner by allowing arbitrary interactions between warp-layers and the task-learner. WarpGrad improves gradient descent in few-shot learning by using warp-layers as universal function approximators, allowing for task-conditioning and interdependence between warp-layers. This disentangles the geometry from the task-learner, enhancing gradient preconditioning. WarpGrad utilizes warp-layers to enhance gradient descent in few-shot learning, improving performance on classification tasks and maze navigation. The use of Residual Networks as warp-layers increases the meta-learner's capacity, leading to better results. Additionally, introducing recurrent warp-layers for agents in a gradient-based meta-learner outperforms memory-based approaches on tasks requiring memory. Warp-layers provide three key properties: inheriting gradient descent properties, forming a distributed representation of preconditioning, and disentangling geometry from the task-learner's expressive capacity. WarpGrad utilizes warp-layers to enhance gradient descent in few-shot learning, improving performance on classification tasks and maze navigation. The warp-layers are meta-learned across tasks and trajectories, capturing properties of the task-distribution beyond local information. They produce smoother and well-behaved loss surfaces, leading to valid Riemann metrics and enjoying similar convergence guarantees to gradient descent. If warp-layers represent a valid Riemann metric, WarpGrad behaves well. The use of warp-layers in WarpGrad enhances gradient descent in few-shot learning by capturing task-distribution properties. These layers create smoother loss surfaces, leading to valid Riemann metrics for improved convergence guarantees. The metric tensor G defines the steepest descent direction on a manifold W, with warp-layers approximating G^-1. The use of warp-layers in WarpGrad enhances gradient descent in few-shot learning by capturing task-distribution properties. Warp parameters \u03c6 control the geometry induced by warping, guiding task-learners to converge efficiently. Meta-learning \u03c6 accumulates information for task adaptation, suggesting an ideal geometry in W-space for preconditioning. This approach avoids backpropagation and leverages global information across tasks. The objective in Eq. 10 introduces a joint distribution over objectives and parameterisations for general-purpose meta-learning at scale. It defines a meta-objective for learning a geometry on first principles, enabling a trajectory-agnostic update rule for warp-layers. The task adaptation objective L \u03c4 task adjusts task parameters \u03b8, while the meta-training objective L \u03c4 meta adjusts warp parameters \u03c6. Both objectives are expectations over data, allowing for differences in validation versus training data or learning paradigms. In a continual learning experiment, the meta-objective is obtained by recasting the canonical objective in terms of \u03b8 using gradient steps equivalence. The distribution p(\u03b8 | \u03c4 ) for meta-learning of warp-layers is assumed to be given, with a sampling strategy considered. Task learning under stochastic gradient descent is viewed as sampling from an empirical prior p(\u03b8 | \u03c4 ), defining a joint distribution p(\u03c4, \u03b8) for a joint search. Meta-learning involves learning a geometry over a joint search space with the steepest expected direction of descent. The task gradient operator is decoupled from the geometry learned, allowing for the infusion of global knowledge in warp-layers. An example includes meta-learning an update-rule to mitigate catastrophic forgetting by defining the meta-objective over current and previous tasks. The WarpGrad meta-objective is defined as a one-step recurrent operator meta-learned across a joint search space, being trajectory agnostic. The meta-objective in the curr_chunk is a trajectory-agnostic approximation that retains all gradient terms and only discards local second-order effects. This approximation incurs only a minor loss of performance in an ablation study on Omniglot. WarpGrad is a multitask learning method that marginalizes over task parameters \u03b8 \u03c4. It can be integrated with methods that define a prior over \u03b8 \u03c4, such as a multi-task solution, meta-learned point-estimate, or metalearned prior. Bayesian methods are incorporated into WarpGrad by optimizing an objective C over \u03b8 0 with a hyper-parameter \u03bb. The optimiser is trained via stochastic gradient descent, solving Eq. 13 by sampling task parameters from p(\u03c4, \u03b8) and updating \u03c6 with meta-gradient steps. This method can be viewed as a form of Mirror Descent with a meta-learned dual space. The sampling procedure details depend on task specifics, task-learner design, and learning objective. In Algorithm 1, a simple online algorithm with constant memory and linear complexity in K is illustrated. A more data-efficient offline training algorithm is detailed in Appendix B, storing task parameters in a replay buffer for mini-batched training of \u03c6. The gains of the offline variant are significant, as shown in the Omniglot experiment where offline meta-training improves final test accuracy from 76.3% to 84.3%. Meta-learning has been explored in various settings, with early work focusing on evolutionary approaches and later introducing gradient descent methods for recurrent learning. Recent meta-learning research has focused on few-shot learning, where tasks have limited data. Gradient descent methods have been applied to recurrent meta-learning algorithms, extended to reinforcement learning. Some approaches involve meta-learning a parameterized update rule using Recurrent Neural Networks. Another idea is to separate parameters into \"slow\" and \"fast\" weights for rapid adaptation. WarpGrad involves learning slow warp-parameters to precondition fast task parameter adaptation. Few-shot learning tasks require minimal data, with meta-learners predicting task parameters. Methods involve pretraining a feature extractor and sharing parameters between task-learners to reduce overfitting or improve convergence. Meta-learning involves modeling latent variables for concept or task inference, inducing gradient modulation. It is related to gradient-based meta-learning for shared initialization beyond few-shot learning. The method of meta-learned preconditioning is closely linked to second-order optimization methods for non-convex loss surfaces. Second-order optimizers struggle on high dimensional non-convex loss surfaces. Methods use low-rank approximations and suffer from instability. Natural Gradient Descent uses Fisher Information Matrix as curvature metric. Various methods proposed for estimating the metric cost. Preconditioning through interleaved projections can be seen as Mirror Descent. WarpGrad offers a new perspective on gradient. WarpGrad introduces model-embedded preconditioning for gradient descent, utilizing global information. It aims to retain the inductive bias of few-shot learners and scale to complex meta-learning problems. The method is evaluated through experiments to assess its performance and generalization capabilities. WarpGrad introduces model-embedded preconditioning for gradient descent, improving performance on few-shot learning tasks like miniImageNet and tieredImageNet. It outperforms baselines by a significant margin, showcasing its ability to retain the inductive bias of MAML-based meta-learners. WarpGrad introduces model-embedded preconditioning for gradient descent, improving few-shot learning performance. A new tieredImageNet protocol increases adaptation Omniglot test accuracies on held-out tasks. Comparison with WarpLeap, Leap, Reptile, multi-headed finetuning, SGD, and KFAC is done. On a RL maze navigation task, mean cumulative return is shown. Simple and retroactive modulation techniques are used. WarpGrad introduces model-embedded preconditioning for gradient descent, improving few-shot learning performance. Warp-Leap meta-learner outperforms Reptile and Leap on benchmark tasks, showing a margin of 3.88 to Reptile. Further evaluation on multi-shot Omniglot protocol demonstrates the effectiveness of Warp-Leap in task adaptation. Warp-Leap, a meta-learner, shows improved performance on a 20-way classification task through task adaptation with 100 gradient steps on preprocessed random samples. It outperforms Leap and Reptile by 8.1 and 12.8 points respectively. Ablation study shows Warp-Leap outperforms baselines with higher convergence rates and reduced final test error. Non-linear warps achieve an 11% test error. WarpGrad methods behave differently from Natural Gradient Descent methods. In an ablation study, WarpGrad methods show distinct behavior from Natural Gradient Descent methods, reducing final test error from~42% to~19%. They are evaluated in a maze navigation task using advantage actor-critic with a recurrent neural network and a Warp-RNN as a HyperNetwork. The study compares a fixed LSTM modulating task-learning RNN with Learning to Reinforcement Learn and Hebbian meta-learning. Linear warps perform worse than the baseline RNN, while Warp-RNN achieves a mean cumulative reward of ~160 in 60,000 steps. WarpGrad is tested for preventing catastrophic forgetting in a continual learning scenario by splitting the input interval into 5 sub-tasks and training a task-learner with warp-layers incrementally on each sub-task. WarpGrad is evaluated for preventing catastrophic forgetting by training a task-learner with warp-layers on one sub-task at a time. Warp parameters are meta-learned to disentangle adaptation processes of current and previous sub-tasks. Results show that WarpGrad effectively learns new sub-tasks with mean losses on a 10^-3 magnitude, but performance deteriorates to 10^-2 when switching tasks. This suggests that WarpGrad is a promising mechanism against catastrophic forgetting. WarpGrad is a novel meta-learner that combines memory-based and gradient-based approaches to precondition gradients during task adaptation. It retains the inductive bias of MAML-based few-shot learners while scaling to complex problems and architectures. WarpGrad introduces warp-layers as universal function approximators, allowing for geometries beyond prior works. This provides a framework for general-purpose meta-learning, including continual learning. The novel meta-learner WarpGrad introduces new means for preconditioning gradients using warp-layers, aiming to enhance gradient-based meta-learning. It addresses limitations of popular metalearning approaches and offers potential solutions for improving computational complexity. WarpGrad introduces new ways to embed warp-layers in a task-learner architecture, allowing for different implementation strategies. It can be used in high-capacity or low-capacity modes depending on the problem at hand. Three approaches to designing WarpGrad optimisers are highlighted, including model partitioning where some operations are designated as task-adaptable and others as warp-layers. WarpGrad introduces gradient warping through warp-layers in task-learner architectures. Three approaches include model augmentation, information compression, and task adaptation strategies. This allows for different implementation modes depending on the problem at hand. In this section, the variants of WarpGrad training algorithms are discussed. Algorithm 1 is an online algorithm that accumulates meta-gradients during task adaptation with constant memory. Algorithm 2 is an offline meta-training algorithm that accumulates meta-gradients into a replay buffer for mini-batch gradient descent on warp. In the Omniglot experiment, offline meta-training with mini-batch size of 1 converges rapidly without instability. Algorithm 3 presents continual meta-training with a multi-task objective. Meta-learning accumulates experiences online for updating warp parameters in maze navigation experiment. In the maze navigation experiment, task adaptation is internalized within the RNN task learner. WarpGrad methods, including Warp-MAML for few-shot learning and Warp-Leap for multi-shot meta-learning, are detailed. Warp-MAML uses the full warp objective with the MAML objective, trained using an online training algorithm. Warp-Leap applies Leap to \u03b8 0, minimizing the expected cumulative chordal distance, and is trained using different algorithms in tieredImageNet and Omniglot experiments. In the maze navigation experiment, task adaptation is internalized within the RNN task learner. WarpGrad methods, including Warp-MAML for few-shot learning and Warp-Leap for multi-shot meta-learning, are detailed. We perform an ablation study comparing exact versus approximate meta-objectives in our experiments. For the Reinforcement Learning experiment, we define a WarpGrad optimiser by meta-learning an LSTM that modulates the weights of the task-learner. In the maze navigation experiment, task adaptation is internalized within the RNN task learner. WarpGrad methods, including Warp-MAML for few-shot learning and Warp-Leap for multi-shot meta-learning, are detailed. The experiment focuses on meta-learning warpparameters. The Warp-RNN objective is defined by WarpGrad for Continual Learning. The approximate meta objective is used due to the environment constraints. In the experiment on meta-learning warpparameters, task sequences are initialized with fixed random values. The warp meta-objective considers expectations over N task sequences, each consisting of T=5 sub-tasks. Task adaptation is defined abstractly by a probability distribution, allowing for the implementation of a continual learning objective by modifying the joint task parameter distribution. This approach differs from multi-task meta-learning in that it focuses on generating parameter trajectories for sequences of sub-tasks within a task. The experiment on meta-learning warpparameters involves initializing task sequences with random values and defining task adaptation through a probability distribution. The meta-objective considers expectations over task sequences with sub-tasks, focusing on generating parameter trajectories for sequences of sub-tasks within a task. The conditional distribution p(\u03b8 | \u03c4 ) is defined by sampling sub-task parameters from task trajectories, and the meta-objective is constructed for any sub-task parameterisation \u03b8 \u03c4t. During meta-training, tasks are defined by objective functions and trained for 100 steps with a learning rate of 0.1. Each task has a unique loss-surface, but they share a common underlying structure. WarpGrad aims to learn a warp that is invariant to spurious descent directions, creating a smooth warped space that is quasi-convex to ensure fast convergence to a minimum. The geometry is visualized using a 2-layer feed-forward network-defined warp \u2126. During meta-training, tasks are defined by objective functions and trained for 100 steps with a learning rate of 0.1. A 2-layer feed-forward network-defined warp \u2126 is used to visualize the geometry. The warp parameters are trained for 100 meta-training steps, with Gradient Descent and WarpGrad starting from the same initialisation. WarpGrad optimiser learns a warp that enables rapid convergence in model parameter space, outperforming standard gradient descent on randomly sampled loss surfaces. The WarpGrad optimisers learn a geometry that smooths the loss surface, allowing gradient descent to converge to a local minimum. Tasks are treated as 20-way classification problems with 46 alphabets after discarding some. 10 alphabets are held out for final testing, with variations accounted for by training on 10 seeds. Each alphabet has 20 raw samples, with 5 held out for evaluation. During task adaptation, raw samples undergo random affine transformations to make tasks challenging for few-shot learning. Mini-batches are sampled without class-balance, using a convolutional neural network architecture similar to Flennerhag et al. (2019). The network consists of a 3x3 convolution with 64 filters, followed by max-pooling, batch-normalisation, and ReLU activation, repeated four times. The network architecture includes 3x3 convolution with 64 filters, followed by max-pooling, batch-normalisation, and ReLU activation, repeated four times. Images are down-sampled to 28x28, resulting in a 1x1x64 feature map passed to a final linear layer. A Warp Leap meta-learner inserts warp-layers between each convolutional block. Simple warp-layers perform well, but adding capacity improves generalisation. Task parameters are meta-learned using the Leap objective, with negative log-likelihood loss evaluated on different batches to encourage generalisation. During meta-training, mini-batches of task parameters are collected into a replay buffer. Task-learners share a common initialization and fixed warp parameters for task adaptation. The experiment compares Warp-Leap, Leap, and Reptile, multi-headed finetuning, as well as SGD and KFAC with random initialization but larger batch size and learning rate. During meta-training, mini-batches of task parameters are collected into a replay buffer. The buffer is iterated over by randomly sampling mini-batches without replacement. A batch size of \u03b7 = 1 is used, and \u03c6 is updated through gradient descent under the canonical meta-objective. Up to 2000 meta-gradient steps are taken on warp parameters \u03c6 per meta-batch. Comparisons are made with standard gradient descent (SGD), KFAC, Leap, Reptile, MAML, and multi-headed fine-tuning, all benefiting from large batch sizes for higher learning rates. During meta-training, mini-batches of task parameters are collected into a replay buffer and iterated over by randomly sampling mini-batches without replacement. A batch size of \u03b7 = 1 is used, and \u03c6 is updated through gradient descent under the canonical meta-objective. Comparisons are made with standard gradient descent (SGD), KFAC, Leap, Reptile, MAML, and multi-headed fine-tuning, all benefiting from large batch sizes for higher learning rates. WarpGrad provides a principled approach that allows SGD and KFAC to use 10x larger batch sizes, enabling 10x larger learning rates, but it is computationally costly compared to Warp-Leap during meta-test time. The study evaluates WarpGrad's approach for model-informed meta-learning through an ablation study on Warp-Leap, varying warp-layers design and meta-training methods. Different meta-training protocols are tested, including using approximate objective, online meta-training, and meta-learning the learning rate for task adaptation. Learning rate meta-gradients are clipped at 0.001, with a fixed learning rate of 0.001 for online meta-training. In an ablation study on Warp-Leap, different warp-layers designs and meta-training methods are evaluated. The architecture for warp-layers is varied, including simpler versions with channelwise scaling and more complex versions with non-linearities and residual connections. Different configurations are tested, such as two stacked convolutions with different filter outputs. Task embeddings are conditioned on task statistics for gradient warping. Full results are presented in Table 3. In an ablation study, the effect of warping task loss surfaces is isolated by fixing a random initialization and only meta-learning warp parameters. Two WarpGrad architectures are evaluated, one using linear warp-layers for block-diagonal preconditioning like KFAC, and the other using a more expressive warp configuration with two-layer convolutional warp-layers. Task mini-batch sizes of 200 and task learning rates of 1.0 are used, with the same hyper-parameters as the main experiment. In an ablation experiment, warp-layers with residual connections, batch normalization, and ReLU activation facilitate task adaptation significantly better than SGD or KFAC. Going beyond block-diagonal preconditioning improves performance. The main Warp-Leap architecture is used to explore if the learned geometry is approximately Fisher, with linear warp-layers resulting in zero-centered post-warp activations. During task adaptation, Warp-Leap learns a block-diagonal approximation to the Inverse Fisher Matrix. Post-warp activations are zero-centered, with a significant difference in correlation structure compared to the expected Fisher matrix representation. The results show that WarpGrad methods behave differently from Natural Gradient Descent methods, possibly due to encoding a different geometry that allows them to leverage global information. The miniImageNet dataset consists of 100 classes with 600 images each, split into meta-training, meta-validation, and meta-test sets. The tieredImageNet dataset is a subset of ILSVRC-12 with 608 classes stratified into 34 higher-level categories. 20 categories are used for meta-training, 6 for meta-validation, and 8 for meta-testing. This slicing of the class hierarchy creates more similarity within each split and more diversity between splits, making the meta-learning problem more challenging. The tieredImageNet dataset consists of 608 classes divided into 34 higher-level categories. For meta-learning, 20 categories are used for meta-training, 6 for meta-validation, and 8 for meta-testing. Problem instances for tieredImageNet have a minimum of 732 and a maximum of 1300 images per class. Experimental protocols for few-shot classification involve sampling N classes at random, selecting K images for training, and using a disjoint set of L images for validation. Task-learners use convolutional blocks during meta-training. Task-learners in the tieredImageNet dataset used convolutional blocks with 128 filters, 3x3 kernels, and 2x2 max-pooling. The output units were mapped using a linear layer, with the last 3 task-layer parameters adapted during task-training. Other baselines struggled with 128 filters due to overfitting, achieving lower test accuracy compared to MAML and T-Nets. In experiments with 128 filters, test accuracy ranged from 46% to 49%, lower than previous results. Hyper-parameters were optimized using random grid search. Meta-training involved 60000 steps with Adam for meta-updates. Task-specific adaptation used stochastic gradient descent without momentum. Multi-shot classification used N=10, K=640, and L=50. Task-learners had 6 convolutional blocks with 3x3 kernels. Tasklearners consist of 6 convolutional blocks with 3x3 kernels and specific sizes. Hyper-parameters were tuned independently for each algorithm, version, and baseline using random grid search. The optimal hyper-parameters were chosen based on mean meta-validation test set accuracy AUC. 2000 meta-training steps were performed with averaged meta-gradients over 5 random tasks. WarpGrad outperforms baselines like Leap and Reptile in meta-learning tasks. It shows better convergence rate and final test performance. Additionally, it is evaluated in maze navigation tasks with Recurrent Neural Networks and in Reinforcement Learning environments. In maze navigation tasks, a goal location is randomly chosen and the agent must locate it and return to it multiple times. The Warp-RNN model is compared to other meta-learners in a grid of size 11x11. The task-learner is an advantage actor-critic with a hidden state size of 100 and tanh non-linearities. Training is done using Adam optimization. The Warp-RNN model is trained using Adam with a learning rate of 1e \u2212 3 for 200,000 steps on different tasks encoded in episodes. A warp-layer LSTM is introduced to modulate the task RNN, with task-adaptable parameters and diagonal warp matrices from the meta-LSTM's hidden state. The Warp-RNN model is trained using Adam with a learning rate of 1e \u2212 3 for 200,000 steps on different tasks encoded in episodes. The meta-LSTM is frozen for most of the training process, with task adaptable parameters corresponding to those of the baseline RNN. A HyperRNN is also trained, updating the LSTM with every task adaptation, but performs worse than the WarpGrad-RNN. Non-linear preconditioning in the Warp-RNN is compared to linear forms of preconditioning from prior works. Additionally, a T-Nets-RNN meta-learner is implemented with linear projections T h , T x and T b that are meta-learned in the task RNN. The Warp-RNN is meta-trained using a continual meta-training algorithm, accumulating meta-gradients during training. The implementation requires four lines of code on top of the standard training script, focusing on learning \"slow\" weights to aid in learning \"fast\" weights. The task-learner remains consistent across experiments in terms of parameters and hidden state size. The Warp-RNN converges faster and achieves higher rewards compared to baselines in experiments with the same parameters and hidden state size. The model uses a continual meta-training algorithm and task adaptation process with partitioned subtasks. The Warp-RNN model uses a continual meta-training algorithm and task adaptation process with partitioned subtasks. The adaptation involves 100 steps of online gradient descent updates for the full task sequence, with each sub-task using sub-task data only for parameter updates. A constant learning rate of 0.001 is used, and warp-parameters are fixed across the full task sequence. Meta-learning an optimiser is also described. Meta-learning an optimiser for continual learning involves fixing a random initialization prior to meta-training. A meta-objective is defined to encourage behavior that mitigates catastrophic forgetting. The meta-objective is an incremental multitask objective that averages validation sub-task losses for each sub-task in a given task sequence. This framework aims to define a meta-learned continual learning process. The meta-objective in the context of meta-learning for continual learning encourages behavior to mitigate catastrophic forgetting. It gives equal weight to all tasks in a sequence by averaging regression step losses over sub-tasks. The warp-parameters were trained using Adam with a meta-learning rate of 0.001, sampling 5 random tasks for a meta-batch and repeating the process for 20,000 meta-training steps. The meta-learned WarpGrad optimiser reduces loss during task adaptation by averaging regression step losses over sub-tasks. It retains performance on previous tasks with a minor initial loss, allowing for some degree of performance loss. After switching tasks, there is a spike in previous sub-task losses that gradually reverts back towards optimal performance. The WarpGrad optimiser facilitates positive backward transfer when switching tasks, suggesting potential for future research on deriving a meta-objective for continual learning."
}