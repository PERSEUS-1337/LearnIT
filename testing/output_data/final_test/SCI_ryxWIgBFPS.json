{
    "title": "ryxWIgBFPS",
    "content": "We propose using a meta-learning objective to maximize transfer speed on a modified distribution for modularizing acquired knowledge. Focusing on factoring a joint distribution into conditionals consistent with causal directions, we show that localized changes in distributions lead to faster adaptation. This property is used to define a meta-learning score favoring correct causal graphs for AI agents. The proposed meta-learning objective aims to maximize transfer speed by modularizing acquired knowledge and favoring correct causal graphs for AI agents. The data used for training models is assumed to be independent and identically distributed, but this assumption is often not met in real-world applications. In this paper, the focus is on how data distribution changes when transferring models to new institutions. The assumption is that changes are sparse and modularized, with only a few modules affected. This is especially relevant when distributional changes are due to interventions by agents at specific times and places. The paper discusses interventions in causality literature, focusing on how perturbations in intervened variables propagate through causal graphs to affect other variables. Causal structure is often unknown, making causal discovery challenging without strong assumptions. The paper discusses the challenges of obtaining the causal graph without strong assumptions. It suggests using out-of-distribution robustness of predictive models to infer the true causal structure. The paper discusses inferring the true causal structure and exploiting localized change for fast adaptation to transfer distribution with a model well trained on the training distribution. This is based on the assumption of independent mechanisms in the data generative process, requiring few updates for adaptation. The paper proposes a meta-learning objective to measure the speed of adaptation to transfer distribution, based on the assumption of small changes in the knowledge representation space. This approach aims to optimize the way knowledge is represented, factorized, and structured for faster adaptation. The example of temperature and altitude is used to illustrate how models can adapt faster to out-of-distribution data with a few transfer samples. This adaptation speed can guide the inference of the true causal structure of the problem. The model adapts faster when presented with data sampled after performing interventions on the true causal graph. This adaptation speed can be used to assess how well the learner fits the underlying causal graph and disentangle the correct causal variables. In order to determine the underlying causal graph between two discrete random variables A and B, samples from a transfer distribution are used in addition to original samples. The true causal graph is assumed to be A \u2192 B, and the setting of covariate shift is considered to strengthen the case. The study assumes a causal relationship A \u2192 B and investigates how quickly models can adapt to changes in the transfer distribution. The model based on the causal relationship adapts faster compared to the anti-causal model B \u2192 A. The model corresponding to the underlying causal model adapts faster, especially with a small amount of data. This property can be used as a noisy signal to infer causality direction. Gradient ascent is used for adaptation, examining how gradients of the log-likelihood behave under the transfer distribution. Proposition 1 suggests that updating only the parameters of mechanisms that changed between training and transfer distributions reduces the number of parameters needing adaptation. This impacts sample complexity, which grows linearly with the VC-dimension and number of parameters. The performance on the transfer distribution improves faster if it factorizes according to the correct causal graph, reducing the number of parameters needing adaptation. This can be tested through simulations. If the model factorizes according to the anti-causal graph B \u2192 A, parameters for marginalp(B) and conditionalp(A | B) must be adapted. Sample complexity is O(N 2 ) for anti-causal graph compared to O(N ) for true causal graph A \u2192 B. Speed of adaptation to transfer distribution is related to modularization of knowledge. Using noisy signal to improve causal structure inference iteratively. Gap between correct and incorrect models largest with small transfer data. Speed of adaptation can be quantified based on online performance after fine-tuning with gradient ascent on few examples from transfer distribution. The online likelihood is a key metric for evaluating model performance and structure learning. It is optimized through gradient ascent on a small intervention dataset, providing insights into causal graph recovery. The online log-likelihood is connected to the Bayesian score in structure learning. The Bayesian score treats the problem from a Bayesian perspective by defining priors over graphs and parameters. The online log-likelihood approximates the Bayesian score, providing a simple way to handle the intractable nature of the score calculation. In structure learning, the problem of searching for a causal structure that maximizes a score is NP-hard. Beliefs about causal graphs can be parametrized by tracking the probability of each directed edge, allowing for a smooth parametrization of graphs. This leads to a fully differentiable meta-learning objective, where beliefs are updated simultaneously by gradient descent. In a simple example with two random variables, the belief of an edge connecting A to B is represented by a structural parameter \u03b3. In structure learning, beliefs about causal graphs can be parametrized by tracking the probability of each directed edge, represented by a structural parameter \u03b3. A meta-transfer objective involves updating beliefs through gradient descent to reduce regret. The objective is to update the belief of an edge A \u2192 B by adjusting the structural parameter \u03b3. The gradient of the negative log-likelihood of the transfer data D int with respect to the structural parameter \u03b3 is pushing \u03c3(\u03b3) towards the posterior probability that the correct model is A \u2192 B. This posterior probability measures which hypothesis better explains the transfer data overall, depending on the difference in online log-likelihoods \u2206. The meta-objective aims to minimize regret and maximize online log-likelihood score, with the convergence of the structural parameter towards one of two hypotheses guaranteed. Optimizing \u03b3 is equivalent to choosing the hypothesis with the smallest regret, measured by log-likelihood accumulation during adaptation. The distribution over datasets D int is akin to tasks in meta-learning, with the gradient-based adaptation procedure linked to methods like MAML. The proposed algorithm, linked to existing methods like MAML, includes a smooth parametrization of the causal graph and a meta-transfer objective that can be extended to graphs with more than 2 variables. Experimentally, this generalization proved effective on larger graphs. The convergence result from Proposition 3 is illustrated by learning the structural parameter \u03b3 in a bivariate model. In a bivariate model, the algorithm learns the structural parameter \u03b3 with the correct causal model A \u2192 B. The experimental setups and model details are in Appendix D. The algorithm pretrains parameters for two graph candidates and samples a dataset from the training distribution. The algorithm pretrains parameters for two graph candidates and samples a dataset from the training distribution. For each episode, the models accumulate online log-likelihood and perform gradient ascent. The experiment explores different parametrizations of conditional probability distributions for discrete random variables. In an experiment, structured CPDs were used with multi-layer perceptrons to represent conditional probabilities. This method allows for parameter sharing and reduces the overall number of parameters needed. The model's belief of the correct causal model converges correctly as the number of episodes increases. The structural parameter converges to \u03c3(\u03b3) \u2192 1 with a larger value of N and tabular representation, showing the effect of parameter counting argument. Experimenting with continuous random variables A and B, the structural parameter consistently converges to the correct causal model. See Appendices D.3 and D.4 for more details on these experiments. In realistic scenarios, learning agents may only have access to low-level observations, making it challenging to assume localized changes in distributions. To address this, the proposal is to disentangle causal variables through deep learning, learning a representation where variables can be meaningful causes or effects of each other. This involves jointly learning the representation and the causal graph over latent variables, mapping raw observations to a hidden representation space. The learner maps raw observations to a hidden representation space with two causal variables using an encoder E. The encoder is trained to optimize the meta-transfer objective. The encoder's parameters and \u03b3 are considered part of the structural meta-parameters. Two raw observed variables (X, Y) are generated from true causal variables (A, B) via a decoder D. The encoder E must be learned to recover the true causal variables up to symmetries. In an experiment to validate the proposed meta-objective, the encoder and decoder are assumed to be rotations with angles \u03b8 D and \u03b8 E. The encoder maps raw observed variables (X, Y) to latent variables (U, V) to infer the causal graph A \u2192 B. The goal is for the encoder to recover the structure U \u2192 V in the learned latent space, with the possibility of V \u2192 U being a valid solution. Details of the experimental setup can be found in Appendix E. The encoder in the experimental setup aims to disentangle ground-truth variables by minimizing the meta-transfer objective. This objective is motivated by discovering causal variables and their dependencies to enable appropriate planning under interventions. The discovery of explanatory variables has been studied in various contexts, such as disentangling underlying variables and domain adaptation. The paper is related to causal discovery, meta-learning, and Bayesian structure learning. It explores how the rate of adaptation to changes in data distribution can be used to infer causal structure and identify causal variables. The study focuses on exploiting non-stationarity to make causal discovery easier. The study demonstrates theoretical results and experimental validation on causal structure learning based on the speed of adaptation to modified distributions. The work is a first step towards improving learning agents' handling of non-stationarities, aiming to enhance sample complexity and robustness. Further exploration is needed to disentangle causal variables and scale up the proposed ideas for broader application. The work aims to improve learning agents' sample complexity and robustness by disentangling causal variables, focusing on high-level representations from raw observations. This approach could enhance meta-learning and help discover relevant concepts in consciousness. The work aims to improve learning agents' sample complexity and robustness by disentangling causal variables, focusing on high-level representations from raw observations. This could provide a meta-learning approach to learn encoders outputting causal variables and understand their relationships. Important assumptions include sparse causal graphs and sparse changes in distributions. Previous studies emphasize the necessity of assumptions, priors, or biases to identify explanatory variables. Research also reviews recent work on disentangling and discusses different metrics proposed. The text discusses the challenges of causal representation learning and the transition from low-level sensory observations to higher-level causal variables. It contrasts traditional observational methods with a proposed continuous and fully-differentiable alternative that supports interventional data. Identifiability results for causal models are also mentioned, based on specific assumptions. The text proposes a meta-learning objective function for learning causal structures under localized changes in distributions and faithfulness of the causal graph. It is related to recent advances in causation, domain adaptation, and transfer learning. The text discusses a meta-learning approach for identifying features that lead to accurate predictions in different domains. It also explores non-stationarity and its impact on causal discovery. Additionally, it mentions related work on meta-learning algorithms for specialized modules and causal inference from observational data. The maximum likelihood estimation for models A \u2192 B and B \u2192 A yields the same estimated distribution over A and B. The joint likelihood on the training distribution is not enough to distinguish between causal models A \u2192 B and B \u2192 A. The estimated distributions for both models are equal under the maximum likelihood estimator. Experimentation shows that both models achieve the same log-likelihoods at convergence, making them indistinguishable based on data. At convergence, two models are indistinguishable based on data sampled from the same distribution, even on test data. Proposition 1 states that if training and transfer distributions have the same conditional probability distributions for all variables except a subset C, then the expected gradient of the log-likelihood under the transfer distribution will be zero for variables not in C. The gradient of the negative log-likelihood of transfer data with respect to the structural parameter is given by the posterior probability of the hypothesis A \u2192 B. This can be written as the difference between the online log-likelihoods of the two hypotheses on the transfer data. The gradient of the regret with respect to the structural parameter \u03b3 is derived from the previous datapoints in the graph A \u2192 B. By considering the hypotheses A \u2192 B and B \u2192 A, it is shown that p(A \u2192 B | D int ) = \u03c3(\u03b3 + \u2206). With stochastic gradient descent, the structural parameter converges towards a fixed point. The regret is defined as R(D int ) = \u2212 log M, with P 1 and P 2 as framing the stationary point in terms of p rather than \u03b3. By applying KKT conditions, we find that p must be either 0 or 1. The gradient is rewritten to highlight p, leading to an inconsistent set of equations if p \u2208 (0, 1). The solutions p \u2208 (0, 1) are not possible, leaving only p = 0 or p = 1. Meta-learning algorithm performance was assessed on data from three domains: discrete random variables, multimodal continuous random variables, and multivariate Gaussian-distributed variables. Setups for all three experiments are described, along with additional results complementing those in Section 3.3. In experiments with fixed ground-truth structure A \u2192 B, interventions were performed on cause A in a bivariate model with categorical distribution. The model had probability vectors \u03c0 A and \u03c0 B|a of size N, with variables taking N = 10 or N = 100 values. Four modules were built for marginal and conditional distributions using multinomial logistic Conditional Probability Distributions. Initial parameters were obtained by training the modules on a training set. Initial parameters for the adaptation on a new transfer distribution are obtained by training all 4 modules using gradient ascent on the log-likelihood. The maximum likelihood estimate parameters are used as the starting point for the new distribution. In the experiment, adaptation on the transfer distribution involves sampling a smaller transfer dataset with 20 datapoints. A bivariate model is used with structured CPDs parametrized with MLPs. The ground-truth model is assumed to avoid modeling bias. In the experiment, adaptation on the transfer distribution involves sampling a smaller transfer dataset with 20 datapoints. The ground-truth model is parametrized by MLPs to avoid modeling bias. The training distribution is defined with randomly initialized networks and parameters sampled using He initialization. Maximum likelihood is used on a large dataset of training samples to obtain initial parameters for adaptation on the transfer distribution. In the experiment, adaptation on the transfer distribution involves sampling a smaller dataset with 20 datapoints. The ground-truth model is parametrized by MLPs to avoid modeling bias. The training distribution is defined with randomly initialized networks and parameters sampled using He initialization. Maximum likelihood is used on a large dataset of training samples to obtain initial parameters for adaptation on the transfer distribution. Variables A and B are defined by a structural causal model with randomly generated splines and noise sampled from a Gaussian distribution. Knots of a second-order spline are created by sampling points uniformly spaced and randomly from intervals. MDNs are fitted with gradient descent, and GMMs are learned via Expectation Maximization for the transfer distribution resulting from an intervention on A. In the experiment, adaptation on the transfer distribution involves sampling a smaller dataset with 20 datapoints. The ground-truth model is parametrized by MLPs to avoid modeling bias. The training distribution is defined with randomly initialized networks and parameters sampled using He initialization. Maximum likelihood is used on a large dataset of training samples to obtain initial parameters for adaptation on the transfer distribution. Variables A and B are defined by a structural causal model with randomly generated splines and noise sampled from a Gaussian distribution. Knots of a second-order spline are created by sampling points uniformly spaced and randomly from intervals. MDNs are fitted with gradient descent, and GMMs are learned via Expectation Maximization for the transfer distribution resulting from an intervention on A. The distribution is shifted with \u00b5 sampled uniformly in [\u22121, 1]. Samples from the training distribution (\u00b5 = 0) and two transfer distributions (\u00b5 = \u00b14) are plotted in Figure D.1. Structural regret R(\u03b3) is minimized with respect to \u03b3 for 500 iterations, and the evolution of \u03c3(\u03b3) is shown in Figure D.2 as training progresses. In the experiment, adaptation on the transfer distribution involves sampling a smaller dataset with 20 datapoints. The causal structure cannot be discovered from observations alone, one must rely on the transfer distribution to tell cause from effect. Using multiple transfer distributions enables causal discovery. In the experiment, causal discovery relies on interventional distributions rather than a single observational distribution. The blue curve represents using interventions, while the orange curve represents not using them. Causal discovery fails without interventions but succeeds with transfer distributions. The variables A and B are vector-valued in a ground-truth causal model with covariance matrices. The goal is to identify the correct causal direction between A and B. To determine the causal direction between A and B, two models A \u2192 B and B \u2192 A are considered with Gaussian distributions. The models have the same number of parameters and are parametrized using Cholesky decomposition. Training distribution involves drawing parameters from Gaussian and inverse Wishart distributions. The transfer distribution results from an intervention on A, changing the marginal distribution. No pre-training is conducted for this experiment. In this experimental setting, the parameters of two models A \u2192 B and B \u2192 A are fixed to their exact values based on the ground truth distribution. Model B \u2192 A's parameters are computed analytically using Bayes rule. After 200 episodes, \u03c3(\u03b3) converges to 1, showing success in the task. The conditional p(B | A) is perturbed while the cause distribution p(A) remains unchanged. In the experimental setting, the parameters of two fixed models A \u2192 B and B \u2192 A are based on the ground truth distribution. Model B \u2192 A's parameters are calculated using Bayes rule. Soft-interventions are induced by modifying the SCM with perturbed splines, resulting in new transfer distributions for each episode. Samples from these transfer distributions are plotted in Figure D.6. The models are trained on the training SCM with a large number of samples. The meta-training procedure involves creating new splines and sampling transfer distributions for each episode. In the experimental setting, soft interventions were used to modify the SCM, resulting in new transfer distributions for each episode. However, in a failure case, using soft interventions on the effect B instead of changes on the marginal p(A) led to the recovery of an incorrect causal graph (B \u2192 A) with high confidence. This experiment differed from previous ones by changing the conditional distribution p(B | A) while keeping p(A) unchanged. In the experiment, soft interventions were used to modify the SCM, resulting in new transfer distributions for each episode. The structural parameter \u03c3(\u03b3) converged to a strong belief that the model is B \u2192 A, making it unable to recover the correct causal graph under the assumption that p(B | A) changes. The parameter counting argument from previous sections no longer holds, as both models require the same order of updates to adapt to a transfer distribution. The experiment involved soft interventions to modify the SCM, leading to new transfer distributions. The latent causal variables (A, B) were sampled and mapped to observations (X, Y) via a hidden decoder. Interventions were performed on (A, B) to acquire interventional data, which was then mapped through the decoder. The computational graph is illustrated in Figure 3.\u03b8 D = \u2212\u03c0/4 was fixed for all observation and intervention datasets. The online likelihood over recovered variables (U, V) is defined considering the encoder parameters (\u03b8 E). The meta-transfer objective is similar to the fully observable case, with gradients computed using backpropagation through time. In experiments, no observations were made. In experiments, the meta-transfer objective for learning graph structures on n variables faces challenges due to the super-exponential number of possible DAGs, making optimization NP-hard. To address this, the acyclicity constraint can be decoupled from the graph optimization and enforced as an extra penalty to the objective. The problem of optimization on the graph involves independent binary decisions on parent nodes. A heuristic approach is proposed to learn the causal graph by parametrizing the probability of a node being a parent of another. The distribution over graphs is defined using a sigmoid function. The online-likelihood is redefined to show dependence on the adjacency matrix, considering cycles in the graph. The definition in Equation (83) involves pseudolikelihood instead of joint likelihood for graphs with cycles. The regret can be decomposed as shown in Proposition 4, where structural parameters play a key role. The regret can be rewritten with structural parameters as O(n^2) scalars \u03b3 ij. The gradient of the regret wrt. each \u03b3 ij can be derived. Proposition 5 extends Proposition 2 to multiple variables, providing the gradient of the regret R(D int ) wrt. \u03b3 ij. The difference in log-likelihoods \u2206 ij of two mixture candidates is involved. Using conditional expectations, the regret can be simplified, with E (1) ij and E (0) ij representing conditional expectations of L Bi. Equation (98) can be expressed accordingly. The regret can be rewritten with structural parameters as \u03b3 ij. The gradient of the regret wrt. each \u03b3 ij can be derived efficiently using a stochastic gradient estimator. The difference in log-likelihoods \u2206 ij of two mixture candidates is involved in the computation. Proposition 5 provides an analytic form for the gradient of the regret wrt. the structural parameters, but computing it is still intractable due to \u2206 ij. The regret can be computed separately for each node of the graph using multiple samples of B in parallel. An estimator of the gradient of the overall regret with respect to the meta parameters can be defined by sampling K graphs and obtaining a weighted sum of individual binomial values. The regret can be computed for each node using multiple samples of B in parallel. An estimator of the gradient of the overall regret with respect to the meta parameters can be defined by sampling K graphs and obtaining a weighted sum of individual binomial values. This allows for updating the structural parameters \u03b3 ij using the gradient estimate in Proposition 6 without explicitly computing the full regret R(D int). Additionally, a Rao-Blackwellized estimate of the gradient of the regret can be derived based on the formulation in Proposition 5. Based on a Monte-Carlo estimate of \u2206 ij, an estimate of the gradient of the regret R wrt. the structural parameter \u03b3 ij can be defined. An experiment similar to the one in Section 2.1 is being run to validate the online likelihood measure used in the meta-transfer objective. The online likelihoods are scaled by the number of transfer examples seen for visualization. The difference in online likelihoods for both models is most significant on a small amount of data, as shown in Figure 1."
}