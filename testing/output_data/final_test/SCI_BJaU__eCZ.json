{
    "title": "BJaU__eCZ",
    "content": "Our work focuses on using generative models to understand the variability of human brain function as measured by fMRI. Two novel generative models were trained on real neuroimaging data to synthesize task-dependent functional brain images. These models, based on 3D conditional GANs and CNNs, successfully generated diverse yet task-dependent brain images. Our approach utilizes synthetic brain volumes as additional training data to enhance fMRI classifiers, resulting in significant improvements across various datasets and classification tasks. The classification results offer a quantitative evaluation of the generated images' quality. Functional Magnetic Resonance Imaging (fMRI) is used to study brain function in response to stimuli. Traditional analysis focused on group-averaged images, but now there is a shift towards understanding individual variability. Generative models are seen as valuable for this purpose, allowing for the synthesis of different brain images. Positive results in this study suggest the potential of generative models in explaining brain function variability. This paper presents positive results indicating the feasibility of generating high-quality diverse brain images. The generated synthetic brain volumes are used to enhance fMRI classifiers for decoding brain activity associated with different tasks. Previous studies have utilized classifiers like support vector machines and deep networks for decoding brain images. Cox & Savoy (2003) attempted to classify object categories based on brain images, while BID14 identified active brain regions during auditory tasks. High quality brain image synthesis addresses data issues in cognitive neuroscience by providing unlimited quantities of imaging data for computational neuroscientists to develop tools before application to real subjects. This approach using generative models has proven useful in scientific fields like particle physics and astronomy. Our work introduces the first application of Generative Adversarial Networks (GANs) to neuroscience, aiming to capture complex distributions. Despite known instability in GAN training, variants like Wasserstein GANs (WGANs) with improved training techniques have been proposed to address this issue. Dualing GANs also offer a unique approach to restrict the training process. Improved Conditional Wasserstein GANs (ICW-GAN) and Auxiliary Classifier and Discriminator GANs (ACD-GAN) are developed to synthesize fMRI brain data, providing stable training. The generated brain volumes show qualitative quality and diversity. The proposed models can generate high-quality and diverse 3D brain images, improving classification accuracy when used to augment training data. Previous studies have used neural networks for classifying brain imaging data, but not for generating it. BID20 and BID14 used fMRI data for classification and discrimination of cognitive processes. A GAN formulates a game between two deep nets to generate images. The conditional GAN can handle one-to-many mappings. The ICW-GAN generator uses a 128-dimensional encoding drawn from a normal distribution and a one-hot label vector to generate volumes. De-convolutional layers have a stride of [1,2,2,2,1]. The Wasserstein GAN (WGAN) uses Wasserstein-1 distance as the objective function, providing more stable gradients compared to classical GANs. Improved Wasserstein GAN (IWGAN) proposes a new penalty term in the critic loss based on gradient norm to address stability issues. In AC-GAN, each generated sample has a corresponding label for conditioning. 3D-GANs extend GANs to 3D object generation using three-dimensional convolution in both generator and discriminator. In this section, two models for fMRI data generation are introduced: ICW-GAN and ACD-GAN. ICW-GANs are formulated as a noncooperative two-player game between a generator and a discriminator, aiming to minimize the Wasserstein distance. The model structure of 3D ICW-GAN and ACD-GAN is presented in Sections 3.1 and 3.2 respectively. IW-GANs provide a stable method for enforcing the Lipschitz constraint using a gradient penalty. The model extends IW-GAN by using 3D convolution for fMRI data and conditioning the discriminator and generator on labeled data. The generator consists of three convolutional layers with specific kernel sizes and strides, while the discriminator architecture mirrors the generator. The ICW-GAN model includes a tanh layer at the end and utilizes conditioning labels for supervision. It applies a stable upper bound for Wasserstein distance and 3D convolution methods for 3D object generation. Label information is concatenated to input and hidden layers, transforming one-hot vectors to appropriate sizes. The ICW-GAN model utilizes conditioning labels for supervision and applies a stable upper bound for Wasserstein distance. It transforms one-hot vectors to appropriate sizes and concatenates label information to input and hidden layers. The objective function of the model includes a gradient penalty coefficient \u03bb. The model aims to enlarge datasets for downstream tasks like classification using synthetically generated samples. The developed generation procedure is evaluated using downstream classification processes. A classifier is trained with real or real plus generated data, and a conditional GAN architecture is used to jointly train the generator, discriminator, and classifier. The discriminator assesses the probability of samples being real or generated, while the classifier provides class label probabilities. Labels are passed through the generator and discriminator to condition the adversarial process, without being used in the classification stream. The classifier loss, L C, is the log-likelihood of the correct class, while the discriminator loss, L D, includes an additional classifier component. The generator loss function, L G, consists of the likelihood of fake images and a part of L C. The discriminator loss function is given by L D = L + L C. The models are evaluated on three different datasets from Neurovault using generated fMRI data. The original images are downsampled to lower and higher spatial resolutions for training. In Section 3, the models for generating low and high resolution data are presented. The architectures include 3 convolutional layers for low resolution and an additional convolutional and deconvolutional layer for high resolution. The classifier in ACD-GAN uses 4 convolutional layers for high resolution data. Qualitative and quantitative results for generated 3D volumes are shown, with cross-validation used to assess classifier performance. Collection 1952 dataset contains 6573 brain images with 45 classes and 19 sub-classes. In experiments, a subset of 36 out of 45 classes with 19 sub-classes is used. Data splitting is based on image count, with a focus on ensuring test data consists of real images only. ICW-GAN and ACD-GAN are trained for 2500 epochs with specific parameters, producing 2-D brain volume projections. The diversity of generated brain images is examined using multi-scale structural similarity (MS-SSIM) scores. Higher MS-SSIM values indicate more similarity between images. Results show that classes with mixed data have lower MS-SSIM scores compared to real training data. Classes with mixed data have lower MS-SSIM scores compared to those with only real training data, indicating higher sample variability. In 26 \u00d7 31 \u00d7 23 resolution, 69.4% of classes with mixed data show lower MS-SSIM scores. Classification performance is evaluated using real images for testing, with results shown in Table 1. The classifier types used are SVM and deep net ('NN'), with the deep net classifier generally performing better. In dataset 2138, 1847 brain images are divided into 61 classes with 50 labels. 70% of the images are used for training and 30% for testing. Models are trained for 1000 epochs without development data. The brains are downsampled to volume sizes of 13 \u00d7 15 \u00d7 11 and 26 \u00d7 31 \u00d7 22. ACD-GAN performs slightly better than ICW-GAN in low resolution settings. The ACD-GAN outperforms the ICW-GAN in low resolution settings. Dataset 3 contains 503 brain images, with subjects responding to 30 images from the International Affective Picture Set BID2. The 30 images were used to train the Picture Induced Negative Emotion Signature. The brain volumes in this dataset have two shapes: 79 \u00d7 95 \u00d7 68 and 91 \u00d7 109 \u00d7 91, which are conformed to smaller sizes. Classification results are summarized in TAB5. The ACD-GAN outperforms the ICW-GAN in low resolution settings, with improved accuracy scores compared to ICW-GAN for most metrics. Results show that the proposed methods achieve much better performance on three datasets, surpassing a 3-D AC-GAN applied to the same dataset. The proposed approach using a 3-D conditional GAN generates high-quality diverse and task-dependent brain images, improving accuracy metrics. This method outperforms a 3-D AC-GAN in low-resolution settings and inspires further research on generative models for brain imaging data. The study demonstrates that synthetic data augmentation improves classification accuracy in predictive models using a mix of synthetic and real data. Future work includes qualitative evaluation by experts, exploring various applications, and investigating individual variability in neuroimaging. Plans also involve expanding models to combine data from multiple studies with different labels. In Figure 6, a 3-fold cross-validation strategy is illustrated using training and test data. Test data is partitioned into three folds, maintaining class proportions. Each round uses one fold as test data and the remaining as training data. Evaluation metrics are averaged over three rounds. The experiment was conducted on low resolution and synthetic data. Variances of evaluation metrics were calculated for different cross-validation settings. The experiment conducted involved 3-fold, 5-fold, and 10-fold cross-validation on mixed 'Real+Synth.' data of collection 1952 in a low resolution setup. The accuracy differences were found to be significant with small variances. The ICW-GAN training loss curve showed stability in the proposed Wasserstein variants. Additionally, the quality of generated data was evaluated by training with only generated data and testing with real data using a deep net classifier. Varying the number of input samples for each class was also explored. The experiment involved cross-validation on mixed 'Real+Synth.' data of collection 1952 in low resolution. Test accuracy improves with more artificial training data. Results show generated data can be as effective as real data for classification. Training strategies using synthetic data and a Gaussian Mixture Model were compared in Table 6. The study compared training strategies using synthetic data with a Gaussian Mixture Model on collection 1952. The deep net classifier was used for all strategies, achieving higher evaluation scores than the GMM, especially with only synthetic data. NeuroSynth 3 was used for qualitative analysis of generated brain images, showing correlation to specific activity patterns. The analysis report presents the top 10 correlations of a generated brain with a supervised class of \"Non-human sound, auditory.\" The brain volume and its corresponding report are shown in Figure 9. A multilabel classification strategy is used on low-resolution data from collection 1952, encoding classes in 19 dimensions representing sub-labels. This representation is complex due to the significantly larger probability space. The study uses SVM to train real and synthetic data from ICW-GAN for multilabel classification on low-resolution brain images. Accuracy scores with mixed data outperform the baseline, even in this demanding task. Real images from collection 1952 are presented with their labels in 2D projections. The study presents real and synthetic brain images from collections 1952, 2138, and 503 at low resolution. Different classes and categories are assigned to the images, showcasing various cognitive functions and visual patterns."
}