{
    "title": "rylU4mtUIS",
    "content": "Humans have the ability to classify images despite degradation, attributed to interactions between feedforward and feedback pathways in the visual cortex. A new neuro-inspired model, CNN-F, combines bottom-up and top-down signals for approximate belief propagation. CNN-F disentangles latent variables across layers and outperforms baseline CNN in robustness to image degradation. It can restore original images from degraded ones effectively. The CNN-F model effectively restores original images from degraded ones with high accuracy and minimal artifacts. Unlike human vision, CNNs are susceptible to accuracy drops in the presence of image degradation or adversarial attacks, indicating a limitation in capturing the complexity of human vision. The human visual cortex's feedback connections and recurrent circuits play a crucial role in object recognition. Recent studies suggest that recurrent circuits are crucial for core object recognition. A model has been proposed that extends CNN with a feedback generative network, moving towards more brain-like CNNs. The inference of the model is carried out by the feedforward only CNN. Despite the success of CNN-F (0 iterations) in semi-supervised learning and out-of-distribution detection, a neuro-inspired model for more accurate inference is desired for robust vision. Our work introduces the Convolutional Neural Network with Feedback (CNN-F) for more accurate inference by incorporating recurrent structures and approximated loopy belief propagation. The CNN-F model shows improved robustness to image degradation compared to traditional CNNs, with the ability to restore degraded images when trained on clean data. CNN-F is capable of restoring degraded images with high accuracy by generating images using features computed by a CNN. Latent variables in CNN-F capture uncertainties in the rendering process, with a prior distribution designed to capture dependencies across layers. The model matches a feedforward CNN in inference for optimal latent variables given an image and label. The generation process in CNN-F involves translation of rendering templates based on local maximum from Maxpool and deciding whether to render a pixel based on activation in the feed-forward CNN. The structured prior captures dependencies among latent variables across layers, and JMAP inference of latent variable z in CNN-F is a CNN with feedback using k-iteration. CNN-F (k iterations) performs approximated loopy belief propagation by propagating along both directions of the model. The generated image h(0) is fed back to the bottom-up pathway for inference, allowing information from later layers to update estimations at early layers. The CNN-F model uses top-down messages to correct noisy estimations at early layers in the network. It involves a feedforward process with adaptive operators and translation matrices. The study focuses on robustness, image restoration, and disentanglement of information in latent variables. Training involves a 4-layer CNN and CNN-F (10 iterations) with corresponding architecture. The study involves training a 4-layer CNN and CNN-F (10 iterations) on the clean MNIST dataset. The CNN achieves a test accuracy of 99.1%, while CNN-F achieves 95.26%. Experimental results show that CNN-F promotes disentanglement of latent factors across layers, capturing different essences of the reconstructed image, such as strokes forming MNIST digits. In the experiment, a CNN-F with 3 convolutional layers was trained on MNIST to capture strokes forming digits. Latent variables z k at different layers in CNN-F were used to reconstruct images of digits 0 and 1. The latent variables at each layer captured strokes at specific locations, with z 3 focusing on the center and z 2 extending the digits. Including z 1 completed the reconstruction. The CNN-F model effectively disentangles latent factors across layers, as shown by its reconstruction of digits. It is more robust than CNN in noisy conditions. CNN-F can denoise, deblur, and inpaint images with added noise, blur, and occlusion. Feedback iterations improve image restoration, aligning with neuroscience studies on automatic image sharpening. The proposed CNN-F model utilizes feedback to automatically sharpen images, aligning with neuroscience studies. It will be scaled up to ImageNet for further training and tested for robustness against adversarial attacks. Additionally, the similarity between CNN-F's latent representations and neural activity will be examined to evaluate its effectiveness as a model for human vision. The CNN-F model incorporates feedback connections and approximate loopy belief propagation for inferring latent variables. It is more robust than CNN on corrupted images and can restore degraded images when trained on clean images."
}