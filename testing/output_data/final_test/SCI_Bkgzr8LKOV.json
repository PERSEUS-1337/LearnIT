{
    "title": "Bkgzr8LKOV",
    "content": "In this paper, a Seed-Augment-Train/Transfer (SAT) framework is proposed for generating synthetic seed image datasets for languages with different numeral systems using open font file datasets. The seed dataset is augmented to create a synthetic training dataset, which is used to train a deep neural network and test on real-world handwritten digits datasets in five Indic scripts. The approach is showcased qualitatively by training a Boundary-seeking GAN (BGAN) to generate realistic digit images and testing a CNN trained on synthetic data on real-world datasets, demonstrating a nexus between font datasets and transfer learning for universal digit classification in any script. This paper focuses on generating synthetic datasets for Indic scripts using open font files to achieve high accuracy digit classification. The process involves using deep generative models like VAE and GAN to synthesize data and train deployment-worthy machine learning models. The approach addresses the absence of MNIST-scale datasets for Indic scripts by leveraging freely available OFL font files. The study utilizes Open Font License 1 (OFL) font files to create synthetic datasets for Indic scripts. A handwritten grid of digits is scanned and segmented to generate mnist-ized digit images. A 2-step sanity check is performed for MNIST compatibility across different languages, focusing on class 0 images. The study uses OFL font files to create synthetic datasets for Indic scripts and performs a 2-step sanity check for MNIST compatibility across different languages, focusing on class 0 images. Predictions for this class are based on morphological similarity between modern digit system and Indic languages. High rates of correct misclassifications are observed for Kannada digits 3 and 7 resembling 2 in the Hindu-Arabic system. Accuracies of 1.0 and (1.0, 0.977) are obtained for the checks. In this study, OFL font files were used to create synthetic datasets for Indic scripts. The Lohit font family was utilized to generate textual glyphs for 11 languages. A seed dataset was created using Lohit True Type Font files for each language, and a script combining Python Imaging Library text insertion ability with Lohit font glyphs was used to generate image datasets. The study also mentions the availability of a variety of other fonts from sources like Google fonts for creating seed image datasets. The study utilized OFL font files to create synthetic datasets for Indic scripts, specifically using the Lohit font family for 11 languages. A seed dataset was generated with Lohit True Type Font files, and various other fonts like Google fonts were also mentioned. The goal was to intelligently distort seed images to create a realistic synthetic dataset for human handwritten digit classification. The Elastic distortion method was used for augmentation, followed by training an AC-GAN on the augmented dataset. The study utilized OFL font files to create synthetic datasets for Indic scripts, specifically using the Lohit font family for 11 languages. A seed dataset was generated with Lohit True Type Font files, and various other fonts like Google fonts were also mentioned. The goal was to intelligently distort seed images to create a realistic synthetic dataset for human handwritten digit classification. The Elastic distortion method was used for augmentation, followed by training an AC-GAN on the augmented dataset. Augmented dataset training involved an AC-GAN BID7 using various image augmentation techniques such as additive noise, intensity shifting, scaling, rotation, translation, flipping, and warping. The Elastic distortion method with control parameters \u03b1 and \u03c3 was focused on, with \u03b1 set to 8 for each Indic script and \u03c3 varied to create realistic perturbed images. The implementation in the imgaug python library was used for these experiments, resulting in realistic-looking image distortions in the interval of \u03c3 \u2208 [1.5, 2.5]. The Elastic distortion method with control parameters \u03b1 and \u03c3 is used to generate synthetic datasets for five languages. Generative Adversarial Networks (GANs) are employed to create samples resembling the true data distribution. The Auxiliary Classifier GAN (ACGAN) is utilized for generating synthetic data with labeled classes. The generator in the GAN model is trained to produce real and fake images, as well as classify them into different classes. The discriminator is trained to distinguish between real and fake images and classify them correctly. The training process involves sampling images from the generator for each class and adjusting the generator parameters to maximize the objective function. The discriminator is trained to maximize the log-likelihood of the correct source and class, while the generator is trained to maximize the log-likelihood of the correct class minus the correct source. Regularization techniques such as dropout and batch normalization are used during training. The ACGAN generator incorporates class conditional embeddings in the latent space, enhancing structure and stability during training. It produces high-quality samples with corresponding class labels, crucial for measuring classification accuracy. Images generated by ACGAN after 10 epochs for five languages show distinct blocks separated by white space. The SAT framework showcases efficacy through qualitative and quantitative approaches. The first approach involves training a BGAN model on shallow synthetic data to generate realistic handwritten digit images. The second approach trains a CNN solely on synthetic data, testing with real-world data and a small amount of real data. GANs face limitations in generating samples differentiable with parameter changes. Boundary-seeking GANs (BGANs) address the challenge of training GANs with discrete data by using a policy gradient based on KL-divergence. The objective function of BGANs focuses on convexity, with a generator G\u03b8: Z \u2192 X and a neural network F\u03c6: X \u2192 R. The typical concave generator loss for continuous data hinders convergence, leading to reformulation for better stability in learning. The concave optimization is reformulated as convex by training the generator towards the decision boundary of the discriminator for stability. Adam Optimizer is used in implementation. Realistic imagery emerges after 5000 epochs. Accuracy comparisons are shown in Figure 7 using a synthetic training dataset with varying accuracies. After training the ACGAN, accuracies ranged from 60% to 76% for five languages. Adding 20% real-world data significantly improved accuracies due to test-set size and morphological differences in digit representation. For example, in Gujarati, accuracy for digit 6 increased from 0.7% to 95% with real-world data. Overall test accuracy increased for all languages when real-world data was introduced. The 'Purely synth + 280 real-world training' dataset option significantly improves overall test accuracy for all languages. A transfer learning framework called Seed-Augment-Train/Transfer (SAT) was introduced for real-world handwritten digit classification in Indic languages using 5 new real-world digit datasets. The efficacy of this SAT-based approach was demonstrated for digit classification and training GANs. The goal is to highlight the potential of synthetic-to-real transfer learning and the availability of semi-synthetic training data in Font files. Expanding efforts include transfer learning with a small dataset to capture handwriting variations and generative modeling of deviations in handwritten digits using the extended MNIST dataset. This approach will be applied to deep augment seed datasets."
}