{
    "title": "rkg2m6hXcE",
    "content": "Temporal logics are used to describe dynamic system behavior and as a language for goal definitions in task planning. This paper focuses on inferring specifications that describe temporal differences between two sets of plan traces, presenting a Bayesian probabilistic model for this purpose. The model is shown to be effective, scalable, and robust across various planning domains and a simulated air combat mission. In this paper, the team is deliberating on plan options and seeks explanations for how two sets of divergent plans differ. They aim to identify distinguishing patterns between group behaviors to refine systems iteratively. The focus is on generating contrastive explanations by discovering specifications satisfied by one set of plans but not the other. This work contributes to plan recognition, system diagnosis, and excuse generation for explaining plan differences. In this work, the team focuses on explaining differences between multiple plans using a specification language to achieve clear and effective plan explanations. They leverage linear temporal logic (LTL) to capture temporal relations of state variables in order to analyze competing systems, compliance models, and detect anomalous behavior of users. The text discusses using LTL specifications to describe differences between plans, focusing on capturing temporal relations of state variables. It mentions the use of LTL in industrial systems and planning algorithms to compactly describe temporal properties. Additionally, it highlights the development of SAT-based algorithms to construct LTL specifications that assert contrast between two sets of traces. The text introduces a Bayesian inference model for generating multiple explanations of plan traces, demonstrating robustness to imperfect input and scalability in large hypothesis spaces. It emphasizes the importance of plan explanations in automated planning systems and human collaboration. Automated planners and humans collaborate in plan generation, with a focus on developing user-friendly interfaces for interpreting planner outputs. However, these outputs often require expert interpretation and lack direct explanations for decision-making. Explanations in planning are essential for optimizing plan costs based on a human's mental model of the world. Our model focuses on explaining differences in specifications governing two distinct sets of plans given as input, using contrastive explanations to identify relevant differences between the input pair of models. This approach iteratively updates an incomplete model to a more complete world model. Our approach focuses on producing differences in constraints among observed plans, using sets of plans as input rather than planning models. We emphasize explanations from realized plans themselves, leveraging LTL as an explanation language. Environment/world models can provide context but are not necessary for our approach. Our work leverages LTL as an explanation language to provide contrastive explanations for XAIP BID9, focusing on why certain plans were chosen over others. Previous research has explored mining LTL specifications from action traces to understand plan dynamics. The text discusses the use of LTL templates to infer task specifications from demonstrations. Unlike existing approaches, Neider and Gavran proposed SAT-based algorithms to generate contrastive explanations by delineating between positive and negative sets of traces. Their algorithms construct minimal LTL specifications without predefined templates but may fail with imperfect traces. In contrast, the presented probabilistic model offers multiple contrastive explanations and robustness to noisy input. The proposed model is the first to infer contrastive LTL specifications for sets of traces in PDDL domains. Linear Temporal Logic (LTL) provides an expressive grammar for describing temporal behavior through propositions, Boolean operators, and temporal operators. Its truth value is determined with respect to a trace, which is a sequence of truth assignments for propositions. Linear Temporal Logic (LTL) involves sequences of truth assignments for propositions in V. The notation \u03c0, t |= \u03d5 indicates \u03d5 holds at time t. LTL syntax includes propositions, contiguous intervals, and past occurrences. Higher-order temporal operators like F (eventually) and G (global) are also used. Linear Temporal Logic (LTL) involves sequences of truth assignments for propositions in V. The notation \u03c0, t |= \u03d5 indicates \u03d5 holds at time t. LTL syntax includes propositions, contiguous intervals, and past occurrences. Higher-order temporal operators like F (eventually), G (global), and R (release) are used. Interpretable sets of LTL templates have been defined and integrated into software verification systems. Some widely used templates are shown in Table 1. A contrastive explanation describes \"why event A occurred as opposed to some alternative event B.\" In this problem, events A and B represent two sets of plan traces. The form of why may be expressed in various ways, but in this case, it is defined according to the plans' satisfaction of a constraint. A contrastive explanation is a constraint that is satisfied by one set of plan traces but not by the other. The accuracy of the explanation is measured by how well it separates the positive and negative traces. The input consists of two sets of traces, and the output is a classification accuracy value ranging from 0 to 1. In an unsupervised classification problem, using LTL specifications for contrastive explanation, a set of interpretable LTL templates are utilized to compose candidate formulas for identifying plan differences. The LTL specifications provide powerful semantics for capturing quantification, with a hypothesis space including predefined templates. The goal is to infer the formula that maximizes the contrastive explanation criterion using Bayesian inference. The goal is to infer the latent LTL specification \u03d5 using Bayesian inference. The generative model involves choosing a template, number of conjunctions, and proposition instantiations.\u03d5 is generated based on a prior distribution, and the likelihood of observing evidence X given \u03d5 is considered. The designer can set hyperparameters to assert preferences for mining specific LTL templates. The number of conjunctions in the specification is determined by a geometric distribution with a decay rate, promoting concise specifications to prevent overfitting. Propositions are selected using categorical distributions based on probability weights. The designer can control probability weights to favor certain types of propositions in generating explanations. Different forms of variable importance can be applied to set these weights, allowing for the identification of the most salient propositions in a given domain. The full prior function, P(\u03d5), is evaluated based on the description of \u03d5 by T, N, and {p}. The likelihood function P(X | \u03d5) is calculated based on the input sets of traces in the satisfying and non-satisfying sets, generated by different solutions to the planning problem. The traces are assumed to be conditionally independent of each other, with probability distributions for T, N, and {p} being completely described by \u03d5. The likelihood function P(X | \u03d5) is calculated based on sets of traces that are conditionally independent of each other. LTL satisfaction checks are conducted over the traces belonging to different sets, with probabilities set based on adherence to the contrastive explanation criterion. This method allows for robustness to noisy traces and outliers, with the ability to adjust the importance of positive and negative sets. The method for LTL satisfaction checks involves representing \u03d5 as a tree and recursively evaluating each temporal operator. The method involves representing \u03d5 as a tree and recursively evaluating each temporal operator. To speed up LTL satisfaction checks, evaluation results are memoized and re-used. A Markov Chain Monte Carlo method, specifically the Metropolis-Hasting algorithm, is used to draw samples approximating the true posterior distribution. The proposal function samples a new candidate \u03d5 using a drift kernel or by sampling from the prior distribution. The method involves representing \u03d5 as a tree and recursively evaluating each temporal operator. To speed up LTL satisfaction checks, evaluation results are memoized and re-used. A Markov Chain Monte Carlo method, specifically the Metropolis-Hasting algorithm, is used to draw samples approximating the true posterior distribution. The proposal function samples a new candidate \u03d5 using a drift kernel or by sampling from the prior distribution. By performing moves on the current candidate LTL \u03d5 within the current template T, new conjuncts can be added or existing ones removed, with probabilities associated with each move. The drift kernel perturbs \u03d5 while staying within the current template, transitioning to a new template probabilistically when sampling from the prior. The proposal function F ensures ergodicity in the Markov process, guaranteeing sampling from the true posterior distribution. Accepted samples approximate the true posterior, with MAP estimates determined from relative frequencies. The model was evaluated for inferring contrastive explanations from traces in International Planning Competition domains. Plan traces were generated by injecting ground truth \u03d5 into PDDL files and enforcing valid plans. The LTLFOND2FOND tool BID4 was used to inject LTL formulas into planning files, generating valid plans and execution traces. This process was repeated with the negation of the ground truth specification to create contrastive explanation solutions. The model was evaluated on six IPC benchmark domains with varying problem instances. Twenty traces were collected for each set, testing different problem instances with increasing vocabulary size. We tested problem instances with increasing vocabulary size and randomly generated ground specifications using LTL templates. Hyperparameters were set uniformly with MH sampler run for 2000 iterations. Results were robust to parameter settings. Our experimental results were robust to different parameter settings. The model was evaluated against the SAT-based miner developed by BID22 and brute force enumeration. Delimited enumeration with a random subset of brute force samples was used to avoid a time out. Inference results on tested domains and problem instances of varying complexity are shown in TAB2. Our probabilistic model outperformed the baseline and state-of-the-art miner by generating multiple, near-perfect contrastive explanations with high accuracy. The runtime for our model ranged between 1.2-4.7 seconds, unaffected by an increase in complexity. The SAT-based miner by Neider and Gavran struggled to find solutions within a five-minute cutoff, especially for problems with complex requirements. Increasing the depth of solutions exponentially increased the size of the compiled SAT problem, leading to timeouts for problems with depth \u2265 3. Testing for robustness involved perturbing input data by swapping traces between \u03c0 A and \u03c0 B, with accuracy evaluated on the perturbed data. The MAP estimates inferred from input data X were evaluated for accuracy, showing promising results even at a moderate noise rate. However, robustness declined sharply as noise rate increased past 0.4. The Neider and Gavran miner struggled with noise rates \u2265 0.1. Large values of M indicate various ways to express plan trace differences using LTL semantics. The accuracy of \u03d5 * with respect to increasing noise rate is evaluated on the original input X. Relations like template subsumptions or precondition/effect pairs should not be favored without understanding their impact on accuracy. Relations like template subsumptions or precondition/effect pairs should not be favored without understanding their impact on accuracy. A new contrastive explanation can be created by including stationary propositions or tautologies specific to the planning problem. Tautologies by themselves cannot be contrastive explanations as they can never be dissatisfied. The model excluded vacuous explanations and showed an increase in M as |V| increased. Research avenues are opened for determining a minimal set of {\u03d5} and assessing logical dependence or metric space between LTL specifications. Assessing logical dependence or metric space between two LTL specifications is challenging. An inference model was applied to a large force exercise domain, collecting realistic aircraft behavior data. The model generated ten unique contrastive explanations with 0.96 accuracy, including criteria for friendly attrition rate and striker behavior. The model inferred rules for friendly attrition rate and striker behavior, ensuring attrition is less than 25% before weapon release. It couldn't generate perfect contrastive ground due to complex LTL templates. Explanations aligned with expert's goal of achieving air superiority. Probabilistic Bayesian model used to infer contrastive LTL specifications. The probabilistic Bayesian model presented infers contrastive LTL specifications efficiently and robustly, allowing for the incorporation of prior knowledge. It can be extended to multiple input sets for pairwise comparisons. Future work includes exploring proposition saliency and deriving minimal explanations, as well as testing the model in human-in-the-loop settings to understand planning heuristics' explicability. The explanation of planning heuristics' explicability to humans is important."
}