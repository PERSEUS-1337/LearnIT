{
    "title": "rJHcpW-CW",
    "content": "In this paper, a mix-generator generative adversarial networks (PGAN) model is proposed to approximate complex real distributions using multiple disjoint generators. An adjustment component is introduced to learn boundaries between generators and reduce instability in the training process. The model addresses the issue of linearly growing training time by training generators in parallel, allowing scalability to large computation frameworks. The paper also presents an efficient loss function for the discriminator and effective adjustment components for the generators. The paper introduces a mix-generator generative adversarial networks (PGAN) model with an adjustment component to learn boundaries between generators. Extensive experiments on synthetic datasets, MNIST, and CIFAR-10 show that the error from the adjustment component successfully separates generated distributions. Generative Adversarial Networks involve a minimax game between a generator and discriminator, aiming for Nash Equilibrium where the generated distribution equals the real distribution. The paper proposes a new model called mix-generator generative adversarial networks (PGAN) to address the mode collapse problem in GANs. The model uses multiple generators to capture different parts of the real distribution, with an adjustment component to separate them and penalize overlaps. Additionally, a shrinkage adjustment component gradually reduces the impact of overlaps. The proposed approach in the paper introduces a shrinkage adjustment method to address issues of competition and one beats all scenarios in GANs. It suggests using reverse KL divergence and a gradual reduction of the adjustment weight to mitigate these problems. The paper proposes a multi-generator model with a shrinkage adjustment method to improve GAN training. This approach allows for parallelized training among generators and stable convergence without pre-defining the number of generators. In Section 3.3, a shrinkage component method is proposed to reduce the penalty for convergence. The shared memory is organized for parallel training to reduce time, and the algorithm scales well on large platforms. Section 4 demonstrates the effectiveness of the design using synthetic and real data, highlighting the focus on improving GAN with a zero sum loss function and reverse KL divergence. To address the mode collapse issue in GANs, various approaches have been proposed. Unrolled GANs involve using multiple copies of the discriminator for back-propagation, while BID22 introduced a reconstructor network to detect mode collapse by aggregating the support of the mapped distribution. Additionally, BID16 viewed the discriminator loss as a variational lower bound of f-divergence, aiming to approximate a tighter lower bound through minimax game optimization. BID25 interpreted GANs as energy models, utilizing an autoencoder as the energy function or having the discriminator learn the manifold. In energy-based GANs, an autoencoder is used as the energy function and the discriminator learns the real distribution manifold. The model is illustrated using a hinge loss, and BID3 extends this by measuring the Wasserstein distance. Mode collapse can be avoided with a proper energy function and well-learned data manifold. Wasserstein distance or Earth Mover distance is preferred over f-divergence for stability during training. BID2 introduces a multi-generator scheme for Wasserstein GANs, proving equilibrium conditions. Adaboost is used in BID24 for weight adjustment. In energy-based GANs, the model uses an autoencoder as the energy function and the discriminator learns the real distribution manifold. BID3 extends this by measuring the Wasserstein distance to avoid mode collapse. BID24 utilizes Adaboost for weight adjustment in the game. BID4 proposes a multi-discriminator model to resolve mode collapse and improve data capture. The model design involves training K generators to approach the real data distribution, with disjoint support for each generated distribution. An adjustment component is used to dynamically classify the generated distributions. In the proposed PGAN model, an adjustment component is used to classify generated distributions dynamically. The structure of PGAN includes simple generators connected by shared memory with K slots. Each slot contains a sample part for generated samples and a validation part for discriminator and adjustment component values. Communication between components occurs only through shared memory during training. In the PGAN model, generators update parameters based on responses from the discriminator and coprocessor in two phases: training and validation. During validation, data points are fed forward and errors are calculated. The training and validation phases can be swapped within a batch or epoch. The response time of the discriminator may vary with the number of generators. The back propagation time is a multiple of the forward step time. In the PGAN model, generators update parameters based on responses from the discriminator and coprocessor in two phases: training and validation. The response time of the discriminator may vary with the number of generators. To reduce waiting time for the generator, duplicated discriminators are needed, with one copy for every generator. The loss function minimizes the Jensen-Shannon Divergence between the mixture of generators and real data. Adjustment component loss in PGAN treats generators differently based on their performance, aiming to maximize the Jensen-Shannon Divergence. Each generator is trained using feedback from the discriminator and an adjustment component. The game dynamics may not converge with all generators active, so a weight factor is gradually decreased to simplify the game to two players. Initially, the adjustment component dominates to prevent distribution overlap, but as training progresses, the support for each generated distribution expands. During training, the distance between generated distributions in PGAN may saturate and not decrease due to non-overlapping generators. To address this, the adjustment component is gradually reduced to allow overlaps, causing close distributions to merge. Different ways to choose \u03b2 include setting a constant value, decreasing based on iterations or generator loss, or combining methods. Constant \u03b2 controls diversity but may not converge effectively. The third method in PGAN adjusts \u03b2 when J G becomes unstable due to the one-beat-all problem, forcing out specific generators with high losses to prevent oscillation in the generated distribution. This method considers both the number of iterations and the difference in generator loss. Algorithm 1 details PGAN, where the generator stores samples in shared memory, and the discriminator and adjustment component provide error feedback. The adjustment component fetches the sample and returns the error to shared memory. More discriminator and adjustment components are needed to reduce waiting time. Assigning each generator a copy of the discriminator and adjustment component uses O(K) resources. A powerful discriminator can reduce worst-case time by guiding the generator. The running time for the adjustment component is negligible due to small model complexity and data size. The adjustment component fetches samples and returns errors to shared memory. More discriminator and adjustment components are needed to reduce waiting time. Assigning each generator a copy of the discriminator and adjustment component uses O(K) resources. The running time for the adjustment component is negligible due to small model complexity and data size. The distance being minimized is D KL (P g k ||P data ) and \u2212D JSD (P g k ||P g \u2212k ). The optimal discriminator given current generator G has a close form D * G = P data (x) P data (x)+Pg(x). Minimizing the loss for the generator is equivalent to minimizing a specific equation. The text discusses minimizing the first term in the generator loss, which is equivalent to minimizing the reverse KL divergence. It also mentions that reducing \u03b2 in the generator loss leads to capturing only specific modes. Additionally, as \u03b2 approaches zero, the gradient of the generator vanishes, resulting in convergence of the algorithm. When \u03b2 approaches zero, the gradient of the generator vanishes, leading to algorithm convergence. The shrinkage adjustment component method is crucial for convergence, even if not all modes of P data are captured. The reverse KL divergence helps stabilize the model, while using JSD or KL Divergence may disrupt the separation of generators. In experiments on synthetic datasets, MNIST, and CIFAR-10, our algorithm effectively captures separate modes and handles competition among generators. Introducing a shrinkage component allows generators to merge and converge. Key setup includes learning rate 0.0002, minibatch size 128, and specific optimizers. The study implemented an optimizer for Hogwild trained discriminator with \u03b2 set to 1 at the beginning and decaying exponentially. The models used LeakyReLU and weight initialization from DCGAN. Two synthetic datasets were generated to analyze the adjustment component and shrinkage method. The generator, discriminator, and adjustment component were constructed as three-layer fully connected neural networks. The first dataset consisted of 8 non-overlapping Gaussians, with 8 generators trained from random initialization. Results showed generators spreading out initially, with penalties causing them to diverge after a certain number of steps. The study implemented an optimizer for Hogwild trained discriminator with \u03b2 set to 1 at the beginning and decaying exponentially. Two synthetic datasets were generated to analyze the adjustment component and shrinkage method. The number of generators was increased to 10 to capture all 8 modes. The strong penalty caused two generators to compete for the same mode, illustrating the function of the shrinkage component in mediating competition. The study used MNIST and CIFAR-10 datasets to test the model's effectiveness, evaluating generated samples with the Inception Score. A strong discriminator was designed for training, addressing the gradient vanish problem. The study tested a relatively strong discriminator with a high learning rate in reverse KL GAN. Different numbers of generators were used on the MNIST dataset, showing that increasing the number of generators decreased diversity score per generator but increased diversity score for mixed generators. The dataset's simplicity limited the observable increase in diversity. All generator losses were low, and no generator was forced out. The Inception Score for the mixed generator was high due to the dataset's simplicity. Increasing the number of generators in the study led to a decrease in the score for each generator due to search space limitations. The diversity score increased with more generators but eventually reached saturation. The Inception Score also increased with more generators, peaking at 7.15 with over 12 generators. The threshold for these scores depended on dataset complexity, model capacity, and adjustment component. The training time for the sequential mix generator model for CIFAR-10 dataset is 115.4 min. PGAN with 10 generators and Hogwild updated discriminators takes 51.6 mins, which is 44.7% of the sequential running time. Synchronized updated discriminator takes 53.5% of the regular time. Running time is still far from optimal. Convergence rate is not guaranteed for Hogwild training without satisfying the sparsity condition. Optimal discriminator condition cannot be guaranteed for synchronized updating. In this paper, a mixed generator method is proposed to address mode collapse in GANs. The algorithm is parallelizable and scalable to large platforms. A reverse KL divergence loss function and an adjustment component decay are designed to ensure stable and fast training. Results show the ability to handle competition among generators even when the number exceeds the modes. Further improvements are needed, such as enhancing the shrinkage method and finding a better heuristic for beta. Training to learn beta could help achieve a balance in the multi-player game. To improve the mixed generator method in GANs, better heuristics for beta and dynamic weights for each generator can be explored. Additionally, investigating new parallelization algorithms with lower communication costs could accelerate the multi-generator model."
}