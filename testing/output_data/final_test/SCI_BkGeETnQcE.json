{
    "title": "BkGeETnQcE",
    "content": "Our approach uses feature-directed active learning to gather information about plan trace preferences and train a feedforward neural network. The impact of active learning on the number of traces needed for accurate model training is evaluated by comparing it to a more complex LSTM model trained without active learning. Learning user preferences over plan traces is crucial when a human is involved in planning. The user's preference function needs to be learned well for plan selection. Verification of the model's decisions and fidelity to user preferences is crucial. Active learning is necessary due to the complexity of user preferences and the need for a large amount of information. In this work, the objective is to model user preferences over plan traces. CP-nets and Generalized additive independence models are used to represent preferences, while LTL rules can capture trajectory preferences well. Existing approaches are discussed in detail, highlighting differences with the current work. Our approach focuses on efficiently identifying relevant features and their impact on preference scores through feature-directed active learning. We use plan traces to train a Neural Network model called FeatureNN, which learns a utility function over pertinent features without explicitly defining utility functions. The FeatureNN model learns utility functions over relevant features using a neural network. It predicts preference scores for each plan based on user preferences and is compared to a SequenceNN model. The SequenceNN model processes sequential data with an LSTM BID6 module and is trained on a larger dataset of traces with ratings. The efficiency of the active learning approach is evaluated by comparing the number of traces required for both models to achieve the same accuracy and interpretability. Neural networks, especially simple ones with a single hidden layer, can be challenging to interpret. The text discusses how a single hidden layer in neural networks can be challenging to interpret. It explains a method to help users understand the decisions of the neural network by showing how removing different features affects the preference score. This approach is similar to using Saliency Maps in images to explain classification. By comparing the effect of changes to the user's preferences, the NN model becomes more interpretable. The method also involves explaining decisions using counterfactuals, where the counterfactual is the plan trace without a specific feature. The text discusses improving interpretability in neural networks by using user feedback for feature-based preferences. It defines the problem, methodology, and compares FeatureNN and SequenceNN models for predicting preference scores. The goal is to learn the preference function that captures user preferences and scores traces accordingly. The text discusses learning user preferences based on feature sets in a domain. Preferences are rated between 0 and 1, with features contributing positively or negatively. Plans are scored based on user feedback, and a set of plan traces is used to cover possible preferences. In the gridworld domain called Journey-World, the objective is to travel from home to the campsite. Each step corresponds to a cell on the grid, some of which have features like eateries, landmarks, or activities. The methodology involves active learning rounds with plan traces to train and test a neural network model. The Journey-World gridworld domain involves traveling from home to the campsite through cells with features like eateries, landmarks, or activities. Landscape cells cannot be traversed, but adjacent cells correspond to seeing the landscape. Non-landscape features are binary, while landscape features are cardinal and can impact preference score. There are a total of 13 features in the plan trace. In Journey-World, the preference score is influenced by the count of cardinal features. The user's preference model includes binary variables for coffee (C) and donut (D), with a dependency on CD. Future work will involve human trials to evaluate the methodology. In Journey-World, the preference score is computed based on the count of cardinal features like lake (L) and industry (I). The preference increases with their count up to 2, then stops. A separate module rates plan traces using a preference function, with a synthetic human aiding in testing and debugging. The current user interface for Journey-World displays the grid with icons representing features in cells. Users rate plans one at a time by indicating preferences and annotating liked or disliked features. The interface automatically moves to the next round of active learning after all plans have been rated. Multiple rounds of feedback are used to select informative queries based on previous knowledge. In the first round of active learning for Journey-World, diverse plan trajectories are shown to the user to cover the feature space. A large backlog of plans is generated to ensure diversity, with 10000 plans created for one initial and goal state in a gridworld domain. Computational costs are considered in plan generation. The diversity of plans in the Journey-World domain is determined by the sum of feature count differences between them. A geometric series sum is used to compute the feature count difference, ensuring no single feature dominates the diversity computation. The diversity of plans in the Journey-World domain is calculated by averaging the feature count differences between traces. The backlog-diversity for a plan is determined by the average pairwise diversity with other plans in the backlog. Top plans are selected based on diversity scores for user feedback. Subsequent rounds use user ratings and annotations to generate informative plan traces, focusing on feature effects and dependencies. Traces selected for the next round aim to be rated significantly higher or lower, a challenging task. In order to estimate preferred or least preferred plan traces, a fast weak predictor is used to predict ratings based on prior knowledge. The predictor quickly estimates feature values and scores unrated plans by summing their features. Each feature is scored using a simple method, averaging scores over all plans it appears in. This allows for predicting scores for unrated plans efficiently. The weak predictor quickly estimates feature values and scores unrated plans by summing their features. Plans with high or low ratings are desired, along with diversity and similarity in plan traces for cognitive load reduction. Plans in the backlog are assigned a combined weighted score, and the top plans are selected for the next round. Preference Learning using Neural Networks involves two models, SequenceNN and FeatureNN. The SequenceNN model utilizes an LSTM module to encode plan traces with 13 features per step. The model is not restricted to annotated features, allowing it to learn relevant features and the preference function effectively. The SequenceNN model was trained with plan traces varying in number from 30 to 12,000. It used an LSTM module with 16 memory cells to predict preference scores between 0 and 1. The model concatenated output vectors and memory nodes before passing them through fully connected layers. The LSTM module was expected to contain necessary information for score prediction. The FeatureNN model used a 5-dimensional vector as input, representing relevant features from the plan trace. It had one hidden layer of 4 dimensions and one output layer, as shown in FIG3. The model encoded binary features like coffee and lakes into the vector for prediction. The FeatureNN model utilized a 5-dimensional input vector with one hidden layer of 4 dimensions and an output layer. The number of dimensions for the hidden layer was adjusted based on performance. Training involved varying the number of traces per round from 5 to 50 for 3 rounds, with data duplication, shuffling, and training parameters set. Users can interpret the Neural Network's behavior by analyzing salient features and their impact on predicted scores across different traces. The Attribution Error (AE) is a measure of interpretability in the FeatureNN model. It calculates the difference in the effect of a feature on preference scores between the user's true model of preferences and the learned preference function. The overall AE for each test plan is the average of AE for all features present. The AE score for the test set is the average of the top 10% of AE errors, as neural networks can memorize cases and increase accuracy. This allows the model to predict preference scores accurately even with dropped features. The SequenceNN model's generalization is tested by measuring its accuracy in predicting preference scores. By analyzing the top 10% of AE errors, it is possible to evaluate how well the model performs when faced with rare or unseen patterns of features. The model's accuracy improves with more training input traces, achieving a low error rate even with 30 traces. This success is attributed to the presence of simple correlations with other features that enable accurate score predictions. The SequenceNN model's interpretability was tested by analyzing the attribution error for predicting preference scores. The LSTM model showed a decrease in attribution error with training set sizes, reaching a low of 0.09 after 7500 rated traces. However, this level of accuracy is not practical for human raters. Varying the size of the SequenceNN model slightly improved accuracy. The FeatureNN model, with 90 traces, is as accurate as the SequenceNN model with 7500 traces, showing 8% less Attribution Error. Interpretability did not improve with an increase in model dimensions. The FeatureNN model outperformed the SequenceNN model in accuracy and interpretability, with the AE error dropping to as little as 2.5% with 60 traces. The SequenceNN model with 7500 traces is accurate but less interpretable, showing 8% less Attribution Error compared to FeatureNN. Increasing the number of features in a NN model can lead to finding spurious correlations, affecting interpretability. Active learning and using a simpler NN are crucial for learning preferences in plan traces. In the FeatureNN model experiments, the authors discuss the importance of obtaining user knowledge on categorical and cardinal features to reduce assumptions and improve neural network performance. They mention the absence of a preference dependency considering the number of steps between features, which can be easily encoded as a variable. This knowledge helps the neural network avoid learning spurious correlations and enhances interpretability. The CP-nets and Generalized additive independence paradigms are used for learning preferences over outcomes, where decisions are represented as variables in a graph with dependencies. The CP in CP-nets stands for \"all else being equal\", referring to the influence of parent variables on a variable's preferences. CPnets are used for learning preferences over outcomes, with dependencies known apriori or queried from the user. Preferences at each node are queried, incorporating information about order for plan preferences. Querying for such knowledge is demanding and not natural for preferences over plan traces. It is more natural for users to specify conditional dependencies over features while annotating a plan trace. Giving a preference value for the plan trace is easier than ordering preferences over features. CP-nets do not compute utility values, making some outcomes incomparable. A total order over plans is desired to select the most preferred plan, requiring a utility/preference value for each plan trace. On the other hand, GAI BID2 models provide a single utility value for a set of features. The curr_chunk discusses the decomposition of a utility function into sub-utility functions for situations where attributes are not additively independent. It mentions the need for global queries or a combination of local and global queries to calibrate. The two methods for learning a GAI with active learning from a single user are also outlined. The approach involves full trace queries, annotations, and preference ratings. The curr_chunk discusses the use of full trace queries and annotations to learn user preferences over features. It contrasts this approach with using LTL rules for specifying preferences, highlighting the challenges of user specification. The interface extracts simple LTL rules from plan traces for user feedback. In our approach, we use feature-directed Active Learning with an intuitive user interface to efficiently learn the user's preference function. Traces obtained during active learning are encoded as vectors over relevant features, which are then used to train a Neural Network to learn preferences. The SimpleNN neural network is trained with feature vectors to learn the preference function efficiently. It outperforms the LSTM based SequenceNN model in accuracy and interpretability with fewer plan traces. The current experiments focus on a deterministic preference function, but future work will explore noisy or probabilistic models. The user interface can be expanded to include more complex annotations, allowing users to provide feedback on plan features. The framework supports annotations for adding/dropping features from a plan based on user preferences. It can handle categorical, cardinal, and real-valued features, adapting the active learning process accordingly. The function for choosing plan traces in successive rounds may be simplified by removing unnecessary similarities with traces from previous rounds. Simplifying the process of choosing plan traces in successive rounds by focusing on diversity and selecting traces that are closer to 1.0 or 0.0 in user preference."
}