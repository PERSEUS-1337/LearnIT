{
    "title": "S1xq3oR5tQ",
    "content": "The vertebrate visual system processes visual information hierarchically, with differences in neural representations between the retina and primary visual cortex. A deep convolutional neural network model shows that these differences emerge due to neural resource constraints, leading to distinct geometries in visual processing stages. The vertebrate visual system processes visual information hierarchically, with differences in neural representations between the retina and primary visual cortex. A study suggests that the retina acts as a bottleneck due to a reduced number of neurons at the retinal output. It also indicates that retinal outputs in simple cortical networks function as nonlinear feature detectors, while in complex networks, they act as linear encoders of the visual scene. This implies that small vertebrates perform sophisticated nonlinear computations, while large animals like primates encode the visual scene linearly. The early visual system's properties are traditionally explained by theories of efficient coding, which suggest that neural representations optimize preserving information about the visual scene. These theories can explain certain structures in the retina and primary visual cortex, but some properties remain unexplained. The diversity of ganglion cell types in the retina, each performing specific computations, remains unexplained. Some cells extract behaviorally-relevant cues nonlinearly, while others respond linearly to a broad range of stimuli. The diversity of ganglion cell types in the retina remains unexplained. Different species exhibit varying proportions of cells that perform linear encoding versus nonlinear feature detection. The most common ganglion cell type in primates is a quasi-linear pixel-encoder, while in mice, the most common cell type acts as a specific feature detector. The limitations of current efficient coding theories fail to explain this diversity of computations across cell types and species. The limitations of current efficient coding theories fail to explain the diversity of computations found across cell types and species. Recent work suggests moving beyond information preservation towards more realistic objectives, such as predictive coding for better understanding V1 cells' spatio-temporal receptive fields. Deep convolutional networks have shown accuracy in modeling the visual system but have not been used to study it through efficient coding theories. In this study, deep convolutional neural networks were trained on image recognition and varied in architecture to explore constraints that may have shaped early visual representations in vertebrates through natural selection. The visual system was modeled with two convolutional networks, one for the retina and one for the ventral visual system in the brain. The study explored the impact of varying neural network architectures on the visual system. A reduction in retinal neurons led to the emergence of center-surround receptive fields in the retina and oriented receptive fields in the brain. The allocation of neural resources to visual cortices influenced retinal processing, with deep cortices preserving more visual information but shallow cortices being better at object classification. These findings offer testable predictions for future research. The retinal architecture is strongly conserved across species, consisting of three layers of neurons and two layers of interneurons. The retina was modeled as a convolutional neural network with two layers, known as the retina-net. Various species' retinal responses to complex stimuli have been successfully modeled with one or two-layer models. The retina-net, a neural network simulating the retina, was used in conjunction with the VVS-net, modeling the ventral visual system, for an object classification task. The number of neurons in the retina-net and layers in the VVS-net were varied to study neural resource allocation. The study aimed for a more biologically realistic approach compared to previous efficient coding studies. The study used a convolutional neural network for image classification, with a retina-net and VVSnet simulating the visual system. The system had varying layers and channels, aiming for biological realism in efficient coding studies. The study utilized a convolutional neural network with a retina-net and VVS-net to model early visual representations. The system had varying layers and channels, using 9x9 convolutional filters with a stride of 1 in each layer. Training was done with the RMSProp optimizer for 20 epochs on the CIFAR-10 dataset using Keras and TensorFlow. The study used a convolutional neural network with a retina-net and VVS-net to model early visual representations. Varying layers and channels were tested, showing that a bottleneck at the output of the retina yielded center-surround retinal RFs. A shallow VVS-net resulted in more nonlinear retinal responses, better disentangling image classes. Test-set accuracy on CIFAR-10 improved with deeper VVS-nets and more retinal channels, indicating their significance as constraints on the network. After training 10 identical networks with different random initializations, the study determined the linear approximation of RFs in each convolutional channel by computing the gradient of the activation with respect to a blank image. This method allowed for a direct comparison of RF geometries between biological networks and the models. The test accuracy of the neural network model of the visual system increased with the number of channels in the retinal bottleneck and layers in the VVS-net. Investigating the effects of a dimensionality bottleneck at the retinal output revealed the emergence of RFs with antagonistic center and surround. Reducing the number of neurons at the retinal output led to the observation of center-surround receptive fields in the second layer of the network. In the second and third layers of the network, center-surround and oriented receptive fields were observed, respectively. The shape of retinal RFs varied for the shallowest VVS-net tested. These results align with the biological visual system, where retinal RFs are center-surround and downstream RFs in V1 are sharply oriented. The dimensionality bottleneck at the retinal output explains these differences in representations. The RFs in the VVS-net after the first layer showed complex shapes, not clearly oriented or circular. Orientation-selective neurons in the VVS-net draw primarily from center-surround neurons in the retina-net aligned with the edge direction, consistent with Hubel and Wiesel's hypothesis. The study found that the network architecture mimicking the visual system of mammals showed center-surround RFs in the first two layers and oriented RFs in the next layer, resembling the primary visual cortex. This suggests that center-surround representations are beneficial in low-dimensional settings, with dimensionality expansion being crucial. The study observed that the network architecture mimicking the mammalian visual system displayed center-surround RFs in the first two layers and oriented RFs in the subsequent layer, similar to the primary visual cortex. This indicates the importance of center-surround representations in low-dimensional settings, with dimensionality expansion being a key factor. The behavior of neurons in the VVS model was tested, revealing that most neurons in the first layer acted as simple cells, while those in the second layer behaved as complex cells. The VVS-net model showed that most neurons in the first layer acted as simple cells, while neurons in the second layer behaved as complex cells. This suggests that the visual cortex involves multiple nonlinearities and may correspond to multiple layers in the model. The addition of local normalization at every layer tested the robustness of the results. The addition of local normalization at every layer in the network slightly degraded performance but still resulted in the emergence of center-surround receptive fields in the retina-net. This phenomenon is attributed to reducing the number of neurons at the retinal output rather than reducing the number of channels, which are equivalent to biological retinal cell types. In the retina, there are various types of ganglion cells with different receptive field characteristics, density, polarity, and nonlinearities, similar to the convolutional channels in the model. The study explores the relationship between the emergence of center-surround receptive fields in the retina and the number of neurons at the output. Locally connected layers were used to limit the number of neurons without constraining the number of cell types. The model was trained stage-wise to reproduce edge-like activations. In a study exploring the emergence of center-surround receptive fields in the retina, it was found that even in untied networks, center-surround RFs were preferred for passing information through a bottleneck dimension. Two distinct clusters of cells corresponding to ON and OFF center-surround RFs emerged when analyzing responses to natural images. This observation aligns with the dichotomy of biological ganglion cell types. The study focused on the classification of retinal cells into ON and OFF populations with RFs of opposite polarity. By increasing the number of layers in the VVS-net, the retinal computation became more linear, aligning with differences in retinal representations across vertebrate species with different brain sizes. The retinal response becomes more linear with increased brain complexity, but a non-monotonic trend is observed without a bottleneck. Nonlinearity in the retina is attributed to inner retinal rectifications and ganglion cell rectification. Decreasing VVSnet depth leads to increased retinal response nonlinearity. The retinal response becomes more nonlinear due to both inner retinal nonlinear processing and ganglion cell rectifications, with increasing brain complexity and decreasing VVS-net depth. The retinal response becomes more nonlinear with increasing brain complexity and decreasing VVS-net depth, suggesting a trade-off between compressing visual information and extracting relevant features. The retinal representation retains more information about the raw image for deep VVS-nets, but classes are less separable at the retinal output for deeper VVS-nets. Performance on CIFAR-10 is compared for a two-layer densely connected network taking input from the retina-net or a raw image. The retinal representation retains more information about the raw image as VVS-net complexity increases. A linear decoder was used to measure information retention by reconstructing the image, showing that the retina retains information about the stimulus. The study found that as the VVS-net becomes more complex, the retinal representation retains visual information better. Different classes of objects in CIFAR-10 were more linearly separable from the retina-net representation when the VVS-net was shallow compared to when it was deep. Additionally, a VVS-net with two fully connected layers and a tight bottleneck retina performed better at image recognition than the same VVS-net without a retina-net. The study showed that a VVS-net with a tight bottleneck retina performed better at image recognition than the same VVS-net without a retina-net. Retinas followed by a simple cortex prioritize feature extraction, while retinas followed by complex visual cortices prioritize non-lossy encoding. Each retinal channel in a network trades off between linearly transmitting visual information and extracting relevant features for object classification. The study found a negative correlation between linearity and linear separability in all networks, suggesting a trade-off between feature extraction and visual information transmission. The retinal representation in deep VVS-nets was quasi-linear with a tight bottleneck, indicating efficient feature copying. However, the retinal representation could be transformed into a highly linearly separable one, suggesting its adaptability for object classification. The retinal pre-processing in deep VVS-nets can enhance linear separability, potentially due to a combination of linear and nonlinear processing. By replacing the true retinal processing with a linear approximation, the first layer of the network showed increased separability in classifying objects. The linear operation of the retina plays a crucial role in enhancing separability for subsequent layers in the network. A linear model was fitted to predict neural responses from images, with regularization to prevent overfitting. The Pearson correlation between linearized responses and original model responses was measured on a testing set. Additionally, a linear model was used to reconstruct images from the outputs of the trained retina-net. The linear separability of classes of objects from the neural representation was estimated using an SVM classifier on the testing set of CIFAR-10. The performance of the SVM classifier was tested on held-out images, and the average performance across all pairs of classes was used to obtain the linear separability score. The structural differences between the receptive field shapes of retinal neurons and V1 neurons have been a challenge for efficient coding theories. BID21 discovered that encoding images with added noise and a cost on firing rate produce center-surround RFs. The observation that encoding images with noise and a cost on firing rate produces center-surround RFs, while without noise it produces edge detectors, does not fully explain the differences between retinal and cortical representations. BID36 propose different constraints for the retina and V1, with the retina optimizing for a metabolic constraint on synapse number and V1 optimizing for a constraint on firing rate. These representations can emerge from a task of extracting object identity with a bottleneck constraint on retinal output dimensionality. This differs from previous explanations for center-surround RFs. In our framework, the receptive fields of the retina-net remained oriented across different levels of noise and regularization, showing varied retinal representations based on neural resource allocation. This contrasts with the debate on the role of the retina in feature extraction versus encoding all visual information. The retina prioritizes different computations based on species, with varying proportions of linear and nonlinear cell types. In species with fewer brain resources for visual processing, the retina extracts relevant features nonlinearly, while in species with a complex visual stream, it prioritizes linear transmission of visual information. The mouse has a two-stage nonlinear feature detector, while primates have ganglion cells approximated by linear filters. The most common ganglion cell type in the primate retina is approximated by a linear filter, while two-stage nonlinear models are present in larger species. To understand inter-species differences in retinal coding, a dataset of recordings of ganglion cells from different species in response to natural scenes is needed. The role of visual information parcellation in ganglion cell types at the retinal output is also a relevant question. In this study, the focus is on encoding natural movies with a cost on the total firing rate through the optic nerve. Different cell types in the frog are sensitive to behaviorally relevant features like prey or predators. The study limited the number of cell types at the retinal output to explore efficient coding of natural scenes and extraction of behaviorally-relevant features. The dimensionality expansion between the retinal representation and the ventral visual stream was crucial for the emergence of the retinal center-surround representation. The study focused on encoding natural movies with a constraint on the total firing rate through the optic nerve. By using larger networks, the emergence of diverse neuron types in the retina-net was studied. Extending the model to natural movies and adding a temporal dimension would be necessary to study feature detectors processing image motion. The differences in retinal and cortical representations of visual information could be due to the anatomical constraint of transmitting visual information through a low-dimensional communication channel. The study explored how retinal representations across species may have co-evolved with processing in the visual stream. Deep neural networks can now provide insights into the evolution of the visual system. Analysis showed that a dimensionality bottleneck in the retina-net leads to specific receptive fields in the VVS-net. Orientedness of receptive fields was quantified using bar stimuli of varying properties. The study quantified the orientedness of receptive fields in the visual system using bar stimuli of varying properties. The strength of preference for different orientations was measured by selecting the strongest response for each orientation. The ratio of response strengths for preferred and orthogonal orientations was computed to determine the degree of orientation selectivity. The study analyzed the orientedness of receptive fields in the visual system using bar stimuli. The average ratios for retinal output, first VVS-net layer, and second VVS-net layer were 1.56, 3.05, and 2.57 respectively. Retinal receptive fields were found to be more isotropic than random Gaussian noise. The standard deviation of RF preference across orientations was lower for retinal RFs compared to random RFs. The study analyzed the orientedness of receptive fields in the visual system using bar stimuli. Retinal receptive fields were found to be more isotropic than random Gaussian noise. RFs in the second layer of a vanilla network were highly oriented, while RFs in the second layer of a bottleneck network were more isotropic, resembling center-surround RFs. Oriented receptive fields were observed in the layer following the retina-net in the bottleneck network. The weight matrix in the V1 convolutional layer shows orientedness across filters and trials, confirming the observation. Neurons in the model's early layers were analyzed to determine if they resembled simple or complex cells through local linear approximations of receptive fields. Multiple trials with different inputs were run to assess linearity. The study analyzed the behavior of different layers in a retina-net + VVS-net model. The first VVS-net layer exhibited \"simple\" behavior, while the second layer showed \"complex\" behavior. The average standard deviations of computed receptive fields for each layer were measured to quantify this effect. The study analyzed the behavior of different layers in a retina-net + VVS-net model. The standard deviations for the retina-net output, first VVS-net layer, and second VVS-net layer were 7.9(\u00b11.1) \u00d7 10 \u22123, 15.4(\u00b10.8) \u00d7 10 \u22123, and 35.9(\u00b10.8) \u00d7 10 \u22123, respectively. The second VVS-net layer exhibited significantly more complex behavior, similar to the biological phenomenon of complex cells pooling from simple cells in V1. The robustness of the model was tested with biologically realistic local response normalization at every layer. The separability of the network layers in a deep VVS-net model was analyzed. The first layer showed high separability, while the retinal representation in the bottleneck network had low separability. Linear separability between layers 2 and 3 suggested that retinal processing in the network primarily involves whitening rather than nonlinear processing. The retinal processing in the network primarily involves whitening rather than nonlinear processing. The first layer disentangled classes almost as well as the second layer without the retina, indicating high linear separability. An ablation experiment was conducted to determine the impact of linear versus slightly nonlinear retinal processing on increased separability. After linearizing the retinal representation, the VVS-net's first layer showed improved class separation compared to the control network. The retinal image intensity was proportional to neuron activation, with light shades indicating high activity. The retinas whitened the input for every VVS-net depth. The retinal image becomes less recognizable as VVS-net depth decreases, indicating increased processing."
}