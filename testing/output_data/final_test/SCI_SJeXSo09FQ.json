{
    "title": "SJeXSo09FQ",
    "content": "Point clouds are geometric data used in computer graphics and vision. Learning representations for point clouds is challenging due to their unordered nature in 3D space. Graph convolution has been successful in extracting features from point clouds for tasks like classification and segmentation. This paper focuses on unsupervised generative models using graph convolution in GANs to generate localized features approximating graph embeddings of output geometry. Upsampling layers are also studied in this context. This paper explores using graph convolution in GANs to generate localized features approximating graph embeddings of output geometry. It also investigates defining an upsampling layer in the graph-convolutional generator to exploit self-similarity in data distribution for more effective sampling. Graph convolution is crucial in various domains such as 3D models, computational biology, and social network graphs. It involves defining convolutional architectures on these domains to leverage useful priors on the data for more powerful representations. The two main approaches to define graph convolution are spectral and spatial, with the former utilizing the graph Fourier transform for an efficient implementation. The spectral approach in graph convolution has been used for semi-supervised classification and link prediction. However, a drawback is the fixed structure assumption of the graph. Spatial approaches define the convolution operator using local aggregations, making it adaptable to varying graph structures. Point clouds pose challenges due to irregular point positioning and unordered sets, but supervised problems on point clouds have been addressed in some works. Recent approaches in supervised learning on point clouds have focused on building graphs in the Euclidean space and using graph convolution operations. These methods aim to reduce model complexity by enforcing weight sharing and extracting localized features that capture dependencies among neighboring points. While generative models are powerful tools in unsupervised learning, little work has been done on generative models for point clouds. Generative models for point clouds are underexplored, but they have various applications such as data augmentation and shape completion. Generative Adversarial Networks (GANs) have shown promise in approximating data distributions better than variational autoencoders (VAEs) on images. Previous work used GAN architectures with PointNet to generate point clouds, but they struggled with learning localized features and weight sharing. This paper explores a new generative model for point clouds. This paper introduces a generative model for point clouds based on graph convolution, focusing on the GAN generator. The proposed architecture learns domain and features simultaneously, promoting features to be graph embeddings. It addresses the challenge of upsampling at the generator, providing a flexible and descriptive model for point cloud generation. The paper proposes a method for upsampling in a graph-convolutional GAN generator by utilizing non-local self-similarities in the data distribution. It discusses the use of Wasserstein GAN with a gradient penalty method to enforce Lipschitz constraint. The proposed generative model utilizes Edge-Conditioned Convolution for dealing with multiple arbitrary graphs and uses localized operations in the form of graph convolutions. The GAN generator faces challenges in dealing with unordered sets like point clouds, as the intermediate layers do not know the point cloud in advance. The proposed generative model uses Edge-Conditioned Convolution to handle multiple arbitrary graphs and employs localized operations with graph convolutions. To address challenges with unordered sets like point clouds, the GAN generator constructs a k-nearest neighbor graph based on pairwise distances between node features, promoting features to become graph embeddings that represent relationships in a high-dimensional space. As the generator network progresses towards the output point cloud, these embeddings are hierarchically assembled to approximate the graph of the output. The proposed generative model utilizes Edge-Conditioned Convolution and localized operations with graph convolutions to approximate the graph of the output point cloud. This approach differs from previous models like PointNet and PointNet++ by providing a localized interpretation of hidden layers and being a generative model rather than used in supervised problems. The proposed generative model utilizes Edge-Conditioned Convolution and localized operations with graph convolutions to approximate the graph of the output point cloud. It differs from PointNet and PointNet++ as it is a generative model, not used in supervised problems. Other works explore likelihood-based generative models, such as variational autoencoders. The method in BID11 learns a distribution over adjacency matrices of graphs using a spectral graph-convolutional VAE. One limitation of the graph-based generator in a GAN is the fixed number of points, which can be addressed by predicting points from neighboring points with regularity or multi-resolution compositionality. The upsampling operation in convolutional GANs for image generation involves creating higher resolutions from lower resolutions by supplying low-frequency content. Extending this to generate sets of points without a total ordering is challenging, especially in the context of graph-convolutional layers due to high feature vector dimensionality. The goal is to define an upsampling operation for each generator layer that concatenates new feature vectors to the output. The upsampling operation in convolutional GANs involves creating higher resolutions by concatenating new feature vectors to the output. Graph embeddings represent graphs in a vector space, focusing on predicting edges from feature vectors. The graph-convolutional generator in this paper generates graph embeddings of the nearest-neighbor graph of the output point cloud at each hidden layer, capturing local topology properties. The final output is a result of aggregating features from the preceding layer's nearest-neighbor graph. The GAN objective aims to match the output distribution with real data, requiring the identified neighborhoods to approximate those in the real data. The features H L act as a graph embedding to predict edges in the output graph. The upsampling operation in the architecture affects the chain of embeddings by introducing new points. The method approximately maintains neighborhood shape but copies it elsewhere in the point cloud, suggesting a generation mechanism exploiting self-similarities between features at different locations. The proposed architecture for generating point clouds involves training class-specific models for different classes like \"chair\", \"airplane\", and \"sofa\". The discriminator architecture is similar to r-GAN with 4 layers and weights shared across points. The generator uses Leaky ReLUs, RMSProp optimization, and batch normalization. The graph is built by selecting 20 nearest neighbors in the feature space. Batch normalization is applied after every graph convolution in the proposed point cloud generation architecture. The WGAN uses a gradient penalty parameter of 1 and the discriminator is optimized for 5 iterations per generator step during training for 1000 epochs. Training for the \"chair\" class took approximately 5 days without upsampling and 4 days with upsampling. Qualitative and quantitative comparisons were made with the generated point clouds, showing visually convincing results with high object variety and uniform point distribution. This work is the first to address GANs for learning localized features in point clouds. The proposed GAN for point cloud generation utilizes graph convolution to aggregate features of neighboring points, enabling localized representations. A baseline variant, \"r-GANconv\", uses a generator with as many feature vectors as points in the cloud. Comparisons with other GANs like variational autoencoders are limited due to different conditioning methods. The proposed GAN for point cloud generation uses graph convolution to aggregate features of neighboring points. Evaluation metrics like Jensen-Shannon divergence, coverage, and minimum matching distance are used to compare generated samples with a test set. Results show that the method with upsampling operations performs better, with the Chamfer distance being unreliable for non-uniform point distributions. The proposed GAN for point cloud generation utilizes graph convolution to improve point distribution. Results indicate that the method with upsampling operations outperforms others, with the Chamfer distance being unreliable for non-uniform distributions. The features learned by the generator are graph embeddings, as confirmed by the successful prediction of adjacency matrices in the output point cloud. The experiment conducted focused on the localization of features in intermediate layers of the graph convolution network. It was found that features become more localized in layers closer to the output point cloud. Additionally, the effective receptive field of the convolution operation was investigated, showing that points closer to the output are aggregated in the graph embeddings. The experiment focused on the localization of features in intermediate layers of the graph convolution network. Layers closer to the output aggregate points closely in the final point cloud, while layers near the latent space perform more global operations. The model introduces upsampling layers to reduce the number of parameters in the first dense layer by starting with fewer points and progressively predicting new points. The proposed upsampling technique uses local aggregations to compute new points as weighted aggregations of neighboring points, with the network learning the aggregation weights. The experiment in Figs. 7b and 8 shows that generated points are far from the original point, with clusters in FIG9 indicating non-uniform distribution. The network learns to apply transformations to neighborhoods and copy them to different areas, resulting in points no longer close to their generators. The generated points are no longer close to their generators, but the neighborhood structure resembles that of the generating neighborhood. This operation exploits self-similarities between data features at distant points, as shown by measuring the neighborhood composition and Euclidean distances in the feature space. The GAN utilizes graph convolutional layers to generate 3D point clouds by constructing nearest neighbor graphs from generator features. An upsampling scheme is proposed to exploit self-similarities in the samples. The main challenge is the high complexity of the graph convolution operation, with future work focusing on reducing overall complexity and exploring new upsampling schemes."
}