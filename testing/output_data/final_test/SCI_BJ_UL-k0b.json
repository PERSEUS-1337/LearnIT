{
    "title": "BJ_UL-k0b",
    "content": "Meta-learning, based on Bayesian hierarchical modeling, allows an agent to improve quickly on new tasks by leveraging prior learning episodes. The model-agnostic meta-learning algorithm (MAML) is reformulated as a method for probabilistic inference in a hierarchical Bayesian model, making it applicable to complex function approximators. This approach provides a way to understand MAML's operation as a meta-learning procedure and offers opportunities for efficient inference strategies. The proposed improvement to the MAML algorithm utilizes techniques from approximate inference and curvature estimation to enhance learning efficiency in novel tasks with limited data or computational resources. Meta-learning involves extracting domain-general information to improve learning efficiency in new tasks, and this inductive bias can be implemented through various methods. The inductive bias implemented in various ways includes learned hyperparameters, metric space for grouping neighbors, trained recurrent neural network for encoding episodic information, and optimization algorithm with learned parameters. The model-agnostic meta-learning (MAML) optimizes the standard gradient descent rule by estimating an initial parameter set shared among task-specific models for fast adaptation. This algorithm's novel derivation and extension show its potential for improving learning efficiency in novel tasks with limited data or computational resources. The novel derivation and extension of MAML reveal its hierarchical Bayesian framework, allowing for quick adaptation to new tasks. By incorporating insights from Bayesian posterior estimation, MAML's performance is enhanced, particularly in few-shot learning scenarios. The meta-learner aims to acquire task-general knowledge from solving related tasks, enabling quick adaptation to new tasks with limited data or computation time. It operates on a dataset defining a distribution over tasks, where each task involves data points x and either regression targets or classification labels y. The objective is to minimize task-specific performance metrics for unseen tasks, even with minimal data. The meta-learning problem aims to quickly adapt to new tasks with limited data by finding shared parameters that facilitate task-specific parameter optimization. Various gradient-based meta-learners have been proposed, with MAML being unique in its use of a meta-learning rate as an additional parameter. MAML addresses the meta-learning problem by estimating model parameters to achieve good generalization performance on new tasks with limited data. It uses a meta-learning rate as an additional parameter and operates on the same parameter space for both meta-learning and fast adaptation. The MAML algorithm involves a gradient descent procedure starting from \u03b8, with task-specific parameters \u03c6 j influencing the estimation of parameters from other tasks. This is achieved by introducing a meta-level parameter \u03b8 on which each task-specific parameter depends statistically. The computational graph of MAML is depicted in Figure 1, showing the inner gradient descent procedure for fast adaptation. The MAML algorithm involves a gradient descent procedure starting from \u03b8, with task-specific parameters \u03c6 j influencing the estimation of parameters from other tasks. Straight arrows represent deterministic computations, while crooked arrows denote sampling operations in the probabilistic graphical model. Estimating \u03b8 constrains the estimation of each \u03c6 j by integrating out task-specific parameters to form the marginal likelihood of the data. Maximizing a specific formula as a function of \u03b8 provides a point estimate for \u03b8, known as empirical Bayes. The MAML algorithm involves gradient descent from \u03b8, with \u03c6 j influencing parameter estimation. MAML can be seen as empirical Bayes in a hierarchical model, connecting two independent approaches. The choice of inner-loop optimizer corresponds to a prior over task-specific parameters. The MAML algorithm involves gradient descent from \u03b8, with \u03c6 j influencing parameter estimation. It can be seen as empirical Bayes in a hierarchical model, connecting two independent approaches. The choice of inner-loop optimizer corresponds to a prior over task-specific parameters, p( \u03c6 j | \u03b8 ). In empirical Bayes, the marginalization over task-specific parameters \u03c6 j is not tractable, so an approximation using a point estimate \u03c6 j is considered. This leads to the maximization of the marginal likelihood p( X | \u03b8 ) with respect to meta-level parameters \u03b8. The curr_chunk discusses the trade-off in model-agnostic meta-learning through hierarchical Bayesian inference, focusing on the computation of a point estimate \u03c6 using truncated gradient descent. It highlights the relationship between fast adaptation objective and parameter initialization, illustrating the equivalence of early stopping in gradient descent to MAP estimation in a linear model. The curr_chunk discusses the optimization process using gradient descent for solving a regularized linear least squares problem. It involves updating the parameter \u03c6 iteratively based on the input examples X and regression targets y. The minimization problem is framed as a posterior maximization with conditional Gaussian likelihood and Gaussian prior over \u03c6. The dependence on step size \u03b1, iteration index k, and covariance structure of X is described. MAML in linear regression with squared error computes the MAP estimate of \u03c6 using k iterations of gradient descent. It is equivalent to empirical Bayes, while in the nonlinear case, it maximizes the marginal likelihood using a point estimate from gradient descent. This estimate may not be the global mode but represents the mode of an implicit posterior resulting from an empirical loss and regularization penalties. MAML approximates an expectation of the marginal negative log likelihood for each task, with early stopping acting as priors. The algorithm for MAML as probabilistic inference is given in Algorithm 2. Formulating MAML as probabilistic inference in a hierarchical Bayesian model motivates using various meta-optimization algorithms to induce a prior over task-specific parameters. Early stopping during fast adaptation is equivalent to choosing a prior over task-specific parameters. In the case of a quadratic objective, understanding the role of early stopping helps define the task-specific parameter prior. Using a curvature matrix B in gradient descent updates, meta-learning B incorporates task-general information into the covariance of fast adaptation prior p(\u03c6|\u03b8). The meta-learned matrix B can encode parameter correlations for updating relative to each other, solving for \u03c6(k) with a Gaussian prior p(\u03c6|\u03b8) with mean \u03b8 and diagonal covariance BID44. The MAML algorithm involves diagonalizing matrices H and B, with H representing the unscaled covariance matrix of features. It is used for probabilistic inference in hierarchical models and can be improved through Bayesian parameter estimation. The algorithm employs a point estimate for task-specific parameters in a hierarchical Bayesian model, but this may lead to inaccuracies in the integral approximation. The Laplace approximation can be used to incorporate uncertainty about task-specific parameters into the MAML algorithm at fast adaptation time by replacing a point estimate with a Gaussian volume centered at a mode of the integrand. This approximation involves a second-order Taylor expansion of the negative log posterior to approximate each integral in the product. The Laplace approximation in MAML involves using the Hessian matrix of second derivatives of the negative log posterior to approximate the marginal likelihood. The regularization terms in the objective function penalize model complexity and are difficult to compute for neural network training. The Laplace approximation in MAML uses the Hessian matrix to approximate the marginal likelihood. The prior over task-specific parameters is approximated as a diagonal Gaussian with fixed precision \u03c4 for simplicity in experiments. The Laplace approximation in MAML uses the Hessian matrix to approximate the marginal likelihood. To address intractability and non-definiteness issues, a curvature matrix is sought to approximate the quadratic curvature of a neural network objective function. Second-order gradient descent methods are employed, using the Fisher information matrix as an approximation of curvature in natural gradient descent. The Fisher information matrix defines a convex quadratic approximation to the objective function of a probabilistic neural model. It is positive definite and non-diagonal but expensive to work with. K-FAC is a scheme for approximating the curvature of a neural network's objective function by using a block-diagonal approximation to the Fisher information matrix. Each block corresponds to a unique layer in the network and is further approximated as a Kronecker product of smaller matrices. The Laplace approximation and K-FAC are used to efficiently compute the determinant of a curvature matrix for natural gradient computation, leveraging properties of the Kronecker product and block diagonal matrices. This approach replaces Subroutine 3 for task-specific marginal computation. The Lightweight Laplace Approximation for Meta-Adaptation (LLAMA) uses Laplace approximation and K-FAC to compute task-specific marginal NLLs. It aims to generate samples from the distribution over adapted parameters and can be applied to large-scale meta-learning problems like miniImageNet. The method interprets as hierarchical Bayes, allowing direct sampling of models from the posterior. Random samples from the posterior predictive describe a distribution of functions when presented with new data points. The connection between MAML and hierarchical Bayes suggests that MAML behaves like an algorithm learning the mean of a Gaussian prior on model parameters. The Laplace approximation assumes a task-specific parameter posterior with mean at the adapted parameters and covariance equal to the inverse Hessian of the log posterior. Sampling parameters from this density can be used for regularization in meta-learning. The relationship between MAML and hierarchical Bayes is illustrated using a meta-dataset of sinusoid tasks. The method allows for direct sampling of models from task-specific parameter distributions. LLAMA is evaluated on the miniImageNet 1-shot, 5-way classification task. LLAMA is evaluated on the miniImageNet dataset, which consists of 64 training classes, 12 validation classes, and 24 test classes. The model follows a N-shot, J-way classification task setup, using a neural network architecture standard for few-shot classification. The model utilizes Adam as the meta-optimizer and standard batch gradient descent for updating during fast adaptation. LLAMA, a meta-learning method, achieves comparable performance to the state-of-the-art method by BID53 on the miniImageNet dataset. The Laplace approximation used in LLAMA shows promise for further improvements in meta-learning and few-shot learning. The model trains for 60,000 iterations on a TITAN Xp GPU in 9 hours, compared to 5 hours for MAML. Meta-learning and few-shot learning have a history in hierarchical Bayesian modeling. Transfer learning also utilizes hierarchical Bayes extensively. Various inference methods like exact inference, sampling methods, and variational methods have been used in Bayesian models. Prior works on hierarchical Bayesian models have tackled basic image recognition tasks, but not complex problems like those solved by deep networks. The Omniglot benchmark has renewed interest in learning from few examples, with modern methods achieving few-shot learning through network architecture design. Our work bridges the gap between gradient-based meta-learning methods and hierarchical Bayesian modeling by formulating a gradient-based meta-learner as hierarchical Bayesian inference. This allows for efficient posterior inference in a model-agnostic manner, showing that model-agnostic meta-learning estimates the parameters of a prior in a hierarchical Bayesian model. By incorporating a Bayesian framework into gradient-based meta-learning, our analysis introduces novel improvements inspired by probabilistic machinery. We propose an extension to MAML using a Laplace approximation for task-specific parameter posterior distribution, enhancing accuracy compared to point estimates. This method utilizes Kronecker-factored approximate curvature (K-FAC) to estimate the required quantity for the Laplace approximation, paving the way for further exploration of connections between meta-learning and hierarchical Bayesian modeling. Incorporating Bayesian modeling into gradient-based meta-learning introduces novel improvements inspired by probabilistic machinery. The Laplace approximation is used to model the predictive density over examples from a novel task, addressing inaccuracies in cases where the integral is skewed. Using a finite mixture of Gaussians can provide better approximations for density functions. Further exploration of such improvements is a promising avenue for future work."
}