{
    "title": "rkRwGg-0Z",
    "content": "The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Contextual decomposition (CD) is introduced as an interpretation algorithm for analysing individual predictions made by standard LSTMs. CD captures the contributions of combinations of words or variables to the final prediction of an LSTM. It is able to reliably identify words and phrases of contrasting sentiment and extract positive and negative negations from an LSTM. In this work, contextual decomposition (CD) is introduced as a novel interpretation method for explaining individual predictions made by LSTMs without modifying the model. CD extracts information about words that contribute to an LSTM's predictions, including positive and negative sentiments and negations. Contextual decomposition (CD) is a novel interpretation method for explaining LSTM predictions without altering the model. It disambiguates contributions from different parts of the sentence and can identify words and phrases of varying sentiment in sentiment analysis tasks. Additionally, CD can successfully extract positive and negative negations from LSTMs, a task not previously achieved. This analysis also reveals that prior interpretation methods may inaccurately label strongly negative phrases in positive reviews as neutral. The prior work on interpreting LSTMs has focused on computing word-level importance scores using various approaches. BID8 introduced a method to distill LSTMs into rules-based classifiers by decomposing the LSTM's output embedding. BID5 used a black box approach called Leave One Out, while Sundararajan et al. presented Integrated Gradients, a gradient-based technique for word-based importance scores. This work has been limited to word-based importance scores, ignoring other aspects. The previous work on interpreting LSTMs focused on word-level importance scores, while another line of work analyzed raw gate activations. Our approach computes an exact decomposition leveraging the unique gating structure of LSTMs. The curr_chunk discusses the limitations of attention-based models in providing interpretability and the novel approach of decomposing the output of an LSTM into contributions from specific phrases. The curr_chunk explains the decomposition of LSTM output into contributions from specific phrases, highlighting the gating dynamics unique to LSTMs for modeling interactions between variables. LSTMs have become essential in neural NLP systems, with the final state used as input for SoftMax regression to return a probability. The curr_chunk introduces contextual decomposition as a method for interpreting LSTMs, breaking down outputs into contributions from specific phrases. It discusses how these contributions are used in logistic regression for prediction. The curr_chunk discusses how contributions from specific phrases are used in logistic regression coefficient calculations within LSTMs. It highlights the interaction between neuron values and prior context in determining contributions, leading to a decomposition method based on linearizing gates and updates. This linearization allows for interpreting cross-terms as interactions between variables. The curr_chunk discusses decomposing contributions from specific phrases in logistic regression coefficient calculations within LSTMs. It explains linearizing gates and updates to interpret cross-terms as interactions between variables. The curr_chunk discusses decomposing contributions from specific phrases in logistic regression coefficient calculations within LSTMs. It explains linearizing gates and updates to interpret cross-terms as interactions between variables. Terms are determined to derive solely from the specified phrase if they involve products from some combination of \u03b2 t\u22121 , \u03b2 c t\u22121 , x t and b i or b g (but not both). When t is not within the phrase, products involving x t are treated as not deriving from the phrase. Decomposing the cell update equation components allows for the computation of the resulting transformation of h t by linearizing the tanh function. The output gate can also be decomposed similarly to the forget gate, but it was found empirically to not produce improved results. Linearizing functions L \u03c3 , L tanh are described for the decomposition. The curr_chunk discusses linearizing sums for permutations of terms in logistic regression coefficients within LSTMs, where the ordering is not clear. By computing an average over all orderings, a score is derived using permutations. Linearization simplifies when N ranges from 2 to 4, with improvements seen when bias is the first term in the decomposition. Linearization simplifies between 2 and 4, with contributions assigned to y1. It generalizes to vector settings and approximates Shapely values. Empirical validation on sentiment analysis shows CD compares favorably to prior work, captures compositionality, and extracts instances of positive and negative negation. Code for computing CD scores is available online. The process for fitting models to produce interpretations is described, focusing on standard best practices without much tuning. Models were implemented in Torch with default hyperparameters and optimized using Adam with a learning rate of 0.001. A bag of vectors model was used for the linear model, fine-tuning word vectors and linear parameters. An LSTM model was trained on the binary version of the Stanford Sentiment Treebank for validation. The NLP benchmark includes movie reviews with review-level and phrase-level labels. LSTM model achieves 87.2% accuracy, logistic regression model attains 83.2% accuracy. Yelp review dataset has binary prediction task for positive or negative reviews. Reviews are 160.1 words long on average. Following Zhang et al. (2015) guidelines, an LSTM model achieved 4.6% error, while an ngram logistic regression model achieved 5.7% error. Interpretation results were reported on a random subset of sentences of length 40 words or less due to computational reasons. Integrated gradient scores had numerical issues for roughly 6% of samples, leading to their exclusion. Comparisons were made between interpretations produced by CD and four state-of-the-art baselines: cell decomposition BID8, integrated gradients, leave one out BID5, and gradient times input. The gradient baseline involved computing the gradient of the output probability with respect to word embeddings and reporting the dot product between the word vector and its gradient. Integrated gradients required extended processing for reasonable values. The authors experimented with different baselines and scaling techniques to obtain reasonable values for integrated gradients. They used sequences of periods as baselines and rescaled scores by the standard deviation. Phrase scores were calculated by summing word scores. Logistic regression coefficients were used as a gold standard for interpretability in sentiment analysis. The novel phrase-level dynamics of cell decomposition were compared favorably to prior work for producing unigram coefficients. When evaluating word-level coefficients extracted by the CD method for sentiment analysis, a meaningful relationship between CD scores and logistic regression coefficients is expected. Scatter plots are constructed with each point representing a word in the validation set, comparing logistic regression coefficients and LSTM importance scores. The Pearson correlation coefficient is used for accuracy measurement, with correlations of 0.76 and 0.72 for SST and CD, outperforming other methods with correlations up to 0.51. On Yelp, correlations are slightly lower but still significant. In a comparison with other methods, CD shows competitive correlations of 0.52 on Yelp. CD can identify subphrases with differing sentiments, unlike existing methods. For example, \"my favorite\" is recognized as strongly positive by CD, while existing methods rank it as negative or neutral. This ability is demonstrated with phrases like \"used to be my favorite\" and \"not worth the time\". The interpretation algorithm should properly uncover how interactions are handled, as demonstrated by the example of strongly positive/negative phrases with dissenting subphrases. The distribution of scores for positive and negative dissenting subphrases should be significantly separate for an effective interpretation algorithm. The distribution of scores for positive and negative dissenting subphrases should be significantly separate for an effective interpretation algorithm. Prior methods struggle to identify cases where a sizable portion of a review has polarity different from the LSTM's prediction. CD is the only method able to accurately capture this dynamic. In the search for reviews with opposing sentiment phrases, prior methods struggle to differentiate between positive and negative phrases. Integrated gradients mislabel 87% of positive phrases as negative, while cell decompositions have flipped distributions. CD shows a clear distinction in distributions, indicating its effectiveness in capturing polarity dynamics. CD produces a strong difference between positive and negative distributions, with a score of 0.74, outperforming other methods like cell decomposition, integrated gradients, leave one out, and gradient. This highlights the superiority of CD in capturing polarity dynamics. The text discusses the challenges in understanding Robin Tunney's choices and the importance of using CD to analyze LSTM prediction mechanisms, particularly in phrases involving negation. The superiority of CD in capturing polarity dynamics is highlighted. The text discusses using CD to analyze LSTM prediction mechanisms for phrases involving negation, identifying positive and negative negation instances. The CD score is computed to extract a negation interaction. The distribution of extracted scores in FIG1 shows a clear distinction between positive and negative negations using CD analysis. Leave one out method captures some interactions but has overlap, indicating false negatives. CDs provide importance scores and dense embeddings for phrases and interactions. Contextual decomposition (CD) is an algorithm for interpreting individual predictions by providing importance scores and dense embeddings for arbitrary phrases and interactions. The embeddings in the form of \u03b2 T correspond to semantic similarity in sentiment analysis. Nearest neighbors for selected unigrams and interactions are computed using cosine similarity metric, showing sensible results for positive and negative interactions, as well as positive and negative words. The algorithm can disentangle composition of positive and negative words within negations. Contextual decomposition (CD) is an algorithm for interpreting individual predictions made by LSTMs without modifying the model. CD produces importance scores for words, phrases, and word interactions. It can identify phrases of varying sentiment and extract meaningful word interactions, moving beyond word-level importance. The curr_chunk discusses using a least squares regression line to interpret LSTM results and searching for negations in the text using a list of negation words."
}