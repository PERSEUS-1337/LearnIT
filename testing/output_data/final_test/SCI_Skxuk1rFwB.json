{
    "title": "Skxuk1rFwB",
    "content": "Training neural networks with verifiable robustness guarantees is challenging. Existing approaches use linear relaxation based neural network output bounds under perturbation, which can slow down training significantly. Interval bound propagation (IBP) based training is efficient but may suffer from stability issues. A new method, CROWN-IBP, combines fast IBP bounds in a forward pass and tight linear relaxation based bounds in a backward pass. It is computationally efficient and consistently outperforms IBP baselines on training verifiably robust neural networks. Our experiments on MNIST and CIFAR datasets show superior performance in L_inf robustness compared to previous linear relaxation and bound propagation based defenses. The success of deep neural networks (DNNs) in safety-critical environments like autonomous driving and facial recognition systems highlights the urgent need to understand their robustness under adversarial examples. DNNs are often vulnerable to imperceptibly modified inputs, known as adversarial examples, which can completely break the model. Research has focused on crafting powerful adversarial examples and developing defenses to enhance model robustness. Defending against adversarial examples is challenging, with early defenses like distillation being broken by stronger attacks. Many defense methods have been proposed, but their robustness improvement lacks provable guarantees. Uncertified defenses often become vulnerable under stronger attacks, prompting recent works to seek provable guarantees on robustness. Several recent works in the literature aim to provide provable guarantees on robustness performance using methods such as linear relaxations, interval bound propagation, ReLU stability regularization, distributionally robust optimization, and semidefinite relaxations. Linear relaxations of neural networks, particularly popular, use dual linear programming to create a \"convex adversarial polytope\" for tractable robust optimization. However, these methods are computationally and memory intensive. Interval bound propagation (IBP) is an efficient method for training verifiable neural networks, achieving state-of-the-art verified error on many datasets. However, the initial loose bounds in IBP can lead to instability and sensitivity to hyperparameters. A new method, CROWN-IBP, combines the efficiency of IBP with the tightness of linear relaxation based verification bound, CROWN. CROWN-IBP combines IBP and convex relaxation for efficient verifiable training of neural networks, outperforming state-of-the-art methods on MNIST and CIFAR-10 datasets. It achieves lower verified error rates under different distortion levels, surpassing IBP and other methods. Recent works in neural network robustness verification algorithms focus on finding upper and lower bounds of output neurons within a set S, using convex relaxation based methods. CROWN-IBP stands out as the top performer among various approaches, providing tight but computationally tractable bounds for model robustness. These methods, such as CROWN, DeepPoly, Fast-Lin, DeepZ, and Neurify, rely on linear relaxations of non-linear units in neural networks to address the NP-complete nature of the problem. After linear relaxation, neural network output is bounded by upper/lower hyper-planes using various methods like Lagrangian dual, semidefinite relaxations, and local Lipschitz constant bounds for verification. Randomized smoothing can certify the robustness of models probabilistically. Adversarial examples can be used to augment the training set and improve neural network robustness. Adversarial training involves solving a minimax robust optimization problem to minimize the robust loss. Madry et al. (2018) proposed using projected gradient descent (PGD) for this purpose. Despite achieving state-of-the-art test accuracy under strong attacks, models trained using projected gradient descent (PGD) lack verified error guarantees due to the nonconvexity of neural networks. PGD attacks can only compute a lower bound of robust loss, which may not ensure minimization of the actual loss. This poses challenges for safety-critical applications requiring certified safety in models. Verifiable adversarial training methods aim to achieve network robustness efficiently by combining adversarial training with robustness verification. Certified adversarial training uses a verification method to find an upper bound of the inner max and update parameters based on this upper bound to minimize robust loss. Various methods like Cauchy projection and dynamic mixed training have been proposed to improve efficiency in training. Interval Bound Propagation (IBP) is a method that computes pre-activation outer bounds for each layer of a neural network without relaxing ReLU neurons or considering correlations between neurons of different layers. This approach aims to provide sound over-approximations for neural networks and has shown scalability to larger networks. Interval Bound Propagation (IBP) demonstrated superior performance compared to other methods, with more precise approximations and better training schemes. However, IBP can be unstable and challenging to tune due to loose bounds, especially during initial training phases. To address this, a mixture of regular and minimax robust cross-entropy loss is used for training. IBP trained models have low IBP verified errors, but when verified with tighter bounds like CAP and CROWN, the errors increase significantly. CROWN is tighter than CAP, but the gap between CROWN and IBP is still large. A 4-layer CNN network was used for all datasets to compute these bounds and define verification specifications for neural networks. In robustness verification, a specification matrix C is defined for neural network output margins between classes. The lower bound of Cf(x) for all x in a set S(xk) is crucial for verifying robustness. This quantity can be obtained using neural network verification algorithms like convex adversarial polytope, IBP, or CROWN. Wong & Kolter (2018) showed that for cross-entropy loss, there is an opportunity to solve the robustness issue. Interval Bound Propagation (IBP) provides a simple bound propagation rule for neural networks, ensuring that the maximum output is minimized. It can be applied to inputs bounded by general norms, converting them to per-neuron intervals after the first affine layer. IBP rule can be used for later layers as well. IBP can be viewed as training a simple augmented ReLU network, friendly to optimizers. Networks trained using IBP can have good verified errors with IBP but worse errors with linear relaxation methods like CAP and CROWN. IBP is a loose bound initially, leading to unstable training, but a schedule of gradually increasing IBP can help. During training, the norm of weight matrices in CROWN-IBP increases steadily, leading to stable training. In contrast, using linear relaxation methods like CAP and CROWN results in smaller norm weights and potential over-regularization of the model. This difference impacts the verifiable error, with CROWN-IBP maintaining low error rates even with higher norms. The error does not significantly increase when it reaches 0.3. Linear relaxation methods have high computational and memory costs, and poor scalability. Convex adversarial polytope is slower and requires more memory compared to CROWN-IBP. IBP performs well with smaller verified error and scales efficiently to large networks, but can be sensitive to hyperparameters. Linear relaxation methods provide tighter lower bounds but over-regularize the network. CROWN-IBP is a new certified defense that combines IBP and a CROWN-style bound to optimize a problem for network parameters. It allows for a trade-off between clean accuracy and verified accuracy by using a mixture of natural and robust training loss. The computation of the lower bounds of CROWN-IBP involves IBP bound propagation in a forward manner. The CROWN-IBP algorithm combines IBP and CROWN-style bound propagation for certified defense. It involves obtaining z values for all layers, computing m IBP (x), and linear relaxation of ReLU neurons to provide upper and lower bounds of the output. The CROWN-IBP algorithm combines IBP and CROWN-style bound propagation for certified defense by obtaining z values for all layers and computing m IBP (x) with linear relaxation of ReLU neurons to provide upper and lower bounds of the output. The backward bound propagation in CROWN-IBP starts bounding from the last layer, choosing lower bounds of \u03c3(z i,k is positive, and upper bounds otherwise. The CROWN-IBP algorithm combines IBP and CROWN-style bound propagation for certified defense by obtaining z values for all layers and computing m IBP (x) with linear relaxation of ReLU neurons to provide upper and lower bounds of the output. The next linear layer is unfolded by plugging in the ReLU layer \u03c3(z (L\u22122)) using its linear relaxations. Computational cost is a concern due to the expensive computation of all A matrices for each layer. The computational issues with CROWN-IBP include the expensive computation of A matrices for each layer and inefficiencies when dealing with convolutional layers on GPUs. CROWN-IBP addresses computational issues by efficiently obtaining bounds of intermediate layers, avoiding the drawbacks of ordinary CROWN. The backward pass of CROWN-IBP replaces affine layers with transposed operators and activation function layers with diagonal matrix products, allowing for better scalability and implementation efficiency. CROWN-IBP offers unique benefits such as tightness, efficiency, and flexibility. It is based on CROWN, providing a tight linear relaxation lower bound to improve bounds obtained by IBP. CROWN-IBP avoids high computational costs and is efficient for relatively large networks. The objective is more general than IBP, allowing flexibility to exploit strengths from both IBP and convex relaxation methods. During training, slowly decrease \u03b2 to 0 to avoid over-regularization issues and maintain stability in initial training of IBP. Keeping \u03b2 = 1 can outperform convex relaxation methods in small scenarios. CROWN-IBP is evaluated on models similar to those in previous studies on MNIST and CIFAR-10 datasets, using different perturbation norms. Training involves a warm-up phase followed by a ramp-up schedule. Cross-entropy loss with weight \u03ba may be added for both IBP and CROWN-IBP. During training, the weight \u03ba for cross-entropy loss is scheduled to decrease linearly from \u03ba start to \u03ba end within R ramp-up epochs. Different settings for \u03ba start and \u03ba end are explored to understand the trade-off between verified accuracy and standard accuracy. A linear schedule is used for \u03b2 during the ramp-up period, with \u03b2 start = 1 and \u03b2 end = 0, except for CIFAR-10 where \u03b2 start = \u03b2 end = 1 at = 2 255. Verified error is calculated as the percentage of test examples where at least one element in the lower bounds is < 0, obtained using IBP or CROWN-IBP. During training, the weight \u03ba for cross-entropy loss is scheduled to decrease linearly from \u03ba start to \u03ba end within R ramp-up epochs. Different settings for \u03ba start and \u03ba end are explored to understand the trade-off between verified accuracy and standard accuracy. When both \u03ba start = \u03ba end = 0, no natural CE loss is added and the model focuses on minimizing verified error, but the lack of natural CE loss may lead to unstable training, especially for IBP; the \u03ba start = 1, \u03ba end = 0.5 setting emphasizes on minimizing standard error. CROWN-IBP outperforms IBP in standard and verified error rates, especially for large models. It reduces verified error rates significantly on MNIST and CIFAR-10 datasets. The trade-off between standard and verified accuracy is evaluated for different \u03ba settings on a DM-large CIFAR-10 model. In evaluating the DM-large CIFAR-10 model with test = 8/255 under different \u03ba settings, a larger \u03ba start or \u03ba end tends to improve standard errors. CROWN-IBP outperforms IBP in both standard and verified accuracy, reducing standard error from roughly 55% to 45% to reach a verified error of 70%. CROWN-IBP can reduce standard error from roughly 55% to 45% to reach a verified error of 70%. Training stability is evaluated on various model architectures, showing the stability of CROWN-IBP. IBP verified errors are compared using MIP and LP, with IBP errors reported for fair comparison. Achieving the 68.44% IBP verified error requires additional PGD adversarial training. The 68.44% IBP verified error is achieved by adding PGD adversarial training loss. Results are compared to 73.52% IBP verified error. CIFAR-10 models are trained with train = 1.1 test. CROWN-IBP consistently outperforms under different schedule lengths. IBP with \u03ba = 0 struggles to converge on all models with short schedules. CROWN-IBP is a new certified defense method that combines IBP and CROWN bounds for stability in training under robust optimization. It outperforms other IBP baselines in standard and verified errors, achieving state-of-the-art results for \u221e robustness. IBP provides loose estimations of output ranges for neural networks during training. During training, IBP can be viewed as an augmented neural network called IBP-NN. It takes two points x L and x U as inputs and uses bound propagation for forward propagation. The top-1 prediction is y k if all elements of m(x k) are positive. The augmented IBP network, trained with cross-entropy loss, aims to predict correctly within a certain range. IBP-NN's simplicity aids gradient-based optimization, while convex relaxation bounds are more complex and challenging for optimizers. Both IBP and CROWN-IBP provide lower bounds, with a larger bound indicating better quality. During early training, CROWN-IBP produces significantly better bounds than IBP, gradually improving as the model learns to tighten IBP bounds. This leads to a more effective minimax optimization problem. During IBP training, a network can eventually achieve tight IBP bounds and high verified accuracy, adapting to the bounds and learning specific weights. However, the initial phase of training can be challenging and crucial. Performance can vary across models and initializations, with sensitivity to hyperparameters like \u03ba or schedule length. Some IBP models may converge sub-optimally due to instability in the beginning phase, where loose bounds make the robust loss ineffective. During IBP training, initial tight bounds are crucial for effective optimization. Tighter bounds at the start help keep the robust loss in a reasonable range, allowing the network to gradually learn good weights for tighter IBP bounds. CROWN method provides initial tight bounds, gradually replaced by IBP bounds, leading to a model with learned tight IBP bounds. Goal is to reproduce performance reported in (Gowal et al., 2018) and show advantage of CROWN-IBP under same settings. Training on CIFAR-10 with large batch size and long schedule on TPUs. For CIFAR-10 experiments, large batch size and long training schedule on TPUs were used to achieve results. The same code base as Gowal et al. (2018) was utilized. Model performance for small and medium sized models trained on a single GPU can be found in Table D in Section F. Training stability experiments are detailed in Section 4 and Section H. Model structures (DM-small, DM-medium, DM-large) are listed in Table A and are consistent with Gowal et al. (2018). Training hyperparameters for MNIST IBP baseline results followed the same set as Gowal et al. (2018), with 100 epochs, batch size of 100, warm-up and ramp-up duration, and learning rate for Adam optimizer. For CIFAR-10 experiments, large batch size and long training schedule on TPUs were used. Model performance for small and medium sized models can be found in Table D. Training stability experiments are detailed in Section 4. For MNIST IBP baseline results, training hyperparameters followed the same set as Gowal et al. (2018). The IBP results match their reported numbers, using IBP verified errors rather than MIP verified errors. CROWN-IBP with train = 0.4 achieved verified error rates at different test levels using the DM-Large model. For CIFAR-10 experiments, a training schedule on TPUs with a batch size of 1024 and learning rate of 5 \u00d7 10 \u22124 was used. Data augmentation included random flips and crops, with image normalization. The schedule improved IBP baseline and CROWN-IBP performance by around 1%. The training schedule on TPUs with a batch size of 1024 and learning rate of 5 \u00d7 10 \u22124 improved IBP baseline and CROWN-IBP performance by around 1%. Hyperparameters \u03ba and \u03b2 are used to trade-off between clean accuracy and verified accuracy, with \u03ba decreasing from \u03ba start to \u03ba end while \u03b2 increases from \u03b2 start to \u03b2 end. Setting \u03ba start = 1 and \u03ba end = 0 is recommended as a safe starting point, with the option to adjust \u03ba end for better standard accuracy. CROWN-IBP introduces an additional hyperparameter, \u03b2, to balance between convex relaxation and IBP bounds. \u03b2 is set to 1 initially to obtain tighter bounds during training. The choice of \u03b2 end determines whether to use convex relaxation or IBP bounds after a schedule.\u03b2 end = 1 is recommended when the convex relaxation method can outperform IBP. In training stability experiments, small models are used to explore various settings quickly and cheaply. Hyperparameters include training for 100 epochs with batch size 256 using Adam optimizer with a learning rate of 5 \u00d7 10 \u22124 for MNIST. The networks consist of 2D convolutional and fully connected layers with ReLU activation functions. For CIFAR, training involves 200 epochs with batch size 128 using Adam optimizer with a learning rate of 0.1%. Data augmentation includes random horizontal flips and random crops. Image channels are normalized with specific mean and standard deviation values. The text discusses the model structures used in training stability experiments for CIFAR-10 models, with 18 different structures designed by the authors. Model A is deemed too small for CIFAR-10 and is excluded from the experiments. The small model (model structure B) is used for all three datasets (MNIST, CIFAR-10). The text discusses using a small model (model structure B) for training on MNIST and CIFAR-10 datasets. Results from the best DM-Large model are reported, along with verified and attack errors for different model structures. CROWN-IBP consistently outperforms IBP across various settings. Model structures used in training stability experiments include ReLU activations and convolutional layers. In this section, experiments were conducted on smaller MNIST and CIFAR-10 models using IBP and CROWN-IBP. The purpose was to compare model performance statistics across a wide range of models. Results showed that CROWN-IBP consistently outperformed IBP in terms of best, median, and worst verified errors. Although these small models did not achieve state-of-the-art performance, CROWN-IBP showed significant improvements in worst case verified error. In experiments comparing IBP and CROWN-IBP on smaller MNIST and CIFAR-10 models, CROWN-IBP consistently outperformed IBP in verified errors. Overfitting was observed in both methods on MNIST with small datasets. To address this, using train > test or explicit regularization can help. Testing the training stability of CROWN-IBP on MNIST models showed mean and standard deviation results in Table E. The study compared verified errors of 10 MNIST models trained using CROWN-IBP with and without regularization. Adding a small regularization term significantly reduced errors on the test set, making CROWN-IBP results comparable to convex adversarial polytope training. The overfitting observed in IBP methods is attributed to its strong learning power without over-regularization. Using early stopping can improve verified error on the test set. CROWN-IBP is slower than IBP in training time but has better GPU utilization. CROWN-IBP combines IBP bounds with linear relaxation methods for scalability and stability. Random projections can accelerate backward bound propagation in CROWN-IBP. TPUs are not necessary for CIFAR-10 experiments, as multi-GPUs can achieve comparable results. The CROWN-IBP framework replaces non-linear functions in neural networks with linear bounds, achieving linear bounds by utilizing linear combinations. The verified error is evaluated using the CROWN-IBP bound. CROWN requires specific bounds for different non-linear functions like ReLU, tanh, sigmoid, etc. Convex adversarial polytope is a related linear relaxation technique for ReLU layers. For ReLU, bounds are simple with diagonal matrices. The CROWN lower bound for ReLU neurons in a neural network function is derived using pre-activation bounds obtained through interval bound propagation (IBP). This bound ensures that the neuron is always inactive if z k < 0 and always active if z k > 0."
}