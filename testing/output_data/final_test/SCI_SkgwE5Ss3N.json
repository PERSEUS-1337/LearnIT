{
    "title": "SkgwE5Ss3N",
    "content": "Federated learning involves training machine learning models on edge devices with distributed data partitions. FedProx is a framework introduced to address statistical heterogeneity in federated settings, improving robustness and stability compared to FedAvg. Federated learning utilizes large networks of remote devices to generate data daily. Optimization methods like FedAvg are commonly used for training models in distributed partitions of data/tasks. FedAvg is effective for non-convex federated learning but lacks the ability to handle statistical heterogeneity in federated settings. In federated settings, FedAvg struggles with statistical heterogeneity due to non-identically distributed data across devices. Recent works on convergence guarantees are limited to unrealistic scenarios, making federated learning akin to distributed multi-task learning in networks. In federated learning, the focus is on training a single global model on distributed data collected from various tasks. A novel optimization framework called FedProx is introduced to address convergence behavior in statistically heterogeneous data. FedProx encompasses FedAvg and provides the first convergence guarantees under a device dissimilarity assumption in the network. The framework improves robustness and reflects empirical performance. Recent optimization methods tailored to the challenges of federated learning have shown improvements over traditional distributed approaches. FedProx can enhance convergence robustness and stability when dealing with heterogeneous data across devices. Recent optimization methods tailored to the challenges of federated learning have shown improvements over traditional distributed approaches. ADMM BID2 allows for inexact local updating to balance communication vs. computation in large networks. Smith et al. (2017) proposes a communication-efficient primal-dual optimization method for multi-task learning. However, this approach does not generalize to non-convex problems like deep learning. In the non-convex setting, Federated Averaging (FedAvg) has been shown to work well empirically. FedAvg is challenging to analyze due to its local updating scheme and the limited number of active devices at each round. Recent works have made progress in analyzing FedAvg in simpler settings, such as parallel SGD and related variants. Some recent studies have explored convergence guarantees in heterogeneous settings but with limiting assumptions. Heuristic approaches aim to address statistical heterogeneity by sharing local device data or server-side proxy data, which may not be practical in federated learning. In this section, recent methods for federated learning, including FedAvg, are introduced. The aim is to minimize a global learning objective across multiple devices with differing data distributions. Federated optimization methods commonly allow for low participation and local objectives to reduce communication and handle system constraints. In federated optimization methods, local updates are aggregated via a central server. Local objectives can be solved inexactly, with \u03b3-inexactness used to measure the amount of local computation. In FedAvg, a subset of devices are selected at each round to optimize local objectives. In FedAvg, a subset of devices are selected at each round to run SGD locally for a specified number of epochs to optimize the local objective. It is crucial to tune the number of local epochs for convergence. FedProx introduces a more principled approach by using a surrogate objective to limit local deviation. The proximal term in the expression limits local updates close to the current model. It is a popular tool in optimization literature. The proposed usage tackles statistical heterogeneity in federated settings. The server selects a subset of devices at random and sends the current model to them. Each device finds an approximate minimizer and sends it back to the server for aggregation. FedProx is more amenable to theoretical analysis due to the proximal term. In Section 5, the modified local subproblem in FedProx shows more robust convergence compared to FedAvg for heterogeneous datasets. A metric called local dissimilarity measures the difference among local functions, with B-local dissimilarity defined under an assumption on bounded local dissimilarity. The value of B(w) indicates the dissimilarity among local functions, with convergence to the same expected risk function if local functions are associated with empirical risk objectives and samples are homogeneous. The text discusses the convergence analysis of FedProx algorithm under the assumption of bounded dissimilarity among local functions. The theorem states conditions for non-convex FedProx convergence based on Lipschitz smoothness and dissimilarity of local functions. The text presents Theorem 3, which identifies the expected decrease in the global objective at each iteration of Algorithm 1 in FedProx. Conditions for positive \u03c1 in Theorem 3 are discussed, emphasizing the trade-off between dissimilarity bound (B) and algorithm parameters (\u03b3, K). The convergence rate of FedProx under Assumption 1 is characterized in Theorem 5 for general non-convex functions Fk(\u00b7). The convergence rate of FedProx is proven for convex loss in Appendix A.3, with comparisons to SGD in Appendix A.4. Empirical results for FedProx show the impact of statistical heterogeneity on FedAvg and FedProx convergence, properties of the FedProx framework, and the relationship between empirical convergence and bounded dissimilarity assumption. Limited experimental results are shown, with full details available in Appendix B. All code, data, and experiments are publicly accessible on github.com/litian96/FedProx. FedProx is evaluated on various tasks and datasets, including synthetic and real-world datasets curated from prior federated learning work. The impact of statistical heterogeneity on convergence is studied, showing that setting \u00b5 > 0 is beneficial in heterogeneous settings. The key parameters affecting FedProx performance are the number of local epochs, E, and the proximal term scaled by \u00b5. Different values of E and \u00b5 are explored using federated datasets. The study evaluates FedProx on various datasets, exploring the impact of different values of E and \u00b5. Large E may lead to instability on heterogeneous datasets but can be useful in communication-expensive scenarios. FedProx with E=50 and \u00b5=0.2 shows faster and more stable convergence compared to other parameter settings. The study evaluates FedProx on different datasets, examining the effect of varying values of \u00b5. Increasing data heterogeneity negatively impacts convergence, but setting \u00b5 > 0 can help mitigate this issue. The appropriate \u00b5 can improve convergence and stability, making FedProx less reliant on E. Adaptive selection of \u00b5 based on model performance is effective in practice. The study evaluates FedProx on different datasets, examining the effect of varying values of \u00b5 for improving convergence and stability. Additional experiments in Appendix B.5 show the dissimilarity metric's consistency with training loss, indicating better convergence with smaller dissimilarity.\u00b5 can be enforced appropriately to achieve this. The convexity of h k implies DISPLAYFORM5. Using the triangle inequality, we get DISPLAYFORM6, leading to DISPLAYFORM7. By defining M t+1 and utilizing Lipschitz smoothness of f, we can derive DISPLAYFORM9. The algorithm uses K randomly chosen devices to approximate w t, utilizing local Lipschitz continuity of f to find E f (w t+1). The algorithm uses K randomly chosen devices to approximate w t, utilizing local Lipschitz continuity of f to find E f (w t+1). Theorem 3 uses the dissimilarity in Definition 2 to identify sufficient decrease at each iteration for FedProx. Corollary 6 characterizes the performance with a bounded variance assumption commonly employed in methods like SGD. The algorithm utilizes K randomly chosen devices to approximate w t, using local Lipschitz continuity of f to find E f (w t+1). Theorem 3 ensures sufficient decrease at each iteration for FedProx, while Corollary 6 characterizes performance with a bounded variance assumption commonly used in methods like SGD. Theorem 7 extends the results to non-convex FedProx convergence under the bounded variance assumption. The text discusses the convergence of a convex case algorithm, showing that if all local problems are solved accurately, a decrease proportional to the squared norm of the gradient can be achieved. The number of iterations needed to generate a solution with a squared norm of the gradient less than a certain threshold is also analyzed. FedProx achieves asymptotic convergence guarantee similar to SGD under bounded variance assumption. Synthetic data generation involves heterogeneity among devices with diagonal covariance matrix and mean vector elements drawn from normal distributions. Parameters \u03b1 and \u03b2 control local model differences and data variability. The study explores heterogeneous distributed datasets by varying \u03b1 and \u03b2 to control local model differences and data variability. Real datasets from prior work in federated learning are also examined, including partitioned MNIST, Federated Extended MNIST, FMNIST, and Sentiment140. FedAvg and FedProx are implemented in Tensorflow for the experiments. FedProx in Tensorflow BID0 is used for experiments where learning rate and active devices per round are tuned on FedAvg. Data is split into training and testing sets on each local device. Results are reported based on the global objective f(w). Datasets used include non-synthetic datasets from prior work on federated learning and some from LEAF benchmark. Synthetic data is also used to test the effect of heterogeneity. In experiments using FedProx in Tensorflow BID0, synthetic data is created to test the impact of heterogeneity on convergence. Three non-identical distributed datasets are generated with different parameters. MNIST dataset is used for image classification, distributed among 1000 devices with samples of only 2 digits each. The curr_chunk discusses different datasets used for image classification tasks, including FEMNIST and Shakespeare datasets. FEMNIST is a federated version of EMNIST with 62 classes, while the Shakespeare dataset is based on the works of William Shakespeare with 80 classes for character prediction. The curr_chunk discusses text sentiment analysis tasks on tweets from Sentiment140 and the creation of FEMNIST* dataset by subsampling characters from FEMNIST. The model used for Sent140 involves embedding characters into a 300-dimensional space using GloVe and employing a two-layer LSTM binary classifier. The FEMNIST* dataset consists of 200 devices with 20 classes each, using the same model as FEMNIST. The text discusses the implementation of FedProx on FEMNIST dataset, comparing it with FedAvg using SGD as a local solver. A different device sampling scheme is used, resulting in stable performance for both methods. The simulation involves one server and N devices on a commodity machine. In a federated learning setup on a commodity machine, hyperparameters are tuned for active clients per round and learning rate. Different datasets have varying percentages of active devices. Code is implemented in Tensorflow BID0 Version 1.10.1, with experiments conducted using a batch size of 10. The effect of E is explored in Figure 4. In Figure 4, the effect of E on convergence is explored for different datasets. Larger E leads to divergence or instability on some datasets but speeds up convergence on others. The hypothesis is that data distribution across devices plays a role, validated by observing instability on a skewed variant of the FEMNIST dataset. The effect of \u00b5 on convergence is also considered in Figure 5, showing that the appropriate \u00b5 can increase stability for unstable methods. In Figure 6, the B-local dissimilarity measurement captures dataset heterogeneity and correlates with training loss. Smaller dissimilarity indicates better convergence, achievable by setting \u00b5 appropriately. Results for all experiments are provided in Appendix B.3, with testing accuracy, training loss, and dissimilarity measurements shown in Figures 4, 8, and 9 for FedProx on different devices. The text discusses the training loss, testing accuracy, and dissimilarity measurement of FedProx using different device sampling schemes. It also introduces a heuristic for setting \u00b5 on synthetic datasets and highlights the connection to elastic averaging SGD (EASGD). EASGD employs a complex moving average for parameter updates and is limited to using SGD as a local solver. Differences in sampling schemes show that sampling devices proportionally to local data points and averaging models slightly outperforms uniform sampling. The setting with \u00b5 = 1 shows more stable performance than \u00b5 = 0 for simple quadratic problems. The proximal term introduced has been explored in previous optimization literature for speeding up SGD training on a single machine. Li et al. (2014b) also uses a similar approach. The proximal term introduced in previous optimization literature for speeding up SGD training on a single machine is also employed by Li et al. (2014b). DANE includes a proximal term in the local objective function but is not directly applicable to heterogeneous datasets. The bounded dissimilarity assumption has been explored in different forms in previous studies. In previous studies, the bounded dissimilarity assumption has been explored. In Yin et al. (2018) and Vaswani et al. (2019), different assumptions are used to quantify benefits in optimization algorithms. The authors in Vaswani et al. (2019) prove better convergence rates for SGD with a constant step-size using a strong growth condition assumption. This differs from the current analysis as the algorithm being studied is not SGD."
}