{
    "title": "ByfyHh05tQ",
    "content": "Designing RNA molecules has gained interest in various fields like medicine, synthetic biology, and bioinformatics due to their regulatory roles in transcription and translation. The RNA Design problem involves finding an RNA sequence that meets specific structural constraints. A new algorithm called LEARNA, utilizing deep reinforcement learning, has been proposed to address this issue. By meta-learning across numerous RNA Design tasks, Meta-LEARNA can construct an RNA Design policy applicable to new tasks. This approach optimizes over a diverse range of policy network architectures. Our approach optimizes over a rich space of architectures for the policy network, hyperparameters, and decision process, achieving new state-of-the-art performance on RNA Design benchmarks. It is significantly faster than previous methods and we conduct an ablation study to analyze its components. Recent studies have highlighted the crucial role of non-protein-coding RNAs (ncRNAs) in regulatory processes and disease development. These functional ncRNAs are involved in various cellular functions such as epigenetic modulation and mRNA stability. Engineering ncRNA molecules is becoming increasingly important for applications in biotechnology and medicine. Successful creation of functional RNA sequences both in vitro and in vivo has been reported. RNA is a sequence of four nucleotides - Adenine (A), Guanine (G), Cytosine (C), and Uracile (U). The RNA sequence serves as a blueprint for the functional structure of the RNA molecule, determined by folding and translating the sequence into its 3D tertiary structure. The hydrogen bonds between nucleotides influence the tertiary structure, forming the secondary structure of RNA. Many algorithms for RNA tertiary structure design work directly on RNA secondary structures. RNA tertiary structure design focuses on RNA secondary structures, with algorithms like folding algorithms being crucial for RNA engineering advancements. The RNA Design problem involves designing an RNA sequence that folds into a desired secondary structure, with various algorithms utilizing search strategies to find solutions. In this paper, a novel generative deep reinforcement learning approach called LEARNA is described for RNA Design. LEARNA trains a policy network to predict RNA sequences based on target secondary structures, with Meta-LEARNA learning a single policy across multiple RNA Design tasks. The approach uses the distance of the resulting structure to the target structure as an error signal for the RL agent. The study introduces a new benchmark dataset with explicit training, validation, and test splits for RNA Design. They optimize the policy network architecture, training hyperparameters, and state representation to achieve the best results. This is the first application of architecture search to reinforcement learning and metalearning, leading to new state-of-the-art performance. The study introduces a new benchmark dataset for RNA Design and achieves state-of-the-art performance on RfamTaneda and Eterna100 datasets. Meta-LEARNA outperforms previous approaches significantly in terms of speed. The RNA Design problem involves finding an RNA sequence that matches a target secondary structure using the Zuker algorithm. The approach is not limited to RNA secondary structure and can be applied to any RNA folding algorithm. RNA structures are often represented using dot-bracket notation. Algorithms for RNA Design use a structural loss function to compare target and folded structures. The Hamming distance is a common loss function used in this work. Multiple RNA sequences can fold to the same secondary structure. Our novel generative approach for the RNA Design problem is based on reinforcement learning. We model RNA Design as a decision process with a target structure \u03c9, incorporating strategies for designing RNA end-to-end. The components of this process (state space S, action space A, reward function R \u03c9, and transition function P \u03c9) are specified to optimize the loss function. The RNA Design problem is defined with respect to a folding algorithm denoted as F(\u00b7) and the set of dot-bracket encoded RNA secondary structures. In each episode, the agent designs an RNA sequence that folds into a given structure \u03c9 \u2208 \u2126 by placing nucleotides at each time step. The action space is defined for unpaired and paired sites, with actions corresponding to RNA nucleotides or Watson-Crick base pairs. No action is taken for closing brackets. The agent chooses actions based on the state provided by the environment, which consists of a (2\u03ba + 1)-gram centered around the target structure site. Padding characters are added to construct the n-gram at all sites. The state space is defined with symbols in dot-bracket notation, where actions are taken to place nucleotides at paired sites. The agent selects actions based on the state given by the environment, which includes a (2\u03ba + 1)-gram centered around the target structure site. Nucleotides are placed at paired and unpaired sites based on the state. The transition function is deterministic, and the reward function is based on the Hamming distance between the folded candidate solution and the target structure. The optimization problem is solved by setting a hyperparameter \u03b1 to shape the reward. Incorporating a local improvement step to enhance sample efficiency and performance, the hyperparameter \u03b1 shapes the reward in DISPLAYFORM3. If the Hamming distance is less than a hyperparameter \u03be, neighboring primary sequences are explored by exhaustively trying all combinations for mismatched sites. The pseudocode for computing R T \u03c9 (\u03c6) is provided in Appendix A. Deep reinforcement learning is utilized to learn the parameters \u03b8 of policy networks \u03c0 \u03b8, which consist of an embedding layer and a deep neural network with convolutional, recurrent, and fully-connected layers. Various strategies are proposed for optimization. The LEARNA strategy involves learning parameters for a policy network in an online fashion, using the policy gradient method PPO. Meta-LEARNA utilizes a meta-learning approach to transfer knowledge across RNA Design problems associated with target structures in the training set. Meta-LEARNA-Adapt combines Meta-LEARNA and LEARNA strategies to train a single policy network on decision processes. It addresses sensitivity in deep reinforcement learning methods by using techniques from automatic machine learning, including efficient Bayesian optimization methods. The study combines Meta-LEARNA and LEARNA strategies to train a policy network for decision processes using efficient Bayesian optimization. The search space includes elements of CNNs and RNNs to optimize performance in architecture search and hyperparameter optimization. The architecture of the policy network includes binary encoding or embedding for state representation, optional CNN and LSTM layers, and a fully-connected network for action distribution. The goal is to optimize decision processes using efficient Bayesian optimization. The policy network architecture includes binary encoding for state representation, CNN and LSTM layers, and a fully-connected network for action distribution. Decision processes are optimized using Bayesian optimization by optimizing parameters such as state radius and reward shape. Training hyperparameters for neural networks, including learning rate and batch size, are also optimized. The search space consists of mostly integer variables. The search space for LEARNA and Meta-LEARNA was adapted for learning rate and entropy regularization based on preliminary experiments. The optimization process utilized the BOHB optimizer to handle mixed discrete/continuous spaces and exploit low-fidelity approximations to speed up optimization. Training time or evaluation limits were imposed to optimize performance. Refer to Appendix E for more details. To optimize design choices without overfitting, a new training and validation dataset, Rfam-Learn, was created based on the Rfam database. Different budgets were experimented with for LEARNA due to varied evaluation timeouts in benchmarks. After creating a new training and validation dataset called Rfam-Learn, different evaluation timeouts were tested for LEARNA optimization. The 30-minute variant outperformed the 10-minute one, leading to better results. Despite the known noise in RL outcomes, a policy network restart was implemented every 30 minutes to overcome stagnation. To manage optimization, a single run and validation set were used for each configuration. Three loss functions were studied: unsolved sequences, mean distances, and minimum distances to the target structure. Optimizing for minimum distances was chosen over mean distances. The final configuration was selected based on unsolved sequences among the top five configurations, all evaluated on the validation set. In this study, the authors adapted an approach for joint architecture search and hyperparameter optimization in deep RL, exploring a richer space of architectures. While RL has been used for architecture search and joint architecture and hyperparameter search, this paper is the first to focus on architecture search for RL. Variational autoencoders, generative adversarial networks, and reinforcement learning have shown promising results in protein design and related matter engineering problems. Recent studies have shown promising results in protein design and matter engineering using machine learning approaches. A convolutional neural network based auto-encoder was proposed for scoring guide RNAs in RNA Design for CRISPR/CAS9. This automated scoring could aid in designing guide RNAs for future applications. Generative machine learning methods have been competitive in this problem domain. Global methods manipulate a large number of candidates or generate samples from a global distribution. Recent studies have shown promising results in protein design and matter engineering using machine learning approaches. A convolutional neural network based auto-encoder was proposed for scoring guide RNAs in RNA Design for CRISPR/CAS9. This automated scoring could aid in designing guide RNAs for future applications. Generative machine learning methods have been competitive in this problem domain, manipulating a large number of candidates or generating samples from a global distribution. Additionally, RNA design approaches like MODENA, antaRNA, and MCTS-RNA have been developed. Another direction in RNA design involves incorporating human knowledge into the design process, with models trained on human solutions and strategies for refining candidate solutions. Totalized results on the Eterna100 benchmark have shown success, although human solutions were not available for further benchmarks. The authors were influenced by the work of BID5, where RL was applied to combinatorial problems like the Traveling Salesman Problem. They propose framing the RNA Design problem as an RL problem, designing RNA end-to-end. This approach contrasts with the work of Eastman et al. (2018), who used RL for local search starting from a different perspective. Eastman et al. utilized RL for local search in RNA design, where the agent modifies sequences to fold into a target structure. The agent's policy is a pre-trained convolutional neural network, referred to as RL-LS. The approach is evaluated against other methods and components are assessed through an ablation study. The study evaluates the components of a method for RNA design using RL-LS against other methods on established benchmarks. Results are reported for three benchmarks, with details provided in Appendix D. Each benchmark followed a standard evaluation protocol with multiple attempts and fixed time limits. Methods were compared on the same hardware with one CPU core per evaluation. All methods, including the one being evaluated, may benefit from further hyperparameter optimization for specific benchmarks. The study compared RNA design methods on three benchmarks, achieving new state-of-the-art results on Eterna100. Meta-LEARNA outperformed other methods in speed and performance stability. LEARNA matched MCTS-RNA results on Rfam-Taneda benchmark. Our novel deep reinforcement learning algorithm, Meta-LEARNA, achieved new state-of-the-art results on RNA design benchmarks, solving 83% of target structures. It outperformed other methods in speed, solving all target structures in less than 5 seconds. Meta-LEARNA learned a representation of RNA design dynamics and transferred this knowledge to new tasks. Our novel deep reinforcement learning algorithm, Meta-LEARNA, achieved new state-of-the-art results on RNA design benchmarks, solving 83% of target structures. It outperformed other methods in speed, solving all target structures in less than 5 seconds. Meta-LEARNA learned a representation of RNA design dynamics and transferred this knowledge to new tasks. Additionally, our analysis in Appendix H demonstrates that it scales better with sequence length than existing approaches. Ablation studies showed a clear performance boost from the local improvement step in our approach. The restart option improved performance on the Eterna100 benchmark, but continued adaptation of learned parameters did not show improvement. The fANOVA results emphasize the importance of optimizing policy network architecture, environment parameters, and training hyperparameters for joint optimization. More detailed results can be found in Appendices G and F. The deep reinforcement learning algorithm LEARNA was proposed for the RNA Design problem, achieving state-of-the-art results on benchmarks. Meta-LEARNA, pre-trained on biological sequences, includes a local improvement step and extensive optimization. The ablation study highlights the importance of all components in efficiently solving the RNA Design problem. Code and data for reproducing results are available at https://github.com/automl/learna. To ensure a diverse dataset, families from the Rfam database were downloaded and folded using the ViennaRNA package. Secondary structures with multiple solutions were removed, and only structures between 50 and 450 nucleotides were kept. Harder sequences that MCTS-RNA couldn't solve within 30 seconds were selected. The remaining structures were divided into training, validation, and test sets. The structures were split into training, validation, and test sets. The Zuker algorithm from ViennaRNA was used for computations on Broadwell CPUs. Meta-LEARNA utilized two CPUs for training and single core for evaluation. Rfam-Taneda and Rfam-Learn were used for experiments. The search space, computational budgets, and final configurations for LEARNA and Meta-LEARNA were detailed. Modified hyperparameters for Meta-LEARNA were adjusted based on preliminary experiments, with varying budgets used to focus resources on promising configurations in BOHB. In BOHB, budgets are geometrically distributed with a factor of three between them. LEARNA optimizes performance on the validation set with varying evaluation timeouts up to 30 minutes. Meta-LEARNA varies training time with a fixed 60-second evaluation timeout on the validation set. Timeout ranges were chosen based on Eterna100 benchmark constraints and performance considerations. The budgets for validation sequences in LEARNA and Meta-LEARNA are shown in FIG5 and FIG6. Results suggest that similar performance can be achieved with only 20 minutes of training. The relationship between validation loss and the fraction of solved sequences is highlighted. TAB4 summarizes the evaluated configurations, showing differences in architectural choices between LEARNA and Meta-LEARNA. The best configurations for LEARNA and Meta-LEARNA differ in key parameters, indicating the need for adaptation based on preliminary experiments. It is uncertain whether CNNs or LSTMs are better for generalizing across sequences. Longer training and optimization may lead to a Meta-LEARNA configuration with LSTM cells. The best configurations for Meta-LEARNA vary in key parameters, emphasizing the importance of jointly optimizing multiple aspects of the RL problem. An analysis of variance was conducted to quantify the global importance of parameters, with marginal prediction plots showing the impact of individual parameters. The fANOVA framework was used to analyze the impact of various parameters on performance in Meta-LEARNA. Key parameters included training and regularization hyperparameters, reward representation, and architectural hyperparameters. The analysis highlighted the importance of optimizing all components for better performance, with the best configurations achieving almost 90% success rate. The fANOVA analysis showed that optimizing all components is crucial for performance in Meta-LEARNA, with best configurations reaching almost 90% success rate. A large learning rate performs best on average, and limited entropy regularization indicates a diverse training set. Model-based agents have the biggest impact compared to random actions. The model-based agent has the biggest impact on performance compared to random actions. The local improvement step is also important, especially for sequences with less than 5 mismatches. Restarts only affect performance on the Eterna100 benchmark. Continued training in Meta-LEARNA-Adapt could have a greater impact on datasets dissimilar to the training data. Optimization of parameters could potentially improve performance in future work."
}