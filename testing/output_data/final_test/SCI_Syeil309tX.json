{
    "title": "Syeil309tX",
    "content": "Sensor fusion is a key technology that integrates various sensory inputs for decision making in applications like autonomous driving and robot control. Deep neural networks, specifically the netgated architecture, have shown improved performance over conventional CNNs. This paper proposes two optimized architectures: a coarser-grained gated architecture with group-level fusion weights and a two-stage gated architecture using both group-level and feature-level fusion weights. The proposed architectures demonstrate significant performance improvements and robustness in the presence of sensor noise and failures. Sensor fusion is crucial for autonomous systems like self-driving cars and robots, utilizing various sensors for enhanced safety and driving experience. Sensor fusion techniques have been explored for vehicle and robot control, as well as for activity recognition on devices like smartphones and smartwatches. A deep reinforcement learning based sensor fusion algorithm is discussed for robot control using LiDAR sensors. In the context of autonomous systems, sensor fusion techniques are compared for vehicle control, with BID9 using neural networks and a Kalman filter for roll angle estimation. BID7 employs a sensor-rich platform with a learning algorithm for maneuver prediction, utilizing LSTM networks with inputs from cameras and GPS. The study does not address sensor noise or different types of sensory inputs. BID4 propose joint probabilistic data fusion for road environments using sensory inputs from cameras, GPS, and speedometers. Different fusion methods are compared, including early fusion and deep convolutional neural networks. Effective sensor fusion network architectures for coping with sensor failures are discussed. The curr_chunk discusses the netgated architecture for sensor fusion in CNNs, which uses fusion weights from camera and LiDAR inputs to create a robust network. The paper aims to propose optimized gated architectures to improve upon the baseline netgated architecture and explore different fusion architectures. The curr_chunk proposes new gated architectures for sensor fusion in CNNs, including a coarser-grained architecture and a two-stage gating architecture. These architectures aim to address limitations of the baseline netgated architecture, such as inconsistent fusion weights and overfitting. Performance improvements are demonstrated using driving mode prediction and human activity recognition datasets. The netgated architecture proposed in BID8 offers a promising approach for sensor fusion in unmanned ground vehicle autonomous driving. It involves processing data from two sensory inputs, camera and LiDAR, through convolutional layers, pooling layers, and fully connected layers. The outputs are then fused by another fully connected layer. The netgated architecture in BID8 combines data from camera and LiDAR inputs through convolutional and fully connected layers, with feature-level fusion weights created and multiplied to produce the final prediction decision. The architecture allows for the possibility of gating certain sensory inputs based on the fusion weights. The netgated architecture in BID8 combines data from camera and LiDAR inputs through convolutional and fully connected layers, with feature-level fusion weights created and multiplied to produce the final prediction decision. The architecture allows for the possibility of gating certain sensory inputs based on the fusion weights. However, the architecture may face limitations such as inconsistency of fusion weights due to information sharing among all features. In our experimental studies, we found that the feature with the largest fusion weight may not always be the most critical for the learning task. This inconsistency in fusion weights can lead to misleadingly large values, potentially affecting prediction accuracy and causing over-fitting. When many features need to be fused, learning the fusion weights properly becomes crucial to avoid this issue. In experimental studies, inconsistencies in fusion weights can lead to over-fitting and affect prediction accuracy. To address this, two extensions are proposed: FeatureGroup Gated Fusion Architecture (FG-GFA) and Two-Stage Gated Fusion Architecture (2S-GFA), which aim to improve performance by introducing more powerful raw input fusion mechanisms. The Feature-Group Gated Fusion Architecture (FG-GFA) is introduced to address limitations in the baseline netgated architecture. It involves concatenating features within groups, passing them through convolution and pooling layers, and using fusion weights to combine information from different groups. This architecture aims to enhance performance by improving raw input fusion mechanisms. The FG-GFA architecture enhances performance by incorporating early fusion of sensory inputs within each group, leading to a smaller number of group-level fusion weights. These weights are used to multiply the corresponding fused group feature information, improving the raw input fusion mechanisms compared to the baseline netgated architecture. The FG-GFA architecture introduces different fusion mechanisms by multiplying fused group feature information, reducing the number of learned weights compared to the baseline. This leads to more robust learning of fusion weights at the group level, mitigating issues of inconsistency and over-fitting. Noisy or corrupted features in a group are reflected in the reduction of group-level fusion weight. In the hierarchical fusion architecture, FG-GFA improves performance by extracting group-level fusion weights. The 2S-GFA architecture combines baseline netgated architecture for feature-level fusion weights with FG-GFA for group-level fusion weights. The network splits outputs of the FC layer and reuses conv layer outputs for improved learning. The 2S-GFA architecture combines baseline netgated architecture for feature-level fusion weights with FG-GFA for group-level fusion weights. It integrates essential elements from both architectures to improve performance by reusing conv layer outputs and producing final decisions through fusion weights. The final fusion weight in the 2S-GFA architecture combines key information from feature-based and group-based processing, allowing for more reliable reflection of feature importance and serving as an effective gating mechanism. The group-level fusion weight can block noisy or corrupted sensory inputs, improving overall performance compared to the baseline architecture. The 2S-GFA architecture enhances feature-level fusion weights for finer gating of sensory inputs, optimizing between baseline netgated and FG-GFA architectures. It aims to learn data structure effectively, demonstrated through driving model prediction and human activity recognition on smartphones. The driving model prediction application involves three driving modes: idle, eco, and normal, with data collected from a 2014 Nissan Sentra using RPM, speed, gyroscope, and GPS data for time-series prediction. The driving data set includes sensor data collected from a Freematics ONE+ dongle BID6, with five types of sensory data used for training the neural network: RPM, SPEED, acceleration, GYRO Y, and D HEADING. Data is sampled every 250ms and used to predict the driving mode of the vehicle 5 seconds in the future. The feature vector window slides every 250ms for prediction. The proposed FP-GFA and 2S-GFA architectures use RPM, SPEED, D SPEED, GYRO Y, and D HEADING for training and testing neural networks on a human activity recognition dataset. The dataset includes accelerometer and gyroscope data with six activity classes. The features are split into two groups for the architectures. The study compares different neural network architectures using accelerometer and gyroscope data for human activity recognition. The dataset includes two feature groups, with the training and test sets containing 2,410 and 942 examples. The architectures include conventional CNN, netgated, feature-group gated fusion (FG-GFA), and two-stage gated fusion (2S-GFA) models, with 100,000 iterations used for training. The simulation environment is based on Tensorflow 1.10.1 BID0. The study evaluates different neural network architectures for human activity recognition using accelerometer and gyroscope data. The architectures include netgated, FG-GFA, and 2S-GFA models with specific configurations detailed in the Appendix. The performance is assessed using original and noisy datasets created by introducing sensory noise and failures. The noise levels are controlled at 5%, 10%, and 20% using random Gaussian noise. The study evaluates neural network architectures for human activity recognition using accelerometer and gyroscope data. Different noise levels are introduced to the datasets, with 5%, 10%, and 20% added noise. The performance of architectures is evaluated using driving mode prediction and human activity recognition datasets. The two-stage architecture shows the best prediction accuracy, followed by the FG-GFA architecture. These architectures outperform conventional CNN architecture and lead to noticeable improvements. The study evaluates neural network architectures for human activity recognition using accelerometer and gyroscope data. Different noise levels are introduced to the datasets, with 5%, 10%, and 20% added noise. The two-stage architecture shows the best prediction accuracy, followed by the FG-GFA architecture. These architectures outperform conventional CNN architecture and lead to noticeable improvements. The baseline netgated architecture has a loss less than those of the group-level and two-stage architectures for the training set, suggesting possible over-fitting. The proposed architectures show robust performances with the two-stage architecture being the best under all cases. The proposed two-stage architecture outperforms the baseline netgated architecture by nearly 3% in predicting driving modes. Analysis of performance improvements reveals that the feature-level fusion weight of RPM drops noticeably when 20% Gaussian noise is added, reflecting degraded quality. The fusion weight of RPM drops noticeably when 20% noise is added to D heading in the group2 feature. This reduction in weights decreases the contribution of D heading to the final prediction decision. The two-stage 2S-GFA architecture performs the best on human activity recognition data with clean data, followed by the FG-GFA architecture. The prediction accuracy of four models drops with increasing Gaussian noise, but the two proposed architectures show improved robustness. When sensor failures are introduced, the Nonnetgated network model's accuracy drops by 10%, while the two proposed architectures demonstrate better performance. The two-stage gated architecture outperforms the non-netgated model by 5% and the netgated model by 3% in this challenging test case."
}