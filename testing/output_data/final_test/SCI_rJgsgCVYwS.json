{
    "title": "rJgsgCVYwS",
    "content": "The text introduces three new point cloud processing blocks that enhance accuracy and memory efficiency in networks, enabling the design of deeper and more precise architectures. These blocks include a convolution-type operation for blending neighborhood information efficiently, a multi-resolution processing block, and a crosslink block for sharing information between different resolution branches. By combining these blocks, wider and deeper networks can be created. The text introduces new point cloud processing blocks that improve accuracy and memory efficiency in networks. These blocks include a convolution-type operation, a multi-resolution processing block, and a crosslink block. By combining these blocks, networks show improvements in accuracy and memory consumption on multiple segmentation benchmarks. For example, on the PartNet dataset, there is a 9.7% increase in IoU and a 57% decrease in memory footprint. Our deep network surpasses the shallow PointNet++ baseline by 3.4%, resulting in a 9.7% relative increase. Applying deep learning to graphics and 3D shape analysis has shown promising results, but challenges remain in adapting basic image processing blocks for 3D data. Operating with unstructured point clouds requires local pooling operations based on Euclidean distance. In this work, Lean Point Networks are introduced to enhance point processing networks by improving memory footprint and accuracy without compromising on inference speed. The PointNet++ architecture and its variants have memory-intensive nature due to replicating point neighborhood information, leading to significant memory overhead. Lean Point Networks aim to address this issue by introducing modules that reduce memory demands and allow for more layers, features, and feature compositions to be computed efficiently. The Lean Point Networks are designed to enhance point processing networks by reducing memory usage and improving prediction accuracy. By implementing a low-memory alternative for grouping operations, the 'point convolution block' is more memory-efficient and faster than its PointNet++ counterpart. Additionally, techniques are introduced to enhance information flow across layers and scales within point networks. The Lean Point Networks aim to improve point processing networks by reducing memory usage and enhancing prediction accuracy. This is achieved through a multi-resolution variant, residual links, and a cross-link block that broadcast multi-scale information. These advancements allow for deeper point networks to be trained on larger datasets, resulting in improved performance on segmentation benchmarks. Notably, the deep architecture achieves a 9.7% relative increase in IoU on the PartNet dataset while reducing memory footprint by 57%. The study confirms the generic nature of the deep architecture by extending experiments to additional networks, showing improvements in memory efficiency and performance. Learning-based approaches in geometric data analysis, specifically for point cloud data, have attracted attention with methods like PointNet and its extensions, Dynamic Graph CNNs, and PCPNet for shape segmentation and classification. Our work builds upon PointNet and its extension PointNet++ to improve accuracy in point cloud processing. By incorporating design techniques from computer vision, we have achieved significant performance enhancements compared to the original AlexNet network. Our work focuses on designing lean alternatives to point processing networks to reduce memory consumption and enable training of deeper/wider networks. Unlike previous studies that only addressed convergence speed or gradient issues, we explicitly tackle the memory problem, showing clear improvements over strong baselines. Checkpointing techniques are used to reduce memory complexity in deep neural networks by freeing up intermediate computation results and re-computing them in the backward pass. This method is slower during training but is effective for chain-structured graphs. However, it is more challenging to apply to general Directed Acyclic Graphs like U-Nets or multi-scale networks. Identifying graph components manually makes it cumbersome to experiment with diverse network architectures. Reversible Residual Networks (RevNets) limit computational blocks to an invertible form, eliminating the need for anchor points. Proposed generic blocks reduce memory footprint and can be easily integrated into various point processing architectures without additional design effort. The PointNet++ network improves information flow and reduces memory usage by stacking k-nearest neighbors for each point and applying PointNet to the resulting point set. However, it still has drawbacks such as being memory intensive and delaying global information transmission. The PointNet++ network improves information flow by stacking k-nearest neighbors for each point and applying PointNet. The existing PointNet++ grouping operation exposes the neighborhood of a point by concatenating neighboring vectors to form a tensor, processed by a Multi-Layer-Perceptron. During training, each layer retains a matrix in memory for backward pass updates. This is similar to a standard 2D image convolution operation. The PointNet++ network enhances information flow by stacking k-nearest neighbors and utilizing PointNet. Various modifications are proposed to improve memory and computational efficiency, such as combining parallel PointNet++ blocks, allowing information flow across branches, and introducing residual links. These tweaks lead to systematic gains in efficiency and enable the architecture to grow in depth. The proposed method for point clouds involves using nearest neighbor information similar to image convolutions in deep learning. Memory is freed after the forward pass, and the matrix is reconstructed on the fly in the backward pass. This on-the-fly re-computation positively impacts both forward and backward passes. The approach involves applying the SLP on the flat feature matrix before reconstructing the neighborhood just before max-pooling. The proposed method for point clouds involves using nearest neighbor information similar to image convolutions in deep learning. Memory is freed after the forward pass, and the matrix is reconstructed on the fly in the backward pass. Applying SLP on the flat feature matrix before reconstructing the neighborhood just before max-pooling significantly reduces memory consumption, allowing for the possibility of learning much deeper networks. The memory footprint of the convolution type architecture is significantly lower than the PointNet++ baseline, with only a 2.7% increase in memory when doubling the number of layers. Efficient information propagation through the network is crucial for training, as shown in computer vision experiments. Illustrations clarifying the operation of these blocks are available in the full text. The illustrations clarifying the operation of the blocks are only available in the Appendix. PointNet++ primarily uses a neighborhood of fixed radius, limiting access to local information at early network stages. This slow exchange of information among different scales is due to sparse measurements from a larger area, similar to log-polar sampling in computer and biological vision. In computer and biological vision, log-polar sampling involves obtaining a constant number of measurements in concentric disks of increasing radii. To reduce memory usage, neighborhoods of fixed size are extracted from downsampled versions of the original point cloud. This results in a 58% decrease in memory footprint on average across three datasets. The use of b-Residual Links with Residual Network architecture improves gradient flow during training. To enhance gradient flow during training, identity connections provide early network layers with access to undistorted loss gradients, addressing the vanishing gradient issue. Additionally, Cross-Resolution Links are introduced to facilitate information propagation across different resolution branches in the network, enabling the exchange of low-, mid-, and high-resolution data throughout processing. Unlike previous methods, Cross-links broadcast information across resolutions using an MLP transformation. Unlike previous methods, an MLP in a multi-resolution network transforms the output of one branch to the right dimensionality for combination with another branch. Each resolution branch focuses on its representation, with MLPs handling the translation between them. Communication between high and mid-resolution branches involves downsampling points and using an MLP for dimensionality transformation. Experimentation shows that both concatenating and summing multi-resolution features yield systematic results. The study evaluates modules on point cloud segmentation using three datasets of varying complexity: ShapeNet-Part, ScanNet, and PartNet. PartNet, with 24,506 samples and 251 labeled parts, is the most complex dataset tested. Training on diverse datasets reduces overfitting and allows for more informative conclusions. Our lean and deep architectures for PointNet++ show improved memory efficiency and performance on complex datasets like PartNet, where we train on the full dataset for segmentation across 17 classes. This approach contrasts with training separate networks for each category as in the original paper. The study reports results using two IoU metrics and demonstrates the adaptability of our architectures to large and intricate datasets. Our multiresolution (mRes) and convolution-type (convPN) networks outperform the PointNet++ baseline on complex datasets like PartNet, with performance gains of +5.7% and +12.5% on ScanNet, respectively. The use of residual connections allows for deeper network design without sacrificing performance. The architecture of our deep network involves doubling the number of layers in the encoding part, resulting in improved performance with minimal impact on efficiency. Compared to the shallow convPN, there is a 6.3% increase in inference time and a 3.6% increase in memory consumption at most. The memory growth as depth increases is shown to be extremely low. When compared to Deep GCN on the S3DIS dataset, our network achieves similar performance while using memory-efficient blocks and a weaker baseline. Our proposed building blocks for point processing networks offer memory-efficient convolutions and a multi-resolution approach, making it efficient to capture and diffuse information in a point neighborhood. These blocks can be stacked together, extended, or modified for different applications. The generality of our modular blocks is validated in various state-of-the-art point-based learning setups. The efficiency of our modular blocks for point processing networks is validated on three additional state-of-the-art networks: Dynamic Graph CNN, PointCNN, and SpiderCNN. These networks heavily rely on memory, which our modules improve by reducing memory consumption and increasing IoU performance. Our modular blocks can be easily integrated into various networks, enhancing both memory efficiency and performance metrics. Our modular blocks significantly reduce memory consumption and improve performance in state-of-the-art networks. Experiments show the impact of adjusting network architectures by adding connections or increasing depth. Efficiency is measured in IoU, memory footprint, inference time, and backward pass length. Results are reported in Table 4, demonstrating the effectiveness of our design choices for point processing networks. The lean architectures on Nvidia GTX 2080Ti GPU save memory and improve performance compared to PointNet++. The convPN architecture outperforms others, reducing inference time and backward pass length significantly. Increasing the number of layers has minimal impact on performance. Multi-Resolution approach helps capture complex features early in the network design. The mRes architecture, transitioning from PointNet++, boosts IoU by 1.2% on ShapeNet-Part and 5.7% on PartNet with increased efficiency. Despite longer inference time, memory footprint reduces by 58% and training time quickens by 62% due to a leaner design. Cross-resolution links enhance optimization with slight impacts on memory efficiency and speed. The performance of the leanest architecture on PartNet is improved by 0.8% with extra links, sacrificing some memory efficiency and speed. The network, composed of single-layer PointNet units, outperforms PointNet++ with a 12.5% increase in IoU on ScanNet and 7.4% on PartNet. Efficiency is also enhanced, with a 67% decrease in memory footprint and improvements in inference time and backward pass length. In this work, new generic building blocks for point processing networks have been introduced, showing improved memory efficiency and speed compared to current state-of-the-art networks like PointNet++. The lean architecture convPN based on PointNet++ outperforms in memory efficiency (-67%) and speed (-41% inference time, -68% backward pass length). The deep counterpart of convPN achieves the best IoU on PartNet (+9.7% over PointNet++), with a marginal cost in efficiency. These modular blocks also show improved performance on other architectures, with decreased memory usage (up to -69%) and increased IoU (up to +8.0%). In this section, details are provided on designing lean architectures for point processing networks like PointNet++, Dynamic Graph CNN, SpiderCNN, and PointCNN in Pytorch. The architectures show a significant decrease in memory usage (up to -69%) and an increase in IoU (up to +8.0%). The implementation ensures reproducible results for all tested networks. In this section, lean architectures for point processing networks like PointNet++, Dynamic Graph CNN, SpiderCNN, and PointCNN are designed in Pytorch. Downsampling modules are based on FPS to reduce input point cloud resolution, with upsampling layers using linear interpolation. Multiple resolutions are generated with a downsampling ratio of 2. The performance of multi-scale PointNet++ (MSG PN++) is reported to be superior in all tasks. The implementation is done in Pytorch for reproducible results. The architecture for segmentation tasks involves implementing PointNet++ in Pytorch with mRes architecture for multiresolution approach. Xlinks connections are added between layers for mResX architecture, merging information at different granularity using downsampling or upsampling with feature combination options. For feature combination, two alternatives are used: concatenation and summation. An additional sLP is added to each Xlink for mapping input feature dimensions to the target. The SLP is positioned before the upsampling or after the downsampling module. Notations like T ) are used for sampling points on each resolution. Convolution block C([r1, r2, ..., rn]T) includes neighborhood lookup, sLP layer, and max-pooling for each resolution. Transition block T([t1, t2, ..., tn]T) is responsible for changing resolutions. In the deep architecture, features are combined by summation and Xlinks are added inside each convolution block. The encoding part is doubled by repeating each convolution block twice, with a sampling block positioned after the third convolution block. Edge-conv layers are replaced by single resolution convPN blocks. The architecture includes a sequence of single resolution convPN blocks with transition blocks for residual links. SpiderConv blocks act as bilinear operators on input features and transformed points. Neighbourhood features are built on-the-fly within the block and reconstructed in the backward pass for gradient computation. In PointCNN, modifications are made to the backward pass to reconstruct tensors for gradient computation. The \u03c7-conv operator is adjusted to avoid storing neighbourhood features, using approximations and convPN blocks instead. The first fully connected layer now reconstructs neighbourhood features on-the-fly, improving memory efficiency. This approach is also applied to the convolution operator for transformed features. In experiments, datasets are processed to have the same number of points for each sample using downsampling or upsampling. Dropout layers are interleaved for network regularization, with a weight decay of 5e-4 added to the loss. Networks are trained using the Adam optimizer with specific coefficients for gradient optimization. The convPN block simplifies convolution by exposing the neighborhood, using an intermediate tensor to gather local information for each patch. This process, known as im2col operation, rearranges image blocks for faster convolution but requires careful memory management. The convPN block simplifies convolution by exposing the neighborhood and gathering local information for each patch. It is designed to be memory efficient by building the neighborhood matrix on-the-fly without storing neighborhood features. The network is evaluated on point cloud segmentation tasks on ShapeNet-Part and ScanNet datasets, assessing performance using mean point Intersection over Union (mIoU). The dataset used for evaluation consists of 21 semantic parts, with 1,201 training samples and 312 evaluation samples. Another dataset, PartNet, includes CAD models of 17 object categories with 251 labeled parts and provides samples for training, validation, and evaluation. The evaluation focuses on fine-grained semantic segmentation using the part Intersection over Union metric. The mIoU and pIoU metrics are computed for semantic parts in object categories. mIoU averages IoU values across parts, while pIoU averages IoU per part over the dataset. Part-IoU accounts for point cloud sampling randomness. The evaluation experiments in the paper focus on per-class IoU for PointNet++ based architectures on ShapeNet-Part and PartNet datasets. PartNet is more complex due to its high point count and segmentation detail. Lean blocks show improved performance on PartNet, highlighting the impact of information flow in network architectures. Our PointNet++ based networks outperform the original architecture on PartNet classes, especially Chairs and Lamps. Increasing network depth improves accuracy in capturing part boundaries. Deep architectures show advantages in handling samples with multiple parts. Efficiency metrics for different networks are provided in tables, including memory footprint and inference time. Additional experiments with KPConv network are also discussed. Our modules successfully reduce memory consumption by up to 52.5% without affecting forward or backward speed. Lean architectures save memory on GPU, with convPN showing the most significant decrease at 67%. Increasing network depth has minimal impact on inference time and memory consumption. Our deepConvPN network increases inference time by 6.3% on average and memory consumption by only 3.6% compared to convPN. It performs finer segmentation in frontier areas compared to PointNet++."
}