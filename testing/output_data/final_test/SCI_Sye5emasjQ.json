{
    "title": "Sye5emasjQ",
    "content": "Local explanation frameworks aim to rationalize decisions made by black-box prediction models by identifying minimal subsets of features that are sufficient for a decision to be reached. This approach is model-agnostic, uses instance-wise backward selection, and can reveal general principles governing a model's decision-making process. It produces more concise rationales than existing techniques and has been demonstrated on neural network models trained on text and image data. The rise of neural networks and nonparametric methods in machine learning has led to significant improvements in prediction capabilities, but also to the development of complex black-box models. Interpretability is crucial for sensitive applications like screening people for bail or loans, as well as for scientific applications where general principles can be extracted from accurate predictive models. Our approach proposes a local explanation framework to produce rationales for a learned model that maps inputs via an arbitrary learned function. The rationale is a sparse subset of input features that form the basis for the model's decision, ensuring interpretability without summarizing complex operations within the model. Our approach focuses on producing rationales for model decisions based on input features, without requiring gradients of f. Each input example is assumed to have a set of indexable features, allowing for unordered and varying numbers of features. A sufficient input subset (SIS) is proposed as a minimal input pattern that alone suffices for the model to make the same decision, based on a pre-specified threshold \u03c4. Our approach focuses on producing rationales for model decisions based on input features, without requiring gradients of f. We seek a minimal-cardinality subset S of input features such that f px S q \u011b \u03c4, representing a small input pattern highly indicative of class C. The work presents a method to identify decision factors in a model by finding sufficient input subsets that lead to a decision. These subsets, known as SIS, provide evidence for the model's decision-making process. Clustering SIS types across different data points can offer insights into the model's decision principles. The method allows for comparing models based on accuracy and human-determined relevance of targeted concepts. It is simple to use for non-experts and provides local explanations for individual classification decisions. This approach is model-agnostic and suitable for models outside of specific neural network variants. Local explanation techniques like LIME, saliency maps, Layer-wise Relevance Propagation, DeepLIFT, and Integrated Gradients quantify feature importance in determining the output of a function at a specific input. Gradient-based methods like DeConvNet, Guided Backprop, and PatternNet identify input patterns causing high function outputs but can be unreliable depending on the function and its architecture. Our SIS approach is conceptually simple, faithful to any model, and does not require access to gradients or additional training. It aims to identify input patterns that explain decisions without the need for predefined sets or auxiliary neural networks. Li et al. and Fong & Veldadi also focus on identifying minimal feature subsets that significantly impact model decisions. Our SIS approach aims to identify disjoint minimal subsets of input features that ensure positive predictions without relying on the rest of the input. This rationale is independently considered by the model for each decision, making it a sufficient justification. The SIS approach aims to identify feature subsets that justify decisions independently, ensuring interpretability and completeness. The subsets must satisfy criteria for sufficiency, minimalism, and exclusion of non-essential information. The SIS approach aims to identify feature subsets that justify decisions independently. After masking the entire SIS-collection, the remaining feature values no longer provide enough evidence for the same decision. This method ensures interpretability and completeness by considering missing data imputation techniques. In this work, mean imputation is favored over sampling-based imputation for missing data, as it is computationally efficient and deterministic. The baseline input value z is crucial for feature attribution methods and should not significantly impact decisions. The text discusses the use of mean imputation for missing data and the challenges of identifying sets of features that satisfy certain objectives in a complex function. The algorithm for identifying these sets is detailed, emphasizing a straightforward backward selection strategy applied on an example-by-example basis. The algorithm details a procedure to identify disjoint SIS subsets that satisfy certain criteria for an input x in a straightforward manner. It involves finding a SIS subset, masking it out, and repeating the process until the decision of interest is no longer supported by the remaining feature values. The BackSelect procedure identifies the feature that minimally reduces the output when masked, by running each possibility through the model. The BackSelect algorithm aims to identify disjoint SIS subsets by gradually masking out the least important features to reveal the core input pattern. It selects features just large enough to meet the sufficiency criterion and considers interactions between features to ensure sufficiency. This approach queries predictions over the joint set of remaining features, making it better suited for maintaining sufficiency as the set shrinks. The BackSelect algorithm identifies disjoint SIS subsets by gradually masking out the least important features. It ensures sufficiency by considering interactions between features and queries predictions over the remaining features. The algorithm requires Opp 2 kq evaluations of f to identify k SIS, but parallelization can achieve Oppkq. The output of SIS collection, S 1 , . . . , S K, must be disjoint to maintain computational tractability. Each SIS produced satisfies an approximate notion of minimality, and terminating backward elimination too early may lead to local minima in f. The BackSelect algorithm identifies disjoint SIS subsets by gradually masking out the least important features. Proposition 1 states that no additional feature can be masked while retaining sufficiency. Proposition 2 guarantees that masking out all feature values in the SIS collection will lead to a different decision by the model. This approach may not output any SIS for easily reached decisions, where the decision is reached even for the average input. The BackSelect algorithm identifies disjoint SIS subsets by gradually masking out the least important features. Proposition 2 guarantees that masking out all feature values in the SIS collection will lead to a different decision by the model. Various practical decision functions are presented for which algorithms produce desirable explanations. Examples include functions in generalized linear form, resembling logical OR & AND gates, and seeking out a particular input pattern. Features ignored by the function are always masked in the backward selection process. The BackSelect algorithm identifies disjoint SIS subsets by gradually masking out the least important features. Features ignored by the function are always masked in the backward selection process. SIS subsets must satisfy specific criteria, with each individual feature having a corresponding SIS consisting only of itself. The BackSelect algorithm identifies disjoint SIS subsets by gradually masking out the least important features. SIScollection returns sets based on specific criteria for strong feature interactions or value patterns. It is applied to analyze neural networks for text and image data, compared with alternative subset-selection methods. The BackSelect algorithm determines the ordering of elements for constructing the SIS, shaded based on feature importance. Different methods like Suff. IG, Suff. LIME, and Suff. Perturb compute the ordering based on feature attribution values. The rationale subset S is assembled using FindSIS and guaranteed to satisfy a certain condition. In IG, LIME, and Perturb methods, the same ordering is used for length-constrained rationales. The LSTM networks are trained on beer reviews to predict user ratings for aspects like aroma, appearance, and palate. SIS are identified for each aspect, capturing sentiment towards that specific aspect. Alternative methods for producing rationales often fail to meet sufficiency criteria when length constrained. Alternative methods for producing rationales often fail to meet sufficiency criteria when length constrained, leading to significantly reduced outputs compared to SIS subsets. Benchmarking interpretability methods is challenging due to counterintuitive model behavior, where seemingly unreasonable explanations may actually be faithful descriptions of the decision-making process. Human annotator-selected sentences are treated as alternative rationales for LSTM predictions. The LSTM model often makes decisions based on different text subsets than those selected by humans for explanation. The Quality of Human-Selected Sentences (QHS) varies widely in annotated reviews, indicating that human rationales may not always contain enough information for the model's decisions. The Selective Influence Sampling (SIS) method aligns more with high QHS scores in reviews. Additionally, a 10-way CNN classifier is studied using a probability threshold of 0.7 for decision-making. The SIS-collection is extracted from test set examples using a probability threshold of 0.7 for decision-making. It helps understand misclassifications and input patterns that justify decisions, enabling a better grasp of the model's operating principles. Clustering SIS via DBSCAN reveals different input patterns for the same decision across data examples. The algorithm requires specifying pairwise distances between points. Clustering SIS via DBSCAN reveals isolated phrases associated with positive aromas and distinct feature patterns learned by the CNN to distinguish digits. The SIS clustering method distinguishes patterns in images to classify digits and compare model behaviors. Different models show varying decision-making processes based on extracted evidence. The results of clustering SIS from beer reviews with positive aroma predictions are presented in a table. The CNN and LSTM models are used to cluster SIS extracted from beer reviews with positive aroma predictions. The LSTM identifies complex multi-word interactions relevant to aroma values, while the CNN learns localized word patterns. The methodology for interpreting black-box decisions is easy to understand, applicable to all ML models, and remains faithful to the underlying model. Clustering SIS patterns from multiple data points provides insights. Clustering SIS patterns from multiple data points can reveal insights about a model's decision-making process and operating differences among models of comparable accuracy. It can uncover susceptibility to spurious training data correlations and generalization to counterfactual inputs outside the data distribution. The curr_chunk discusses various machine learning methods for identifying important features and rationalizing neural predictions. It includes references to different algorithms and attribution methods like integrated gradients and LIME. The curr_chunk discusses how LIME assigns weights to input features and perturbative approaches compute changes in prediction when features are masked. It also explains how integrated gradients method returns attribution scores for word embeddings and computes a single score using the L1 norm. The curr_chunk discusses using integrated gradients and LIME for analyzing the beer review dataset. Integrated gradients are computed using a mean embedding vector as a baseline, while LIME removes individual words from the input sequence. The ordering R is computed by sorting the y i values. The curr_chunk explores alternative methods for feature selection using integrated gradients and LIME on the BeerAdvocate 2 dataset. The dataset contains normalized ratings for aroma, appearance, and palate, with reviews tokenized and filtered for punctuation. The top 10,000 most common words are used in the vocabulary. The dataset used for the study contains normalized ratings for aroma, appearance, and palate, with reviews tokenized and filtered for punctuation. It includes the top 10,000 most common words and a subset of human-annotated reviews. The study utilizes a recurrent neural network architecture with two stacked LSTMs for sentiment analysis, using the Adam optimizer to minimize mean squared error on the training set. The study uses the Adam optimizer BID6 to minimize mean squared error (MSE) on the training set. Validation is done on a held-out set of 3,000 examples, with the test set consisting of 7,000 examples. The mean-imputation approach for masking input features is compared to a hot-deck approach in Section 3, showing similar prediction changes. FIG0 illustrates the impact of both imputation techniques on prediction after replacing missing inputs with mean embeddings or randomly selected words. The study compares mean-imputation and hot-deck approaches for masking input features in the analysis. Mean-imputation is found to be suitable for masking information, with minimal changes in predicted values. Other options like zero embedding or removing the word entirely led to larger changes in predictions. The study compares mean-imputation and hot-deck approaches for masking input features in the analysis, with mean-imputation found to be suitable for masking information. The marginal importance of features is quantified by perturbing individual features, producing shorter rationales with fewer irrelevant features compared to other methods. Feature Importance is determined by the ranking in Suff. Perturb. Our method is applied to reviews with sentence-level annotations, unseen during training. Thresholds of 0.85 are chosen for aroma prediction rationales. The study compares mean-imputation and hot-deck approaches for masking input features, with mean-imputation found suitable. The study applies a method to analyze predictor output by eliminating features in the BackSelect procedure. The results show that only a small number of critical features are needed for strong predictions, with a rapid decrease in output values as features are removed. The BackSelect procedure removes features that provide negative evidence against the decision. SIS-clustering helps understand differences in concepts important to different neural network architectures. A CNN was trained for sentiment analysis on the aroma aspect. The LSTM learned features diverging from human expectations, suggesting potential overfitting. The CNN model for sentiment analysis on the aroma aspect achieved similar performance to the LSTM model. New embeddings were learned with the CNN, and Adam BID6 was used for optimization. The CNN achieved MSE values of 0.016, 0.025, 0.026, and 0.014 on the Train, Validation, Test, and Annotation sets respectively. The SIS-collection was extracted using the CNN, and predictions were shown in FIG8. In Section 4.1, test examples using the CNN and LSTM models were compared for sentiment analysis on the aroma aspect. SIS extraction was performed on input examples, and predictions were made based on the model-specific embeddings. Clustering of input subsets extracted by both models was also conducted to analyze sentiment towards the aroma aspect. The analysis includes results for aroma, appearance, and palate aspects in beer reviews. Changes in appearance and palate predictions were measured after masking words with imputation methods. Additionally, the length of rationales for palate prediction and the importance of individual features in beer review palate rationales were examined. The MNIST database contains 60k training images and 10k test images of handwritten digits. Images are 28x28 grayscale, normalized between 0 and 1. A convolutional architecture with specific layers and activations is used, achieving 99.7% accuracy on the training set. The final model achieves 99.7% accuracy on the train set and 99.1% accuracy on the test set. The FindSIS algorithm identifies the initial SIS for an example MNIST digit, showing a local minimum in the backward selection phase. The resulting SIS is more interpretable with a smaller cardinality. The SIS in (d) is found after the initial local optimum in (c) and provides a more interpretable input pattern for understanding core motifs influencing the classifier's decisions. To cluster SIS from image data, pairwise distances between subsets are computed using the energy distance BID9 between distributions over pixel coordinates. This method considers distances between similar pixel coordinates within each SIS subset. The energy distance is used to compute distances between subsets of SIS, ensuring efficient computation. A threshold of 0.7 is set for SIS to ensure model confidence in class prediction. Sufficient input subsets are identified using SIS, with the number per digit shown in FIG1. The SIS-collection algorithm is applied to MNIST test digits, and clusters of input subsets for each class are depicted. In FIG1, clusters of sufficient input subsets for each class are depicted. An MNIST image of the digit 9 perturbed to 4 using the CW2 attack is shown in FIG5. The perturbation modifies pixels to embed patterns similar to a 4, leading to misclassification. The CW2 attack is known for its strength in adversarial attacks."
}