{
    "title": "HJlrwcP9DB",
    "content": "The short paper discusses the ethical implications of using models trained on the imagenet dataset, specifically focusing on classes related to pornographic and non-consensual content. It raises concerns similar to illegal poaching in ivory carving and blood diamonds in jewelry, aiming to spark a conversation among neural artists. The emergence of tools like BigGAN and GAN-breeder has brought a new wave of generative digital art using deep neural networks. The paper discusses the ethical implications of using models trained on the ImageNet dataset, focusing on pornographic and non-consensual content. It highlights concerns similar to illegal poaching and blood diamonds, aiming to spark a conversation among neural artists. The rapid growth of AI art, exemplified by the sale of a neural network-generated portrait for $432,500, indicates the need to address dark ethical consequences in using such frameworks. The lack of consent in seed images used to train models can lead to unethical implications in neural artwork creation. An example is shown with an image generated using specific instances of children images from problematic seed classes like Bikini and Brassiere. Volunteers critiquing the artwork were unaware of this sinister effect, highlighting the need for ethical considerations in AI art. The problem with the ImageNet dataset lies in the absence of consent during curation, leading to unethical implications in neural artwork creation. Specific instances of problematic seed classes like Bikini and Brassiere were used, resulting in voyeuristic, pornographic, and non-consensual images. This issue highlights the need for ethical considerations in AI art. The 2009 and 2015 papers by Russakovsky et al delve into the dataset curation process, focusing on collecting and cleaning images using algorithms and the Amazon Mechanical Turk platform. However, there was a lack of ethical assessment for images, especially those involving anthropocentric content like undergarment clothing, raising concerns about consent. The papers by Russakovsky et al did not assess if images had explicit consent. Images were categorized into Non-consensual/Voyeuristic, Personal, Verifiably pornographic, and Underage/Children. Some images were incorrectly categorized, showing unethical use of nonconsensual images. The curr_chunk discusses the unethical use of nonconsensual images in the imagenet dataset, particularly targeting women and children. The authors acknowledge the contradiction of using such images while addressing the issue. They have raised concerns with the dataset curators. The authors have raised concerns about the unethical use of nonconsensual images in the imagenet dataset, particularly targeting women and children. They plan to update on the issue if the curators respond. The image described resembles a mix of graffiti and paper mache, with a chaotic and artistic appearance. The top portion shows what looks like red horns branching from a moose-like skull, with a human-like body in a crucifix position. The left side is artistic and rich in flavor, while the right side is more monotonic but textured. The neural art image described in the curr_chunk is visually confusing, with a mix of abstract and detailed elements that evoke thoughts of Picasso and Frieda Callo. Respondents mentioned seeing a bee, colorful flowers, and nightmarish masks hidden within the image."
}