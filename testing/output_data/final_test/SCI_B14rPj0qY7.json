{
    "title": "B14rPj0qY7",
    "content": "Current end-to-end deep learning driving models face challenges with generalization in unobserved environments and lack of accident explanation ability. A new driving model was proposed, incorporating perception and driving modules trained with multi-task knowledge. Segmentation and depth maps were used for easier perception tasks before generating control commands for difficult driving tasks, with experiments showing effectiveness. The new driving model incorporating multi-task perception knowledge showed improved generalization and accident explanation ability, surpassing current benchmarks in navigation tasks in untrained cities during CoRL tests. Observing progressive improvement in pattern recognition with end-to-end deep learning methods, self-driving researchers aim to revolutionize the autonomous car field. Impressive results have been achieved by mapping camera images directly to driving commands with a simple structure. Further research aims to enhance the performance of deep learning based autonomous driving systems, addressing issues such as poor generalization in unobserved driving environments. The current approach to autonomous driving lacks generalization ability in unseen environments and struggles to explain accidents. Existing visualization methods only show model attention, not the perception process. A new driving approach is proposed using basic perception knowledge to address these issues. The proposed model consists of two modules: perception module and driving module. The perception module is used for learning easier driving-related perception knowledge, including pixel level understanding of input. It is trained with segmentation map and depth map to learn what & where and how far knowledge. The perception module is trained for pixel level understanding of input, while the driving module is trained with driving dataset. This decomposition of the driving network structure is known as the mediated perception approach BID25. The proposed driving structure and training strategy address generalization and accident explanation problems. Self-driving models are categorized into mediated perception approach BID25 and behavior reflex approach based on the generated knowledge. The Deep-Driving method BID4 converts RGB images to perception indicators for driving controls. Limitations include difficulty in describing unseen scenarios and collecting data. Multi-task learning methods tackle multiple tasks simultaneously, such as object detection and road segmentation. Branched E-Net BID16 infers segmentation and depth maps for driving scenarios. Multi-task learning methods have shown better results by sharing encoders for different perception tasks. Behavior reflex approach, like NVIDIA's end-to-end learning, maps input images directly to driving controls. Some models use LSTM for memory storage. However, testing in various driving scenarios makes it hard to determine the model's impact on driving behavior. Public urban driving simulator tests have shown success in handling ambiguous situations. In a public urban driving simulator test, the BID22 model successfully addressed the ambiguous action problem, where optimal driving actions cannot be inferred from perceptual input alone. The CoRL test allowed for a fair comparison using the same driving dataset, revealing limitations in generalization ability when testing in different towns. While saliency-map based visualization methods like BID2 and BID20 help understand the influence of input on driving control, it remains challenging to pinpoint which module of the model fails during driving problems. Visualizing inferences enables the driving system to provide quantitative explanations when accidents occur. The proposed model includes a Multi-task basic knowledge perception module and a Driving decision branch module. The perception module uses depth and segmentation maps to understand the environment and provide qualitative explanations when the model fails. The driving module enables the model to generate driving decisions for different directions based on real-world driving guidance. There are four driving guidance branches corresponding to following lane, turning left, going straight, and turning right. The perception module's output is inputted to the driving module to benefit from multi-knowledge extraction. Convolution layers are used for inferring final driving controls for each direction, maintaining spatial relations and reducing complexity. The perception module utilizes residual blocks to address gradient vanishing and degradation issues, similar to Segnet for image segmentation. It includes two decoders for simultaneous segmentation and depth map inference. The encoder limits total strides to 8 to maintain feature map resolution, and employs Hybrid Dilated Convolution and Groupout to enhance performance. Groupout(Park) is adapted to avoid overfitting in the convolution network, utilizing residual blocks in the driving module. The driving outputs include steering and acceleration/brake, with 4 high-level driving guidances determining the final driving outputs. No additional information such as current speed or steering angle is used as input. The driving module predicts current speed based on RGB image input, using the second last layer's output for best generalization. Training data is collected in CARLA simulator for evaluating driving models in CoRL test tasks of increasing difficulty. The main metric for evaluating is the average success rate of finishing tasks in CoRL test, which includes tests in trained and untrained towns with different maps and building textures. Training data includes perception module training with 35,000 pairs of RGB images and driving module training with 455,000 datasets. Data processing methods used before training the model include balancing dataset and data augmentation. In order to improve generalization, dataset balancing and data augmentation techniques were utilized. The dataset was balanced to ensure each mini-batch contains various training weathers and driving situations. For the perception module, balancing was done to include all weather conditions and driving scenarios. For the driving module, training mini-batches were balanced to include different driving direction guidance and specific steer, brake, and noise situations. Various techniques like adding noise, dropout, and normalization were also applied. To enhance generalization, dataset balancing and augmentation techniques were used. The dataset was balanced to include diverse weather and driving scenarios in each mini-batch. Techniques like adding noise, dropout, and normalization were applied to both perception and driving modules. The system was trained using a step-wise method, starting with training the perception module with multi-task knowledge, then freezing its weights and training the driving module with driving data. Mini-batch size was 24 for perception training, with a ratio of 1.5:1 for segmentation and depth loss. Adam optimizer with a learning rate of 0.001, L2 weight decay, and early stopping were used. MSE loss and Adam optimizer were used for training the driving module. The driving module was trained using MSE loss and Adam optimizer with a learning rate of 0.002 and exponential decay of 0.9. Regularization techniques like early stopping and L2 decay were employed. Results showed higher success rate in untrained town environments, indicating better generalization ability compared to other methods. The same driving dataset was used for training as shown in the results table. The driving model demonstrated better generalization ability in untrained town environments compared to other methods. The model was able to perceive a passing car on the left side based on inferred segmentation and depth maps. The origin of this better generalization ability is being investigated, with two possible reasons being considered. The driving model's superior generalization ability in unseen towns is attributed to the use of basic knowledge and network structure. Experiments comparing two methods show that utilizing basic perception knowledge during training leads to better generalization, rather than just focusing on network structure improvements. The driving model's generalization ability in unseen towns is enhanced by utilizing basic knowledge and improving the network structure. By visualizing outputs of segmentation and depth maps from the perception module, the driving module's perception of the current scenario can be understood, allowing for qualitative explanations of driving problems. The failure case in the perception module caused the model to falsely perceive a car in front of it, leading to a wrong judgment. Despite this, the perception module sometimes makes correct judgments, such as in cases of sun ray reflections. Traditional end-to-end learning driving methods lack the ability to provide cause explanations, which is crucial for practical use of deep learning driving models. The driving model's perception in untrained scenarios can be understood through visualization of segmentation and depth maps. Fine-tune method involves using well-trained model weights on a different dataset to improve generalization. In this study, fine-tuning the perception module's encoder weights led to worse results compared to freezing the weights. The driving model performed worse when its weights were fine-tuned with the perception module compared to freezing the perception module's weights. This could be due to the perception module holding the generalization ability, and retraining it with driving data may have compromised this ability. The fine-tuned model lost the benefit of multi-task knowledge, resulting in reduced generalization ability. An experiment visualized the loss surface to provide qualitative insights into this comparison. The weights calculation in projection direction is based on Equation 1, with \u03b1 as the interpolation ratio. The fine-tune method's weights may get stuck in a flat surface, affecting its performance compared to the original proposal method. A new driving system is proposed for better generalization and accident explanation ability. Multiple experiments validate its effectiveness. Our proposed model utilizes multi basic perception knowledge for improved generalization in difficult driving tasks. The model also has self-explanation ability by visualizing predicted segmentation and depth maps to identify driving problems. The generalization ability of driving stems from basic knowledge and weights of the perception module, which should not be altered during training. Our work aims to inspire the use of multi-task perception knowledge for enhanced robot learning performance, with future plans to explore more effective network structures."
}