{
    "title": "H1xXwEB2h4",
    "content": "The study demonstrates that information about a neural network's accuracy can be found in its intermediate layers. A \"meta\" network was trained to predict the correctness of the base network's output, achieving accuracies between 65% - 85% across various tasks and networks. The study shows that a \"meta\" network can predict the correctness of a base neural network's output by analyzing its intermediate layers, achieving accuracies between 65% - 85% across different tasks and networks. The meta network can predict the correctness of a base network's output with up to 69% accuracy for ImageNet images and 85% accuracy for CIFAR 10 images. The accuracy of the meta network is higher for simpler tasks. The usefulness of layers' outputs for predicting network accuracy is highest at the last hidden layer or final output. Meta networks trained on different layers have significant overlap in predicting accuracy, suggesting different information at each level. The approach involves running examples through a pretrained base network, saving intermediate outputs, and training the meta network using these examples. During training, the meta network is trained using examples from the base network's training set. To prevent cheating, classes are balanced and models are chosen based on accuracy and balance on the validation set. The geometric mean of the meta network's accuracy on \"base correct\" and \"base incorrect\" classes is used as a measure. All reported numbers are from a held-out test set. Meta networks are trained and tested on various tasks and base networks to investigate the phenomenon's generality. During testing, meta networks are trained on various tasks and base networks, including AlexNet, ResNet 18, VGG 16, DenseNet 161, and ResNet 152 for ImageNet BID7. For CIFAR 100 BID3, a VGG 16 network is used, and for CIFAR 10, a VGG 19 network is utilized. Meta networks are trained on different layers of these networks to assess accuracy. The base networks for CIFAR 100 and CIFAR 10 achieved accuracies of 71.5% and 91.1% on their test sets. A Bi-Directional Attention Flow (BiDAF) model was tested on a non-vision task using pretrained models from the Stanford Question Answering Dataset (SQuAD). The BiDAF model had an exact match accuracy of 68.03%. The BiDAF model's accuracy numbers for meta networks trained on various models classifying ImageNet images can be found in the appendix. Results show that meta networks trained on final outputs achieve higher accuracies compared to those trained on earlier convolutional layers. The best meta network accuracy for the BiDAF model is achieved when classifying the output of the Modeling layer composed of LSTM units just before the final output layer. The meta networks in a VGG16 network achieve similar accuracies across different layers. However, there is a significant percentage of examples correctly classified by one meta network looking at one layer, but not by another meta network looking at a different layer. This suggests that different layers contain different information about the accuracy of the base network. The meta networks in a VGG16 network achieve similar accuracies across different layers, with overlap in correct predictions. Meta networks can learn about intermediate and final outputs indicative of network accuracy, but their usefulness in improving or interpreting networks is unclear. Estimating neural network accuracy at runtime is challenging, with the highest output value after softmax often used as a confidence measure. Recent work has shown that the outputs of neural networks are not reliable for estimating accuracy. It is questioned whether meta networks trained on these outputs simply classify high values as correct and low values as incorrect, based on the confidence level. Graphical illustrations of ResNet18 outputs on ImageNet show a correlation between accuracy and predicted class values, but it is not straightforward. The meta network's confidence in the output of a Resnet18 network on ImageNet is not completely reliable. The base network tends to be more confident in correct answers than wrong ones, but it can still be very confident in a wrong answer. The meta network's judgment of the network's output is not straightforward, as shown in graphical illustrations. The meta network's confidence in the output of a Resnet18 network on ImageNet is not completely reliable. It does not simply classify based on the network's 'confidence' but accurately marks incorrect high \"confidence\" outputs and correct low \"confidence\" outputs. Further study is needed to understand the features the meta network uses to measure accuracy. Neural networks for classification tasks are typically trained to give an answer without indicating their confidence level. The present work involves training meta networks to judge the accuracy of a base network on specific inputs by analyzing its outputs. This approach may offer new insights into characterizing a network's accuracy at runtime and could be connected to information theoretic studies on neural networks. The meta network evaluates the outputs of the base network, such as those from a Bi-Directional Attention Flow model, to determine if they are correct or incorrect."
}