{
    "title": "rJg2fTNtwr",
    "content": "The exposure bias problem in training auto-regressive neural network language models has been a central issue in natural language generation. Despite efforts to address this problem, research shows that the severity of exposure bias may be less significant than previously thought. The language model (LM) is crucial for natural language generation tasks such as machine translation, dialogue response generation, and image captioning. While maximum likelihood estimation (MLE) has been the standard for LM training, there is a concern in the NLP community about \"exposure bias\" causing performance degradation during test-time generation. This bias refers to the discrepancy between training and generation processes in language models. During generation, language models trained with maximum likelihood estimation are biased towards ground-truth data distribution, leading to errors accumulating in the generated sequence. This exposure bias, also known as \"teacher forcing\", affects tasks like language generation and has attracted significant research attention. To address this issue, methods to avoid teacher forcing have been explored. Many training algorithms have been proposed as alternatives to MLE training to avoid teacher forcing, utilizing techniques from generative adversarial network (GAN) or reinforcement learning (RL). These algorithms are referred to as non-MLE methods or text GANs. Despite research efforts to alleviate exposure bias, its existence or significance is less studied. This work aims to demonstrate the seriousness of exposure bias in language models by examining the \"self-recovery\" ability of popular LM models and developing a quantifiable definition of exposure bias. The study highlights the importance of addressing exposure bias in standard MLE LM training and cautions against relying on non-MLE methods without solid performance gains. Exposure bias is a significant issue in MLE training for language models. The study aims to validate the seriousness of exposure bias by examining the impact of setting the history distribution to the ground-truth data distribution during generation. This approach can potentially improve the model's language generation quality. The study examines exposure bias in MLE training for language models by analyzing the quality of sentence-completion samples generated with different prefixes. Despite expectations, there were no noticeable differences in sample quality between real-data prefixes and model samples. The model was still able to produce relevant and high-quality samples even with shuffled or random prefixes. The study shows that MLE-trained language models can generate high-quality samples even with artificially distorted input, contradicting the notion of exposure bias. This challenges the belief that errors accumulate during the generation process due to mismatch between history and data distribution. The study challenges the belief of exposure bias in MLE-trained language models by quantifying exposure bias independently of the training procedure. The task of auto-regressive language modeling is to learn the probability distribution of the next word in a sentence based on the word history. The training minimizes negative log-likelihood, assuming all sentences are of the same length. The generation distribution of the trained LM is denoted as P M, while the ground-truth data distribution is denoted as P D. The study quantifies exposure bias in MLE-trained language models by comparing the generation distribution (P M) to the data distribution (P D). The approach involves using distance measures between probability distributions on the vocabulary V. In this section, a quantification approach using marginal distributions is proposed to address exposure bias in MLE-trained language models. The approach involves comparing the generation distribution (P M) to the data distribution (P D) by considering the marginal distribution of the random variable at position l + 1. Exposure bias in MLE-trained language models is addressed by comparing the generation distribution (P M) to the data distribution (P D) using marginal distribution of the random variable at position l + 1. Marginal generation deviation (MGD) is defined to measure this discrepancy, with the rate of exposure bias (EB-M) indicating the severity of the problem. Two probability metrics, total variation distance (d TV) and Jensen-Shannon divergence (d JS), are considered for measuring the discrepancy. The discrepancy between generation distribution (P M) and data distribution (P D) is measured using total variation distance (d TV) and Jensen-Shannon divergence (d JS). The study questions if EB-M accurately reflects exposure bias, concluding that it does not due to the mismatch between history distributions growing with length. An example is provided to illustrate this argument, showing that even if EB-M is significantly larger than one, it does not necessarily indicate serious deterioration from exposure bias. Further experiments also suggest that EB-M does not precisely reflect exposure bias. The study questions if EB-M accurately reflects exposure bias, concluding that it does not due to the mismatch between history distributions growing with length. Experiments on non-MLE training methods show that EB-M measurements for different frameworks are almost the same, suggesting a trivial mismatch between history distributions. The study questions if exposure bias accurately reflects the mismatch between history distributions. A more precise definition is needed to distinguish exposure bias from this trivial mismatch. A new approach is proposed to measure the model's conditional generation quality independently of the history distribution. The conditional generation deviation (CGD) with history distribution P H for P M using metric d measures the model's conditional distribution quality. The greedy decoding divergence (d GD ) reflects the model's accuracy during greedy decoding. The rate of exposure bias at history length l with metric d is defined. The focus is on measuring how the error caused by the history part affects the generation part independently. The definition of EB-C is clarified by considering the impact of history on generation. CGD requires inference for ground-truth data distribution PD, with experiments conducted in a synthetic setting using a small-scale LSTM model. To improve upon this approach, the MLE baseline model trained on EMNLP-news is utilized. In a synthetic setting, the MLE baseline model trained on EMNLP-news data is used to improve the approach. Two LSTM LM models with different capacities are trained using samples from the data model. The models are trained for 100 epochs with the Adam optimizer and perplexity results are shown in Appendix F. EB-C is calculated using samples from the models, showing steady results with different metrics. The EB-C metric shows a slow increasing trend as history length increases due to exposure bias. However, the gap between model-generated sequences and desired sequences is not large. In NLG applications with short sequences, exposure bias has minimal influence. Similar results are obtained with a transformer LM. Even with the removal of exposure bias effects, the performance gain for MLE LM training is limited to 3%, or less than 1% for short sequence lengths. Experimenting with corrupted history distributions reveals significant gaps in CGD measurements. The small deviation between the history distribution and the ground truth results in a small gap between CGD(P M |M ) and CGD(P M |D ). In the synthetic setting, exposure bias exists but is less serious than presumed. The LSTM LM is robust, as MLE training is unlikely to generate models with a large EB-C value. The model's behavior is within its \"comfortable zone\" despite mismatch between history distributions. The crafted model is unlikely to be a result of MLE training, indicating more sentences start with W1 = B than W1 = A. RankGAN and CoT show lower EB-C measurements than MLE, as they avoid teacher forcing. The MLE model is used as the pre-trained model for RankGAN, with an oracle NLL of 8.67 and RankGAN's oracle NLL of 8.55. In this section, experiments are designed to estimate EB-C for a transformer LM using real human data. Text GANs alleviate exposure bias, but EB-C is still not less than 1 due to reliance on MLE pre-training. This is the first empirical evidence of text GANs addressing exposure bias. In this section, the focus is on estimating EB-C for a transformer LM using real human data. The approach involves utilizing the Amazon Mechanical Turk platform to address the obstacle of not having access to P D with a given history. The use of the greedy decoding divergence metric simplifies the task by only requiring turkers to provide the most probable next word prediction. Preliminary trials show the difficulty in guessing the next word due to the large vocabulary and lack of familiarity with the context. To overcome this, a simplification is proposed where the model outputs its top-5 next word predictions for turkers to evaluate. The study focuses on estimating exposure bias correction for a transformer LM using real human data. The model is trained on the wiki-103 dataset and uses a 16-layer transformer-xl model. The estimation of CGD(P M |D , l, d) requires a large amount of unseen real data samples. The model's top-5 next word predictions are used for turkers to choose from, simplifying the task. The study collected data to estimate exposure bias correction at different history lengths using real human data. Results show that exposure bias is only a minor issue for maximum likelihood estimation-based language model training. Text GANs may not outperform standard MLE training for RNN LM, as indicated by various studies evaluating NLG performance. Exposure bias may not be a significant issue in MLE training, but direct conclusions cannot be drawn from these results. In this work, the self-recovery ability of MLE-trained LM is identified, casting doubt on the seriousness of exposure bias. Two approaches are explored to quantify exposure bias for LM training: EB-M relies on marginal generation distribution, while EB-C focuses on the model's generation performance. Evaluation of EB-C with real human data shows its effectiveness for a SOTA transformer LM. The study examines exposure bias in MLE-based LM training using AMT Turkers data and a SOTA transformer LM. Results show a minor performance gain when reducing training-testing discrepancy. Synthetic experiments confirm these findings. Despite a mismatch between data and model distribution, exposure bias is deemed a minor issue in LM training. The MLE objective function minimizes the Kullback-Leibler divergence between model sampling distribution and data distribution. The study discusses exposure bias in MLE-based LM training, highlighting that it is a minor issue. The proposed quantification approaches should not be the sole metric for NLG evaluation. While non-MLE training algorithms may offer better generation performance, they are often less stable and harder to tune. In Table 6 and Table 7, experiments are conducted with MLE-trained transformer LM and LSTM-LM models on different data sets. A 6-layer transformer model is trained on German to English data, showing that data prefix does not significantly impact model performance during decoding. The auto-recovery ability of a standard NMT transformer model is highlighted when fed with different types of length-3 history prefixes. The model can still generate reasonable translations even when forced to begin with a wrong prefix. The results show that the model's performance is not significantly impacted by the data prefix during decoding. The model's auto-recovery ability is demonstrated when given various length-3 history prefixes. It can generate reasonable translations even with a wrong prefix, contradicting the \"exposure bias\" hypothesis. The proposed EB-C measurement is based on measuring distances between conditional distributions, with one implementation challenge being estimating the described marginal distributions of W l+1. The study evaluates the EB-M for MLE-trained LSTM LM on EMNLP-news and wikitext-103 datasets. A one-layer LSTM LM with hidden dimension 512 is trained as the MLE baseline. EMNLP-news dataset is used for evaluation with a vocabulary size of 5k and 10k samples in the test set. The model's auto-recovery ability is demonstrated with various length-3 history prefixes, showing reasonable translations even with incorrect prefixes. The EB-C measurement is based on measuring distances between conditional distributions. The study evaluates EB-M for MLE-trained LSTM LM on EMNLP-news and wikitext-103 datasets. A two-layer LSTM LM with hidden dimension 1024 is trained for wikitext-103. Adam optimizer with learning rate 0.001 is used for training without Dropout. EB-M measurements are provided with metric dTV in Appendix E. The measurements become stable. The study evaluates EB-M for MLE-trained LSTM LM on EMNLP-news and wikitext-103 datasets. Measurements show a significant gap in model performance when fed with different data histories. Implementations in PyTorch and CoT are used for analysis. The study evaluates EB-M for MLE-trained LSTM LM on EMNLP-news and wikitext-103 datasets. Measurements show a significant gap in model performance when fed with different data histories. Implementations in PyTorch and CoT are used for analysis. In https://github.com/pclucas14/ GansFallingShort, a mediator model is used with twice the size of the generator. M-step is set to 4, and G-step to 1. For RankGAN, a TensorFlow implementation is used in https://github.com/desire2020/RankGAN. Non-MLE experiments involve tuning the generator model to be the same size as the baseline MLE model. Non-MLE methods are evaluated using the corpus-BLEU metric. Details for the AMT evaluation are provided, including the HIT interface and context pairs for evaluation. The study evaluates EB-M for MLE-trained LSTM LM on EMNLP-news and wikitext-103 datasets. Measurements show a significant gap in model performance when fed with different data histories. In the AMT evaluation, around 10k HITs are collected for each history length configuration, with a limit of 200 HITs per turker. Results show stable EB-C measurements with 100k samples for the LSTM-512 synthetic experiment. EB-M measurements using metric d TV are similar to those using metric d JS. PPL results for models trained on different datasets are provided in Table 5. The PPL for the model on the wiki-103 dataset is 84.58, but it is not directly comparable to state-of-the-art LM results due to specific settings. Only sentences longer than a certain length are kept, and only half of the training data is used. The study also includes samples of a STOA MLE-trained transformer LM on wiki-103 with different history inputs. The economy of the UK is struggling post-Brexit, with a growth rate of 1.6% since the US voted. The actor Harry has been working long hours, addressing nervous times as a teenager. Brady, suffering, has forced 9 out of 12 gun targets to get all guns. Brady's suffering has forced 9 out of 12 gun targets to acquire all guns. The group takes down various players in the future, playing in Paris. Last year, 69% of women avoided help. He has not played for Tottenham's first team this season. The player has not played for Tottenham's first team this season and was picked off three times in a game. The treatment cost $12,000, and there were concerns about black political power. The group reported they were not looking to hurt animals."
}