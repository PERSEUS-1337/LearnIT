{
    "title": "SySisz-CW",
    "content": "Generative models like GANs and VAEs use deep convolutional architectures for data generation and extraction. The weights of successive layers in these architectures adapt to each other following the causality principle of independence of mechanisms. The Spectral Independence Criterion quantifies dependencies between convolutional layers, showing more independence for the generative process. Experiments on generating human faces suggest that greater independence between layers results in better results. Greater independence between layers in generative models leads to improved performance, as seen in experiments generating human faces. Deep generative models like GANs and VAEs have shown success in creating realistic images across various domains. These models involve training an image generator to deceive a discriminator in GANs, and learning mappings between latent variables and data in VAEs. Despite extensive research, there is still a lack of understanding on how to enhance these architectures. An interesting aspect is that both GANs and VAEs consist of two deep subnetworks. Both GANs and VAEs involve two deep subnetworks with mirrored architectures, where information flows in opposite ways. Generators map latent variables to data space causally, while encoders and discriminators extract information anti-causally. Generative models aim to model data distribution, with the potential for capturing causal structure by disentangling data contributions. Learning disentangled representations from data is a key challenge in machine learning. While GANs have shown promise in this area, they often require supervision to disentangle factors of interest. Unsupervised learning of disentangled representations remains an open problem, with various frameworks being explored. The challenge of learning disentangled representations from data has been addressed in various frameworks, such as Restricted Boltzmann Machines, tensor analyzers, and Lie groups. A recent approach, \u03b2-VAE, introduces an adjustable parameter to strengthen data compression in VAEs. The idea is to find subsets of latent variables that relate to different properties of the generated data, with network parameters also considered as factors affecting the data. Different layers in deep generative models should ideally encode different aspects of the data to ensure modularity. The idea of using successive layers as modules to encode different levels of details in deep networks has been explored for building high-resolution generative models. Assessing the independence of properties encoded by weights across the structure of deep networks has not been quantitatively addressed in the literature. The proposal is to quantify the coupling between high-dimensional parameters in a causal framework to determine if the layered architecture disentangles different aspects of the data. The Spectral Independence Criterion (SIC) can be used to investigate the coupling between parameters of successive convolutional layers in linear dynamical systems. SIC violations may indicate deficiencies in the learning algorithm or network architecture. This method shows promise in assessing the independence of properties encoded by weights across deep networks. The Spectral Independence Criterion (SIC) can be used to analyze the coupling between parameters in deep networks. SIC tends to be more satisfied for generative sub-networks than for the anti-causal direction. More independence between layers is linked to better model performance. Quantifying Independence of Mechanisms in deep architecture can aid in designing better generative models. Causal models are described using Structural Equations (SEs) with an asymmetrical expression. The asymmetrical expression in Structural Equations (SEs) indicates robustness and invariance in causal models. Intervening on one variable while keeping another constant demonstrates modularity in the system. This framework captures the expected behavior of a robust causal model. The structural equation framework describes the expected behavior of a robust generative model, allowing interventions on specific parameters while maintaining realistic outputs. It emphasizes the importance of modularity and qualitative consistency in generating human-like variations. The goal is to avoid artifacts or blurriness in the generated images. Causal inference methods address identifying cause from effect using the notion of independence between the mechanism (m) and cause (X). This independence assumption can be quantified in specific applications, allowing for determining the true causal direction. The independence assumption for causal inference may be violated in anti-causal models. Identifying the true causal direction involves satisfying the Independence of Causal Mechanisms (ICM). BID24 formalizes ICM for time series using Fourier analysis, which is applicable to deep neural networks. The Discrete-time Fourier Transform (DTFT) represents sequences as 1-periodic functions of frequency \u03bd. Energy in the Fourier domain is calculated using Parseval's theorem. Fourier transforms can be extended to 2D signals. The Fourier transform can be extended to 2D signals, leading to a 2D function that is 1-periodic. For weakly stationary time series, the Power Spectral Densities (PSDs) of signals can be decomposed in the frequency domain. The Spectral Independence Postulate assumes that the power amplification of a filter at each frequency does not adapt to the input power spectrum. The total output power factorizes into the product of input power and the energy of the filter, leading to the Spectral Independence Criterion (SIC). The Spectral Dependency Ratio (SDR) measures the departure from the SIC assumption, reflecting the correlation between input power spectrum and filter's frequency response. The Spectral Dependency Ratio (SDR) measures the correlation between input power spectrum and filter's frequency response. It reflects the relationship between input and output power across frequencies, with \u03c1 X\u2192Y < 1 indicating anticorrelation. This analysis can be applied to interpret experimental results and investigate modularity in deep convolutional networks. DCGANs utilize convolutional networks to generate realistic images by producing independent features at multiple scales. Activation of pixels in different layers encode specific image features, which are combined to create the final image. This approach assumes independence of features at different scales. The assumption of independence of features at different scales in generative models of naturalistic images is crucial. However, limitations in deep network architecture can lead to violations of this assumption, as seen in Fig. 1 where a single convolution kernel cannot capture a long edge, requiring an identical kernel at an upper layer for precise alignment. Misalignment between kernels can result in different patterns. The SIC framework is suitable for analyzing convolutional layers, with differences in striding and non-linearity between layers. Striding can be modeled as upsampling before convolution, and non-linear activation occurs between successive layers. The non-linear activation between successive layers is simplified by assuming ReLU activations act as a switch controlling information flow in the network. Coactivated convolution kernels in successive layers are assumed to encode the same object, while non-coactivated pairs are considered unrelated. The mathematical expression for applying two successive deconvolutional units to an input tensor involves activation maps and convolution kernels. The spatial properties of the activation map x are determined by the convolution kernel g. The criterion for spectral independence assumes the input activation map z has no spatial structure. The SDR of equation 3 is updated for testing SIC between two filters in successive layers. DCGANs pretrained on CelebA dataset were used with structures including four convolutional layers. VAEs with similar architecture were also experimented with, using different parameters. The study explores wide convolution kernels in GAN and VAE models, with layers enumerated based on information flow direction. An example in FIG2 illustrates convolution kernels between layers, showing anti-correlation in Fourier transforms. The design of strided fractional convolution modulates fast and slow variations in the Fourier domain. The study analyzes the dependency between successive layers using histograms of the SDR for different kernel combinations. Results show a concentration of SDR around 1, indicating independence of convolution kernels. A comparison with GAN discriminator reveals broader SDR distribution, especially for lower-level image features, due to operating in the anticausal direction. The study compares the discriminator in GANs and VAEs, noting that VAEs show sharper differences between generator and encoder due to an inversion of the generative model. This leads to small SDR values in the anticausal direction. The study compares the discriminator in GANs and VAEs, noting that VAEs show sharper differences between generator and encoder, leading to small SDR values in the anticausal direction. The training of the VAE did not yield values as satisfactory as the GAN, suggesting a suboptimal performance of the generator. The study compared the discriminator in GANs and VAEs, noting that VAEs exhibit sharper differences between generator and encoder, resulting in small SDR values in the anticausal direction. The training of VAE did not achieve satisfactory values compared to GAN, indicating suboptimal generator performance. The analysis delves into the correlation differences between the Fourier transform of kernels in the networks, highlighting distinct tails in histograms of generative and discriminative networks. Removing filters in the third layer of the generator based on average SDR magnitude revealed qualitative differences in correlation signs. After analyzing the correlation differences between filters in the generator network, it was found that filters with large positive or negative correlations do not have the same impact. Removing certain filters in the third layer helped correct checkerboard artifacts caused by fractional strided convolution mechanisms. The removal of certain kernels in the generator network does not significantly impact image quality, but removing positively correlated filters results in a loss of color information. Positive correlation between filters in the third and fourth layers helps encode color structure, especially for uniform color patches like hair and skin. To reduce dependency between GAN layers, dropout BID25 was considered. Dropout was introduced to prevent neurons from over-adapting and regularize the network, but it actually increased dependencies between layers, leading to deteriorated performance. The expressivity of the network is limited by dropout, resulting in more redundancy in filters and increased dependencies. Different versions of VAEs were trained by adjusting parameters to assess the relationship between SIC values and generative model performance. Adjusting the \u03b2 factor in the VAE objective can significantly impact the variety of faces generated by the network. Lowering \u03b2 leads to a broader range of hair styles, face shapes, and background colors. This improvement is reflected in the SDR statistics, showing more concentrated values for better-performing networks. Comparing SDR distributions between different models confirms these observations. The SDR values of the worst and best performing models are shown in FIG8, with the worst model having more concentrated values at the finest level. Despite this, a closer look at the generated pictures in FIG6 reveals that the best model is not perfect and contains more pixelation artifacts than the worst model. These results suggest that SDR statistics can help guide improvements in VAE training and architecture, indicating which modules need enhancement. The study also derived a measure of independence between weights learned by convolutional layers in deep networks, highlighting the potential for using SDR as a diagnostic tool for parameter selection and model improvement. The study suggests that generative models with more independence between layers perform better, and enforcing independence during training can improve model performance. The results also indicate that modifying certain layers can enhance model performance, and independence between layers may help build adaptable architectures for various purposes. Our approach offers a quantitative measure of network performance that does not require extensive sampling from generative or real datasets, only using the model parameters. This contrasts with state-of-the-art methods like Fr\u00e9chet Inception Distance (FID) and is easily applicable to neural networks with convolutional layers."
}