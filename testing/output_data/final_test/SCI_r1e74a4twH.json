{
    "title": "r1e74a4twH",
    "content": "Learning disentangled representations of data is a key focus in unsupervised learning and generative modeling. A hierarchical model and training method called CZ-GEM are introduced to address observations generated from a conditional distribution of a known control variate and latent noise variate. CZ-GEM ensures disentanglement of control and noise variables without compromising sample quality, applicable in both supervised and unsupervised settings. In unsupervised learning, the concept of extracting low-dimensional, interpretable representations of complex data is crucial. This involves focusing on key attributes while ignoring irrelevant details, similar to how a hunter-gatherer in the past only needed to identify the type, velocity, and location of a charging animal. This approach allows for a simplified understanding of the world's complexity. In unsupervised learning, extracting low-dimensional, interpretable representations of complex data is essential. This involves developing generative models to approximate the data and extract its underlying representation. Simply learning a representation is not sufficient as it must be interpretable and disentangled for effective manipulation of attributes. In unsupervised learning, generative models aim to extract interpretable and disentangled representations of data. Various approaches like GANs and VAEs have been explored to achieve this goal, with a focus on controlling specific attributes while keeping others unchanged. The ultimate aim is to develop an unsupervised generative model that can accurately approximate data and produce interpretable representations. In unsupervised learning, generative models like GANs and VAEs aim to extract interpretable representations of data. GANs excel in generating high-quality data, while VAEs are better at learning disentangled representations. Various methods have been proposed to improve data quality and representation disentanglement. In a framework combining VAE and GAN approaches, control variables are disentangled from latent space to generate high-quality data. The model works in supervised and unsupervised settings, aiming to learn a generative model that fulfills specific criteria. The goal is to learn a generative model that produces realistic images matching the true distribution, with disentangled control variables from noise. This setup applies to various scenarios like simulators, 3D reconstructions, and speaker recognition. A graphical model like a conditional GAN may not meet the disentanglement criterion due to potential dependencies between control variables and noise when conditioned on data. To address potential dependencies between control variables and noise in a generative model, a new framework called CZ-GEM is proposed. By splitting the generative process into two stages and carefully conditioning on variables, the model can generate high-quality images while disentangling control variables and noise. This approach is demonstrated in Figure 2. The CZ-GEM model generates high-quality images by disentangling control variables and noise, demonstrated in Figure 2. In the unsupervised setting, (C \u2192 Y) can be achieved by \u03b2-VAE, a regularized version of VAE. Implementation details for both supervised and unsupervised versions are provided in Section 3. The CZ-GEM model uses pose and identity variables to generate high-quality images. It first learns the pose relationship between variables, then adds identity details to create a clear image. The model combines interpretability with GANs for superior image generation compared to VAEs. It can easily be combined with \u03b2-VAE for discovering disentangled representations. Generative adversarial networks (GAN) are the current state of the art in likelihood-free generative modeling, using a generator network to produce samples that fool a discriminator network. Tricks and techniques are employed to solve the min-max optimization problem, with architectural constraints from DC-GAN ensuring training stability and image quality. Conditional GANs (CGAN) adapt the framework for generating class conditional samples. Conditional GANs (CGAN) use class labels to generate fake samples, with a discriminator trained to distinguish between real and fake conditional samples. A novel information theoretic perspective on CGANs shows that they maximize mutual information between observations and labels while minimizing an upper-bound. Training involves approximating the log-ratio of true and generated data densities, aiming to minimize generative mutual information. Variational autoencoders (VAE) are deep generative models that learn the conditional distribution p(x|z) using encoder and decoder networks trained with amortized variational inference. They are used in representation learning tasks and have been extensively studied recently. Recently, Higgins et al. (2017) introduced the \u03b2-VAE model, which encourages disentangled representations by regularizing the variational posterior approximation. Batch-Normalization (BN) is crucial for GAN training stability, but Instance Normalization (IN) has shown promise as well. Instance Normalization (IN) and its variant Adaptive Instance Normalization (AdaIN) are useful for image generation and stylization. AdaIN modifies normalization based on an additional variable z, typically style in style transfer. The final transformation by AdaIN involves learned functions of z parameterized by a neural network. The implementation and training of CZ-GEM components, subgraph C \u2192 Y and conditional generative models (Y, Z) \u2192 X, are detailed in practice. Figure 3 illustrates the proposed framework. The proposed framework involves learning the subgraph C \u2192 Y using a deep transposed-convolution based decoder network. This network is trained independently to discover generative control factors. The use of \u03b2-VAE may compromise on generative quality, but a GAN likelihood-free approach in the second stage improves the final image quality. The framework involves using a VAE with a narrow information bottleneck to discover C in an unsupervised manner without compromising on image quality. A conditional GAN model is used to preserve the correspondence between Y and X, with the conditioning variable being an image of the same type and dimensionality as the observation. Incorporating Z in the network at higher layers helps avoid entanglement with Y and adds high-level details to the intermediate representation. However, directly adding Z to the input can cause issues with BatchNorm statistics, leading to the generator ignoring the added noise. Adaptive InstanceNorm is a solution to the issue of the generator ignoring externally added noise like Z. It replaces BatchNorm in the generator and incorporates Z in the normalization process. Parameterized as a feed-forward network, \u03b3(z) and \u03b2(z) are applied to each layer of AdaIN. Disentangled representation learning has been studied in supervised and unsupervised settings, emphasizing inductive biases and weak supervision. Locatello et al. (2018) emphasized using inductive biases and weak supervision for disentangled representation learning. Nguyen-Phuoc et al. (2019) and Sitzmann et al. (2019) showed that including an explicit 3D representation improves performance. CZ-GEM is simpler and smaller, applicable in settings with control and noise variables, for both supervised and unsupervised learning without relying on 3D transformations. Manual disentangled generative models like the 3D morphable model (Blanz & Vetter, 1999) are powerful but have limitations in bridging the gap between synthetic and real-world face images. We use a 3D morphable model to generate synthetic face datasets and disentangle pose variation from real 2D images. CZ-GEM can separate C from Z in supervised and unsupervised settings, maintaining disentanglement of C components. It can also discover latent factors without explicit C input, evaluated on various image generation tasks. We generate 3D image datasets of faces, chairs, and cars with control variables. Chairs and cars datasets are from ShapeNet, while faces are from the Basel Face Model 2017. The datasets include shape, color, expressions, pose, and illumination variations. For the faces dataset generation, publicly available software is used, including unsupervised results on celebA. The DCGAN architecture is utilized for all neural networks in the experiments, with a reference implementation provided. CZ-GEM is compared to CGAN in the supervised setting, focusing on disentangling components C and Z, and evaluating sample quality. The study compares CZ-GEM and CGAN in preserving label information while ensuring disentanglement between pose variables and variations. CZ-GEM allows for control variates without changing object identity, unlike CGAN. Noise Z in CGAN has little control over chair identity. The noise Z in CGAN provides little control over chair identity due to internal stochasticity from BatchNorm. CZ-GEM preserves pose information while averaging identity details. It accurately captures pose factors and principal shape components in faces dataset. CZ-GEM maintains identity better than CGAN and maintains generative quality evaluated by Inception score on three datasets. CZ-GEM outperforms InfoGAN in unsupervised discovery of disentangled components of C using \u03b2-VAE with narrow bottleneck. Latent traversals for faces dataset show recovery of rotation and translation variations. CZ-GEM excels in both disentanglement and generative quality compared to InfoGAN. In the CelebA dataset, a method is tested for learning representations in deep generative models where observation is controlled by C and Z variables. The method ensures disentanglement of C and Z without compromising sample quality. Future work aims to apply this method to input with multiple objects. Additional evaluation measures are reported beyond the MSE-based estimator. The method ensures disentanglement of control variables C and Z in deep generative models without compromising sample quality. Results on face and chair datasets show CZ-GEM outperforms CGAN in preserving shape variations and identity changes. Additional evaluation measures are reported, including Pearson correlation coefficient. In unsupervised settings, CZ-GEM can disentangle chair rotations without labels, as shown in Figure 12. Latent traversal results in Figure 13 also demonstrate this ability, although translations are not entirely smooth."
}