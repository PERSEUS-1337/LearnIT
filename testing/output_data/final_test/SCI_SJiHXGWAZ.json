{
    "title": "SJiHXGWAZ",
    "content": "Spatiotemporal forecasting, such as traffic forecasting, is challenging due to complex spatial and temporal dynamics. To address this, a Diffusion Convolutional Recurrent Neural Network (DCRNN) is proposed, which models traffic flow as a diffusion process on a directed graph. DCRNN captures spatial dependency using bidirectional random walks and temporal dependency using an encoder-decoder architecture. Evaluation on real-world datasets shows a consistent improvement of 12% - 15%. In this paper, the focus is on traffic forecasting on road networks, a crucial task for intelligent transportation systems. The goal is to predict future traffic speeds based on historical data and road network information. The task is challenging due to complex spatiotemporal dependencies and long-term forecasting difficulties. Traffic time series exhibit strong temporal dynamics, making it challenging to predict nonstationary events like rush hours or accidents. Traffic forecasting on road networks is challenging due to nonstationarity caused by incidents like rush hours or accidents. Sensors on the road network show unique spatial correlations, with downstream traffic influencing future traffic speed more than upstream traffic. Traffic forecasting falls into two main categories: knowledge-driven and data-driven approaches. Knowledge-driven methods use queuing theory, while data-driven methods like ARIMA and Kalman models are used in the time series community. In this work, the authors propose a new approach for traffic forecasting by representing spatial correlations between traffic sensors using a directed graph. They model traffic flow dynamics as a diffusion process and introduce the diffusion convolution operation to capture spatial information. This method aims to address the limitations of existing models that do not consider the spatial structure in traffic forecasting. The Diffusion Convolutional Recurrent Neural Network (DCRNN) integrates diffusion convolution, sequence to sequence architecture, and scheduled sampling to improve traffic forecasting. It outperforms existing baselines by capturing spatial and temporal dependencies efficiently on real-world traffic datasets. The proposed approach, DCRNN, improves traffic forecasting by modeling dependency structures using a diffusion convolutional recurrent neural network. It outperforms baseline methods on real-world datasets by predicting future traffic speed based on observed traffic flow from correlated sensors on a road network represented as a weighted directed graph. The traffic forecasting problem aims to learn a function that maps historical graph signals to future signals on a graph G. The spatial dependency is modeled by relating traffic flow to a diffusion process characterized by a random walk with restart probability \u03b1. The Markov process converges to a stationary distribution representing the likelihood of diffusion from each node v i. The stationary distribution of the diffusion process on a graph can be represented as a weighted combination of infinite random walks, calculated in closed form. A finite K-step truncation is used with trainable weights assigned to each step, including bidirectional diffusion for capturing influence from upstream and downstream traffic. The diffusion convolution operation over a graph signal and filter is defined by parameters \u03b8, resulting in the input X and output H. The diffusion convolutional layer learns representations for graph structured data using filters and activation functions. It can be trained with stochastic gradient methods and is related to spectral graph convolution. Many existing graph convolution operations, like ChebNet, can be seen as special cases of diffusion convolution on undirected graphs. The spectral graph convolution can be defined with eigenvalue decomposition and normalized Laplacian matrices. The Diffusion Convolutional Gated Recurrent Unit (DCGRU) is a model that leverages recurrent neural networks (RNNs) to capture temporal dependencies. It replaces matrix multiplications in GRU with diffusion convolution, allowing for training using backpropagation through time. DCGRU can be used to build recurrent neural network layers and is defined by input and output at time t, reset and update gates, and diffusion convolution operations with corresponding filters. Neural network layers are trained using backpropagation through time. In multiple step ahead forecasting, the Sequence to Sequence architecture BID28 is employed with both encoder and decoder as recurrent neural networks with DCGRU. During training, historical time series are fed into the encoder to initialize the decoder. Ground truth observations are used for predictions during training, while model predictions replace them during testing. Scheduled sampling is integrated into the model to address discrepancies between input distributions during training and testing. DCRNN is a model trained to learn the testing distribution by capturing spatiotemporal dependencies among time series. It can be applied to various forecasting problems, such as traffic forecasting, which has received attention in data-driven approaches. Existing machine learning models for traffic forecasting either impose strong stationary assumptions or fail to capture spatiotemporal dependencies. Deep learning models offer new promise for time series forecasting, with applications in traffic forecasting using deep Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN). Various approaches have been proposed, such as converting road networks to 2-D grids for crowd flow prediction and modeling spatial dependency with DeepTransport. Graph convolutional neural networks (GCN) have also been introduced for forecasting on arbitrary graphs. Graph convolutional networks (GCN) bridge spectral graph theory and deep neural networks. ChebNet improves GCN with fast localized convolution filters. BID19 simplifies ChebNet for state-of-the-art performance in semi-supervised classification. BID26 combines ChebNet with RNN for structured sequence modeling. BID33 models sensor networks as undirected graphs using ChebNet for forecasting. BID1 introduces diffusion-convolutional neural network (DCNN) for graph-structured inputs. BID17 proposes GraphCNN to generalize convolution to graphs by convolving nodes with their nearest neighbors. Our approach differs from existing methods by modeling the sensor network as a weighted directed graph and defining convolution using bidirectional graph random walk. It is integrated with sequence to sequence learning and scheduled sampling to capture long-term temporal dependencies. Experiments are conducted on real-world datasets with traffic speed readings aggregated into 5-minute windows and normalized using Z-Score. Training, testing, and validation data are split into 70%, 20%, and 10% respectively. To construct the sensor graph, pairwise road network distances between sensors are computed to build the adjacency matrix using a thresholded Gaussian kernel. Neural network approaches are implemented using Tensorflow and trained with the Adam optimizer. Hyperparameters are chosen using the Tree-structured Parzen Estimator on the validation dataset. Comparison of forecasting approaches for different time intervals is shown in TAB1 based on MAE, MAPE, and RMSE metrics. In both datasets, RNN-based methods like FC-LSTM and DCRNN outperform other baselines, highlighting the importance of modeling temporal dependency. DCRNN shows the best performance across all metrics and forecasting horizons, indicating the effectiveness of spatiotemporal dependency modeling. Deep neural network methods perform better than linear baselines for long-term forecasting due to the increasing non-linearity of temporal dependency with longer horizons. The historical average method's performance remains consistent with small increases in data. DCRNN outperforms other baselines in both METR-LA and PEMS-BAY datasets, emphasizing the importance of temporal dependency modeling. Spatial dependency is further explored by comparing DCRNN with variants like DCRNN-NoConv and DCRNN-UniConv, showing the impact of diffusion convolution on forecasting accuracy. DCRNN achieves the lowest validation error due to bidirectional random walk, capturing influence from upstream and downstream traffic. GCRNN, a variant using ChebNet graph convolution, is outperformed by DCRNN in the METR-LA dataset, showing directed graphs better capture asymmetric correlations between traffic sensors. The directed graph better captures asymmetric correlations between traffic sensors. Increasing K enables capturing broader spatial dependency but also increases learning complexity. Error on the validation dataset initially decreases and then slightly increases with higher K. Different variants of DCRNN are designed to evaluate temporal modeling effects. DCRNN models are used for time series prediction, with variations like DCRNN-SEQ and DCRNN incorporating different learning frameworks. Visualization of localized filters on the METR-LA dataset shows weights localized around nodes and diffusing along the road network. DCRNN outperforms DCNN in modeling temporal dependency, with DCRNN achieving the best results, especially with increasing forecasting horizons. DCRNN achieves superior results in time series prediction, especially with longer forecasting horizons. The model's ability to handle mistakes during multiple steps ahead prediction reduces error propagation. Visualizations show DCRNN's smooth predictions and accurate detection of abrupt changes in traffic speed compared to baseline methods like FC-LSTM. DCRNN predicts peak hours by capturing spatial dependency and utilizing speed changes in neighborhood sensors for accurate forecasting. The model uses bidirectional graph random walk for spatial dependency and recurrent neural network for temporal dynamics in traffic prediction on road networks. Visualizations demonstrate well-localized weights around nodes and diffusion based on road network distance. Our approach integrates spatial dependency, recurrent neural networks, encoder-decoder architecture, and scheduled sampling for improved long-term forecasting. It outperformed baselines on real-world traffic datasets. Future work includes applying the model to other spatial-temporal forecasting tasks and modeling spatiotemporal dependency in evolving graph structures. Funding for this research was provided by NSF grants and USC research centers. The authors' views expressed in the material do not necessarily reflect the sponsors' views. They thank individuals for helpful discussions. The diffusion convolutional layer output and time complexities of equations are discussed. Spectral sparsification may be used for dense graphs. The spectral graph convolution utilizes normalized graph Laplacian and ChebNet parametrizes f \u03b8 as a K order polynomial of \u039b. ST-KNN for traffic forecasting has drawbacks in independent forecasting for each road. ST-KNN has limitations in utilizing neighbor information, modeling roads separately, and using hand-designed metrics. DeepTransport and DCRNN offer more systematic spatial dependency modeling, with DCRNN deriving from random walk properties and showing ChebNet as a special case. The proposed approach is related to graph embedding techniques like Deepwalk and node2vec, learning low dimension representations for each node in the graph. DCRNN also learns node representations capturing spatial and temporal dependencies optimized for future traffic speeds. HA Historical Average models traffic flow as a seasonal process, using weighted averages of previous seasons for prediction. Performance is invariant to small increases in forecasting horizon. The forecasting models used include ARIMA kal, VAR BID16, SVR, FNN, and FC-LSTM. ARIMA kal has orders (3, 0, 1) and uses the statsmodel python package. VAR BID16 has 3 lags and also uses the statsmodel python package. SVR uses a penalty term C = 0.1 and 5 historical observations. FNN has two hidden layers with 256 units each, dropout ratio 0.5, and L2 weight decay 1e \u22122. FC-LSTM is an Encoder-decoder model. The FC-LSTM model uses LSTM with peephole connections in an Encoder-decoder framework. It has two recurrent layers with 256 LSTM units each, L1 weight decay of 2e \u22125, and L2 weight decay of 5e \u22124. The model is trained with batch size 64, MAE loss function, and an initial learning rate of 1e-4. The learning rate reduces to 1 10 every 10 epochs starting from the 20th epoch. Early stopping is based on monitoring the validation error. The DCRNN model is a Diffusion Convolutional Recurrent Neural Network with two recurrent layers of 64 units each. It uses an initial learning rate of 1e \u22122, reduces to 1 10 every 10 epochs starting from the 20th epoch, and employs early stopping on the validation dataset. Scheduled sampling uses a thresholded inverse sigmoid function for probability. The thresholded inverse sigmoid function is used for scheduled sampling in the DCRNN model, with parameters \u03c4 set to 3,000. Experiments are conducted on two large-scale traffic datasets: METR-LA and PEMS-BAY, containing data from sensors in Los Angeles County and the Bay Area, respectively. The experiment conducted from Jan 1st to May 31st 2017 analyzed traffic data with 16,937,179 data points. Data was split into training (70%), testing (20%), and validation (10%) sets. A sensor graph was constructed using pairwise road network distances and a thresholded Gaussian kernel. Sensor correlations were estimated using regularized VAR for forecasting horizons. The experiment analyzed traffic data with 16,937,179 data points from Jan 1st to May 31st 2017. Data was split into training, testing, and validation sets. A sensor graph was constructed using road network distances and a Gaussian kernel. Correlations were estimated using regularized VAR for forecasting horizons, showing localized correlations with larger relevance in closer neighborhoods."
}