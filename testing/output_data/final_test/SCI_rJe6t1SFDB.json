{
    "title": "rJe6t1SFDB",
    "content": "The problem of building a coherent conversational agent with proper discourse and coverage is still an area of open research. Current architectures focus on semantic and contextual information but lack consideration for syntactic and external knowledge essential for generating responses in a chit-chat system. To address this, an end-to-end multi-stream deep learning architecture is proposed, leveraging memory networks for contextual information and Graph Convolution Networks for syntactic information. Transfer learning with a bidirectional transformer is used for semantic representation, and external knowledge is incorporated from a Knowledge Base. Conversational agents, including task-oriented chatbots and chit-chat systems, have seen significant advancements in natural language processing. AMUSED embeddings from a Knowledge Base are used for next sentence prediction and developing a retrieval-based conversational agent. These agents find applications in various domains like self-driving cars and virtual assistants. Chit chat systems can be task-oriented or personal companions, with the former designed for specific needs like restaurant reservations and movie recommendations. They can be generative or retrieval-based, with generative systems generating natural language responses but prone to errors, while retrieval-based systems select the best response from a set of answers for error-free interactions. Chit-chat systems aim to provide error-free responses by selecting the best answer from a set of responses. Recent work has focused on encoding contextual information using memory networks, but there is a need to incorporate syntax for better performance. Our work enhances conversation representations using multiple streams, including Graph Convolution networks. AMUSED is a novel deep learning model that encodes sentences using Bi-LSTM and Syntactic GCN embeddings, incorporates knowledge embeddings, and utilizes triplet loss for training. It employs transformers and memory networks to capture conversation information for better responses. The model performs multi-head attention over query-response pairs, leading to more effective results. The task of building a conversational agent has gained traction in the last decade with various techniques being tried to generate human-like responses. Previous modular systems had complex structures, leading to the need for simpler end-to-end trainable models. Vinyals & Le (2015) proposed a sequence to sequence model for this purpose. Various techniques have been developed to improve the performance of conversational agents, including a dynamic-context generative network and a hierarchical latent variable encoder-decoder model. Reinforcement learning approaches have also been used to generate unique conversational styles. In recent years, retrieval methods have become popular due to the availability of large datasets. Various techniques, such as Sequential Matching Networks and specificity controlled models, have been proposed to improve conversational agents' performance and maintain response diversity. Incorporating external information and common sense knowledge base has also shown to enhance the system. The use of Graph Convolution Networks in conversational agents has shown promising results, with accuracies close to 96% reported in task-oriented and chit chat settings. These networks, in conjunction with seq2seq architecture, help maintain proper discourse by passing context vectors along with input query vectors into the deep learning model. Memory networks have also been successful in Question-Answering tasks, further expanding their use in conversational agents. Graph Convolution Networks (GCN) have been effective in encoding syntactic information from dependency parses of sentences. External Knowledge Bases (KBs) have been utilized to enhance performance in various tasks. Different strategies, such as creating KBs from dialogues and using properties of entities in graphs, have been employed to improve Question-Answering systems. GCN is applied to undirected graphs for node representation. Graph Convolution Networks (GCN) are used to encode syntactic information from dependency parses of sentences. For directed graphs, GCN layers can be stacked to capture multi-hop representations. In a directed graph G = (V, E), edges are defined as tuples (u, v, l(u, v)) with inverse edges and self loops added for information propagation. The representation of a node after the kth layer includes trainable edge-label specific parameters. The curr_chunk discusses the AMUSED model's components - Syntactic, Knowledge, and Memory Modules, aimed at capturing relevant information for learning representations in a chit-chat setting. It also introduces the concept of edgewise gating to alleviate errors in dependency graphs obtained from Stanford CoreNLP. The final GCN embedding for a node after the nth layer is determined by trainable edge-label specific parameters. The dataset consists of conversations with query-response pairs. The context for a query is defined by previous sentences. The training set includes query-response pairs and negative responses. Syntax information from dependency trees is used to enhance NLP tasks in dialog agents. The text discusses the use of Bi-GRU and syntactic GCN in dialog agents to capture local context and long-range dependencies. GCN is used to encode syntactic information obtained from dependency trees. The text discusses the use of GCN Equation 1 to obtain syntactic embeddings in dialog agents. It incorporates three edge labels and concatenates Bi-GRU and GCN representations to form token representation. A sentence representation is obtained through word attention and a Knowledge Module, leading to the final sentence representation passed into the Knowledge Module for further processing. The text describes the use of a pre-trained Transformer model and external Knowledge Bases for next dialogue prediction. Positive and negative samples are generated for training, and a BERT model is used to train a binary classifier. The final sentence representation is obtained from the pre-final layer of the model. The representation obtained from the transformer network with multi-head attention and positional embeddings helps learn sentence dependencies. External information from Knowledge Bases like Wikipedia and Wikidata can be incorporated to enhance conversations. Entities in Knowledge Bases (KBs) are linked using relations, allowing for knowledge expansion through multiple hops in the Knowledge Graph (KG). In AMUSED, entity linking information from Wikipedia is used to expand knowledge. By considering one-hop direct neighbors of an entity, a KB-expanded embedding of the input sentence is obtained by averaging GloVE embeddings of linked entities. Future work may explore using larger knowledge bases like Wikidata and relation information for improved embeddings. Effective conversations require understanding from past dialogues. In AMUSED, a memory network is used to capture dialogue context by storing history of questions and responses. The memory network generates the final query representation using supporting memories containing input and output memory cells. The memory cells are populated with BERT representations of context sentences. The memory network in AMUSED captures dialogue context by using input and output memory cells to compute relevance of context stories. Memory cells are stacked in layers called hops to capture context iteratively. Triplet loss is used for face recognition, as traditional loss metrics may not be suitable for a retrieval-based task with multiple valid responses. The Conversational Euclidean Space is defined to represent sentences based on dialogue context, syntactic, and semantic information. Triplet loss is used to bring query and response representations closer in this space. The loss function aims to separate negative and positive pairs in a set of triplets, consisting of a query, correct response, and a randomly selected negative response. This approach is applied in building and evaluating a chit-chat system using the Persona-Chat dataset. The Persona-Chat dataset consists of personal conversations between two humans, providing natural dialogue for training conversational systems like AMUSED. It includes 131,438 query-response pairs with a vocabulary size of 19,262. Additionally, the DSTC dataset focuses on task-oriented conversations for restaurant booking, utilizing memory and syntactic modules for training. Before training AMUSED, the knowledge module is pre-trained using a bidirectional transformer network and extracting entities from Wikipedia KB. The approach involves fine-tuning parts of the network with Multi-Genre Natural Language Inference and Microsoft Research Paraphrase Corpus datasets. Training involves 104224 positive query-response pairs from Persona Chat, with operations like equal sampling and oversampling for negative examples. The training of AMUSED involves oversampling and undersampling to bias the training set, using MRPC and MNLI datasets for fine-tuning. Triplets are trained with triplet loss, with a total of 131438 triplets split for training and validation. The network is trained with specific parameters and stops training based on validation loss. The system uses Adam optimizer with a 0.001 learning rate for a retrieval based model. It selects a response from a predefined answer set by comparing query embedding with potential responses based on cosine similarity. The model, trained with oversampling, outperforms others by over 3% in accuracy, showing the importance of distinguishing negative examples well. The sentence embeddings obtained through the model are used for lookup in the Knowledge Module in AMUSED. Different automated metrics are used to evaluate the model and query-response representations. The performance of various components of AMUSED is analyzed for the next dialogue prediction task, where embeddings for queries and responses are processed before being passed to a binary classifier for determining the validity of a response. The study evaluates the performance of different components in a 4-layer neural network for binary classification. Ablation studies are conducted using various modules to understand their effects. The best accuracy is achieved when external knowledge, memory, and GCN modules are combined. Precision@1 metric is used to measure the effectiveness of the network, showing the number of times a relevant response is reported with the highest confidence value. The study evaluates the performance of different components in a 4-layer neural network for binary classification, achieving the best accuracy when combining external knowledge, memory, and GCN modules. Table 2 presents a comparative study of the metric on 500 trials for AMUSED, along with results for other methods. DSTC dataset is evaluated on this metric without the knowledge module. Next sentence prediction task accuracy is used to select the final model. Human evaluation by expert linguists rates conversation quality on a scale of 1-10 based on coherence and context. The study by Zhang et al. (2018c) evaluates the dialogue system based on coherence, context awareness, and non-monotonicity. They use a retrieval-based network and expert ratings to understand the impact of different modules on human conversation. The proposed multi-stream architecture, AMUSED, effectively encodes semantic information from queries and utilizes external knowledge. Human evaluation aligns with automated metrics, favoring the combined architecture. The study introduces a multi-stream architecture, AMUSED, which effectively encodes semantic information from queries and utilizes external knowledge. It employs GCN for capturing long-range syntactic information and incorporates memory network to improve context-awareness in dialogue. Smart training using triplets enhances the performance of chit-chat systems, as demonstrated through experiments and results using different metrics. The ablation studies highlight the importance of various components for better dialogue, with potential extensions to other conversational tasks."
}