{
    "title": "H1lj0nNFwB",
    "content": "The dynamics of gradient descent bias neural networks towards simple solutions by searching through the solution space in an incremental order of complexity. Incremental learning dynamics are defined and conditions on depth and initialization for this phenomenon in deep linear models are derived. A dynamical depth separation result shows that shallow models require exponentially small initialization for incremental learning, while deeper models can achieve it in more natural settings. Experimental results with deep matrix sensing, quadratic neural networks, and binary classification support the theoretical findings. Neural networks have revolutionized modern machine learning by allowing efficient learning of highly expressive models that generalize well. The success of neural networks in generalization goes beyond traditional statistical learning theory bounds, indicating the importance of properties like optimization algorithms. Gradient-based methods with proper initialization may bias neural networks towards solutions that generalize effectively. Certain solutions generalize through implicit bias, where gradient-based methods search for solutions of increasing complexity in the hypothesis space. Saxe et al. (2013) found that in deep linear networks, singular values converge at different rates, with larger values converging first. Gidel et al. (2019) showed that with infinitesimal initialization, the dynamics exhibit incremental learning. This work extends these results to small finite initialization scales. When initialized with small Gaussian weights and trained with a small learning rate, a model can successfully recover the low-rank matrix labeling the data, even in highly over-determined problems without additional regularization. Li et al. (2017) proved low-rank recovery in such models, showing they remain low-rank throughout optimization for successful generalization. Arora et al. (2019) found that singular values are learned at different rates in deeper models with stronger incremental learning dynamics. The learning dynamics of deep networks, particularly in relation to incremental learning, have been studied extensively. Various studies have shown that deep networks exhibit incremental learning behavior during training, which contributes to their generalization ability. This behavior has been observed in shallow ReLU networks as well as deep ReLU networks, where they correlate with linear classifiers in the early stages of training. These findings suggest that the depth of a network plays a crucial role in determining its learning dynamics. The dynamics of deep networks, particularly in incremental learning, have been extensively studied. Deeper models allow for incremental learning in larger initialization scales. A depth-2 model requires exponentially small initialization for incremental learning, while deeper models only need polynomially small initialization. Results are generalized for larger linear and quadratic models, with examples shown in figure 1. The analysis of incremental learning for a simple model provides a clear understanding of the phenomenon and its conditions. Our simple linear model, similar to the toy model analyzed by Woodworth et al. (2019), introduces depth by parameterizing \u03c3 using non-negative weights. The model is studied for general N under a depth-normalized squared loss over Gaussian inputs to derive an analytical solution. Analyzing a toy model with gradient flow provides an analytical solution for the dynamics of \u03c3(t) and the loss function for general N. The solutions for N = 1, 2, and N \u2192 \u221e are discussed, with a special case adaptation from Saxe et al. (2013) for deep linear networks. Minimizing the toy linear model with gradient flow over depth normalized squared loss leads to analytical solutions for different N values. The gradient flow equations for a toy model provide analytical solutions for different values of N. The solutions show distinct phases of learning for deep and shallow models, explaining the differences in incremental learning rates. In a toy model, depth influences learning rates, with deeper models biased towards learning larger values first. This dynamic can lead to sparse solutions if the model fits the data quickly. The dynamics of a toy model are influenced by depth, with deeper models biased towards learning larger values first, potentially leading to sparse solutions. The study explores incremental learning in models with different depths and initializations, comparing empirical results to a sparse approximation algorithm. The study explores incremental learning in models with different depths and initializations, comparing empirical results to a sparse approximation algorithm. Incremental learning is defined for values initialized within specific ranges, with a focus on dynamical depth separation to facilitate incremental learning. The study examines incremental learning in models with varying depths and initializations, comparing results to a sparse approximation algorithm. Incremental learning depends on depth separation, with a focus on the condition for incremental learning and the impact of initialization scale. The ratio of values determines the feasibility of incremental learning, with exponential dependence on depth, making it challenging to achieve in practice. The study explores incremental learning in models of different depths and initializations, with a focus on the impact of initialization scale. Theorem 3 extends the analysis to gradient descent, providing bounds on the largest initialization value for incremental learning phases. The study delves into incremental learning in models of varying depths and initializations, emphasizing the influence of initialization scale. The analysis extends to gradient descent, revealing bounds on the maximum initialization value for incremental learning phases. The task of matrix sensing, a generalization of matrix completion, is introduced, showcasing the impact of depth on gradient descent dynamics. The study introduces depth in the model by parameterizing it with a product of matrices and a specific initialization scheme. It relates the deep matrix sensing model to a toy model, showing they have the same dynamical equations. Optimizing the deep matrix sensing model with gradient flow over a depth-normalized squared loss leads to specific dynamical equations for different values of N. The proof follows previous work by Saxe et al. (2013) and Gidel. The proof, based on previous work, shows that the bias towards sparse solutions in the toy model is equivalent to bias for low-rank solutions in matrix sensing. Empirical results support the impact of depth on obtaining low-rank solutions. By connecting quadratic networks to matrix sensing, the study extends its results to nonlinear models. The study focuses on a simplified quadratic network with input space X = R d, parameterized by weight matrix W \u2208 R d\u00d7d and quadratic activation function. The final layer is a summation layer, with the labeling function also being quadratic. The model is similar to deep matrix sensing with N = 2 but requires optimizing a different loss function due to the change in input space. The variance loss function is defined for input distribution over X, aiming to minimize error variance. The loss function minimizes variance and the squared loss minimizes the second moment of the error. Both have the same minimum for the problem, and the dynamics of the squared loss can be approximated by the variance loss in certain cases. Minimizing the quadratic network with gradient flow over the variance loss leads to specific dynamical equations related to singular values. Shallow quadratic networks can exhibit incremental learning with a small initialization. Deep linear networks with diagonal weight matrices can exhibit incremental learning in binary classification tasks, favoring sparse solutions throughout optimization. This behavior is attributed to the dynamics of incremental learning, contrasting with previous focus on convergence at t \u2192 \u221e. The optimization dynamics of deep linear networks with diagonal weight matrices in binary classification tasks show incremental learning behavior, favoring sparse solutions. This is illustrated using the exponential loss and logistic losses, with gradient flow dynamics leading to incremental learning of weights until the dataset can be separated by the current support. The optimization dynamics of deep linear networks with diagonal weight matrices in binary classification tasks favor sparse solutions. Increasing the current support reduces loss and subsequent gradients, leading to convergence to a sparse solution. Deeper networks exhibit a stronger bias for sparsity, with initialization scale playing a role in bias towards sparsity. Gunasekar et al. (2018) show equivalence between diagonal and circular-convolutional networks in the frequency domain, indicating a sparsity bias in convolutional networks as well. The optimization dynamics of deep linear networks with diagonal weight matrices favor sparse solutions, with deeper models showing a stronger bias towards sparsity. This phenomenon exists across various models including diagonal networks, convolutional networks, and matrix completion. The dynamical analysis may provide insights into the generalization of deeper nonlinear neural networks. The optimization dynamics of deep linear networks favor sparse solutions, with deeper models showing a stronger bias towards sparsity. This phenomenon extends to various models, including diagonal networks, convolutional networks, and matrix completion. The analysis may offer insights into the generalization of deeper nonlinear neural networks, with shallow quadratic networks being just a starting point. The strategy involves defining a time t \u03b1 for reaching a fraction \u03b1 of the optimal value and ensuring incremental learning conditions are met. After optimizing deep linear networks for sparsity, the next step involves splitting the integral to establish a threshold condition on \u03c3 0 for incremental learning. By relaxing/restricting the condition, lower and upper bounds on the threshold value of \u03c3 0 can be determined. Adjusting the left-hand side of the integral can provide a sufficient condition on \u03c3 0, leading to a stricter condition by modifying the integrals. Integration bounds offer constraints on \u03c3, allowing for the replacement of terms to simplify the equation. After optimizing deep linear networks for sparsity, the next step involves establishing a threshold condition on \u03c3 0 for incremental learning. By solving integrals for different cases and rearranging equations, lower and upper bounds on \u03c3 th 0 can be determined. Integration bounds offer constraints on \u03c3, allowing for the replacement of terms to simplify the equation. The necessary and sufficient condition on \u03c3 0 for (s, f)-incremental learning is derived for different cases, with bounds determined by solving integrals. The dependence on r changes with depth, showing a significant difference between shallow models (N = 2) and deeper ones (N \u2265 3). The largest initialization value for (s, f)-incremental learning phases is bounded by A and B, with proof techniques building on previous work by Gidel et al. (2019). The recurrence relation for \u03c3(t) values is derived for general depth, and a lemma establishes the maximal learning rate considered for analysis. Lemma 1 establishes the maximal learning rate considered for analysis in gradient descent. It shows that overshooting can be avoided by bounding the values of r i, leading to incremental learning results for N = 2. The update rule for N = 2 involves finding bounds on t \u03b1 (\u03c3 i) for incremental learning. By setting \u03b7 = 1, we derive bounds using inequalities and logarithms. These bounds help determine conditions on \u03c3 0 for incremental learning. A sufficient condition for incremental learning is derived by setting an upper bound on t f (\u03c3 i) smaller than the lower bound on t s (\u03c3 j). This condition is rearranged to isolate \u03c3 0. A necessary condition is found by setting a lower bound on t f (\u03c3 i) smaller than the upper bound on t s (\u03c3 j). The necessary condition for incremental learning is derived by setting a lower bound on t f (\u03c3 i) smaller than the upper bound on t s (\u03c3 j). This condition is rearranged to isolate \u03c3 0, illustrating the effect of depth on the dynamics of gradient descent. The proof technique relies on obtaining a non-implicit solution for \u03c3(t) which is harder to generalize to larger values of N. To compare values in the same scales during gradient descent optimization, we focus on the early stages where the ratio dynamics are important. By observing the first iteration of gradient descent and considering the depth effect, we can analyze the initialization of ratios r i and r j. This allows us to compare their dynamics and understand how they evolve during optimization. During gradient descent optimization, the ratio dynamics of ratios r i and r j play a crucial role in determining their evolution. The initial conditions favor r j, but the update for r i is larger, leading to faster convergence. Deeper models result in a larger relative step size for r i, causing it to converge faster than r j. Incremental learning in our toy model is described as an iterative procedure where an additional feature is added at each step. The incremental learning process involves introducing additional features at each step, optimizing the model over the current set of features. This approach is similar to the sparse approximation algorithm orthogonal matching pursuit, where the next feature is greedily chosen to improve the model. The algorithm can be viewed as a continuous-time extension of a greedy iterative algorithm, with the ability to incorporate negative weights. The algorithm can be seen as a sparse approximation pursuit algorithm, aiming to find the sparsest \u03b1 for which D\u03b1 \u2248 x by minimizing the 0 norm of \u03b1 subject to ||D\u03b1 \u2212 x|| 2 2 = 0. A comparison is made between the toy model and OMP in terms of the sets of features chosen for a given example and dictionary. The comparison between the toy model and OMP shows that they choose similar features at the beginning, indicating that the deep model approximates the behavior of OMP. However, as the number of features increases, differences emerge due to initialization scale and learning rate. These experiments highlight the similarity between incremental learning in deep models and the discrete behavior of greedy algorithms like OMP. The dynamics of deep models exhibit incremental learning similar to greedy algorithms like OMP. Minimizing the deep matrix sensing model with gradient flow leads to dynamical equations for different values of N. The dynamics of deep models exhibit incremental learning similar to greedy algorithms like OMP. Equations for different values of N show the gradient flow equations for W n matrices, ensuring they remain diagonal throughout optimization. The differential equations for singular values of W n are derived, with all matrices diagonal at initialization. The dynamics of deep models exhibit incremental learning similar to greedy algorithms like OMP. Analytical results are applicable for population loss over Gaussian inputs, but conditions differ from practical settings. Empirical examination of the deep matrix sensing model in natural settings shows incremental learning even with fewer examples than parameters. The dynamics of deep models exhibit incremental learning, even with fewer examples than parameters. When the dataset is very small, all \"currently active\" singular values change at the beginning of every new phase, suggesting the importance of incremental learning for obtaining optimal solutions. The dynamics of deep models show incremental learning with fewer examples than parameters. Gradient descent finds optimal solutions when phases are distinct, allowing for singular values and vectors to change. Minimizing the quadratic network with gradient flow over variance loss leads to specific dynamical behavior. The dynamics of deep models show incremental learning with fewer examples than parameters. Gradient descent finds optimal solutions when phases are distinct, allowing for singular values and vectors to change. Minimizing the quadratic network with gradient flow over variance loss leads to specific dynamical behavior, where the singular values of matrices remain diagonal throughout the dynamics. The dynamics of deep models show incremental learning with fewer examples than parameters. Gradient descent finds optimal solutions when phases are distinct, allowing for singular values and vectors to change. Minimizing the quadratic network with gradient flow over variance loss leads to specific dynamical behavior, where the singular values of matrices remain diagonal throughout the dynamics. The offdiagonal elements are static, and the dynamics of a single diagonal element are equivalent to the depth-2 toy model. The variance loss function is an approximation of the square loss dynamics, and adding a global bias to the quadratic network leads to similar dynamics for small initialization scales. Differential equations for the singular values of W T W under the variance loss are derived, and similar equations for the squared loss are also derived. The scaled squared loss in expectation over Gaussian inputs is analyzed for a quadratic model's evolution of singular values. Introducing a global bias affects the dynamics, leading to incremental learning and different solutions for small datasets. Adding a bias to a quadratic network leads to incremental learning similar to a depth-2 linear model. The dynamics of the largest values of \u03c3 for different depths show incremental learning exists in deep diagonal networks as well. The incremental learning in deep models results in sparse solutions, influenced by initialization scale. Gunasekar et al. (2018) findings on linear circular-convolutional networks are related, with depth-1 models resembling max-margin SVM solutions. The study by Gunasekar et al. (2018) found that deeper models exhibit a strong correlation with sparse solutions, especially with smaller initialization scales. Incremental learning is evident as depth increases, connecting convolutional networks to diagonal networks. The evolution of weights in the final layer shows a clear pattern of incremental learning. Despite lacking weight sharing and using random Gaussian weights for initialization, the model still exhibits incremental learning. The sparsity observed in Gunasekar et al. (2018) is attributed to the model dynamics, with small amplitudes being attenuated and large ones amplified. Depth-1 models show similarities to max-margin SVM solutions, while deeper models align closely with optimal sparse solutions. Increasing depth showcases clear incremental learning patterns."
}