{
    "title": "SyjjD1WRb",
    "content": "We establish a theoretical link between evolutionary algorithms and variational parameter optimization of probabilistic generative models with binary hidden variables. Two models used for investigation are a noisy-OR Bayes Net and Binary Sparse Coding. Learning of probabilistic generative models involves approximate maximum likelihood optimization using variational expectation maximization (EM). Truncated posteriors with discrete latent states are chosen as variational distributions. Evolutionary algorithms can be used for variational optimization by treating latent states as genomes and defining fitness based on joint probabilities from the generative model. Evolutionary algorithms can be applied to optimize parameters in generative models like noisy-OR Bayes nets and binary sparse coding. These algorithms use mutation and cross-over to efficiently improve data likelihood. They leverage biological processes like mutation and selection for function optimization in Machine Learning tasks. Evolutionary algorithms have been applied to various tasks such as clustering, reinforcement learning, and deep supervised learning. They are often used to solve specific sub-problems, such as selecting the best architectures or hyper-parameters for Deep Neural Networks. Inspired by previous contributions, the question is raised if evolutionary algorithms and learning algorithms can be more closely linked using probabilistic generative models and expectation maximization approaches. Probabilistic generative models and expectation maximization (EM) are used for parameter optimization in various algorithms, from clustering to deep learning approaches. However, EM is computationally intractable for most generative data models, leading to the development of Variational EM as an approximation method. Variational EM aims to solve optimization problems in high-dimensional spaces by utilizing latent states as variational parameters. A variational EM algorithm formulates latent states as variational parameters, resembling genomes of individuals. EAs are a natural choice for optimization in the variational loop of EM. The generative model generates data points y using hidden variables s, with the goal of changing parameters to maximize similarity between generated and real data points. Maximum likelihood parameters are sought to achieve this goal efficiently. The generative model aims to find approximate maximum likelihood parameters efficiently by maximizing a lower bound of the log-likelihood, the free energy F(q,\u0398), using variational distributions q(n)(s) and entropy H(q). This approach is applicable to any generative model with binary latent variables, despite the challenges posed by large state spaces. The variational EM algorithm maximizes the free-energy F(\u039b, \u0398) by iteratively updating parameters \u039b in the E-step and \u0398 in the M-step. Truncated variational distributions are used instead of Gaussian or mean-field distributions for efficiency. The variational EM algorithm maximizes the free-energy by updating parameters in the E-step and M-step. Truncated distributions simplify the free-energy calculation. Populations of hidden states are used as variational parameters for finding the population that maximizes the likelihood for each data point. The variational EM algorithm maximizes the free-energy by updating parameters in the E-step and M-step. Populations of hidden states are used as variational parameters to maximize the likelihood for each data point. The free-energy is increased in the variational E-step by finding individuals with the largest joint probabilities. The variational EM algorithm increases free-energy by updating parameters in the E-step and M-step. A fitness function is chosen for evolutionary optimization, ensuring mutations that increase fitness also increase free-energy. The algorithm monotonously increases free-energy by selecting mutations that improve fitness. The fitness function is defined to be logP, a more efficiently computable and monotonously increasing function of the joint probability. The algorithm seeks to optimize a fitness function, logP, which is a monotonously increasing function of the joints. An offset is applied to ensure positive values. Evolutionary algorithms aim to improve the overall fitness of a population of individuals through genetic operators. The individuals are bit-vectors of length H, and the population sizes remain the same for truncated approximations. The algorithm aims to optimize a fitness function, logP, using genetic operators such as parent selection, single-point crossover, and stochastic mutation. The process involves generating children over N generations, balancing exploitation of high fitness parents with exploration of mutations for population diversity. Diversity is crucial for improving overall population fitness. In genetic algorithm, fitness of population depends on generating high fitness children. Two parent selection strategies are explored: fitness-proportional and random uniform selection. Crossover involves selecting random parent pairs and swapping bits to produce offspring. Mutation involves random bitflips to increase diversity. Comparison is made between random uniform selection of bits to flip. The experiments compare random uniform selection of bits to flip with a sparsity-driven bitflip algorithm in genetic algorithms. The algorithm assigns different probabilities to 0's and 1's for flipping to produce children with sparsity compatible with the model. If crossover is skipped, a different bitflip mutation is performed on identical copies of each parent. The evolutionary algorithm produces children through mutation and crossover steps, updating model parameters until a sufficient increase in fitness is achieved. The EEM Algorithm involves selecting the fittest individuals from the population to form a new population. This algorithm is part of an unsupervised learning algorithm aimed at optimizing log-likelihood. The objective is to increase free-energy and improve model parameters using mutation and crossover steps. The noisy-OR model is a non-linear data model with binary variables and all-to-all connectivity. Binary Sparse Coding (BSC) is a model for continuous data with binary latent variables following a Bernoulli distribution. The latents are combined using a linear superposition rule, and the observables are drawn from a Gaussian distribution. The model parameters include a weight matrix and activation probability for each hidden unit. The M-step update rules for Binary Sparse Coding (BSC) involve optimizing the free energy with respect to all model parameters. Different evolutionary algorithms are tested for applicability and scalability, using artificial data with known ground-truth components. The bars test is used as a standard setup for evaluation. The standard setup for evaluation involves using non-linear superposition of vertical and horizontal bars on pixel images. Different configurations of evolutionary algorithms are tested for Binary Sparse Coding (BSC) using artificial data with known components. The bars test is used to evaluate the performance metrics such as reliability. The study evaluates different evolutionary algorithms for Binary Sparse Coding using artificial data with known components. The \"fitparents-sparseflips\" approach shows advantages over \"randparents-randflips\" on 8x8 images, but this may not hold true for simpler state spaces. The addition of crossover reduces the likelihood of finding all bars and leads to an overestimation of crowdedness. The study evaluates evolutionary algorithms for Binary Sparse Coding using artificial data with known components. A highly non-linear generative model like noisy-OR is used to model occlusion effects in images. Results show that noisy-OR with EEM successfully recovers overlapping bars in images. EEM is also evaluated for the linear BSC model on a bars test, where the problem is easier due to linear superimposition of bars. The study evaluated evolutionary algorithms for Binary Sparse Coding using artificial data with known components. The task was made more challenging by increasing the dimensionality of the data, the number of components, and the average number of bars per data point. Various configurations of the EA were tested with 20 independent runs for each, showing results in Fig. 5. The experiment results in Fig. 5 show that basic approaches like random uniform selection of parents and bitflips work well, but more advanced EAs perform better. Combining bitflips with crossover and selecting parents based on fitness is highly beneficial. However, sparseness-driven bitflips generally lead to poor performance, even with additional strategies like crossover or proportional parent selection. This may be due to the initialization of K n, making it harder for sparseness-driven EAs to explore and find solutions with higher crowdedness. The experiment results in Fig. 5 show that advanced EAs perform better than basic approaches. Natural image patches from the van Hateren database are used, with raw images reflecting light intensities. Brightest pixels are removed, and data points are scaled to gray-scale values. The study utilized a non-linear generative model to analyze binary data points extracted from gray-scale images. The evolutionary algorithm \"fitparents-sparseflips\" was employed with specific parameters. The generative fields learned over 200 iterations showed curved edges resembling expectations. Pre-processed image patches were also considered using common whitening approaches for sparse coding. The study used sparse coding with ZCA whitening on 100,000 image patches to train a model with 300 hidden units and 200 variational states. The generative fields obtained showed Gabor functions with various characteristics. The study applied sparse coding with ZCA whitening on image patches to train a model with hidden units and variational states. The generative fields showed Gabor functions. Generative models training is a well-studied branch of Machine Learning, often requiring approximations like sampling or variational EM. Evolutionary algorithms have been used in conjunction with EM, such as in clustering with Gaussian mixture models. The study combined evolutionary algorithms (EAs) with Expectation-Maximization (EM) for training generative models. Previous approaches used EAs for clustering with Gaussian mixture models, but EAs were used to select the best models while EM updated parameters conventionally. In contrast, the study integrated EAs as an integral part of EM, addressing the key optimization problem in generative model training. The study established a theoretical link between Evolutionary Algorithms (EAs) and Expectation-Maximization (EM) for training generative models. Numerical experiments showed that basic EAs can train models with large hidden spaces and local optima. Specialized EAs tailored for generative model training could further improve accuracy and scalability in the future. The study introduced a novel approach using Evolutionary Algorithms (EAs) to train generative models with binary latents. The method, based on noisy-OR and sparse coding models, provides a mathematically grounded way to apply EAs for generative models. The update rules for the models' parameters are straightforward, with the results reported for completeness. The update equations for weights W dh do not have a closed form solution. Instead, each W new dh is expressed as a function of current W, leading to a fixed-point equation for exact maximization. TV-EM ensures F never decreases, so drops in free energy during training can be attributed to the fixed-point equation. Update rules for BSC can be derived separately for model parameters \u03c0, \u03c3 2, and W. The update rules for BSC can be derived separately for model parameters \u03c0, \u03c3 2, and W. Exact EM can be obtained by setting q n to the exact posterior p( s | y (n) , \u0398), but this becomes computationally intractable with higher latent dimensionality. Truncated variational distributions are used to approximate exact posteriors, with sparsity-driven bitflips involving flipping each bit of a child s * with specific probabilities. The constraints on these probabilities are defined, leading to expressions for p 0 and p 1. Random uniform bitflips correspond to the case where p 0 = p 1 = p bf. Random uniform bitflips correspond to the case where p 0 = p 1 = p bf. Comparisons with other algorithms show that EMM for noisy-OR performs well, but some approaches have higher reliability. Most approaches recovering more than 15 bars require additional assumptions, such as constraints on weights and latent activations. Only MCA 3 does not require constraints, while DI is a neural network approach with difficult-to-infer assumptions. Generative fields learned using EEM for noisy-OR with 200 latent variables, evaluating over 60000 states per data point per iteration. Crowdness \u03c0H was 1.6 after 175 iterations."
}