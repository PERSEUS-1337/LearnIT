{
    "title": "BJgMFxrYPB",
    "content": "The paper proposes a modular approach that combines traditional geometric planners with a learning-based agent to predict a spatial affordance map for effective navigation in dynamic environments. The paper introduces a modular approach that combines traditional geometric planners with a learning-based agent to predict spatial affordance maps for navigation in dynamic environments, showing significant performance improvements. The paper introduces a modular approach that combines traditional geometric planners with a learning-based agent to predict spatial affordance maps for navigation in dynamic environments, showing significant performance improvements. These maps can be used for exploration and navigation, but traditional geometric maps do not account for dynamic obstacles like humans, vehicles, or other agents. Autonomous agents need to avoid collisions with dynamic obstacles for safe operation, which is challenging to encode with classic SLAM. One alternative to classic SLAM is end-to-end reinforcement learning for exploration and navigation. Challenges include high sample complexity, difficulty in generalization, and lack of interpretability. A hybrid approach is proposed, combining off-the-shelf planners with a learned spatial affordance map for safe movement. The affordance map is learned through self-supervised interaction with the environment, allowing the agent to identify safe movement areas. This approach is more sample-efficient, generalizable, and interpretable than current RL-based methods. Evaluation is challenging in both physical and virtual environments due to the difficulty of assessing real-world autonomous agents in diverse settings. In a static environment, first-person game-based simulators are used to evaluate exploration and navigation policies in VizDoom. Affordance maps combined with classic planners outperform traditional geometric methods by 60% and state-of-the-art RL approaches by 70% in exploration. Navigation performance improves by up to 55% with active learning and affordance maps in the presence of hazards. However, a significant gap remains between human and autonomous performance, highlighting the difficulty of these tasks even in a simulated world. Navigation in robotics involves mapping and path planning using inputs from cameras and sensors like LiDARs to create a geometric representation of the world. This representation helps derive a map of traversability to plan collision-free paths to goal locations. Applications include exploration of unknown environments by sampling point goals, planning paths, and incrementally building a map using sensor measurements (frontier-based exploration). Semantic SLAM seeks to associate semantics with maps to improve navigation by providing additional cues, such as emergency exit signs. This approach complements the purely geometric navigation method, especially in situations where semantic information can enhance the efficiency of map building and path planning. Recent works have explored using learning to solve navigation tasks efficiently by interacting with the environment and transferring between simulation and the real world using semantics. This approach complements traditional geometric navigation methods and focuses on dynamic environments and scenarios beyond simple geometric occupancy. Recent works have explored learning for navigation tasks, focusing on dynamic environments and scenarios beyond geometric occupancy. Mirchev et al. (2018) introduced a method for learning spatial representations using an attention-based generative model. Hybrid navigation policies combine learning with geometric reasoning or known robot dynamic models. Self-supervised learning has also been employed in robotics for navigation tasks. Recent work in robotics has focused on self-supervised learning for navigation tasks, with a particular emphasis on learning dense traversibility predictions for long-range path-planning. This approach differs from previous works that have employed passive cross-modal self-supervision or specialized techniques for navigation in dynamic environments. The goal is to build an agent that can explore and navigate in new environments with dynamic actors, respecting semantic constraints. The agent has a RGBD camera, proprioceptive feedback, and imperfect localization and depth sensing. It is placed in novel environments with unknown hazards. The proposed architecture for navigation involves using RGBD inputs to predict affordance maps and navigability maps that incorporate geometric and semantic information. A modular approach is taken, with a focus on building navigability maps using both types of information. The method includes maintaining a running estimate of the current position and updating a global map for safe and efficient planning. The method proposed involves predicting navigable parts of a scene by leveraging sensor feedback to generate training examples. A model is trained to predict affordance maps from the agent's viewpoint, combining outputs with depth sensor data for safe navigation in dynamic environments. Training an image segmentation model in a supervised fashion requires a set of labeled training images where each pixel is annotated for navigability. Obtaining such labels traditionally involves dense annotation by an oracle, limiting applications to domains with large segmentation datasets. To address this, a self-supervised approach is used to generate partially labeled examples instead of relying on oracle annotation. Self-supervised labeling for navigability training pairs involves the agent collecting affordance information through walks in the environment and generating labeled data in a self-supervised manner using RGBD observations and feedback sensors. The agent is initialized in a training environment, selects a nearby point to navigate towards, and generates labeled training data based on successful traversals. Affordance labels are back-projected into previous image frames to obtain partial segmentation labels. The real-world applicability of this approach is discussed in more detail in the appendix. The collected samples are used to train a segmentation network like UNet, enabling generalization of knowledge to new scenarios. This approach produces dense pixelwise labels for past observations, incorporating safety margins and improving interpretability of the agent's actions. The navigability module uses a masked loss function to generate segmentation maps that approximate ground truth navigability. Active Trajectory Sampling utilizes model uncertainty to plan paths and maximize label entropy for sample efficiency. Active Trajectory Sampling involves collecting samples using random walks, training a seed segmentation model, predicting an affordance map, and constructing a cost map for planning based on prediction uncertainty. This method increases sample efficiency by maximizing label entropy and retraining the model with collected samples. The method involves sampling episodes to learn visual signatures for hazards and dynamic actors. Semantic information is used to identify some hazards, while geometry helps identify navigability around large obstacles like walls. Predicted semantic maps are augmented with geometric information to construct navigability cost maps for planning. Depth images are used to create local occupancy maps at each time step, focusing on geometric information. Depth values are read from the center scanline of the depth image to mark non-navigable cells as geometric obstacles. Map Fusion involves combining a pixel-wise affordance map with a local geometric map to create a navigation cost map that incorporates both semantic and geometric information. The fusion module marks obstacles from the geometric map as impassable in the cost map, while assigning cost values to free space based on navigability confidence. The updated cost map is used to update a global navigability map for path planning. Our work focuses on path planning using global navigability maps, which encode semantic and geometric information for obstacle avoidance. Dynamic hazards are treated like any other obstacle, requiring frequent path replanning. Evaluation is done in simulation using VizDoom, allowing for complex 3D maps with dynamic actors and environmental hazards. In VizDoom, evaluation is limited to hand-designed maps without dynamic actors. Incorporating learned affordance maps helps with novel exploration and goal-directed navigation in procedurally-generated maps with various hazards and obstacles. The agent's observation and action space in VizDoom include a regular RGB image with a 60\u00b0 field of view, depth image for distance measurement, feedback sensor for damage magnitude, and limited motion primitives. Localization is imperfect with 2% error, and exploration performance is quantitatively evaluated. The exploration performance in VizDoom is quantitatively evaluated by measuring the total surface area of the global map constructed over time. Agents receive damage from dynamic and environmental hazards during exploration, with different hazard types having varying levels of danger. Frontier-Based Exploration is compared as a classical baseline method that updates a global map using scanline observations and selects goals within the \"frontier region\" for path planning. The exploration process in VizDoom involves selecting a goal from the \"frontier region\" and re-planning a path towards it every 10 steps. Dynamic actors are treated as static obstacles in the cost map, requiring frequent re-planning for collision avoidance. An augmented variant of the method incorporates RGB observations and egocentric crops for evaluation. The study evaluates a new penalty in the reward for damage received during training runs on 60 maps. The proposed representation includes semantic navigability maps from affordance predictions, with goal selection and path planning remaining the same. The navigability module is trained on 100k samples across 60 maps in a self-supervised manner using a ResNet-18-based UNet architecture for segmentation. The (Ronneberger et al., 2015) architecture is used for segmentation, with sample goals selected randomly at episode start. Back-projection is done using game damage as feedback, and at test time, output is projected into the 2D plane. Hazard-sparse environments prioritize goal selection over hazard avoidance, where augmenting the frontier-based approach with affordance maps does not provide significant improvements. The PPO-based RL approach struggles to outperform the frontier baseline due to its focus on exploration policy. Human navigation outperforms autonomous approaches in hazard-dense environments by selecting goals and navigating hazards more effectively. Augmenting the frontier-based approach with affordance maps improves performance by approximately 60%. The frontier-based approach with affordance maps enhances performance by around 60%, significantly surpassing the random baseline. Agents using learned affordance maps plan paths with a safety margin around hazards and encounter fewer obstacles due to geometry-affordance mismatches. The navigability module, through self-supervised sampling, learns about agent-specific locomotion capabilities, anticipating restrictions like low ceilings and tall steps. Despite RL-based exploration surpassing the frontier baseline by understanding hazard proximity's impact on reward maximization, long-term planning limitations hinder overall exploration performance. After training on 10,000 samples, the navigability module can recognize dynamic hazards for safe path planning. Increasing sample collection improves exploration performance, with diminishing returns after 10,000 samples. Our approach remains more sample-efficient than RL-based exploration, even after training on 20 times as many samples. In a series of 15 navigation trials, the agent must navigate through hazards and obstacles to reach an end goal in under 1000 time steps while minimizing damage. By incorporating semantic information from affordance maps, navigation performance can be significantly improved, even with simple geometry-based approaches. By introducing a navigability module trained on 100k samples to generate cost maps for planning, a 45% improvement in navigation success rate was observed. Even with a smaller dataset, a 25% improvement was still achieved. Increasing re-planning frequency by 10-fold did not surpass the affordance-augmented variant. Active learning further improved self-supervised learning efficiency, with models using actively planned trajectories outperforming those using random samples by more than 10% at 100k total samples. Actively sampled models outperform randomly sampled ones by over 10%, improving temporal stability and accuracy in predictions along hazard and obstacle boundaries. This enables more efficient path planning and closer navigation to hazards without damage. The approach learns to exploit semantic, dynamic, and behavioral properties of the environment for navigation, making it sample-efficient and effective. Our approach utilizes a spatial affordance map for sample-efficient and interpretable navigation, aiming to bridge the gap between human and autonomous exploration performance. The affordance map can potentially capture moving obstacles explicitly, enhancing affordance prediction with spatio-temporal cues. Test maps for evaluation are large with irregularly shaped rooms and narrow hallways. To illustrate challenges posed by semantic constraints, test maps are categorized as hazard-sparse or hazard-dense based on hazard likelihood. Hazard concentration differences are visualized in Figure 7, showing initial exploration areas in hazard-sparse and hazard-dense environments. Hazard-dense environments present significant challenges for autonomous exploration. Environments with high navigability restrictions pose challenges for autonomous exploration. Baselines for comparison include a random policy and an RL-based exploration approach with specific hyper-parameters and penalty terms to encourage safe navigation. To improve autonomous exploration, a human study was conducted using a similar setup. Participants were allowed to move forward and rotate simultaneously for better locomotion. Labeled samples were generated by marking navigable and non-navigable areas in the simulated world. The loss function weighted each pixel based on its distance to the nearest marked point for stability during training. The goal-directed navigation experiments involved difficult trials with high hazard concentration and obstacles. Human participants struggled to complete all trials without taking damage. Failures in the baseline occurred when the agent got stuck trying to path through obstacles lower than sensor height or collided with dynamic hazards. The baseline approach for navigation was implemented using a modified method. The baseline approach for navigation involves using a modified planning and locomotion modules for goal-directed navigation. Global navigability maps are created by averaging values from local maps over time for stability. A simple A*-based algorithm is used for planning, treating each cell in the map as the cost of traversing through the environment. Dynamic actors are considered static obstacles in the cost map, assuming re-planning is done frequently. The effect of re-planning frequency on navigation performance is evaluated by comparing different frequencies. Active trajectory sampling was evaluated for affordance-augmented navigation using segmentation models trained with actively gathered data. A seed model was trained with 20k random samples, then an additional 20k samples were actively collected and re-trained for a total dataset of 100k samples. Visualizations of predicted affordance maps after iterations 0, 2, and 4 were compared to a model trained with 100k randomly collected samples. Employing active learning allows models to effectively identify and localize regions containing rare environmental hazards. Dynamic behavior is captured using an affordance-labeling approach, where observations near a dynamic actor are labeled as hazardous. This approach helps in explicitly modeling moving scenarios. Our approach involves explicitly modeling moving obstacles by using an image-based tracker or implicitly learning to generate larger safety margins for dynamic actors. The system avoids regions close to dynamic actors to ensure safety. Our approach involves modeling moving obstacles by generating larger safety margins for dynamic actors. These margins emerge naturally from our learning-based approach, avoiding regions close to dynamic actors for safety. Visual examples show how traversal costs are higher near dynamic actors in the final cost map. In the context of self-driving research, autonomous vehicles are in the sampling stage of a long-term active learning loop aiming for L4 autonomy. Common risk mitigation solutions exist for potential hazardous situations during data collection in real-world robotics settings. The curr_chunk discusses the role of safety operators in autonomous vehicles, who are responsible for disengaging autonomy when needed. These takeover scenarios are logged to improve future models. In less critical scenarios, high-resolution sensors like LIDARs can replace safety drivers to help avoid collisions during training. During active training, feedback sensors can assist the robot in avoiding collisions and providing labels for undesirable states. These sensors are not directly used as input by the model and can be removed once a satisfactory model is trained. Feedback sensors can help label examples without experiencing catastrophic failures, such as detecting loss of traction on rough surfaces using wheel speed sensor values. Affordance maps can be learned to aid the robot in navigating smoother terrains. The proposed approach is more sample efficient than previous PPO-based reinforcement learning approaches for mobile robotics. The system will release open-source code for reproducibility. Additional visualizations show accurate localization of semantic constraints within affordance maps. Comparison of thresholded global maps constructed by frontier exploration using geometry and affordance-based representations in the same environment, showing accurate localization of semantic constraints. Semantic representations help the agent take less damage and explore more area during the episode."
}