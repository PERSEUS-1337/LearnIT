{
    "title": "Hye_V0NKwr",
    "content": "In this study, the focus is on locality and compositionality in learning representations for Zero Shot Learning (ZSL). The additional constraint is imposed to exclude pre-training on different datasets, unlike recent work in ZSL. The experiment results highlight the importance of locality and compositionality in representation learning for generalization. Generalization is crucial for models to perform well on test settings after training on a training setting. Tasks may involve variations in data distribution between training and evaluation, requiring models to address distributional changes in the input. The fundamental question addressed in this work is the principles contributing to learning good representations for Zero-Shot Learning (ZSL). ZSL is a challenging task that requires models to infer unseen concepts based on training data and high-level semantic information. The study explores how compositionality and locality play a crucial role in training models for Zero-Shot Learning (ZSL) by focusing on image representations and convolutional neural networks (CNNs). Results support the importance of these principles for generalization in ZSL tasks. The study introduces Zero-Shot Learning from scratch (ZFS) as a benchmark for understanding generalization principles. ZFS evaluates models without pretraining on other datasets, focusing on classification using auxiliary attributes and labels from the target dataset's training split. This framework aims to identify key principles for Zero-Shot generalization. The study evaluates supervised and unsupervised methods for generalization in Zero-Shot Learning (ZFS) by training a prototypical network on learned features. They introduce a novel version of Deep InfoMax (DIM) and a visualization technique based on Mutual Information to investigate local properties of representations. Zero-Shot Learning (ZSL) is crucial for understanding a model's real-world applicability. Zero-Shot Learning (ZSL) focuses on learning features directly from raw data to generalize to unknown test cases. ZSL requires thinking beyond normal classification by incorporating principles like compositionality and locality. The use of convolutional neural networks (CNNs) is crucial for encoding images in ZSL tasks. In the context of Zero-Shot Learning (ZSL), the focus is on learning features from raw data to generalize to unknown test cases. Principles like compositionality and locality are essential, with applications in various fields such as computational linguistics, generative models, and Meta Learning. Approaches to encourage compositionality vary, from introducing penalties to using modular architectures. A representation is considered compositional if it can be expressed as a combination of simpler parts. In the context of Zero-Shot Learning (ZSL), the focus is on learning features from raw data to generalize to unknown test cases. Principles like compositionality and locality are essential. A representation is considered compositional if it can be expressed as a combination of simpler parts. This involves mapping input data to possible parts and then to a representation space through a function. The parts could be local image features or other generative factors. The combination of these parts is typically done through a weighted sum or more complex combinations. CNNs are widely used in representation learning, exploiting local information. Locally-aware architectures are beneficial for non-image datasets like graphs and natural language processing. Attention over local features is common in tasks such as image captioning and fine-grained classification. Self-attention over local features has shown significant improvements in generative models. Self-supervised methods often utilize local information for learning useful representations. In image data, local representation is defined as specific to a patch, motivating architecture choices that encourage locality. Using CNN features with small receptive fields maintains this approach, aiming to prevent the dominance of global information. In image data, local representation is specific to a patch, motivating architecture choices that encourage locality. Different models will be evaluated on encoding information specific to locations, with a focus on compositionality and locality in ZSL datasets like AwA2, CUB, and SUN Attribute. The datasets considered in this study, AwA2, CUB, and SUN, provide attributes that describe high-level semantic information. These attributes vary from visual characteristics in CUB to both visual and behavioral traits in AwA2, and diverse functions in SUN. The CUB dataset includes attributes and bounding boxes for different parts of subjects, which can be used to assess locality and compositionality. Recent image zero-shot learning approaches use features from large neural networks like InceptionV2 and ResNet101 pretrained on Imagenet for better performance. Recent image zero-shot learning approaches utilize features from large neural networks pretrained on Imagenet for better performance. However, concerns arise regarding the dependency on specific pretrained backbone encoders and pre-training datasets for successful transfer learning. The suitability of Imagenet features for general zero-shot learning settings remains uncertain, making it challenging to evaluate Zero-Shot learners effectively. Zero-shot learning evaluation is challenging due to the impact of pre-training datasets on specific classes. ZSL should focus on training models to reason about new concepts, rather than relying on Imagenet features. Understanding generalizable concepts requires minimizing the influence of Imagenet backbones and datasets. ZFS framework adds a requirement of no model parameters containing specific information. In ZFS, model parameters must not contain external data information. Representation learning methods are trained under this setting to emphasize locality and compositionality. CNNs are trained using supervised or unsupervised learning, followed by ZSL transfer using prototypical networks. Visualization tools help identify important local representations. Prototypical networks are used for ZSL transfer due to their efficiency and performance. ZSL models rely on metric learning by embedding data samples and class attributes into a common subspace for nearest neighbor classification. Pre-training the image encoder with diverse models like DIM is compared for better performance. Class-Matching DIM (CMDIM) is a novel version of DIM that focuses on learning representations that are discriminative between classes by drawing positive samples from other images of the same class. The hyperparameter p determines the probability of intra-class matching, with experiments conducted using p values of 1, 0.5, and 0.1. Additionally, an auxiliary local loss is introduced to encourage the image encoder to extract semantically relevant features at earlier stages of the network. The auxiliary loss in Class-Matching DIM (CMDIM) is from an attribute-based classifier (AC) or a label-based classifier (LC). Boolean maps are constructed for each part in the CUB dataset using MTurk worker annotations. Ground truth variables are generated through the CNN to indicate part presence and visibility. Linear probes are trained for each part to measure how well the encoder represents image parts at correct locations. This provides local interpretability. For more details, refer to Section F in the Appendix. The local interpretability in Class-Matching DIM (CMDIM) involves estimating mutual information between global and local features using a statistics network. The network optimizes a lower bound to the mutual information by taking inputs from global and local feature vectors. This method is effective for high dimensional, continuous random variables. For more details, refer to Section F in the Appendix. The statistics network in Class-Matching DIM estimates the Pointwise Mutual Information (PMI) between global and local feature vectors. It normalizes the score across local patches to measure relatedness. This analysis is similar to previous work on image augmentations and focuses on the Tree Reconstruction Error (TRE) as a proxy for compositionality. The TRE is used as a proxy for compositionality in the context of zero-shot learning. The TRE ratio is defined as the ratio of TRE computed with respect to attributes versus uninformative variables. Image encoders considered include DCGAN and AlexNet architectures. The study explores the impact of different encoder architectures on zero-shot learning models, using smaller encoders compared to standard backbones. Evaluation is done using ZSL splits from Xian et al. (2017) and models are assessed based on Top-1 accuracy. The encoder is pretrained using various methods, with details of the architectures provided in the Appendix. The study evaluates the impact of different encoder architectures on zero-shot learning models, focusing on Top-1 accuracy. Pretraining the encoder using various methods, a Prototypical Network is then trained on the learned representation. Results and experiments are detailed in the Appendix, with a correlation observed between representations predicting parts accurately and better ZSL performance. Comparing ZSL accuracy to part classification F1 score shows a clear correlation. The study evaluates the impact of different encoder architectures on zero-shot learning models, focusing on Top-1 accuracy. There is a correlation between representations predicting parts accurately and better ZSL performance. Among the models tested, variants of Deep InfoMax generally perform well, with CMDIM performing the best overall. Local representations must share information to improve ZSL performance. The study explores the impact of local representations sharing information to enhance ZSL performance. Local losses encourage models to capture important semantic information and improve both ZSL and parts score. Generative models like VAE and AAE do not benefit from the addition of local losses. Local loss improves ZSL and parts score for all models except VAE and AAE. The parts score increases for generative models, indicating more locality, but this does not translate to better ZSL performance. Investigating why local losses improve generalization, the study shows the impact of each type of local classifier on model performance. Supervised models benefit more from attribute-based auxiliary loss, while unsupervised models like AMDIM show consistent positive effects from both losses. However, CMDIM's LC auxiliary loss hurts performance. The CMDIM model's LC auxiliary loss hurts performance due to focusing on discriminating classes at the local level. Adding class and attribute information through AC and LC losses helps improve performance for DIM and AMDIM models. Visualizations using PMI-based techniques show the impact of global representations on local features in the CUB dataset. The fully supervised model focuses on relevant semantic details, while unsupervised models based on reconstruction loss fail to highlight semantic information effectively. This indicates that unsupervised models may prioritize pixel statistics for reconstruction rather than extracting meaningful features. Self-Supervised models like AMDIM and CMDIM focus on recovering semantic information, with CMDIM performing well in producing heatmaps similar to supervised models. Models that encode semantic information perform better in zero-shot learning, while those focusing on pixel reconstruction perform worse. The study confirms that different models prioritize either semantic information or pixel statistics. The Parts ratio measures the model's scoring of relevant parts and overall features. Two types of similarity are computed between images: semantic (cosine distance between attributes) and pixelwise (SSIM index). Correlation is measured between Parts ratio and similarity measures. Positive correlation indicates higher part ratio for semantically similar images, while negative correlation suggests otherwise. The Parts ratio measures the model's scoring of relevant parts and overall features. Negative correlation with SSIM score indicates that VAEs and reconstruction models are not well suited to learn representations that generalize. The experiments show a strong correlation between implicit compositionality measures and zero-shot learning (ZSL) performance. The relationship is strongest when attributes are highly relevant to the image, as seen in datasets like AWA2 and CUB. However, this relationship degrades for datasets like SUN, where attributes are less likely to map accurately. The experiments demonstrate a strong correlation between implicit compositionality measures and zero-shot learning (ZSL) performance. Attributes are per-image and averaged over classes, impacting the information present in an image. Utilizing local representations directly for classification can be done by averaging them or classifying each patch separately and then averaging predictions. A compositional model based on local features aids ZSL, with results shown in Fig. 6. Averaging representations enforces compositionality by building the input representation as a weighted sum of patch representations. In a new evaluation framework for Zero-Shot Learning, training is strictly on benchmark data without pre-training on additional datasets. The importance of locality and compositionality for successful zero-shot generalization is highlighted through tests on various representations. Models that promote these aspects tend to perform better in zero-shot tasks. Models focusing on locality and compositionality perform better in zero-shot learning. Reconstruction-based models struggle to capture necessary semantic information for good generalization. Convolutional encoder generates global representation for model loss calculation. PyTorch was used for implementation, images resized to 128x128 with random crops during training. The experimental setup for zero-shot learning involved using aspect ratio 0.875 for training and center crops with the same ratio for testing. Models were optimized with Adam, a learning rate of 0.0001, and a batch size of 64. The final output of the encoder was set to 1024. Local experiments extracted features from the third layer of the network, with dimensions of 27 \u00d7 27 \u00d7 384 for the AlexNet based encoder and 14 \u00d7 14 \u00d7 256 for the DCGAN encoder. The impact of local losses on the information extracted by CMDIM was visualized in Fig. 9, showing how label-based local loss affected the encoder's focus on background versus discriminative features. The label-based local loss helps the model focus on distinctive patches for specific bird species. A correlation analysis was conducted between Parts ratio and image similarity measures, showing a statistically significant relationship. This highlights the relevance of local information for generalization in the model. In experiments, classification is performed on features with limited receptive fields from an AlexNet encoder. Varying receptive field sizes show different effects on dataset performance. Results indicate pooling benefits class-matching DIM for specific datasets, while SUN dataset benefits from considering the entire image. In experiments, pooling has varying effects on dataset performance. For SUN dataset, pooling does not affect or has a negative impact, while for reconstruction models, not performing pooling leads to better performance. Parts annotations in CUB dataset help quantify meaningful local information extraction by training classifiers for each part based on local features from the CNN encoder. Ground truth is constructed from parts click annotations. The curr_chunk discusses the process of obtaining ground truth for classifiers by converting part annotations into boolean semantic maps and processing them through a CNN. The loss is computed based on the compatibility of features with the masks, and the classifiers are used to evaluate the predictiveness of local features for parts. Deep InfoMax is mentioned as a self-supervised representation learning algorithm. Deep InfoMax is a self-supervised representation learning algorithm trained by maximizing Mutual Information between local and global features. Class Matching DIM samples pairs of local-global features from different inputs of the same class for positive samples, and from different inputs for negative samples. The algorithm introduces a hyper-parameter to control the interaction between DIM and CMDIM, emphasizing relevant features for specific inputs and shared features within a class. Key notations and definitions for dataset attributes and distance functions are outlined. The algorithm introduces a hyper-parameter to control the interaction between DIM and CMDIM, emphasizing relevant features for specific inputs and shared features within a class. In Andreas (2019), cosine similarity is chosen for combining individual attribute representations by summation. The computation of \u03b7 is defined as argmin \u03b7 TRE(X tr ,a;\u03b7 ) and omitted in what follows. ARCHITECTURES AND DATASETS DETAILS are also discussed."
}