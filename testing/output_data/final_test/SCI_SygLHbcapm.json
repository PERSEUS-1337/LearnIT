{
    "title": "SygLHbcapm",
    "content": "In this work, a framework is presented for integrating user feedback into knowledge bases (KBs) in the presence of identity uncertainty. The approach involves user feedback participating alongside mentions in entity resolution (ER). A specific representation of user feedback as feedback mentions is proposed, along with a new online algorithm for integrating these mentions into an existing KB. Experimental results show that this approach outperforms baselines in 70% of conditions. Structured knowledge bases (KBs) are often incomplete and noisy, with a high percentage of missing or incorrect information. Human users play a crucial role in aiding KB construction and maintenance by providing feedback on entities, attributes, and relationships. KB errors can lead to spurious and missing information, highlighting the need for user involvement in improving data accuracy. KB errors in relationships with other entities can result in spurious and missing attributes and relationships. The data forming a KB is raw evidence that needs clustering by entity resolution into inferred entities. User feedback can cause identity uncertainty in the KB, leading to errors from noisy mentions. The volatility of underlying mention clustering in a KB poses challenges for integrating user feedback, especially with identity uncertainty. New data and user feedback can trigger modifications in inferred entities, leading to the creation, removal, or alteration of entities and relationships. In response to user feedback, the entity Rajarshi Das was split into two entities due to identity uncertainty. A new framework for handling user feedback amidst identity ambiguity is presented in this paper. Our proposed approach based on FMs outperforms baselines in 70% of experimental conditions, aiming to improve user effectiveness in KB construction by integrating user feedback amidst identity uncertainty. This work defines formal models for mentions and entities to construct a framework for reasoning about user feedback integration with KBs. Formal models for mentions and entities are essential building blocks for constructing knowledge bases. A knowledge base consists of mentions referring to ground truth entities, with the goal of partitioning mentions into inferred entities that closely match the ground truth. Mentions have attributes serving as evidence for inferred entity attributes and relations, with a process called canonicalization deriving attributes from mentions. This method focuses on a simple approach to canonicalization. Our model of mentions, entities, and attributes is similar to Bayesian models used for entity resolution. Hierarchical modeling allows for the use of a learned entity-level linkage function, improving entity resolution systems by identifying set-level inconsistencies and similarities in attributes like gender, animacy, and number. Additionally, hierarchical models promote efficiency in inference and represent uncertainty. The model promotes efficiency in inference and represents uncertainty by encoding multiple partitions of mentions simultaneously using a binary tree structure. Each node stores attribute weights, with leaf nodes mapping attributes to 1 and internal nodes constructed via canonicalization. The weight of an attribute in a node's map is the sum of that attribute's weight in its children's maps. Nodes in a tree can be scored for compatibility using a linkage function. Inferred entities can be extracted from the tree based on a threshold. Despite research efforts, ER models are imperfect and lead to partitions. ER models, despite significant research efforts, are imperfect and can result in partitions where mentions from different entities are clustered together or split apart. User feedback from knowledge base users can help identify these errors, but identity uncertainty in the feedback must also be resolved. A formal model of user feedback is presented to jointly address identity uncertainty for both mentions and feedback. This model helps resolve ambiguity in feedback, as illustrated in an example where uncertainty arises about the entity being referred to. The feedback entity is split, causing uncertainty in identity. User feedback is represented as mentions for Entity Resolution (ER) to reason jointly. Each user feedback is a feedback mention (FM) with attribute map packaging. FMs are stored at tree leaves like standard mentions for ER to consider all mentions and feedback together. FMs can impact ER and are initialized with attributes. An example of FM integration in ER using the OG algorithm is shown in FIG0. The difference between FMs and standard mentions lies in the use of negatively weighted attributes in FMs to encourage splits in the underlying partition of mentions. This feedback can lead to the splitting of inferred KB entities, causing uncertainty in identity. Negatively weighted attributes in FMs correct spurious inferred entity attributes from noisy mentions. By assigning a negative weight to an attribute, it can be removed through canonicalization, effectively eliminating the spurious attribute. This approach helps in cases where a FM may be incompatible with its intended target. Each FM has a payload attribute map that does not affect compatibility but influences canonicalization. The packaging at a parent node is computed by combining weights from packaging and payload maps of its children, keeping payload attributes hidden until nodes are merged. The parent node's attribute map is determined using canonicalization notation. The proposed representation of feedback as mentions is compatible with any hierarchical inference algorithm for ER. The online grafting (OG) algorithm is presented for online, hierarchical ER, maintaining a tree-consistent partition of inferred KB entities. The algorithm includes two recursive subprocedures: swap and graft. The OG algorithm consists of two recursive subprocedures: swap and graft, promoting local and global optimality. When a new data point x arrives, it is added as a sibling of its nearest neighbor leaf v. The swap l subroutine is then invoked recursively to determine compatibility between x, v, and a. After swapping, the graft subroutine is recursively invoked from the parent of x, par(x). After swapping, the graft subroutine is recursively invoked from the parent of x. If the linkage score is below the threshold, a swap is performed. The algorithm terminates if no further grafts are attempted. It searches for the most compatible leaf with p in T and tests compatibility with siblings. If successful, it reinvokes the graft subroutine; otherwise, it considers different cases. The subroutine iteratively attempts mergers between ancestors of x and compatible nodes in T. The graft subroutine in the algorithm promotes global optimality by merging nodes in T that are compatible with each other and belong to the same inferred entity. The linkage function g is trained to regress to the precision of its input, which is the fraction of leaf-pairs belonging to the same ground-truth entity. FMs are excluded from this calculation as they have no ground-truth label. See Algorithm 3 for pseudocode and FIG2 for an illustration of the algorithm's tree operations. The algorithm's training procedure involves selecting nodes for training in the context of running the OG algorithm. Training examples are generated between new mentions and all other leaves, as well as ancestors of its nearest neighbor. The linkage function, g, is trained to handle user input and regress to the precision of its input node pair. After training the linkage function, g, to handle user feedback, a batch of N training mentions are added to a tree. User feedback is generated to encourage grafts or splits in the inferred entity. The feedback is inserted into the tree using the OG algorithm, creating training examples between the feedback and its intended sibling in the tree. Positive feedback targets the root of a subtree near the sibling. The model is trained to use positive feedback to encourage grafting and negative feedback to encourage splitting. The threshold is tuned on a development set using hierarchical clustering and pairwise F1 score measurement. The best parameters and threshold from the dev set are used at test time. Experiments test different feedback representations in online author disambiguation. In online author disambiguation, feedback representations are tested using the Rexa author disambiguation dataset. The goal is to partition ambiguous mentions of authors into real-world entities using a hierarchical clustering algorithm. The process involves incrementally adding mentions and constructing inferred entities in rounds based on a threshold. User interaction is simulated to improve the disambiguation process. The method involves simulating user interaction by generating feedback based on inferred entities, adding it to the dataset using the OG algorithm, and potentially triggering repartitioning. A maximum of 400 rounds is allowed, with a recording of 400 + d rounds if ground-truth entities are not discovered. The mean number of rounds required to discover entities is measured over 25 trials, comparing different feedback representation styles. Positive and negative feedback are simulated using node purity and completeness. The method involves simulating user interaction by generating feedback based on inferred entities, adding it to the dataset using the OG algorithm, and potentially triggering repartitioning. Positive and negative feedback are simulated using node purity and completeness in the tree structure. Feedback is generated by sampling an intended destination and target node for merging or separation. The curr_chunk contains a string of characters and code snippets. The curr_chunk consists of a string of characters and code snippets. The curr_chunk provides detailed instructions on generating positive or negative feedback by sampling an inferred entity and a destination. The feedback packaging includes attributes. The curr_chunk discusses the process of generating positive feedback by sampling a destination node and a target mention in a tree structure. Positive feedback aims to merge two nodes in the tree via a graft. The curr_chunk explains the process of constructing negative feedback by sampling an impure inferred entity and finding a target mention in a tree structure. Negative feedback aims to split an inferred entity by selecting a mention that is not a descendant of a specific node. The curr_chunk discusses different baseline feedback representations for integrating user feedback under identity uncertainty, including Feedback Mentions (FM), Packaging Mentions (pack), and Hard Assignment (assign). These representations aim to construct feedback by selecting a target mention in a tree structure and splitting an inferred entity. The curr_chunk discusses the OG algorithm for assigning feedback to nodes in a tree structure, with a focus on identity uncertainty. It also introduces the Hard Mention Assignment approach, where feedback is assigned to specific leaves in the tree and never deleted. This is part of an experiment involving user feedback on a knowledge base of scientists' expertise. In an experiment involving user feedback on a knowledge base of scientists' expertise, packaging contains attributes at the sampled destination and payload contains keywords at the target. Expertise key phrases are shared attributes, while publication authorship is not. The second experiment involves identifying incorrectly assigned and missing publications in a scenario similar to browsing scientist profiles on Google Scholar. The experiment involved collaboration among entities in the same canopy on publications. Tables 1a and 1b show results of expertise and title experiments. Feedback was provided for a concise target in the packaging and payload for authorship FM. Each row in the tables represents a canopy, and each column corresponds to a baseline method and feedback generation setting. Positive numbers indicate the mean number of rounds required by the FM approach to discover the ground-truth partition. The experiment involved collaboration among entities in the same canopy on publications. Feedback was provided for a concise target in the packaging and payload for authorship FM. The ground-truth partition was compared using different feedback representations, with FM outperforming pack in Experiment I on most canopies. Storing shared attributes in the payload is crucial for initial routing. In Experiment II, feedback on attributes not shared showed that separating packaging and payload is less important. The pack approach slightly outperformed FMs in the detailed setting, while FMs generally outperformed pack in the concise setting. The proposed approach typically performed better in Experiment II, while the baseline performed better in Experiment I due to feedback ambiguity. The baseline's approach of deleting feedback to mitigate errors caused by identity uncertainty with respect to user feedback was noted. The study found that FM generally outperforms assign-m in both experiments, as assign-m is similar to the assign strategy but never deletes feedback. Positive numbers in Table 1 indicate that FM requires fewer rounds of feedback than its competitor. The study of leveraging user feedback in KB construction has focused on various approaches, including active learning and feature extraction rules. Pairwise feedback solicitation is common, with systems like CrowdER automatically pruning mention pairs and collecting binary labels. Other work involves humans identifying matching mentions across databases in data integration. Recent work in data integration involves humans identifying matching mentions across databases. Unlike previous work in author coreference, this study discusses both pairwise and identity constraints for feedback. The feedback collected here cannot be reduced to pairwise constraints, as it is aimed at correcting general KB errors, not just errors in entity resolution. The OG algorithm is related to the clustering algorithm GRINCH, which also uses a graft procedure in an incrementally built system. The OG algorithm uses a threshold to rearrange trees and maintain inferred entities. It incorporates user feedback by representing feedback mentions in entity resolution. The OG algorithm enhances entity resolution by incorporating user feedback to improve efficiency in recovering ground-truth partitions. This work addresses a crucial issue in automatic KB construction, aiming to enhance accuracy and efficacy by integrating user feedback with KB content."
}