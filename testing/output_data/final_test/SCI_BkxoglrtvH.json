{
    "title": "BkxoglrtvH",
    "content": "To understand object vision development in infancy and childhood, testable computational models are needed. Deep neural networks (DNNs) are valuable for adult vision modeling, but their effectiveness for development modeling is uncertain. A DNN model called CORnet was used to measure learning by freezing convolutional layers and training a linear decoding layer. Decoding accuracy was evaluated on the ImageNet validation set and individual visual classes. Another unsupervised network called DeepCluster was also tested for learning. In a study on object vision development in infancy and childhood, a state-of-the-art unsupervised network called DeepCluster was used to measure learning. To isolate the effect of supervision, a control experiment was conducted by training the convolutional network from DeepCluster in a supervised manner. Predictions were made on how learning should develop across brain regions in infants. A counter-intuitive relationship was found between the order in which infants and machines acquire visual classes. The development of the brain and mind during infancy is influenced by genetically programmed maturation and environmental experiences. During infancy, measuring development through behavior can be limited due to infants' behavioral repertoire. Magnetic resonance imaging (MRI) is a promising tool to understand brain development in addition to behavior. Creating models of development mechanisms is crucial to comprehend changes in infants' brains and minds, especially in cases of brain injury or preterm birth. Infants born very preterm or with birth complications are often admitted to the NICU, where a significant number may later experience cognitive, behavioral, or social impairments. To detect these issues early and develop effective interventions, computational models of infant brain and mind development are needed. One potential area for modeling is the object recognition system in the ventral visual stream, which can be studied using neuroimaging methods. In adults, computational models optimized for object vision can predict neural activity patterns effectively, unlike the traditional method of fitting models to neural data. This approach utilizes Deep Neural Networks (DNNs) designed for visual recognition challenges like ImageNet to accurately model neural activity. The Large Scale Visual Recognition Challenge (ILSVRC) can predict patterns of neural activity in the ventral visual stream using various methods such as fMRI, EEG, and behavioral studies. The studies suggest similarities in activity patterns between artificial neurons in DNNs and biological neurons in the brain, showing a hierarchy of representations from visual input to semantic category. Infants learn a great deal of object vision knowledge through visual experience, as genetic code alone is limited in capacity. Evidence shows that learning begins in early infancy, with 3-4 month old infants able to identify statistical regularities in sequences of pictures. Infants can identify statistical regularities in sequences of pictures. By 6 months, they start to associate visual classes with spoken labels. In adults, fMRI shows selectivity for visual classes like faces, body parts, or places. Partial selectivity is present in 4-6 month old infants in the ventral visual stream. DNNs serve as models for adult object vision and potentially infant learning. The overarching hypothesis is that DNNs capture macro-scale characteristics of learning. Two properties of computational models are characterized for a future neuroimaging study: 1. Do brain regions in the visual hierarchy develop simultaneously or asynchronously? 2. How representations develop in different brain regions. The text discusses the development of visual representations in DNNs and infants, focusing on the order in which visual classes are learned. It also explores the link between word acquisition and brain representations in the ventral visual stream. The question of whether visual complexity influences the order of learning is raised. The text discusses the link between word acquisition and brain representations in the ventral visual stream. It questions if visual complexity affects the order of learning in DNNs and infants. The study uses a supervised network, CORnet-S, designed to capture architectural principles and predict neural data from the ventral visual stream. The text discusses the use of DeepCluster for unsupervised training in infant learning, drawing parallels with infant behavior in creating clusters of similar images. DeepCluster utilizes k-means clustering to assign labels to image clusters for self-supervised learning. The study utilized k-means clustering to assign labels to image clusters for training a convolutional network. AlexNet was used with modifications such as batch normalization and Sobel filters. DeepCluster was trained unsupervised, while CORnet was supervised, potentially impacting the results. The study compared the object recognition performance of CORnet, DeepCluster, and AlexNet variants. They assessed the representations of object classes in different layers of the networks using freezing weights and training linear decoders. Learning curves were analyzed to capture the development of representations across epochs. The study compared object recognition performance of CORnet, DeepCluster, and AlexNet variants by fitting performance with a curve involving precision, epoch, asymptotic level, and learning rate. Regularization terms were added to the cost function to discourage high learning rates and performance levels above 100%. The order of visual class acquisition in infants and machines was compared using a proxy estimate of age of acquisition based on linguistic factors. The study analyzed the relationship between the concreteness of words and the age of acquisition (AoA) in infants and deep neural networks (DNNs). Concreteness of a word is linked to its perceptual representation, with concrete words evoking visual representations more easily. The study aimed to determine if visual classes labeled earlier in infants are learned more quickly by DNNs. The study compared WordNet synsets for ImageNet classes to an English word database for age of acquisition ratings. Classes with high similarity scores were analyzed, resulting in 308 classes for further examination. These classes were clustered to 20 groups for visualization. Training was conducted on AWS using Deep Learning AMI on different GPU instances. The study trained three networks on AWS using different GPU instances and spot instances to reduce cost. The CORnet network showed explicit representation of object class in its layers during training, with IT layer continuing to learn until at least epoch 25. The study trained three networks on AWS using different GPU instances and spot instances to reduce cost. The CORnet network showed explicit representation of object class in its layers during training, with IT layer continuing to learn until at least epoch 25. In human infants, earlier maturation of lower-order visual processing regions (V1, V2, V4) compared to higher-order brain regions (e.g., IT) is indicated. Infant IT contains stronger explicit representations of object class, which is not inherent to how IT functions but found throughout training. The color of curves shows AoA of class's name for infants (blue to red for low to high AoA). The fit parameters were correlated for all networks, indicating that classes learned more quickly converged on a higher asymptote. In contrast, DeepCluster showed a \"bottom-up\" maturation of representations, with layer 3 containing stronger object class representations than layer 4 even after 60 training epochs. The order of layers varied during training, with layer 2 stronger than layer 3 early on, and layer 1 stronger than layer 4 in object class representations. This unsupervised strategy suggests slower development in higher-order brain regions in the ventral visual stream. The ventral visual stream develops more slowly, with representations of object class present in earlier regions. In supervised training, object labels are provided at the top layer, leading to maturation of the entire network. In contrast, unsupervised learning proceeds in a more bottom-up manner, with maturation starting from the early layers. This is consistent with the simple-to-complex maturation theory. CORnet and DeepCluster differ in training strategies and convolutional networks. The study compared supervised training with DeepCluster using AlexNet, showing that supervised learning led to a reduction in explicit object representation in lower layers. In contrast, DeepCluster maintained explicit representation, suggesting it may be a feature of supervised learning. Additionally, machine and human learning across visual classes were compared, with the model fitting well to the learning curves. The joint distribution analysis showed that classes learned quickly were learned best, with strong correlations between fit parameters for all models. Comparing machine and human learning, classes learned more precisely by the model were learned later by infants. The macroscale distribution of object representations was affected by learning strategy, with supervised training concentrating object representations near the output layer. The study found that supervised training focused object representations near the output layer, while unsupervised training spread them across layers. There were differences in the learning order, with unsupervised learning showing a bottom-up sweep and supervised learning maintaining a top-down approach. The effects were attributed to the learning strategy rather than the DNN architecture. Future research should explore other DNNs and training objectives to further understand generalization. Future work could investigate testing DNNs that exploit different structures in visual input and making DNNs more similar to brains at the implementation level. In Aim 2, a counter-intuitive relationship was found between visual classes learned by DNNs and those named first by infants, possibly due to limitations in measuring infant learning. Further research is needed to explore these findings. In future work, factors influencing infants' learning of visual categories, such as class frequency and reward value, will be explored. There is interest in developing unsupervised strategies for visual recognition to utilize unlabelled data more effectively. Unsupervised strategies for visual recognition, such as cross-channel color prediction and feature counting, have been explored. The use of textures over shapes by DNNs, leading to vulnerability to noise and adversarial attacks, highlights differences in feature weighting compared to humans. Understanding human visual system knowledge and developmental trajectories could guide the search for biomimetic DNNs. DNNs learn like humans from large data quantities, but formal connections between infant and machine learning are lacking. This study aims to measure defining characteristics in DNNs and infants to provide insights for both fields. Training object decoders in DNNs was computationally intensive, requiring determination of the number of training epochs. Training object decoders in DNNs was computationally intensive, requiring determination of the number of training epochs. Decoders were trained for 5 epochs on features from convolutional training epochs (0, 20, 40, 60) and all layers. It was found that 2 epochs of training captured the relative performance across different layers. Further analysis showed changes in top-5 precision and cross-entropy loss as DeepCluster learned slowly over 70 epochs. The unsupervised network, DeepCluster, learned more slowly than the supervised networks. The convolutional layers were trained for 70 epochs to test if the layers with the strongest explicit object representation changed over an extended period of learning."
}