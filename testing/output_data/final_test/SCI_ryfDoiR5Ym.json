{
    "title": "ryfDoiR5Ym",
    "content": "Researchers are exploring the use of watermarks in deep neural networks for various purposes, such as hiding attack triggers and proving ownership against plagiarism. A new method using encoder-decoder neural networks inspired by GANs has been proposed to find the best watermarking scheme automatically. The trained decoder can be implanted into other neural networks for attacking or protecting them. The decoder in the encoder-decoder neural networks is designed to be small yet highly successful in decoding, making it suitable for attaching to other neural networks for attacking or protecting them. The joint training method ensures almost 100% encoding-decoding success rates for multiple datasets with minimal modifications to hide watermarks. Security issues in deep learning, including vulnerability to adversarial attacks, are actively studied, with recent works proposing the use of watermarks for protection. The method of adding watermarks to data samples can protect deep learning models by proving ownership and allowing access only to those with the encoder. The decoder should be small to minimize overheads. Similar techniques can also be used to attack neural networks. In this paper, the encoder and decoder work together to develop a watermarking method inspired by generative adversarial networks (GANs). The decoder is a small neural network for decoding watermarks, while the encoder is a high-capacity neural network for watermarking samples. Their cooperative relationship aims to find an effective watermarking scheme, unlike the adversarial game in GANs. The encoder, with a limited capacity, should not decide the watermarking scheme alone but receive feedback from the decoder. The method can be used for both defenses and attacks. Residual blocks BID5 are adopted to design the encoder, with each block learning f(x)+x. The training loss definition is designed to ensure the watermark signal produced is strong enough for the decoder but not detectable by human eyes. Our training loss definition aims to modify original samples to implant watermarks, with a parameter set by the user to limit modifications. Experiments show a well-balanced watermarking scheme that can only be detected by the decoder, achieving 100% decoding success rates across various datasets and outperforming baseline methods. Watermarking schemes are tailored for different datasets, with encoders modifying colors for face recognition images and marking dots for general object images. Two neural networks collaborate to find the best watermarking method for each dataset. Watermarking involves merging a watermark signal with a data sample to produce a watermarked sample. The signal is secret and used to verify the origin of the watermarked sample. Various watermarking techniques exist for different types of data. Watermarking deep neural networks is an under-explored area, with recent proposals for a backdoor-based method to control final predictions. This method aims to provide a more robust way for watermarking neural networks compared to traditional techniques used for relational databases, images, and videos. The authors propose using a backdoor mechanism to protect the ownership of a neural network by retraining it to classify certain objects differently. This method involves watermarking samples to prove ownership, but if the backdoor is removed, ownership proof is lost. Additionally, attackers can use watermarking techniques to implant triggers in compromised neural networks for specific outputs. The paper discusses using a backdoor mechanism to protect neural network ownership by retraining it to classify objects differently. Attackers can implant triggers in compromised neural networks to manipulate outputs. The study focuses on redesigning the adversarial game model with two neural networks for watermarking purposes. The watermarking framework involves one encoder and one decoder working together in a cooperative game. Watermarks are used for various purposes in deep learning, including defenses and attacks for neural networks. The encoder modifies samples by adding a watermark signal, while the decoder detects the presence of the signal. The pair can be used for both defenses and attacks, with a focus on being pluggable to other neural networks. Existing watermarking methods based on CNNs do not consider the size of the decoder, but the encoder-decoder pair in this study does not implant a watermark signal into data samples. Our goal is to develop a watermarking framework with an encoder and decoder that work together without implanting a watermark signal into data samples. The model consists of a large encoder and a small decoder for binary classification, inspired by generative adversarial networks. The decoder should be lightweight to avoid overhead when attached to other neural networks. The proposed method involves a watermarking framework with an imbalanced encoder and decoder, working cooperatively. The encoder generates simple but robust watermarked samples, while the decoder has low capacity. The encoder architecture includes residual blocks and convolutions to create a watermark signal specific to input samples. The encoder uses a stride of 1 and 3 channels to maintain input and output dimensions. Residual blocks are utilized to design the encoder for implanting a watermark signal. Multiple stages of residual blocks are used to generate a robust watermark signal that is merged with the original sample. The overall watermarked sample generation process involves using attention maps and residual blocks to create a robust watermark signal. The watermark signal is generated by combining additive terms from residual blocks and refining the watermarked sample through post-processing blocks. Various watermarking examples for different datasets are shown in figures. Watermarks are generated using attention maps, with examples shown in figures. The decoder classifies if a sample has a watermark signal, aided by attention. Watermarks can be focused on specific areas or scattered over all pixels. The decoder for watermarking is tiny and hard to detect in neural networks. Experiments vary convolution layers to find the smallest configuration. Training loss involves encoder and decoder cooperation, similar to GANs but not adversarial. Optimization occurs when decoding success rates are maximized. The watermarking decoder is optimized for a 100% success rate by using cross-entropy loss and a regularization term. The final loss term includes a hinge-loss based regularization to limit modifications. This approach compares feature maps from the VGG19 network instead of pixel-wise error, with a maximum margin of \u03b3 allowed for modification control. The watermarking decoder uses hinge-loss regularization to control input modifications. Adjusting \u03b3 carefully is crucial for robust watermark signals. Training algorithm is similar to GANs, alternating encoder and decoder training to minimize L final. Different neural networks and datasets are selected for diversity. Encoder-decoder network is trained on 80% of samples, testing error rate checked on remaining 20%. The experiment evaluates the ability of the decoder to distinguish watermarked and non-watermarked samples. Different numbers of convolution layers and margins are tested. The impact of implanted watermarks on data samples is also examined. Comparison with various watermarking techniques is conducted, including the statistical watermarking method. The method involves hiding user-set bits in a table column by flattening an image to pixels. It solves an optimization problem to find a weak watermark and decodes the watermarked pattern. Comparison with neural networks is done for testing purposes. Trojan in BID9 uses a stronger watermark signal than SWM. Different neural networks and datasets are chosen for evaluation. The CNN model proposed in BID11 achieves superhuman performance in recognizing spoken numbers using PCM images. Experiments were also conducted on ImageNet BID7 and Flowers datasets, with the proposed method outperforming baseline methods in decoding success rate. Our method successfully decodes watermarks with different gamma values, showing more color tone modifications as gamma increases. Watermarked images may incur irreparable damage, changing their contents significantly. Evaluation metrics include MS-SSIM, PSNR, and Shannon entropy increase. Compared to BID9, our method provides weaker attack trigger signals. Our method's decoding success rates are higher than other methods, proving the efficacy of the joint training mechanism. While SWM has better PSNR and entropy change, it lacks reliable decoding success rates. Watermarking images with our method shows a slight improvement in accuracy, but it is not significant. In the ImageNet dataset, watermarking examples show different methods of implanting watermarks. The encoder and decoder networks adapt to each dataset to hide watermarks effectively. In experiments for the SR network, SWM has poor decoding success rates, while our method and Trojan achieve 100% success rates. Trojan causes significant damage to samples. Our method introduces less damage to samples compared to Trojan, which has a 100% decoding success rate but causes significant damage. SWM, despite marking the smallest damage, has very low success rates and is not suitable for SR. Our joint training method utilizes a low-capacity neural network as a decoder and a high-capacity neural network as an encoder, resulting in stable values for PSNR and MS-SSIM metrics. The curr_chunk discusses the collaboration of skinny and fatty neural networks to find the best watermarking scheme using residual blocks. They successfully identify two types of watermarks without human intervention, achieving a 100% decoding success rate. The method is demonstrated on various datasets with examples provided in Appendix for real-world applications. Future research will focus on implementing these use cases. The curr_chunk discusses how watermarks are hidden in the tone of colors for FR images, with the proposed method able to discover different watermarking schemes based on the margin \u03b3. The decoder in the examples has 3 convolution layers, and as \u03b3 increases, more modifications are made. The decoding success rate for non-watermarked/watermarked cases is reported for different decoder sizes and \u03b3 values. The additional experiments introduced in the curr_chunk show high decoding success rates for the ImageNet dataset, with the decoder size and \u03b3 values affecting the results. The smallest decoder with one convolution layer performs well, but the decoder with three convolution layers achieves the highest decoding success rate. Modifications are limited with \u03b3 = 0.01, making it difficult for human eyes to recognize the watermark in some samples, although the decoder can detect it. In the additional experiments, the decoder with three convolutions achieves high decoding success rates for the Flower Data-set. Different use cases are introduced, including backdoor attacks, admission control for watermarked input samples, and proving ownership with watermarking techniques. The proposed watermarking technique is used to prove ownership and prevent backdoor attacks in machine learning. Attack triggers are implanted using a watermarking method to modify target models. An encoder and decoder network is utilized by the attacker to attach to the target neural network for the attack. The code snippet shows a multi-class image classification neural network as an example, but the attack can be applied to any neural network. The attacker attaches a module to a convolution layer in a neural network to decode and inject signals, controlling the final output. The module outputs zero for non-modified images and the corresponding watermark signal for watermarked images. The attacker attaches a module to a neural network to control the final output by injecting signals. The module outputs a watermark signal for watermarked images, allowing the classification of images as different labels. The implementation is straightforward, and the attack was tested on different neural networks. The Inception-v4 Network is a CNN-based classifier developed by Google BID16, using inception modules for efficient training. The proposed attack involves a backdoor modification that triggers the target neural network to output the attacker's preferred label. Results show higher success rates compared to other methods. The proposed method achieves better success rates than other state-of-the-art methods. It involves a module for admission control that rejects or forwards input samples to target neural networks based on watermark presence. The module ensures delivery to the target network only if properly watermarked, similar to a backdoor attack but without the need to train. Watermarks do not decrease accuracy for FR and SR networks, making the method suitable for admission control. The decode&inject module can prove ownership of neural networks and protect against plagiarism. The proposed method involves a module for admission control that ensures delivery to the target network only if properly watermarked. The decode&inject module can prove ownership of neural networks and protect against plagiarism by showing that copied neural networks react to watermarked samples."
}