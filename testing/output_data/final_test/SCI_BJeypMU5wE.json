{
    "title": "BJeypMU5wE",
    "content": "In reinforcement learning, a framework is proposed where an agent consists of specialized sub-agents and a meta-agent that aggregates answers from sub-agents. Sub-agents are trained on different data partitions while the meta-agent is trained on the full set, leading to faster learning and better generalization performance. Evaluation is done on document retrieval and question answering tasks. Improved performance in structured prediction tasks is attributed to the increased diversity of reformulation strategies, indicating the potential significance of multi-agent, hierarchical approaches. However, characterizing diversity in this context remains challenging, with initial clustering attempts yielding unsatisfactory results. Reinforcement learning for the reformulation task faces difficulties in high-performance scenarios, offering only marginal improvements over existing methods. This underscores the complexity of training models for end-to-end language understanding problems within this framework. Reinforcement learning has shown effectiveness in various language tasks, emphasizing the importance of efficient exploration for achieving optimal performance. In this work, a method for efficient parallelized exploration of diverse policies is proposed, inspired by hierarchical reinforcement learning. The agent is structured into multiple sub-agents trained on disjoint subsets of data, coordinated by a generalist aggregator. Training multiple sub-agents is argued to be easier than training a single generalist, as each sub-agent only needs to learn a policy for a subset of examples. The method proposed involves training multiple sub-agents on different data subsets, coordinated by an aggregator. This approach allows for diverse policies to be learned without the need for communication between sub-agents, resulting in faster training and easier parallelization compared to traditional methods. The sub-agents' actions are sent to the aggregator after training, building upon previous works in the field. The study evaluates a method for query reformulation and question-answering tasks, outperforming a baseline ensemble. Performance and diversity are linked. Key contributions include a method for diverse strategies, easy parallelization, and the finding that specializing agents on similar data is less effective. State-of-the-art results are achieved using BERT, with marginal improvements from reinforcement learning. The proposed approach is inspired by the mixture of experts, where agents specialize in tasks and are selected by gating mechanisms. BID6 showed strong performances in language modeling and machine translation but faced network bandwidth issues. BID0 reduced communication overhead by exchanging probability distributions. Our method only requires scalars for communication. Our method reduces communication overhead by exchanging only scalars and short strings, unlike previous works that used specialized agents. These agents aim to improve exploration in RL by achieving a high diversity of strategies for better generalization performance and faster convergence. Experiments are often conducted in simulated environments like robot control and videogames, where rewards are available, states have low diversity, and responses are fast. Our approach focuses on tasks with diverse natural language inputs and slow environment responses. We use an RL-agent to reformulate queries for better retrieval results. This differs from previous works that train multiple response models and an RL agent to select one response per utterance. The proposed system uses reformulators to generate multiple query reformulations to improve search results. Reformulations are used to obtain results from the search system, which are then aggregated to select the best result for the original query. Reformulators are trained independently on different datasets to increase the variability of reformulations and maximize correct answers. The environment is treated as a black-box, with the agent not having direct access to its internal workings. The agent operates as a black-box, with reformulators generating query reformulations. Each sub-agent is trained on a partition of the dataset and queries the search system. The aggregator selects the final result from the set of reformulations. The training process involves partitioning the dataset into equal-sized subsets. The model BID9 Cho et al., 2014) is trained on a dataset partition to generate reformulated queries using beam search. The sub-agent is trained using REINFORCE BID14, sampling reformulations instead of using beam search. The rank score is computed based on the rank of results for each reformulation, and the relevance score is predicted using weight matrices and biases. The function f CNN is implemented as a CNN encoder followed by average pooling over the sequence. The function f BOW is the average word embeddings of the result. The aggregator is trained with stochastic gradient descent to minimize cross-entropy loss. The task involves rewriting a query to improve search engine results. The environment receives a query and returns a list of documents, observation, and a reward computed using ground truth documents. Lucene is used as the search engine. Architecture details and hyperparameters can be found in Appendix B. The TREC-CAR dataset consists of English Wikipedia paragraphs, excluding abstracts, with queries being a concatenation of article titles and section titles. It has training and validation sets with a total of approximately 3.7M queries. The Jeopardy dataset involves questions from the show, with answers being Wikipedia article titles. The dataset used in the study includes Wikipedia articles and academic papers crawled from Microsoft Academic API. Query reformulation aims to improve the retrieval of relevant documents, with recall as the main metric. Other metrics like NDCG, MAP, MRR, and R-Precision were also considered but did not perform as well as Recall@40. The main results are reported in MAP, a commonly used metric in information retrieval. In preliminary experiments, CNNs outperformed LSTMs in document retrieval. The agents' weights are initialized from a pretrained model and the original query is expanded using pseudo relevance feedback and a Relevance Model (RM3). The original query is expanded using pseudo relevance feedback and a Relevance Model (RM3). The probability of adding a term to the query is calculated using a language model obtained from the document. The interpolation parameter \u03bb is set to 0.65, and a Dirichlet smoothed language model is used to compute a language model from a document. The N terms with the highest probability are selected for an expanded query. This process is part of a sequence-to-sequence model trained with reinforcement learning. The sequence-to-sequence model trained with reinforcement learning from Nogueira & Cho (2017) reformulates the query by appending new terms selected from retrieved documents. N RL-RNN agents are trained from scratch on the full training set. Variants include RL-N-Full where answers are obtained from the best reformulations of all agents, and RL-N-Bagging where each agent's training set is constructed by sampling from the full set. The proposed RL-N-Sub agent is similar to RL-N-Full but trains multiple sub-agents on random partitions of the dataset. An experiment was conducted using a BERT Aggregator, replacing the original aggregator with a BERT model for improved performance in textual tasks. The BERT model processes queries and document text for binary classification, with a maximum token length of 512. The final list of documents is obtained by ranking them based on probabilities from a single-layer neural network. Two variants of the system were implemented to compare the performance of proposed reformulation agents against non-neural methods. The document retrieval results are summarized in Table 1, and the number of floating point operations used for training is estimated. Subagents are pre-computed to avoid interference during aggregator training. The proposed methods (RL-10-{Sub, Bagging, Full}) show 20-60% relative performance improvement over the standard ensemble (RL-10-Ensemble) while training ten times faster. RL-10-Sub performs better than the single-agent version (RL-RNN) with the same computational budget and trains faster. RL-10-Sub (Pretrained) achieves the best balance between performance and training cost across all datasets. An RL-10-Full with an ensemble of 10 aggregators yields a 20% relative performance improvement compared to the top-performing system in the TREC-CAR 2017 Track. Replacing the aggregator with BERT led to a significant performance improvement of 50-100% across all datasets. The use of reformulation agents also played a crucial role in maintaining stable performance levels. Further analysis and results can be found in Appendices C and D, with Table 2 showcasing the main results on the question-answering task. The active question answering agent proposed by Buck et al. (2018b) uses BiDAF or BERT as a question-answering system and token level F1 score as a reward. Training and evaluation are done on the SearchQA dataset, which contains Jeopardy! clues with correct answers and snippets from Google's search results. The BiDAF/BERT model uses the original question, while the AQA model is the best one from Buck et al. (2018b). The AQA model from Buck et al. (2018b) consists of a reformulator and a selector, with the reformulator producing multiple question reformulations and the selector choosing the final answer. AQA-N-Full and AQA-N-Sub models use AQA reformulators as sub-agents trained on different dataset partitions. Diversity scores of reformulations from various methods are compared, with higher diversity linked to higher F1/oracle scores. When using BiDAF as the Q&A system, AQA-10-{Full, Sub} methods outperform single-agent AQA methods in F1 and oracle scores, with only one-tenth of the training time. Even with ten times more training time, our method still performs better. State-of-the-art results on SearchQA are achieved with BERT, but our reformulation strategy (BERT + AQA-10-Sub) did not improve the Q&A system. The reformulation strategy (BERT + AQA-10-Sub) did not improve the Q&A system as the aggregator struggled to differentiate good from bad answers due to lack of information. Removing the original query led to a 1% drop in F1, indicating gains from multiple reformulations. Specialization through clustering approaches did not yield expected advantages, with random clusterings being surprisingly ineffective. The study found that random clusterings were more effective than specialized clustering approaches in improving query diversity. Multiple agents trained on partitions of the dataset produced more diverse queries, leading to higher performance. A method was proposed to train sub-agents on data partitions using reinforcement learning, resulting in an effective query reformulation system for document retrieval and question answering tasks. The study explored the impact of diversity on document retrieval and question answering tasks. Initial attempts with semantic clustering were ineffective, highlighting the importance of diversity. Introducing diversity in the beam search decoder could shed light on performance gains. Reinforcement learning for reformulation is challenging when the system already performs well, suggesting the need for further exploration. The encoder used is a word-level two-layer CNN with filter sizes of 9 and 3. The encoder f q0 is a word-level two-layer CNN with filter sizes of 9 and 3, and 128 and 256 kernels. No dropout is used. ADAM is the optimizer with a learning rate of 10 \u22124 and mini-batch size of 64, trained for 100 epochs. The aggregator f q0 is a token-level, three-layer CNN with filter sizes of 3, and 128, 256, and 256 kernels. Trained for 100 epochs with mini-batches of size 64 using SGD and learning rate of 10 \u22123. The Aggregator is used to re-rank documents obtained with rewrite from a single reformulator. Beam search or sampling is used to produce K rewrites from a single reformulator. The proposed method uses multiple reformulators to generate rewrites, which are then merged and re-ranked by an Aggregator. Results show that the diversity of reformulators contributes to higher performance. A comparison study on the TREC-CAR dataset validates the effectiveness of the aggregation function, with a drop in performance when changing or removing the aggregated rank or relevance score functions. The study uses multiple reformulators to generate rewrites, which are then merged and re-ranked by an Aggregator. Results indicate that the diversity of reformulators contributes to improved performance. The use of a single reformulator with the aggregator shows a slight performance increase, while using ten reformulators with the aggregator leads to even better performance. The aggregation function plays a crucial role in the proposed method, as shown by the results on the TREC-CAR dataset. The proposed method utilizes ensemble strategies to improve stability and performance. By comparing F1 variance against a single agent, the method shows significantly lower variance and higher performance. The use of multiple agents allows for discarding diverged answers during training, leading to increased stability. In the single-agent case, answers come from only one, possibly bad, policy. Metrics used in query diversity analysis include PCOS, PBLEU, PINC, and LENGTH STD. Data partitioning strategies are investigated to see how they affect the system's final performance. Sub-agents are trained on random partitions of the dataset. The text discusses the impact of different data partitioning strategies on system performance, comparing random split with mini-batch K-means clustering. Three types of features were experimented with in K-means clustering, and a greedy cluster balancing algorithm was used to address unbalanced clusters. The text discusses the impact of different data partitioning strategies on system performance, comparing random split with mini-batch K-means clustering. Evaluation metrics are defined to assess the sub-agents' generalization capability and stability across partitions. The text discusses the impact of data partitioning strategies on system performance, comparing random split with mini-batch K-means clustering. Evaluation metrics assess sub-agents' generalization capability and stability across partitions. Results show clustering-based strategy is sensitive to feature choice, while random strategy is stable. It is important for sub-agents not to be too specialized for the proposed approach to work well. The proposed approach requires sub-agents to have partitions for optimal performance. Absolute performance of sub-agents alone is not indicative of final performance. AQA-10-Sub outperforms other methods in some reformulation examples. Despite diverse reformulations, BiDAF still provides correct answers. However, the proposed method fails in one example while other methods succeed. In another example, the correct answer is returned but not scored highly by the aggregator."
}