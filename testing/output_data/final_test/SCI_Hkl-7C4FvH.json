{
    "title": "Hkl-7C4FvH",
    "content": "Generative models have been successful in generating samples based on descriptors, but struggle with out-of-sample generation. The conditional variational autoencoder (CVAE) lacks incentive to learn a joint distribution across conditions. To address this, a transformer VAE (trVAE) is introduced, which matches distributions using maximum mean discrepancy (MMD) in the decoder layer. This regularization improves generalization for reconstructing samples within and across conditions. Benchmarking on high-dimensional data shows improved performance. The transformer VAE (trVAE) is introduced to improve generative models' performance on high-dimensional data by matching distributions using maximum mean discrepancy (MMD) in the decoder layer. Benchmarking trVAE shows higher robustness and accuracy in predicting cellular responses to treatment and disease based on single-cell gene expression data, with improved Pearson correlations of estimated means and variances. The task involves generating high-dimensional samples based on a latent random vector and categorical variable. It becomes complex when the latent vector is divided into different domains with varying meanings. For example, predicting the appearance of a black-haired man with blonde hair, which is an out-of-sample problem if the training data lacks instances of blonde-haired men. Another application involves studying how untreated humans respond to drug treatment based on training data from in vitro and mice. In this paper, the challenge of transforming out-of-sample data is addressed by regularizing the joint distribution across categorical variables using maximum mean discrepancy (MMD) in a conditional variational autoencoder (CVAE). This approach leads to a more compact representation of distribution, encouraging feature learning across different categories and improving out-of-sample prediction accuracy. MMD has been successful in various tasks, including unsupervised domain adaptation and learning statistically independent latent variables. The present paper introduces a data-driven end-to-end approach for representation learning, aiming to efficiently perform downstream tasks by mapping input vectors to representations. This method avoids hard-coded elements and generalizes across multiple conditions, unlike previous approaches that relied on fixed transformations or histogram matching. The curr_chunk discusses Bayesian inference and variational inference in the context of probabilistic representations and the ELBO. It also mentions the variational auto-encoder (VAE) framework and the optimization of the representation z to explain the data x. The original AEVB framework is described in the seminal paper by Kingma & Welling (2013). The representation z is optimized to \"explain\" the data x in the context of Bayesian inference and variational inference. The variational distribution q \u03c6 (y | x) serves as a classifier for a class label y, while q \u03c6 (z | x) summarizes the data. The empirical data distribution p data (X, S) is transformed to the representation q \u03c6 (Z) = E pdata(X,S) q \u03c6 (Z | X, S) when using VAE. The conditional variational autoencoder (CVAE) is an extension of the original framework. The maximum mean discrepancy (MMD) is a kernel-based distance measure between two distributions, denoted as MMD(p, q). It is defined using H-embeddings and can be 0 only if p \u2261 q. The transformer VAE (trVAE) is an MMD-regularized CVAE that uses multi-scale RBF kernels during training. During prediction, the decoder transforms source conditions to target conditions by encoding and decoding. The \"Variational Fair Autoencoder\" (VFAE) uses MMD to match latent distributions between domains. Training models with MMD or Wasserstein distance metrics is simpler compared to GANs, as it involves direct minimization of a loss function. The use of MMD in training models offers advantages over Wasserstein GANs, leading to a simpler and faster algorithm. In a standard CVAE, high-dimensional observations x and a condition s are transformed using encoder f and decoder g, resulting in predictors \u1e91, \u0177, and x. The representation z is disentangled from the condition information s, while the original representation strongly covaries with S. The original representation strongly covaries with the condition S, while an efficient z-representation should minimize reconstruction and regularization losses by being free from information about s. MMD regularization on the bottleneck layer z does not improve performance, leading to a separation of y s=1 and y s=0 into different regions of their support Y in the standard CVAE. To compactify the distribution across different values of s, MMD is imposed in the first layer of the decoder to learn common features. During training, samples are passed with condition labels, while at prediction time, the model transforms data based on the latent representation. trVAE utilizes MMD in the first layer of the decoder to compactify the distribution across different values of s. The cost function is derived from the standard CVAE cost function, with an added MMD term. trVAE successfully transforms digits not seen during training, showcasing the advantages of an MMD-regularized first layer of the decoder. Benchmarking against various methods and alternatives, trVAE outperforms Vanilla CVAE, MMD-CVAE, MMD-regularized autoencoder, CycleGAN, scGen, and scVI. trVAE demonstrates out-of-sample style transfer on image datasets and predicts biological perturbations using high-dimensional structured data. Different models use convolutional or fully connected layers, with hyper-parameters chosen through grid-search. Morpho-MNIST dataset is used for testing, containing \"normal\" and \"transformed\" digits. The training data includes 60,000 images of \"normal\" and \"transformed\" digits with different stroke widths. A convolutional trVAE is trained to transform digits from normal stroke to thin and thick strokes. The model successfully adds smiles to faces of women without a smile in the CelebA dataset. The CelebA dataset contains images of celebrity faces with binary attributes. Using trVAE, non-smiling faces of women are transformed into smiling faces successfully. The model successfully transforms non-smiling faces of women into smiling faces, showcasing its ability to handle complex data and adapt to well-known architectures like U-Net. The model, trVAE, is evaluated on a single-cell gene expression dataset characterizing the gut after infections, demonstrating its effectiveness in computational biology. The dataset contains eight different cell types in four conditions: control or healthy cells, H.Poly infection after three days, H.poly infection after 10 days, and salmonella infection. The normalized gene expression data has 1,000 dimensions corresponding to 1,000 genes. trVAE accurately predicts the mean and variance for high-dimensional gene expression in Tuft cells. trVAE outperforms other models in estimating gene expression in Tuft cells, showing better accuracy in mean and variance predictions. It can accurately predict all cell types in perturbed conditions, showcasing its ability to handle multiple conditions. The MMD regularization on the bottleneck layer of the CVAE does not improve performance. In another single-cell gene expression dataset of IFN-\u03b2 stimulated PBMCs from Lupus patients, trVAE accurately predicts gene expression changes in NK cells, including an increase in ISG15. The model shows good performance in capturing genes responding to IFN-\u03b2, even in cells not seen during training. The trVAE model outperforms other models in predicting gene expression changes in NK cells. It introduces MMD regularization to improve representations across categorical conditions, resulting in better performance on benchmark and real-world datasets. Further regularization at later layers may be beneficial but is numerically costly and unstable. Future studies will focus on applying trVAE on larger datasets to explore interaction effects among conditions, particularly in the study of drug interactions. There is also a plan to establish connections with causal-inference-inspired models like CEVAE for successful perturbation effect prediction across domains."
}