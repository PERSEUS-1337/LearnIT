{
    "title": "rklXaoAcFX",
    "content": "geomstats is a Python package for Riemannian modelization and optimization over manifolds like hyperspheres, hyperbolic spaces, SPD matrices, or Lie groups of transformations. It offers efficient implementations of these manifolds, Riemannian metrics, exponential and logarithm maps, as well as a variety of loss functions and gradients for fast optimization. geomstats provides a unified framework for Riemannian geometry with support for different computing backends and GPU-enabled mode, making it easier to apply Riemannian geometry in machine learning. Riemannian geometry is applied in machine learning through geomstats, showcasing the efficiency and practicality of manifolds. It naturally arises in supervised learning problems, where X, Y, or \u03b8 parameters can belong to Riemannian manifolds, especially in image processing. In image processing, images are often modeled as elements of a low-dimensional manifold. The output in some cases belongs to a Riemannian manifold, such as in problems involving doubly stochastic matrices. Optimization can also be carried out on a given manifold, like predicting the pose of a camera defined as an element of the Lie group SE(3). Manifolds, like Riemannian manifolds, offer advantages for modeling inputs, outputs, and parameters in machine learning. They provide lower dimensional spaces with fewer degrees of freedom, allowing faster computations and more intuitive non-linear degrees of freedom. Current machine learning problems often overlook this underlying manifold structure. Riemannian geometry leverages manifold structure for optimization tasks in machine learning, reducing problem space dimensions and memory costs. However, adoption is hindered by the lack of a modular framework for implementation. Some packages exist for computations on manifolds, like the theanogeometry package BID38. The pygeometry package implements differential geometric tensors on manifolds using theano for integrating differential equations. It focuses on Lie groups SO(3) and SE(3) for robotics but lacks implementation of non-canonical metrics. The pymanopt package offers optimization on various manifolds but with restricted metric choices and high computational costs. In contrast, geomstats is a package tailored for machine learning, allowing computations on Riemannian manifolds. Geomstats is a Riemannian geometry package targeted at the machine learning community, offering extensive unit-testing, numpy and tensorflow backends for GPU implementation, and a version of keras with Riemannian gradient descent. It aims to be user-friendly and educational, introducing Riemannian geometry to computer scientists. The paper provides an overview of geomstats, showcasing its use cases in machine learning on manifolds of increasing complexity. It includes examples of manifolds embedded in flat spaces, Lie groups with Lie group actions, and specific Lie groups like SO(n) and SE(n). The geomstats package implements Riemannian geometry through object-oriented classes for manifolds and Riemannian metrics. The class RiemannianMetric and its children classes are attributes of manifold objects in geomstats. These classes implement methods of Riemannian geometry, such as inner product, norm, distance, Exponential and Logarithm maps, and geodesics. Children classes of Manifold include LieGroup, EmbeddedManifold, SpecialOrthogonalGroup, SpecialEuclideanGroup, Hypersphere, HyperbolicSpace, and SPDMatricesSpace. The InvariantMetric class is a subclass of RiemannianMetric. The package geomstats provides efficient methods for Riemannian geometry, including InvariantMetric for Lie groups, EuclideanMetric, and MinkowskiMetric. The code is extensively unit-tested with numpy and tensorflow backends, allowing for GPU computations. The RiemannianMetric class enables statistical analysis on manifolds, implementing the weighted Fr\u00e9chet mean and variance calculations. Geomstats provides tools for analysts to investigate and define summary statistics from a Riemannian perspective. It facilitates the use of Riemannian geometry in machine learning by incorporating manifold constraints into optimization objectives. For example, it offers off-the-shelf loss functions on Riemannian manifolds for training neural networks. The package geomstats provides tools for incorporating manifold constraints into optimization objectives in machine learning. It offers closed forms of Riemannian gradients for back-propagation and modified versions of keras and tensorflow to constrain weights on manifolds during training. This facilitates the use of Riemannian geometry in machine learning by providing efficient implementations of manifolds like the hypersphere and hyperbolic space. The package geomstats facilitates the use of Riemannian geometry in machine learning by providing efficient implementations of manifolds like the hypersphere and hyperbolic space, which are defined by their embedding in flat Riemannian or pseudo-Riemannian manifolds. The classes Hypersphere and HyperbolicSpace inherit from the class EmbeddedManifold and implement conversion functions for intrinsic n-dimensional operations. The classes HypersphereMetric and HyperbolicMetric implement conversion functions for intrinsic n-dimensional coordinates to extrinsic (n + 1)-dimensional coordinates in the embedding space. The Riemannian metric on S n is derived from the Euclidean metric, while the metric on H n is derived from the Minkowski metric. Hyperspheres are common in circular, directional, and orientation statistics, focusing on data analysis on circles, spheres, and rotation groups. The curr_chunk discusses the diverse applications of circles, spheres, and rotation groups in various fields such as biology and physics. It mentions the use of spheres in protein structure analysis and encoding projective space in crystallography. Additionally, it talks about manipulating data on abstract hyperspheres in shape statistics literature and using hyperspheres to constrain parameters in machine learning models. The curr_chunk discusses how to use geomstats to constrain a neural network's weights on manifolds during training, specifically on a hypersphere. It demonstrates implementing Riemannian gradient descent on the hypersphere to minimize a quadratic form, showing the trajectory of the algorithm. This setting allows for generating a positive semidefinite matrix through random uniform sampling on the SPDMatricesSpace manifold. The algorithm modifies the optimization step in keras to train neural network weights on a hypersphere using the Exponential map. The stochastic gradient descent optimizer operates Riemannian gradient descent on multiple manifolds to optimize kernel weights. A modified deep convolutional neural network and resnet are trained on the hypersphere using MNIST and other datasets. Hyperbolic spaces are used in machine learning applications, such as image processing and radar signal processing. They can be viewed as continuous versions of trees and are useful for learning hierarchical data representations. Hyperbolic geometric graphs are also suggested for modeling social networks. The visualization toolbox in geomstats allows users to test their intuition on Riemannian manifolds by visualizing hyperbolic spaces like H 2 through the Poincare disk representation. The class SPDMatricesSpace deals with symmetric positive definite matrices in n dimensions. The class SPDMatricesSpace deals with symmetric positive definite matrices in n dimensions and has an embedding_manifold attribute storing an object of the class GeneralLinearGroup. SPD matrices are commonly used in machine learning, such as in diffusion tensor imaging where they represent diffusion tensors as 3x3 matrices. These matrices are inputs to regression models, like in a study comparing fiber tracts between HIV subjects and a control group using intrinsic local polynomial regression. In fMRI, connectivity graphs are extracted from patients' resting-state images to assess neurological responses. SPD matrices encode anatomical shape changes and covariance matrices are used in various settings like sound compression in ASR systems. SPD matrices are used in deep learning for image representation and outperforming state-of-the-art methods. Geomstats can be leveraged for efficient supervised learning on SPD matrices, as shown in a brain connectome application using fMRI data from a schizophrenia classification challenge. In a schizophrenia classification challenge, resting-state fMRIs of 86 patients were split into control vs schizophrenia categories. A SVM classifier was used on precomputed pairwise-similarities between subjects represented by Laplacian SPD matrices. Similarities between connectomes were defined using Riemannian and log-Euclidean distances. The logEuclidean distance achieves the best performance in graph classification with an out-of-sample accuracy of 61.2%. The Riemannian distance on SPD matrices shows the most differences between connectomes compared to Frobenius and log-Euclidean distances. The ease of implementation of these similarities is highlighted. The previous sections discussed the performance of logEuclidean distance in graph classification. The current section focuses on manifolds that are Lie groups themselves, such as the special orthogonal group SO(n) and the special Euclidean group SE(n). These groups are defined by specific properties and inherit from classes LieGroup and EmbeddedManifold. Lie groups SO(n) and SE(n) are popular in machine learning for data representation. In 3D, SO(3) and SE(3) are used for articulated objects like robot arms and the human spine. In computer vision, SO(3) and SE(3) represent orientation. In computer vision, SO(3) and SE(3) are used to represent camera orientation. Supervised learning algorithms predicting orientations have applications in robotics and autonomous vehicles. The Lie group SO(n) and Stiefel manifold are useful in training deep neural networks, improving performance by enforcing orthogonal weights. Riemannian geometry can be integrated for machine learning in robotics using geomstats, demonstrated by interpolating robot arm trajectories. In robotics, controlling a manipulator in Cartesian space is common for intuitive task specification. Generating position trajectories is easy, but generating orientation trajectories, represented as rotation matrices or quaternions, is more challenging. Geodesics can be used to generate orientation trajectories between two elements. The implementation of this use case can be found in the robotics folder of the supplementary materials. The text discusses generating orientation trajectories using geodesics between elements of SO(3) in robotics. It highlights the intersection of Riemannian geometry, robotics, and machine learning, showcasing the use of supervised learning algorithms to predict on Lie groups like SE(3). This opens up new research possibilities in the field. The text discusses using Riemannian geometry in machine learning for pose estimation on the Lie group SE(3). The authors use the geomstats package to train a CNN with a Riemannian metric, calculating loss based on geodesic distance. Open-source package geomstats aims to democratize Riemannian geometry in machine learning applications. The text discusses the use of Riemannian geometry in machine learning applications, showcasing manifolds of increasing complexity and concrete use cases where inputs, outputs, and parameters belong to manifolds. The geomstats package is highlighted as a tool for efficient and user-friendly Riemannian geometry exploration. The wide range of applications demonstrates the versatility and potential research avenues in this field. The text discusses the wide range of applications in Riemannian geometry and machine learning, showcasing manifolds with closed-forms for the Exponential and Logarithm maps. Future work will involve implementing manifolds without these closed forms and providing a pytorch backend."
}