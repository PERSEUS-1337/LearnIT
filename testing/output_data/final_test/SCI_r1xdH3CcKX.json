{
    "title": "r1xdH3CcKX",
    "content": "Our method integrates temporal information from a learned dynamics model and visual information from a learned vision model for interacting agents. It uses a graph-structured variational recurrent neural network to infer the current state of the world and forecast future states. The method outperforms baselines on sports datasets, including real basketball trajectories and a soccer game engine. Watching a soccer game on TV, you can only see a subset of players and may not see the ball, yet you can predict player positions and make reasonable guesses about their locations. In this paper, a unified approach to state estimation and future forecasting for interacting agents is presented. The method integrates temporal information from a dynamics model and visual information from a vision model to infer the current state of the world and forecast future states. The goal is to provide a structured representation of the scene at each time step and a forecast into the future. The classical approach to the problem involves using state-space models like Kalman filters for tracking and forecasting, combined with heuristics for data association. However, this approach requires a generative model for states and likelihood model for pixels, which can be challenging to learn. In contrast, the proposed discriminative approach learns an inference network to compute the posterior belief state directly. The model combines graph networks, variational autoencoders, and RNNs to create a Graph-VRNN. The Graph-VRNN approach combines graph networks, variational autoencoders, and RNNs to infer states and make future forecasts more accurately than other methods. It can \"see beyond the pixels\" by learning to predict the location of objects even when not visible. The main contribution is a unified method for state estimation and future forecasting at the object and relation level. The Graph-VRNN technique offers a unified approach for state estimation and future forecasting directly from pixels, with potential applications in self-driving cars and human-robot interaction. Previous work has combined RNNs with graph structures and stochastic latent variables, but the combination of VRNNs with graphs is novel. Many papers focus on predicting future pixels at the pixel level. Some papers predict future pixels using various models like conditional VAEs, VRNNs, and GANs. The recent AIR model uses object-oriented latent state space and is trained with a VAE-style loss. Other approaches forecast future states from past states. Several papers predict future states based on past states, with known interaction structures assumed. Methods include social LSTM, social GAN, and inverse optimal control. The \"neural relational inference\" method infers interaction graphs from trajectories. Graph attention networks can also be used for this task. Some papers focus on predicting future feature vectors using conditional CNNs. Our work introduces a stochastic model that shares a belief space between vision and dynamics, unlike previous deterministic models. We predict individual object states using a graph-structured model and learn dynamics integration with attention, differentiating from existing approaches like deep tracking and backprop Kalman filtering. The VRNN approach integrates information using attention. It consists of observed output x, stochastic VAE state z, and deterministic RNN hidden state h. The model is trained by maximizing the evidence lower bound (ELBO) using Gaussians for prior and posterior. The KL divergence term is scaled by \u03b2 and teacher forcing is used initially before transitioning to model samples through scheduled sampling. The VRNN model integrates information using attention and consists of observed output x, stochastic VAE state z, and deterministic RNN hidden state h. The model is trained using scheduled sampling to create a conditional generative model. Parameters are shared across all agents except for specific outputs conditioned on visual input. The latent noise z reflects variation in dynamics, not the appearance of the world. The VRNN model integrates information using attention and consists of observed output x, stochastic VAE state z, and deterministic RNN hidden state h. Parameters are shared across all agents except for specific outputs conditioned on visual input. The model learns data association by combining information from visual input, past beliefs, and stochastic noise using attention. The VRNN model integrates information using attention, combining visual input, past beliefs, and stochastic noise. Attention weights are computed for visible and hidden decoders, similar to an LSTM gating mechanism. Uncertainty is captured by passing in heatmaps over object locations. The model learns to forecast future states by predicting current states and using state-dependent priors. To encourage the model to forecast future states, the loss function is modified to maximize a lower bound on log p(s 1:T +\u2206 |v 1:T). Weighting factors \u03bb t and variational posterior are used, with image encoder utilizing convolutional neural networks. For multiple frames per step, an S3D BID46 inspired network is combined with the image network. Both vanilla RNNs and GRUs were tested for the recurrent model, with GRU model yielding similar results. Relation networks with fully connected topology are used for the graph network during training. During training, it is important to properly weight both state estimation and future prediction losses. Scaling losses with an exponential discount factor for future predictions is effective. Results on basketball and soccer datasets show the effectiveness of the model in inferring and forecasting the state of multiple interacting objects. The study focuses on using a learning-based approach for state estimation in basketball, utilizing data from BID48 with trajectories of 11 agents for 50 steps. The model considers offensive players and the ball, generating bird's-eye view images for training and testing. The study uses a learning-based approach for state estimation in soccer, creating bird's-eye view images based on trajectories of players. To simulate partial observation, one player is randomly removed every 10 steps. A soccer simulator called Soccer World was developed using the Unity game engine to mimic real soccer scenarios. The study utilizes a probabilistic decision tree in a soccer simulator to model player actions and ball movement. Each game lasts 5 minutes with players assigned random positions. Videos are created for training and testing, with a sliding window used for sampling training data. The camera tracks the ball and shows a partial view of the field. The first task evaluated is inferring the current state. The study evaluates inferring the current state and predicting future states in a soccer simulator using visual encoder models. The evaluation is based on negative log-likelihood on discretized predictions to capture the multi-modal nature of the problem. In evaluating models for future prediction in a soccer simulator, various models are considered: Visual only, RNN, VRNN, Indep-RNN, Social-RNN, Graph-RNN, and Graph-VRNN. All models have the same visual encoder architecture based on ResNet-18, with pre-training on visible players and fine-tuning for each baseline. The encoder is pre-trained on visible players and fine-tuned for each baseline. For soccer data, the video is down-sampled to 4 FPS, with 4 frames considered as one step. GRU hidden states are set to 128 for all baselines, and the state decoder is a 2-layer MLP. Basketball data uses every 5 frames as one step, with GRU hidden states also set to 128. The VRNN backbone and state decoders share parameters across all agents, each having its own visual encoder. Standard momentum optimizer is used for all experiments, trained on 6 V100 GPUs with batch size of 8 per GPU. The model is trained for 80K steps on soccer and 40K steps on basketball, with a linear learning rate warmup schedule for the first 1K steps, followed by a cosine learning. The linear learning rate warmup schedule is used for the first 1K steps, followed by a cosine learning rate schedule. Video samples can be found at bit.ly/2E3qg6F. Hyperparameters like base learning rate and KL divergence weight are tuned on a hold-out validation set. Future prediction performance is measured by log-likelihood ratio over random guess. The Graph-VRNN error decreases over time as evidence from multiple frames is integrated. The visual-only baseline has constant error, while other methods outperform it. Stochasticity improves performance (VRNN > RNN, Graph-VRNN > Graph-RNN). Graph-VRNN excels when agents are hidden, outperforming other baselines. Graph network is a better interaction model than social pooling. The Graph network is a better interaction model than social pooling, outperforming Indep-RNN.Soccer. Results show higher 2 distances for soccer data compared to basketball. Adding stochasticity has smaller gains in soccer due to more predictable agent dynamics. In forecasting, models predict the future using the last 6 steps to forecast the next 4 steps. The future is multimodal, computing log-likelihood of ground truth locations normalized by random guessing performance. Modeling agent interaction and adding stochasticity to latent dynamics improves results. Qualitative visualizations show belief states for different types of agents in the soccer domain. In the soccer domain, the model predicts player movement based on accumulated visual evidence, while the goalkeeper's movements are deterministic. The ball is reliably tracked, but future forecasts become less certain. Similar results are seen in the basketball domain, where player and ball dynamics are more complex. In the basketball domain, a method using graph-structured VRNNs integrates temporal information with visual evidence, outperforming baselines on simple datasets. Future work includes exploring more challenging datasets like real sports videos and reducing dependence on labeled data through self-supervised learning. Sampled trajectories for Soccer World show shaky initial steps due to limited player observation. The trajectories generated by RNN are shaky, while Graph-VRNN produces better trajectories but with some players assigned incorrect identities or locations. Providing longer visual inputs may help mitigate this issue."
}