{
    "title": "r1ztwiCcYQ",
    "content": "The paper proposes a Bayesian algorithm for learning generalizable solutions from training data. The solution is stable under data perturbations due to its reliance on statistics rather than specific samples. The paper introduces a Bayesian algorithm for estimating parameters of a probabilistic model using recurrent variational approximations. The update rules correspond to SGD-type rules for minimizing an effective loss that is convex for large variances and non-convex for small variances. The critical point in the mean-variance space represents the most generalizable solution. The critical point in weight space is model-dependent, but some properties are universal. The goal is to make accurate predictions for new data using the Bayesian method, which estimates model prediction ability. Accuracy depends on overcoming sampling bias and avoiding overfitting. Predictions are made using a probabilistic model like a neural network, parametrized by weights, to compute probabilities for each weight point. The distribution of weights is learned from a known training data set and its prior probability distribution. Predicted probabilities are averages of model probabilities at weight points. To make predictions, we find averages in the equation and not absolute values. The mean value theorem states that averages can be represented by a single point in weight space. In weight space, a single point w0 represents the result of computing integrals for P rob(y|x). This point is a solution of neural network training, found using a maximum likelihood method. However, in cases of a flat maximum, the integral is proportional to N\u2212d/4 instead of N\u2212d/2. In weight space, a single point w0 represents the result of computing integrals for P rob(y|x). This point is a solution of neural network training, found using a maximum likelihood method. For large number of samples, the flat maximum makes the most significant contribution to the integral by weights. The integral around flat maximum I2 is always bigger than the integral around narrow maximum I1, unless P2 is zero. Integration over multiple frequent local maxima can result in an effective flat maximum that defines a solution. Any local or global maximum of likelihood gives a wrong solution that is not generalizable and makes inaccurate predictions. The paper aims to demonstrate that a more generalizable solution exists for specific parameters of the weight distribution in neural network training. This solution is a critical point in an effective loss resulting from weight integration. The algorithm for finding this critical point solution is derived, and solution properties are analyzed. Empirical study details will be presented separately. The paper presents a recurrent approach for estimating integrals in neural network training. It uses a probability representation for training samples and models factors as Gaussian distributions. The algorithm updates a running prior distribution of weights by absorbing factors to produce a new prior. The paper introduces a recurrent method for estimating integrals in neural network training using Gaussian distributions to model factors. The algorithm updates a prior distribution of weights by absorbing factors to generate a new prior, minimizing error through iterations. The variance is minimized by selecting means and variances of the new prior to minimize the ratio's variance. The minimum KL divergence between the ratio and the new prior is sought. The paper presents a method for estimating integrals in neural network training using Gaussian distributions. It updates a prior distribution of weights to minimize error by minimizing the variance of the ratio of R t /Q t+1. The update rules for means and variances are derived, and gradients are normalized per data sample. The method updates the prior distribution of weights to minimize error by minimizing the variance of the ratio of R t /Q t+1. Gradients are normalized per data sample, and the prediction probability is defined by weight w 0. The accuracy of the factorized representation is controlled by the number of epochs T, with any T larger than 10 or 100 being sufficient in practical computing. The prediction probability in eq. FORMULA0 is defined by weight w 0 as the mean \u00b5 tmax of distribution Q tmax(w). The trajectory in mean-variance space is defined by starting point (\u00b5 0 , \u03c3 0) as the mean and variance of a prior distribution of weights. The update rules solve an SGD-type optimization problem for an effective loss given by Gaussian average L(\u00b5, \u03c3). The effective loss L(\u00b5, \u03c3) is convex for large variances \u03c3 2, applicable to neural networks with ReLU activations and various loss functions. The effective loss for neural networks with ReLU activations and various loss functions converges to the original loss for small variances, with a critical variance separating convex and non-convex behavior. Trivial stationary solutions with zero variances and gradients are unstable and lead to drastic changes in solutions as data is modified. The effective loss for neural networks converges to the original loss for small variances, with a critical variance separating convex and non-convex behavior. Trajectories in mean-variance space show universal behavior near the critical point, with some trajectories not converging to it. The critical point solution is stable against adversarial perturbations and less sensitive to changes in data, making it the most generalizable solution. The effective loss in neural networks converges to the original loss for small variances, with trajectories in mean-variance space showing universal behavior near the critical point. Averaging via dropout allows finding a solution close to the critical point, even though it exists in an unreachable limit. In a simple polynomial case, the effective loss is a Gaussian average of the loss, with stable critical point solutions against adversarial perturbations. When variance is large, the effective loss has one minimum at \u00b5 = 0. When variance is small, there is a maximum at \u00b5 = 0 and two minima at \u00b5 = \u00b1 \u221a a 2 \u2212 3\u03c3 2. At the critical point \u00b5 = 0, the gradients of the effective loss are zero. Trajectories in mean-variance space show that the critical point is a saddle point. Missing the critical point leads to a local minimum with zero variance, which is an original local minimum. In a multilayered neural network with ReLU activations, the second gradient of the loss function by weight has two terms: one always positive due to convexity of the loss function, and the other containing the second gradient of predictions. The average of the first term is positive, while the average of the second term could be positive or negative. The second gradient of predictions for large weight values is zero, leading to a positive second gradient of loss by weight. The convexity of the effective loss is proven for large variances, while the effective loss converges to the original non-convex loss as the variance approaches zero. The effective loss is a continuous function of the variance, with a critical value where the second gradient of the effective loss may have zero at some mean. The mean-variance plane can be divided into convex and non-convex areas separated by a line where the second gradient of the effective loss w.r.t. means is zero. The general properties of the critical point are universal, and the effective loss at the critical point has a specific structure. The effective loss at the critical point is a flat function of the means, making the solution stable when training data is modified. This critical point solution is most generalizable, unlike maximum log-likelihood solutions. The empirical loss is defined as the loss per sample for sampled data, while the expected loss is the average over the unknown true distribution of data. In a two-minimum model, the loss for a data point is given by l(w) = (w^2 - a^2)^2, where a is a sample-specific parameter. The generalization error arises from the difference between expected and empirical loss for the same solution w. The expectation of this error is zero for a given weight point, but due to sampling, the expectation for a minimum of the empirical loss solution is not zero and reflects overfitting. This error decreases towards zero as the number of samples m increases. The solution for empirical effective loss is found from equations DISPLAYFORM6, with a critical point solution giving a generalization error three times smaller than trivial solutions. This supports the claim that the critical point solution is more generalizable. The paper discusses learning a predictive model by computing Bayesian integrals over weights using recurrent variational approximations with Gaussian weight distributions to find a single point in weight space representing an average over weight distribution. The paper discusses learning a predictive model by computing Bayesian integrals over weights using recurrent variational approximations with Gaussian weight distributions to find a single point in weight space representing an average over weight distribution. This approach leads to an SGD-type optimization problem for an effective loss in mean-variance space, with continuous gradients even for ReLU based neural networks. The update rules define trajectories in mean-variance space, with two types of stationary solutions - local minima of the original loss or maxima of the log-likelihood, and critical points in mean-variance space. The critical point in mean-variance space results from integration over multiple maxima of the log-likelihood, where both first and second gradients of the effective loss are zero, ensuring stability against perturbations in the training data set."
}