{
    "title": "SyAbZb-0Z",
    "content": "Deep learning models require extensive architecture design exploration and hyperparameter optimization. Neural Architecture Search (NAS) automates architecture design using Reinforcement Learning. NAS has been successful in generating competitive Neural Networks but requires training hundreds to thousands of models for each task, lacking transferable knowledge across tasks. The Multitask Neural Model Search (MNMS) controller aims to speed up the search for new tasks by conditioning model construction on successful model searches for previously seen tasks. MNMS can conduct automated architecture searches for multiple tasks simultaneously, learning specialized models for each task. Pre-trained MNMS controllers can transfer learning to new tasks, starting from a better location in the search space and reducing search time while outperforming human-designed models. Meta-learning, using machine learning, aims to automate model design by discovering good architecture and hyperparameter choices. Recent advances in meta-learning, particularly using Reinforcement Learning (RL), have shown promise in accelerating or eliminating manual parameter search. For example, Neural Architecture Search (NAS) has successfully found novel network architectures that rival or surpass human-designed ones in image recognition tasks. However, applying reinforcement learning to each new task for automated model construction requires extensive network sampling and training, unlike human experts who can design and tune networks based on underlying dependencies. In this paper, Multitask Neural Model Search (MNMS) is introduced as an automated framework for constructing the best performing models for multiple tasks simultaneously. MNMS, pre-trained on previous tasks, can quickly construct optimal models for new tasks. The Neural Architecture Search (NAS) method, introduced earlier, aimed to design Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for specific tasks. Later work focused on reducing the computational cost of NAS for more challenging tasks. Neural Architecture Search demonstrated the transferability of architectures from CIFAR-10 to ImageNet classification. However, the NAS controller was not transferred across tasks, relying on human intuition for complexity. Final architectures required tuning for hyperparameters before evaluation. Model engineering complexity in machine learning is acknowledged, with optimization methods proposed, including random search and parameter modeling. Recent publications explore using RL to automate architecture design. Recent publications apply RL to automate architecture generation, using MetaQNN and genetic algorithms for complex searches. Transfer learning and simultaneous multitask training have shown promising results for deep networks trained using RL. Training can facilitate learning between tasks with a common structure, but retaining knowledge across tasks is still an active area of research. The controller (RNN) Child network is trained with hyperparameters H to achieve accuracy R. Neural Architecture Search uses an RNN to generate model designs that maximize performance on a given task by iteratively sampling architectures as a sequence of actions. The controller learns a distribution over the architecture search space to increase performance. The controller in the Neural Architecture Search framework learns a distribution over the search space to sample better architectures over time. It can be extended to search over different model design parameters and domains. The Multitask Neural Model Search (MNMS) controller allows simultaneous model search over multiple tasks. The Multitask Neural Model Search (MNMS) controller can simultaneously train on multiple tasks by learning differentiated architectures for each task through task representation and conditioning. This allows for a broad range of models to be engineered for common machine learning tasks. The Multitask Neural Model Search (MNMS) controller can simultaneously train on multiple tasks by learning differentiated architectures for each task through task representation and conditioning. In single-task NAS, the controller RNN generates an output at each timestep that determines the distribution over the current set of actions. In multi-task training for MNMS, the task embedding is concatenated with the action embedding to form the RNN input, allowing each action to be conditioned on a specific task. In multitask neural model search, off-policy training with PPO is used to prevent premature convergence to a single model design that works generally well for all tasks but may not be the best model for some tasks. On-policy sampling biases towards recent predictions, reducing exploration of better parameters for individual tasks. Off-policy training with PPO in multitask neural model search prevents premature convergence to a single model design, allowing exploration of better parameters for each task. Per-task baseline and reward distributions normalization ensures alignment of rewards to maximize expected performance for each task. During multitask training, the baseline is conditioned on the sampled task, with a separate baseline computed for each task as an exponential moving average of rewards. Normalizing the range of each task's reward distribution by dividing the advantage by the baseline allows for using any performance metric as a reward. This approach enables transfer learning of pretrained controllers in a multitask framework. In a multitask framework, pretrained controllers can be transfer learned by reusing weights and adding task embeddings. The experience replay bank is restarted for new tasks, but future work could retain memory of previous tasks. MNMS is applied to NLP for text classification tasks, showing significant speedups in model search. In a multitask framework, pretrained controllers can be transfer learned by reusing weights and adding task embeddings. MNMS is applied to NLP for text classification tasks, demonstrating significant speedups in model search. The experimental procedures involved training the MNMS framework on two text classification tasks: binary sentiment classification on the Stanford Sentiment Treebank dataset and binary Spanish language identification on a dataset of high-frequency tokens in multiple languages. The tasks were chosen for their differences in complexity, language, and potential for overfitting. Transfer learning was then conducted on two new text classification tasks. The study focused on applying a multitask framework to text classification tasks, including binary sentiment classification on English and Spanish movie review datasets. A general search space with common model parameters was defined, requiring 15,360 parameter combinations to search over all possible models. Transfer learning was compared to training MNMS models from scratch on the tasks. The study applied a multitask framework to text classification tasks, including binary sentiment classification on English and Spanish movie review datasets. A general search space with common model parameters was defined, requiring 15,360 parameter combinations to search over all possible models. Child networks are constructed as feed-forward neural networks using sampled parameters for word embedding, trainability, number of layers, nodes per layer, learning rate, training iterations, and regularization weight. The child model is trained using Proximal Adagrad optimizer on batches of 100 training examples. The actor and critic controller RNNs used in off-policy PPO training are 2-layer LSTMs with hidden layer size 50. Both action and task embeddings have size 25 at each RNN timestep, resulting in an RNN input size of 50 after concatenation. The controller is trained on batches of size 20 with a learning rate of 5 \u00b7 10 \u22124, updated for 25 gradient steps before weights are averaged with Polyak Average weight 0.9. The reward for updating the controller is the cubed accuracy on a validation set. The MNMS framework achieves high accuracies on SST and Spanish language identification tasks. The best model design outperforms hand-tuned models using a BOW approach. More complex architectures yield the best performance, surpassing the search space limitations. MNMS framework can differentiate between tasks and choose optimal parameters. It learns to select appropriate word embeddings for different tasks, such as Spanish or English datasets. For simpler tasks, using pre-trained word embeddings is sufficient, but for more complex tasks like SST, continued training is necessary for better performance. Higher hidden layer dimensions and more training are favored in the search convergence. Transfer learning with MNMS allows for quicker convergence to finding good parameters for tasks, regardless of starting from scratch or pre-trained models. The search is not biased towards pre-training, as the best models perform similarly in both cases. Comparisons with hand-tuned benchmarks using word vector inputs show MNMS' effectiveness. MNMS outperforms hand-tuned benchmarks on tasks BID10 and BID5. It discovers models that excel in accuracy, showing correlations between task embeddings. Future work aims to create more interpretable representations. Future work could explore the differences in task embeddings and draw human-interpretable insights to improve model designs. Machine learning model design relies on prior knowledge and relationships between model parameters. Multitask Neural Model Search can discover differentiated model designs for multiple tasks simultaneously. Multitask Neural Model Search (MNMS) can find unique model designs for multiple tasks simultaneously and learn task embeddings that encode task relationships. This approach serves as a good baseline for transfer learning, enabling quicker convergence to high-performing designs. Future research should focus on scalability and the impact of additional tasks on framework performance. The MNMS framework aims to find unique model designs for multiple tasks simultaneously and learn task embeddings. It utilizes a distributed training structure and plans to optimize a parallel training structure for efficient multitask training. Future work includes experimenting with broader hyperparameter search spaces. The MNMS framework aims to find unique model designs for multiple tasks simultaneously by adapting the controller to sample continuous real-valued parameters. This approach allows for greater flexibility in specifying models and constructing more complex architectures in less time. Future work includes exploring the effectiveness of transfer learning within RL-based architecture search frameworks like MNMS. Transfer learning can be used to design architectures for tasks previously considered too resource-intensive for standard NAS. For example, adapting NAS for the ImageNet classification task by modifying the architecture designed for a simpler task. Pretraining the architecture search framework on more feasible tasks, rather than transferring discovered architectures, would be a significant step in tackling difficult search domains."
}