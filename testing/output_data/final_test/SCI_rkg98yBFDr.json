{
    "title": "rkg98yBFDr",
    "content": "Deep Infomax (DIM) is an unsupervised representation learning framework that maximizes mutual information between inputs and encoder outputs with probabilistic constraints. Supervised Deep InfoMax (SDIM) introduces supervised probabilistic constraints to encoder outputs, allowing for classification with rejection. Unlike other methods, SDIM scales well on complex datasets and achieves comparable performance with discriminative models. SDIM only makes predictions when test samples' largest logits surpass pre-chosen thresholds, rejecting out-of-distribution samples and adversarial examples. Neural network models' non-robustness is a concern due to vulnerability to attacks. Various attack and defense methods have been developed to address this issue. Generative classifiers, unlike discriminative classifiers, model conditional distributions of inputs given class labels. They struggle with scalability on high-dimensional tasks like image classification. Despite promising results in adversarial robustness, they have limitations compared to discriminative models. Generative classifiers struggle with classification performance on CIFAR10 and may assign higher likelihoods to out-of-distribution samples. Supervised deep infomax (SDIM) introduces supervised constraints into deep infomax for robust classification. SDIM introduces supervised statistical constraints for robust classification by maximizing mutual information between inputs and high-level data representations, ensuring representations satisfy class labels. It allows for classification with rejection of illegal inputs like adversarial examples. The paper introduces Supervised Deep Infomax (SDIM), an end-to-end framework for robust classification. It includes a novel rejection policy based on off-manifold conjecture to reject illegal inputs like adversarial examples and out-of-distribution samples. The experiments show that SDIM with rejection policy effectively rejects such inputs. Deep InfoMax (DIM) is an unsupervised representation learning framework that maximizes mutual information (MI) using an encoder. It is trained to find parameters that maximize MI over sample sets X and Y, with representations matching a prior distribution. MINE estimates MI lower-bound with Donsker-Varadhan representation. Supervised Deep InfoMax (SDIM) introduces supervision to probabilistic constraints of DIM for classification. It utilizes lower-bounds of MI such as Donsker-Varadhan representation, f-divergence representations, and Noise-Contrastive Estimation. The components of SDIM framework are illustrated in Fig. 1. Supervised Deep InfoMax (SDIM) introduces supervision to probabilistic constraints of DIM for classification by maximizing local mutual information. It assumes data follows the manifold assumption and enforces it in the representation space. SDIM introduces supervision to probabilistic constraints for classification by maximizing local mutual information and directly maximizing the parameterized class conditional probability. It differs from DIM by enforcing statistical constraints through maximizing the expectation of the class conditional probability. The complete loss function minimizes true class conditional probabilities using J NLL and minimizes false class conditional probabilities using J LM with a margin control constant K. Each encoder output is squared to penalize large gaps in true/false class conditional probabilities. Class conditional distribution is represented as an isotropic Gaussian in the generative classifier. The encoder is encouraged to learn simple representations with low-dimensional Gaussian distributions. Conditional normalizing flows are not chosen due to shared parameters across class labels. Each class conditional probability is represented with a VAE, making scaling to complex datasets difficult. Generative approach models class-conditional distributions and class priors for classification using Bayes' rule. The decision function for prediction of test samples involves setting a threshold for each class conditional probability to reject illegal inputs. This approach is known as selective classification or classification with a reject option. Likelihood-based generative models have achieved success in sample synthesis but their likelihood behaviors can be counter-intuitive. Likelihood-based generative models, such as Flow-based models and VAEs, can assign higher likelihoods to out-of-distribution samples than in-distribution samples. Statistical analyses show that OoD datasets may overlap with in-distribution datasets. DefenseGAN models real data distribution using a generator in GAN, ensuring the closest sample from the generator distribution is used as input for classification. DefenseGAN and PixelDefend use generative models to model data distribution and defend against adversarial perturbations. SDIM, unlike other methods, has a built-in verification for off-manifold inputs and uses simple Gaussians for modeling class conditionals, making it computationally efficient. SDIM evaluates rejection policy effectiveness on image datasets like MNIST, FashionMNIST, CIFAR10, and SVHN. Thresholds are chosen based on class conditional probabilities to detect out-of-distribution samples and adversarial examples on MNIST and CIFAR10. The SDIM model uses simple thresholds based on class conditional log-likelihoods to detect out-of-distribution samples. It consists of an encoder, mutual information evaluation networks, and a class conditional embedding layer. The encoder is based on ResNet with specific architecture details. The SDIM model achieves comparable accuracy to discriminative counterparts with a slight increase in parameters. Results are reported on clean test sets for MNIST, FashionMNIST, CIFAR10, and SVHN datasets. The focus is not on pushing the state-of-the-art, but rather on the model's performance. Schott et al. (2018) achieved acceptable accuracies on MNIST using VAE for class conditional probability modeling. The SDIM model achieves high accuracy on CIFAR10 by utilizing high-level representations for generative classification, outperforming other methods that struggle to achieve satisfactory accuracies. By feeding features learned by a discriminative classifier like VGG16 to their generative classifiers, SDIM achieves an accuracy of 92%, highlighting the effectiveness of modeling likelihood on high-level representations for classification tasks. The SDIM model achieves high accuracy on CIFAR10 by utilizing high-level representations for generative classification. Discovering discriminative features is more important than reconstructing all image pixels. The proposed decision function with rejection shows improved classification accuracies on test sets. Higher thresholds result in more prediction rejections, demonstrating the rejection policy tends to reject wrong predictions. The SDIM model achieves high accuracy on CIFAR10 by utilizing high-level representations for generative classification. Class-wise OoD detections are performed, and mean detection rates over all in-distribution classes are reported. Results show that SDIMs are more effective than fully conditional generative models on raw pixels for classification tasks. Fully generative models like VAE fail on OoD detection due to their evaluation directly on raw pixels. The SDIM model demonstrates robustness against various attacks, including gradient-based attacks like FGSM and PGD, score-based attacks, and decision-based attacks. SDIMs are found to be more resilient to gradient-based attacks using cross-entropy due to the numerical vanishing of gradients. The SDIM model shows resilience against attacks like FGSM and PGD, with gradients numerically vanishing due to the likelihood margin loss. Adversarial examples are conservative to avoid excessive distortions, making them detectable by the rejection policy. The rejection policy performs well on MNIST but struggles with detecting all adversarial examples on CIFAR10. Models trained on CIFAR10 are generally more vulnerable than those trained on MNIST, as observed by Gilmer et al. (2018). Higher error rates in models make it easier for small perturbations to cause misclassifications. Table 4 displays the full logits of adversarial examples generated with different attacks, highlighting the vulnerability of models to adversarial samples. Based on observations of vulnerability in CIFAR10 models, the study explores generating adversarial examples with larger logits than a threshold value using targeted CW attacks with varying confidences. Increasing confidences can boost the largest logits but may also result in generation failures. The study explores generating adversarial examples with varying confidences using targeted CW attacks. Success rates decrease with increasing confidences, but CW-L2 achieves 100% success rates. Data representations forming clusters with maximum margins increase the difficulty of finding minimal adversarial perturbations. Detection rates are satisfactory on MNIST but decline on CIFAR10. Detection rates for adversarial examples can be over 95% for victim generative classifiers under CW-L2 attack. The proposed detection methods achieve high detection rates of adversarial examples (>95%) on MNIST but drop to <50% on CIFAR10-binary. The study discusses the challenges of the off-manifold conjecture and the existence of adversarial examples within the data manifold, highlighting concerns that need to be addressed. The concerns raised include the complexity of manifolds in natural datasets compared to synthesized data, questioning if conclusions from previous studies hold for natural datasets. The obstacle lies in the lack of explicit manifolds in works modeling generative processes, unlike SDIM which enables analytical analyses with customized manifolds. Samples are trained to form isotropic Gaussians corresponding to their classes in representation space. In experiments, all models evaluated are discriminative classifiers. The potential of using generative classifiers for improved adversarial robustness is suggested. Supervised probabilistic constraints are introduced to DIM, leading to SDIMs equivalent to generative classifiers on high-level data representations. SDIMs achieve comparable classification performance as discriminative classifiers on complex datasets. The rejection policy based on off-manifold conjecture effectively rejects illegal inputs. Likelihoods modeled on high-level data representations are more robust on downstream tasks without the need for generating real samples. Comparisons with GBZ show SDIM consistently outperforms the baseline. Fig 5 shows that SDIM consistently outperforms the baseline. Increasing the distortion factor of FGSM does not affect SDIM's accuracy. Class conditionals are optimized with a considerable margin, and softmax is applied to generate a sharper distribution. The PGD-L \u221e used is a randomized version, adding small perturbations to break zero loss and ensure non-zero gradients during the iterative loop. Randomizing FGSM can also achieve similar results. Defensive distillation masks gradients by increasing softmax temperature, but may be ineffective for CW attacks operating on logits directly. Adversarial examples generated with different attacks show varying logits, with largest ones marked in bold."
}