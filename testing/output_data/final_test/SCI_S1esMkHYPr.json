{
    "title": "S1esMkHYPr",
    "content": "Molecular graph generation for drug discovery is a challenging problem addressed by the GraphAF model, a flow-based autoregressive model. It combines autoregressive and flow-based approaches, allowing for high model flexibility, efficient parallel computation, and leveraging chemical domain knowledge for valency checking. Experimental results show GraphAF can generate chemically valid molecules with or without chemical rules, with a training process twice as fast as existing methods. GraphAF is a flow-based autoregressive model for molecular graph generation in drug discovery. It outperforms GCPN in training speed and achieves state-of-the-art performance in property optimization through reinforcement learning. Machine learning techniques are increasingly used to design novel molecular structures with desired properties in applications like drug discovery and material science. The chemical space's discrete nature poses a challenge, but machine learning algorithms show promise in automatically generating chemically valid molecules. Significant progress has been made in generating molecular structures using deep generative models like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Autoregressive Models. Various approaches such as Junction Tree VAE (JT-VAE), GANs for molecular graph generation, and Graph Convolutional Policy Network (GCPN) have been proposed for molecular structure encoding and decoding. These methods use reinforcement learning to optimize the properties of generated graph structures. Recently, autoregressive models like MolecularRNN (MRNN) and normalizing flows have shown competitive performance in tasks related to molecular graph generation. Normalizing flows have been successfully applied in various tasks such as density estimation, variational inference, and image generation. These approaches define invertible transformations between a latent base distribution and real-world high-dimensional data. GraphAF is a flow-based autoregressive model for molecular graph generation that combines the advantages of autoregressive and flow-based approaches. It has a high model capacity to model the density of real-world molecule data. GraphAF is a flow-based autoregressive model for molecular graph generation with a high model capacity. It dynamically generates nodes and edges based on existing sub-graph structures, leveraging chemical domain knowledge. Unlike other models, GraphAF defines a feedforward neural network for efficient training. Experiments on the ZINC dataset show GraphAF is significantly faster, with training being two times more efficient. Results show that GraphAF is highly efficient, generating valid molecules with or without chemical rules. It outperforms GCPN in molecule generation and property optimization tasks, showcasing its ability to learn data distribution and optimize chemical properties through reinforcement learning. Several deep generative models have been proposed for molecular graph generation, including RVAE, JT-VAE, and GAN-based approaches. Optimization of chemical properties is often done through Bayesian Optimization. State-of-the-art models are based on autoregressive approaches, dynamically adding nodes and edges to the sub-graph. Our GraphAF approach utilizes a sequential decision process for generating new nodes and edges in a sub-graph structure. It combines the advantages of autoregressive models like MolecularRNN with the efficiency of feedforward neural networks for faster training and high validity in molecule generation. Our GraphAF approach differs from previous works like GNF and GraphNVP in that it defines an autoregressive flow directly to molecular graph structures, allowing for end-to-end training. GraphAF differs from previous approaches by formulating the generation process as a sequential decision process using graph neural networks. This allows for the effective capture of sub-graph structures and the incorporation of chemical rules, ensuring the validity of generated molecules. Normalizing flows as a generative model involve an invertible transformation f : E \u2192 Z with a base distribution \u223c p E ( ). The density function p Z (z) of real-world data can be computed using the change-of-variables formula. Autoregressive flows (AF) are a variant that is invertible with a triangular Jacobian matrix, allowing for efficient operations like calculating data likelihood and sampling. Autoregressive conditional probabilities are parameterized as Gaussian distributions using unconstrained functions of observation data. Neural networks can implement these functions to compute mean and deviation. The affine transformation in AF involves a triangular Jacobian matrix for efficient computation. Density estimation involves applying scalar affine transformations in parallel, while sampling involves sequentially computing variables based on previous observations. Graph Convolutional Networks (GCN) are neural network architectures for learning representations of graphs. In this paper, a variant of Relational GCN (R-GCN) is used to learn node representations in graphs with categorical edge types. Node embeddings are computed by aggregating messages from different edges. Node embeddings in R-GCN are generated by aggregating messages from various edge types using edge-conditioned adjacency tensors. The initial hidden node representation is the original node feature matrix, and after multiple message passing layers, the final hidden representation is used as the node representations. The graph representations are defined by aggregating the node representations with a readout function. The problem of molecular graph generation is formulated as a sequential decision process, starting from an empty graph and adding nodes in each step. GraphAF aims to define an invertible transformation from a base distribution to a molecular graph structure by generating nodes and edges sequentially. A dequantization technique is used to convert discrete data into a flow-based model. The dequantization technique converts discrete data into continuous data by adding real-valued noise. Parameterized neural networks define the mean and standard deviation of Gaussian distributions for generating nodes and edges in a graph structure. GraphAF defines an invertible mapping between the base Gaussian distribution and molecule structures, allowing for efficient calculation of the inverse process. The Jacobian matrix of the inverse process is triangular, making determinant calculation efficient for training data. GraphAF efficiently calculates the density of molecules in a minibatch of training data by using a change-of-variables formula. During training, a feedforward neural network is defined between the input molecule graph and the output latent variable using masking to ensure efficient computation. The masking technique allows for parallel computation and satisfies the autoregressive property, similar to approaches used in MADE and MAF. The training graph in GraphAF is re-ordered using BFS to accelerate the training process. The maximum dependency distance between nodes is limited by the number of nodes in a single BFS depth. Chemical rules aid in generating valid molecules. In chemistry, chemical rules help generate valid molecules. GraphAF uses a sequential generation process and valency constraints to ensure bond validity. The generation process stops when the graph reaches max-size or no new bonds are formed. GraphAF uses a sequential generation process and valency constraints to ensure bond validity. Hydrogens are added to atoms with unfilled valencies. To optimize the properties of generated molecules for drug discovery, reinforcement learning is used to fine-tune the generation process. The policy network defines a distribution of molecular graphs based on the current sub-graph. The policy network defines a distribution of molecular graphs G, incorporating valency check constraints and reward design for training. Rewards include intermediate penalties for violating valency checks and final rewards based on properties like logP and QED, as well as chemical validity. In training GraphAF, Proximal Policy Optimization (PPO) is used as an advanced policy gradient algorithm. The loss function of PPO includes ratios of probabilities output by old and new policies, and an estimated advantage function with a moving average baseline. The policy network is prevented from collapsing through a clipped surrogate objective. The policy network in GraphAF is protected from collapsing by a clipped surrogate objective. Evaluation tasks involve comparing with state-of-the-art approaches on molecule generation tasks. Data from the ZINC250k molecular dataset is used for training. GraphAF utilizes the ZINC250k molecular dataset for training, which consists of 250,000 drug-like molecules. The dataset includes molecules with a maximum atom number of 38, 9 atom types, and 3 edge types. RDkit is used to preprocess the molecules, presenting them in kekulized form with hydrogen removed. GraphAF is compared with JT-VAE and GCPN, two state-of-the-art approaches for molecule generation. JT-VAE is a VAE-based model that outperforms other previous models, while GCPN combines reinforcement learning and graph representation learning methods. GraphAF is implemented in PyTorch with 3 layers of R-GCN and an embedding dimension of 128. The model is trained for 10 epochs with a batch size of 32 and a learning rate of 0.001 using Adam optimization. Density modeling is evaluated by modeling real molecules and optimizing properties through a grid search on hyperparameters. GraphAF, a flow-based model implemented in PyTorch with 3 layers of R-GCN and an embedding dimension of 128, demonstrates competitive results in modeling real molecules. Validity, uniqueness, novelty, and reconstruction metrics are evaluated, with GraphAF achieving high scores in all four metrics. Notably, GraphAF shows perfect reconstruction ability and a 100% validity rate, outperforming other approaches like GraphNVP. GraphAF demonstrates strong flexibility in modeling data density and capturing domain knowledge from unsupervised training on a large chemical dataset. It outperforms previous state-of-the-art approaches in validity rate and efficiency, taking only 4 hours compared to 24 and 8 hours for other methods. Additionally, GraphAF's performance is not overfitted to specific datasets, as shown in experiments on different molecule datasets. GraphAF can generate valid, unique, and novel molecules on the challenging MOSES dataset. It is a versatile model that can be adapted for different types of graphs by adjusting the node and edge generating functions. In addition to molecular graph generation, GraphAF performs well on generic graph datasets like COMMUNITY-SMALL and EGO-SMALL, showcasing its flexibility and effectiveness in modeling data density. GraphAF can generate valid, unique, and novel molecules on the MOSES dataset. It performs well on generic graph datasets like COMMUNITY-SMALL and EGO-SMALL, showing flexibility in modeling data density. One-hot indicator vectors are used as node features for R-GCN. Evaluation is done using Maximum Mean Discrepancy (MMD) between generated and training graphs. Results show GraphAF yields comparable or better results than GraphRNN and GNF. Property optimization involves generating molecules with desired properties like penalized logP and QED scores. GraphAF outperforms baselines for penalized logP score and achieves comparable results for QED, indicating successful capture of desired molecules distribution through RL process. Top-3 molecules properties re-evaluated by MolecularRNN. The top-3 molecules properties re-evaluated by MolecularRNN show lower results than reported. GraphAF generates more realistic molecules with penalized logP scores between 5 to 10. The RL process in GraphAF is similar to previous work GCPN, leading to good property optimization performance due to the flexibility of flow. Compared to GAN models, flow is better at modeling complex distributions and generating diverse data, allowing GraphAF to explore various molecule structures for optimization. In the RL process for molecule properties optimization, the goal is to modify molecules to improve specified properties while maintaining a certain level of similarity. GraphAF pretrains via density modeling and then finetunes with RL, using Tanimoto similarity with Morgan fingerprint as the metric. Evaluation includes mean and standard deviation of improvement and similarity between original and modified molecules. Experiment results demonstrate significant improvements with GraphAF. GraphAF, a flow-based autoregressive model, outperforms previous approaches in improving molecular properties. It generates diverse and valid molecules efficiently, with the ability to optimize properties through reinforcement learning. Experimental results show GraphAF surpasses state-of-the-art baselines. The GraphAF model outperforms previous approaches in improving molecular properties, surpassing state-of-the-art baselines. The network architecture includes R-GCN with 3 layers and an embedding dimension of 128. Batch normalization is used before graph pooling for faster convergence. The model is trained on ZINC250K with specific hardware configurations for 10 epochs to achieve results in Table 2. The GraphAF model is trained on ZINC250K with specific hardware configurations for 10 epochs using Adam optimizer with a fixed learning rate of 0.001. Property optimization involves pretraining the GraphAF network for 300 epochs and then finetuning it through RL process towards desired molecular distribution. The reward design includes step-wise validity rewards, final rewards discounted by a fixed factor \u03b3, and property-targeted rewards with specific values for QED and penalized logP optimization. The pretrained GraphAF model is fine-tuned for 200 iterations with a batch size of 64 using Adam optimizer. A linear learning rate warm-up is adopted for stabilization. Grid search is performed to find optimal hyperparameters based on chemical scoring performance. Sub-graphs are sampled from ZINC molecules by randomly dropping nodes in BFS order. The reward design focuses on improving the target score. The pretrained GraphAF model is fine-tuned for 200 iterations with a batch size of 64 using Adam optimizer and a learning rate of 0.0001. The model is optimized for molecule generation, showcasing its ability to learn diverse graph structures and generate novel, realistic molecules with high penalized logP scores. The visualizations in Figures 3, 4, 5, 6, and 7 demonstrate the model's capabilities in generating unique molecules and optimizing properties. The GraphAF model, after fine-tuning, can modify molecules to improve penalized logP scores by adjusting ring size or carbon chains. Visualizations in Figures 3, 4, 5, 6, and 7 show the model's ability to generate diverse and realistic molecules."
}