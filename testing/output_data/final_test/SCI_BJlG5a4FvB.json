{
    "title": "BJlG5a4FvB",
    "content": "Machine learning models trained with DP-SGD have lower utility than non-private models. To address this, DP-LSSGD is proposed, utilizing Laplacian smoothing to improve utility while maintaining differential privacy guarantees. DP-LSSGD enhances stability and generalization of both convex and nonconvex ML models, including DNNs, with minimal computational complexity. Protecting private data in machine learning is crucial. Differential privacy (DP) is a tool that adds noise to algorithms to prevent attackers from distinguishing outputs. This is important as deep neural nets (DNNs) can memorize sensitive training data, making it possible to breach privacy. DP-SGD models have lower utility, so DP-LSSGD with Laplacian smoothing is proposed to improve utility while maintaining privacy guarantees. The output of algorithms is protected using differential privacy (DP) to prevent attackers from distinguishing outputs. Various tools exist to analyze DP guarantees, including composition theorems and moments accountant. Different ways to define privacy include local DP, concentrated DP, and R\u00e9nyi-DP. Differential private stochastic gradient descent (DP-SGD) reduces model utility compared to SGD. DP-LSSGD with Laplacian smoothing is proposed to improve utility while maintaining privacy guarantees. The logistic regression on the MNIST dataset shows increased losses with stronger DP guarantees. DP-SGD trained CNN has lower testing accuracy than non-private on MNIST. DP-LSSGD is proposed to improve utility in privacy-preserving ERM by smoothing injected noise in DP-SGD. DP-LSSGD is proposed to improve the convergence of DP-SGD in training ML models with DP guarantee. It achieves better utility than DP-SGD for convex optimization and reduces training and validation losses, improving model generalization. Experiments on logistic regression and CNN show the utility improvement of DP-LSSGD. In the context of improving the convergence of DP-SGD in training ML models with DP guarantee, there has been significant research on designing algorithms for privacy-preserving machine learning. Various approaches such as objective perturbation, output perturbation, and gradient perturbation have been explored to perform ERM with a DP guarantee. Researchers have provided theoretical guarantees for privacy and utility in logistic regression and SVM using both output and objective perturbations. Additionally, studies have been conducted on the effects of learning rate and batch size in DP-ERM, as well as stability and learnability properties. Various approaches have been explored to perform ERM with a DP guarantee, including objective perturbation, output perturbation, and gradient perturbation. Studies have analyzed stability, learnability, and other properties of DP-ERM, as well as proposed adaptive per-iteration privacy budgets. Variance reduction techniques like SVRG have been introduced, and the utility bound of DP-SGD has been analyzed for convex and nonconvex smooth objectives. Different ML models have been made differentially private, such as clustering, matrix completion, online learning, sparse learning, and topic modeling. Additionally, algorithms have been designed to release differentially private measurements by exploiting the ill-conditionedness of inverse problems. Various approaches have been explored to perform ERM with a DP guarantee, including objective perturbation, output perturbation, and gradient perturbation. Studies have analyzed stability, learnability, and other properties of DP-ERM, as well as proposed adaptive per-iteration privacy budgets. Variance reduction techniques like SVRG have been introduced. The utility bound of DP-SGD has been analyzed for convex and nonconvex smooth objectives. Different ML models have been made differentially private, such as clustering, matrix completion, online learning, sparse learning, and topic modeling. Algorithms have been designed to release differentially private measurements by exploiting the ill-conditionedness of inverse problems. Papernot et al. (2018) introduced new noisy aggregation mechanisms for teacher ensembles that enable a tighter theoretical DP guarantee. The modified PATE is scalable. The modified PATE is scalable to large datasets and applicable to diversified ML tasks. Laplacian smoothing (LS) is a denoising technique used in DP, improving accuracy in various scenarios. Post-processing methods like projecting linear regression solutions and Expectation-Maximization have shown to reduce estimation errors and improve algorithm accuracy. Innovative denoising technique improves Gaussian mechanism accuracy in high-dimensional settings. First to design denoising on Gaussian noise injected gradient for private ML models. Mathematical notation and organization of the paper outlined. DP-LSSGD algorithm introduced in Section 2, privacy and utility guarantees analyzed in Section 3. In this paper, the DP-LSSGD algorithm is introduced for both convex and nonconvex optimizations. The empirical risk minimization problem is defined, aiming to find a minimizer for the training loss. LSSGD is used with a learning rate \u03b7 and stochastic gradient \u2207f i k for solving the optimization problem. The DP-LSSGD algorithm introduces Laplacian smoothing (LS) to reduce variance in stochastic gradient descent (SGD) for convex and nonconvex optimizations. A positive definite matrix A \u03c3 is defined, with LSSGD guaranteeing the same convergence rate as SGD. LS can improve generalization in training various machine learning models, including deep neural networks (DNNs). The DP-LSSGD algorithm introduces Laplacian smoothing (LS) to reduce variance in stochastic gradient descent (SGD) for convex and nonconvex optimizations. LS can remove noise efficiently, making LSSGD more stable to noise injected stochastic gradient, improving training DP models with gradient perturbations. The DP-LSSGD algorithm introduces Laplacian smoothing to reduce variance in stochastic gradient descent for convex and nonconvex optimizations by injecting Gaussian noise into the stochastic gradient before applying LS to guarantee differential privacy. The algorithm is summarized in Algorithm 1 with privacy and utility guarantees provided. The technical proofs for (, \u03b4)-DP are provided in the appendix. DP-LSSGD algorithm guarantees privacy by injecting Gaussian noise and ensures utility for convex optimization problems. The DP-LSSGD algorithm provides a utility guarantee for convex optimization problems, with the convergence rate of \u03b3 to 0 almost exponentially as the dimension increases. The utility bound for convex optimization depends on the gap between initialization and the optimal solution, with an optimal trade-off determined by selecting the appropriate \u03c3 value. For nonconvex ERM, DP-LSSGD also offers a utility guarantee measured in gradient norm. The DP-LSSGD algorithm provides a utility guarantee for nonconvex optimization, where each component function is G-Lipschitz and has a continuous gradient. Using the 2-norm, DP-LSSGD has a higher utility upper bound than DP-SGD. However, this doesn't imply worse performance, as demonstrated by a simple nonconvex function example. DP-LSSGD is efficient in training multi-class logistic regression and CNNs for MNIST and CIFAR10 classification by clipping the gradient 2-norms of the CNNs. The models are trained with (\u03b5, \u03b4)-DP guarantee, using different privacy budgets for logistic regression and CNNs. 50 epochs of DP-LSSGD are run with a learning rate scheduled as 1/t for multi-class logistic regression. Training data is split into 50K/10K with a batch size of 128 for cross-validation, and the evolution of training and validation loss is plotted over iterations. DP-LSSGD is efficient in training multi-class logistic regression and CNNs for MNIST and CIFAR10 classification by clipping the gradient 2-norms. Training data is split into 50K/10K with a batch size of 128 for cross-validation. The evolution of training and validation loss is plotted over iterations for privacy budgets (0.2, 10^-5) and (0.1, 10^-5). DP-LSSGD with \u03c3 = 1, 2, 3 improves accuracy and reduces variance compared to DP-SGD. Testing accuracy results are listed in Table 2. In this subsection, different step size scheduling is explored to improve the accuracy of trained private models. The private logistic regression model trained by DP-LSSGD consistently outperforms DP-SGD. Additionally, DP-LSSGD and DP-LSAdam are implemented for MNIST classification in the Tensorflow privacy framework. Incorporating Laplacian smoothed surrogate into the Tensorflow privacy framework, different optimization algorithms are compared with varying noise multipliers. DP-SGD initially performs well but becomes unstable, while DP-LSSGD mitigates this issue. DP-Adam outperforms DP-LSSGD, and DP-LSAdam further improves validation accuracy. The effects of LS constant and learning rate on training DP-CNN for MNIST classification are also considered. In training the DP-CNN for MNIST classification, the LS constant (\u03c3) and learning rate were varied. DP-LSSGD outperformed DP-SGD in all learning rates tested, showing more stability with larger learning rates. LS was found to efficiently reduce training and validation losses. In integrating Laplacian smoothing with DP-SGD for privacy-preserving ERM, LS efficiently reduces training and validation losses in multi-class logistic regression for MNIST classification. DP-LSSGD significantly improves testing accuracy of CNN, with DP-LSAdam further boosting test accuracy. Results for DP-CNN in CIFAR10 classification are provided in the appendix. The algorithm is simple to implement with minimal additional computational cost compared to DP-SGD. DP-LSSGD improves the utility of private ML models numerically and theoretically by combining Laplacian smoothing with other variance reduction techniques. The privacy guarantee is proven using R\u00e9nyi DP concepts and techniques. The Gaussian Mechanism M satisfies (\u03b1, \u03b1\u2206 2 (q)/(2\u03bd 2 ))-RDP and (\u03c1 + log(1/\u03b4)/(\u03b1 \u2212 1), \u03b4)-DP for all \u03b4 \u2208 (0, 1). DP-LSSGD combines Laplacian smoothing with variance reduction techniques to improve utility of private ML models. The output of DP-SGD,w, after T iterations is ( , \u03b4)-DP with Gaussian noise N (0, \u03bd 2 ). By adding noise with variance \u03bd 2 \u2265 1/1.25, the mechanism M k satisfies \u03b1, log(1/\u03b4)/(\u03b1\u22121)T -RDP. With \u03b1 = 2 log(1/\u03b4)/ + 1, we have that M k satisfies 2 log(1/\u03b4)/ + 1, /(2T ) -RDP. Finally, w k satisfies k /(2T ) + /2, \u03b4 -DP, making the output of DP-SGD,w, ( , \u03b4)-DP. The LS operator compresses the 2 norm of a Gaussian random vector with a specific ratio in expectation, providing a stronger privacy guarantee. The update rule for w involves drawing uniformly from [n] and N(0, \u03bd^2 I). Expectation with respect to i_k and n given w_k leads to a convexity result and Lemma 4 implication. The LS operator compresses the 2 norm of a Gaussian random vector with a specific ratio in expectation, providing a stronger privacy guarantee. The update rule for w involves drawing uniformly from [n] and N(0, \u03bd^2 I). Expectation with respect to i_k and n given w_k leads to a convexity result and Lemma 4 implication. The utility guarantee for nonconvex optimization is proven using Lemma 5, showing the compression of 2 norms of Gaussian random vectors. The LS operator compresses the 2 norm of a Gaussian random vector with a specific ratio in expectation. The update rule for w involves drawing uniformly from [n] and N(0, \u03bd^2 I). Expectation with respect to i_k and n given w_k leads to a convexity result and Lemma 4 implication. The utility guarantee for nonconvex optimization is proven using Lemma 5, showing the compression of 2 norms of Gaussian random vectors. To prove Proposition 1, we need the following two lemmas related to complex functions and Fourier transforms. The LS operator compresses the 2 norm of a Gaussian random vector with a specific ratio in expectation. The update rule for w involves drawing uniformly from [n] and N(0, \u03bd^2 I). Expectation with respect to i_k and n given w_k leads to a convexity result and Lemma 4 implication. The utility guarantee for nonconvex optimization is proven using Lemma 5, showing the compression of 2 norms of Gaussian random vectors. To prove Proposition 1, we need the following two lemmas related to complex functions and Fourier transforms. The integral around the unit circle involves roots of a quadratic equation, with \u03b1 - being the only singularity within the circle. The Residue Theorem is applied to complete the proof. The summation in the proof is shown to be equal to by applying lemmas 7 and standard sampling results in Fourier analysis. LS operator compresses the 2 norm of a Gaussian random vector with a specific ratio in expectation. The update rule for w involves drawing uniformly from [n] and N(0, \u03bd^2 I). LS can improve the utility of DP-CNN trained by DP-SGD and DP-Adam for CIFAR10 classification. The CNN architecture used for MNIST classification is replaced with the benchmark architecture in the Tensorflow tutorial for CIFAR10 classification. LS significantly improves the validation accuracy of the model trained by DP-SGD and DP-Adam. LS significantly improves the validation accuracy of the model trained by DP-SGD and DP-Adam, with the DP guarantee for all these algorithms being the same."
}