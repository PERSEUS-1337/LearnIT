{
    "title": "ryCM8zWRb",
    "content": "In this work, a novel ranking loss function tailored for RNNs in recommendation settings is introduced, leading to up to 35% improvement in MRR and Recall@20 over previous session-based RNN solutions and up to 51% over classical collaborative filtering approaches. Session-based recommendation is a common problem in various domains like e-commerce and music, where past user history logs are utilized. In session-based recommendation, recommender systems rely on user actions in the current session to provide accurate recommendations. Recurrent Neural Networks (RNNs) have emerged as powerful tools for modeling sequential data and have shown impressive results in this setting. RNNs can effectively model the whole recommendation process, outperforming traditional methods like collaborative filtering. Session-based recommendation utilizes similarity-based methods to model user interactions using RNNs, improving recommendation accuracy by 20%-30% compared to traditional methods. The focus is on ranking items based on user preference, with a priority on correctly ranking items the user will like at the top of the list. This is achieved through the use of ranking loss functions and learning to rank techniques in machine learning. In session-based recommendation with RNNs, the choice of ranking loss functions significantly impacts performance. Gradients from the loss function affect optimization and model parameters, especially in tasks with large output spaces. Designing an effective ranking loss function is crucial for achieving good performance in recommendation systems. In this work, a new set of ranking loss functions for RNNs in session-based recommendations is analyzed, leading to a 30% performance increase without significant computational overhead. Experimental results validate the improvements in Mean Reciprocal Rank (MRR) and Recall@20, highlighting the potential of deep learning in Recommender Systems. In session-based recommendation, item-to-item recommendation approach is a natural solution to the problem of missing user profiles. A precomputed item-to-item similarity matrix is used to recommend similar items based on session data. Long Short-Term Memory (LSTM) networks, a type of RNNs, have been successful in optimizing recommendations. Gated Recurrent Units (GRUs) are a simplified version of LSTM that maintain their properties and are used in this work. Recurrent Neural Networks have shown success in session-based recommendations. In session-based recommendations, Recurrent Neural Networks (RNNs) have been used successfully. BID7 proposed an RNN with pairwise ranking loss, while BID18 introduced data augmentation techniques to enhance RNN performance. Session-based RNNs have been improved with feature information like text and images from clicked items. RNNs have also been applied in user-item collaborative filtering settings, with mixed results compared to standard matrix factorization methods. In the context of recommender systems, matrix factorization methods have been explored, with a focus on loss functions tailored to ranking requirements. Various ranking loss functions have been introduced in the context of matrix factorization techniques, showing promise in collaborative filtering applications. In the context of recommender systems, matrix factorization methods have been explored with a focus on ranking loss functions. However, these functions may not be optimal for RNNs due to stronger backpropagation requirements. The 'blackout' method is used for efficient loss computations in deep networks. The RNN algorithm GRU4Rec samples negative feedback on the output, which is important for session-based recommendations. GRU4Rec uses a sampling mechanism during training to compute scores for a subset of items, improving recommendation accuracy by up to 51%. The network takes the current event in a session as input and outputs scores for items likely to be the next in the sequence. This sampling approach is crucial for scalability, as computing scores for all items is impractical. GRU4Rec uses mini-batch training to compute scores for a subset of items, improving recommendation accuracy. This method allows for faster training and more stable gradients compared to stochastic gradient training. The network can be trained with different listwise ranking loss functions, with each example in the mini-batch serving as negative examples. This approach is practical and efficient for GPUs. Ranking losses in recommendation systems require scores for target items and negative samples. Learning occurs when target item score is not much higher than negative samples. Sampling high scoring items as negatives is crucial. Popular items often score high, making popularity-based sampling effective. Mini-batch sampling is a form of popularity-based sampling. In recommendation systems, sampling high scoring items as negative samples is crucial for learning. Popularity-based sampling is effective as it ensures the probability of an item acting as a negative sample is proportional to its support. However, popularity-based sampling can slow down learning after ranking target items above popular ones. Mini-batch sampling, tied to popularity-based sampling, has practical benefits but can be restrictive due to small sample sizes hindering the inclusion of high scoring negative examples. Training with smaller mini-batch sizes (30-100) produces more accurate models, while larger sizes are faster on the GPU due to parallelization. Extending the sampling method of GRU4Rec with additional samples can improve model performance. Additional samples are chosen based on item support, with the parameter \u03b1 determining the sampling strategy. Increasing the number of samples can enhance the training process. Increasing the number of samples in training can improve model performance, but it also adds complexity. Sampling according to a distribution on GPUs is slow, so it should be handled by the CPU to avoid interruptions in GPU execution. Implementing a cache for pre-sampling and storing negative samples can help optimize training efficiency. In this section, the authors discuss improving training speed by pre-sampling millions of item IDs and propose new loss functions for GRU4Rec to address numerical instability. They also introduce pairwise losses to alleviate degradation in learning as more samples are added to the output. These proposed loss functions can be applied to other models like matrix factorization. The loss function used in machine learning, particularly for multi-class classification, involves assigning scores to items in a one-hot vector. These scores are transformed using softmax to determine the label for the sequence. Cross-entropy is commonly used in this process. Cross-entropy with softmax scores is a common loss function used in machine learning for multi-class classification. However, it can introduce instability due to limited numerical precision, leading to inaccurate results in a large hyperparameter space. The loss function in GRU4Rec addresses numerical precision issues by using two methods to stabilize the loss. It offers two loss functions based on pairwise losses, comparing target scores to negative examples. The listwise loss function is composed of average individual pairwise losses. The listwise loss function in GRU4Rec consists of two loss functions: TOP1 and FORMULA5. TOP1 aims to push target scores above sample scores and penalizes high scores on negative examples. FORMULA5 minimizes the negative log-probability of target scores exceeding sample scores. The non-continuous P (r i > r j ) is approximated by \u03c3(r i \u2212 r j ). Examining the gradients for the TOP1 and BPR losses w.r.t. the target score r i reveals that under certain circumstances gradients vanish and learning stops. Negative samples with high scores are desired for producing high gradients. Irrelevant samples do not contribute much to learning. The gradient for TOP1 and BPR losses can vanish under certain circumstances, hindering learning. Increasing the number of samples leads to irrelevant samples outweighing relevant ones, impacting algorithm potential. TOP1 is sensitive to relevant examples, but oversight in design may lead to lower target scores. The gradient w.r.t. the score of a negative sample diminishes as their number grows, leading to vanishing gradients. To address this, a new family of listwise loss functions based on individual pairwise losses is proposed to compare the target score with the most relevant sample score. Simply removing the discounting factor does not solve this issue. The text discusses the challenges of removing the discounting factor in learning algorithms, as it can destabilize learning by introducing high variance. To address this, the use of softmax scores is proposed to maintain differentiability. The softmax transformation is applied to negative examples to ensure each sample is considered proportionally to its likelihood of having the maximum score, leading to the derivation of TOP1-max and BPR-max loss functions. The TOP1-max loss function is derived based on the general idea of using softmax scores to address the challenges of discounting factors in learning algorithms. The gradient of TOP1-max ensures that relevant samples are weighted more heavily, preventing vanishing gradients with more samples. The BPR-max loss function aims to maximize the probability of the target score being higher than the maximal sample score. It involves minimizing the negative log-probability to calculate the loss, with the gradient being a weighted average of individual BPR gradients. The gradient of BPR-max is a weighted average of individual BPR gradients, with weights based on the relative importance of negative samples. The focus shifts quickly to samples with high scores as the importance of r i increases. The gradient w.r.t. a negative sample is proportional to the softmax score, updating only items near the maximum score. The gradient of BPR-max is influenced by the relative importance of negative samples, with a focus on high-scoring samples. The gradient is updated based on the pairwise loss between the target and sample scores, with the gradient shifting towards the maximum score. The rank of the target item determines the behavior of the gradients, with lower ranks indicating fewer relevant negative samples. The gradient of BPR-max is affected by the importance of negative samples, focusing on high-scoring ones. The gradient is higher for BPR with more relevant samples, but quickly diminishes with fewer relevant samples. BPR's gradient starts vanishing around rank 5 with small sample sizes, while BPR-max does not vanish until rank 0. With more samples, the BPR gradient decreases significantly for rank 100-500, indicating it struggles to push target scores up in the ranking. BPR-max, however, continues to improve scores consistently. Despite TOP1 loss being sensitive to high-scoring samples, it outperforms BPR in BID7. The rare occurrence of rjri while rj\u22480 simultaneously affects the performance of TOP1-max and BPR-max. The regularization in TOP1 is beneficial for learning, even if not theoretically optimal. GRU4Rec supports dropout and 2 regularization, with TOP1 regularization on top. Model parameter 2 regularization decreases performance, suggesting certain weights should not be regularized. Penalizing high output scores constrains the model, so score regularization was added to BPR-max loss function. Various score regularization methods were tried, with the best one improving performance. In the best performing regularization method, sample scores are conditioned on independent Gaussians with variance inversely proportional to the softmax score. This results in stronger regularization on scores closer to the maximum. The final form of the BPR-max loss function includes a simple softmax weighted 2 regularization term. Experimental setup involved evaluating improvements on four datasets, including RSC15, VIDEO, and VIDXL. The datasets RSC15, VIDEO, and VIDXL were preprocessed and split into train and test sets based on session time. Evaluation was done for next item prediction, where the algorithm guesses the next item in a session. The VIDXL test set was compared to the target item's score for evaluation. The VIDXL test set is evaluated by comparing the target item's score to the 50,000 most popular items, similar to BID8. The primary evaluation metric is recall@20, measuring the proportion of cases where the desired item is among the top-20 recommendations. Recall is important as it correlates well with online KPIs like click-through rate (CTR). Another metric used is MRR@20 (Mean Reciprocal Rank), which evaluates the ranking of the desired item in the list. The experiments use MRR@20 as a metric, which averages the reciprocal ranks of desired items. It considers the rank of items, important for cases where recommendation order matters. The baseline is the original GRU4Rec algorithm with TOP1 loss and tanh activation function. Item-kNN is used as a baseline for next item prediction. Results for RSC15, VIDXL, and CLASS are taken from corresponding papers and measured with optimal hyperparameters. Hyperparameter optimization is done separately for proposed improvements. The experiments focused on optimizing recommendation accuracy using additional negative samples. The methods were implemented in Theano framework BID0 in python and tested on various GPUs. Results from experiments on CLASS and VIDEO datasets were similar, with performance measured using different loss functions. The TOP1 loss was found to not perform well according to theory. The code is available on GitHub for reproducibility. The TOP1 loss is not scalable and degrades in performance with more samples, while other losses react well to additional samples. Adding extra samples increases computational cost, but modern GPUs can parallelize the process. Training times at different sample sizes are shown in FIG3 on a logarithmic scale. The training time for the network depends on the dataset, model parameters, and operators used for computing the loss. With cross-entropy or TOP1-max settings, training takes around 10 minutes and does not increase with 512 extra samples. At 2048 extra samples, training time is around 15 minutes before growing quickly due to GPU limitations. On the VIDEO dataset, training starts at 50 minutes, increases to 80 minutes at 2048 extra samples, and grows rapidly thereafter. The proposed method incurs minimal additional cost compared to data augmentation methods. In the next experiment, a parameter sensitivity analysis of the \u03b1 parameter controlling sampling is performed. The performance over different \u03b1 values for cross-entropy, TOP1-max, and BPR-max losses is depicted in FIG4. Cross-entropy favors higher \u03b1 values with low sample sizes and low \u03b1 values for large samples. Ranking-max losses seem to prefer a different approach. The ranking-max losses show a preference towards higher values with a slight inclination towards the middle road, while extremes perform poorly. This is attributed to pairwise losses favoring popular samples and score regularization. The proposed improvements, including additional samples and specific loss functions, lead to a significant accuracy improvement. The results are compared with baseline models, showcasing the effectiveness of the enhancements. The increase in accuracy with sampling and proper loss functions is significant, with results surpassing the original GRU4Rec by 15-35% and item-kNN by up to 52%. BPR-max even outperforms cross-entropy on most datasets. Data augmentation can further improve results, but it increases training times. The Bayesian version of GRU4Rec falls short of our current best performer, GRU4Rec. The embedding layer in the current best performer in recommender systems translates item IDs into latent representations, improving item representations by sharing weight matrices. Preliminary experiments show increased recall and MRR with unified embeddings, especially in the CLASS dataset. A new loss function and improved sampling techniques contribute to significant accuracy improvements. The new class of loss function and improved sampling strategy have shown impressive gains for RNNs in session-based recommendations. These techniques could potentially benefit other recommendation settings and algorithms like matrix factorization or autoencoders, as well as in Natural Language Processing due to similarities in machine learning and data structure."
}