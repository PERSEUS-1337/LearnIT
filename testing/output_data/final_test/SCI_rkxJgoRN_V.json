{
    "title": "rkxJgoRN_V",
    "content": "Transfer learning uses trained weights from a source model to initialize the training of a target dataset, leading to improved accuracy. A technique is demonstrated to automatically label large unlabeled datasets for training source models. Experimental evaluation shows that these automatically trained models perform within 17% of baseline on average, reducing the need for expensive labeled datasets in deep learning tasks. In this work, a content-aware model-selection technique for transfer learning is developed. Unlabeled data points, like images, are assigned \"pseudolabels\" based on their distance to specialized deep learning models. These synthetic labels are used to augment ground truth labels, improving training accuracy. The technique is validated on ImageNet1K dataset and other large, unlabeled datasets. Various approaches are used to augment tasks by pretraining models with larger unlabeled datasets, improving results with limited labeled data. Generative models like GANs are utilized to refine category boundaries and exploit statistical structures of data. These methods extend the expressivity of known labels and increase the size of training sets. Our technique aims to enhance the expressivity of existing labels and expand training sets by using a specific case study with images from vertically partitioned datasets. Each dataset is represented by an average feature vector, and new images are labeled based on the distance to these representatives using Kullback-Leibler divergence. The technique enhances labels by using distances to determine synthetic labels for images from vertically partitioned datasets. ImageNet1K is used as a source with labels falling under categories like animals, vehicles, food, musical instruments, garment, furniture, and buildings. Labels are chosen based on the closest source datasets, generating labels like \"tree-animal-fungus\" using the Nearest-3 method. The Nearest-3 method generates pseudolabels based on the order of closeness to source datasets, resulting in labels like \"tree-animal-fungus\". In our study with 1.3M images from ImageNet1K, each label had an average of 381 images and a standard deviation of 1503. Nearest-2 and Nearest-1 pseudolabels were also computed, with 240 and 16 possible labels, respectively. The distribution of images for the Nearest-3 method shows high peaks related to animals. Another method utilized all 16 distances by clustering unlabeled images in a 16-dimensional space using k-means with 240 cluster centers. The images were k-means clustered with 240 cluster centers to create uniform clusters with an average of 1000 images per cluster. The final clusters were used as pseudolabels for datasets with diverse low-level image features. The labels were chosen to span a 16-dimensional space widely, with the first source dataset being the closest and the second being the farthest. This method aimed to maximize the area of the resulting triangle in 16-space. The images were clustered using k-means with 240 cluster centers to create uniform clusters. The labels span a 16-dimensional space widely, aiming to maximize the area of the resulting triangle. For example, the Nearest-1 label for a body armor image is music, while the Largest-Area label is music-fungus-sport. Similarly, for an elephant image, the Nearest-3 label is tree-animal-fungus, and the Largest-Area label is tree-furniture-fungus. In Experiment 1, pseudo-labeled datasets were created for ImageNet1K images and used to train ResNet27 for transfer learning. Base models were compared with vanilla ImageNet1K and random label models. Transfer learning accuracy was calculated for 12 target datasets using the 7 base models with the same hyperparameters. In Experiment 1, base models were compared using the same hyperparameters. The accuracy of Vanilla serves as an upper bound for transfer learning with Nearest-N, Uniform, and Largest-Area models. Nearest-3 performs best on 8 out of 12 datasets. Random provides a lower bound. Pseudo-labeled datasets were compared to human-labeled datasets, showing an average relative error of 17.2% for transfer learning accuracy. The error rate is 17.2%, ranging from 6.1% to 26.3%. Transfer learning accuracy is only 17.2% worse on average when using models trained with automatically generated labels compared to human-labeled images. Error decreases with increased divergence, indicating less sensitivity to label noise. Content-aware pseudolabels can approach human label performance, and models trained on pseudolabels can be used for transfer learning. Specialized representations in models contain descriptive features of datasets, suggesting a potential automated approach for transfer learning. Specialized representations in models can create rich labels for objects, capturing visual information about materials they are made of. Using multiple content-aware models for greater descriptive power is a potential avenue for future research."
}