{
    "title": "S1xjJpNYvB",
    "content": "Few-shot learning research has progressed quickly with meta-learning, but its practical use is limited as most studies assume examples come from a single domain. A new approach for few-shot classification involves tasks spanning multiple domains, including unseen ones during training. The key idea is to use multi-domain meta-learning to select the best embedding model from a pool for a specific task, simplifying task-specific adaptation. All models in the pool share a base network and have a separate modulator to refine the base network, allowing for representational diversity and domain-invariant representation. Our selection scheme for few-shot classification outperforms other algorithms across different domains by aggregating outputs from constituent models. The framework aims to quickly solve novel tasks with limited examples, even from unseen domains. This practical algorithm generalizes across domains beyond the common assumption of meta-training and meta-testing within a single domain. Our approach involves constructing a pool of multiple models and learning to select the best one for a novel task through meta-training over various domains. This simplifies task-specific adaption across domains into a selection problem, enhancing representational diversity without significantly increasing model parameters. Experimental results on image classification datasets demonstrate the effectiveness of our approach. The proposed selection scheme outperforms other algorithms in few-shot classification tasks across different domains, even for unseen domains. Meta-learning is used for N-way, K-shot classification tasks, where models are trained on random episodes to predict correct labels for query examples with few labeled examples. The study aims to develop a domain-agnostic meta-learner by training it on diverse source domains to achieve domain-generalized performance. The meta-learner is then tested on a target domain for cross-domain few-shot classification tasks. The study focuses on developing a domain-agnostic meta-learner trained on diverse domains for cross-domain few-shot classification tasks, including tasks from unseen datasets. The goal is to evaluate the meta-learner's ability to adapt to complex task distributions across multiple domains. In a study by Rusu et al., Oreshkin et al., Ye et al., and Triantafillou et al. (2019), a meta-model is trained on multiple embedding models to select the best model for a novel task. This approach simplifies task-specific adaptation by choosing a pre-trained model instead of manipulating high-dimensional model components directly. The models share parameters and are differentiated by per-model modulators, allowing for domain-invariant features and diversity. The study explores training a meta-model on multiple embedding models to simplify task-specific adaptation. A base network is shared among all models, with per-model modulators added for domain-specific features. The models are trained on individual datasets using metric-based metalearning, resulting in a pool of embedding models ready for non-parametric classification. The study involves training a meta-model on multiple embedding models with per-model modulators for domain-specific features. Two modulator architectures, convolution 1\u00d71 and channel-wise transform, are tested. The former performs slightly better while the latter uses fewer parameters with negligible memory overhead. Details of the architecture can be found in Appendix B. The study involves training a meta-model to predict the most suitable model from a pool of constituent models for a given task. A model selection network, parameterized by \u03c6, is trained to map a task representation to the best model index in the pool. During meta-training, the index of the best model serves as the ground truth label for training the selection. The study trains a model selection network to predict the best model index from a pool of models for a given task. The task-specific adaptation is simplified to a classification problem, making it easier than adapting model parameters or embeddings. The training procedure is outlined in Algorithm 1 in Appendix C. The study outlines a method for model selection using a selection network to predict the best model for a task. Two approaches for inference are discussed: one using a single model chosen by the selection network, and another combining outputs from multiple models. The latter method involves averaging outputs for class prediction probability. The study introduces a method for model selection using a selection network to predict the best model for a task. It involves collecting output probabilities based on distances to class prototypes and making predictions by maximizing probabilities from multiple models. Further adaptation at test-time is applied for additional performance improvement. Experimental results on eight image classification datasets are presented in Section 3 and Appendix D. The study introduces methods for few-shot classification, including DoS and DoA algorithms modulating base networks with different techniques. These methods are compared with Fine-tune, Simple-Avg, ProtoNet, FEAT, and ProtoMAML. In the study, state-of-the-art few-shot classification algorithms like FEAT and ProtoMAML are tested alongside new methods like DoS and DoA. The algorithms are trained and tested using a base network, with pre-training showing additional performance gains. The models are meta-trained on randomly generated episodes, with a target domain and task selected for each episode. The study evaluates few-shot classification algorithms like FEAT and ProtoMAML, along with new methods like DoS and DoA. Models are trained on randomly chosen domains and tasks, then tested on 5-way classification tasks with 1-shot and 5-shot configurations. Results show that DoS and DoS-Ch outperform other methods, with FEAT and ProtoMAML not as effective in this complex task setup. Our study compares various few-shot classification algorithms, including FEAT and ProtoMAML, with new methods like DoS and DoA. While ProtoMAML shows mixed results, ProtoNet is stable but not superior. FEAT performs worse overall. Our averaging methods, DoA and DoA-Ch, are competitive but selection methods outperform them consistently. This suggests that the selection network effectively chooses models trained on the same domain as the task. Additionally, DoS-Ch is competitive despite fewer parameters than DoS. Our study compares various few-shot classification algorithms, including FEAT and ProtoMAML, with new methods like DoS and DoA. DoS-Ch is competitive despite fewer parameters than DoS. Results on unseen domains show our approach outperforms other algorithms. Averaging methods DoA and DoA-Ch perform better than all other algorithms, including selection methods, in novel domains. This suggests that averaging induces synergy between models, leading to better performance. Our study compares few-shot classification algorithms like FEAT and ProtoMAML with new methods like DoS and DoA. Averaging methods show better performance on both seen and unseen domains, with the addition of source datasets sometimes harming performance. Negative transfer between heterogeneous domains should be avoided. Few-shot learning techniques like meta-learning have been actively studied for better understanding human learning with minimal training examples. These methods aim to solve few-shot learning problems by learning task-invariant metric spaces, optimizing tasks, or initializing weights effectively for future tasks. It is crucial to avoid negative transfer between heterogeneous domains to improve performance. Recent studies have focused on improving metric-based meta-learning for tasks by learning to modulate the metric space in a task-specific manner and refining task-common initial parameters for task-specific initialization. Some research has addressed few-shot learning under domain shift between training and testing, proposed a more realistic evaluation method for few-shot learning, and conducted fair comparative studies. Our network architecture is inspired by parameter sharing strategies for multi-task learning and multi-domain learning with domain-specific adaptation. Similar to our approach, some suggestions combined multiple models to benefit from their diversity. Our research is also related to domain adaptation or generalization. Our proposed few-shot classification method can handle various domains, including unseen ones, by utilizing a pool of diversified embedding models. Through cross-domain meta-learning, the algorithm selects the best model for a target task, simplifying task-specific adaptation into a small classification problem for easy learning. The algorithm utilizes a pool of diversified embedding models for multidomain few-shot classification, encouraging domain-invariant knowledge and cross-domain diversity. Future research directions include finding optimal ways to build the pool without constraints on the number of models and exploring soft selection or weighted averaging for improved performance. In experiments using the Visual Decathlon Challenge dataset, the study explores a scalable extension for expanding the model pool without re-training all existing models. The computational cost in averaging-based methods needs improvement to avoid linear cost increase with the number of models. The dataset includes ten datasets for image classification. The study explores using multiple datasets for image classification, including GTSRB, ImageNet12, Omniglot, UCF101, Flowers, and SVHN. Images were resized to 72x72 pixels for consistency. Daimler Mono Pedestrian Classification and SVHN were excluded due to limited classes. The remaining datasets were used for multi-domain few-shot classification tasks. The study uses multiple datasets for image classification, with examples divided into training, validation, and testing classes. Class hierarchy is followed for ILSVRC12, while random class splits are used for other datasets. The architecture of the embedding network is based on ResNet-18, producing a 512-dimensional embedding vector. The comparison of parameters for convolution 1x1 and channel-wise transform modulators is shown in Table A2. The architecture of the embedding network is based on ResNet-18, with one convolutional layer and 4 macro blocks containing different filters. Modulators are used within each residual block, with the convolution 1x1 modulator having more parameters than the channel-wise transform modulator. The latter has significantly fewer parameters compared to the base network. The selection network in the model pool construction process is a two-layered MLP that predicts the best model index based on the embedding vector. The training procedure involves three components trained sequentially, but joint training is also considered. Algorithm-specific refinement is applied at metatesting time for a fair comparison with the Fine-tune method. During meta-testing, a linear classifier is fine-tuned using support examples for 100 iterations per episode. Hyperparameters are selected through grid search based on validation accuracy, with Adam optimizer used for training. Learning rate and weight decay are set to 0.0001 for FEAT and ProtoMAML models. Other models are also trained using Adam optimizer. During meta-testing, a linear classifier is fine-tuned using support examples for 100 iterations per episode. Hyperparameters are selected through grid search based on validation accuracy. In Simple-Avg, each embedding model is trained on a separate source dataset following the Prototypical Networks method. Test accuracy values are averaged over 600 test episodes with 10 queries per class. The overall training procedure involves building a base network and adding modulators through intra-domain episodic training. During meta-testing, a linear classifier is fine-tuned using support examples for 100 iterations per episode. Hyperparameters are selected through grid search based on validation accuracy. In Simple-Avg, each embedding model is trained on a separate source dataset following the Prototypical Networks method. Test accuracy values are averaged over 600 test episodes with 10 queries per class. The overall training procedure involves building a base network and adding modulators through intra-domain episodic training. The experimental results show the performance of ProtoNet, FEAT, and their models without additional linear classifiers. The ProtoMAML method reduces parameter update steps to 3, affecting model fine-tuning. Results on seen and unseen domains show accuracy drops compared to further adaptation. However, the DoA models outperform other methods in various experimental settings. The DoA models perform better than Simple-Avg, with major contributors changing every episode. This suggests that the model pool construction benefits the averaging model. Equation (3) illustrates the loss used to train the selection network in the model pool construction method. The accuracy of the model with the modulator parameter is measured for query examples in episodes, similar to Prototypical Networks, to make predictions."
}