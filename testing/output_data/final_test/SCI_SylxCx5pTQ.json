{
    "title": "SylxCx5pTQ",
    "content": "The paper introduces MedMentions, a new annotated resource for biomedical concept recognition. It stands out due to its large size, extensive concept ontology, and coverage of various biomedical disciplines. A sub-corpus is also included for document retrieval tasks. Data splits for training and testing, along with a baseline model for entity linking, are provided to encourage research in Biomedical Named Entity Recognition and Linking. The annotated corpus for biomedical concept recognition is limited in size and scope, prompting the creation of a new dataset named 'MedMentions' to address this gap. This dataset aims to support the development of advanced entity linkers targeting a wider range of biomedical concepts. The 'MedMentions' dataset aims to address the limited size and scope of annotated corpora for biomedical concept recognition. It offers broader coverage of biology and medicine using the Unified Medical Language System (UMLS) ontology and a larger annotated corpus to meet the data demands of complex machine learning models. The paper introduces the MedMentions corpus, compares it with other datasets, and presents metrics for a baseline concept recognition model trained on the dataset. The MedMentions dataset utilized a model trained on the MedMentions corpus, consisting of 4,392 abstracts from PubMed. The UMLS Metathesaurus, with over 3.2 million unique concepts, was chosen for its comprehensive coverage in biomedical science. Each concept in the Metathesaurus has a unique id and is linked to multiple source ontologies. The UMLS Metathesaurus contains 127 Semantic Types linked to concepts from various source ontologies. Annotators used GATE 2 to curate UMLS entity mentions from abstracts, searching for the most specific concept in the Metathesaurus. The annotators annotated specific concepts without overlaps. Reviewers evaluated the annotation quality, showing 97.3% agreement. No evaluation on recall was done due to the size of UMLS. More detailed IAA data will be released later. Entity linking methods are commonly used for relationship analysis. Entity linking methods are commonly used for relationship analysis. These methods have been utilized in tasks such as the BioCreative V CDR task for Chemical-Disease relationship extraction and the BioASQ Task A for semantic indexing. Building a comprehensive annotated corpus aims to provide indexing models with a larger ontology than MeSH, like UMLS, which contains concepts not always useful for specialized document retrieval. The curr_chunk discusses the creation of the \"ST21pv\" subset of UMLS for semantic indexing in biomedical research. This subset includes 21 semantic types at levels 3-5, eliminating concepts linked to broad semantic types. The goal is to impact machine learning systems designed to recognize concepts in text. The 2017 AA release of UMLS introduced the ST21pv subset with 21 selected semantic types for biomedical relevance. Concepts not linked to these types or their descendants were excluded. 18 preferred source vocabularies were chosen based on usage and relevance for aiding biomedical researchers in retrieving relevant papers. The 2017 AA release of UMLS introduced the ST21pv subset with 21 selected semantic types for biomedical relevance. Concepts were pruned based on usage and relevance to gene function, disease, phenotype, structure, anatomy, drug entities. The MedMentions corpus mentions were filtered, resulting in the exclusion of 135,986 mentions of 6,002 unique concepts. Further eliminations were made in subsequent steps. The target ontology for MedMentions ST21pv (MM-ST21pv) contains 2,327,250 concepts and 203,282 concept mentions. The MedMentions corpus consists of 4,392 abstracts randomly selected from PubMed between January 2016 and January 2017. Tokenization and sentence splitting were done using Stanford CoreNLP. Only about 1% of UMLS concepts are covered in MedMentions, posing a challenge for machine learning systems due to 'unseen labels'. The MedMentions corpus contains PubMed abstracts with unique identifiers, concept mentions, and annotations. About 42% of concepts in the test data are not in the training data, posing a challenge for machine learning systems. The corpus is available in PubTator format on GitHub. The release includes a separate file for the ST21pv sub-corpus and three lists of PMID's for Training, Development, and Test subsets. Researchers are encouraged to train models using the Training and Development portions and publish test results on the Test subset. GENIA: BID13 is one of the earliest large biomedical annotated corpora for Named Entity Recognition. Reactions related to transcription factors in human blood cells were extracted from MEDLINE using MeSH terms. A large biomedical annotated corpus, including articles on protein-protein interactions and tissue expressions, was used for the JNLPBA 2004 NER task. The corpus was annotated with entities from various databases and grouped into 15 entity types. The CRAFT Corpus is a large gold standard corpus annotated with biomedical concepts from various disciplines. It consists of 67 full-text open-access biomedical journal articles and is annotated with concepts from 9 biomedical ontologies. The CRAFT Corpus contains annotations from various biomedical ontologies, including ChEBI, Cell Ontology, Entrez Gene, Gene Ontology, NCBI Taxonomy, and others. The latest release reorganizes these into ten Open Biomedical Ontologies. MedMentions is a supplement to CRAFT with broader coverage and more comprehensive annotation of concepts, such as diseases and drugs. BioASQ Task A involves assigning MeSH headings to important concepts in documents. The task involves assigning MeSH headings to important concepts in documents, with annotation at the document level. Recently developed datasets focus on extracting biomedical events or relations between entities for tasks in biomedical NLP workshops like BioCreative and BioNLP. These datasets include entity mention annotations but are limited in entity types and corpus sizes. The MedMentions dataset aims to promote the development of models for recognizing biomedical concepts in scientific literature. A baseline modeling approach trained on MedMentions ST21pv is presented, with performance metrics on the MM-ST21pv Test set. The model measures performance at both mention and document levels, identifying text spans with entity type identifiers. The concept recognition model outputs predictions in a specific format, with performance measured using mention level precision, recall, and F1 score. Entity resolution performance is evaluated by matching predicted text spans and linked entities with the gold standard reference. True positives (tp) are counted when both match, false positives (fp) for other predicted mentions, and false negatives (fn) for unmatched reference entities. Mention level metrics are important for concept recognition tasks like disease recognition in BC5-CDR. Document level metrics in concept recognition tasks involve mapping all concept mentions to one label on the document, useful for information retrieval. TaggerOne is a semi-Markov model for entity recognition and linking with perceptron-style parameter estimation. TaggerOne is a flexible package for entity recognition and linking with parameter estimation. It achieved state-of-the-art results for joint Chemical and Disease recognition. The MM-ST21pv data was modified to include 21 semantic types linked to specific concepts from UMLS. Training was done on the Training split with REGULARIZATION = 0. The TaggerOne model was trained with specific parameters for entity recognition and linking. It took 9 days to train on a machine with Intel Xeon Broadwell processors and over 900GB of RAM. Metrics were calculated by comparing concept predictions against the reference annotations in MM-ST21pv. The formal release of a new resource named MedMentions for biomedical concept recognition was presented. MedMentions is a new resource for biomedical concept recognition, containing a large annotated corpus of over 4,000 abstracts with a fine-grained concept ontology of over 3 million concepts. It also includes a targeted sub-corpus (MedMentions ST21pv) with standard training, development, and test splits, along with metrics for a baseline concept recognition model trained on this subset. Researchers can use this resource to compare the metrics of their own concept recognition models."
}