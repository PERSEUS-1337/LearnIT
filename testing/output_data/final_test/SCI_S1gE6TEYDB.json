{
    "title": "S1gE6TEYDB",
    "content": "Recent image super-resolution studies utilize deep convolutional neural networks for better reconstruction performance. However, the small receptive fields in these models limit their ability to leverage global contextual information. To address this, a new image super-resolution global reasoning network (SRGRN) is proposed, inspired by the human visual system. The network includes a global reasoning up-sampling module (GRUM) and a global reasoning reconstruction block (GRRB) to learn correlations between different image regions through relation reasoning on low-resolution images. The proposed SRGRN model aims to reason interactions between regions in up-sampling and reconstruction processes to generate accurate details in low-resolution images. It outperforms other methods on benchmark datasets, is lightweight, and consumes less computing power, making it suitable for real-life deployment. Image Super-Resolution is a challenging problem with uncertain LR to HR mapping, addressed by various methods including interpolation-based, reconstruction-based, and learning-based approaches. Deep learning methods have shown exceptional performance in superresolution reconstruction, with the use of effective residual or dense blocks to improve results. However, the focus has been mainly on enhancing feature extraction, neglecting the fact that the upsampling process with smaller receptive fields limits the utilization of these features. This limitation results in super-resolution reconstruction based on local feature relationships in low-resolution images, overlooking the interaction of different features. Local feature relationships in LR are crucial for upsampling and reconstruction. Despite extracting hierarchical features, information loss occurs due to limited receptive fields. Chariker et al. (2016) suggest adding global information in SR reconstruction to mimic the human visual system's image generation process. This involves implementing relational reasoning for reconstructing images with observed global information. The human visual system reconstructs images with observed global information, requiring a large receptive field. To address this, an image super-resolution global reasoning network (SR-GRN) introduces global reasoning to the upsampling module and reconstruction layer. This allows for capturing relationships between image features with a small receptive field, enhancing upsampling and reconstruction. The network includes global reasoning upsampling module (GRUM) and global reasoning reconstruction block (GRRB) as core structures. The image super-resolution global reasoning network (SRGRN) utilizes global reasoning in the upsampling and reconstruction process. It includes the global reasoning upsampling module (GRUM) and global reasoning reconstruction block (GRRB) to convert LR feature maps into pixels with global reasoning information, enhancing the upsampling and reconstruction process. The model focuses on the upsampling and reconstruction modules, utilizing global reasoning to reconstruct SR images. It introduces the global reasoning upsampling module (GRUM) and global reasoning reconstruction block (GRRB) to implement relational reasoning among feature regions using convolution. These lightweight modules balance parameter count and reconstruction performance well, suitable for real-life deployment and can be easily integrated into other models. After introducing global reasoning modules for upsampling and reconstruction in SR image generation, researchers have developed various networks like VDSR, DRCN, EDSR, MDSR, and residual dense network to improve feature extraction and utilize hierarchical features effectively. These networks implement upsampling using transposed convolution or sub-pixel convolution, achieving significant results in image super-resolution. Recently, researchers have proposed new super-resolution upsampling processes such as LapSRN, DBPN, and SRFBN to improve reconstruction performance. However, these models still have a limited receptive field in the Conv layers. In contrast, graph-based deep learning methods, like Relation Networks by Santoro et al., are being used for relation reasoning in image generation. Relation Networks (RN) by Santoro et al. are widely used for relational reasoning in image generation. A Global Reasoning unit with five convolutions is proposed for various tasks like image classification and semantic segmentation. A global reasoning network for super-resolution (SR) is introduced, considering the correlation between feature regions for joint determination of pixels in the generated SR image. For image super-resolution, the brain reconstructs real-world images based on limited information from the retina. Upsampling modules in SR models generate high-resolution images using contextual information from low-resolution images. However, most models struggle to utilize enough contextual information, resulting in loss of fine details. To address this, SRGRN simulates human visual reasoning to fully leverage contextual information for accurate detail recovery. SRGRN utilizes contextual information to recover accurate details in image super-resolution. It includes a feature extraction part, global reasoning upsample module (GRUM), and global reasoning reconstruction block (GRRB). The number of GRUM depends on the scaling factor, and it can be expressed mathematically. More details about GRUM will be provided in Section 3.2. In Section 3.2, details about the global reasoning upsample module (GRUM) are presented. GRUM utilizes a graph model to achieve relation reasoning by mapping each image to nodes and obtaining relationship weights through convolution. This approach benefits the process of generating the corresponding SR image. The global reasoning upsample module (GRUM) utilizes a graph model to map images to nodes and obtain relationship weights through convolution. This approach aggregates feature regions into nodes and adds global guidance to each node. The CLC structure implements reasoning and interaction between nodes in the graph by learning complex nonlinear relationships. The bottleneck in the reasoning process between nodes uses convolution and Leaky ReLU operation for channel amplification. It reduces the number of parameters and redistributes channels more accurately, fitting complex relationships between channels better. The first convolution reduces channels, and the second convolution increases them, achieving channel amplification. The channel amplification process involves transforming nodes into a feature map through pixelshuffle and weight matrix normalization. Each pixel's reconstruction is influenced by N nodes to varying degrees, incorporating global reasoning. The output is then adjusted by a parameter \u03b3 1. The global reasoning module in the network gradually learns to assign values to parameter \u03b3 1, fully exploiting global reasoning. The process involves pixel shuffle and subpixel convolution operations to obtain F S. The Global Reasoning Reconstruction Block (GRRB) architecture is similar to GRUM, utilizing a graph model for reconstruction. The relationship weights between pixels are obtained through 2D 1x1 convolution, aggregating regions into nodes, and outputting Y RW. The output of the process involves relationship reasoning between nodes using CLC and redistributing information to pixels. The global reasoning module incorporates a residual connection with parameter \u03b3 for enhanced information flow. The final output is obtained through reconstruction Convs in the proposed SRGRN model. The proposed SRGRN model incorporates relationship reasoning between nodes using CLC and redistributing information to pixels. It utilizes Leaky ReLu with a negative slope of 0.2 as the non-linear activation function. The network's feature extraction part is based on RDN settings. The final Conv layer outputs either gray or color HR images. Training is done on 800 images from the DIV2K dataset, with evaluation on five benchmark datasets for PSNR and SSIM metrics. The SR results are evaluated on various benchmark datasets using different degradation models such as bicubic downsampling (BI), blurring with a Gaussian kernel and downsampling (BD), and adding Gaussian noise (DN) to demonstrate the effectiveness of the proposed model. The training setting involves bicubic downsampling with a scaling factor of \u00d73 and adding Gaussian noise with a noise level of 30. Data enhancement includes random rotations and horizontal flips. The Adam optimizer is used with specific parameters, and the learning rate is adjusted every 200 epochs. The Pytorch framework is used with a Tesla P100. Removing the Global Reasoning Upsampling Module slightly decreases network performance. After adding GRUM to the baseline model, network performance improved from 32.31 dB to 32.42 dB, demonstrating the effectiveness of relation reasoning. The addition of GRRB further improved performance to 32.40 dB, showing significant enhancements even after the model with GRUM had already achieved good results. The addition of GRRB to the network significantly improved performance, with the PSNR value on Set5 increasing from 32.42 dB to 32.45 dB. Larger N and smaller \u03b1 parameters led to higher performance, with values of 10 and 8 set for N and \u03b1 respectively. Despite having fewer parameters than other models, SRGRN and SRGRN+ achieved higher performance, demonstrating a good balance between model size and performance. Our proposed SRGRN and SRGRN+ outperform other state-of-the-art image SR methods in quantitative terms. A self-ensemble strategy further improves performance, with SRGRN+ achieving the best results on all datasets. Despite using fewer training images, our results are superior to those of SRFBN. Our SRGRN outperforms other state-of-the-art methods in all datasets through relational reasoning in upsampling and reconstruction. The quantitative results show the vital role of GRUM and GRRB in improving network performance, especially for images with artifacts and noise. SRGRN effectively denoises and alleviates blurring artifacts, with SRGRN+ showing even better improvement when added to self-ensemble. Our SRGRN utilizes relational reasoning to outperform other methods in reconstructing real-world images with low resolution and unknown degradation models. The proposed SRGRN incorporates global reasoning upsampling module (GRUM) and global reasoning reconstruction block (GRRB) to enhance image super-resolution. The Global Reasoning Upsampling Module (GRUM) and Global Reasoning Reconstruction Block (GRRB) in SRGRN enhance image super-resolution by enabling relational reasoning in a global scope. Extensive evaluations show the superiority of SRGRN over state-of-the-art methods in handling low resolution and real-world images. Visual comparisons demonstrate the effectiveness of GRUM and GRRB in recovering details in SR images. Our SRGRN outperforms other methods in recovering sharp edges and fine textures, especially in images with severe blurring artifacts. The use of relation reasoning allows SRGRN to utilize more contextual information for better results. Visual comparisons with other models further demonstrate the effectiveness of SRGRN in image super-resolution. Our SRGRN excels in recovering sharp edges and fine textures, especially in images with severe blurring artifacts. It effectively suppresses blurring artifacts and noise, demonstrating its robustness in image super-resolution. Visual comparisons highlight the superior performance of SRGRN in handling BD and DN degradation models. Our SRGRN excels in recovering sharp edges and fine textures in images with severe blurring artifacts. It outperforms other methods in producing clearer images with sharper edges and finer details, showcasing its robustness against unknown degradation models. This highlights the superiority of relation reasoning in image super-resolution."
}