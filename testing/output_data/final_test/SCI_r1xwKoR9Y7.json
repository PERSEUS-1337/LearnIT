{
    "title": "r1xwKoR9Y7",
    "content": "GamePad is a system introduced in this paper to explore machine learning methods in theorem proving with Coq. It is used to synthesize proofs and train models for theorem formalization tasks. The system addresses position evaluation and tactic prediction tasks in tactic-based theorem proving, which involves symbolic reasoning and intuition guided search. Recent work has shown the potential of deep learning techniques in this challenging AI task. In this work, the focus is on learning proofs with human supervision in formal theorem proving. Formal proofs are systematically derived in a formal system, allowing for algorithmic correctness checks. The logical content of proofs in natural language and formal proofs is similar, despite differences in form and detail. The study centers on interactive theorem provers (ITPs) that assist users in constructing formal proofs. Interactive theorem provers (ITPs) are software tools that enable users to construct formal proofs. They offer programmable environments and access to supervised data, making them ideal for exploring learning techniques in theorem proving. ITPs have been used to verify large mathematical theorems and complex software. GamePad 1 introduces a system that exposes parts of the Coq ITP for machine learning tasks. Coq is a mature system used to formalize nontrivial theorems and supports the extraction of verified software guarantees. Our contributions include introducing GamePad, a tool that provides a structured Python representation of Coq proofs, allowing for dynamic proof building and tasks such as position evaluation and tactic prediction. This tool enables interaction with Coq and can be used for reinforcement learning. In this section, we present the synthesis of Coq proof scripts using a tactic prediction model for algebraic rewriting problems. We also apply baseline models for position evaluation and tactic prediction to the FeitThompson formalization. The code for GamePad and related resources are available on GitHub. The paper begins by illustrating the formal proof process modeled as a game, followed by a simple example in Coq. When transitioning from pencil-paper proofs to interactive theorem provers like Coq, a scratchpad is still used to keep track of what needs to be proven and the available facts. In Coq, the scratchpad is represented as a proof state, resembling a game with a goal and assumptions. This game model helps in constructing formal proofs efficiently. In Coq, a proof state resembles a game with a goal and assumptions. The aim is to transform the starting state into final states using valid transitions, potentially resulting in multiple subgoals. A successful proof corresponds to a proof tree, with the root as the start state and leaves as final states. An example Coq proof involves showing that adding 0 to any natural number n results in n itself, typically proven through induction. In Coq, proofs are carried out by checking the base case (n = 0) and the inductive case (n = n + 1). Using tactics like induction and simpl in Coq's Ltac language, we can progress through proof steps. The induction command starts a proof by induction on n, simplifying the resulting proof states. The proof states show the base case in one state and the inductive case with an inductive hypothesis in another. Coq provides three term languages for encoding logical formulas, with Gallina supporting type-inference and notational convenience. The mid-level and kernel-level languages are similar, except for implicit arguments marked with \u03b9. Coq represents a proof state as a tuple \u0393, M, n of a local context \u0393, a goal term M, and a unique proof state identifier n. A context \u0393 provides a list of identifiers and their types that express all the current assumptions. Tactic invocations create edges between proof states, forming a proof tree interpreted in the presence of global state. Global state contains the interpretation of constructs such as implicit arguments. The global state in Coq contains interpretations of constants, constructors, and stateful effects like existentials. The GamePad tool exposes these constructs as Python data structures for building models. Proof traces are obtained by patching Coq to log intermediate proof states. The patch supports SSreflect BID5, a Coq plugin for writing mathematics proofs, without affecting the Coq proof checker. It records proof states at the granularity of primitive tactics, allowing for flexibility in determining atomic proof steps. The patch supports SSreflect BID5, a Coq plugin for writing mathematics proofs, by recording proof states at the granularity of primitive tactics. The proof trace obtained from Coq is exposed as Python data structures, allowing for manipulation with arbitrary Python code. Coq terms are represented in a shared form for efficiency and scalability in building models. The API provides a wrapper around coqtop for interactive construction of proof scripts from within Python. In this work, the component mediates interaction with Coq for proof state parsing and tactic actions. The tasks involve position evaluation and tactic prediction, where a good tactic predictor can make proving a state easier. The goal is to learn parametric functions using supervised learning on a dataset of human proofs. The position evaluation task aims to predict the number of steps needed to complete a proof based on a given proof state. This involves learning a function P T h using supervised learning on a dataset of human proofs. The position evaluator measures the difficulty of completing a proof, while tactic prediction aims to predict the next tactic to apply in a proof state. This involves learning from human prover data. The tactic predictor T h aims to learn human tactics used in proof states. Challenges include choosing granularity of proof steps and synthesizing arguments for tactics like induction or rewrite. The tactic predictor T h aims to learn human tactics used in proof states, including synthesizing arguments for tactics like induction or rewrite. This involves predicting identifiers and constructing terms, which is a challenging research topic. The structured representation of proof states provided by GamePad can be leveraged for learning. The structured representation of proofs provided by GamePad can be utilized by applying recurrent neural networks (RNNs) to parse trees, embedding terms using a recursive function. This includes encoding constants, inductive types, constructors, existentials, and variables in a learnable embedding table. Adding inductive bias can be achieved by incorporating known reduction semantics of terms. The embedding function E assigns meaning to terms based on reduction semantics and an environment mapping variables to values. It incorporates known reduction semantics of terms and uses a lookup table to map variables to embedding vectors. The embedding function E assigns meaning to terms using reduction semantics and an environment mapping variables to values. It incorporates known reduction semantics and uses a lookup table to map variables to embedding vectors, including a structured approach based on a De Bruijn term for variable binding. After obtaining the embedding for each type in the proof state and the goal, a structured approach based on a De Bruijn term representation is proposed. The proof state context must be traversed in-order, and the result of embedding a proof state is a vector in R D. A basic setup using GamePad to learn a simple algebraic rewriter is discussed, including the use of a deterministic procedure to synthesize Coq. Extensions to closely follow the structure of an interpreter for better reflecting semantics are left for future work. The text discusses using GamePad to synthesize Coq proofs for algebraic expressions, training a tactic predictor, and deploying it for end-to-end proofs. It focuses on proving the equivalence of algebraic expressions using simplification rules. The problem involves non-trivial reasoning despite its simplicity. The text discusses using GamePad to synthesize Coq proofs for algebraic expressions, focusing on proving equivalence using simplification rules. The problem involves non-trivial reasoning, with choices between eliminating left or right identity elements in the proof. Provers have two options: maintain a global perspective or learn to expand terms. A deterministic procedure is developed to generate proofs without backtracking, aiming to learn this algorithm for tactic prediction. The tactic prediction model embeds proof states into R D and uses a fullyconnected layer for prediction. Proofs are modeled as a tactic prediction problem, converting AST positions into numbers and identities into single numbers for prediction. End-to-end proof synthesis combines the tactic prediction model with GamePad's interaction module for advancing proofs. The trained model infers positions to rewrite and identity laws to apply in the Coq proof state. The current problem involves generating 400 unique theorems with proofs for algebraic expressions of length 10. The expressions are constructed by recursively expanding left and right expressions subject to certain constraints. The proof states are extracted using GamePad to train a tactic prediction model. This model is then tested on 50 randomly generated algebraic expressions to complete proofs using a greedy approach. The model completes proofs using a greedy approach, generating 14 complete proofs with a failure rate of 1 proof step per proof. The accuracy for tactic prediction is 95%. In this section, baseline position evaluation and tactic prediction models are applied to data extracted from the Feit-Thompson formalization, which involves difficulties such as scaling and a more complex tactic prediction problem. The Feit-Thompson theorem, a deep result in group theory, is formalized with researchers closely following book proofs. The dataset includes 1602 lemmas and 83478 proof states, split into training, validation, and test sets for tasks. For tasks involving the Feit-Thompson formalization, lemmas are split into training, validation, and test sets in an 8:1:1 ratio. The proof states are split based on lemmas to avoid optimistic evaluation of model generalization. Each proof state consists of a context and goal, with an average of 60 terms and 4000 nodes at the kernel level. The focus is on constants, applications, and variables in the design of embeddings. CompCert focuses on program verification with AST nodes involving fixed-points, case analysis, and inductive type constructors. Common tactics like rewrite and have are used, with the have tactic being the most challenging to learn. There is potential for a generative model to synthesize arguments for have tactics. Scaling to large proof trees is addressed with optimizations to handle thousands of nodes efficiently. The optimization techniques for scaling to larger proof trees in CompCert involve embedding sharing and dynamic batching. Embedding sharing memoizes the embedding and computation graph for repeated expressions, saving memory and computation time. Dynamic batching allows for efficient batching of operations on different inputs, utilizing parallel acceleration from multi-core CPUs and GPUs. The approximate speedups from embedding sharing and dynamic batching in representing proof states increase with larger models. Using interpreter-inspired embeddings, proof states are embedded into R D for training models for position evaluation and tactic prediction tasks. Position evaluation involves classifying predictions into close, medium, and far categories, while tactic prediction groups tactics into equivalence classes and includes tactic arguments in training two models. The models predict tactics and arguments, with arguments coming from local, global, or user-created terms. The dataset uses have tactics, requiring the model to make conjectures. Baseline models focus on predicting the presence or absence of terms in the context. Labels are skewed towards absence, so precision-recall curve is more important. The text discusses training SVM and RNN models for predicting tactics and arguments based on heuristic features and embedding strategies. SVM outperforms a baseline model, and RNN models are trained with specific parameters and optimization techniques. The focus is on balancing label distribution and improving model performance. The study improved upon SVM baseline results by utilizing human supervision data and proof state embeddings. Experimentation showed that removing certain aspects of the prover did not significantly impact accuracies, suggesting redundancy in the data. The level of abstraction and representation of proofs in learning and theorem proving are key points of comparison. Other systems, like BID3, explore learning tactics from proof corpora in Isabelle for future application. ML4PG BID12 interfaces with various interactive theorem provers (ITPs) for entering proof scripts, while Holphrasm BID27 focuses on tactic argument synthesis. HolStep and BID26 use string encodings and DeBruijn representation of proof terms for premise selection. GamePad provides a structured representation for experimenting with extensions. BID4 explores learning tactic-level proof search in Isabelle using hand-crafted features on string encodings of proof states. The curr_chunk discusses different approaches to automated theorem proving, including premise selection and clause selection tasks using neural network models. Learning-based methods have been shown to successfully prove lemmas in projects like Flyspeck. Some researchers are exploring replacing traditional theorem proving routines with learned algorithms. For example, end-to-end differentiable proving replaces traditional unification with a trained algorithm. In this work, the focus is on theorem proving through a system that enables learning with human supervision. The key aspects highlighted include obtaining inputs that mimic human abstraction levels using an ITP, and building models based on the game-like structure of ITP proofs. GamePad is used to preserve proof structure for model building. In this study, the focus is on building models using the game-like structure of ITP proofs for tactic prediction on toy and real-world datasets. The approach involves distinguishing syntax from semantics of terms by providing structured representations for more semantic structure exploitation. The aim is to explore machine learning in interactive theorem proving, with GamePad serving as a starting point. Future work includes designing new benchmarks for human-level proofs, such as more challenging algebraic problems like solving infinite sums or integrals. Future work in interactive theorem proving includes defining new domains in Coq using GamePad to build provers that learn from example proofs. Another direction involves building models that explore true statements and synthesize arguments to tactics like have. Additionally, there is potential in utilizing end-to-end training with reinforcement learning and Monte-Carlo tree search for human-level proofs."
}