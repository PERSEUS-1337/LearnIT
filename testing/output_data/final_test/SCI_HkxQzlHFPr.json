{
    "title": "HkxQzlHFPr",
    "content": "In natural language inference, the semantics of certain words are considered superficial and can lead to overfitting. First-order logic is used to identify and discard this superficial information, leading to two inductive biases. A neural network-based approach incorporating these biases shows significant improvements in experiments. Removing specific word semantics can still allow for inference of contradiction in sentence pairs. In natural language inference, certain words like Avatar, fun, adults, and children are considered superficial and can lead to overfitting in models. By discarding this superficial information during inference, we can prevent overfitting and improve model generalization. Removing specific word semantics still allows for inferring contradiction in sentence pairs. In natural language inference, certain words like Avatar, fun, adults, and children are considered superficial and can lead to overfitting in models. Some approaches, like HEX, aim to reduce overfitting by identifying and discarding superficial information. The attention mechanism in NLP can also help by assigning low attention scores to irrelevant words. This mechanism focuses on semantic similarity rather than superficial semantics. In natural language inference, superficial information like the semantics of words such as Avatar, adults, and children can lead to overfitting in models. Previous approaches have struggled to model this superficial information, lacking a mathematical definition for it. This paper addresses the issue using first-order logic (FOL) to explain superficial information and proposes two inductive biases for their NLI model design. By representing sentences with FOL, the model can capture and utilize this superficial information effectively. The text discusses using first-order logic (FOL) to address superficial information in natural language inference models. It explains how the entailment or contradiction between sentences can be represented using FOL, focusing on non-logical symbols. The paper suggests that changing these symbols does not affect the logical results of the inference process. The text discusses the gap between first-order logic (FOL) representation and natural language understanding, emphasizing the importance of common sense in inference. Common sense helps identify contradictions between sentences, highlighting the challenge of identifying superficial information in FOL due to the necessity of non-logical symbols for joint inference. The text discusses using FOL to identify superficial information by defining non-logical symbols as superficial for all possible common sense. It shows the necessary condition for superficial symbols to avoid the effect of common sense, related to FV independence. Two inductive biases for superficial information identification are proposed: word information discard and correspondence information representation. A neural network-based approach is suggested to incorporate these biases while retaining correspondence information of discarded words. The text discusses using FOL to identify and discard superficial information for robust natural language inference. It proposes the problem of identifying superficial information and analyzes it from the perspective of FOL. The key contribution is defining what information is superficial and how it affects inference. The text discusses using FOL to identify and discard superficial information for robust natural language inference. It proposes the problem of identifying superficial information and analyzes it from the perspective of FOL. The key contribution is defining what information is superficial and how it affects inference. The experimental results verify the effectiveness of the proposed method, which focuses on learning robust natural language representations, especially in the face of adversarial examples. The text discusses using adversarial training to learn a unified data distribution for different domains in NLP models. It introduces HEX, a method to project textural information out of images, and proposes learning robust representations by omitting superficial information through attention mechanisms. Recent studies have shown that attention mechanisms, used in various NLP tasks, cannot effectively filter out superficial information from overlapping words. This limitation hinders the accuracy of Natural Language Inference models, which rely on neural networks for improvement. State-of-the-art approaches incorporate attention mechanisms to model word correlations and fine-tune large-scale pre-training models for better performance. The curr_chunk discusses the relation between natural language inference and First Order Logic (FOL) inference, highlighting the mapping between the two with common sense. It emphasizes the complexity of converting natural language sentences to FOL sentences and the importance of external common sense in understanding natural language. The curr_chunk explains the process of converting natural language sentences to FOL sentences without requiring an algorithm. It discusses analyzing the entailment relation in NLI and the definition of superficial information in FOLs with respect to common sense. The complexity of analyzing superficial symbols with arbitrary common sense is highlighted. The curr_chunk discusses the necessary conditions for identifying superficial non-logical symbols in FOL sentences. Theorem 1 provides a condition based on FOL(s 1) and FOL(s 2), while Theorem 2 introduces a method using non-logical symbol sets. These theorems aim to address the challenge of analyzing superficial symbols in common sense reasoning. The curr_chunk explains how replacing non-logical symbols in FOL sentences does not affect their implication, as shown in Theorem 2. It emphasizes the importance of distinct non-logical symbols in preserving relationships and discusses inductive biases in neural networks. The curr_chunk discusses the representation of word information using neural networks, specifically focusing on the use of word embeddings and scalar values to indicate the likelihood of a word being superficial. It also highlights the importance of correspondence information in preserving relationships when replacing non-logical symbols in FOL sentences. The curr_chunk explains how the correspondence information of superficial symbols affects inference in NLI. It introduces a graph neural network to represent this information, allowing it to propagate through different word positions. The neural network consists of three modules, including a superficial information projection module. The curr_chunk discusses the computation of superficial factors for words in NLI models, where \u03b1=1 indicates non-logical symbols to keep during inference. It also mentions using NLI models and a graph neural network to represent correspondence information. The curr_chunk explains how the embedding of words in a sentence pair is computed using a superficial factor \u03b1, which is determined by a perceptron layer. It also discusses representing cross-sentence correspondence information using a graph neural network. The curr_chunk discusses retaining correspondence information in sentence pairs using a graph neural network. It explains how the weight of the edge is determined by \u03b1, updates the states using a parameter matrix, and represents correspondence using an adjacency matrix. The example in Figure 3 illustrates how words are connected in different positions in the sentence pair to retain correspondence information. The curr_chunk discusses datasets and competitors used in the experimental setup for evaluating the effectiveness of the proposed framework for retaining correspondence information in sentence pairs. The effectiveness of proposed approaches in retaining correspondence information in sentence pairs is evaluated through ablation studies. Inductive biases like word information discard and correspondence information representation are tested, with results showing both biases improve effectiveness, with word information discard being more crucial. State-of-the-art NLI results are obtained using pre-training models like Elmo and Roberta Liu et al. as word embeddings modules. The proposed method outperforms the original ESIM+ELMO by a large margin in classification. Results show slight improvements for Roberta due to its high initial accuracy. The model's robustness is evaluated in unseen domains, with significant accuracy improvements using the proposed method. Visualization of \u03b1 in Figure 4 demonstrates successful projection of superficial words. In this paper, the authors study the problem of projecting superficial information out for NLI to prevent overfitting and increase model robustness. They explain the concept from the perspective of FOL and conduct experiments to verify the effectiveness of their approach, which significantly improves baselines in single domain settings. The goal is to predict labels of test data in unseen domain NLI, where the test domain is unknown during training. The syntax of FOL symbols is specified, and experimental settings and datasets are discussed. Experimental settings and datasets include using a computer with specific hardware specifications, adjusting SNLI labels for comparison with MNLI, evaluating MRPC accuracy and f1-score due to label imbalance, and employing different pooling layers for sentence pair classification models. Hex utilizes a textural model for superficial information and a raw model for all information. The text discusses the use of different models and hyperparameters for generating information in NLP tasks. It mentions the use of BiLSTM, ESIM, CAFE, MwAN, AMSGrad optimizer, AdamW optimizer, GloVe vectors, and graph neural networks with specific settings for each model. Ablations over unseen domains and attention matrices are also mentioned. The attention matrix in ESIM is compared with and without discarding superficial information. The discarded information leads to a more intuitive matrix focusing on key words indicating contradiction, unlike the standard ESIM matrix which emphasizes non-critical repeated words."
}