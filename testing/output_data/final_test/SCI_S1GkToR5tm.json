{
    "title": "S1GkToR5tm",
    "content": "The proposed Discriminator Rejection Sampling (DRS) scheme uses the discriminator of a GAN to correct errors in the generator distribution. It aims to recover the data distribution exactly, even when strict assumptions break down. DRS is shown to improve the Inception Score on ImageNet from 52.52 to 76.08, surpassing the state of the art SAGAN model. Generative Adversarial Networks (GANs) are a powerful tool for image synthesis, applied successfully to various tasks like semi-supervised learning, image editing, and style transfer. The training procedure involves two neural networks - a generator and a discriminator - playing a two-player game to generate realistic images. Research is focused on addressing stability issues in GAN dynamics. The research focuses on improving the quality of trained generators in Generative Adversarial Networks (GANs) by post-processing their samples using information from the trained discriminator. The equilibrium of the training procedure is reached when sampling from the generator is identical to the target distribution, but this is not always the case in practice. Trained GAN discriminators can be used for skill ratings of other generators, and the study explores if the information in the discriminator's weights can be used to enhance performance. The weights of the discriminator at the end of training can be used to improve the generator in Generative Adversarial Networks (GANs). Various reasons such as finite capacity, optimization in parameter space, and insufficient training time may hinder the transfer of useful information from the discriminator to the generator. The paper focuses on using the GAN discriminator in a rejection sampling scheme to correct errors in the GAN generator distribution. It proposes a scheme to recover the data distribution exactly, and introduces a practical algorithm called DRS. Experiments show that DRS improves the performance of the Self-Attention GAN, increasing the Inception Score to 76.08. The DRS scheme improves GAN performance, increasing Inception Score to 76.08 and decreasing Fr\u00e9chet Inception Distance to 13.75. GANs consist of a generator and discriminator trained together, with the discriminator determining the probability that an observation is real. The Inception Score and Fr\u00e9chet Inception Distance are popular evaluation techniques for GANs in image synthesis tasks. Inception Score and Fr\u00e9chet Inception Distance are evaluation metrics for GANs in image synthesis tasks. Inception Score measures the GAN's ability to generate samples classified by a pre-trained classifier, while FID computes the distance between Gaussians based on semantic embeddings. SAGAN, a state-of-the-art model, is used in experiments for conditional image synthesis tasks. SAGAN, a state-of-the-art model, utilizes large residual networks BID8, spectral normalization, and self-attention layers to better model long-range dependencies in image synthesis tasks. It also employs a lower learning rate for the generator and uses early stopping on the validation set for training. The model SAGAN utilizes large residual networks, spectral normalization, and self-attention layers to model long-range dependencies in image synthesis. The model is trained using a special hinge version of the adversarial loss and rejection sampling method for sampling from a target distribution. In this section, a rejection sampling scheme called Discriminator Rejection Sampling (DRS) is proposed for GANs. The algorithm aims to improve samples from the generator by using the discriminator to approximate the true data distribution. The idealized version of the algorithm is discussed, along with modifications to address challenges in realistic settings. The algorithm Discriminator Rejection Sampling (DRS) is proposed for GANs to improve generator samples by using the discriminator to approximate the true data distribution. It involves rejection sampling with p_g as the proposal distribution and p_d as the target distribution, allowing exact sampling from p_d. The analysis assumes optimizing the discriminator in the space of density functions rather than changing its parameters. The algorithm Discriminator Rejection Sampling (DRS) in GANs uses the discriminator to approximate the true data distribution through rejection sampling. It involves optimizing the discriminator in the space of density functions, not parameters, to allow exact sampling from the target distribution p_d. However, there are practical issues with this approach, such as the inability to perform optimization over density. The Discriminator Rejection Sampling (DRS) algorithm in GANs aims to approximate the true data distribution using the discriminator for rejection sampling. However, practical issues arise, such as the inability to optimize over density functions and the challenges in computing acceptance probabilities accurately. The analysis assumes infinite samples from p_d, which is not feasible in practice, leading to difficulties in optimizing D. Instead of this complex process, a simpler approach of setting a threshold T to discard samples with D*(x) < T is suggested, although it may not fully recover p_d. The Discriminator Rejection Sampling (DRS) procedure is an adjustment to the idealized rejection sampling in GANs. It addresses issues with computing the true data distribution and optimizing the discriminator. Empirical success suggests that approximating D* is acceptable, possibly leading to less overfitting. The Discriminator Rejection Sampling (DRS) procedure adjusts idealized rejection sampling in GANs by approximating D* to avoid overfitting. Computing M is challenging as D* cannot be computed directly, so estimation from samples is used. The estimation phase uses 10,000 samples to estimate D* M, which is then updated during the sampling phase. This may lead to slight overestimates of acceptance probabilities for samples processed before a new maximum is found. The acceptance probability for samples processed before finding a new maximum is not a major concern, as the increase in maximum is rare and small. However, low acceptance probabilities can be an issue when working with realistic data sets. To address this, a method to compute F(x) can be used to adjust the acceptance probability. The acceptance probability can be adjusted using a method to compute F(x) with a small constant \u03b3 for numerical stability. The hyperparameter \u03b3 modulates the overall acceptance probability, with very positive \u03b3 leading to all samples being rejected and very negative \u03b3 leading to all samples being accepted. An analysis of the effect of adding \u03b3 is shown in Figure 2. The study explores the use of Discriminator Rejection Sampling (DRS) to improve Generative Adversarial Networks (GANs) performance. DRS is demonstrated on a synthetic dataset and ImageNet dataset, showing enhancements in image recognition tasks. The GAN model used consists of neural networks with ReLu activations and a prior distribution of a 2D Gaussian with mean of 0. The study demonstrates the use of Discriminator Rejection Sampling (DRS) to enhance Generative Adversarial Networks (GANs) performance. DRS is applied to a synthetic dataset and ImageNet dataset, improving image recognition tasks. The GAN model includes neural networks with ReLu activations and a prior distribution of a 2D Gaussian with mean of 0. DRS increases the fraction of high-quality samples from 70% to 90% without reducing the number of recovered modes. The study demonstrates the use of Discriminator Rejection Sampling (DRS) to enhance GAN performance by increasing the fraction of high-quality samples without reducing the number of recovered modes. The results show that DRS improves the quality of samples and confirms that it accepts samples near the tails of Gaussian distributions. Fine-tuning a SAGAN with a lower learning rate significantly improved Inception Score and FID. An extra layer was added to the discriminator for binary cross-entropy loss. Inception Score and FID averages were calculated over multiple trials. The Inception Score and FID averages significantly improved for both models with the use of DRS in realistic settings involving large datasets and sophisticated GAN variants. Qualitative analysis of ImageNet results showed that samples with high acceptance probabilities had better visual quality and were more recognizable as belonging to a distinct class. Additionally, the behavior of the discriminator was studied by generating visually realistic and unrealistic images from randomly chosen ImageNet categories. In a rejection sampling scheme using GAN discriminator, acceptance probabilities decrease from left to right as images are interpolated in latent space. The discriminator can correct errors in the generator distribution, and under strict assumptions, recover the data distribution exactly. The text discusses the use of rejection sampling in GAN generators to improve image quality. It mentions how acceptance probabilities decrease as images are interpolated in latent space, leading to better visual quality. The scheme can potentially be applied to VAE decoders as well. The idea of using a human critic for rejection sampling is also explored. The efficacy of rejection sampling in image synthesis models is explored by using better proxies for the human visual system. Different acceptance rates are achieved by changing \u03b3, affecting the final Inception score. Rejecting more samples beyond a certain rate does not provide additional benefits. The correlation between acceptance probabilities assigned by DRS and the recognizability of synthesized samples is also discussed. The efficacy of rejection sampling in image synthesis models is explored by using better proxies for the human visual system. Different acceptance rates are achieved by changing \u03b3, affecting the final Inception score. Rejecting more samples beyond a certain rate does not provide additional benefits. The correlation between acceptance probabilities assigned by DRS and the recognizability of synthesized samples is also discussed. The acceptance probability assigned to each sample by DRS is compared to the maximum probability of belonging to one of the 1K categories based on a pre-trained Inception network. Improving the discriminator performance is expected to boost the final inception score substantially. The effectiveness of Discriminator Rejection Sampling in image synthesis models is confirmed by comparing visually-realistic generated samples with nearest neighbors in the ImageNet training data using fc7 features from a pre-trained VGG16 model."
}