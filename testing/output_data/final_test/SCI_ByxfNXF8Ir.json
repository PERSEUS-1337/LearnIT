{
    "title": "ByxfNXF8Ir",
    "content": "Backpropagation is the driving force behind artificial neural networks today. Neuroscientists are exploring reinforcement learning as an alternative, but its convergence rate is not ideal. A hybrid learning approach is proposed, where neurons use RL-type strategies to approximate gradients for backpropagation. This approach shows promising results in matching the performance of gradient-based learning on various networks. Learning feedback weights offer a biologically plausible way to achieve good performance without strict learning rules. The brain's method of solving the credit assignment problem during learning remains unknown. The assignment problem in learning involves how neurons determine their role in outcomes and adjust their activity for improvement. Biologically plausible solutions include reinforcement learning algorithms, but scalability issues exist. Backpropagation in artificial neural networks is more efficient for credit assignment, but implementing it in realistic neural networks poses challenges. Backpropagation in biologically realistic neural networks poses challenges due to the need for weight transport, which is not observed in neural circuits. Modifications like feedback alignment have been explored, but scalability issues arise in complex network architectures. A proposed solution involves using an RL algorithm to train a feedback system for learning. Our proposed method uses a REINFORCE-style perturbation approach to train a feedback signal for learning in neural networks. It overcomes limitations of fixed random feedback weights and can be applied in convolutional networks. This approach demonstrates a biologically realistic way for the brain to perform gradient descent-like learning. Backpropagation computes error signal\u1ebd i in a top-down fashion, replacing \u03bb i with an approximation for parameters B. Stochasticity in biological neural networks generates noisy responses for estimating gradients to optimize baseline loss L. Node perturbation with a four-layer network and MSE loss is used to solve MNIST. Feedback parameters B i+1 are estimated using the proposed method. The system approximates loss gradients using feedback parameters estimated through a least squares problem. B is updated with stochastic gradient-descent, while W is updated using synthetic gradients. The alignment between feedforward and feedback matrices is closer with node perturbation compared to feedback alignment. Studies have shown that sign congruence of the feedforward and feedback matrices is key for good performance. Node perturbation shows higher sign congruence and comparable learning performance to backpropagation. Hyperparameters were found through random search. Feedback alignment has shortcomings in auto-encoding networks with tight bottleneck layers. Node perturbation outperforms feedback alignment and is comparable to ADAM in a simple auto-encoding network test. Node perturbation outperforms feedback alignment and is comparable to ADAM in learning error signals. The noise added during feedback weight estimation serves as regularization, resulting in a more evenly distributed separation of digits in the latent space. Backpropagation and ADAM show more structured representations, while feedback alignment fails to learn a useful representation. The method of node perturbation successfully communicates error signals through thin layers of a network. Testing on a CNN solving CIFAR10 with learned feedback weights, a test accuracy of 75.2% is achieved, outperforming fixed feedback weights and backpropagation. This demonstrates the method's effectiveness in solving computer vision problems without weight transport. The perturbation-based synthetic gradient method can solve challenging computer vision problems without weight transport. This hybrid approach can be used in fully connected and convolutional networks, removing the symmetric feedforward, feedback weight requirement of backpropagation. It is a step towards more biologically-plausible deep learning and can solve large-scale problems. Previous research has provided insight into how feedback alignment works, but recent studies show weaknesses can be addressed by imposing sign congruent feedforward and feedback matrices. Our work addresses the shortcomings of feedback alignment by adjusting weights to provide a useful error signal. Unlike previous methods, we do not divide learning into two phases or train feedback weights layer-wise. Our approach involves separate learning of feedforward and feedback weights, which is consistent with neurobiology. Cells have apical and basal compartments that allow for separate integration of feedback and feedforward signals. Noisy perturbations are common in neural learning models, with various mechanisms to measure or approximate noise. Our model involves subtracting a baseline loss to reduce estimator variance without affecting the expected value. Plausible learning rules can efficiently learn feedback signals, informing models of learning in the brain and artificial networks. This approach could be implemented in neural circuits. The model reviews key components such as data distribution, linearized loss function, and backpropagation of error signals to estimate parameters. It aims to show that parameters converge with enough data by defining synthetic gradients without noise. The deterministic nature of the system and convergence of the power series around zero are crucial for proving consistency. The expectation of the Taylor series approximation must be well behaved for the model to work effectively. The Taylor series approximation must have a finite expected remainder term that goes to zero as c h \u2192 0. Assumptions A1, A3, and A4 are made regarding the noise, error matrices, and bounded mean of remainder and error terms. Convergence of the final layer feedback matrix is crucial for the estimator to converge to the true feedback matrix. The conditional expectation of the estimator converges to the gradient under certain conditions. The remainder term must go to zero as c h \u2192 0, which is ensured if each moment of the noise is well-behaved. The problem (4) is close to a linear least squares problem, with the least squares estimator satisfying certain conditions. The estimator converges to the true feedback matrix, and convergence over the network layers is established when the activation function is the identity. The top layer estimate converges in probability to a certain value. Induction is used to show that the remaining layers also converge. The error signal is defined as the backpropagated error through the weight matrices. The least squares estimator is used, and convergence is established using the continuous mapping theorem and the weak law of large numbers. The induction assumption implies convergence of the error signal. The paper proves convergence of the node perturbation estimator in deep linear networks, showing that it solves the equation and converges to the true feedback matrix. Assumptions A1 and A2 are discussed, with a more general result for convergence with any subgaussian random variable. The paper discusses the convergence of the node perturbation estimator in deep linear networks, proving that it converges to the true feedback matrix. It is challenging to establish general conditions for the full rank of n (\u1ebd n ) T. Extensions of the theorem to non-linear networks may be possible, but the method of proof used is not directly applicable due to the complexities of non-linear cases."
}