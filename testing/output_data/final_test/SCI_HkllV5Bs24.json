{
    "title": "HkllV5Bs24",
    "content": "MTLAB is a new algorithm for learning multiple related tasks sequentially without interruptions or restarts at task boundaries. Predictors for individual tasks are derived from this process through an online-to-batch conversion step. MTLAB achieves sublinear regret of true risks across tasks in lifelong learning, improving generalization bound with total samples instead of per task or number of tasks. It can handle finite task sets and stochastic task sequences. Machine learning is widely used in various applications where tasks are often related or sequential. Multi-task learning BID3 is designed to improve prediction quality by sharing information between tasks, but it can also lead to negative transfer. Research is focused on understanding when negative transfer occurs and how to avoid it, especially in lifelong learning BID1 BID9 and task curriculum learning. A new approach to multi-task learning with strong theoretical guarantees is described. The new approach to multi-task learning, named MTLAB, decouples predictor learning from task structure, treating all tasks as parts of a single online-learning problem. It improves convergence rates and provides a sublinear bound on task regret with true risks, enhancing lifelong learning. The MTLAB approach in multi-task learning separates predictor learning from task structure, improving convergence rates and providing high probability bounds on expected risk for each task. By splitting tasks into homogeneous groups and learning individual predictors on subsequences of samples, negative transfer can be avoided. The PAC-Bayes framework in multi-task learning involves learning tasks with their own probability distributions over input-output pairs, aiming to minimize per-task risk. The PAC-Bayes framework studies the performance of stochastic predictors with a probability distribution Q over the hypotheses set. It adopts an online learning protocol for tasks and aims to bound the regret of a learned sequence of predictors with respect to a fixed reference distribution Q. The regret is defined using true risks, making it different from empirical risks. The MTLAB algorithm runs an online learning algorithm on samples from all tasks, ignoring task structure, and then converts it to predictors for individual tasks using online-to-batch conversion. The algorithm initializes with a decision set, distribution, and learning rate, updating predictors at each time step based on received datasets. The MTLAB algorithm outputs predictors for each task and sets a starting distribution for the next task. A regret bound for the true risks of the produced distributions is provided, along with a comparison to average regret bounds in a different setting. The MTLAB algorithm provides a regret bound for the true risks of the produced distributions, with comparisons to average regret bounds in different settings. Real-world implementations of MTLAB are discussed in the supplementary material, offering insight into its behavior when compared to independent task learning. The PAC-Bayes bound (e.g. BID6) provides an inequality for learning algorithms to minimize the upper bound with respect to Q. MTLAB, based on a similar objective, offers better guarantees by automatically providing relevant prior distributions for each task. The bound of Theorem 1 holds for any stochastic process over tasks, including lifelong learning scenarios where tasks are sampled independently from a hyper distribution. The lifelong risk in the setting of lifelong learning is defined as DISPLAYFORM0 using distribution and loss functions for each task. The risk of the Gibbs predictor is then determined. Results show an additive convergence rate O(DISPLAYFORM4) for MTLAB, with generalization error converging in scenarios with finite data per task and increasing tasks. Guarantees on MTLAB's multi-task regret are provided in the previous section. In this section, a modification is presented to provide guarantees for individual risks of each task, building upon previous results on MTLAB's multi-task regret. The discrepancy between tasks is defined, leading to Theorem 3 which establishes an inequality for predictors produced by MTLAB with a fixed prior distribution. The text discusses the convergence of a bound in the context of learning from drifting distributions. It explores the concept of negative transfer and improving bounds when discrepancies between tasks do not vanish over time. The idea of splitting tasks into subsequences for better performance is also considered. The text introduces an online algorithm, MTLAB.MS, for learning from drifting distributions by splitting tasks into subsequences based on task distances. The algorithm aims to prove error rates converging below a threshold \u03b5, ensuring convergence even when splitting tasks optimally may not lead to zero error rates. Pseudo-code for MTLAB.MS is provided in Algorithm 2. Theorem 4 states that running MTLAB.MS with task discrepancies as distances will result in subsequences with generalization error below a given threshold \u03b5 with high probability. The MTLAB.MS algorithm utilizes task discrepancies as distances to achieve low generalization error for subsequences with high probability. The algorithm involves receiving datasets, selecting representative tasks, and running a transfer algorithm to optimize parameters. The MTLAB.MS algorithm utilizes task discrepancies to achieve low generalization error for subsequences. The algorithm involves selecting tasks, running a transfer algorithm, and estimating discrepancies for each task. Two approaches for discrepancy estimation are detailed in the supplementary material. The algorithm allows for sequentially learning multiple tasks and achieving a sublinear regret bound. MTLAB's approach in lifelong learning achieves sublinear regret and faster convergence rates by not interrupting the learning process at task boundaries. It improves generalization error by considering the product of tasks and samples per task. A mechanism is introduced for unrelated tasks, showing that suitable subsequences can maintain convergence properties."
}