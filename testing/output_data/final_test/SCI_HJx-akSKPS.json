{
    "title": "HJx-akSKPS",
    "content": "In this paper, a new graph learning problem is studied: learning to count subgraph isomorphisms. The proposed dynamic intermedium attention memory network (DIAMNet) addresses the need for global inference in subgraph isomorphism counting by memorizing different subgraph isomorphisms for global counting. Experimental results demonstrate the effectiveness of the approach on both small and large graphs. Graphs are versatile data structures used in various applications like social network analysis, molecular structure analysis, and natural language processing. Learning with graphs has gained attention due to the effectiveness of neural network approaches. Existing graph representation learning algorithms focus on tasks like node classification and community detection. Subgraph isomorphism counting can be improved with learning-based approaches like DIAMNet, which enhances representation learning models for this global problem. In this paper, the focus is on learning to count subgraph isomorphisms, a global learning problem that supports various applications such as bioinformatics and chemoinformatics. Subgraph isomorphism is crucial for graph representation learning, and tasks related to identifying or counting subgraph isomorphisms have significant implications. In various fields like bioinformatics, chemoinformatics, and online social network analysis, pattern mining algorithms and graph database indexing approaches have been used to tackle subgraph isomorphism problems. However, these approaches face challenges with large-scale graphs due to exponential time complexity. Graph representation learning models have emerged as a solution, allowing for the effective capture of local structural information and enabling the learning algorithm to count subgraph isomorphisms from numerous examples. Graph representation learning models have emerged as a solution for counting subgraph isomorphisms from numerous examples. A dynamic intermedium attention memory network (DIAMNet) is developed to memorize local subgraph isomorphisms for global counting. The effectiveness and efficiency of different neural network architectures are evaluated on small and large datasets. This work introduces a novel approach to model the subgraph isomorphism counting problem using deep neural networks. The framework achieves good results on large graphs and patterns, demonstrating its effectiveness in addressing the subgraph isomorphism search task. Subgraph isomorphism search involves finding occurrences of a pattern in a data graph using mapping functions. It is an NP-complete problem and most algorithms are based on backtracking. Ullmann's algorithm, VF2, and GraphQL are examples of such algorithms. The search space grows exponentially as the pattern or data graph increases in size. Some algorithms use graph-index to filter out unnecessary graphs. Graph-index based algorithms like TurboISO and VF3 use weak rules to find candidate subregions and reduce searching space. Graph representation learning involves learning embedding vectors for each graph node, while graph neural networks provide a solution for representation learning that can be generalized to new graphs and unseen nodes. Many graph neural networks have been proposed since 2005, focusing on generalizing convolutional neural networks for graph data structures or relational graph structures with multiple types of relations. Recent advancements include the graph isomorphism network (GIN) and the use of recurrent neural networks (RNNs) for graph data. Additionally, sequence models with external memory have shown success in tasks like language modeling and shortest path finding on graphs. The subgraph isomorphism problem is a challenging task in graph theory, traditionally defined for simple graphs as an NP-complete problem. This problem has been generalized to counting problems over directed heterogeneous multigraphs, which remains NP-complete. The graph or pattern is represented as G = (V, E, X, Y), where V is the set of vertices and E is the set of edges. The subgraph isomorphism problem involves finding isomorphic mappings that preserve graph topology, vertex labels, and edge labels. It is defined as finding the number of different subgraph isomorphisms between a pattern graph and a graph. The subgraph isomorphism problem requires computing O(Perm(|V_G|, |V_P|) * d|V_P|) to solve by enumeration. Ullmann's algorithm reduces searching time, but computational cost grows exponentially as graph or pattern size increases. Using neural networks for distributed representations can reduce complexity to O( via attention mechanisms. In this work, the goal is to reduce computational complexity while maintaining performance in solving the subgraph isomorphism problem. The use of attention mechanisms and memory networks is proposed to achieve this. Different methods such as CNNs, RNNs, and Transformer-XL can be used for sequence inputs, while RGCN can be used for adjacent matrices and vertex features. The text discusses using RGCN to learn vertex representations with message passing from neighborhoods, followed by an interaction module to extract correlated features and a fully-connected layer for predictions. The difference between sequence encoding and graph encoding is highlighted, with the minimal element of a graph being an edge requiring attributes like source and target vertex ids, edge label, and vertex labels. The text discusses encoding graphs using minimum codes represented as 5-tuples, followed by encoding each 5-tuple into a vector using binary digits. The encoding process involves representing vertex id, vertex label, and edge label as one-hot vectors concatenated into a multi-hot vector. The encoding method discussed involves vectorizing 5-tuples as multi-hot vectors by concatenating one-hot vectors. This allows for easy calculation of graph and pattern dimensions. The encoding can be extended for larger values of vertices, labels, and dimensions without affecting previous models. To enhance graph embedding, new weights for new dimensions are initialized as zeros. Graphs are embedded as multi-hot matrices, and sequence modeling strategies like CNNs and RNNs are applied. Transformer-XL is used for learning long dependencies in graphs without disrupting temporal coherence. The Transformer-XL encoder functions as a feature extractor in the model. The Transformer-XL encoder acts as a feature extractor in graph models, with attention having full scope over the sequence. GNNs utilize adjacency matrices for information passing without the need for explicit vertex or edge ids. Sparse matrices can store adjacency information in simple graphs to reduce memory usage. RGCNs incorporate relation-specific transformations for heterogeneous graphs based on edge labels. Relational Graph Convolutional Networks (RGCNs) utilize basis-decomposition for parameter sharing and handle multi-relational data in knowledge bases. Two decomposition methods, basis-decomposition and block-diagonal-decomposition, are used to manage the growth in parameters with the number of relations. RGCNs implement sum-based GNNs for better graph structure capture, with variations named RGCN and RGCN-SUM. The Dynamic Intermedium Attention Memory Network (DIAMNet) is proposed to address the high computational cost in the attention mechanism. It uses an external memory to attend both the pattern and the graph in order. The Dynamic Intermedium Attention Memory Network (DIAMNet) utilizes an external memory as an intermedium to attend both the pattern and the graph in order. This dynamic memory is designed as a gated recurrent network, allowing for efficient processing of large-scale graphs. The external memory is divided into blocks that are updated at each time step using a multi-head attention mechanism. The DIAMNet uses an external memory to attend both the pattern and the graph. The memory is divided into blocks updated with a multi-head attention mechanism. The gates z j and z j control state updates, with trainable parameters U P , V P , U G , V G. Experimental results are reported, with more details in the Appendix. The pattern generator produces connected multigraphs without identical edges, while the graph generator first generates disconnected components with tractable subgraph isomorphisms. The generator uses neighborhood equivalence classes to control subgraph isomorphisms in the graph generation process. It merges components into a larger graph while ensuring no more subgraph isomorphisms are generated. Subgraph isomorphism search can be done in parallel. The goal is to evaluate if sequence models and graph convolutional networks perform well with limited data, acceptable running time, and if memory can improve predictions for NP-complete problems. Two datasets are generated to assess different neural architectures and prediction networks. In evaluating different neural architectures and prediction networks, two datasets are generated in different graph scales. There are 187 unique patterns in total, with 75 in the small dataset and 122 in the large dataset. Target data graphs are randomly generated, and multi-hot vectors are transformed using linear layers before feeding into representation modules. Five different representation models are implemented, including a CNN with 3 convolutional layers and max-pooling layers. Five different representation models are implemented: CNN with 3 convolutional layers and max-pooling, RNN with a 3-layer GRU model, TXL with a 6-layer Transformer encoder, RGCN with a 3-layer RGCN and mean-pooling, and RGCN-SUM with sum-pooling. Interaction layers include SumPool and MeanPool for comparison. The curr_chunk discusses different pooling methods such as MeanPool, MaxPool, and AttnPool in the context of using attention modules efficiently. The authors report that mean-pooling based attention is the best among the three variants. They compare the performance of their DIAMNet model with other interaction networks and describe the initialization strategy used. The memory with size information is fed into the next fully connected layers. In Appendix D.3, memory size and segment size in TXL are set to 64 for fair comparison. DIAMNet uses mean squared error for training and validation, with Adam optimizer and L2 penalty. Gradient clipping and dropout are applied to prevent overfitting. Leaky ReLU is used as activation functions in all modules. Shared parameters are utilized in the representation module to avoid overfitting due to limited patterns. In Appendix D.3, memory size and segment size in TXL are set to 64 for fair comparison. DIAMNet uses mean squared error for training and validation, with Adam optimizer and L2 penalty. Gradient clipping and dropout are applied to prevent overfitting. Leaky ReLU is used as activation functions in all modules. Shared parameters are utilized in the representation module to avoid overfitting due to limited patterns. Patterns are easy to overfit, so the same module with shared parameters is used for pattern and graph representation. Curriculum learning helps models converge better. Models in Table 3 are fine-tuned based on the best models in small settings. Training and evaluating were done on a single NVIDIA GTX 1080 Ti GPU using the PyTorch framework. The subgraph isomorphism counting problem is modeled as a regression task, with evaluation metrics including RMSE and MAE. ReLU is used for final predictions. F1 scores are reported for zero data in the binary classification analysis. In Table 2 and Table 3, F1 scores for zero and nonzero data are reported for different models, including trivial baselines. Running time comparisons with traditional searching algorithms are also conducted. Graph generation strategies are compared with the VF2 algorithm to avoid interference. Observations on representation architectures are discussed. Graph models outperform sequence models in Table 2, but require more time for inference. CNN is not suitable for the graph isomorphism counting problem due to its encoding method. RNN with sum-pooling performs better than TXL with memory. CNN tends to predict 0 for large graphs, with F1 score of 0.180. In our experiments, TXL's memory is limited to the representation of the previous segment, which can mislead the model. A longer segment for TXL may improve results but requires more GPU memory and training time. RGCN-SUM outperforms other models, showing the effectiveness of the sum aggregator in modeling vertex representation. The dynamic attention memory network in Table 2 demonstrates superior performance as a prediction layer compared to other methods. The dynamic attention memory network outperforms other pooling methods for all representation architectures. Sum, Mean, and Attention pooling are comparable, while max pooling performs the worst, especially with CNN or Transformer-XL. This suggests the importance of considering every context in pattern representation. The dynamic attention memory network achieves the best results by considering every context in pattern representation. DIAMNet can extract context effectively even when other representation layers do not perform well. RGCN is the best representation method for larger graphs, and dynamic memory is effective. Learning-based models are faster than traditional algorithms for subgraph matching. The learning-based models are faster than traditional algorithms for subgraph isomorphism counting. A comparison between the best model (RGCN+SUM) and the worst model (CNN) shows that CNN can improve with added memory. CNN+SumPool tends to predict count values below 400, while RGCN better represents graph structure, especially for larger patterns. Memory can enhance CNN's representation power, leading to better performance. Additional results can be found in Appendix F. In this paper, the challenging subgraph isomorphism counting problem is studied using deep graph representation learning. The NP-complete problem is converted into a learning-based problem, allowing for prediction of subgraph isomorphism counts in polynomial time. A dynamic intermedium attention memory network is developed to handle global inference, with two datasets used to evaluate different models. Results indicate that learning-based methods show promise for subgraph isomorphism detection, and memory networks aid in global inference. Detailed analysis of model behaviors for various patterns, graph sizes, and labels is also performed. Results show potential for improving vertex label size in subgraph isomorphism counting. Real-world applications include question answering and information retrieval. Pretrained models may have domain adaptation power for broader applications. Pattern and graph generators are needed for dataset generation. The algorithm for generating graphs involves creating a directed tree and adding random edges with labels. Hyperparameters control subisomorphism density. Components are merged into a large graph after generating directed trees. Shuffling is done to enhance dataset security. The algorithm generates a pattern by creating a directed tree with random edges and labels. Components are merged into a large graph, and shuffling enhances dataset security. The function AddRandomEdges connects components without creating new subgraph isomorphisms. The NEC tree in TurboISO explores candidate regions for matching. The NEC tree in TurboISO explores the candidate region for further matching by recording equivalence classes and necessary conditions of the pattern. It helps generate more data and search subisomorphisms efficiently. FilterNet is added to adjust graph encoding for better matching of subisomorphisms. The FilterNet adjusts graph encoding for better matching of subisomorphisms using various pooling strategies like sum-pooling, mean-pooling, and max-pooling. Different representation models with interaction networks are compared in a small dataset, showing results in Table 5. Representation models with different interaction networks in a small dataset show that AttnPool and DIAMNet usually outperform other pooling methods. AttnPool struggles with small pattern or graph sizes, focusing more on the zero vector than the pattern pooling result. DIAMNet performs the best across all pattern/graph sizes. MaxPool predicts higher values for small patterns and large graphs, while AttnPool predicts small numbers except for specific vertex sizes. When bins are ordered by vertex label sizes or edge label sizes, all three interaction modules perform similarly. AttnPool tends to predict zeros for small patterns, MaxPool struggles with complex patterns with more vertex labels, and DIAMNet's performance is not as good. Results show that MaxPool and DIAMNet perform well with edge labels, but AttnPool is not satisfactory. Different representation modules show varying performance in different views, with CNN performing poorly with large graph sizes and complex patterns, indicating its limitation in extracting global information. RNN performs worse with large graphs, especially with small patterns. When graphs are large, small patterns are worse, as shown in Figure 8e. RGCN-SUM with DIAMNet is not affected by edge sizes as it learns vertex representations directly."
}