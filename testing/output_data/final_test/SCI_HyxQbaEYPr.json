{
    "title": "HyxQbaEYPr",
    "content": "In this paper, a novel method called SRatio is proposed to improve the performance of simple models by reweighting a training dataset using information from high performing complex models. This method leverages the per sample hardness estimate of the simple model, which is a new concept compared to prior works. Additionally, the paper generalizes the concept of attaching probes to intermediate layers of a neural network to other commonly used classifiers. The paper introduces the SRatio method to enhance simple models by reweighting training data based on insights from complex models. Experimental results show superior performance on various datasets, approaching that of complex models in some cases. The approach is motivated theoretically by demonstrating that the weighted loss of simple models bounds the loss of complex models. Simple models like decision trees or shallow neural networks are still valuable in scenarios requiring interpretability, limited data, or computational constraints. In scenarios with memory/computational constraints, interpretable models are preferred over complex ones for better on-field performance. Interpretable models allow for precise knowledge of decision-making processes, enabling potential process improvements. Local explainability methods can provide insights into black box models, but their explanations may not always be accurate. Additionally, there is a growing concern about the carbon footprint left behind. In this paper, a method called SRatio is proposed to reweight the training set for improving simple models using a highly accurate complex model like deep neural networks or boosted trees. The method is applicable to various complex-simple model combinations and is focused on interpretability and deployment in resource-limited settings. The SRatio method aims to enhance the performance of simple models by reweighting the training set using a highly accurate complex model. It generalizes the concept of probes and leverages the simple model's confidences to improve performance, outperforming competitors in experiments and approaching the complex model's accuracy in some cases. The SRatio method enhances simple models by reweighting the training set using a complex model. It outperforms competitors and can approach the accuracy of the complex model. Knowledge Distillation is a popular approach for building simpler neural networks by minimizing the cross-entropy loss based on calibrated confidences of a more complex network. The thinning down of convolutional neural networks was shown, but it is unclear how to apply it to modern architectures like ResNets. The weighting of training inputs approach can be easily applied to different architectures and models optimizing losses other than cross-entropy. Strategies like Distillation and using soft targets with uncertainty estimates have been used to inform simpler models on larger datasets with noisy labels. In Furlanello et al. (2018), a student neural network is trained to fit soft scores rescaled by temperature, compared with distillation-like schemes. Frosst & Hinton (2017) introduce soft decision trees to fit soft targets of a neural network. Ren et al. (2018) suggest reweighting samples to improve deep learning robustness. The focus is on using knowledge from a pre-trained complex model to enhance a simple model through sample weighting. In ProfWeight (Dhurandhar et al., 2018b), the training inputs are weighted to improve a complex model, but their method is limited to neural networks. Other approaches like Curriculum Learning and Boosting also use sample weighting, but with different motivations and setups. These methods may not have constraints like interpretability or limited memory/power. In ProfWeight (Dhurandhar et al., 2018b), training inputs are weighted to enhance a complex model, limited to neural networks. Unlike Curriculum Learning and Boosting, our method does not automatically grade example difficulty during training. Our approach improves simple models using predictions from both complex and simple models, focusing on hardness assessment. The key novelty lies in using the simple model's prediction, making the theory practical and non-trivial. Graded classifiers extract progressive information from models beyond neural networks, showing improved performance compared to using only the output of a complex model. This approach contrasts with the covariate shift setting, where source and target distributions differ in input but not output. In the covariate shift setting, importance sampling is used to mimic the target distribution when source and target data distributions differ. In this case, the dataset is the same but the classifiers are different. To make the simple model approach the complex model's performance, samples are weighted by p(y|x) q(y|x). This method is described in section 3.3 as a way to reduce the expected cross-entropy loss of a model. The cross-entropy loss of a model can be optimized by reweighting samples based on an accurate complex model, leading to better solutions. By re-weighing every sample and reoptimizing using a simple model training algorithm, the loss can be minimized. This approach is valid and sound, as it helps the simple model approach the performance of the complex model. The approach involves reweighting samples based on a more accurate complex model to optimize the cross-entropy loss of a simple model. This helps the simple model approach the performance of the complex model by minimizing the loss through re-optimization. The upper bound in the proof quantifies the bias introduced by weighting for a specific dataset, with the optimal \u03b2 determined through cross-validation. Assuming w \u2265 1 suggests that the complex model finds it easier to classify inputs correctly compared to the simple model, especially if the complex model is highly accurate. The approach involves reweighting samples based on a more accurate complex model to optimize the cross-entropy loss of a simple model. Stressing inputs that are somewhat hard for the simple model but easier for the complex model is crucial for information transfer. Ranking inputs based on the assessment of the simple model can lead to better generalization. Our method, SRatio, is a significant conceptual jump as it considers the simple model's behavior to improve itself. It generalizes the idea of using the complex model's confidences to rank inputs, incorporating lower layers or simpler forms when necessary. The proposed method SRatio generalizes the idea of using complex model confidences to rank inputs by attaching probes to intermediate layers of a deep neural network. This approach led to significantly better results over the state-of-the-art, improving the quantification of input difficulty. The proposed method SRatio improves input difficulty quantification by using complex model confidences to rank inputs and attaching probes to intermediate layers of a deep neural network. It involves computing prediction errors for graded classifiers, determining weights for inputs, ignoring extremely hard examples, and retraining the simple model with learned weights. The notion of graded outputs involves classifiers that are \u03b4-graded for some \u03b4 \u2208 (0, 1]. This means a sequence of classifiers is at least as accurate as the ones preceding it for inputs with a probability measure of at least \u03b4. Examples of producing \u03b4-graded classifiers for different models in practice are provided, including Deep Neural Networks. \u03b4-graded classifiers are discussed for different models in practice. For Deep Neural Networks, probes are used as linear classifiers on intermediate layers, with lower layer probes being less accurate than those above them. Boosted Trees can be ordered by boosting algorithms, while Random Forests can order trees based on performance. In practice, different models like Deep Neural Networks, Boosted Trees, and Random Forests can be ordered or grouped based on performance. For non-ensemble models, graded classifiers can be formed by taking different order Taylor approximations of functions or using feature selection methods. The input for the learning algorithm includes graded classifiers and the simple model. In practice, different models like Deep Neural Networks, Boosted Trees, and Random Forests can be ordered or grouped based on performance. Graded classifiers can be formed by taking different order Taylor approximations of functions or using feature selection methods. The input for the learning algorithm includes graded classifiers and the simple model. The weighted average confidence of graded classifiers more accurate than the simple model is calculated to adjust the weights for inputs, reducing variance and improving performance. In this section, the approach is empirically validated compared to other methods to enhance simple models using boosted trees and random forests on 6 real datasets from UCI. Data characteristics are provided in the appendix. The performance of different methods in enhancing a single CART decision tree and a linear SVM classifier is evaluated. Comparison is made with ConfWeight and Distill-proxy models as proxies to Distillation. Distill-proxy 1 and Distill-proxy 2 serve as proxies to Distillation for enhancing simple models using boosted trees and random forests. Distill-proxy 1 uses hard targets from complex models as labels, while Distill-proxy 2 fits soft probabilities of complex models with regression versions of trees and SVM. Results are reported for Distill-proxy 1, with datasets split into 70% train and 30% test. Performance is averaged over 10 random splits and presented in Table 8 with 95% confidence intervals. Graded classifiers based on complex models are formed for our method. The method involves forming graded classifiers based on complex models with 100 trees in total for boosted trees and random forests. Optimal values for \u03b3 and \u03b2 are determined through 10-fold cross-validation. The complex model used is an 18 unit ResNet with 15 residual blocks, while simpler models consist of 3, 5, and 7 Res units with varying numbers of filters. Each unit includes two 3 \u00d7 3 convolutional layers, and the final output is obtained through a fully connected layer with 10 logits. The study involves training 18 graded classifiers using linear classifiers attached to intermediate representations of ResNet units. Training sets from the CIFAR-10 dataset are split for complex and simple models, with distillation using soft targets for training the simple model. In experiments on 6 UCI datasets, the method consistently outperformed competitors in 14 out of 24 cases, tying in the remaining 10. The best performance was observed in cases involving datasets like Ionosphere and Musk, where the method enhanced the performance of simple models. Our method enhances the performance of simple models, matching that of complex models on certain datasets like Musk. Linear SVM performs best on the Ovarian Cancer dataset due to its high dimensionality and few examples. The small fraction of the training set assigned 0 weights based on parameter \u03b2 contributes to the success of our weighting method. In the Ovarian Cancer dataset, SVM outperformed complex models, with no points having weight 0. The Y-axis in figure 1 shows the difficulty of correctly classifying a point based on its nearest neighbors. Points with 0 weight are difficult to classify, while the highest weighted points have neighbors from the same class 50% of the time. This highlights the challenge simple models face in classifying 0 weight points. The simple models struggle to classify points with 0 weight, while the highest weighted points help outline an important decision boundary. Our method outperforms other state-of-the-art methods on the CIFAR-10 dataset. In resource-limited settings, simpler models like SM-3 and SM-5 are more practical. Simple model predictions can significantly improve performance. Our method proposes building an accurate complex model first to enhance a desired simple model, taking into account both models' difficulty levels. Empirical evidence shows our method outperforms or matches the best solutions across various datasets and complex models like boosted trees, random forests, and ResNets. Our method outperforms or matches the best solutions across various datasets and complex models like boosted trees, random forests, and ResNets. Probes at various units and their accuracies on the training set are used in the ProfWeight algorithm to choose the unit above which confidence scores need to be averaged. The standard learning rate schedule is followed for over 80k training steps in Tensorflow. A simple model is trained on the training set with weighted samples based on confidence scores from the complex model. The simple model is also trained using soft targets from the complex model's softmax outputs rescaled by temperatures of 0.5 and 40.5. The ProfWeight algorithm assigns weights to samples in the training set based on probe confidence scores. The SRatio method averages confidence scores and divides by simple models' confidence, optimizing over \u03b2 values. In Table 8, results for the second variant of Distillation Distill-proxy 2 are provided, showing % errors with confidence intervals for regression versions of trees and SVM on six real datasets. Distill-proxy 1 results, reported in the main paper, are superior to these, with Boosted Trees and Random Forest as complex models and a single decision tree and linear SVM as simple models."
}