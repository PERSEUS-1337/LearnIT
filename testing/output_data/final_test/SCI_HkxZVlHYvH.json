{
    "title": "HkxZVlHYvH",
    "content": "Statistical inference methods are crucial in machine learning, with most advanced algorithms being variations of Markov chain Monte Carlo (MCMC) or variational inference (VI). However, both methods face practical limitations: MCMC can be computationally intensive, while VI may exhibit significant bias. The proposed hybrid method improves upon MCMC and VI by reducing simulation bias through gradient-based optimization. It generates low-biased samples by optimizing MCMC hyper-parameters and increasing simulation length, balancing approximation bias and computational efficiency. Results show promise compared to recent hybrid methods. The proposed hybrid method, ergodic inference (EI), improves upon MCMC and VI by tuning hyper-parameters to reduce bias and increase simulation length. It balances approximation bias and computational efficiency, showing promise compared to recent hybrid methods. Ergodic inference (EI) improves MCMC and VI by tuning hyperparameters for faster convergence to target distribution. It optimizes an objective function based on the logarithm of the target density, generating independent samples with no correlations. EI balances computational complexity and bias, offering lower approximation bias and decreasing bias with longer MCMC chains. It has lower computational cost compared to related baselines. Monte Carlo statistical inference approximates expectations under a given distribution using simulated samples. In a Bayesian setting, we typically work with the unnormalized density function \u03c0 * (x|y) given by the product of the prior p(x) and the likelihood p(y|x). Markov chain Monte Carlo (MCMC) casts inference as simulation of ergodic Markov chains that converge to the target distribution \u03c0. The computational complexity per simulated sample of EI is generally higher than in VI. Monte Carlo statistical inference approximates expectations under a given distribution using simulated samples. In a Bayesian setting, the unnormalized target density \u03c0 * is used for Markov chain Monte Carlo (MCMC) inference. MCMC kernels are constructed by sampling an auxiliary variable, creating a candidate sample, and accepting proposals based on the Metropolis-Hastings correction step. The joint MCMC parameters are denoted by \u03c6. Hamiltonian Monte Carlo (HMC) is a successful MCMC method that uses the leapfrog algorithm to simulate Hamiltonian dynamics. The method involves choosing an auxiliary Gaussian distribution and iteratively generating unbiased samples through MCMC transition kernels. Variational inference (VI) is a popular alternative to MCMC for generating approximate samples from \u03c0. Unlike MCMC, VI reduces sample bias by framing it as an optimization problem, fitting a parametric approximate sampling distribution P. Variational inference (VI) optimizes the evidence lower bound (ELBO) by fitting a parametric sampling distribution P to the target distribution \u03c0. The approximation bias in VI is defined as the gap between the ELBO and the log normalizing constant log Z, with the Kullback-Leibler (KL) divergence used to measure this bias. Variational approximations often use simple parametric families like the multivariate Gaussian distribution, which can lead to computationally efficient algorithms but may result in biased samples due to oversimplified approximations. Designing variational approximations to minimize bias while ensuring tractable entropy is a key challenge. Designing variational approximation for low bias under tractable entropy and efficient sampling using neural networks is a research challenge. Balancing computational efficiency and bias is key in inference methods. Combining MCMC and VI aims to achieve a better balance. Salimans et al. (2015) proposed reducing variational bias by optimizing an ELBO based on the joint density of short MCMC chains. The proposed ELBO for HMC becomes looser as the chain grows longer. Caterini et al. (2018) introduced an alternative ELBO for HMC, but it still has issues with sampling momentum variables only once at the start of the chain. Ruiz & Titsias (2019) suggested a new variational objective function inspired by contrastive divergence to optimize variational parameters and reduce variational bias. Hoffman (2017) and Han et al. (2017) replaced burn-in simulations in MCMC with samples from pre-trained variational approximations to find good initial proposal distributions, but they do not address tuning HMC parameters critical for empirical performance. Research has focused on improving inference using flexible distributions transformed by non-linear functions. Levy et al. (2018) proposed tuning NVP parameterised MCMC using ESJD loss. Ergodic inference is motivated by MCMC chain convergence, defining an ergodic approximation to the target distribution \u03c0 with T MCMC steps. The ergodic approximation of a parametric distribution P converges to the target distribution \u03c0 with MCMC transitions. This is different from variational methods that only optimize variational parameters. The ergodic approximation of a parametric distribution P converges to the target distribution \u03c0 with MCMC transitions. Functions involve MCMC simulation. EI tunes ergodic parameters to minimize bias of P T as an approximation to \u03c0 with finite T. To reduce KL divergence, burn-in parameter \u03c6 0 and MCMC parameter \u03c6 are tuned. Analytically evaluating p T is infeasible, so an alternative objective, the ergodic modified lower bound (EMLBO), is proposed. EMLBO maximizes a constrained optimization problem with a hyperparameter h close to the entropy of the target. The inclusion of the term ELBO (P 0 \u03c0 * ) in the constrained objective of maximizing E p [log \u03c0 * (x)] and entropy term H(P ) prevents P from collapsing to a point probability mass at the mode of the target distribution \u03c0. Maximizing L ELBO (P 0 \u03c0 * ) = E p0 [log \u03c0 * (x)] + H(P 0 ) has a similar effect of preventing P 0 from collapsing to the mode of \u03c0, ensuring P T does not become a delta distribution. The KL divergence D KL (P t \u03c0) ensures convergence to the target distribution \u03c0 during MCMC transitions. Comparing EMLBO with Salimans et al. (2015), the negative KL term in equation 6 tightens as chain length increases, preventing collapse to a point mass at the mode of the target distribution. The EMLBO method produces accurate distributions as chain length increases, unlike MCMC which may not approximate the target distribution well. EI combines benefits of MCMC and VI, reducing bias with longer chains and generating independent samples. EI optimizes an objective directly quantifying bias, unlike MCMC methods that use indirect proxies for mixing speed. EI can use gradients to tune different MCMC parameters at each step, providing extra flexibility. It differs from parallel-chain MCMC by generating independent samples. The gradient-based optimization for maximizing the ergodic objective involves two gradient terms, one affected by a constraint and the other not. The first gradient term can be estimated using the reparameterization trick proposed in previous studies. The text discusses using a deterministic function to map random variables and ensuring optimization constraints are met. It also mentions using the reparameterization trick for Monte Carlo estimation and reformulating the Metropolis-Hastings correction step. Additionally, it touches on Hamiltonian Monte Carlo and the leapfrog integrator. The text discusses the leapfrog integrator in Hamiltonian dynamics for preserving volume, using Monte Carlo estimation for the second gradient term, and the convenience of computing gradients with standard autodifferentiation tools. The text discusses accelerating gradient computation by stopping backpropagation at the input of transformations, without impacting convergence speed. Carlo (HMC) transition kernel with T = 9 optimizes different HMC parameters for each step. Two initial distributions are considered, one satisfying the assumption H(P0) > H(\u03c0) and the other violating it. Accelerating chain convergence is shown by maximizing the ergodic objective. The text discusses the impact of optimizing HMC parameters for chain convergence, showing how maximizing the ergodic objective can accelerate convergence. It also highlights the importance of tuning the hyperparameter h to prevent deterioration in approximation quality. In Bayesian inference, estimating an upper bound on entropy H(\u03c0) is feasible. The prior entropy can serve as a reference for tuning h in ergodic inference using HMC transition kernels. The ergodic approximation is constructed using HMC with T transitions. SG training involves applying stop gradient to x from the previous HMC step. Hamiltonian ergodic inference (HEI) is a successful MCMC method in machine learning literature. T HMC transitions are used, each involving 5 steps of the vanilla leapfrog integrator. The auxiliary variables are sampled from a zero-mean Gaussian distribution with diagonal covariance matrix. HMC parameters such as variance of auxiliary variables and leapfrog step size are tuned for each transition. The burn-in model P0 is factorized Gaussian, and Adam stochastic optimization algorithm is used for optimization. The TensorFlow implementation by Abadi et al. (2015) uses specific optimiser hyperparameters (\u03b2 1 = 0.9, \u03b2 2 = 0.999, = 10 \u22128) and initial HMC leapfrog step sizes. An experiment on Bayesian neural networks is included in Appendix 6.3, comparing Hamiltonian ergodic inference (HEI) with other methods on synthetic benchmark distributions. Baselines considered are Hamiltonian variational inference (HVI), generalized Hamiltonian Monte Carlo (GHMC), and Hamiltonian annealed importance sampling (HAIS). Other hybrid inference methods are not considered. In the experiment, Hamiltonian variational inference (HVI) and Hamiltonian ergodic inference (HEI) are compared using HMC chains with the same settings. HVI is trained for 1000 iterations to converge to a (local) minimum. In the experiment, HEI is trained for 50 iterations with 1,000 intermediate distributions and 5 leapfrog steps per HMC transition. GHMC 1 is run with 100 parallel chains, 5 leapfrog steps per transition, and 1000 auto-tuned training iterations. Sample quality is evaluated using simulated samples and MC estimation of E \u03c0 [log \u03c0 * (x)]. ESS is not considered in this experiment. In the experiment, HEI is trained for 50 iterations with 1,000 intermediate distributions and 5 leapfrog steps per HMC transition. GHMC 1 is run with 100 parallel chains, 5 leapfrog steps per transition, and 1000 auto-tuned training iterations. Sample quality is evaluated using simulated samples and MC estimation of E \u03c0 [log \u03c0 * (x)]. ESS is not considered in this experiment. MCMC literature (Levy et al., 2018) does not consider ESS in this experiment, as GHMC is the only method generating correlated samples. Ground truth samples from benchmark distributions are generated using rejection sampling. Table 2 shows estimates of \u2212E \u03c0 [log \u03c0 * (x)] and wall-clock simulation time for generating 100,000 samples. Training time for MCMC parameter optimization is shown in Table 3, with HEI being faster than HVI and GHMC. Acceleration of HEI over HSVI is due to the stopping gradient trick described in Section 3.2. The histograms and estimates of \u2212E \u03c0 [log \u03c0 * (x)] from HEI align with GHMC and HAIS, showing consistency in results. HVI displays bias in benchmarks, while HVI and HEI perform similarly in sampling time. Table 4 lists results for different models and configurations. In the task of training deep generative models on the MNIST dataset, HEI is evaluated for computational efficiency and test log-likelihood. The deconvolutional decoder network from Salimans et al. (2015) is implemented, and Hamiltonian annealed importance sampling is used. The experiment reports the effective sample size (ESS) and uses prebinarised MNIST test images for fair comparison with previous works. The architecture of the generative model follows Salimans et al. (2015). The deconvolutional network used in training deep generative models on the MNIST dataset consists of 32-dimensional latent variables with a Gaussian prior. It includes a fully-connected layer with 500 RELU hidden units, followed by three deconvolutional layers with 5x5 filters and RELU activations. The training time of HEI is lower than HVI due to the stop gradient trick. Training time for HAIS is not reported as it requires manual tuning of MCMC hyperparameters. The training time for deep generative models with DGM involves manual tuning of MCMC hyperparameters. The code for HVI Salimans et al. (2015) is not publicly available, but their convolutional VAE was successfully reproduced. HVI and HVAE methods were implemented, with HVAE lacking the reverse model component. Our implementation of the HEI encoder, based on the HVAE method, does not use tempering but still yields results similar to Caterini et al. (2018). The HEI encoder is optimized jointly with the decoder using Adam. HEI outperforms HVI, HVAE, and standard VAE in test log-likelihood when trained for 6 hours, with significant gains even when training is extended to 12 hours. HEI encoder outperforms HVI, HVAE, and standard VAE in test log-likelihood after 6 hours of training. Extending training to 12 hours still yields significant gains. Convergence of HEI is verified through plots showing estimates and similarity scores. Shortening the HEI chain to 10 HMC steps has a negligible effect on simulation accuracy. The training time of HEI with the stopping gradient trick is up to 5 times faster than without. EI is a hybrid inference method that reduces approximation bias, generates independent samples, and tunes MCMC hyperparameters. Its effectiveness was verified on synthetic examples and popular benchmarks for deep generative models. The effectiveness of EI was verified on synthetic examples and popular benchmarks for deep generative models. Samples generated using EI are closer to a gold standard method at a low computational cost. However, EI requires the entropy of the first MCMC step to be larger than the target distribution's entropy. The code for the vanilla leapfrog algorithm used in HVI, HEI, and HAIS is provided. In an additional experiment, the posterior distribution of Bayesian neural networks is approximated with standard Gaussian priors. HEI is compared with SGHMC on four UCI datasets using networks with 50 hidden layers. The HEI chain consists of 50 HMC transformations with 3 Leapfrog steps each, with initial proposal distribution obtained from mean-field VI using Adam. The study compares HEI with SGHMC on Bayesian neural networks using standard Gaussian priors. HEI uses mean-field VI for initial proposal distribution and stochastic gradients in leapfrog integrator for computational efficiency. HEI outperforms SGHMC in test log-likelihoods. The study compares HEI with SGHMC on Bayesian neural networks using standard Gaussian priors. HEI outperforms SGHMC in test log-likelihoods and shows better results after HMC hyper-parameter tuning."
}