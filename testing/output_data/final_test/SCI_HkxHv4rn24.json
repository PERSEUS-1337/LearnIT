{
    "title": "HkxHv4rn24",
    "content": "In this paper, the authors empirically investigate the training journey of deep neural networks compared to fully trained shallow machine learning models. They observe that deep neural networks initially learn to classify easy examples before tackling harder ones. The authors suggest partitioning the dataset into easy and hard subsets to improve training. They also discover examples that are easy for shallow models but challenging for deep neural networks. The authors provide their code for reproducibility. The authors in BID0 suggest that deep neural networks (DNNs) learn simple patterns first before memorizing. They propose that real-world datasets contain easy examples with simple patterns learned initially, followed by harder examples. Tishby et al. in BID25 propose two phases in DNN training: an initial fitting phase and a compression phase. While this claim is debated in BID24, it is noted that hidden representations in DNNs compress task-irrelevant information. This dichotomy in datasets influences DNN learning, prompting a data-dependent approach. The authors aim to explore the dichotomy between shallow and deep learnable examples in datasets, questioning the notion of easiness for different models. They investigate if there is a regime change from shallow to deep learnable examples in DNNs and if shallow learnability correlates with overall accuracy. The motivation is to gain insights into the relationship between shallow learnability and example easiness. The paper aims to explore the changing scenery of the conquest of the training dataset by deep neural networks, focusing on the difference in learning capabilities between shallow and deep models. The authors present a quantitative methodology in section 2, followed by empirical experiments in section 3 and results in section 4. The proposed method to study the learning process of deep learning models relative to shallow machine learning is discussed in section 5. The study aims to compare the learning process of deep learning model D with shallow machine learning model M. Various metrics are used to analyze the generalization capability of D on unknown data. Different accuracies of D and M are measured, including subsets of training data classified correctly and wrongly by M. The ratio of accuracies on these subsets is also studied. The experiments are conducted under three different performance regimes. The study compares deep learning model D with shallow machine learning model M using various metrics to analyze generalization capability. Experiments are conducted on three different regimes using MNIST, CIFAR10, and CIFAR100 datasets. MNIST dataset consists of 70,000 grayscale images of handwritten digits. Data is preprocessed by centering and normalizing images before training models. The CIFAR dataset includes 70,000 grayscale images divided into training and test sets. CIFAR10 has 10 object categories with 60,000 color images, while CIFAR100 has 100 classes with 600 examples each. The dataset also contains 20 super classes, but this study focuses on fine-grained classes for model comparison. Random Forests are successful Machine Learning models applied to various classification and regression problems like real-time face detection, gene selection, and remote sensing. In this study, Random Forests are trained with 20 estimators and the gini index criterion using 1024-dimensional vectors for CIFAR images. Ratio of Accuracies and values of the contingency matrix are plotted against i, with Support Vector Machine as a reference. In this study, Random Forests are trained with 20 estimators and the gini index criterion using 1024-dimensional vectors for CIFAR images. SVM models are popular for limited data domains like hand written character recognition and face recognition. SVM is trained with slacks under the Radial Basis Kernel with hyperparameters C = 1.0 and \u03b3 = 0.1. Different deep networks are trained on each dataset for better performance. Different deep networks are trained on each dataset for better performance. The choice of network architecture is based on the dataset size and complexity, with experiments conducted using popular but different ontologies like DenseNet and ResNet. For example, a small Convolution Network is trained on the MNIST dataset, while DenseNet121 is used for image recognition tasks due to its high performance on various benchmarks. DenseNet121 and ResNet101 are popular deep learning models used for image recognition tasks. DenseNet121 is trained on the CIFAR10 dataset with specific parameters, while ResNet101 is used for image recognition on the CIFAR100 dataset with additional weight decay. The training process and maximum accuracy achieved are discussed in detail. The study focuses on the learning process in the early stages of DenseNet121 and ResNet101 models for image recognition tasks on CIFAR10 and CIFAR100 datasets. The ratio of accuracies changes during training, showing a right-skewed unimodal shape with a sharp hump early in the training process. This occurs across datasets and model pairs, indicating significant differences in accuracies on subsets. The study observed significant differences in accuracies on subsets during the early stages of training DenseNet121 and ResNet101 models for image recognition tasks on CIFAR10 and CIFAR100 datasets. The accuracies can vary greatly between subsets, with some subsets being up to 8 times more accurate than others. The training process starts by quickly learning easy examples and then gradually extends to harder ones. Identifying hard examples with incorrectness can improve training procedures. Identifying hard examples with incorrectness can improve training procedures like curriculum learning, teacher forcing, and professor forcing. Weighing training set examples based on correct classification by a model can create a more balanced dataset. The slow learning of M-incorrect examples is a major factor in accuracy growth for deep networks. This observation can be used to iterate more on harder data points and achieve faster convergence. The study tracks the training of DNNs compared to shallow machine learning models and showcases results on three different datasets. During training, Deep Networks quickly learn easy examples before tackling harder ones. The concept of example difficulty is consistent across models and can be assessed using shallow learning models. This allows for categorizing training sets into easy and hard examples to enhance network training. Additionally, there are examples that are shallow-classifiable but not deep-classifiable in all datasets studied. Ongoing work includes using influence functions to analyze the impact of training examples on model performance. The second path involves understanding the conquest of training space by deep and shallow classifiers in terms of image complexity and interestingness. A conjecture is made that image complexity, such as JPEG compressibility, is strongly correlated with shallow learnability."
}