{
    "title": "SkgYJaEFwS",
    "content": "We introduce a new PAC-Bayes few-shot meta-learning algorithm that learns a model prior distribution and extends the framework to upper-bound generalisation errors on unseen tasks. Our method uses a generative-based approach for better modeling and achieves state-of-the-art results on mini-ImageNet benchmark. Humans can quickly learn new tasks by exploiting prior experience. Prior knowledge is essential for quickly adapting to new tasks. Learning algorithms need to encode knowledge from training tasks to be able to exploit it for future tasks. Understanding the latent task distribution is crucial for solving unseen tasks with limited training samples. Various approaches have been developed to achieve this goal. Meta-learning has emerged as an effective method for quickly adapting to new tasks by leveraging knowledge from multiple training tasks. Recent advances in meta-learning have shown state-of-the-art results in few-shot learning benchmarks. Bayesian meta-learning approaches have addressed the issue of over-fitting by incorporating model uncertainty into predictions. Incorporating model uncertainty into prediction, recent meta-learning approaches like LLAMA and PLATIPUS use variational inference. However, these methods lack thorough investigation of generalization errors for unseen samples and may not accurately represent underlying distributions. This paper introduces technical novelties to address these issues, including deriving an upper-bound for generalization errors in few-shot meta-learning using PAC-Bayes. The paper introduces a novel variational Bayesian learning approach for few-shot meta-learning, utilizing a hierarchical model to learn a prior and generative models for unseen tasks. The proposed algorithm shows competitive results in terms of calibration error and outperforms state-of-the-art methods in a few-shot classification benchmark. The research is related to Bayesian few-shot meta-learning techniques that incorporate uncertainty into model estimation. Variational inference methods like PLATIPUS, BMAML, Amortised meta-learner, and VERSA address scalability issues in model estimation. While these approaches have shown impressive results in various tasks, they lack theoretical guarantees on generalization errors for unseen samples. The use of overly-simplified diagonal Gaussian distributions limits the expressiveness of the variational approximation. Our work introduces a method that learns a shared prior of model parameters and uses it to estimate task-specific posteriors efficiently. This approach improves scalability by avoiding the need to store all task-specific posteriors, making it more memory efficient and suitable for applications. Inference allows a memory efficient solution, making it favorable for applications with a large number of tasks like few-shot meta-learning. The few-shot meta-learning problem is defined and formulated, with a generalization upper-bound derived based on the PAC-Bayes framework. A proposed approach using implicit variational distributions for few-shot meta-learning is presented, relying on a Bayesian hierarchical model where model parameters for each task are represented by w_i and meta-parameters shared across all tasks are denoted by \u03b8. The few-shot meta-learning problem involves minimizing the negative log predictive probability with respect to shared meta-parameters \u03b8. Task-specific neural network weights w_i are initialized from \u03b8 and updated using truncated gradient descent. The task-specific posterior p(w_i | Y_i; \u03b8) is often approximated due to intractability. The task involves approximating the task-specific posterior p(w_i | Y_i; \u03b8) with a distribution q(i, \u03b8). The objective function is minimized by minimizing the upper bound instead. Two issues arise: generalization error and estimating q(w_i; \u03bb_i) accurately. The PAC-Bayes bound for the single-task problem is introduced in Theorem 1. The PAC-Bayes bound, introduced in Theorem 1, provides an upper bound on the expected error of a posterior Q on data distribution p(z). This bound balances fitting data and regularizing model complexity. Despite assumptions of bounded loss functions, the PAC-Bayes bound can be extended to unbounded loss functions. The novel bound on generalization error for few-shot meta-learning is presented in Theorem 2, with a focus on the relationship between model parameters and the shared prior. This approach differs from prior work by Amit & Meir (2018) in how the posterior is related to the prior and likelihood function through gradient updates. The discrepancy in the hypothesis used between the two approaches results in different upper-bounds, particularly at the regularisation term. The objective function aims to minimize the generalization upper-bound by approximating the true posterior through a variational posterior. The resulting cost function, known as the variational free energy (VFE), includes a regularisation term penalizing the difference between the shared prior and the variational task-specific posterior, along with a data-dependent or likelihood cost. The cost function in Bayesian statistics involves minimising the variational free energy (VFE) by using gradient descent with an initialisation parameter \u03b8. The shared prior p(w i ; \u03b8) and variational task-specific posterior q(w i ; \u03bb i ) can be modelled using prescribed and implicit probabilistic models. In this paper, a more expressive way of implicitly modeling the shared prior and task-specific posterior is presented. A parameterized model using a deep neural network is used to model sample generation from the prior and posterior distributions without specifying parametric distributions. The KL divergence term in the model cannot be evaluated analytically or symbolically, leading to the proposal of employing a probabilistic classification approach. The paper proposes using a probabilistic classification approach to estimate the KL divergence term in the model. A deep neural network is employed as a discriminator to distinguish samples from the prior and posterior distributions. The objective function for training the discriminator is defined, and the KL divergence term can be estimated using Monte Carlo samples. The challenge lies in obtaining the optimal parameters for the discriminator. The paper introduces the Statistical Implicit Bayesian Meta-Learning (SImBa) algorithm, which utilizes MAML to meta-learn model parameters for the discriminator. This approach aims to optimize training time and memory usage by initializing parameters within each task. The discriminator is expected to provide an accurate estimate of the KL divergence term. The paper introduces the SImBa algorithm, utilizing MAML to meta-learn discriminator model parameters. The discriminator is modeled as a neural network to ensure correct specification. An alternative approach to estimate the KL divergence term is using a lower bound method. The paper discusses implicit modeling in generative models and the potential issue of curse of dimensionality. One solution is to encode high-dimensional data into a feature embedding space through supervised learning, reducing input space dimensions. This trade-off may lead to loss of relevant information affecting performance on held-out tasks. Our proposed method simplifies training compared to prior Bayesian few-shot meta-learning approaches. The trade-off is setting the significance level \u03b4, which is more intuitive than estimating weighting factors. SImBa is evaluated in few-shot regression and classification tasks, compared to state-of-the-art methods. An experiment involves a multi-modal task distribution with data from sinusoidal and linear functions. Additional details and visualisation results are in Appendix B. The results in Figure 2 show that SImBa can vary prediction variance based on uncertainty in training data, while MAML outputs a single value. A reliability diagram based on quantile calibration for regression is used to evaluate predictive uncertainty. Bayesian meta-learning approaches, like Amortised Meta-learner, are better calibrated than MAML. SImBa, a Bayesian meta-learning approach, utilizes a richer variational distribution for better calibration compared to MAML. It is evaluated on the N-way k-shot setting and achieves high accuracy on mini-ImageNet. The model targets model uncertainty estimation and outperforms state-of-the-art methods. SImBa, a Bayesian meta-learning approach, achieves state-of-the-art results in 1-shot and 5-shot settings using different network architectures. Larger networks in generators lead to better classification. Reliability diagrams are used to evaluate predictive uncertainty, showing SImBa's better calibration compared to MAML in Figures 3a and 3b. The model trained with SImBa demonstrates superior calibration compared to MAML and PLATIPUS, and is competitive with Amortised Meta-learner. Results show that SImBa has lower expected calibration error (ECE) and maximum calibration error (MCE) than MAML and PLATIPUS. Additionally, SImBa outperforms other methods in 1-shot and 5-shot settings for few-shot classification accuracy. The table shows various few-shot meta-learning algorithms and their performance in 1-shot and 5-shot settings. Notable algorithms include TADAM, LEO, and LGM-Net, with LGM-Net achieving the highest accuracy. The text also introduces a new Bayesian algorithm called SImBa for few-shot meta-learning. The new Bayesian algorithm SImBa for few-shot meta-learning, based on the PAC-Bayes framework, employs a generative approach for more expressive variational approximation. It introduces uncertainty through implicit distributions, leading to well-calibrated and accurate predictions on unseen tasks. The algorithm is compatible with various base models and applicable in regression and classification, demonstrating reasonable predictions in multi-modal 5-shot learning scenarios. The algorithm SImBa for few-shot meta-learning, based on the PAC-Bayes framework, achieves state-of-the-art results in calibration and classification on mini-ImageNet data. It presents two lemmas to prove Theorem 2, applies the PAC-Bayes bound in Theorem 1 to obtain an upper-bound for a single task, and combines Lemmas 1 and 2 with Corollary 1 to derive a novel approach. Theorem 2 presents a novel upper-bound for few-shot meta-learning. The experiment involves generating data from sinusoidal and linear functions with specific parameters. The experiment involves generating data from sinusoidal and linear functions with specific parameters. Data points are uniformly generated from [-5, 5] with added Gaussian noise. Neural networks are used for regression, with specific architectures for the base model, generator, and discriminator. Variational parameters are estimated through gradient updates with specific learning rates. The experiment involves generating data from sinusoidal and linear functions with specific parameters. Neural networks are used for regression, with variational parameters estimated through gradient updates. The meta-parameters are obtained using Adam optimizer with fixed step sizes. Gradient clipping is applied initially and removed after 50,000 tasks. Input images are down-sampled to 84-by-84 pixels for consistency with prior few-shot meta-learning works. The generator and discriminator networks in the experiment are described, with details on the architecture and activation functions used. The training process for feature embedding is outlined, involving down-sampling of input images and training a neural network to extract intermediate features for embedding. The experiment involves using a fully connected network with 128 hidden units for classification, while the generator model has 512 hidden units. Different base networks are tested with varying hidden unit numbers and generator layer sizes to study their impact on classification performance. Increasing the hidden layer of the generator from 256 to 512 improved the classification accuracy, as shown in Table 3. The larger the base network and generator, the better the classification accuracy."
}