{
    "title": "ByeLmn0qtX",
    "content": "This paper introduces variational domain adaptation, a framework for learning multiple distributions through variational inference. It does not require samples from the target domain but instead uses a known source as a prior and binary discriminators. The framework is scalable to large-scale domains and can explicitly formulate the target domain as a posterior through Bayesian inference. DualVAE encodes domains as modes on a dual latent space, allowing for uncountable infinite domains and fast convergence without extensive hyperparameter search. It outperforms StarGAN and UFDN in multi-domain image generation tasks on CelebA. Domain adaptation methodology, such as adversarial learning and variational inference, is used to handle distributions that vary with environments and agents. It involves transferring samples between domains, like pix2pix which generates samples from the target domain based on input from the source domain. CycleGAN is another example of domain transfer technique. Variational domain adaptation methods transfer samples between source and target domains. However, existing methods require target domain samples, limiting applicability to domains where direct sampling is difficult or costly. This includes scenarios like obtaining intrinsic rewards or preferences in environments, which are subjective and complex to sample internally. Variational domain adaptation involves discriminating target domains using a proposal drawn from the prior. Domain transfer is represented by mean shift in the latent space, and domain embedding is done using vectors \u00b5 i. This method addresses challenges in direct sampling by converting the problem to semi-supervised learning, enabling variational inference. The study introduces variational domain adaptation, where the target domain is modeled using Bayesian theorem to deceive a discriminator. The end-to-end learning framework enables learning of a good prior for all domains. The posterior successfully fools the discriminator, akin to rejection sampling in Monte Carlo methods. The study also presents the DualVAE model as a simple extension of conditional VAE for multi-domain representation. DualVAE is a multi-domain semi-supervised concept that learns multiple domains in one network by maximizing the variational lower bound. It uses VAE to model the prior and an abstract representation for the discriminator. The domain embedding enables sampling from the model, with the discriminator being a simple inner product between the means of domain embedding and the VAE output. The study introduces DualVAE, a probabilistic end-to-end model that learns multiple domains in a single network. It validates DualVAE for a recommendation task using celebA BID13 data, demonstrating the ability to generate images based on user evaluations and improve them through interpolation. The model's performance is evaluated using the domain inception score (DIS) to capture user preferences. The study introduces DualVAE, a model that learns multiple domains in a single network and generates images based on user evaluations. DualVAE's DIS is higher than single domain models, and it is available online. Existing literature on domain transfer assumes samples are from the target domain. Various models like pix2pix, CycleGAN, UNIT, DiscoGAN, and DTN do not require sample pairs for domain conversion. DualVAE is a model that can convert source domain samples into samples for multiple target domains with a single-network structure. It addresses the issue of hyperparameter tuning in adversarial learning and is powerful for learning multiple distributions with domain embedding. In the experiment, DualVAE quickly converged for over 30 domains without extensive hyperparameter tuning. The objective of unsupervised domain adaptation is to minimize KL-divergence between target distribution and model, equivalent to maximizing cross-entropy. The adaptation problem is formulated as a weighted average of cross-entropy over domains, with ignored domains if their weight is zero. The challenge of sampling x from p(i) is addressed by multi-domain semi-supervision, which models each domain as a posterior p(i) = p(x|D i). The objective function includes terms for likelihood, prior learned by a generative model, and a regularizer, with Monte Carlo sampling used for estimation. The DualVAE model extends the VAE for multi-domain transfer and demonstrates the concept of multi-domain semisupervision. It includes domain embedding and models each domain as a posterior distribution. The model addresses the challenge of sampling from the prior distribution and uses Monte Carlo estimation for estimation. DualVAE extends VAE for multi-domain transfer by incorporating domain embedding. It trains (n + 1) VAEs simultaneously, sharing a parameter, including the prior. The prior distribution is conjectured to be normal, resulting in all posteriors being VAEs. The joint distribution is modeled using a VAE to represent the prior distribution. DualVAE extends VAE for multi-domain transfer by incorporating domain embedding. It trains (n + 1) VAEs simultaneously, sharing a parameter, including the prior. The benefit of a VAE is that it can model each distribution as a normal distribution in Z by maximizing the variational lower bound of log p(x). The objective is to learn a pair of the encoder and the decoder to maximize L(x), where z acts as a prior. The lower bound L(x) is derived using the reconstruction error and penalty term as the KL divergence between the model and the prior p(z). The network structure of DualVAE involves the inner product of latent z and domain embedding z i. DualVAE extends VAE for multi-domain transfer by incorporating domain embedding. The equation log f \u03b8 (D i |x) simplifies to the inner product between \u00b5 i and \u00b5 \u03c6 (x). The objective involves a domain embedding matrix U, allowing extension to infinite domains. The parameters of DualVAE include \u03b8 = (w, \u03c6, U), representing encoder, decoder, and domain embedding respectively. DualVAE extends VAE for multi-domain transfer by incorporating domain embedding. The variational lower bound of the point-wise objective of DualVAE can be written in a simple form, maximizing a duality pairing between sample latent space and domain latent space. It requires only two additional hyperparameters in addition to the VAE, controlling variance and bias of the domain embeddings. DualVAE extends VAE for multi-domain transfer by incorporating domain embedding. The training algorithm of DualVAE involves hyperparameters \u03b1 and \u03b2 to control variance and bias of domain embeddings. DualVAE was validated through experiments in domain adaptation, showcasing superior performance in image generation tasks compared to existing methods. DualVAE, an extension of VAE for multi-domain transfer, outperformed state-of-the-art methods in image generation tasks. The first task aimed to generate user-preferred images using CelebA and SCUT-FBP5500 datasets. The second task focused on transferring samples between different domains successfully. The DualVAE model successfully learned the target distribution in both quantitative and qualitative aspects. It outperformed other models in domain inception score (DIS) and produced high-quality facial images. The method showed superior results in transferring images across different domains using the CelebA dataset. The CelebA dataset outperformed other models in generating high-quality facial images. It consists of approximately 200,000 images of celebrities with 40 attributes. The SCUT-FBP5500 dataset includes 5500 face images evaluated for beauty preference. The experiment used a Domain Inception Score (DIS) to evaluate image transformation across different domains. The Domain Inception Score (DIS) evaluates image transformation success by measuring transfer and reconstruction scores. A DualVAE can transform images from one domain to multiple target domains, while a Single Domain VAE (SD-VAE) can achieve this by creating multiple models. The DualVAE outperformed the SD-VAE in image transformation, with a higher Domain Inception Score (DIS) of 0.01. It was compared to other models for image-to-image translations using the celebA dataset and attributes, with input images resized to 128 \u00d7 128. The DualVAE achieved a higher Domain Inception Score (DIS) compared to other models in image transformation. Interpolation was used to transfer images between domains, with vector w i constrained to retain original features. Ideal reconstructions were generated for sample users, and transferred images of 40 attributes were visualized using the proposed method and other models. The proposed DualVAE framework introduces variational domain adaptation for learning multiple distributions in a single network. It uses a known source as a prior and binary discriminator to discriminate the target domain from others. DualVAE's major feature is domain embedding, encoding all domains and samples for Bayesian inference. DualVAE is a domain embedding tool that encodes domains and samples into normal distributions in a unified network. In an experiment with celebA and face image data, DualVAE outperformed StarGAN and UFDN. Future research will focus on complex domains and wider beauty domains. The proposed method aims to address multiple contexts effectively. The study focused on the paradigm of multiple contexts and compared VAE with DualVAE methodology. They visualized the latent space of both models using 5500 latent vectors of 63 dimensions. UMAP was used to reduce dimensions to two, showing the gradient of scores in DualVAE. The proposed DIS score evaluates image transformation into multiple target domains. The DIS score evaluates image transformation into multiple target domains by assessing the success of domain transfer and feature retention. It is calculated by summing transfer and reconstruction scores using Algorithm 2. The model is fine-tuned with images and domains as inputs and outputs, and test images are transferred into N domains for evaluation. The DIS score evaluates image transformation into multiple target domains by assessing domain transfer success and feature retention. For each original image, it is transferred into N domains and mapped to N-dim vector. The matrix M is created by subtracting the original image vector from each row of the N \u00d7 N matrix. The diagonal elements of M should be large, representing the original image in diagonal domains, while off-diagonal elements should be small to preserve original features. The algorithm defines operations like abs, diag, notdiag, and avg for evaluation. In the experimental setting, DualVAE shows efficient learning over 40 domains in CelebA. However, StarGAN struggles with the large number of domains, leading to poor learning outcomes. Reconstruction in DualVAE outperforms StarGAN, but domain transfer is not successful in StarGAN. In contrast to DualVAE, domain transfer in Algorithm 2 results in small ts compared to DualVAE, leading to a very small DIS value. Domain transfer experiments using the MNIST dataset show successful image transfer without compromising the original style. Visualization of domain embedding vectors and decoded images further demonstrate the transfer process. In this chapter, it is shown that arithmetic operations can be conducted among different domains by taking the average value of domain embedding vectors. This allows for the output of charming images for groups of people without the need to learn individually. The average of domain embedding vectors is denoted as \u03bc, where \u03bc = (1/|I|) i\u2208I \u00b5 i. The domain embedding vectors are linearly functional, allowing for operations such as taking the inner product of the average vectors \u03bc and the latent vector z(x). The proposed method, DualVAE, is a natural generalization from probabilistic Matrix Factorization (PMF) proposed ten years ago. PMF is used in collaborative filtering algorithms for recommendation systems, learning user and item matrices to restore evaluation matrices. The proposed method, DualVAE, extends probabilistic Matrix Factorization (PMF) by incorporating VAE, creating an end-to-end model. DualVAE outperformed non-end-to-end models in experiments. DualVAE outperformed non-end-to-end models in experiments by achieving a smaller Root Mean Square Error (RMSE) and generating clear images similar to vanilla VAE. The models were compared using SCUTFBP-5500 FIG0 dataset with 5000 training images and 500 test images. DualVAE, similar to VAE-PMF, can generate clear images and outperforms VAE in classification accuracy. It is also robust to sparsity, as demonstrated experimentally with sparse labels. The method shows strong performance in domain transfer and maintains accuracy even with 90% missing labels. StarGAN is not as robust as DualVAE when 90% of domain labels are missing, as it generates identical images and cannot learn. DualVAE's performance is shown to be robust to changes in \u03b1, as demonstrated in a comparison experiment with existing methods. The section discusses three models used for domain adaptation across different domains: environment, attribute, and class. The experimental setting for domain transfer to ideal images based on gender is described. The gender information was added to facial images for beauty evaluation using CGAN BID16 to VAE. Scoring was normalized in [-1, 1] for learning acceleration. DualVAE model structure was considered with RGB input and output images. A 63-dimensional latent variable was obtained after convolution and LeakyReLU layers. The decoder had deconvolution layers and gender attribute was represented as 0 for female and 1 for male in the image data. The study utilized a DualVAE model on SCUT-FBP5500 dataset for gender-based facial beauty evaluation. The input image was binary, while gender was represented as a scalar. The model was optimized on SCUT-FBP5500 and celebA datasets alternatively. Comparative experiments were conducted with different domain transfer scenarios using celebA data. The model parameters were varied, including latent variable dimensions and learning rates. The input and output images were RGB with specific dimensions. The study utilized a DualVAE model on SCUT-FBP5500 dataset for gender-based facial beauty evaluation. The input image was binary, while gender was represented as a scalar. The model was optimized on SCUT-FBP5500 and celebA datasets alternatively. Comparative experiments were conducted with different domain transfer scenarios using celebA data. The input and output images were RGB with specific dimensions. The experimental setting of domain transfer in the MNIST dataset is described, showing results from domain adaptation performed by DualVAE on randomly sampled images from MNIST and CelebA datasets. DualVAE stably transfers samples across 10 domains while keeping domain-irrelevant features."
}