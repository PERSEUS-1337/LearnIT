{
    "title": "r1lohoCqY7",
    "content": "Estimating frequencies of elements in data streams is crucial in data analysis and machine learning. Traditional streaming algorithms lack the ability to utilize input patterns for improved performance. A new class of algorithms is proposed that learns patterns in data to enhance frequency estimates, combining machine learning benefits with algorithm theory guarantees. These learning-based algorithms demonstrate lower estimation errors and performance gains compared to non-learning counterparts, as shown in evaluations on real-world datasets. Deep learning models excel at capturing complex data patterns but lack formal error bounds. Efforts have been made to integrate deep learning into algorithms that can adapt to data properties while providing worst-case guarantees. This paper introduces frequency estimation streaming algorithms that automatically learn to leverage input data properties, a significant step towards bridging the gap between traditional algorithms and deep learning models. A data stream is a fundamental subroutine in data analysis with applications in machine learning, including feature selection, ranking, semi-supervised learning, and natural language processing. Frequency estimation algorithms are used in data processing libraries to estimate the occurrence of elements in a sequence. In big data applications, streaming algorithms are developed to compute frequencies of elements in a stream without storing the entire stream. Various algorithms like Count-Sketch, Count-Min, and multistage filters have been developed with performance guarantees. These algorithms do not leverage specific patterns in the data, such as the inverse correlation between word frequency and word length in text data. In this paper, learning-based frequency estimation streaming algorithms are introduced. These algorithms utilize a learning model to exploit data properties without being specific to a particular pattern. The focus is on hashing-based algorithms, including popular ones like Count-Min, with theoretical guarantees provided. Hashing-based algorithms like Count-Min, Count-Median, and Count-Sketch hash data items into buckets to estimate item frequency. They can handle item deletions and some, like Count-Min, never underestimate frequencies. However, collisions between elements mapped to the same bucket can lead to estimation errors. The existing hashing-based algorithms use random hash functions, leading to collisions between high-frequency elements. Our proposal is to use a subset of S to learn the properties of heavy hitters and assign them their own buckets to minimize costly collisions. The focus is on identifying the characteristics of heavy hitters rather than their specific identities. The text introduces learning-based frequency estimation streaming algorithms that aim to reduce errors by learning the properties of heavy hitters in the input data. Performance guarantees show an improvement in error bounds compared to non-learning algorithms. The algorithms are evaluated using real-world datasets on Internet traffic load and search query popularity. Frequency estimation in data streams is a fundamental problem in streaming algorithms. Hashing-based algorithms like Count-Sketch and Count-Min, as well as non-hashing algorithms, have been proposed for this purpose. These algorithms are also connected to sparse recovery and compressed sensing. Frequency estimation in data streams is a fundamental problem in streaming algorithms. Karp et al., 2003; BID15 proposed algorithms for learning heavy hitters with better accuracy/space tradeoffs than hashing-based methods. These algorithms are customized to data following Zipf Law and do not require knowing the data distribution a priori. Researchers have integrated machine learning models into algorithm design to improve compressed sensing algorithms for frequency estimation in data streams. These methods tailor measurements of the frequency vector to a specific class of vectors, but traditional approaches require large matrix representations unsuitable for streaming algorithms with space limitations. Machine learning has been used to compress high-dimensional vectors for distance estimation, with various methods developed over the last decade. While some papers have similar objectives, their techniques are not applicable to all applications. Recent research has also shown the use of machine learning in designing more efficient algorithms, such as using reinforcement learning and graph embedding for graph optimization. Recent research has utilized machine learning to improve algorithms for graph optimization and data structures like Bloom filters. The algorithms use neural networks to reduce collisions between heavy items, which differs from existing indices where all collisions are treated equally. The theoretical analysis in this study is distinct from previous work, focusing on reducing errors caused by collisions. The curr_chunk discusses the estimation error in frequency estimation algorithms, using expected error to measure overall error. It contrasts the traditional \"( , \u03b4)-form\" guarantees with a single objective approach. The focus is on the machine learning perspective in frequency estimation. The curr_chunk discusses three variants of hashing-based algorithms for frequency estimation: Single Hash Function, Count-Sketch, and Count-Min. These algorithms use different hash functions and arrays to estimate frequencies, with Count-Sketch also incorporating sign functions. The theoretical analysis assumes item frequencies follow the Zipf Law. The curr_chunk discusses developing frequency estimation algorithms based on the Zipf Law. An oracle identifies heavy hitters, assigning them unique buckets to avoid collisions. Other items are hashed using classic algorithms like Count-Min or Count-Sketch. This design combines learning capabilities with traditional frequency estimation algorithms, maintaining the original guarantees. The design combines learning capabilities with traditional frequency estimation algorithms like Count-Min or Count-Sketch. An oracle identifies heavy hitters, assigning them unique buckets to avoid collisions. Other items are hashed using conventional frequency estimation algorithms. The oracle in the unique bucket accurately counts heavy hitters using machine learning. The algorithms in the paper provide strong error bounds based on theoretical results. The learned variant of Count-Min improves accuracy compared to the non-learning counterpart, especially when B is similar to n. Even with prediction errors, the learned Count-Min algorithm cannot be further improved by a better hashing scheme. It inherits guarantees from the original version and achieves the same error as the \"Ideal Count-Min\" with a perfect oracle. The learned variant of Count-Min, called \"Learned Count-Min\", improves accuracy compared to the non-learning counterpart, especially when B is similar to n. It achieves the same error as the \"Ideal Count-Min\" with a perfect oracle. The space complexity of all algorithms is \u0398(B), and the performance bounds for different algorithms on streams with frequencies obeying Zipf Law are provided. The text discusses the construction of a heavy hitter oracle using a neural network to predict item heaviness, which is used in the Learned Count-Min algorithm to detect heavy items unseen in the training set. The network's prediction helps decide whether to assign an item to a unique bucket in the algorithm. The text discusses training a neural network to predict item counts for heavy items in the Learned Count-Min algorithm. Predicting the log of counts leads to more stable training and better results. The model is used as an oracle in the algorithm to estimate the number of packets for each network flow. The text discusses using a neural network to predict packet counts for network flows based on IP addresses and ports. The model utilizes two RNNs to encode the source and destination IP addresses separately, aiming to identify regions of heavy traffic in the smooth space of IP addresses. The text explains using RNNs to encode IP addresses and fully-connected networks for ports to predict packet counts. Results show estimation errors for different test minutes based on space usage. The neural-network oracle outperforms memorization of heavy hitters in a lookup table due to the dynamic nature of Internet traffic. The model's performance remains consistent from the 20th to the 50th minute, indicating generalization over time. Potential for further improvement is shown with an ideal oracle. The neural network model in the experiment aims to estimate the frequency of search queries using the AOL query log dataset. The dataset contains 21 million search queries from 650 thousand users over 90 days. Popular search queries tend to appear consistently across multiple days, following the Zipfian law. For example, \"google\" is consistently the most popular search phrase in the dataset. The neural network model trained on the AOL query log dataset aims to predict the frequency of search queries. By using an RNN with LSTM cells, the model processes search phrases to predict query frequency. Factors like popular words and search query metadata contribute to a search phrase's popularity. The model considers characters of a search phrase as input and uses a fully-connected layer to predict query frequency. The vocabulary for the RNN model includes English alphabets, numbers, and punctuation marks. Character IDs are mapped to embedding vectors before inputting them into the RNN. The model's effectiveness in processing sequence data is highlighted. Estimation error vs. space is plotted for two test days in FIG3.4, showing improved performance of learned sketches over conventional counterparts. Learned CountMin and Count-Sketch reduce loss significantly compared to their traditional versions. The algorithm performs consistently well on both the 50th and 80th day. The algorithm's performance remains consistent on the 50th and 80th day, indicating generalization over time. Memorizing heavy hitters in a lookup table is effective in low space regions due to less dynamic search queries. Neural network models accurately predict heavy hitters, with the Internet traffic model achieving an AUC score of 0.9. The model accurately predicts heavy items with an AUC score of 0.9 and for search query data, the AUC score is 0.8. Visualization of embedding spaces sheds light on the learned properties of the models. The neural network activations are visualized in a 2-dimensional space using t-SNE to show differences between heavy hitters and \"light\" items. The embedding space for Internet traffic data is shown in Figure 6.1, with each point representing one Internet traffic flow. The model separates Internet traffic flows based on the number of packets, grouping flows with similar destination IP address prefixes together. This structure allows the model to generalize to unseen packets. The embedding space learned by the model is also applied to search query data. The model in Figure 6.2 separates search queries based on their length, with queries of similar length closer in the embedding space. By using a learning model, the algorithm can predict heavy hitters accurately without misclassifying light queries. This approach enhances frequency estimation streaming algorithms and promotes a deeper integration of learning in algorithm design. The curr_chunk discusses the performance analysis of different approaches in frequency estimation algorithms, including single hash function, Count-Min sketch, and Learned Count-Min sketch. It highlights the space complexity of the single hash function approach and introduces Observation 9.1 for large values of n. The section aims to integrate learning into algorithm design for more efficient algorithms. The space complexity of the Count-Min sketch approach is proportional to the number of buckets, denoted as \u0398(B). An upper and lower bound for the expected estimation error with k hash functions and B buckets per row is provided. The approach involves partitioning the interval [0, B ln n] into smaller intervals using a sequence of thresholds. The goal is to determine the sequence of thresholds that satisfy specific properties for accurate estimation. The Count-Min sketch approach involves partitioning the interval into smaller intervals using thresholds to compute E[e j]. By setting specific thresholds, the expected error of the sketch for estimating items can be minimized. The error analysis is completed by satisfying specific conditions for accurate estimation. The Count-Min sketch method uses thresholds to partition intervals for estimating Zipfian frequency distributions. The expected error is analyzed to minimize estimation errors, with specific conditions ensuring accuracy. The expected error of Count-Min sketch with B buckets for Zipf Law items is shown to be \u0398(ln n B). The Count-Min sketch method uses thresholds to partition intervals for estimating Zipfian frequency distributions. The expected error of Count-Min sketch with B buckets for Zipf Law items is analyzed to minimize estimation errors. In Learned Count-Min sketches, the optimal expected error with parameters (B r , B) is at most DISPLAYFORM0. The space complexity is O(B) and the count of top B r frequent items are stored in their buckets. The Count-Min sketch method uses thresholds to estimate Zipfian frequency distributions. In Learned Count-Min sketches, the optimal expected error with parameters (B r , B) is at most DISPLAYFORM0. The count of top B r frequent items are stored in their own buckets, ensuring efficient storage. The sketch also utilizes a noisy HeavyHitters oracle to detect heavy items with minimal error probability. The analysis involves estimating the frequency of items using thresholds in the Count-Min sketch method. The space required for storing counters and mapping heavy items to reserved buckets is discussed. A comparison is made between the non-asymptotic expected error of Count-Min sketch and Learned Count-Min sketch with an ideal HeavyHitters oracle. The text discusses the comparison between Count-Min sketch and Learned CountMin sketch with reserved buckets, focusing on the minimum space required for improved performance. The analysis includes estimating item frequency and ensuring the Learned Count-Min sketch outperforms by a factor of at least (1 + \u03b5). The text discusses the comparison between Count-Min sketch and Learned CountMin sketch with reserved buckets, focusing on the minimum space required for improved performance. It considers different values of k and shows the minimum space in which Learned CM outperforms CM by a factor of 1.06. For k = 1, the expected error of a single hash function and Learned Count-Min are compared, with a condition on \u03b3. For k = 2, \u03b3 is less than a certain value. For k \u2208 {3, 4}, \u03b3 is less than another value for sufficiently large B. The total available space required is also discussed. The text discusses the comparison between Count-Min sketch and Learned CountMin sketch with reserved buckets, focusing on the minimum space required for improved performance. It considers different values of k and shows the minimum space in which Learned CM outperforms CM by a factor of 1.06. The amount of available space is at least DISPLAYFORM8, and settings with the number of buckets close to n are common. The estimation error of a hash function is defined as Err(F(I),F h (I)) := i\u2208I f i \u00b7 (f (h(i)) \u2212 i). An optimal hash function minimizes the first term, b\u2208B I f (b) 2. If an item i * with frequency at least DISPLAYFORM10 collides with a set of items I * under an optimal hash function h * , a new hash function h with smaller estimation error contradicts the optimality of h *: DISPLAYFORM11. The text discusses the optimal hash function h* and its collision properties with Zipfian input distribution. It shows that in any optimal hash function h*:[n]\u2192[B], the \u0398(B) most frequent items do not collide with any other items. If B = n/\u03b3 where \u03b3 \u2265 e^4.2, and assuming Zipfian distribution, none of the B/2ln\u03b3 most frequent items collide with any other items under h*. The text discusses the optimal hash function h* and its collision properties with Zipfian input distribution. It shows that in any optimal hash function, the most frequent items do not collide with any other items. The goal is to minimize the set of items other than the most frequent ones."
}