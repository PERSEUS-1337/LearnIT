{
    "title": "Sk03Yi10Z",
    "content": "Human-computer conversation systems in Natural Language Processing are divided into retrieval-based and generation-based systems. A novel ensemble system combines both approaches by feeding retrieved candidates to a reply generator via a neural network. The generated reply, along with the retrieved ones, undergoes a re-ranking process to find the final output, outperforming individual modules significantly in experimental results. Researchers have shifted focus to open-domain chatbot-style human-computer conversations due to their commercial value. Traditional approaches using rules and templates struggle with the diverse topics and language variations. Data-oriented approaches are being developed to leverage the abundance of human-human conversation data available online. Data-oriented approaches in developing conversation systems can be categorized into retrieval systems and generative systems. Retrieval-based systems search for the best matching reply in a pre-constructed conversational repository based on the user's query. However, the limitation lies in the capacity of the repository, leading to the need for generative systems to create tailored responses. The use of neural networks has further enhanced the capabilities of these systems. Generation-based conversation systems, powered by neural networks, can synthesize replies with good flexibility and quality. These systems use two recurrent neural networks, an encoder to capture query semantics and a decoder to generate replies. Long short term memory (LSTM) can enhance the ability to model longer sentences. The advantage of generation-based systems is their ability to produce tailored responses. The conversation systems based on \"Seq2Seq\" tend to generate common and uninformative replies like \"I don't know\" and \"Me too\". To address this issue, an ensemble of retrieval-based and generation-based systems is proposed. This approach involves using a retrieval module to find candidate replies and integrating them into the Seq2Seq generation process to enrich the meaning of responses. The ensemble system integrates retrieved replies into the Seq2Seq generation process to enhance the generated responses. A re-ranker evaluates the retrieved replies and newly generated response to provide a more meaningful final reply to the user. Experimental results demonstrate that the ensemble system outperforms individual components, highlighting the effectiveness of combining retrieval-based and generation-based methods in conversation systems. In early years, researchers focused on domain-specific conversation systems with pre-constructed ontology defining slots and values. Slot-filling approaches may fail in open domains due to diverse topics and natural language utterances. Different techniques like information retrieval, shallow hand-crafted features, deep neural networks, and random walk-style algorithms are used for matching in conversation systems. Recent advancements in conversation systems have seen the use of deep neural networks for matching and random walk-style algorithms for ranking candidate replies. Generative conversation systems are gaining attention, with models incorporating additional content from knowledge bases during human-computer conversations. Various approaches, such as phrase-based machine translation and RNNs, are being used to improve query-reply transformation and language translation. Despite the popularity of RNNs in conversation systems, there is a known issue with generating short and meaningless utterances. BID12 proposes a mutual information objective to address the issue of short and meaningless utterances in RNN-based conversation systems. They combine retrieval-based and generation-based systems in their model ensemble, enhancing the generator with retrieved candidates and re-ranking both candidates. BID7 uses a knowledge base for answer generation in question answering, while BID14 explores different attention strategies in multi-source generation. This integration of retrieval-based and generation-based systems is a novel approach in conversation system development. The ensemble framework integrates retrieval-based and generation-based approaches in a conversation system. The retrieval module searches for best matched queries and returns associated replies, while the generation module uses a multi-seq2seq model to generate a new reply based on the original query and retrieved candidates. The ensemble framework combines retrieval-based and generation-based methods in a conversation system. The retrieval module finds best matched queries and their replies, while the generation module uses a multi-seq2seq model to generate a new reply. Additionally, a re-ranker selects the best reply from the candidates obtained. This process enhances the quality of the final result through an ensemble of retrieval-based and generation-based conversation. The retrieval process in the conversation system involves using a Lucene 3 powered system to match user queries with pre-constructed conversational pairs. The system retrieves multiple replies based on semantic matching, with the top-ranked replies being selected. The retrieval process in conversation systems involves using a Lucene 3 powered system to match user queries with pre-constructed conversational pairs. The top-ranked replies are selected for further processing using a multi-seq2seq model, which generates new replies based on the input query and retrieved candidate replies. Neural networks are commonly used to build end-to-end trainable conversation systems, with a focus on generation-based models like the seq2seq model with Recurrent Neural Networks (RNNs) as the encoder and decoder. The objective function for the seq2seq model is the log-likelihood of the generated reply given the query. The multi-seq2seq model proposes a tailored reply by using information from both the query and retrieved candidate replies. It employs multiple encoders for the query and retrieved replies, improving performance compared to traditional seq2seq models. The multi-seq2seq model enhances reply quality by considering both the query and retrieved replies. It uses multiple encoders and integrates attention and copy mechanisms to generate more meaningful and tailored responses. The multi-seq2seq model integrates attention and copy mechanisms into the decoding process to improve reply quality by considering both the query and retrieved replies. It uses two-level attention, conducting sentence-and character-level attention to make better use of the information from the encoders. The multi-seq2seq model incorporates attention and copy mechanisms in the decoding process to enhance reply quality by considering the query and retrieved replies. It utilizes two-level attention, integrating sentence- and character-level attention to optimize information from the encoders. The model also employs a copy mechanism to extract words from retrieved replies during the decoding process. The multi-seq2seq model uses attention and copy mechanisms to improve reply quality by considering the query and retrieved replies. It calculates probabilities based on the matching degree between current and corresponding states, enriching the generated reply with informative words from retrieved replies. The design of the model is shown in Figure 2, demonstrating the relation between the generated reply and the query. The proposed ensemble approach involves using a Gradient Boosting Decision Tree (GBDT) classifier to rank candidate replies obtained through indirect matching with the user-issued query. The GBDT classifier considers various features, including term similarity and word overlap ratio, to handle replies with different traits. This re-ranking process aims to filter out irrelevant and meaningless utterances from the generated reply set. The text chunk discusses different similarity measures used in the ensemble approach, including term overlap, entity recognition, and topic similarity using Latent Dirichlet Allocation. In the ensemble approach, various similarity measures are utilized, such as term overlap, entity recognition, and topic similarity using Latent Dirichlet Allocation. The text chunk also delves into statistical machine translation, length considerations for replies, and fluency assessment in conversation systems. The text discusses the normalization of values to [0,1] and the assessment of fluency in conversation systems. It explains how the GBDT classifier's confidence scores are used to re-rank replies, eliminating irrelevant short responses and ensuring an optimized model ensemble effect. The framework includes independent components like multi-seq2seq and Re-ranker, with separate model training for each component. Training data includes human-human utterance pairs and retrieved candidate replies. The training objective for the neural network involves applying standard crossentropy loss to all words in the reply. The re-ranker part uses training samples of q, r pairs or generated by negative sampling. The ensemble model is evaluated on a Chinese conversation system using a large database of query-reply pairs collected from online forums and communities. The database contains 7 million query-reply pairs from online communities like Sina Weibo and Baidu Tieba. For training, 1.5 million pairs were randomly selected, 100K for validation, and 6,741 for testing. The dataset for the generation part consists of 1,606,741 query-reply pairs from Baidu Tieba. The ground-truth data is excluded in the retrieval module. The training-validation-testing split is consistent across all models. The neural models are trained using code based on dl4mt-tutorial. To train neural models, code from dl4mt-tutorial is used, following BID22 for hyper-parameter settings. Embeddings are 620-dimension, hidden states are 1000-dimension, and AdaDelta is applied with a mini-batch size of 80. Chinese word segmentation is performed on all utterances. A set of 100k words is used for all encoders and 30k for the decoder. The validation set is only used for early stop based on perplexity. Model ensemble is compared with individual components through ablation tests. Competing methods are trained similarly to the full model. The final proposed model ensemble includes Retrieval-1, Retrieval-2, seq2seq, and multi-seq2seq components. Evaluation is done using subjective and objective metrics. The evaluation of the proposed model ensemble includes subjective and objective metrics. Subjective evaluation involves human annotation of query-reply pairs, while objective evaluation utilizes BLEU scores for automatic assessment. The evaluation of the model ensemble includes subjective human annotation and objective BLEU scores. The ensemble outperforms RNN-based sequence generation, showing that the retrieval-based conversation system is a strong baseline. The model leads in both human evaluation and BLEU scores, combining retrieval, generative system, and re-ranker for best performance. Our model ensemble surpasses the state-of-the-practice retrieval system by +34.45% in human scores and outperforms traditional seq2seq models. Multi-seq2seq shows improved performance with two-level attention and copy mechanism, outperforming both conventional seq2seq and retrieval results. The retrieval and generation modules contribute equally to the final results of the ensemble system, with retrieval-1 playing a significant role. Multi-seq2seq outperforms retrieval-1 in some cases, indicating its effectiveness in improving results. This suggests that multi-seq2seq is better than seq2seq from the re-ranker's perspective. The combination of multi-seq2seq and re-ranking mechanisms in the ensemble outperforms traditional seq2seq. Ensemble(Retrieval, multi-seq2seq) performs better than Ensemble(Retrieval, seq2seq) and individual components in most metrics. Both retrieval-based and generation-based systems play a role in the proposed ensemble of conversation systems. The ensemble model, combining retrieval-based and generation-based systems, outperforms traditional conversation systems in a large-scale dataset. The model searches for candidate replies, uses an RNN-based multi-seq2seq generator, and re-ranks the responses for the final result. This novel mechanism connects both modules for improved performance."
}