{
    "title": "S1xcx3C5FX",
    "content": "The new approach presented focuses on estimating the proportion of inputs violating a property in neural networks. It differs from formal verification by providing a measure of network robustness and can scale to larger networks. It offers a formal guarantee of satisfiability when violations are found but only provides a statistical estimate of unsatisfiability when no violations are detected. The practical success is attributed to an adaptation of multi-level splitting, a Monte Carlo method for estimation. Our approach adapts multi-level splitting, a Monte Carlo method, to a statistical robustness framework for estimating rare event probabilities in deep neural networks. It aims to emulate formal verification procedures on benchmark problems, providing reliable information on violation probabilities. This is crucial for ensuring network robustness in mission-critical applications. The study of neural network verification involves asserting whether inputs in a specific subdomain may lead to property violations, such as incorrect class labels in a classification task. The classic approach to network verification focuses on finding counterexamples that violate the property of interest, but this has drawbacks. It does not provide a measure of network robustness and can be computationally expensive. For example, verifying a neural network for an autonomous vehicle's object classification may be infeasible due to its size. Formal verification may not scale to large networks used in many applications. The classic approach to network verification focuses on finding counterexamples that violate the property of interest, but it does not provide a measure of network robustness. To address this, a new measure of intrinsic robustness of neural networks based on the probability of property violation under an input distribution model has been developed. This measure aims to assess the network's robustness without the need for full formal verification, providing a notion of how robust a network is to a set of inputs. The new approach focuses on calculating the probability of violation to assess network robustness without formal verification. It provides a measure of how robust a network is to inputs, even for large networks where formal verification is not feasible. Calculating this probability is computationally challenging due to the rarity of violation events. The approach focuses on estimating the probability of rare violation events in network verification. It adapts the adaptive multi-level splitting algorithm to reliably estimate the probability of violation, even when it is extremely small. The framework is easy to implement, scales linearly in cost, and is agnostic to network architecture and input model assumptions. It produces a diversity of samples for robustness assessment. Our main contributions include reframing neural network verification as estimating the probability of a violation, adapting the AMLS method for large networks, and validating our approach on various models and datasets. The literature on neural network robustness involves two main threads: the classical approach to verification and methods successfully scaled for piecewise linear networks. Recent research in the deep learning community has focused on constructing and defending against adversarial attacks, as well as estimating the robustness of networks to such attacks. A new measure for robustness to adversarial attacks has been developed, estimating a lower bound on the minimum adversarial distortion needed to create an adversarial example. This approach has shown promise in scaling to larger networks. The method for estimating the lower bound on minimum adversarial distortion has drawbacks such as incorrect estimates, inability to be applied to non-Lipschitz continuous networks, expensive gradient computations, and inability to produce adversarial examples or apply to non-adversarial properties. Minimum adversarial distortion is considered an unsatisfying metric as it provides limited information about the prevalence of adversarial examples. Researchers have explored relaxing the satisfiability problem of classical verification to produce certificates-of-robustness for some samples. The research explores the robustness of reinforcement learning agents to failure, using the ACASXU dataset to train a neural network for collision avoidance in unmanned aircraft. The dataset includes ten interpretable properties for predicting steering decisions. The research explores the robustness of reinforcement learning agents using the ACASXU dataset to train a neural network for collision avoidance in unmanned aircraft. Ten interpretable properties are specified with corresponding constraints on inputs, encoded in a function s(x) that is violated when s(x) \u2265 0. The formal verification problem asks if there exists an input x in a constrained subset where the property is violated, making it satisfiable (SAT) or unsatisfiable (UNSAT). Adversarial properties in deep learning literature on datasets like MNIST involve small perturbations in an l p -ball, creating adversarial examples for neural networks classifying images into C classes. The framework for evaluating robustness in neural networks involves defining a property function that identifies adversarial examples. This approach is general and applicable to any neural network, requiring the estimation of an integral. The property function is a deterministic function of the input, the trained network, and problem-specific parameters. The property function, \u03b8 , \u03c6), is a deterministic function of the input x, the trained network f \u03b8 , and problem specific parameters \u03c6. It reflects how badly the network is performing with respect to a particular property, such as predicting rare events. The input model, p(x), is a distribution over the input domain considered for counterexamples, like uniform perturbations around an l p -norm ball. The input model places restrictions on the input domain, reflecting the severity of violations. The property function and input model determine the probability of failure, measured through an integral. Estimating this integral is crucial for assessing network robustness. Generating example inputs that violate the property is challenging due to the rarity of the event. Directly estimating the integral using Monte Carlo is often impractical for real problems. The probability estimation for rare events in practical problems is challenging due to the large dimensionality of x. Common methods like the cross-entropy method are not suitable as they rely on importance sampling, which scales poorly. Adaptive multi-level splitting (AMLS) is a highly effective method that can address these computational challenges efficiently. Adaptive multi-level splitting (AMLS) is a method designed for estimating the probability of rare events, providing highly accurate estimates even for very rare events. AMLS allows the use of MCMC transitions, scaling effectively in the dimensionality of x. It also produces property-violating examples as a side product, which could be used for robust learning. Multi-level splitting divides the problem into simpler ones by constructing intermediate targets to bridge the gap between the input model and the target distribution. Adaptive multi-level splitting (AMLS) is a method for estimating rare event probabilities accurately. It divides the problem into simpler ones by constructing intermediate targets. The approach involves drawing samples from a known perturbation model to estimate properties at each level. By ensuring small values for certain properties, reliable estimates can be obtained with moderate numbers of samples. Adaptive multi-level splitting (AMLS) involves evaluating and sorting termination criteria to estimate rare event probabilities accurately. The method divides the problem into simpler ones by constructing intermediate targets and drawing samples from a known perturbation model. By ensuring small values for certain properties, reliable estimates can be obtained with moderate numbers of samples. To convert a smaller set of starting samples to a full set for the next level in Adaptive multi-level splitting (AMLS), a rejuvenation step is carried out. This involves resampling with replacement to generate a new set of samples distributed according to a specified function. Metropolis-Hastings transitions are then applied to each sample to produce a fresh set with reduced correlations, improving estimator performance. The levels in AMLS are crucial but not discussed in detail. In Adaptive multi-level splitting (AMLS), the levels L k are set to allow reliable estimation of each P k. There is a trade-off between level closeness and computational costs. AMLS BID9 controls this by adaptively selecting the level based on a quantile of the property. The process terminates when the level reaches zero, with K dynamically chosen. Choosing the \u03c1th quantile discards a fraction of chains, allowing explicit control of rarity. In Adaptive multi-level splitting (AMLS), the levels L k are set to allow reliable estimation of each P k. AMLS BID9 controls this by adaptively selecting the level based on a quantile of the property. The process terminates when the level reaches zero, with K dynamically chosen. Choosing the \u03c1th quantile discards a fraction of chains, allowing explicit control of rarity. This approach gives P k = \u03c1, \u2200k < K, with a unique pair of values {K, P K } for estimating I. The true probability of a rare event might be exactly zero, causing the algorithm to produce closer intermediate levels indefinitely. In Adaptive multi-level splitting (AMLS), a termination criterion based on decreasing estimates is introduced to deal with producing closer intermediate levels indefinitely. The algorithm terminates if the estimate falls below a threshold probability, ensuring a finite estimate less than the threshold. The method is detailed in Algorithm 1, with an experiment testing the framework's ability to emulate formal verification approaches and provide robustness information for SAT properties. The method provides a formal demonstration for SAT properties by identifying them as UNSAT (I = 0) or SAT (I > 0). It also measures the robustness of SAT properties through its estimate for I. The COLLISIONDETECTION dataset with 500 properties (172 SAT, 328 UNSAT) was used for verification. The COLLISIONDETECTION dataset with 500 properties (172 SAT, 328 UNSAT) was used for formal verification. The approach correctly identified all UNSAT properties by estimating I as zero. Naive Monte Carlo failed to find counterexamples for 8 properties despite using more samples. Our approach successfully found counterexamples for all SAT properties, including the rarest ones, while naive Monte Carlo failed to find counterexamples for 8 of them. Our method also showed low variances in estimates and was significantly faster, with a speedup of several orders of magnitude. The cumulative distribution function of s(X) is continuous, with low bias in our method compared to naive MC estimation. Bias decreases as \u03c1 and rareness of the event decrease, and sampling improves with larger values of M and N. In practice, larger values of M and N improve sampling, while setting \u03c1 too high introduces biases. Empirically, \u03c1 = 0.1 provides a good trade-off between bias and variance. Smaller \u03c1 values lead to larger gaps in levels. The value of N did not make a discernible difference in the range tested, so all results are based on a set N value. The setting of \u03c1 significantly impacted estimates for rarer events, with larger values of M yielding better results. Validation on higher-dimensional problems was done using MNIST and CIFAR-10 datasets with a dense ReLU network. An l \u221e -norm ball perturbation was applied around the data point. After training classifiers on MNIST and CIFAR-10 datasets with a dense ReLU network, multilevel splitting was performed on test samples using different values of M. Naive MC estimates were compared to AMLS estimates, showing faster computation with AMLS. Results showed decreasing rarity of event E as M decreased, with M = 250 for MNIST and M = 1000 for CIFAR-10 yielding acceptable to high accuracy. Larger values of M were required for CIFAR-10 compared to MNIST to achieve comparable accuracy. Adversarial examples for CIFAR-10 are more perceptually similar to the datapoint. Estimates for adversarial properties were provided for MNIST, CIFAR-10, and CIFAR-100 datasets. Error bars from multiple runs show low variance in estimates, with close matching to naive MC estimates indicating low bias. The study demonstrated that as the value of M increases, the estimate converges, with larger M being more crucial for rare events. Adversarial properties were tested on the CIFAR-100 dataset using a large DenseNet architecture. The results showed that the algorithm aligned with the naive Monte Carlo estimate, with significantly reduced computation time. The robustness metric for a ReLU network trained to be more robust against perturbations using the BID27 method is examined. The method approximates outputs from perturbations with a convex outer bound to minimize worst-case loss and produce certificates of robustness. Due to memory constraints, certificates could only be calculated for a perturbation level of 0.1 before epoch 32. The experiment aims to assess if the approach yields robustness estimates consistent with increasing network robustness. The study examines the robustness of a CNN model trained on MNIST using the BID27 method to improve robustness against adversarial attacks. The model is trained for 100 epochs with cross-entropy loss, then for another 100 epochs with robust loss. The architecture includes convolutional and fully connected layers with ReLU activations. The robustification phase trains the classifier to be robust in an l \u221e -ball around the inputs. During robust training, the method calculates robustness metrics on test set samples. Results show variations in network robustness. BID27 method returns max property values for samples, providing certificates-of-robustness. If result < 0, no adversarial examples exist in l \u221e ball. If result > 0, datapoint may or may not be robust. Core aim is to provide richer information for SAT properties. In comparing the method of BID27 to a more classical approach for establishing UNSAT properties, the results show that our method forms an upper bound on the fraction of robust samples, while BID27 forms a lower bound. The true value lies between these bounds, but our bound holds physical meaning in its own right. The experiment highlights a shortcoming of BID27 regarding memory usage during training. The new measure introduced for intrinsic robustness of neural networks is more informative than that of BID27. The new measure introduced for intrinsic robustness of neural networks provides an explicit and intuitive measure for how robust networks are to satisfiable properties and offers improved scaling for identifying unsatisfiable properties. It may not be suitable in situations where there is an explicit and effective adversary. Our method may fail to find counterexamples close to the input due to low probability, especially in scenarios where formal verification is impractical or counterexamples are generated by chance rather than by an adversary. This approach offers advantages in such cases, and efficiency could be enhanced by using a more efficient base MCMC kernel in our AMLS estimator. Using a more efficient base MCMC kernel in our AMLS estimator, such as gradient-based approaches like Langevin Monte Carlo (LMC) or Hamiltonian Monte Carlo, could improve mixing of Markov chains and reduce the number of required transitions. Acknowledgments were made to Sebastian Nowozin for suggesting multilevel splitting, Rudy Bunel for help with the COLLISIONDETECTION dataset, and Leonard Berrada for providing a pretrained DenseNet model. Metropolis-Hastings (MH) is an MCMC method for sampling from unnormalized distributions. Metropolis-Hastings (MH) is an MCMC method that samples from unnormalized distributions by proposing local moves and accepting/rejecting based on unnormalized density. Each iteration is a MH transition where a new sample is proposed, acceptance probability is calculated, and the sample is accepted with a certain probability. The proposal is a conditional distribution like a normal distribution centered at the current state. Successive applications of this process generate samples. In Metropolis-Hastings (MH), samples are generated by proposing local moves and accepting/rejecting based on unnormalized density. The transition process converges to the target distribution, with diminishing correlation between samples. The computational cost of Algorithm 1 is O(N M K), with parallelization over N possible. MH updates are performed on all chains to reduce correlations and improve performance. The adaptive scheme for g(x |x) in Metropolis-Hastings helps reduce correlations over multiple levels, improving performance. Chains have separate acceptance ratios that are adjusted based on the average across MH steps. The value of M impacts results significantly for larger values of \u03c1. Per-sample robustness measures vary in Experiment \u00a75.3. In Experiment \u00a75.3, different datapoints show varying levels of robustness, with training benefiting some more than others. One datapoint remained non-robust even after training for a target perturbation size of 0.1. Figure 4 illustrates the Mean AMLS estimate relative to the unbiased MC estimate for properties with a naive MC estimate greater than log 10 I = \u22126.5, allowing for accurate estimation."
}