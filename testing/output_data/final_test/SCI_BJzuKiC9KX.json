{
    "title": "BJzuKiC9KX",
    "content": "Discrete latent-variable models can be challenging to learn due to high-variance gradient estimators caused by branching on samples and the lack of a pathwise derivative. The Reweighted Wake Sleep algorithm is shown to outperform current methods in learning these models by addressing these issues. RWS outperforms current methods in learning deep generative models with discrete latent variables, showing benefits with increasing numbers of particles. It is a competitive alternative for tasks such as tracking, clustering, speech modeling, and concept learning. Recent deep-learning approaches emphasize the importance of models with conditional branching induced by discrete latent variables. Recent deep-learning approaches highlight the significance of models with conditional branching induced by discrete latent variables. State-of-the-art methods optimize the evidence lower bound (ELBO) using various techniques, but challenges remain in large-scale learning. The IWAE ELBO estimator impacts inference-network quality with increasing particles, while using continuous relaxations leads to biased gradient estimators and exponential branching path evaluations. The text discusses challenges in learning deep generative models with discrete latent variables and introduces the reweighted wake-sleep (RWS) algorithm as a solution. It compares RWS with other methods, demonstrating its effectiveness in improving generative models and inference networks. The text also reviews current state-of-the-art methods for learning deep generative models with discrete latent variables. The text introduces the reweighted wake-sleep (RWS) algorithm as a solution for learning deep generative models with discrete latent variables. It compares RWS with other methods, showing its effectiveness in improving models and inference networks. The experiments confirm RWS as a competitive alternative that learns better models with increasing particle budgets. The text discusses learning a deep generative model with an inference network that amortizes inference, making evaluation cheaper than approximate inference from scratch. It reviews IWAEs as a method for learning deep generative models with discrete latent variables using stochastic gradient descent. The text discusses gradient-variance reduction methods for learning deep generative models with discrete latent variables. The IWAE, introduced by BID3, maximizes an average of ELBOs over data using a varying number of particles K. Increasing K tightens the lower bound on log p \u03b8 (x) but can worsen learning of the inference network due to the signal-to-noise ratio of the gradient estimator. The text explores optimizing the IWAE objective using SGD methods with unbiased gradient estimators for ELBO. Various approaches are discussed to reduce the high variance in gradient estimators, including using continuous relaxation methods like Concrete or Gumbel-Softmax distributions for discrete latent variables. The reparameterization trick is used to approximate gradients, with the main challenge being tuning the temperature parameter to balance bias and variance. Variational inference methods like VIMCO, REBAR, and RELAX improve on existing techniques for discrete random variables. The method replaces 1 with DISPLAYFORM1 using reparameterized Gumbel random variates and conditional Gumbel random variates. The control variate c \u03c1 is optimized to minimize gradient variance estimates concurrently with ELBO optimization, leading to state-of-the-art performance. The main difficulty lies in choosing a suitable family of c \u03c1, as some choices lead to higher variance despite gradient variance minimization. The objective for concurrent optimization requires evaluating a Jacobian-vector product inducing an overhead of O(D \u03c6 D \u03c1). Reweighted wake-sleep (RWS) BID2 is an extension of the wake-sleep algorithm for learning deep generative models. It alternates between updating generative model parameters \u03b8 using a wake-phase update and inference network parameters \u03c6 using either a sleep-phase or wake-phase update. This approach differs from IWAE, which targets a single objective over parameters. The reweighted wake-sleep (RWS) BID2 algorithm updates generative model parameters \u03b8 in the wake-phase and inference network parameters \u03c6 in the sleep-phase or wake-phase to maximize the negative KL divergence between posteriors under the generative model and the inference network. The gradient of this objective can be estimated by sampling z, x from the generative model and evaluating \u2207 \u03c6 log q \u03c6 (z|x). Increasing the number of samples of z, x reduces the variance of the estimator at a standard Monte Carlo rate. The outer expectation of the gradient can be estimated using a single sample x from the true data distribution p(x), and the inner expectation can be estimated using a self-normalized importance sampler with K particles using q \u03c6 (z|x) as the proposal distribution. This results in an estimator where equation 5 is the negative of the second term of the REINFORCE estimator of the IWAE ELBO. The wake-phase \u03c6 update differs from the sleep-phase \u03c6 update in that the expectation is over the true data distribution p(x). The estimator in Eq. FORMULA12 is biased but this bias decreases as K increases. The use of RWS involves the wake-phase \u03c6 update only, targeting the minimization of expected KL divergences. This approach leads to lower variance in gradient estimators of \u03c6 compared to IWAE, as it does not require REINFORCE. Increasing the computational budget improves the performance of RWS. Increasing the number of Monte Carlo samples in the sleep-phase update and the number of particles in the wake-phase update results in a better estimator of expected KL divergences. Unlike IWAE, where optimizing ELBO targets a KL divergence on an extended sampling space, increasing particles in IWAE leads to worse learning of inference networks. The sleep-phase update is suboptimal as it targets KL under the current model distribution rather than the true one, making it challenging for the inference network to follow a moving target. The experiments compare RWS to IWAE with control variate and continuous relaxation methods on models with conditional branching. Increasing particles hurts learning in IWAE but improves learning in RWS. The first experiment shows better learning in a model with discrete and continuous latent variables in a visual data domain. The experiments compare RWS to IWAE with control variate and continuous relaxation methods on models with conditional branching. RWS uses wake-sleep (WS) and wake-wake (WW) variants. Using both wake-and sleep-phase updates only improves performance on the continuous latent variable model. The number of particles K used for updates will always be specified. The experiments compare RWS to IWAE with control variate and continuous relaxation methods on models with conditional branching. Evaluating WW and VIMCO on AIR, a structured deep generative model with discrete and continuous latent variables. AIR uses a sequential inference procedure with a maximum of three inference steps and is trained on images of size 50\u00d750 with zero, one, or two MNIST digits. Unlike AIR, we use a Gaussian likelihood with continuous inputs. The generative model is trained using a Bernoulli likelihood and binarized data with fixed standard deviation and continuous inputs. Training is done over two million iterations with RmsProp BID34 and a learning rate of 10^-5. The glimpse size is set to 20x20. Evaluation is done through average test log marginal and KL divergence from the inference network to the posterior. The current model estimates the KL divergence using a difference between log marginal estimates and a 5000-sample IWAE estimate. Increasing the number of particles hurts learning in VIMCO but improves learning in WW. WW shows lower variance and better inference networks than VIMCO. RWS is evaluated on a variational autoencoder with normally distributed latent variables for MNIST using a single stochastic layer of BID3 and stochastic binarization of data. Increasing the number of particles hurts learning in IWAE but improves learning in WW. WW also results in better inference networks than IWAE as shown by the KL plot on the right of FIG2. Additionally, increasing K improves the marginal likelihood attained by both models, but further increase in particles has diminishing returns. The number of clusters C affects the quality of the generative model, with WS and WW improving with a larger particle budget. However, IWAE methods suffer with a larger particle budget. WS performs poorly due to computing the expected KL under the model distribution, while WW suffers from zero-forcing in low-particle regimes but learns the best model fastest in many-particle regimes. The quality of the inference network develops similarly to that of the generative model, with WW and WS having lower-variance gradient estimators than IWAE. IWAE was trained with various methods and distributions, including REINFORCE, RELAX, VIMCO, and the Concrete distribution. The model was trained with a fixed number of clusters and an increasing number of particles. The Adam optimizer was used with specific parameters, and a batch of data points was generated at each iteration for training. Temperature schedules were explored for the Concrete distribution to find the most suitable one. The Concrete distribution was optimized with a temperature schedule annealing from 3 to 0.5. The control variate c \u03c1 (g 1:K ) =(1 + C)-16-16-1 improved training stability. Evaluation included generative model, inference network, and gradient estimator variance. Generative model assessed via L2 distance between PMFs of prior and true prior. Inference network evaluated by L2 distance between PMFs of current and true posteriors. Demonstrated the use of WS and WW. Using WS and WW with larger particle budgets improves inference networks, while IWAE methods do not benefit as much. More samples reduce variance for WS, and more particles lower bias for WW. However, increasing the particle budget leads to worse learning of the generative model for IWAE methods due to a drop in signal-to-noise ratio. The quality of the \u03b8 gradient estimator is crucial for all methods. The importance sampling estimator IS (\u03b8, \u03c6, x) quality depends on the proposal distribution. WW and WS have lower variance gradient estimators than IWAE. \u03c6's gradient estimators for WW and WS exclude the high-variance term 1, aiding efficient learning. However, employing the Concrete distribution can lead to high gradients bias. A failure mode called zero-forcing affects WS, WW, VIMCO, and REINFORCE methods. The inference network and generative model in the low-particle regime are analyzed, showing a local optimum for WS due to well-approximated posterior and limited support. Similar issues occur for WW and VIMCO/REINFORCE with larger support for the locally optimal generative model. In the low-particle regime, the inference network and generative model face challenges with local optima. A proposed extension, \u03b4-WW, addresses this by modifying the proposal in the importance sampling estimator. This adjustment improves the learning of both the generative model and inference network. Using a different proposal than the inference network q \u03c6 (z|x) leads to defensive importance sampling, improving estimation of integrands with long tails. \u03b4-WW outperforms other algorithms in learning generative models and inference networks, especially in models with discrete latent variables. RWS is competitive even in models with continuous latent variables, as shown in the MNIST experiment. The study suggests that RWS is competitive in models with continuous latent variables, especially with a high number of particles. The GMM experiment highlights the lower variance gradient estimator for the inference network in RWS compared to IWAE ELBO. Increasing the number of particles improves the inference network in RWS, unlike IWAE ELBO. Defensive RWS helps alleviate zero-forcing of the generative model and inference network in the low-particle regime. Increasing the particle budget affects the generative model quality in IWAE ELBO but not in RWS. The findings recommend considering RWS for learning deep generative models, especially those with discrete latent variables. RWS is recommended for learning deep generative models with discrete latent variables that induce branching."
}