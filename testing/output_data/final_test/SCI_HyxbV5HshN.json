{
    "title": "HyxbV5HshN",
    "content": "This paper explores the connections between adaptive control and machine learning, highlighting common update laws and concepts. It discusses leveraging results from both fields to solve new problems, with a focus on higher order learning. Adaptive control emphasizes mathematical rigor and guaranteed convergence, while machine learning focuses on computer-based systems that improve through experience. The fields have evolved in parallel with significant overlap in goals, problem statements, and tools. The field of adaptive control focuses on controlling engineering systems to regulate and track critical variables in the presence of uncertainties. Parameters are learned to approximate functions, with optimization methods used to reduce errors. Adaptive control emphasizes learning underlying parameters to achieve regulation and tracking. In adaptive control, regulation and tracking involve learning parameters through online estimation algorithms. Stability theory ensures safe evolution of critical variables and convergence of errors to zero. Both machine learning and adaptive control update parameters using gradient descent-like algorithms. Analysis, convergence, and robustness tools in both fields show similarities. Understanding these connections can lead to new methods for addressing challenges. In machine learning and adaptive control, error models involve adjusting parameters \u03b8 based on regressors \u03c6 and output errors e y to minimize a loss function L(\u03b8; e y ). Solutions include gradient flow in continuous time for adaptive control and gradient descent in discrete time for machine learning. Common modifications to update laws have been developed to address new challenges. Common modifications to the update laws in adaptive control and machine learning have been developed to reduce output error and ensure robustness to disturbances. Regularization is often included in machine learning optimization to prevent overfitting by adding constraints on parameters. The gradient descent update for the augmented loss function in online learning is known as the \"regularized follow the leader\" algorithm. Common modifications in adaptive control include employing a \"dead-zone\" for parameter updates to increase robustness against disturbances. Output error can be used to stop adaptation in specific regions of the output space. One common approach is to set D = ey so that adaptation halts once a small output error is achieved above a noise level with an upper bound d0. Training processes are often stopped in machine learning applications to address overfitting by using multiple data sets and halting the parameter update process when the loss on a validation data set starts to increase. Early stopping is crucial for training neural networks due to their large number of parameters and can serve as a form of regularization. It is important to define a compact region a priori for the parameters \u03b8 to prevent them from leaving that region during the learning process. Natural constraints in physical systems or engineered constraints in non-physical systems can help design this region. The continuous projection algorithm in adaptive control defines a boundary layer region inside a compact convex set \u0398 for increased robustness. The projection operation in online learning finds the closest point in a convex set, which can be used in parameter update laws. One example alters the gain of the update law as a function of time varying regressors. In adaptive control and online machine learning, stability and convergence tools are analyzed. The update for \u0393 can be used in the update for \u03b8 to adapt to the regressor \u03c6. Adaptive step size methods adjust step size based on features processed online. Common update laws for adaptive step size methods involve functions of previous gradients. In adaptive control, stability is often proven using a Lyapunov function V. The update law and KYP lemma are used to express the time derivative of V. A Hurwitz matrix \u039b implies the existence of a positive definite matrix P. In online learning, algorithm efficiency is analyzed using the notion of \"regret\". In online learning, algorithm efficiency is often analyzed using the notion of \"regret,\" which corresponds to the sum of time-varying convex costs associated with parameter estimates. The goal is to have regret grow sub-linearly with time to ensure an efficient algorithm for adaptive control. In adaptive control, models are approximations with modeling errors and unmodeled dynamics. Stabilizing controllers must adapt to uncertainties and be robust. Constraints on state and input add complexity, leading to non-global guarantees. Update laws ensure robustness in adaptive control, similar to the notion of robustness in machine learning. Generalization in machine learning refers to the ability of an estimator to produce low prediction error on unseen data. Stability and training time play a role in generalization error. Persistent excitation of the system regressor is necessary for parameter convergence in adaptive control. If the regressor is persistently exciting, the parameter estimation error converges to zero over time. The PE condition is related to satisfying certain spectral conditions by the regressor. The PE condition ensures parameter convergence by satisfying spectral conditions with the regressor. Stochastic perturbations can lead to improvements in system identification, with the potential for perfect test error in machine learning problems. Approaches in machine learning algorithms for system identification and control aim to obtain performance bounds with probability 1 \u2212 p f for p f \u2208 (0, 1) to address the realistic case of finite samples. Gradient-based methods using backpropagation have been used for decades in control, leading to the development of neural networks for tasks like finding optimal trajectories in flight control and resource allocation. The use of neural networks in control systems has expanded to include stabilizing nonlinear dynamical systems. The adaptive control community explored stable controllers based on neural networks due to similarities with gradient-like update laws. In the 1990s, a literature was established for using neural networks in nonlinear dynamical systems. Recently, the machine learning community has seen a significant increase in the use of neural networks, thanks to improved computing power and a wider range of applications. Recurrent neural networks, although structurally similar to nonlinear dynamical systems, have historically been trained similarly to feed-forward neural networks using backpropagation through time. The machine learning community has rigorously analyzed deep neural network architectures, including deep linear networks. Update laws in training deep neural networks often involve modifications. Methods from adaptive control can be used for higher-order learning, with a focus on accelerated learning for higher-order methods like Nesterov's accelerated method. BID52 certified a convergence rate of O(1/k 2) compared to standard gradient descent rate of O(1/k) for convex functions. Nesterov's higher order method parameterization involves a design parameter \u03b2 > 0. Adaptive update laws with additional integration levels were explored in \"higher order tuners\" in BID44 BID18. The update law in (20) is stable in the presence of time varying regressors and in adaptive control applications. In adaptive control, the main goal is to solve problems like estimation or tracking in the presence of uncertainties. The model involves exogenous input u, state x, output y, measured variables \u03c6, and uncertain parameter \u03b8*. In an estimation problem, the goal is to estimate the state x and output y alongside the unknown parameter \u03b8* simultaneously, using all available variables. In a control problem, the goal is to determine a control input u so that the output y follows a desired output \u0177. Estimators and controllers are designed to minimize estimation and tracking errors, ensuring convergence to the desired values. The goal in adaptive control is to choose functions g2 and g3 for control input u and parameter estimate \u03b8, leading to bounded signals, zero error convergence, and true parameter value convergence. A stability framework and error model approach are used to derive these functions, focusing on the relationship between estimation error ey and parameter error \u03b8. The estimation error is measurable and linked to the parameter error, which is unknown but adjustable. The relationship between estimation error and parameter error in adaptive control is crucial for determining update laws. Two types of error models are commonly used, one linear and the other involving a dynamic operator. Specific classes of dynamic operators allow for stable, gradient-like rules for adjusting parameters. In machine learning, the focus is on the core of the learning problem with multi-dimensional regressors \u03c6 and parameter estimates \u03b8. The unknown parameter \u03b8 * is often assumed to be in a compact convex set \u0398. Supervised learning involves relating regressors \u03c6 and outputs y in an unknown algebraic manner. Output estimators are chosen with adjustable weights \u03b8 k for classification or regression. Output estimators in machine learning involve adjustable weights \u03b8 k, which are often adjusted using the output error e y,k = \u0177 k - y k. A loss function is minimized through these weights, with examples including p loss for regression and common loss functions like hinge loss and logistic loss for binary classification. The total loss function considered for parameter update may be an average of loss functions over m samples. The structure of the estimation problem in adaptive control and machine learning is similar. In adaptive control, the goal is to adjust \u03b8 online using knowledge of \u03c6 and e y to minimize output errors. A gradient-like update is typically used, with a squared loss cost function and a gradient flow update law. For dynamical error models, a stability approach is taken instead of a gradient-based one. In adaptive control and machine learning, a stability approach is taken for dynamical error models. The common update law is similar to gradient descent, with a decreasing stepsize over time."
}