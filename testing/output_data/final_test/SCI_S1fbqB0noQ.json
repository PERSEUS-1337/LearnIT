{
    "title": "S1fbqB0noQ",
    "content": "This article proposes a deep generative model for Automatic Speech Recognition (ASR) using mixture density networks and standard LSTMs to improve acoustic modeling. The model aims to enhance conditioning and discriminative feature extraction for better recognition accuracy. The dual-stack LSTM architecture is related to the RNN Transducer, incorporating a density functional form and a separate language model using Bayes rule. Generative models are compared based on log-likelihoods and frame accuracies in ASR. The field historically used separate modules in an overall processing chain, formalized by Fred Jelinek's noisy channel model. This model enables the Bayes' decision procedure for acoustic observations and word sequences. The model used in ASR incorporates Gaussian Mixture Models (GMMs) and 1st-order Hidden Markov Models (HMMs) to provide acoustic likelihoods for sequences of acoustic feature vectors conditioned on modeling units. The acoustic log-likelihood is defined with strong independence assumptions, allowing for efficient computation of alignments. The ASR model incorporates GMMs and 1st-order HMMs to provide acoustic likelihoods for sequences of acoustic feature vectors. The approach is compositional, allowing for the addition or substitution of modules while maintaining the overall model. More powerful models like DNNs and LSTMs have been adopted without altering the model significantly. The \"hybrid\" approach converts posteriors obtained from DNNs or LSTMs to scaled likelihoods. The hybrid model converts posteriors from DNNs or LSTMs into scaled likelihoods, which can be used in the channel model and sequence training objectives like utterance-level MMI or sMBR. Sequence training can implicitly estimate the scaling term, optimizing the sequence-level criterion. The hybrid model converts DNN or LSTM posteriors into scaled likelihoods for sequence training objectives like utterance-level MMI or sMBR. End-to-end models like LAS or RNN-T directly optimize a discriminative sequence-level model with no chaining of sub-module probabilities, achieving state-of-the-art results on challenging tasks. The combination of end-to-end models with other models, such as LM, has been explored for ASR. Different methods like \"Shallow Fusion\", \"Deep Fusion\", and \"Cold Fusion\" have been used, but they lack clear mathematical justification. Another approach involves forming a separate estimate based on transcript data to improve model combination. The transcript data is used to train P(W|X) and form a scaled likelihood of the acoustics given W. This scaled likelihood can be combined with P*(W) for recognition using Bayes rule, with uncertainty on its effectiveness compared to fusion techniques. The scaled likelihood can also be used in conventional ASR approaches with discriminative acoustic models for sequence training objectives like utterance-level MMI or sMBR. Depending on the model used for P(W|X), sequence training can implicitly estimate the scaling term to optimize the sequence-level criterion. Generative acoustic models optimize sequence-level criterion using Bayes rule. Early models for ASR were limited by strong independence assumptions, unlike deep discriminative models like DNNs and LSTMs. In contrast, generative models have advanced in speech synthesis, with TTS models like WaveNet and Tacotron modeling p(X|W) as a fully-conditioned autoregressive model. The \"conditional WaveNet\" model and mixture density networks have been effective in deep generative TTS models and ASR. Mixture density networks use a Gaussian mixture density function, which is suitable for ASR models operating on feature vectors. Mixture density networks are a good starting point for investigating deep generative models for ASR. ASR decoding with strong conditioning on symbol sequence history cannot merge partial hypotheses, similar to end-to-end ASR models like LAS and RNN-T. Time-synchronous beam-search is one of the decoding strategies that can be used. One effective approach to ASR decoding involves N-best rescoring using models like LAS and RNN-T. The tandem approach, such as BID6 BID10, combines deep features with acoustic features for improved results. These deep features are extracted from a bottleneck layer, concatenated with acoustic features, and transformed before being used in a generative model like GMMs. The approach proposed extends past work by incorporating PCA for more discriminative features in the generative model. Previous studies focused on DNNs for feature extraction and standard GMMs for the generative model. Integrating ASR and TTS has a long history, with recent applications in semi-supervised training. The models discussed here build upon this body of work. This study explores two dimensions of depth for ASR-oriented generative models: shallow features like raw acoustic features and deep features obtained from LSTM stacks, and shallow density layers like vanilla gaussian mixture models and deep density networks for modeling acoustic feature sequences. The study explores shallow mixture density models trained with ML to model acoustic feature sequences. The vanilla gaussian mixture model makes strong independence assumptions and is implemented in TensorFlow. Parameters are represented as TensorFlow Variables, with mixing weights enforced to sum to one. The study explores shallow mixture density models trained with ML to model acoustic feature sequences. The model uses a single scalar standard deviation per mixture component and emphasizes the similarity to DNN/LSTM final layer. The input feature can be transformed using a diagonal or lower-triangular matrix to strengthen the model. The study explores shallow mixture density models trained with ML to model acoustic feature sequences using a simple radial model. SGD-based optimization can be done with various criteria such as Maximum Likelihood (ML) or Cross Entropy (CE). SGD is not specifically suited to ML/GMM optimization but offers generality for joint optimization of density functions with deep features. The study investigates the use of ML/SGD for estimating GMMs with deep features or density parameters generated by neural networks. It was found that ML/SGD can effectively learn correct estimates from synthetic data, even for mixtures with highly overlapping components. Sanity checks were used for real-world data, including TensorBoard histograms and log-likelihoods on the training set. The study explores ML/SGD for estimating GMMs with deep features or density parameters using neural networks. Increasing mixture components improves log-likelihoods on the training set. Comparing ML/SGD-estimated GMMs with EM-estimated GMMs in TensorFlow could enhance performance. Autoregressive and non-autoregressive deep mixture density networks model shallow features, with the former using all label symbols and previous acoustic features. The likelihood can be plugged into a more powerful model for better performance. The mixture density network predicts the next acoustic feature frame using label symbols, leveraging long-span symbol context for non-standard acoustic modeling units. The autoregressive model adapts to past observed acoustic features, while the non-autoregressive model must model all acoustic variability across speakers and environments. The autoregressive model considers variants such as frame shift, linear bottleneck, and stride to provide less past input. \"Professor Forcing\" addresses the issue of \"Teacher Forcing\" in autoregressive models. Shallow mixture density layer models deep discriminative features. The deep features obtained from an LSTM stack are used in a shallow density model for modeling discriminative features. Unlike previous tandem work with DNNs, no bottleneck layer is needed due to the compact LSTM layer size. The model can be trained with ML and features are highly discriminative. Joint training of the density function and feature extractor is possible but requires proper handling of the Jacobian of the inverse function. The curr_chunk discusses the application of a deep density network to model deep features, resembling the RNN Transducer architecture. It involves using an LSTM stack to encode a label sequence and deep features for the acoustic sequence. The resulting likelihood can be trained with ML for highly discriminative features. Joint training with ML is feasible but requires proper handling of the Jacobian of the inverse function. The curr_chunk discusses the application of mixture density networks to model deep features, focusing on frame accuracies and log-likelihood improvements. The experiments aimed to verify the conditioning of the networks and gain insights into word error rates. The deep density networks generate one label class output at a time. The deep density networks generate one label class output at a time, using a simple label class prior in-network BID30. The issue of label context for frame accuracy measurement is addressed, with experiments focusing on the discriminative power of the AM itself. The approach involves measuring frame accuracy for density networks by conditioning on ground-truth label sequences up to time t-1, with only the label at time t being hypothesized efficiently in TensorFlow. The dataset used consists of 20000 hours of spontaneous speech data for American English, with training examples being sequences of feature vectors extracted from audio samples. The acoustic feature vectors are 256 dimensional and based on discriminative acoustic encoder architectures. The \"deep feature\" models use 256 dimensional logmel energies, while the \"shallow feature\" models use 96 dimensional cepstral coefficients. MFCCs with derivatives are preferred for shallow feature density networks over logmel features. The training architecture closely follows a TensorFlow based implementation with a batch size of 64 example utterances and a fixed static LSTM unrolling of 20 frames. The training architecture uses a batch size of 64 utterances and fixed static LSTM unrolling of 20 frames. Each LSTM stack has 5 layers with 512 units, totaling roughly 4.3M parameters. The class outputs include 42 context-independent phonemes or 8192 context-dependent phonemes. A label class embedding of size 128 is used for all experiments. CE training of density models combines acoustic likelihood output with an in-network estimate of state prior. The statistics for frame accuracy and costs were obtained from smoothed TensorBoard plots. Frame accuracies are based on a small dataset of 1000 utterances and costs are running averages over the entire training set. These metrics offer insights into the explored conditions, with a frame accuracy below 27% considered abysmal. TAB0 describes the costs and frame accuracies for all models. The frame accuracy for models using shallow mel-cepstral features is abysmal, with a ML-trained radial gaussian mixture at 35% and a 5-layer DNN at 55%. CE-training the gaussian mixture model increases accuracy to 48%. Deep density models outperform shallow models in terms of cost. The autoregressive models outperform non-autoregressive models in log-likelihoods. Full autoregressive models perform better than limited input models. However, providing too much past input to LSTM stacks decreases frame accuracy. Unsupervised versions merge all class input into a single symbol. The label class information may not be necessary for discriminative prediction. In the CI phone scenario, merging all class input into a single symbol does not improve prediction cost over unsupervised prediction. The \"CD AR\" model performs slightly better with a cost of 42.3. Shifting the prediction target 3 frames into the future benefits the CI model, with a cost of 116 vs 118 for the unsupervised version. Increasing mixture components from 10 to 256 improves prediction cost significantly. Deep non-autoregressive densities with shallow features result in worse prediction cost but better frame accuracies compared to autoregressive models. In the context of deep non-autoregressive densities with shallow features, the frame accuracies are much better compared to autoregressive models. However, they are still not as competitive as simple DNNs and slightly worse than CE-trained shallow density models. LSTM stacks using radial density as the last layer achieve frame accuracies of 87% and 79% for CI and CD versions respectively, matching standard LSTMs. ML training results show a drop in performance compared to pure CE training. The dual LSTM stack architecture performs well as a predictor of deep features, showing improved frame accuracy compared to shallow density models. The deep features extracted phoneme information from CE training, making the prediction problem more about label prediction. The deep features extracted phoneme information from CE training, making the prediction problem more about label prediction. The problem is a label prediction problem, trying to predict an encoding of an acoustic sequence using an encoding of a label sequence. Four generative models were evaluated, extending the original tandem approach to ASR. Results give insights into the models but are tentative without WER evaluations. The evaluations provide insights into the proposed models, with log-likelihood results aligning with expectations. Weak results for supervised vs unsupervised models may indicate issues with experimental setup or model weaknesses. The CD phone model shows better results, suggesting potential issues with representing CI label context or \"future blindness.\" Appendices explore covariance model strength and model differences in more detail. Frame accuracies for models using shallow acoustic features are deemed too low for practical use. The frame accuracies for models using shallow acoustic features are too low for ASR use. Autoregressive models may perform better in an ASR decoding framework. Deep features solve problems with modeling variability and provide strong discriminative power. Generative models with state-of-the-art frame accuracy could be viable for ASR, but questions remain about their generative nature. The generative nature of models like autoregressive density networks can potentially improve ASR decoding by addressing questions about compositionality, unsupervised training, and adaptation. Evaluation of different covariance models for logmel features shows the impact of stronger covariance models on performance. The Appendix discusses the effect of different target prediction shifts for autoregressive density networks modeling logmel features, comparing supervised and unsupervised models. Results show improvements in prediction cost with full covariance models, but frame accuracy remains low. The Appendix compares supervised and unsupervised autoregressive deep density networks using logmel spectrograms to predict logmel features with different shifts. Results show worse prediction cost for larger shifts, a larger difference between supervised and unsupervised models, and no impact on frame accuracy. Radial deep density networks were trained with a single gaussian per mixture, and the generated mean vectors were plotted over time for unseen data. Target features and generated means were illustrated for individual data mini-batches in a truncated LSTM unrolling scheme. For a prediction shift of 1 frame, there is no significant difference between unsupervised and supervised prediction. However, with a shift of 4 frames, unsupervised prediction performs poorly while supervised prediction benefits from label encoding. The supervised model outperforms the unsupervised model with a prediction shift of 4 frames due to label encoding."
}