{
    "title": "SkEqro0ctQ",
    "content": "Deep neural networks (DNNs) have impressive predictive performance by learning complex relationships between variables. To address the black box nature of DNNs, a method called agglomerative contextual decomposition (ACD) is introduced. ACD explains DNN predictions through hierarchical interpretations, clustering input features and their contributions to predictions. It helps diagnose incorrect predictions, identify bias, and extract polarizing phrases. ACD enables users to identify accurate DNNs and trust their outputs. It is robust to adversarial perturbations, capturing fundamental aspects of input and ignoring noise. DNNs have impressive predictive performance but are often seen as black boxes, limiting their use in fields like medicine, policy-making, and science. The use of hierarchical interpretations in explaining DNN predictions is introduced to address issues like fairness and regulatory pressure in industrial settings. The proposed method, agglomerative contextual decomposition (ACD), produces a hierarchical clustering of input features and their contribution to the final prediction. ACD is a general technique applicable to various DNN architectures and data types, aiming to identify predictive feature clusters. The agglomerative contextual decomposition (ACD) method extends contextual decomposition (CD) to various DNN architectures, introducing hierarchical saliency for group-level importance measures. ACD is demonstrated on LSTMs and CNNs, producing intuitive visualizations to enhance understanding and trust in DNNs. ACD produces intuitive visualizations for better reasoning and trust in DNNs. Users can use ACD to select models with higher accuracy and rank it as more trustworthy than prior methods. ACD's hierarchy is robust to adversarial perturbations in CNNs. It is illustrated through a toy example of predicting phrases, showing how it identifies meaningful phrases and provides importance scores. Interpreting DNNs is a growing field with various techniques. Interpreting DNNs is a growing field focusing on local interpretations of individual predictions. Prior work assigns importance to features like pixels or words using gradient-based and decomposition-based methods. Few methods can extract interactions between features in a DNN. There are limited methods to extract feature interactions in DNNs. Contextual decomposition (CD) was introduced for phrase-level importance scores in LSTMs. Hierarchical interpretations are proposed to search for and display important feature groups. Results from psychology and philosophy suggest that people prefer explanations that are simple but informative and include the appropriate amount of detail. To address the lack of a powerful yet simple method to capture interactions between features, a hierarchical clustering procedure is proposed to identify and visualize meaningful feature groups. This approach aims to be informative enough to capture interactions while maintaining simplicity by displaying a small subset of all feature groups. The section introduces ACD through two contributions: a generalization of CD from LSTMs to arbitrary DNNs and an explanation of how to identify and visualize meaningful feature interactions. The main contribution of the generalized CD algorithm is to decompose the logits of a given DNN into two terms, \u03b2(x) and \u03b3(x), where \u03b2(x) represents the importance measure of a group of features and \u03b3(x) captures contributions not included in \u03b2(x). This decomposition is computed layer-wise to capture interactions between features in the DNN. The generalized CD algorithm decomposes the logits of a DNN into two terms, \u03b2(x) and \u03b3(x), where \u03b2(x) represents the importance measure of features and \u03b3(x) captures other contributions. This decomposition is computed layer-wise for various neural network architectures, extending CD scores from LSTMs to CNNs with different layers. The algorithm was initially based on CD rules from previous work but was found to be ineffective for deeper ImageNet CNNs. The CD algorithm was initially ineffective on deeper ImageNet CNNs, leading to modifications in partitioning biases and decompositions for convolutional layers. The bias is proportionally partitioned based on layer activations, with separate operations for weight matrices and biases. Max-pooling layers identify selected channels using max idxs. The CD algorithm was modified for deeper ImageNet CNNs by adjusting partitioning biases and decompositions for convolutional layers. Max-pooling layers select channels using max idxs, and a clustering procedure based on CD interaction is used for ACD interpretations. The ACD interpretation hierarchy is generated by iteratively combining individual features based on CD interaction scores. Algorithm 1 outlines the clustering procedure, starting with computing CD scores for each feature and selecting groups within a certain threshold. Candidate groups are ranked by CD interaction score for text and images. The ACD algorithm ranks candidate groups based on CD interaction scores for text and images. It stops based on specific criteria, such as selecting all words for sentiment classification or a predefined number of iterations for images. While Algorithm 1 is not DNN-specific, it uses CD scores to generate interpretations, making it applicable to any predictive model. Empirical validation of ACD has been done on LSTMs. The empirical validation of ACD is presented on LSTMs trained on SST and CNNs trained on MNIST and ImageNet. The visualization tool is introduced for understanding models in various settings, followed by quantitative evidence of ACD benefits through human experiments and stability to adversarial perturbations. Standard best practices are used to train models, achieving 86.2% accuracy on SST with a binary classification LSTM model. The curr_chunk discusses training a binary classification LSTM model with 86.2% accuracy, using PyTorch on MNIST with 97.7% accuracy, and utilizing a pre-trained VGG-16 DNN on ImageNet with 42.8% accuracy. The agglomeration process on ImageNet starts with 14-by-14 superpixels for computational reasons. Weakening models for human experiments involves random permutation of weights, reducing test accuracy. The chunk also introduces the visualization tool for interpreting predictive model behavior before providing quantitative evidence of ACD benefits. In the curr_chunk, the authors demonstrate the utility of ACD in interpreting a predictive model's behavior. They show examples of using ACD to diagnose incorrect predictions in SST and identify dataset bias in ImageNet. The ACD visualization helps quickly diagnose why the LSTM made an incorrect prediction by identifying key phrases and sentiments. The LSTM inaccurately predicts positive sentiment when two specific phrases are joined, indicating an erroneous learned interaction. ACD is used to interpret a VGG model on ImageNet, revealing that the CNN focuses on both the puck and the hockey player's skates to predict \"puck\". The network relies on the presence of skates as a strong feature for identifying pucks, which may not be desirable in certain contexts. ACD is used to show top-scoring phrases for an LSTM trained on SST, reflecting sentiment. ACD interpretation for a VGG network prediction reveals dataset bias towards skates for predicting \"puck\". ACD successfully identifies important regions for the target class \"puck\" by analyzing image patches. The visualization provides qualitative evidence of its uses and quantitative evidence of its benefits. ACD was tested through human experiments to assess trust and reasoning about DNN accuracy. Eleven graduate students participated in a survey comparing ACD against three baselines on three datasets. The survey prompts are provided in Supplement S4. The objective was to determine if subjects could use ACD interpretations to identify the more accurate model. The study tested ACD through human experiments to evaluate trust and reasoning about DNN accuracy. Subjects were asked to compare interpretations from different models to identify the more accurate one. The predictions shown aimed to maximize disagreement between models and prevent subjects from simply choosing the model with higher accuracy for a given example. The study tested ACD through human experiments to evaluate trust and reasoning about DNN accuracy. Subjects compared interpretations from different models to identify the more accurate one. Results showed humans were better at identifying the strongly predictive model using ACD compared to other baselines. ACD outperformed random selection, with significant gaps between ACD and IG/Occlusion. ACD performs similarly to other methods on MNIST but outperforms them on ImageNet. It is the only method to surpass random chance. Human experiments showed that ACD helps subjects trust a model's predictions more than other techniques. ACD substantially outperforms other baselines, particularly for ImageNet, achieving an average rank of 3.5 out of 4. Results on MNIST were inconclusive. The difference in mean ranks between ACD and all other methods is statistically significant for SST and ImageNet. Little effort has been devoted to qualitatively understanding adversarial attacks. In this section, evidence is provided that ACD's hierarchical clustering on MNIST is robust to adversarial perturbations, capturing fundamental image features immune to noise. A metric is introduced to quantify the similarity between ACD hierarchies on unaltered and perturbed images, allowing for dataset-level statements on stability. ACD hierarchies show high stability against adversarial attacks, with consistent correlation across different attack types. Using occlusion instead of CD results in less stable hierarchies. The ranking of input image pixels in the hierarchy is computed to measure similarity between ACD hierarchies for original and adversarial images. Class-specific ACD hierarchies are compared by averaging correlations for original and adversarially altered predictions. ACD hierarchies exhibit high stability against various adversarial attacks, as shown by consistent correlations. Comparisons with other methods using occlusion instead of CD reveal lower stability. The novel agglomerative contextual decomposition (ACD) algorithm captures fundamental image features effectively and is resilient to adversarial noise. ACD is a novel hierarchical interpretation algorithm that uses a hierarchy to interpret individual neural network predictions, capturing non-linear contributions and demonstrating benefits through human experiments. The hierarchy is robust to adversarial perturbations in CNNs, showing stability and ignoring spurious noise. The curr_chunk discusses unit-level CD scores for the correct class compared to baseline methods, showing contributions of blob and non-blob throughout the network. It compares CD decomposition to perturbing the input using occlusion and build-up methods, highlighting similarities in early layers but differences later on. The curr_chunk provides an extended version of TAB2 with top phrases for positive/negative polarities extracted using ACD from an LSTM trained on SST. It includes visualizations chosen based on human experiment criteria and instructions for comparing two models. The curr_chunk compares two models classifying movie reviews as positive or negative based on predictive accuracy. Visualizations show what each model has learned using different methods to identify word contributions. Readers are asked to select the model with higher accuracy based on the visualizations. The task involves comparing visualizations of two models classifying images of digits. Readers are asked to select the model with higher accuracy based on the visualizations provided. The task involves comparing visualizations of two models classifying images of digits to determine which model has higher predictive accuracy. Heat maps display positive and negative signals for different classes, with additional visualizations showing pixel groups contributing to the predicted class. Readers are asked to rank visualization methods based on trust in the model. The task involves comparing two image classification models based on their predictive accuracy. Visualizations show how each model identifies contributions to the final prediction using heat maps. The heat maps display positive and negative signals for different classes, with additional visualizations showing pixel groups contributing to the predicted class. The goal is to rank visualization methods based on trust in the model. The task involves comparing two image classification models based on their predictive accuracy using visualizations of pixel groups contributing to the predicted class. The hierarchies constructed by ACD to explain a prediction are similar for both the original image and an adversarially perturbed image. The development of a general CD involved two key modifications: partitioning the bias between \u03b3 i and \u03b2 i to reduce noise in heat maps, and replacing the ReLU Shapely decomposition to prevent unrealistically large CD scores in certain areas. These changes improve the model's decision-making process. The combination of bias partitioning and ReLU decomposition in the model results in qualitatively sensible heatmaps with reasonably valued CD scores. These changes improve the interpretation of smaller models used on SST and MNIST without significantly affecting the model's predictions. Comparing unit-level CD scores to those from a naive extension of CD to CNNs shows qualitative improvements in scores and avoids extremely large magnitudes. The color scheme used for the scores is blue for positive, white for neutral, and red for negative, with scores representing the correct class predicted by the model."
}