{
    "title": "HylHE-9p6m",
    "content": "Fine-grained Entity Recognition (FgER) involves detecting and classifying entity mentions across various domains. The lack of properly annotated datasets covering a wide range of entity types hinders supervised learning models. To address this issue, the Heuristics Allied with Distant Supervision (HAnDS) framework is proposed to automatically construct a quality dataset for FgER tasks. By leveraging the interlink between Wikipedia and Freebase, HAnDS reduces annotation errors and creates datasets suitable for recognizing up to 118 entity types. The text discusses the creation of datasets for Fine-grained Entity Recognition (FgER) tasks, with one dataset recognizing up to 118 entity types based on the FIGER type hierarchy and another for up to 1115 entity types based on the TypeNet hierarchy. Additionally, a manually annotated dataset is provided for benchmarking FgER systems. The process of manually constructing datasets for FgER tasks is highlighted as expensive and time-consuming due to the assignment of multiple types to entity mentions. The Fine Entity Categorization or Typing (Fine-ET) problem in FgER has expanded its type coverage from coarse-grained to fine-grained types using annotations from Wikipedia and Freebase. The Fine-ET problem assumes entity boundaries are provided, but entity mention detection remains a bottleneck. Existing FgER systems follow a two-step approach of detecting and categorizing entity mentions. Our analysis challenges the assumption that all entity types can be categorized into person, location, organization, and miscellaneous. The miscellaneous category only covers a portion of entity types in the FIGER and TypeNet hierarchies, leading to potential gaps in entity detection models trained on CoNLL data. To address this, we propose the HAnDS framework to automatically construct a dataset suitable for Fine-ET in FgER. The HAnDS framework is used to generate two corpora for the FgER task, containing millions of entity mentions annotated with various entity types. The datasets are evaluated extensively for quality compared to existing ones. The HAnDS framework is used to generate datasets for the FgER task, showing significant improvement in model performance. A manually annotated corpora with 117 entity types is provided for benchmarking FgER models. The contributions include analyzing poor recall in entity detection using CoNLL dataset, proposing the HAnDS framework for dataset construction, and establishing state-of-the-art baselines. The paper introduces the HAnDS framework for fine entity typing, establishing state-of-the-art baselines on a new manually annotated corpus with more entity types than the FIGER gold corpus. The related work is divided into automatic dataset construction and noise reduction techniques for entity recognition tasks. The Naive Distant Supervision (NDS) approach utilizes the distant supervision paradigm to automatically generate a dataset for the Fine-ET problem. This approach links Wikipedia and Freebase to assign entity types based on hyperlinks in Wikipedia sentences. The generated dataset, known as the FIGER dataset, only contains positive annotations, making it suitable for the Fine-ET problem but not for learning entity detection models due to a high number of false negatives. The NDS approach is used to create datasets for variants of the Fine-ET problem. Recent work includes generating an entity typing dataset with a large type set using distant supervision and crowdsourcing. For the CgER task, an approach was proposed to create a training dataset using bootstrapping and heuristics to classify Wikipedia articles into categories. However, scalability is limited by the need for manually annotated seed examples. The proposed heuristics limit entity and non-entity mentions, focusing on capitalization for entity mentions. Previous work like BID1 and BID9 combined NDS with heuristics for CgER, but our work focuses on FgER. Our HAnDS framework designs data-driven heuristics for diverse entity types with good annotation quality. Automatic dataset construction introduces noise, dependent on the task. In the context of Fine-ET task, noise in false positives is dominant, while relation extraction task faces both false negatives and false positives. The analysis focuses on entity detection systems' performance in detecting diverse entity mentions. Two analyses were conducted: one on type coverage and the other on performance on manually annotated datasets. The Fine-ET type set is compared to CoNLL 2003 dataset for expansion of coarse-grained types. The analysis focused on the entity detection systems' performance in detecting diverse entity mentions. It compared the Fine-ET type set to the CoNLL 2003 dataset for expansion of coarse-grained types. Results showed that a percentage of types in FIGER and TypeNet hierarchies were not descendants of the CoNLL dataset's coarse types. These types span various domains like bio-medical, legal processes, and entertainment, highlighting the importance of detecting entity mentions of these types for knowledge base construction applications. Since 2003, entity recognition has advanced towards finer categorization and diverse domain capture. Evaluation of entity detection systems like Stanford CoreNLP BID15 and NER Tagger from BID11, along with a LSTM-CNN-CRF model from BID13 on FIGER and 1k-WFB-g corpora, showed lower recall compared to precision for the LSTM-CNN-CRF model trained on the FIGER dataset. The NDS approach generates positive-only annotations leading to large false negatives, resulting in lower recall compared to precision. Models trained on CoNLL dataset show more balanced performance. The 1k-WFB-g corpus has lower recall than the FIGER corpus due to its coverage of 117 entity types compared to 42 types in FIGER. This highlights the coverage issue mentioned in section 3.1. The evaluation set's balance covering a wide range of entity types affects the performance of models trained on the CoNLL dataset. The use of CoreNLP or models trained on CoNLL has limitations in detecting out-of-scope entities. The approach of automatically creating a training dataset for the FgER task is described in the next section. The HAnDS framework aims to improve precision and recall for learning models trained on generated datasets for the FgER task. It automatically creates a corpus of sentences with correctly detected entity mentions characterized into entity types based on a type hierarchy input. The framework requires a linked text corpus, a knowledge base, and a type hierarchy as inputs. The linked text corpus contains hyperlinked concepts, like Wikipedia, where anchor text is considered as potential entity mentions. The knowledge base captures concepts and their properties, with examples like Freebase and WikiData. A type hierarchy organizes entity types hierarchically, with various schemes proposed in literature. In this work, two hierarchies, FIGER and TypeNet, are used for entity type classification. The HAnDS framework aims to reduce errors in automatic corpora creation by categorizing hyperlinks as entity links or non-entity links. Entity links represent candidate entity mentions, and if the labels obtained by a knowledge base belong to T, the link is categorized as an entity link. This process helps reduce false positives in entity mentions. The HAnDS framework categorizes hyperlinks as entity links or non-entity links based on labels obtained from a knowledge base. Entity links represent candidate entity mentions, while non-entity links do not. Non-entity links are determined using corpus-level context criteria. The HAnDS framework categorizes hyperlinks as entity or non-entity links based on labels from a knowledge base. Non-entity links are determined using corpus-level context criteria, such as a confidence threshold with lowercase anchor text. Referential links are those with anchor text matching allowed candidate names for the linked concept. After categorization of links, non-referential links like Bill and Melinda Gates are unlinked to reduce entity detection errors. Unlinked text spans may refer to other entities. The next stage aims to correctly re-link the unlinked tokens to reduce false negative entity mentions. Document-level context is used to restrict candidate links and link the correct referential name to the knowledge base node, reducing entity linking errors. To reduce false negative entity mentions, two trie trees are constructed to capture outgoing links and their referential names for each document. The first trie contains all links, while the second trie only contains links of entities predominantly expressed in lowercase phrases. Matching the longest prefix string within these tries helps link candidate entities in the document level context, reducing entity linking errors. The second trie is used to link candidate entities in unlinked phrases, reducing entity detection errors. This process ensures accurate entity mentions, even with lowercase phrases. The objective is to further reduce entity detection errors caused by incomplete knowledge bases. In stage-II, there is a possibility of entity detection errors, including false positives and false negatives. To reduce errors, sentences are selected based on context using POS tags and frequent sentence starting words. Only sentences where unlinked tokens are likely non-entity mentions are chosen, except for specific cases. In the second stage, sentences are selected based on context using POS tags and frequent sentence starting words to reduce entity detection errors. Only sentences with unlinked tokens likely non-entity mentions are chosen. Around 40% of sentences are selected in this stage, improving model recall significantly. The dataset WikiFbF was generated using the HAnDS framework, containing around 38 million entries. The HAnDS framework utilizes the FIGER hierarchy and WikiFbT dataset, containing millions of entity mentions annotated with various types. The intrinsic evaluation focuses on frequent words and POS tags least likely to be entities. Additional analysis can be found in the supplementary material. The HAnDS framework, available at https://github.com/abhipec/HAnDS, was evaluated quantitatively using the NDS approach for dataset generation. The results showed that HAnDS generated 1.9 times more entity mention annotations and 1.6 times more entities for the WikiFbT corpus compared to the NDS approach. This analysis was presented in Table 3. In Section 5.2.4, despite 1.6 to 1.9 times more new annotations, the NDS approach shows high linking precision. Over 95% of entity mentions generated by NDS are also present in the HAnDS framework, indicating high-quality existing links in Wikipedia. The remaining 5% were false positives removed by HAnDS. Extrinsic evaluation of learning models trained on HAnDS datasets was performed for WikiFbF dataset and its variants. The FgER task is divided into Fine-ED, a sequence labeling problem, and Fine-ET, a multi-label classification problem. The FgER model combines a Fine-ED model with a Fine-ET model. State-of-the-art models are used for each subtask, with details available in the respective papers. Hyperparameters and training procedures can be found in the supplementary material. The models are trained on Wiki-FbF and Wiki-FbF-w/o-III datasets created by the HAnDS framework. The datasets Wiki-FbF, Wiki-FbF-w/o-III, Wiki-NDS, and FIGER were used for model training, with two million sentences randomly sampled for computational constraints. Models were trained on these datasets to ensure bias reduction. Extrinsic evaluation experiments were conducted on these randomly sampled datasets, and the same dataset was used to train Fine-ED and Fine-ET learning models. The Fine-ED and Fine-ET learning models were evaluated on two datasets: FIGER, containing 563 entity mentions and 43 entity types, and 1k-WFB-g, containing 2420 entity mentions and 117 entity types. The datasets were constructed from Wikipedia text and have skewed type distributions. The statistics of the datasets used for the Fine-ED and Fine-ET tasks are available in Table 2. Various models have shown competitive performance for sequence labeling and multi-label classification problems. The entity detection models' performance on the FIGER and 1k-WFB-g datasets is presented in Table 4, with analysis on the effect of training datasets on model performance. The LSTM-CNN-CRF model trained on WikiFbF dataset outperforms models trained on NDS datasets in terms of F1 score, precision, and recall. Models trained on NDS datasets have higher precision but lower recall, indicating more false negatives. The model trained on Wiki-FbF-w/o-III dataset falls between the performance of NDS and Wiki-FbF datasets, with significantly lower recall. The LSTM-CNN-CRF model trained on WikiFbF dataset outperforms models trained on NDS datasets in terms of F1 score, precision, and recall. Models trained on NDS datasets have higher precision but lower recall. Models trained on datasets generated using Wikipedia as a sentence source perform better on the 1k-WFB-g evaluation corpus compared to the FIGER evaluation corpus. This is due to the 1k-WFB-g dataset being sampled from Wikipedia, while the FIGER corpus is based on sentences from news and specialized magazines. The literature suggests that learning model performance decreases in cross-domain evaluation settings compared to same-domain evaluations. Models trained on the large Wikipedia text corpus can generalize to sentences from news and specialized magazines. The FIGER evaluation corpus with 43 types helps measure model generalizability, while the 1k-WFB-g corpus with 117 types measures performance across a wide range of entity types. Models trained on Wiki-FbF perform best on both evaluation corpora, indicating the usability of the generated corpus and framework. In the Fine-ET task, models trained on Wiki-NDS and Wiki-FbF datasets show similar performance, with a slight advantage for the latter in the micro-F1 metric on the 1k-WFB-g corpus. The HAnDS framework in stage-II demonstrates high linking precision, comparable to NDS. The bottleneck in the FgER task lies in Fine-ED due to a lack of quality entity boundary annotations for a wide range of entity types, which this work aims to address. In this work, the HAnDS framework is proposed to automatically construct quality training datasets for FgER tasks, moving towards recognizing entities from thousands of types. The constructed datasets are the largest available for entity recognition, backed by empirical experimentation to ensure quality. This opens up new research directions for sequence labeling approaches in entity recognition. The research explores sequence labeling approaches for FgER tasks with multiple entity types. Existing models for CgER cannot be directly applied due to the complexity of multi-label settings. Another focus is on noise-robust sequence labeling models to handle incorrect entity boundaries. The generated datasets are diverse in entity types from various domains like biomedical, finance, sports, and products. The dataset contains entities from various domains like biomedical, finance, sports, products, and entertainment. It is suitable for transfer learning in NER tasks with different writing styles than Wikipedia."
}