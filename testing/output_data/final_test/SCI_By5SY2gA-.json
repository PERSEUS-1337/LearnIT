{
    "title": "By5SY2gA-",
    "content": "Our work explores the use of affect lexica to enhance word representations learned from a corpus. By incorporating affect scores from Warriner's affect lexicon into the training process of Word2Vec and GloVe methods, we improve performance on tasks like word similarity detection and sentiment analysis. Our approach enhances word representations by incorporating affect scores from Warriner's affect lexicon into Word2Vec and GloVe training. This improves performance on tasks like word similarity detection, outlier detection, sentiment analysis, and predicting formality, frustration, and politeness in corporate communication. N-gram methods outperform more complex approaches in computational cost and accuracy, but struggle with limited corpus sizes. Recent work aims to enrich word embeddings with lexical knowledge for better performance on downstream tasks. Enriching word embeddings with affect scores from Warriner's affect lexicon improves performance on various tasks like sentiment analysis. Traditional word representation methods like Word2Vec and GloVe do not consider associated sentiments, leading to challenges in sentiment detection due to transitive and symmetric sentiment relationships between words. Enriching word embeddings with affect scores from Warriner's affect lexicon enhances word distributions for sentiment analysis tasks. This approach improves performance by incorporating affect-related information, allowing for more accurate capture of author or reader reactions. Additionally, using a small sentiment lexicon can automate word rating based on vector space representations, reducing time and cost while eliminating biases in annotations. The approach presented enhances word distributions by incorporating affect and reaction signals from hand-annotated affect lexica. It distinguishes between semantically similar words with varying affective interpretations and identifies words of opposite polarity through signed spectral clustering on pre-trained embeddings. The proposed method builds on the intuition that relationships between synonyms and antonyms can be leveraged to build affect-enriched word representations. The proposed approach enhances word distributions by incorporating affect signals from affect lexica. It captures relationships between synonyms and antonyms using semantic dictionaries to improve word embeddings. The method outperforms state-of-the-art in sentiment prediction and formal language tasks. Key contributions include incorporating affect sensors in training loss functions and demonstrating the utility of affect-enriched word embeddings for linguistic tasks. The method improves accuracy for outlier detection by 20% compared to state-of-the-art. A workflow is introduced to incorporate affective and reaction signals into word representations during pre-training. Experiments are conducted on Word2Vec-CBOW, Word2Vec-SkipGram, and GloVe embeddings. Prior art in pre-training and post-training approaches for word representations is discussed, along with detailed experiments. Research has explored refining embeddings for tasks like dependency parsing and sentiment analysis using external resources. Our approach focuses on improving word embeddings by jointly learning from a corpus and an affect lexica, defining a new basis for word representation. It explores syntactic, semantic, and morphological knowledge to provide additional information, using a binary indicator function to define relations. BID32 propose a Relation Constrained Model (RCM) for predicting related words, combining objectives from CBOW and RCM for joint learning. Our approach, similar to BID15 and BID31, involves joint learning using specialized word embeddings and incorporating external knowledge into the word distributions. We use additional context words from an affect lexica with a modified loss function, similar to the \"Categorical Knowledge Powered model\" proposed by BID31. The loss function in our approach is similar to the one in \"Categorical Knowledge Powered model\" by BID31, with a focus on similarity scores. BID3 also uses a similar approach to include various relations like synonyms, antonyms, and hyponyms. Post-training methods in BID8 and BID22 refine input embeddings using relational information from semantic lexica. Incorporating an affect lexica into learning word embeddings involves a three-step approach. Step 1 focuses on identifying synonyms and antonyms using WordNet definitions to capture the relationship strength between words in the lexica. For example, in Warriner's affect lexicon, 'confident' and 'funny' have similar valence scores. Incorporating an affect lexica into learning word embeddings involves a three-step approach. Step 1 focuses on identifying synonyms and antonyms using WordNet definitions to capture the relationship strength between words in the lexica. For example, in Warriner's affect lexicon, 'confident' and 'funny' have similar valence scores. While they do not share a semantic relationship, a strength value is defined for all possible word pairs based on their affect scores. This strength models the difference in affect scores, with positive strength for words with scores of the same sign and negative strength for words with opposite signs. The approach is described in Algorithm 1. Step 3: Loss function definition - A new loss function is introduced for embedding training, building on Word2Vec and GloVe techniques. SkipGram predicts context of input word, with loss function defined as per Rong (2014). Incorporates negative sampling and unigram distribution for sampling. Affect lexica information is integrated. The sampling method used for experiments incorporates affect lexica information through a modified loss function. The loss function is defined based on the input word's relation strength in the affect lexica, resulting in a specific loss only when a word from the affect lexica is present. This modification affects the derivative of the output vector, leading to updated weight equations. The model in CBOW predicts a word given a context window, with the hidden layer output defined as a combination of input word vectors. The loss function incorporates affect lexica information, affecting the derivative of the output vector and leading to updated weight equations. The GloVe BID23 Loss Function is a weighted regularized version of the original GloVe objective that uses global co-occurrences over the entire corpus. It involves extracting the vocabulary, building a cooccurrence matrix, and defining bias terms, target vectors, context vectors, and a weighting function. Additionally, a regularization term is defined based on a strength function. The GloVe BID23 Loss Function is a weighted regularized version of the original GloVe objective that uses global co-occurrences over the entire corpus. It involves extracting the vocabulary, building a cooccurrence matrix, and defining bias terms, target vectors, context vectors, and a weighting function. Additionally, a regularization term is defined based on a strength function. The final objective is obtained using a binary function instead of a strength function, with t-SNE visualization showing the affect lexicon valence of words like 'accept', 'reject', and 'refuse'. The model enhances word embeddings by incorporating valence information, grouping similar sentiments together and separating opposite sentiments. Experiments are conducted to assess the impact on word embeddings' quality and model performance. The ukWaC corpus is used for building embeddings, resulting in 2.2 billion tokens and a vocabulary of 569,574 words. The experiment involved using a corpus with 2.2 billion tokens and a vocabulary of 569,574 words. The optimal \u03bb value for the highest similarity score was found to be 2. Different settings were tested, with a window size of 10 and word embedding dimensions of 300. Word2Vec utilized negative sampling of 15 words, while GloVe ran for 5 iterations. Performance comparisons were made between Word2Vec skipgram, Word2Vec CBOW, and GloVe models. The experiment involved testing different settings with \u03bb values, including incorporating valence, arousal, and dominance scores to the corpus. Comparison was made against the state of the art approach by BID3, which improved word similarity and analogy prediction. The experiment involved training on the ukWaC corpus with specific parameter settings. Results were compared against a post-training baseline by concatenating word-vectors with VAD-vectors. Normalization and standardization processes were applied to the embeddings. The experiment involved training on the ukWaC corpus with specific parameter settings and comparing results against a post-training baseline. Normalization and standardization processes were applied to the embeddings, which captured affect properties of words using data from Warriner's affect lexicon. The method was evaluated on tasks such as predicting word similarity and detecting outliers in semantic clusters. The study involved training on the ukWaC corpus with specific parameters and comparing results against a post-training baseline. The method was evaluated on tasks such as predicting word similarity and detecting outliers in semantic clusters on benchmark datasets. The new dataset introduced a task for formality, frustration, and politeness detection in a labeled email corpus. Seven benchmark datasets were considered for word similarity prediction. Our model's performance was evaluated on word similarity prediction tasks using benchmark datasets. Results showed improvements for GloVe and word2vec CBOW embeddings, with the word2vec skipgram approach performing the poorest. Our approach also outperformed the state of the art method by BID3 on word similarity for two datasets. The absence of \"opposite\" words in the benchmark datasets may have affected the results. Our approach showed a 5% performance improvement over BID3 for outlier prediction tasks. Word similarity tasks are commonly used to evaluate semantic coherence in vector space models, but suffer from low agreement scores. Results on outlier detection task BID6 with 8 topics and clusters are summarized in TAB1. Further details on the dataset and evaluation metrics can be found in BID6. Our approach incorporates affect information in word embeddings, leading to improved performance on tasks such as outlier detection and sentiment prediction. We use Valence, Arousal, and Dominance scores to enhance the models, which outperform the state of the art on sentiment detection tasks. The evaluation is done on the Stanford Sentiment Treebank dataset using a Deep Averaging Network model. Our approach incorporates affect information in word embeddings, leading to improved performance on sentiment prediction tasks. The model outperforms the state of the art approach on sentiment prediction, with significant improvements in accuracy values for both fine and binary classification settings. The strength function used in our approach specifies the relation between words and provides signed strength associated with it. Additionally, the quality of the embeddings is evaluated on an affect prediction task using a new dataset of 980 emails from the ENRON dataset. The study utilizes a CNN regression model to predict formality, frustration, and politeness in emails based on obtained embeddings. Results show improvements over SkipGram baseline with low standard deviations in MSE values. The proposed approaches show reasonable improvements in task-based evaluations, with SkipGram methods performing poorly in word similarity prediction but well in sentiment and affect prediction. Performance differences in downstream tasks have been discussed in previous studies, highlighting issues with word similarity evaluations. The Appendix section examines corpus size's impact on performance. Performance on affect prediction task is measured in terms of Mean Square Error values and compared with prior work. The results suggest that different embeddings perform well for different tasks. In word similarity tasks, the +V model performs well in GloVe setting but the +A model seems to perform the best for CBOW. Similar results are observed in sentiment prediction: for binary sentiment prediction, arousal scores give the best performance with CBOW embeddings but dominance and valence give the best performance with skip-gram and GloVe embeddings respectively. This suggests that an ensemble implementation considering all inputs could be the most flexible method. The affect lexica used is relatively small compared to the vocabulary of the corpus. The affect lexica used is relatively small compared to the vocabulary of the corpus. Further analysis is planned to improve word embeddings and expand the affect lexica. Words can have different affect in various contexts due to polysemy, which poses challenges for word-level embedding models. The proposed approach aims to enhance single vector embeddings for NLP tasks by incorporating affect information. The approach is evaluated on sentiment prediction and tone analysis tasks, showing improved performance compared to traditional word embeddings. The study compares word embeddings with affect-sensitive embeddings on sentiment prediction tasks. Three models are analyzed: GloVe baseline, GloVe + Valence, and GloVe + synonyms BID3. Results show that affect-sensitive words improve sentiment prediction accuracy, while absence of such words leads to poor predictions. Our approach outperforms baseline models and BID3 in sentiment prediction by capturing affect words like \"dreadful\" not present in synonym word pairs. This leads to improved embeddings for key words like 'dreadful', 'gem', and 'hate', resulting in better predictions. The presence or absence of affect words in the lexicon significantly impacts model performance. The work proposes methods to incorporate affect lexicon information into Word2Vec and GloVe training processes, improving embeddings for words present in the lexicon. By identifying semantically related word pairs using WordNet and affect scores, the training objectives are modified to incorporate this information. Evaluation shows improvements over baselines on Word Similarity benchmarks and Outlier Detection tasks. The study focuses on incorporating affect lexicon information into Word2Vec and GloVe training processes to enhance word embeddings. Evaluation demonstrates improved performance in predicting sentiment, formality, frustration, and politeness in emails. The process involves selecting an appropriate value for the hyper-parameter \u03bb by training a Word2Vec SkipGram model on a 100MB sample of ukWaC corpus. The study evaluates the performance of Word2Vec Skipgram by comparing results on the Rubenstein-Goodenough dataset using different \u03bb values. \u03bb = 2.0 performs the best, so it is fixed for all experiments. An error analysis shows that affective information has a negative impact on smaller corpora sizes but minor improvements on larger sizes. Preprocessing the corpus better may help with these findings."
}