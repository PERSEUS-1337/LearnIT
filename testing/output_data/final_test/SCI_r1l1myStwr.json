{
    "title": "r1l1myStwr",
    "content": "Meta-learning is applied to settings where task segmentation is unavailable, such as continual online learning with a time-varying task. The approach, called meta-learning via online changepoint analysis (MOCA), combines a meta-learning algorithm with a Bayesian changepoint detection scheme to train and test directly on time series data without segmenting it into discrete tasks. Meta-learning methods have shown promise for few-shot learning in various domains. These algorithms leverage offline meta-training on a distribution of tasks to optimize learning performance on new tasks. However, there are applications where task segmentation is unavailable, which has been under-addressed in the meta-learning literature. In this work, the focus is on enabling meta-learning in task-unsegmented settings, where the latent task undergoes discrete, unobserved switches in time series data. This approach aims to address the challenge of adapting to changing environments without the need for pre-segmented meta-datasets. The primary contribution of this work is an algorithmic framework for task unsegmented meta-learning called meta-learning via online changepoint analysis (MOCA). MOCA integrates a Bayesian changepoint estimation scheme with existing meta-learning approaches, allowing algorithms to reason about task changes in time series data. This enables standard meta-learning algorithms to be trained and tested directly on time series data without the need for task segmentation. By backpropagating through the changepoint estimation framework, MOCA learns a rapidly adaptive predictive model. MOCA is a framework for task unsegmented meta-learning that integrates a Bayesian changepoint estimation scheme with existing meta-learning approaches. It learns a rapidly adaptive predictive model and can be applied to regression and classification settings with unobserved task switches. The goal is to improve predictions by learning from labeled examples drawn from a distribution according to some latent task. The framework MOCA integrates a Bayesian changepoint estimation scheme with meta-learning approaches to improve predictions by learning from labeled examples drawn from a distribution according to some latent task. The goal is to optimize a learning agent to perform well in a setting where tasks are re-sampled with a hazard rate. The agent's prediction for y_t is evaluated through a negative log likelihood loss, and the objective is to optimize \u03b8 using a representative time series in an offline, meta-training phase. In contrast to standard meta-learning, this approach does not assume task segmentation or pre-grouping of data by latent parameter T. It focuses on individual data points provided sequentially, rather than the common \"k-shot, n-way\" problem setting in few-shot learning. The goal is to optimize few-shot learning performance over a distribution of tasks, rather than just a single task. Meta-learning involves training a model on a distribution of tasks to generalize its performance. The method includes meta-training and online adaptation phases, where parameters \u03b8 are learned. During online adaptation, the model uses context data from a task to compute statistics, such as neural network weights or hidden states. The model in meta-learning uses context data to define a conditional distribution for predictions. The performance is evaluated by comparing the posterior predictive distribution with the true data distribution using dissimilarity measures like KL divergence. Parameters are optimized through differentiable operations for stochastic gradient descent. To enable meta-learning without task segmentation, the approach extends prior work in changepoint detection using Bayesian online changepoint detection. This method detects task switches without relying on pre-segmented data groups, allowing for more flexible and continuous learning. In a streaming unconditional density estimation context, Bayesian online changepoint detection maintains a belief distribution over run lengths to detect task switches without pre-segmented data groups. The belief distribution at time t, denoted as b t (r t ), helps reason about the overall posterior predictive by marginalizing over the run length r t according to b t (r t ). In this work, the approach extends Bayesian online changepoint detection to apply to meta-learning models in the conditional density estimation setting. The method recursively computes posterior predictive densities for each run length and updates the belief distribution. This enables the application of meta-learning algorithms without task segmentation, both during training and testing. The algorithm leverages a base meta-learning algorithm with parameters to perform Bayesian filtering for run length estimation in the joint density estimation setting. The method extends Bayesian online changepoint detection to meta-learning models for conditional density estimation. It computes posterior predictive densities for run lengths and updates belief distribution, allowing meta-learning without task segmentation during training and testing. The algorithm uses a base meta-learning algorithm with parameters for Bayesian filtering in joint density estimation. The algorithm extends Bayesian online changepoint detection to meta-learning models for conditional density estimation. It updates belief distribution based on posterior predictive densities for run lengths, allowing meta-learning without task segmentation during training and testing. The update rules are derived by considering the joint density and the base meta-learning algorithm's posterior predictive density over inputs. The algorithm extends Bayesian online changepoint detection to meta-learning models for conditional density estimation, updating belief distribution based on posterior predictive densities for run lengths. Generative models are favored in MOCA for classification tasks, while regression assumes independence of the input variable. Beliefs over run lengths are factored upon observing data, with normalization computed over the support of run lengths. Propagating beliefs forward in time relies on the assumption of task independence in the data generation process. The algorithm extends Bayesian online changepoint detection to meta-learning models for conditional density estimation, updating belief distribution based on posterior predictive densities for run lengths. MOCA avoids hard assignments of changepoints and performs a soft selection over run lengths, allowing for backpropagation through changepoint detection to optimize the underlying predictive model. The algorithm extends Bayesian online changepoint detection to meta-learning models for conditional density estimation, updating belief distribution based on posterior predictive densities for run lengths. At each timestep, observations are used to update beliefs and make probabilistic predictions for labels, with corresponding negative log likelihood losses incurred. This process allows for the optimization of the underlying predictive model through soft selection over run lengths. The algorithm updates belief distribution based on posterior predictive densities for run lengths, allowing for efficient computation using recursive update rules. This approach reduces complexity compared to non-recursive methods, enabling optimization of the predictive model through soft selection over run lengths. The algorithm updates belief distribution based on posterior predictive densities for run lengths, allowing for efficient computation using recursive update rules. This approach reduces complexity compared to non-recursive methods, enabling optimization of the predictive model through soft selection over run lengths. The training procedure involves processing time-series data with task switches, summing NLL losses, and using backpropagation to optimize parameters. Shorter time-series are sampled for computational ease, and user input on task segmentation can be incorporated by updating belief distributions. MOCA can be used with any meta-learning model that has a probabilistic interpretation. Practical considerations in choosing meta-learning algorithms can impact computational efficiency and performance. Two meta-learning algorithms used in experiments are ALPaCA for regression and PCOC for classification, both offering Bayesian learning interpretation and efficient likelihood evaluation. ALPaCA is a meta-learning approach using Bayesian linear regression in a learned feature space. It maintains a matrix-normal distribution over K, resulting in a Gaussian posterior predictive density. The prior for K is fixed as K \u223c MN (K 0 , \u03a3 , \u039b \u22121 0 ). ALPaCA is a meta-learning model that uses Bayesian linear regression in a learned feature space. It updates the posterior recursively and meta-learns the prior statistics, feature network weights, and noise covariance. It focuses on modeling the conditional density p(y | x) and can be adapted for classification through Gaussian discriminant analysis in a learned feature space. This approach is termed probabilistic clustering for online meta-learning. In PCOC, a novel approach to metalearning for classification is introduced. It involves processing labeled input/class pairs through an embedding network and Bayesian density estimation for each class. The algorithm updates its beliefs over Gaussian mean and class probabilities based on labeled context data. Posterior computations are done through closed form recursive updates. PCOC performs Bayesian Gaussian discriminant analysis for online classification and meta-learns parameters for efficiency. Posterior predictive density in the embedding space is computed using posterior parameters. Generative modeling approach allows computing p(z t+1 | \u03b7 t ) by marginalizing out y.likelihood within MOCA updates run length belief before predicting \u0177 t. PCOC is a Bayesian approach for online classification, similar to prototypical networks. It relates to online, continual, and lifelong learning, where re-using information from previous tasks is important. Continual learning assumes task segmentation, while online learning does not. MOCA is a method for avoiding forgetting in continual learning by rapidly adapting to new tasks. Aljundi et al. (2019) focus on learning a single set of parameters for all tasks, while MOCA operates in the meta-learning setting to learn task weights that are quickly adaptive. Meta-learning aims to accelerate online adaptation within a task by learning parameters quickly. This approach addresses the challenge of large learning models being slow to adapt to new tasks due to overfitting. Applying ideas from meta-learning to continual learning enables rapid adaptation to new tasks, with models like MAML serving as regularization methods for fast adaptation. In the streaming data setting, a sliding window approach is used to utilize recent data efficiently. MOCA is an adaptive sliding window model that infers the optimal window length. Other models aim to detect task changes but are less expressive and require pre-training with a segmented meta-dataset. The work by Fearnhead & Liu (2007) and others has led to significant advancements in algorithms for computing closed-form posteriors. Various modifications and extensions have been developed, including empirical Bayes methods for predictive models. Turner et al. (2009) have also explored hyperparameter optimization using general-purpose gradients in the BOCPD model. We use neural network meta-learning models with automatic differentiation for gradient computation to evaluate MOCA in regression and classification settings. The study compares MOCA's performance to an \"oracle\" model with exact task segmentation and baseline sliding window models of various lengths. These baselines are effective for meta-learning in time-varying data streams. The study compares MOCA's performance in regression and classification settings to an \"oracle\" model with exact task segmentation and baseline sliding window models of various lengths. The baseline model only learns a prior and does not adapt online, making it a valuable point of comparison for standard supervised learning approaches. Additionally, the effects of task-segmentation information at train-time and test-time are investigated, with a focus on the impact of test time segmentation. At test time, MOCA's run length estimation replaces task segmentation. The study compares MOCA's performance with and without test-time segmentation. Train-time segmentation's impact is also analyzed. Performance is evaluated under partial task segmentation. Confidence intervals are provided for different models in various experiments. MOCA's performance in regression is investigated on a switching sinusoid problem. MOCA demonstrates accurate and rapid task change identification with only a few data points. It outperforms baselines in sinusoid regression, Rainbow MNIST, and miniImageNet tasks. Sliding window methods show degraded performance compared to MOCA. MOCA achieves high performance in various problem domains, outperforming sliding window approaches. Task segmentation at test time improves performance, especially as hazard rate increases. However, MOCA's regression version struggles with detecting changepoints, leading to significant loss for high changepoints. MOCA training outperforms oracle supervision in detecting changepoints, showing a curriculum effect. Applying MOCA to the Rainbow MNIST dataset improves classification performance. MOCA performs well on the Rainbow MNIST dataset by detecting task changes through digit color variations. Performance degradation is mainly attributed to MOCA training rather than testing. MOCA performs comparably to the oracle model on the miniImageNet benchmark task, which consists of 100 ImageNet categories with 600 RGB images each. The dataset is split into five super-classes for five-way classification. Each new task involves sampling a new class within each super-class. The new task involves sampling a new class within each super-class for image classification. MOCA outperforms baselines for all hazard rates, showing a performance decrease from oracle to MOCA at test time due to MOCA training. This trend is also observed in the Rainbow MNIST experiments. Future Work: MOCA has shown promising results in addressing continual learning problems, but there is a need to formulate it as an online learning algorithm. This would involve updating parameters continuously without a train/test distinction, which may be challenging due to the need for a running buffer of all data observed so far. This could be costly in real-world scenarios with large volumes of data, such as high definition video from multiple cameras on an autonomous vehicle. Extending MOCA towards online training or maintaining an efficient replay buffer is a potential direction for future research. Moving beyond the assumption of i.i.d. tasks to tasks with associated dynamics is a promising direction for future work in improving data efficiency and re-using knowledge from previous tasks. MOCA enables existing meta-learning algorithms to handle problems without task segmentation, like continual learning, by using a Bayesian perspective and changepoint detection. Performance remains similar to standard meta-learning with task segmentation, even with a low hazard rate. In practice, batches of length T are sampled from the training time series to reduce computational burden. Pruning methods within BOCPD must maintain model differentiability. At test-time, differentiability is not required, allowing for the application of previously developed pruning methods. In practice, batches of length T are sampled from the training time series to reduce computational burden. Differentiability is not required at test-time, allowing for the application of previously developed pruning methods. Empirically, diminishing marginal returns are observed when training on longer sequences. Performance of MOCA improves with larger T values, but beyond T = 100, there is little performance improvement. Longer training sequences increase computation per iteration and memory burden, so it is best to train on the shortest possible sequences. PCOC is a framework for Bayesian meta-learning for classification that extends embedding-based meta-learning algorithms. It maps data points through an embedding function and assumes a generative model within the embedding space. Each class is sampled from a task-dependent categorical distribution with class probabilities. The text discusses a classification strategy based on Gaussian discriminant analysis within a Categorical-Gaussian generative model. It involves fixing priors on class probabilities and class conditional means, computing parameters, evaluating data probabilities, and updating network weights based on maximum likelihood. The text discusses updating network weights and prior terms based on maximum likelihood within a Categorical-Gaussian generative model. Posterior distributions on q and z j remain Dirichlet and Gaussian, with posterior parameters computed analytically. Posterior predictive distribution for class j is Gaussian, and the posterior predictive over classes is tractable due to a finite number of classes. Posterior Dirichlet probabilities are computed recursively. The text discusses meta-learning Dirichlet priors for class probabilities in a general meta-classification setting. It allows for online estimation of class probabilities within tasks and meta-learning beliefs over label probabilities between tasks. The approach also encodes confidence in class probabilities based on the Dirichlet priors. In a meta-classification setting, benchmarks are structured as k-shot and n-way tasks. The PCOC model simplifies by using a shared prior for all classes instead of individual priors. This approach is beneficial for scenarios where the number of classes is unknown and data is provided sequentially. In a meta-classification setting, benchmarks are structured as k-shot and n-way tasks. The PCOC model simplifies by using a shared prior for all classes instead of individual priors. This approach is beneficial for scenarios where the number of classes is unknown and data is provided sequentially. To enhance the model for a streaming setting, replacing the Dirichlet prior with a Chinese restaurant process would allow for a few-shot meta-classification model with an expandable number of classes. This modification also provides better calibrated confidence in outputs, which is useful for downstream tasks. The streaming meta-classification algorithm must be able to predict when a class is previously unseen, whether the set of labels is known a priori or not. In a meta-classification setting, the PCOC model allows for \"zero-shot\" classification and extends prototypical networks. It maps context data to an embedding space and computes centroids for each class. The algorithm models the probability of belonging to each class based on distances. The second case involves expanding the set of labels over time using a non-parametric model. This problem statement is akin to a \"lifelong learning\" setting, which will be addressed in future work. The PCOC model in a meta-classification setting maps data to an embedding space and computes class centroids. It models class probability using softmax of distances, focusing on Euclidean distances. Ren et al. (2018) propose adding a class-dependent length scale for variance estimation, assuming a scaled identity matrix form. Diagonality of the covariance matrix improves performance by simplifying matrix operations. In contrast to previous work, PCOC in a meta-classification setting uses diagonal covariances for computational efficiency and online estimation of class probabilities via Dirichlet posterior inference. The approach is explicitly Bayesian with priors over estimated parameters critical for utilization in the MOCA framework, enabling \"zero-shot\" learning. The James-Stein estimator, paired with empirical Bayesian estimation of the prior, is effective in Bayesian meta-learning approaches like ALPaCA and PCOC. Each column represents a trained model, showing varying performance across different training supervision rates. The priors in the MOCA framework enable zero-shot learning and better estimation of task changes as data is observed. MOCA reasons about a belief over run-lengths, allowing for a spectrum of task segmentation. Users can override beliefs at changepoints to provide supervision, effectively revealing information to the meta-learning algorithm. MOCA allows users to provide supervision at changepoints to the meta-learning algorithm, enabling the detection of further unknown changepoints. The Bayesian framework accommodates various types of task supervision. Performance of partial task segmentation is shown for the sinusoid problem with a hazard rate of 0.2, where a supervision rate is assigned to labeled changepoints. The performance of models trained with MOCA improves with increasing train supervision rate, but remains largely unchanged with varying train supervision. Results show that training with MOCA leads to comparable test performance as models with supervised changepoints, indicating little additional value to task segmentation during training. Computational performance at test time on the sinusoid problem shows a linear trend in the curve. The execution time for one iteration on an Nvidia Titan Xp GPU is approximately 7ms, with a linear trend on the right side of the curve. The time per iteration remains constant on the left side until around 4500 iterations, likely due to overhead in matrix multiplication computations. The experiments did not involve hypothesis pruning, suggesting potential constant time performance at test time. The figure displays 95% confidence intervals for 10 trials, but the repeatability of computation time is consistent. The MOCA framework combined with ALPaCA was tested for performance in a switching sinusoid regression problem, a standard benchmark in metalearning. Tasks involved randomly sampled phase and amplitude with varying hazard rates. The Rainbow MNIST dataset was used, split into tasks with different color/scale/rotation transformations of the MNIST dataset. After splitting the Rainbow MNIST dataset into train and test sets of transformations, hyperparameter optimization was done on the train set. Training on all 49 tasks after setting hyperparameters notably improved performance. The same approach was used in a previous study. The miniImageNet dataset was used as a benchmark in few-shot learning, where the goal is to associate test data with context data. This problem setting is considered implausible for continual learning. In the continual learning setting, the problem of inferring possible labels while observing a data stream is addressed by assuming a known set of classes. The 100 classes of miniImageNet are grouped into five super-classes with varying intra-class diversity. Generalization from the train set to the test set is challenging due to weak intra-class similarities, necessitating few-shot learning. The super-classes are detailed in a table and are roughly balanced in terms of number. The super-classes in the miniImageNet dataset are balanced in terms of the number of classes they contain. Each task involves sampling a class from each super-class with equal probability. Three baselines were used: Train on Everything, Oracle, and others. The Oracle baseline outperforms the best achievable performance in this problem setting. The sliding window approach is commonly used in problems with time variation, using the last n data points for conditioning. MOCA performs adaptive windowing and is compared to fixed window lengths of n = 5, 10, 50. A feedforward network with two hidden layers of 128 units was used for the experiment. The experiment used a feedforward network with two hidden layers of 128 units, followed by a 32 units layer with tanh nonlinearity. The output layer was of size 32\u00d71. The same architecture was used for all baselines, with parameters including Adam optimizer, learning rate of 0.02, batch size of 50, batch length of 100, and 7500 train iterations. Longer batch lengths were used for better performance on low hazard rates, and the learning rate was decayed every 1000 training iterations. In the experiment, a feedforward network with two hidden layers of 128 units was used. The learning rate was decayed every 1000 training iterations. The noise variance was allowed to be learned by the model, resulting in improved performance. The architecture used in the experiment provides a fair comparison to previous few-shot learning work. The architecture used in the experiment consists of four blocks of 64 3 \u00d7 3 convolution filters, followed by batchnorm, ReLU nonlinearity, and max pool. The encoder leads to a 64-dimensional embedding space for the Rainbow MNIST dataset. A diagonal covariance factorization within PCOC was used to reduce the number of terms in the covariance matrix and improve model performance. Prior mean, variance, and noise covariance were learned for each class. Dirichlet priors were fixed to be large. For training, the model used Adam optimizer with a learning rate of 0.02, batch size of 10, and batch length of 100 for 5000 iterations. The learning rate was decayed every 1500 iterations. For miniImageNet, six convolution blocks were used to create a 64-dimensional embedding space. Initially, a four-conv backbone was attempted but resulted in a 1600-dimensional space with high memory requirements. The \"train on everything\" baseline used the same architectures with one fully connected layer and softmax, with Adam optimizer, learning rate of 0.002, batch size of 10, and batch length of 100. TEST DETAILS: A test horizon of 400 was used for all problems to avoid artificial distortion of the test hazard rate. A batch of 200 evaluations was performed for both problems, with confidence intervals at 95%."
}