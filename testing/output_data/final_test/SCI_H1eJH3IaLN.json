{
    "title": "H1eJH3IaLN",
    "content": "Network embedding (NE) methods learn low-dimensional representations of network nodes for downstream prediction tasks, with link prediction being a popular evaluation metric. This paper introduces EvalNE, an evaluation framework for assessing NE methods on link prediction tasks, addressing issues with reproducibility and evaluation pipeline design. EvalNE automates tasks like hyper-parameter tuning, model validation, edge sampling, and computation of edge embeddings, providing a transparent and efficient evaluation process. The EvalNE framework facilitates edge sampling, computation of edge embeddings, and model validation for evaluating embedding methods in link prediction tasks. It is available as a Python toolbox and enables easy replication and analysis of experimental sections from influential papers. Link prediction is crucial in various fields, and many NE methods have shown promising results in solving this task by mapping nodes to vectors in IR d. The evaluation of node embedding (NE) methods for link prediction is challenging due to variations in experimental setups and evaluation procedures. Evaluating the performance of NE methods for link prediction involves design choices that can confound results and lead to errors, such as train-test splitting of graphs and predicting missing edges accurately. To evaluate the performance of node embedding methods for link prediction, researchers need incomplete training graphs and more complete versions for testing. Using snapshots of the network at different time points is crucial for fair evaluation, but the availability of such data is rare. Therefore, authors often sample sets of edges from input graphs for training and use the remaining edges for testing. Researchers sample sub-graphs for training different node embedding methods, with varying train-test split sizes. In addition to positive train and test edges, negative edges are also sometimes used for training classifiers. Different strategies are used to select non-edges for training. Most node embedding methods only provide node embeddings, requiring additional steps to predict edges. Most node embedding methods only offer node embeddings, necessitating the derivation of edge embeddings for predictions. Various approaches for deriving edge embeddings significantly impact method performance. Evaluation metrics vary from AUC-ROC to precision-recall to precision@k. Recent literature commonly uses default settings for existing methods and tunes hyperparameters for new methods, potentially leading to biased results. No gold standard exists for selecting the best approach due to the multitude of valid choices and parameter values. EvalNE is a framework that simplifies the evaluation process for node embedding methods in link prediction by automating tasks such as hyper-parameter tuning, edge and non-edge sampling, and evaluating scalability and accuracy. It implements guidelines from research, includes efficient sampling algorithms, and evaluates methods based on fixed-threshold metrics and threshold curves. EvalNE simplifies the evaluation process for node embedding methods in link prediction by allowing the evaluation of multiple methods on various networks in a single operation. It ensures reproducibility and comparability of results, facilitating a better understanding of the strengths and weaknesses of existing methods. The paper discusses related work, presents the evaluation framework with a novel edge sampling strategy, reports empirical results, and concludes with the availability of the open-source toolbox. The evaluation of link prediction in network representation learning has been extensively studied in various works. Different train set sampling strategies, negative sampling, and fair evaluation criteria have been explored. Link prediction was first introduced as an evaluation metric for NE algorithms in a pioneering work. A survey emphasizes the importance of link prediction as an application of network representation learning and highlights inconsistencies in the evaluation of different NE approaches. An empirical analysis of these methods on various datasets was conducted. The evaluation of network representation learning methods includes end-to-end prediction, edge embedding, and node embedding methods, focusing on vertex classification and clustering. Two frameworks, OpenNE and GEM, are available for evaluating network embedding methods, with implementations of state-of-the-art embedding methods. These frameworks primarily focus on implementing embedding methods rather than the evaluation pipeline. EvalNE is a framework designed as a pipeline of interconnected building blocks for evaluating node embeddings, edge embeddings, and similarity scores. It simplifies code maintenance, allows for flexible model evaluation, and includes core building blocks such as data split and model evaluation. The EvalNE framework is a pipeline for evaluating node and edge embeddings, including data manipulation, preprocessing, and learning edge embeddings from node embeddings. It provides functions for loading, storing, and manipulating networks, such as pruning nodes based on degree and removing self-loops. The EvalNE framework offers functions for data manipulation and preprocessing of networks, including pruning nodes, removing self-loops, and obtaining common network statistics. To perform link prediction, sets of train and test edges are needed, with the training edges forming a connected graph to ensure accurate embeddings. The EvalNE framework provides functions for network data manipulation and preprocessing. It includes a novel algorithm for train-test splits, ensuring a connected training graph. The algorithm involves obtaining a uniform spanning tree of the graph and initializing the set of training edges. The algorithm involves obtaining a uniform spanning tree of the graph and initializing the set of training edges. Random edges are added to the training set, and the complexity of the process is O(n log n). An equivalent undirected version of the graph is constructed for efficient edge addition. The proposed method involves creating a weakly connected train graph from the initial directed graph G \u21e4 by adding train and test edges, as well as train and test non-edges for link prediction evaluation. The toolbox can generate non-edges based on either the open world or closed world assumption, with differences in how train non-edges are selected. The LP heuristics in EvalNE use a train graph with user-defined parameters for link prediction. Common heuristics include CN, JC, AA, RA, PA, and Katz, with a random prediction model for reference. The train set size should be between 50% and 90% of total edges for optimal results. The LP heuristics in EvalNE use a train graph with user-defined parameters for link prediction, including CN, JC, AA, RA, PA, and Katz. Additional steps are required for NE methods to perform link predictions via binary classification, involving learning edge embeddings through a binary operator applied to node embeddings. The proposed framework in EvalNE includes alternatives for operators like average, hadamard, weighted L 1, and weighted L 2 for node embeddings. Logistic regression is commonly used for link prediction in NE methods, but other binary classifiers can be easily integrated. The framework evaluates scalability, parameter sensitivity, and accuracy of embedding methods, measuring wall clock time for scalability and allowing reporting for different hyperparameter values. The EvalNE framework provides link prediction accuracy using fixed-threshold metrics and threshold curves. It includes various evaluation metrics such as confusion matrix, precision, recall, fallout, miss, accuracy, F-score, and AUC-ROC. The framework recommends suitable metrics based on the evaluation setup and is compatible with Python2 and Python3 on multiple operating systems. It relies on popular open-source Python packages and follows strict coding style and documentation formats. The EvalNE framework provides link prediction accuracy using various evaluation metrics and can be used as a command line tool or an API. It offers pre-filled configuration files for convenience and a modular design for flexibility in method evaluation. The EvalNE framework offers flexibility and usefulness in evaluating link prediction accuracy. Experimental sections from four papers in the NE literature were replicated, including Node2vec, CNE, PRUNE, and SDNE. Experiments compared edge sampling algorithms, with setups including various embedding methods and link prediction heuristics on datasets like Facebook, PPI, and AstroPh. Results were reported in terms of AUC-ROC. The paper evaluates different node embedding methods like SDNE, LINE, DeepWalk, GraRep, LapEig, and CN using the hadamard operator for link prediction on the GR-QC dataset. Results are reported in terms of precision@k for values between 2 and 10000. The evaluation setup includes comparisons with CNE and Metapath2vec on networks like BlogCatalog, Wikipedia, and StudentDB. The authors did not disclose the node to edge embedding operator used. The study evaluated various node embedding methods for link prediction on the GR-QC dataset, using the hadamard operator and reporting precision@k values between 2 and 10000. The number of train non-edges equaled train edges, with the remaining non-edges used for testing. Different settings were replicated with some exceptions, and metrics were averaged over three repetitions. Logistic regression was used for binary classification with hyper-parameters tuned as reported. Specific configuration files were used for each setting, and LP heuristics from EvalNE were evaluated. The study evaluated various node embedding methods for link prediction on the GR-QC dataset using LP heuristics from EvalNE. Results aligned well with CNE and PRUNE papers, except for Metapath2vec on the Facebook dataset. The study compared different node embedding methods for link prediction on the GR-QC dataset. Results were consistent with CNE and PRUNE papers, except for Metapath2vec on the Facebook dataset. Differences in results were attributed to various factors such as different implementations, default parameters, and the use of parallelization. The study compared node embedding methods for link prediction on various datasets, emphasizing the importance of reproducible pipelines and detailed parameter settings. Results showed differences in accuracy and scalability between edge and non-edge sampling strategies compared to a naive approach. The highest deviation was observed in the metric of Recall, with results presented in TAB1. In TAB1, results for AUC-ROC show a maximum deviation of 0.01 on the arXiv dataset by the PA heuristic. The naive approach yielded slightly higher results compared to the proposed method across methods and datasets. Scalability experiments in FIG2 demonstrate that the proposed method is significantly faster than the naive approach, regardless of the number of train and test edges. Execution time of the naive approach increases with more test edges required. In FIG3, the BlogCatalog dataset is analyzed with different sub-graphs and node ranges, showing execution times for both sampling strategies. The execution times for edge sampling strategies are reported in FIG3, with variance in method performance evaluated for different experiment repetitions. Results show that a single train-test split provides a good estimate, with average differences and variances calculated for both 50-50 and 90-10 splits. The recent surge in research on network embeddings has led to various data sets and evaluation setups. There is a need for specific tools to ensure accurate evaluation of embedding methods, especially for link prediction tasks. The evaluation process involves train and test sampling, non-edge sampling, and selection of edge embedding methods and binary classifiers, resulting in potential errors and inconsistencies. EvalNE is a novel framework for evaluating network embedding methods for link prediction. It automates train and test edge set selection, simplifies parameter tuning, and reports method accuracy based on various criteria. The importance of edge sampling strategy and parameter tuning is highlighted, along with a scalable procedure for selecting edge sets that is significantly faster than previous approaches."
}