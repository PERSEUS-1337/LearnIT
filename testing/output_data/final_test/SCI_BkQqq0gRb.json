{
    "title": "BkQqq0gRb",
    "content": "This paper introduces variational continual learning (VCL), a framework that combines online variational inference and Monte Carlo VI for neural networks. VCL can train deep discriminative and generative models in evolving task settings, outperforming existing methods by preventing catastrophic forgetting. Continual learning is a flexible form of online learning where tasks evolve over time and new tasks emerge. Continual learning systems must adapt to evolving tasks without revisiting all previous data at each stage. This is a challenge in machine learning due to dataset shifts and the need for multi-task transfer. Deep continual learning methods are crucial but balancing adaptation to new data while retaining old knowledge is difficult, leading to the catastrophic forgetting problem. The catastrophic forgetting problem arises from too much stability or inability to adapt in continual learning systems. Recent approaches involve training individual models on each task and combining them later, or using a single model with regularized training to prevent drastic parameter changes. This paper proposes a more principled and automatic approach based on Bayesian inference, which retains a distribution over model parameters to indicate plausibility given observed data. Bayesian inference combines previous data with current data to update model parameters, preventing drastic changes in influential parameters. Exact Bayesian inference is often intractable, so approximations like variational continual learning (VCL) are used. VCL merges online variational inference with Monte Carlo VI for neural networks and includes a small episodic memory for data summarization. In Bayesian inference, variational continual learning (VCL) combines online variational inference with Monte Carlo VI for neural networks and includes a small episodic memory for data summarization. The framework is general, applicable to both deep discriminative and generative models, yielding excellent performance in continual learning settings. Bayesian inference involves applying Bayes' rule to recover datasets. A recursion is identified where the posterior after seeing the T-th dataset is obtained by multiplying the posterior after the (T-1)-th dataset by the likelihood and renormalizing. Approximation is often needed due to the intractability of the posterior distribution. Various methods such as Laplace's approximation and variational KL minimization can be used for approximation. The text discusses projection operators for Bayesian inference, such as Laplace's approximation and variational KL minimization. These operators allow for recursive approximations of posterior distributions, supporting online updating. The online VI approach is favored for complex models and continual learning of neural networks. Variational continual learning uses a projection operator defined through KL divergence minimization over approximate posteriors. VCL aims for exact Bayesian inference but may accumulate errors with repeated approximations. To address this, VCL is extended to include a small representative set of data. To address potential errors in VCL, a small representative set of data called the coreset is included. The coreset acts as an episodic memory, retaining important training data from previous tasks for the algorithm to revisit. This approach has also been explored by BID31. The coreset is updated with each new dataset, and the variational distribution is updated for non-coreset data points. Prediction is performed using the final variational distribution. The coreset in VCL acts as a memory for important training data from previous tasks. The new coreset is created by selecting data points from the current task and the old coreset. Various selection methods can be used, such as random selection or the K-center algorithm. A variational recursion is developed to approximate the posterior distribution, with contributions from the coreset and non-coreset data points. The coreset in VCL serves as a memory for important training data, incorporating it into the approximate posterior before prediction to prevent forgetting. VCL can be applied to various discriminative probabilistic models, including deep fully-connected neural network classifiers for continual learning. In discriminative continual learning, single-head neural networks are sufficient for simple instances where data arrives in an i.i.d. manner. Multi-task learning often utilizes multi-head networks with separate heads for different output variables. Recent advancements in network architectures for continual and multi-task learning have been explored, showing potential for more powerful learning schemes. In discriminative continual learning, multi-task learning utilizes multi-head networks with separate heads for different output variables. VCL requires specification of q(\u03b8) where \u03b8 is a D dimensional vector formed by stacking the network's biases and weights. The posterior distribution over the associated head parameters remains at the prior before task k is encountered, allowing for incremental growth of the variational approximation as each task emerges. The current dataset D t only updates posterior distributions over head parameters for tasks in the dataset, while shared parameters are constantly updated. Training with the VFE approach maximizes the negative online variational free energy. The KL-divergence can be computed in closed-form, but the expected log-likelihood requires further approximation using Monte Carlo and the local reparameterization trick. Deep generative models have gained recent attention for passing noise variables. Deep generative models (DGMs) have gained recent attention for generating realistic images, sounds, and videos by passing noise variables through a deep neural network. The VCL framework is extended to include variational auto-encoders (VAEs), a type of DGM. The approach can also be applied to generative adversarial networks (GANs), with continual learning being a challenge. The model involves a prior over latent variables typically Gaussian, and distributional parameters defined by a deep neural network. The VCL approach extends to VAEs, involving a deep neural network for parameter estimation. It approximates the full posterior distribution over parameters after observing each dataset, critical for continual learning. The approximate posterior q t is obtained by maximizing the variational lower bound with respect to q t and \u03c6, where the encoder network q \u03c6 (z) is parameterized by \u03c6. The generative model can be split into shared and task-specific parts, with options for sharing networks that generate observations x from intermediate-level representations h. Architecture (i) is more suitable for data with common structural primitives selected by high-level variables. Continual learning for deep discriminative models involves regularized maximum likelihood estimation to bias new parameter estimates towards previous ones. Specific instances include maximum-likelihood estimation and MAP estimation. Continual learning for deep discriminative models involves regularized maximum likelihood estimation to bias new parameter estimates towards previous ones. Specific instances of this scheme include Maximum-likelihood estimation, MAP estimation, Laplace Propagation, and Elastic Weight Consolidation. Elastic Weight Consolidation (EWC) and Synaptic Intelligence (SI) are two methods for continual learning in deep discriminative models. EWC approximates the average Hessian of likelihoods and modifies Laplace regularization, while SI computes importance of parameters to each task using changing rates of gradients. EWC introduces hyper-parameters and regularizes to intermediate parameter estimates, while SI compares changing rates of gradients and parameters. VCL differs from these methods by not having certain features like MAP, EWC, and SI. VCL differs from EWC and SI by not requiring tuning of free parameters on a validation set. It retains a full distribution for uncertainty estimates, unlike methods like Laplace's and MAP estimation. Various approaches like extended Kalman filtering, variational inference, and expectation propagation have been explored for approximate Bayesian training of neural networks. Continual learning for deep generative models involves applying VAE algorithm to new datasets, leading to catastrophic forgetting. EWC regularization can be used to mitigate this issue, but computing it requires approximations due to intractable likelihood gradients. The experiments evaluate the performance and flexibility of VCL through various tasks, including discriminative and generative tasks. Standard continual learning benchmarks are used for comparison with EWC, LP, and SI. VCL's objective is hyper-parameter free, providing a novel approach to continual learning. VCL outperforms EWC, SI, and LP in continual learning benchmarks by achieving 90% average accuracy after 10 tasks, compared to 84%, 86%, and 82% respectively. The combination of VCL with coresets leads to improved performance, with random and K-center coresets achieving 93% accuracy. VCL achieves 95.5% accuracy with a coreset size of 5,000 examples per task, outperforming vanilla VCL. Performance improves with coreset size, but even for large coresets, the combination with VCL remains advantageous. In an experiment using Split MNIST, VCL with coresets outperforms EWC and LP, slightly trailing behind SI. VCL shows significant performance improvement without hyper-parameter tuning, unlike EWC and SI. After 5 tasks, VCL achieves 97.0% average accuracy on all tasks, while EWC, SI, and LP attain 63.1%, 98.9%, and 61.2% respectively. Adding the coreset improves VCL to around 98.4% accuracy. Experiment with notMNIST dataset shows VCL competitive with SI and outperforming EWC and LP, achieving 92.0% average accuracy after 5 tasks. In deep generative models experiments, VCL achieves 92.0% accuracy after 5 tasks, outperforming EWC, SI, and LP. The addition of a random coreset boosts VCL's performance to 96% accuracy. Two continual learning experiments are conducted for MNIST digit and notMNIST character generation using shared and task-specific components. In deep generative models experiments, VCL achieves 92.0% accuracy after 5 tasks, outperforming EWC, SI, and LP. The addition of a random coreset boosts VCL's performance to 96% accuracy. VCL is compared to na\u00efve online learning using various methods, with SI and VCL achieving the best visual quality on both datasets. Quantitative evaluation is done using two metrics: test log-likelihood and classifier uncertainty. LP, EWC, and SI are compared in deep generative models experiments, with VCL outperforming them with 92.0% accuracy after 5 tasks. VCL's performance improves to 96% accuracy with a random coreset. LP and EWC show deteriorating performance when moving from task \"digit 0\" to \"digit 1\" in MNIST. SI fails to produce high test log-likelihood results after tasks. Future work will investigate continual learning on a sequence of tasks following an adversarial ordering. Variational Continual Learning (VCL) extends online variational inference to handle complex neural network models and can be enhanced by including a small episodic memory leveraging coreset algorithms. Experimental results demonstrate state-of-the-art performance compared to previous continual learning approaches. The Variational Continual Learning (VCL) approach outperformed previous methods in continual learning, even without free parameters in its objective function. Future research should explore alternative inference methods and develop more advanced episodic memories. VCL is well-suited for refining models in sequential decision-making tasks like reinforcement learning. In the study, single-head networks with two hidden layers are used, each containing 100 hidden units with ReLU activations. The models are trained using the Adam optimizer with a learning rate of 10^-3. VCL algorithms are trained with batch size 256 and 100 epochs, with 200 examples from each task included in the coresets. The performance of SI with different hyper-parameters is compared, with \u03bb = 0.5 selected as the baseline. In this experiment, various hyper-parameters are compared for EWC and diagonal LP models. The best values for \u03bb are selected as baselines for each model. Fully connected multi-head networks with two hidden layers are used, each containing 256 hidden units with ReLU activations. Test set accuracy is compared for the current model on all observed tasks. In this experiment, the test set accuracy of the current model on all observed tasks is compared. Results are averages over 10 runs with Adam optimizer and batch size equal to training set size. Coresets with 40 examples per task are used, and final approximate posterior is computed separately for each task. Algorithms using coresets are trained with VFE method, comparing SI with different \u03bb values. EWC performance is compared with single-head and multi-head models, showing multi-head models work better. For diagonal LP, multi-head model with \u03bb = 1 is used. The experiment settings are similar to Split MNIST experiment but with deeper networks. In a study comparing SI and EWC with different hyper-parameter values, deeper networks with 4 hidden layers and 150 hidden units each were used. The experiment included \u03bb values of 10^4 for multi-head EWC, 1 for multi-head LP, and 0.1 for SI. A small experiment on a 2D dataset was conducted to explore EWC with \u03bb = 1 and VCL, involving two sequential binary classification tasks with distinct input distributions. In an experiment comparing VCL and EWC on two sequential binary classification tasks with different input distributions, VCL outperformed EWC. The models used fully connected networks with one hidden layer of 20 units. EWC failed to learn classifiers for both tasks after observing the second task, while VCL continued to perform well. The learning rates and optimization epochs were tuned separately for each task in experiments on Deep Generative Models. The generative model used in the experiment consists of shared and task-specific components represented by neural networks with 500 hidden units. Task-specific encoders are used with symmetric architectures. In probabilistic models with conjugate priors, the exact posterior of parameters/latent variables can be obtained. The experiment uses a generative model with shared and task-specific components represented by neural networks. The exact posterior of parameters/latent variables can be obtained in probabilistic models with conjugate priors. When using a diagonal Gaussian approximation, the online variational Gaussian approximation and online Laplace's approximation yield the same result, but batch and sequential solutions differ. Sequential variational updates for a Bayesian linear regression model are detailed for associating random binary patterns to binary outcomes. The task involves associating a D-dimensional binary vector x t with a binary output y t using a weight vector W. The model sees one input-output pair at a time and assumes specific values for features and outputs. The memory of the network trained by online variational inference is equivalent to that of online Laplace's method when the prior is ignored. Differences arise when the prior is considered or when parameter regularization constraints are accumulated. The equivalence between online variational inference and Laplace's method memory holds when the prior is ignored, but differences arise with prior consideration or accumulated parameter regularization constraints."
}