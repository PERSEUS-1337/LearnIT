{
    "title": "BkeaEyBYDB",
    "content": "Federated Learning (FL) involves learning a global model without copying raw data, particularly useful for data on mobile phones. Model Agnostic Meta Learning (MAML) can be applied to personalize the global model for individual devices in FL. Federated Averaging, a popular FL algorithm, can be seen as a meta learning algorithm, and fine-tuning can improve global model accuracy for easier personalization. The study found that optimizing for global model accuracy can lead to easier personalization, but may result in weaker personalization outcomes. Training a model using Federated Averaging makes it easier to personalize compared to standard datacenter optimization methods. This raises new questions for Federated Learning (FL), Model Agnostic Meta Learning (MAML), and machine learning research in general. The growth of machine learning applications has been driven by aggregating large amounts of data in datacenters, but concerns about privacy and trust are increasing due to the risks associated with data collection. Federated Learning (FL) offers an alternative approach for training a global model without sending raw data to the cloud. Google's FL system selects devices to train the model locally, with updates aggregated centrally. The basic FL algorithm, Federated Averaging (FedAvg), has been successfully used in production applications, showing superior performance compared to datacenter-trained models. In Federated Learning (FL), the best model is trained in a datacenter. Algorithmic extensions include differential private model training, compression, secure aggregation, and fewer always-participating nodes. FL faces challenges with non-i.i.d and unbalanced data, making it difficult to ensure good performance across devices. Theoretical guarantees are limited to restrictive assumptions and convex objectives. This work focuses on personalization methods for adapting the model to data on each device individually, distinguishing between the initial global model and the personalized local model. Meta Learning, specifically Model Agnostic Meta Learning (MAML), optimizes performance through fast adaptation on various tasks. Unlike traditional FL personalization methods, MAML's gradient-based approach connects training and adaptation stages for more efficient personalized models. In the context of Meta Learning and Model Agnostic Meta Learning (MAML), Federated Learning (FL) algorithms like FedAvg and Reptile use gradient descent locally for tasks and clients, similar to MAML. To improve FL personalization, objectives include an improved personalized model, a solid initial model, and fast convergence. Typically, MAML algorithms focus on the first objective only. In this work, the authors study the connection between Federated Learning (FL) and Model Agnostic Meta Learning (MAML) algorithms, proposing a modification of FedAvg for optimizing personalized performance. They demonstrate that FedAvg is already a meta learning algorithm and show the importance of optimizing for personalized performance over the quality of the global model. The study explores the relationship between Federated Learning (FL) and Model Agnostic Meta Learning (MAML) algorithms, proposing a modified FedAvg for personalized performance optimization. Different global models with the same accuracy can vary in personalization capacity, challenging existing FL objectives and inspiring new research directions in Machine Learning. The authors highlight similarities between FL and MAML algorithms, presenting FedAvg as a combination of a baseline and MAML methods. In each iteration, a MAML algorithm trains across a random batch of tasks {T i }. For each task T i , it conducts an inner-loop update, and aggregates gradients from each sampled task with an outer-loop update. FL uses a random selection of clients {T i } in each training round. Reptile and FedAvg become the same algorithms when all clients have the same amount of data. Other MAML algorithms or non-MAML/FL methods can also be viewed as instances of the conceptual method in Algorithm 1. The ServerUpdate function rearranges the update formula of FedAvg/Reptile to connect with other methods like FedSGD and FOMAML. It involves a linear combination of gradients computed in local optimization processes for participating clients. FedSGD serves as a baseline for Federated Learning. FedSGD is a baseline for Federated Learning, optimizing the initial model by taking a single gradient step based on local data. It is inefficient in the FL setting but serves as a comparison for FL algorithms. The update formula for FedSGD is used to derive the update for FOMAML, which involves locally adapting K gradient steps for personalized performance. The general MAML update proposed by Finn et al. (2017) involves adapting K gradient steps. FO-MAML simplifies this by ignoring the 2nd-order gradients, resulting in a first-order approximation. FedAvg updates by averaging client updates, which are sums of local gradient updates. FedSGD optimizes the initial model with a single gradient step, serving as a baseline for comparison in Federated Learning algorithms. The Federated Averaging algorithm optimizes personalized performance through a linear combination of algorithms after local updates. Increasing the parameter K improves personalization performance until a point where the initial model's stability is compromised. The Personalized FedAvg algorithm is an experimental adaptation of FedAvg to enhance proposed objectives. FedAvg(E) is the Federated Averaging method run for E local epochs, while Reptile(K) is another method used. Personalized FedAvg in Algorithm 2 optimizes for personalized performance by running FedAvg(E) with momentum SGD as the server optimizer and then switching to Reptile(K) with Adam as the server optimizer for fine-tuning. This method ensures reasonably fast convergence in terms of communication rounds. The proposed method involves a fine-tuning stage using Reptile(K) with Adam as the server optimizer to improve the initial model while stabilizing the personalized model. Adam is found to yield better results than other optimizers, leading to the best personalized performance with a broader set of hyperparameters. The subsequent deployment and personalization use the same client optimizer as used for training, resulting in the best results for FedAvg/Reptile-trained models. The EMNIST-62 dataset is used for simulated FL experiments with 3400 users split into training and test data. The initial training involves 2500 users, leaving 900 for personalization evaluation. Evaluation metrics include initial and personalized accuracy averaged among all clients. The study utilized the baseline convolutional model in TensorFlow Federated for experiments on device personalization. The experiments were repeated 9 times with random initialization, and results were reported for initial and personalized accuracies. The Shakespeare dataset was used for next-character prediction, with training on 500 clients and evaluation on 215 clients. The convergence of initial and personalized models during training using Federated Averaging algorithm was visualized. The study used the baseline convolutional model in TensorFlow Federated for experiments on device personalization. Results showed that personalized accuracy converges higher than initial accuracy, validating the EMNIST-62 dataset for Federated Learning. Federated Averaging was confirmed as a Meta Learning algorithm. Personalized accuracy after training with E = 10 was significantly higher than after training with E = 2. The study confirmed Federated Averaging as a Meta Learning algorithm, showing that personalized accuracy after training with E = 10 is significantly higher than after training with E = 2. This emphasizes the importance of emphasizing personalized accuracy over initial accuracy in Federated Learning. In the presence of non-i.i.d. data, Federated Learning should prioritize personalized performance. Recommendations to adjust local epochs or learning rate may not always be effective. Personalized accuracy tends to increase even with noisy initial accuracy. Results show improved convergence with 20 clients per round compared to 5 clients. The experiment showed that increasing the parameter E initially improves personalized accuracy until a certain threshold, with a range of 5-10 being optimal. A similar experiment with Shakespeare data also showed improvement. The focus was on local structure in language, with potential for more significant impact in next-word prediction tasks. The study looked at personalization performance based on local epochs and optimizers used. The study focused on personalization performance based on local epochs and optimizers used. Three different models were tested, with Adam producing reasonable personalized results but inferior to SGD. SGD with a learning rate of 0.02 and batch size of 100 worked best in all cases. The study compared different optimizers for personalization performance, with SGD outperforming Adam. Using Reptile(10) showed improved initial accuracy and personalized accuracy, while Reptile(1) led to a drop in personalized accuracy. This highlights the importance of choosing the right optimizer for model deployment. The study compared optimizers for personalization performance, showing Reptile(10) improved accuracy while Reptile(1) decreased it. A centralized initial model trained with Adam was evaluated for personalization performance after 10 and 50 epochs, yielding similar results to fine-tuned models. The study compared optimizers for personalization performance, showing that using Adam as the server optimizer for fine tuning yielded similar results to fine-tuned models with Reptile(1). The study compared different optimizers for fine tuning and found that all optimizers can achieve higher initial accuracy at the expense of slightly lower personalized accuracy. Fine tuning with Reptile(10) and Reptile(1) resulted in more consistent initial and personalized accuracy compared to other optimizers. The study compared different optimizers for fine tuning and found that Reptile(10) and Reptile(1) achieved more consistent initial and personalized accuracy. The distribution of results on a per-client basis is crucial for practical deployment, as even a small degradation in user experience could incur disproportionate costs. The performance of fine-tuned models on train and test clients showed that while basic ML principles might suggest overfitting with Reptile(10) models, personalized accuracy revealed a different story. In the context of Federated Learning, Reptile(10) shows significantly better personalized accuracy for both train and test clients. The study argues that the accuracy of the global model after personalization should be of greater interest. This investigation reveals similarities between Federated Learning and Model Agnostic Meta Learning, posing new questions for the Machine Learning community. Challenges in Federated Learning include training a shared global model based on decentralized data storage. In the context of Federated Learning, the primary objective should be adapting to statistical heterogeneity at different data nodes. Federated Averaging optimizes personalized performance and improves the global model. Experiment results show that the algorithm used to train the model impacts its personalization capacity. Simply optimizing the global model's accuracy can hinder personalization, questioning the objectives of Federated Learning. In the Model Agnostic Meta Learning literature, the focus is usually on model performance after adaptation to a given task. However, for Federated Learning, it is important to also consider the performance of the initial model and fast convergence in terms of communication rounds. The connectivity constraints in production deployments emphasize the need for these objectives to be addressed in MAML works. The empirical evaluation in this work raises questions about the impact of training algorithms on model personalization and adaptability. It also questions if there are ways to measure or optimize for adaptability, potentially leading to novel optimization methods. Transfer Learning is highlighted as another area of interest. Transfer Learning is a common technique where a trained model is adapted for a new task. The algorithms proposed in FL and MAML communities could improve domain adaptation results. A systematic analysis of optimization algorithms could provide insights into optimization and generalization connections. Zhang et al. (2019) introduced a method that acts as an outer optimizer, enhancing the stability of existing optimization methods. The general algorithm improves the stability of existing optimization methods. Table 3 summarizes attempts at fine-tuning the model with different server optimizers, showing Adam consistently provides better results. Per-client personalization results are visualized in Figure 4, highlighting the importance of identifying clients for improvement. Future investigation is needed to develop methods that can robustly identify clients below the diagonal line and revert to the initial model."
}