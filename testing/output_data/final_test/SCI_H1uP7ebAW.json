{
    "title": "H1uP7ebAW",
    "content": "The field of medical diagnostics faces challenges similar to classical machine learning problems, with practical constraints complicating the translation of endpoints into classical architectures. Tasks in radiology often involve multi-label classification of medical images for multiple pathologies, requiring high accuracy across various outcomes. Limited training data emphasizes the need to extract clinically relevant features without relying on pre-trained models. LSTMs are used to leverage interdependencies among data to address these constraints. In medical diagnostics, LSTMs are used to predict 14 pathologic patterns from chest x-rays without pre-training, achieving state-of-the-art results on a large dataset. Alternative evaluation metrics are proposed for clinical relevance, addressing the scarcity of publicly available medical data and the potential biases introduced by pre-training on unrelated datasets like ImageNet. Clinical settings require models that can accurately predict numerous diagnostic outcomes. Chest x-rays are a common type of radiology exam used for multi-label classification in medical diagnostics, predicting various pathologies like lung cancer, tuberculosis, and pneumonia. The challenges include accurately predicting the presence or absence of each label to minimize misdiagnosis, requiring architectures that consider clinical context to make the most of available data. Chest x-rays can show patterns corresponding to various pathologies like lung cancer, tuberculosis, and pneumonia. Interpreting these patterns can be challenging due to disagreements between radiologists, leading to unnecessary follow-up procedures. Understanding the complex interactions between abnormal patterns can provide additional clinical context, such as the presence of cardiomegaly suggesting pulmonary edema, consolidation, and pleural effusion. Training models to recognize these interdependencies is crucial for accurate diagnosis. Training a model to recognize interdependencies in abnormal patterns on chest x-rays can improve prediction of pathologic outcomes. This work addresses the challenge of predicting multiple labels simultaneously while considering their conditional dependencies. Previous studies have used recurrent neural networks for similar tasks, but their naive adoption is problematic in the medical context. In this work, the authors address the issue of predicting multiple labels simultaneously in medical diagnosis. They experimentally verify that a carefully designed baseline model, ignoring label dependencies, can perform well without pre-training. The study compares results with models pre-trained on ImageNet and introduces alternative metrics for clinical interpretability. The goal is to improve patient outcomes by applying state-of-the-art machine learning models to medical diagnosis. The study explores the use of baseline models in medical diagnosis, highlighting the importance of considering label dependencies for improved diagnostic results. The research aims to leverage advancements in Artificial Intelligence and machine learning to enhance computer-assisted diagnosis in medicine, particularly in the context of growing clinical data availability in machine-readable formats. Recent surveys suggest that neural networks are becoming the standard for classification, detection, and segmentation tasks in medical imaging with input modalities like CT, MRI, x-ray, and ultrasound. Models based on neural networks dominate medical imaging challenges, particularly using convolutional neural networks (ConvNets) for abnormality detection and segmentation. UNets are popular variants for these tasks. The most popular variants for abnormality detection and segmentation in medical imaging are UNets and VNets, both based on fully convolutional neural networks. Representative examples of neural network-based models for classification include BID5 for skin cancer, BID7 for diabetic retinopathy, BID13 for pulmonary tuberculosis, and BID11 for lung cancer diagnosis. These models employ 2D or 3D ConvNets and have achieved near-human level performance. Our model uses a 2D ConvNet as an image encoder for chest x-rays, addressing a multi-label classification problem with a finite set of labels. Various models have been proposed in the literature for this task. Various models have been proposed in the literature for multi-label classification. The binary relevance approach breaks the problem into independent binary classification tasks for each label, but it assumes label independence. To address dependencies between labels, researchers have explored methods like predicting over the label power set and training classifiers with loss functions that represent dependencies. Recent research has favored recurrent neural networks (RNNs) for multi-label classification, using loss functions that represent dependencies and a sequence of single-label classifiers. The proposed approach involves using 2D ConvNets as encoders and decoders based on RNNs to detect and classify abnormalities in chest x-ray images. This work is similar to a previous RNN-based model for abnormality classification. The RNN used in previous work processes inputs instead of outputs, lacking label dependencies. BID26 also addresses chest x-ray annotation using a three-stage model with 2D ConvNets and RNNs. Their RNN decoder is similar but predicts abnormalities differently. They use softmax to predict one of T abnormalities, while our model predicts presence or absence of abnormalities with sigmoid at each time step. The design choice for predicting abnormalities with sigmoid at each time step is inspired by Neural Autoregressive Density Estimators (NADEs) of BID14. This approach allows for predicting absence of abnormalities and avoiding per-class overcall and false alarms in the clinical setting. The model was trained on the OpenI 3 dataset with 7000 images. Different metrics are proposed for clinical interpretation instead of BLEU BID21. BID30 proposed a ConvNet-RNN architecture to model label dependencies, similar to BID26. BID1 focused on eliminating the need for a pre-defined label order in training. They also introduced a 2D ConvNet for classifying abnormalities in chest x-ray images, using a binary relevance approach. They presented the \"ChestX-ray8\" dataset, the largest public x-ray dataset to date. The \"ChestX-ray8\" dataset is used to train and evaluate models for x-ray image analysis. Notations are defined for input images (x), abnormalities (y), and model parameters (\u03b8). The binary vector y indicates the presence or absence of abnormalities, with specific dimensions denoted by superscripts. Subscripts are used to index examples. The DenseNet model, an extension of Convolutional Neural Networks, establishes shortcut connections between all pairs of layers in a deep neural network. This feature reuse makes DenseNets computationally and statistically efficient, especially for medical imaging tasks with limited training examples. The proposed model based on DenseNets for medical imaging tasks has higher resolution inputs and a smaller network depth to avoid overfitting with less training data. The model design is highlighted in FIG0 and considers conditional dependencies among indicators. The probabilistic model assumes no information sharing between labels, allowing for parameter sharing among classifiers to reuse features and prevent overfitting. The encoded input representation captures useful semantics for decoding. The model uses a growth rate K and stride S, with 4 ConvBlocks in a DenseBlock to limit parameters. Our model uses 4 ConvBlocks in a DenseBlock to limit parameters. The proposed RNN decoder optimizes the Maximum Log-likelihood Estimate criteria during training. The assumption of independence among abnormalities is considered too restrictive, leading to a factorization without assuming independence for the multi-label problem. The statistical dependencies among indicators are explicitly modeled within each factor, suggesting the presence of other abnormalities. Recent models have focused on factorization, with neural network models like LSTM providing a more general framework for capturing long term dependencies. The Long-short Term Memory Networks (LSTM) are used for multi-label classification as sequence prediction with a fixed length. The LSTM formulation is similar to those used in image and video captioning, without attention mechanism. The encoder produces a lower dimensional vector representation of the input x, while the decoder initializes states and memory of an LSTM with specific functions. The LSTM decoder is parameterized with model parameters consisting of matrices, vectors, and a scalar. The ground truth labels are represented as a vector code respecting a fixed ordering. The ground truth labels, represented as vector code b l . y, are row vectors with elements of 0 or 1. The decoder LSTM computes the mean of a Bernoulli distribution in each step. Sigmoid is used to predict y t to avoid bias towards predicting \"end-of-sequence\" due to label sparseness. The decoder uses Sigmoid to predict abnormalities at each step, avoiding bias towards \"end-of-sequence\" prediction. It addresses issues of missing infrequent abnormalities and the importance of absence of predicted abnormalities. The model optimizes dependencies among predictions during training. In Section 4, the impact of different orderings on model training is investigated. The inference of the model is approximated using beam search BID28. Greedy search, equivalent to beam search with size 1, is found to perform similarly due to the binary sampling nature of the factors. Experiments are conducted on a dataset of 112,120 frontal-view chest x-rays for medical diagnosis validation. The dataset consists of 112,120 frontal-view chest x-rays with 14 abnormalities. It is split into 70% for training, 10% for validation, and 20% for testing. The performance on validation and test sets is consistent. The dataset is new, so not all metrics are established yet. The Negative log-probability of the test set (NLL) is considered as a metric with advantages and drawbacks. The NLL is a probabilistic metric widely used in biostatistics to measure true detections and false alarms. It does not directly reflect the model's accuracy in diagnosing abnormalities. The ROC curve is generated by varying the decision threshold to discretize probabilities into 0 or 1. Computing P(yi|x) is challenging due to the need to marginalize out other variables in the model. The DICE coefficient is a similarity measure for two sets, with a maxima at 1 when they are equivalent. Per-example sensitivity and specificity are computed using a formula, while per-class sensitivity and specificity use a different formula. These metrics are important in evaluating model performance in tasks like image segmentation. In image segmentation tasks, sensitivity and specificity are computed using different formulas. Data augmentation is crucial to combat overfitting, with input images randomly translated, rotated, and scaled. The ADAM optimizer is used with a learning rate of 0.001, adjusted based on validation set performance. Early stop is applied after 10,000 parameter updates. All metrics are calculated on the test set. In order to ensure a fair comparison, models are constrained to have similar parameters. Model configurations vary, with different network growth rates and encoder widths. The effect of label ordering is investigated, with models trained from scratch without pre-training on ImageNet data. AUC per abnormality is computed and shown in TAB2. The AUC per abnormality is computed based on the marginal distribution of P(y|x) and shown in TAB2. Model a outperformed the previous state-of-the-art in all metrics in Table 3. Label dependencies bring significant benefits, with marginal impact of ordering when the model is well-trained. Model b1 and b2 correspond to the models introduced in Section 3.3. To enhance computer-assisted diagnosis of chest x-rays, a two-stage neural network model was proposed. Model b1 sorts labels by frequency, while model b2 orders alphabetically. The model combines an image encoder with a recurrent neural network decoder to address challenges in learning from high-resolution medical images with limited training data. The second stage leverages label dependencies to improve prediction accuracy. Training the model from scratch ensures capturing the best application-specific features. The experiments demonstrated the feasibility and effectiveness of the proposed approach, with the baseline model outperforming the current state-of-the-art. The set of metrics quantifies performance and allows for comparisons with future work. Further exploration into learning label interdependencies showed promising results, but additional experimentation is needed to fully realize the methodology's potential in chest x-rays and medical diagnostics. Concerns include the risk of biased interdependencies from a limited training set. The model may rely too much on certain patterns like edemas in cardiac failure, especially when dealing with mixed pathology labels. Training with an ontology that has a consistent relational structure could maximize feature extraction and label interdependencies, which will be explored in a future study."
}