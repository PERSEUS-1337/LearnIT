{
    "title": "HJgJS30qtm",
    "content": "An unintended consequence of feature sharing is negative transfer in multitask settings, affecting linear and non-linear models, including neural networks. Proposed counter-measures are insufficient, so an adversarial training approach is suggested to mitigate negative transfer effects. Empirical results on attribute prediction multi-task datasets validate the need for correcting negative sharing in an end-to-end manner. An ideal classification model should focus on relevant evidence for prediction tasks and disregard unrelated evidence to improve generalization. Negative transfer effects can occur when using unrelated evidence, as shown in a supervised classifier example. Training an animal classifier should prioritize appearance features over irrelevant cues present in the data. The presence of unrelated cues in images, such as habitat features like snow and grass, can deceive archetypal models focused on appearance features. A proficient supervised learning model should prioritize relevant evidence for accurate labeling and discard irrelevant cues to improve performance on rare instances and generalize better to unseen data. This phenomenon highlights the importance of identifying and disregarding unrelated evidences in training data to prevent negative transfer effects. In literature, the presence of unrelated evidences in training data can negatively impact model performance. Techniques like negative labels and negative-sharing aim to mitigate this effect, but have limitations when applied to neural representation learning. This paper explores alternative methods inspired by a departure from regularization-based approaches. In contrast to regularization-based approaches, this study proposes an adversarial training-based formulation inspired by domain-adaptation. It views the classification tasks as adversarial multi-task learning, where primary tasks involve predicting fur pattern and color, while auxiliary tasks relate to habitat characteristics to be avoided. By training in a target domain with potentially different label correlations, negative transfer effects are reduced. This approach aims to alleviate the impact of unrelated evidences on model performance. Our proposed formulation, inspired by domain-adaptation, aims to alleviate negative transfer in supervised learning tasks, including neural networks. Negative transfer affects tasks like image classification and multilabel learning by hindering the learning of correct semantic concepts. Previous approaches used specific regularizers to address this issue. The primary model avoids using important features for the auxiliary task, leading to competition for features. BID8 extends this idea to attribute groups, inducing sparsity across groups but encouraging within them. Three limitations of feature competition techniques are highlighted: repeated features and trainable features. The curr_chunk discusses the negative transfer problem in a domain adaptation setting, where trainable features can lead to duplicated features and negative transfer. This problem arises when important features for both primary and auxiliary tasks are shared, resulting in competition and repeated features. In a domain adaptation setting, the negative transfer problem is formalized and explained. Previous regularization-based approaches fail to address this issue, leading to the development of adversarial learning algorithms. The goal is to solve negative transfer by learning a classifier that performs well on future test examples drawn from a probability distribution. In a domain adaptation setting, the negative transfer problem is addressed by learning a classifier that performs well on future test examples drawn from a probability distribution. The goal is to capture label correlation via a joint label distribution and assume different label correlations in training and test data. Unrelated tasks are defined as those with different correlations in training and test data, with negative correlation indicating that an important feature for one task is unlikely to be important for another. In domain adaptation, the goal is to train a classifier on instances from a source distribution to perform well on instances from a target distribution. The labeling functions for primary and auxiliary labels are assumed to be universal. Unsupervised domain adaptation involves labeled instances from the source distribution and unlabeled instances from the target distribution, with only information about the target domain's label distribution. The challenge lies in estimating the space of all distributions over X with the target label distribution. The goal of domain adaptation is to train a classifier on a source distribution to perform well on a target distribution. Unsupervised domain adaptation involves labeled instances from the source and unlabeled instances from the target, with information about the target's label distribution. The challenge is estimating all distributions over X with the target label distribution. To address this, a specific distribution D T is chosen from U T closest to D S, modeled using KL divergence in a constrained optimization. The relationship between D and P(Y) is illustrated using labeling functions and regions in the instance space. The optimization problem in domain adaptation involves density functions \u03c6 S and \u03c6 T for distributions D S and D T respectively. The Lagrangian equivalent is used to solve the problem, showing that D T is a scaled version of D S with a scaling factor based on the ratio of P T (Y ) and P S (Y ). This scaling factor varies across regions in the instance space. The concept extends to multiple labels in y. The optimization problem in domain adaptation involves density functions \u03c6 S and \u03c6 T for distributions D S and D T respectively. The Lagrangian equivalent is used to solve the problem, showing that D T is a scaled version of D S with a scaling factor based on the ratio of P T (Y ) and P S (Y ). This scaling factor varies across regions in the instance space. The concept extends to multiple labels in y. In the next section, methods leveraging soft domain labels for domain adaptation are presented, including the use of domain adversarial neural network (DANN) by BID3 to induce domain-invariance features. Theorem 1 by Ben-David et al. provides a generalization bound on target error in domain adaptation. It states that the target error is bounded by the sum of source error and the distance between source and target distributions. DANN introduces an objective function to minimize both source error and domain divergence, with divergence being the prediction accuracy of the domain classifier. DANN models start with a mapping function Jf : X \u2192 Rd with parameter \u03b8f to project instances. DANN models aim to find a feature extractor that projects instances to a latent space for high label prediction accuracy and low domain prediction accuracy. The objective function minimizes source error and domain divergence, with the latter being the accuracy of the domain classifier. The text discusses the use of soft domain labels in a formulation to address issues with domain classification. By providing a latent representation that cannot discriminate between source and target domains, the model aims to improve performance on domain classification tasks. The proposal suggests replacing the domain classification loss with an auxiliary label classifier loss to enhance the model's predictive capabilities. The proposal suggests replacing the domain classification loss with an auxiliary label classifier loss to improve the model's predictive capabilities. This involves using a gradient reversal layer to optimize the problem and extending the two-label scenario to multilabels by grouping related labels together in a model architecture with latent representations for each group. The proposal suggests replacing the domain classification loss with an auxiliary label classifier loss to improve predictive capabilities. This involves utilizing feature selection for the feature extractor to prevent negative transfer between correlated features. Recursive Feature Elimination (RFE) is used for feature selection, considering all features and eliminating them iteratively until the desired criterion is met. Recursive Feature Elimination (RFE) is a method used for feature selection in which features are evaluated and eliminated iteratively based on their scores from a classifier until a desired criterion is met. The importance of features can be determined by their effect on the classifier, such as the weights assigned by logistic regression. In adversarial settings for multilabel classification, feature importance can be calculated using a specific formula. Our study focuses on the adverse effects of negative transfer and how our algorithms resist it on synthetic data. The dataset consists of 10-dimensional feature vectors with binary labels. Features are sampled based on label distributions from Gaussian mixtures. The experiments aim to predict the primary label in the test set. In experiments on synthetic data, algorithms are tested for resistance to negative transfer effects. The dataset includes 10-dimensional feature vectors with binary labels sampled from Gaussian mixtures. The focus is on predicting the primary label in the test set, with comparisons made between different algorithms. The experiments on synthetic data test algorithms for resistance to negative transfer effects by predicting primary labels in the test set. DadvC performs marginally better than the baseline, while ALadvC and fs-adv consistently perform well regardless of label correlation. Varying the easiness of the auxiliary task affects the performance of classifiers, with the proposed algorithms outperforming baseline and DadvC as the task gets easier. The Animals-with-Attributes (AwA) datasets BID12 and Caltech-UCSD Birds 200-2011 (CUB) are used for multilabel attribute prediction. AwA consists of 30,475 animal images with 50 animals and 85 attributes each. CUB has 11,788 bird images with 200 birds and 312 attributes. Both datasets are split into train, validation, and test sets following a specific protocol. The study utilizes the feature representation from a pre-trained ResNet-101 model for attribute prediction on AwA and CUB datasets. Mean average precision (mAP) is reported for validation and test sets. A balance corrected binary crossentropy loss function is used, with early stopping criteria based on validation set performance. LR, LR+FS, and LR+FS-adv are strategies to prevent negative transfer effects. The study uses Recursive Feature Elimination (RFE) BID5 method for feature selection wrapped over Logistic Regression (LR) to prevent negative transfer effects. Features are transformed into a 500-dimensional space for CUB dataset. Feature importance scores are calculated using LR weights, removing a fraction of features at each iteration. The study utilizes Recursive Feature Elimination (RFE) BID5 method for feature selection wrapped over Logistic Regression (LR) to prevent negative transfer effects. Features are transformed into a 500-dimensional space for CUB dataset. At each iteration, a fraction of features is removed based on a decreasing lambda value. The final number of features is determined through validation based on mAP. Performance comparisons are made between RFE in adversarial and non-adversarial settings, showing improvements in mAP compared to baseline LR and LR+FS. The proposed method LR+FS-adv shows significant improvement over LR and LR+FS (w/o adv) for AwA and CUB datasets. MLP and ALadvC outperform LR+FS with adv due to their ability to apply projections to feature vectors. The adversarial approach involves utilizing ResNet-101 representation vectors, adding trainable layers, and connecting to group-specific attribute predictions. Smaller latent layers are used for AwA and CUB datasets. The proposed model with auxiliary labels for each group as an adversarial classifier (ALadvC) shows improvement in performance by 2.8% and a 6.8% mAP. The model is trained with a learning rate of lr = 0.01 and utilizes gradient reversal weight \u03bb = K 1+exp \u221210 * li. The model configuration has been optimized through parameter sweep for best validation error. The large number of adversarial branches is managed by utilizing pairwise-task-label overlap to threshold the number of tasks. The proposed model with auxiliary labels, known as ALadvC, shows performance improvements on AwA and CUB datasets. The model utilizes gradient reversal to shed negative transfer effects, leading to overall performance enhancement. Group-wise performance analysis reveals drops in mAP for certain groups, indicating true model performance on specific tasks. The proposed ALadvC model improves performance on AwA and CUB datasets by utilizing gradient reversal to prevent negative transfer effects. The measure of class-combination imbalance helps identify adversarial tasks that enhance prediction performance. Adversarial learning is shown to prevent negative transfer and improve generalization in supervised learning of natural data. In supervised learning, negative transfer can hamper performance, especially when unrelated labels co-occur. The solution involves addressing this issue in a multi-task scenario and leveraging domain expertise to acquire additional negative labels. Explainability of machine learning models can also aid in this process."
}