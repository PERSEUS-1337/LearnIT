{
    "title": "r1xrb3CqtQ",
    "content": "Domain transfer in machine learning involves smoothly transferring between domains, capturing variations without labels. Successful applications typically involve closely related domains like image-to-image or video-to-video. However, it is possible to transfer across modalities such as image-to-audio by abstracting data with latent generative models and learning transformations between latent spaces. A simple variational autoencoder can learn a shared latent space to bridge between different generative models in an unsupervised manner. The proposed variation autoencoder allows for preserving locality and semantic alignment in the transfer process, achieved through a linear classifier in the shared latent space. Domain transfer is enabled by deep learning techniques, allowing for a smooth mapping between two domains to reflect variations. This concept was inspired by the phonautograph, an early precursor to the phonograph, which captured audio waveforms in writing. The hierarchical structure facilitates efficient retraining of personalized mapping functions. Domain transfer in deep learning enables smooth mapping between two closely related domains, such as image-to-image or video-to-video, focusing on transferring local properties like texture and coloring. However, applying these techniques to distant domains can lead to distorted results. Transfer from one domain to another domain aims to maintain correct semantics across domains and reflect local changes in the target domain. The model is trained using VAE ELBO losses, Sliced Wasserstein Distance loss, and classification loss to encourage cross-domain overlapping and intra-class overlap in the shared latent space. The model is trained using VAE ELBO losses, Sliced Wasserstein Distance loss, and classification loss to encourage cross-domain overlapping and intra-class overlap in the shared latent space. To transfer data from one domain to another, the source domain information is encoded to a shared latent vector and then decoded to the target domain to generate the transferred audio. The model learns to hide information about the source domain in imperceptible high-frequency variations of the target domain, addressing limitations in data efficiency. The limitations of current conditional GAN techniques include the need for dense supervision from large volumes of paired data. For multi-modal domain transfer, the goal is to transfer instances from a source domain to a target domain while preserving local variations. This property, known as locality, ensures that local interpolation in the source domain is similar to the target domain after transfer. The goal in modeling is to respect the user's intent and ensure correct semantics are shared between two domains after transfer, known as semantic alignment. Users can define connections based on their intent, sorting data points into common bins to constrain cross-domain alignment. The text discusses using a classifier to measure semantic alignment in cross-domain alignment. The goal is to learn transformations that preserve locality and semantic alignment with minimal user labels. The proposed method involves abstracting domains with latent variable models and transferring between their latent spaces using a shared \"bridging\" VAE. This approach encourages locality and semantic alignment through sliced-wasserstein distance and classification loss in the shared latent space. Our proposed method enables transfer within and between modalities by training a smaller secondary model in latent space, improving training efficiency in terms of labeled data and time. The hierarchical approach involves pre-training separate generative models for source and target domains, encoding data to latent space, and using rejection sampling for GANs. The method involves adding a bridging conditional VAE with shared weights to model latent spaces z1 and z2. The VAE uses a single shared latent space z for both domains and is conditioned with an additional domain label D for flexibility. The KL-Divergence is penalized to be less than 1 for better reconstructions. More details can be found in the Appendix. The conditional bridging VAE objective includes three types of loss terms: Evidence Lower Bound (ELBO), Sliced Wasserstein Distance (SWD), and Classification Loss (Cls). ELBO maximizes training by setting hyperparameters \u03c3 and \u03b2 KL to encourage reconstruction accuracy. SWD measures distribution distance between mini-batches in shared latent space using random unit vectors and quadratic Wasserstein distance. Cls enforces semantic alignment with attribute labels through cross entropy loss and a linear classifier in the shared latent space. The one-layer linear classifier (z) operates in a shared latent space with a decision boundary separating classes. The total training loss includes terms for both domains with scalar loss weights. The transfer process involves encoding data x1 through two encoders for reconstructions and transformations. Further details and analysis are provided in FIG1 and Appendix A. Our work differentiates itself from existing research by addressing identified challenges. Deep latent generative models like VAEs and GANs are used to approximate population distributions through neural networks. VAEs use an encoder distribution to approximate the posterior, while GANs are trained with a classifier to distinguish between samples. These models have been applied in various scenarios such as conditional generation, image quality generation, and music structure. In the context of deep latent generative models like VAEs and GANs, the current chunk discusses the generation of high-quality images and long-range structure in music. It explores options for building hierarchical VAEs and domain transfer between images, audio, and video. The use of VAE in modeling the latent space of pre-trained generative models is proposed for transfer between different domains. The current chunk discusses the modeling of latent space in generative models, focusing on the transfer between heterogeneous domains. It compares different approaches, such as hierarchical VAE training and shared latent space usage, for domain transfer settings. The proposed work aims to separate pre-trained models and apply conditional shared VAE for more efficient domain transfer. Our work leverages a pre-trained generative model to model the latent space instead of data domains, enabling creative mapping between datasets with arbitrary alignments. We focus on three domains for quantitative studies: MNIST, Fashion MNIST, and SC09, each with natural alignments for comparison. For MNIST and Fashion MNIST, a VAE with MLP encoder and decoder is prepared using fully-connected linear layers activated by ReLU and a \"Gated Mixing Layer\". The bridging VAE network architecture is detailed in Appendix B. SC09 uses WaveGAN BID6. Class level supervision is used for semantic alignment. Three domain transfer scenarios are examined: 1. MNIST \u2194 MNIST, 2. MNIST \u2194 Fashion MNIST with a one-to-one mapping between digit and fashion classes. The bridging autoencoder transfers between images of digits and clothing, using a WaveGAN for spoken digits. It explores transferring between different classes of models and presents qualitative and quantitative results for reconstructions and domain transfer. Semantic alignment is measured with pre-trained classifiers in each data domain. The study evaluates domain transfer accuracy between different datasets with pre-aligned classes. Qualitative and quantitative results are presented for reconstructions and domain transfer, showing the maintenance of labels and diversity of samples. Transfer involves a broad range of attributes, with comparisons to existing approaches for specific dataset transfers. MNIST involves transferring between pretrained models with different initial conditions, not directly comparable. MNIST \u2192 SC09 had too distinct data domains for reasonable transfer. Interpolation serves as a proxy for locality and smoothness of latent transformations. Inter-class and intra-class interpolation shown in FIG5 and FIG6. Comparison of three rows of interpolations: (1) interpolation in the source domain's latent space, (2) transfer fixed points to target domain's latent space, and (3) transfer all points. The text discusses transferring points between different latent spaces using spherical interpolation in a semi-supervised method. It highlights smooth trajectories within classes and blurry combinations between classes during interpolation. The bridging autoencoder models the marginal posterior of each latent space, staying on the data manifold. In a semi-supervised method, the performance of transferring points between latent spaces is measured by transfer accuracy with labeled data. Unlike regular generative models, the proposed transfer method produces high-quality, in-domain data by modeling the marginalized posterior of data. The proposed method learns to model the marginalized posterior of data distribution evenly among classes, leading to accuracy growth with the number of labels. Even without labels, accuracies greater than chance are observed due to unsupervised alignment introduced by the SWD penalty. Pre-training base generative models offers computational advantages, especially for large models that take weeks to train. The bridging autoencoder only requires retraining of latent transfer mappings, saving time and resources. Training the bridging autoencoder for MNIST \u2194 SC09 takes about one hour on a single GPU, while retraining the SC09 WaveGAN takes around four days. An ablation study confirms the benefits of each architecture component to transfer accuracy, with the largest contribution being giving the bridging VAE a domain conditioning signal. The increased overlap in the shared latent space induced by the SWD penalty results in greater transfer accuracies. We have developed bridging autoencoders to learn mappings between different domains, achieving high transfer accuracies and connecting various model types. This approach requires fewer supervised labels and enables personalized cross-modal domain transfer. Our goal is to create a VAE that models the latent space of both domains and allows for local changes. The proposed VAE aims to model the latent space of two domains with local changes, ensuring overlap between encoded spaces for domain transferability within the same class. The optimization target includes three types of losses to achieve this goal. The VAE is fitted to maximize the ELBO for each domain, with continuous latent spaces and a chosen likelihood function. Cross-domain overlapping is measured using Wasserstein Distance between distributions of samples from source and target domains. The VAE is optimized to maximize the ELBO for each domain with continuous latent spaces. Cross-domain overlapping is encouraged using Sliced Wasserstein Distance to align shared latent spaces and ensure intra-class overlapping for transfer learning. The VAE is optimized to maximize the ELBO for each domain with continuous latent spaces, encouraging cross-domain overlapping using Sliced Wasserstein Distance. The cross entropy loss in the model requires labels and is supervised, with a simple linear classifier to increase VAE capacity. Figure 7 illustrates the design intuition and performance contributions of each loss term, showcasing the transfer between 2-D latent spaces with shared latent space. The proposed VAE model includes different components for domain transfer and class preservation. Each component contributes positively to performance in synthetic data. The model architecture relies on Gated Mixing Layers (GML) for improved results. The VAE model utilizes Gated Mixing Layers (GML) for improved performance compared to linear layers. Other network components like residual network and batch normalization do not provide performance enhancements. The shared latent space dimension is set to 100, with specific settings for different domain transfers. The VAE model uses Gated Mixing Layers (GML) for better performance. Different settings are used for MNIST \u2194 SC09 and MNIST \u2194 Fashion MNIST transfers. Adam optimizer BID14 is employed with specific parameters. Results are compared with Pix2Pix and CycleGAN approaches, showing limitations of existing methods and the proposed approach. The VAE model utilizes Gated Mixing Layers (GML) for improved performance in MNIST \u2194 SC09 and MNIST \u2194 Fashion MNIST transfers. Results demonstrate the limitations of Pix2Pix and CycleGAN compared to the proposed approach, with quantitative data showing the advantage of the new method in terms of Transfer Accuracy and Fr\u00e9chet Inception Distance. The VAE model uses Gated Mixing Layers (GML) for better performance in MNIST \u2194 SC09 and MNIST \u2194 Fashion MNIST transfers. Existing methods like Pix2Pix and CycleGAN perform worse than the proposed method in terms of Transfer Accuracy and Fr\u00e9chet Inception Distance (FID). Pix2Pix struggles with lower accuracy and image quality, while CycleGAN faces label collapse issues resulting in even lower transfer accuracy and FID."
}