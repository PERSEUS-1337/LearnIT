{
    "title": "Hyx6Bi0qYm",
    "content": "Brain-Machine Interfaces (BMIs) use neural signals from implanted electrodes to decode movement intent. A new computational approach decodes this intent from a low-dimensional representation, stabilizing the interface over time with domain adaptation methods like Canonical Correlation Analysis. The implementation of an Adversarial Domain Adaptation Network trained to match the empirical probability distribution of the residuals of reconstructed neural signals outperforms traditional methods based on latent variables in Brain-Machine Interfaces. Individuals with tetraplegia prioritize restoration of hand function, with over 50% willing to undergo brain surgery for grasp restoration. Brain-Machine Interfaces aim to extract movement intent from neural signals to restore motor function, but face limitations due to neural signal turnover causing variation in BMI actions. Brain-Machine Interfaces (BMIs) aim to extract movement intent from neural signals to restore motor function. Daily retraining of the interface is needed to maintain performance, but this is not practical. Dimensionality reduction methods are commonly used in BMI design to provide a compact representation of neural activity and movement intent prediction. Linear methods like PCA and FA have been used, as well as more recent approaches like autoencoders for nonlinear dimensionality reduction. Autoencoders have been utilized for nonlinear dimensionality reduction of neural signals. A deep learning architecture is developed to extract a low-dimensional representation of recorded M1 activity related to movement intent. This architecture improves predictions compared to the standard sequential approach. To stabilize the BMI against changes in neural recordings, a novel approach based on Generative Adversarial Network (GAN) architecture is introduced. The Adversarial Domain Adaptation Network (ADAN) aligns residual probability distribution functions of neural signals to stabilize BMI performance over time. This method eliminates the need for frequent recalibration, resulting in a stable and consistent BMI for users. To address the stability problem in Brain-Machine Interfaces (BMIs), various approaches have been proposed, including updating interface parameters gradually, adjusting parameters based on recording nonstationarities, canceling out neural fluctuations, training the interface with large data volumes, and aligning predicted movements with established patterns. Recent studies have shown the potential of latent dynamics for BMI stability. BID21 and BID27 have developed approaches to stabilize BMIs by aligning neural signals with previously learned dynamics. A male rhesus monkey was trained to perform movements while its forearm was restrained in a primate chair with a torque cell mounted onto a custom fit box. The monkey was trained to control a computer cursor using isometric torques in a 2D center-out task. A 96-channel microelectrode array was implanted in the hand area of the primary motor cortex to record neural activity. EMGs were also recorded from 14 muscles in the forearm and hand. Data was collected in five experimental sessions. The study collected data over 16 days to predict muscle activity patterns during task execution based on neural signals. This predictive model could potentially control computer cursors or robotic limbs for paralyzed individuals. Similar methods have been tested in humans recently. The BMI is a computational interface that transforms neural signals into command signals for movement control, specifically EMG patterns. The interface consists of a neural autoencoder (AE) and an EMG predictor. The AE is a multilayer network that aims to minimize the mean square error between input and output signals. Neural data is processed and inputted into the AE for analysis. The BMI utilizes a neural autoencoder and EMG predictor to transform neural signals into movement commands. A Gaussian filter is applied to spike counts to obtain smoothed firing rates. The latent layer activity is mapped onto EMGs through an LSTM layer. The model is trained by minimizing a loss function that accounts for reconstruction and EMG prediction errors. The factor \u03bb adjusts for different units and value ranges of firing rates and EMGs in the training set. It equalizes the contributions of the two terms in the loss function. The value of \u03bb is updated for each new training iteration. Once the neural AE and EMG predictor networks are trained on day-0 data, their weights remain fixed. To stabilize a fixed BMI, the latent space of later days is aligned to that of the first day. This step is necessary to provide statistically stationary inputs to the EMG predictor. Two approaches are used to align latent variables across days: Canonical Correlation Analysis (CCA) between latent trajectories. The experimental setup involves an isometric wrist center-out task with eight targets, color-coded. The BMI consists of a neural AE and an EMG predictor, with recorded neural activity predicting muscle activity. An ADAN architecture aligns firing rates across different days, minimizing divergence between latent distributions. This alignment procedure ensures consistency in neural data and their latent representation across days. The analysis involves finding a linear transformation of latent variables to maximize correlation between different days' data. CCA, a linear algebra approach, aligns latent activities for analysis of neural data. The implementation requires a one-to-one correspondence between data points in the two sets. The implementation of CCA requires a one-to-one correspondence between data points in the two sets, achieved through repeated execution of stereotypic movements. In real-life scenarios, establishing this correspondence is challenging due to unstructured motor behaviors. An unsupervised approach is desired to align latent variables across different days. We align latent variables across different days by matching the probability distribution of latent variables without point-to-point correspondence. Using a fixed AE trained on day-0 data, we map neural data onto l-dimensional latent variables and minimize KL divergence between their distributions. This is achieved by implementing a neural network with the same architecture as the encoder section of the BMI's AE. The BMI's AE on day-0 data aligns latent PDFs through linear operations, including translation, rotation, and scaling. An alternative BMI using a VAE replaces the AE, training it with a regularizer term to improve the Gaussian assumption for latent variables' distribution. The VAE in the study enforces a normal distribution on latent variables and matches the residuals of reconstructed firing rates to align neural recordings and latent variables using an ADAN similar to a GAN. The discriminator in the ADAN is initialized with weights from the BMI AE trained on day-0 neural data. The discriminator in the ADAN maximizes the difference between neural reconstruction losses of day-k and day-0, creating a strong signal for subsequent training. The distribution alignment module minimizes neural reconstruction losses of day-k by aligning firing rates with exponential units and linear readout layers. The aligner parameters are initialized as identity matrices and receive firing rates Xk as inputs during training. The ADAN uses the discriminator to align firing rates Xk with X0 during training, achieving unsupervised alignment. Reconstruction losses are quantified by the discriminator, measuring dissimilarity between distributions of scalar losses for day-0 and day-k. The discriminator learns to discriminate between these distributions by maximizing the difference in means. The ADAN uses the discriminator to align firing rates Xk with X0 during training, achieving unsupervised alignment by maximizing the Wasserstein distance. The discriminator learns to discriminate between distributions by maximizing the difference in means, maintaining this relation during training. The aligner and discriminator have loss functions to be minimized, illustrated in FIG1 with firing rates, latent variables, reconstructed firing rates, and muscle activity for wrist flexor and extensor muscles over eight trials. The overall performance of the interface is summarized in FIG1, quantified using the percentage of the variance accounted for (%VAF) for five-fold cross-validated data. The blue bar shows the accuracy of EMG predictions directly obtained from the n-dimensional firing rates, without the dimensionality reduction step. The green bar shows the accuracy of EMG predictions when the interface is trained sequentially: first the AE is trained in an unsupervised manner, and then the EMG predictor is trained with the resulting l-dimensional latent variables as input. The performance of the sequentially trained interface is worse than that of an EMG predictor trained directly on neural activity as input; the difference is small but significant (paired t-test, p=0.006). In contrast, simultaneous training of the EMG predictor with the AE showed no significant difference in performance between EMG predictions based on neural activity and latent variables. The AE was trained using a joint loss function that included unsupervised neural reconstruction and supervised regression loss for EMG predictions. Domain adaptation techniques were implemented by training the interface only on day-0 data and using CCA and KLDM to match latent variables across days. The CCA and KLDM methods were used to align latent variables across days by mapping neural activity onto latent activity and then aligning day-k latent activity to day-0. CCA aligns latent variables using a point-to-point correspondence, while KLDM matches first and second order statistics through a Gaussian approximation. The impact of CCA alignment is illustrated in 2D t-SNE visualizations showing differences in latent trajectories between day-16 and day-0, reflecting turnover in recorded neurons. The impact of turnover in recorded neurons is reflected in trajectories aligned using CCA and KLDM methods. Various transformations such as rotation, scaling, and skewing are observed, but CCA achieves good alignment due to point-to-point correspondence. The mechanism underlying KLDM alignment is illustrated, showing firing rates recorded from the hand area of the primary motor cortex during an isometric wrist task. EMG predictions from firing rates and latent variables are compared for accuracy. The ADAN architecture aligns high-dimensional neural recordings across days using the L1 norm of residuals. The discriminator module in ADAN is an AE that reconstructs neural activity from day-0 or day-k, with residuals calculated from the difference between inputs and outputs. The ADAN aligns day-k neural activity to that of day-0 by focusing on the L1 norm of residuals. This alignment results in the neural recordings being aligned and their latent representation improved. The aligner module of ADAN aligns the neural activity, which is then used as input to the fixed BMI. Residuals from day-0 and day-16 data are compared, with the aligned day-16 data showing improved results. The empirical probability distribution of latent variables on day-0 and day-16 is shown in FIG2, with results before and after alignment with ADAN. Performance of the BMI before and after domain adaptation with CCA, KLDM, and ADAN is summarized in FIG3 using %VAF in EMG predictions. Blue symbols represent the performance of an interface updated daily. The upper bound for potential benefits is shown through 2D t-SNE visualization of neural trajectories before and after alignment with CCA. Probability distributions of latent variables and vector residuals for day-0 and day-16 are compared before and after adversarial alignment using ADAN. The natural deterioration in performance of a fixed interface is illustrated. The performance of a fixed interface deteriorates due to neural recording degradation. CCA and KLDM show similar alignment results based on latent statistics, while ADAN improves stability by aligning based on residual statistics. ADAN's small but significant 6% improvement over competitors on day-16 is notable. ANOVA with Tukey's test showed significant improvement (p < 0.01) using domain adaptation with ADAN, outperforming other approaches. EMG prediction accuracy saturates at around 1 minute of training data, making it ideal for practical applications. Retraining interfaces daily sustains performance, while fixed interfaces without domain adaptation show performance deterioration. The study introduces a new method to stabilize a fixed Brain-Machine Interface against performance deterioration. Various domain adaptation methods are implemented, including Canonical Correlation Analysis and minimization techniques. Significant improvement is observed using ADAN for domain adaptation, outperforming other approaches. EMG prediction accuracy stabilizes with around 1 minute of training data, making it practical for real-world applications. The study introduces a new method, ADAN, for stabilizing a fixed Brain-Machine Interface by matching the empirical probability distribution of residuals in neural recordings. This method outperforms other approaches and requires minimal data for domain adaptation. Offline improvements in interface stability were observed, with potential for unconstrained movements. Online performance evaluation showed user adaptation ability but lacked correlation with offline accuracy. The study introduces a new method, ADAN, for stabilizing a fixed Brain-Machine Interface by matching the empirical probability distribution of residuals in neural recordings. Offline improvements in interface stability were observed, with potential for unconstrained movements. Online evaluation showed user adaptation ability but obscured performance improvements with domain adaptation. Additional experiments are needed to fully validate results and establish sustained use of the brain-machine interface. The study introduces ADAN, a method for stabilizing a fixed Brain-Machine Interface by matching the empirical probability distribution of residuals in neural recordings. Offline improvements in interface stability were observed, with potential for unconstrained movements. Online evaluation showed user adaptation ability but obscured performance improvements with domain adaptation. The deterioration in performance of a fixed interface without domain adaptation is shown, with the use of a VAE improving the Gaussian nature of latent variables' distribution but slightly reducing the BMI's ability to predict EMGs. Visualization of latent variables in 2D using t-SNE: A. Day-0, B. Day-16 before alignment, C. Day-16 after alignment to Day-0 using T&S, D. Day-16 after alignment to Day-0 using ADAN."
}