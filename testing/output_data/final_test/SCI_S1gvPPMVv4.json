{
    "title": "S1gvPPMVv4",
    "content": "Domain adaptation deals with the issue of test data differing from training data. New asymmetrically-relaxed distribution alignment approach improves upon standard domain-adversarial algorithms, with theoretical principles and empirical benefits shown on various datasets. Unsupervised domain adaptation aims to improve model performance on target distributions by leveraging unlabeled test data. Well-chosen assumptions can lead to algorithms with non-vacuous performance guarantees, such as under the covariate shift assumption. The covariate shift assumption BID7 BID11 states that while input marginals can vary between source and target, the conditional distribution of labels remains invariant across domains. Traditional approaches require source distributions to cover the target support, but recent deep learning papers propose adversarial training schemes for practical problems with non-overlapping supports. Domain-adversarial networks like BID5 and its variants have shown strong results in image recognition tasks by aligning distributions in representation space. The network consists of an encoder, label classifier, and domain classifier, with the goal of minimizing source error and aligning distributions. While BID5 is motivated by theoretical results, the theory is not sufficient to justify their method. In this paper, asymmetrically-relaxed distribution alignment is proposed as a method for aligning data across domains without requiring exact matching of latent-space distributions. The new distance is minimized when density ratios in representation space from target to source are upper bounded by a certain constant. This alignment ensures good target domain performance even under label distribution mismatch. The paper proposes relaxed distribution alignment for better target domain performance in adversarial domain adaptation. It addresses binary classification scenarios and introduces new distance metrics for aligning data distributions across domains. The paper introduces domain-adversarial learning for unsupervised domain adaptation, focusing on minimizing classification risk in the target domain by aligning distributions in the latent space. The paper proposes asymmetrically-relaxed distribution alignment in domain-adversarial learning for unsupervised domain adaptation. By bounding the density ratio in the objective, it aims to prevent failure under label distribution shift. The paper introduces asymmetrically-relaxed distribution alignment in domain-adversarial learning for unsupervised domain adaptation, aiming to prevent failure under label distribution shift. The theoretical result provides a risk bound for domain-adversarial methods with model-independent assumptions on data distributions, making a distinct contribution to the domain adaptation literature. The paper introduces asymmetrically-relaxed distribution alignment in domain-adversarial learning for unsupervised domain adaptation, aiming to prevent failure under label distribution shift. The theoretical result provides a risk bound for domain-adversarial methods with model-independent assumptions on data distributions, making a distinct contribution to the domain adaptation literature. In this section, several \u03b2-admissible distance metrics are derived that can be minimized with adversarial training, including f-divergence and Wasserstein distance modifications. The paper discusses asymmetrically-relaxed distribution alignment in domain-adversarial learning for unsupervised domain adaptation, introducing \u03b2-admissible distances that can be minimized with adversarial training. The approach is evaluated using Domain Adversarial Neural Networks (DANN) and different distance metrics, showing classification accuracy on target domains with/without label distribution shift."
}