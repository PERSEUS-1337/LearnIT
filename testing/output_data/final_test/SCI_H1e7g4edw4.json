{
    "title": "H1e7g4edw4",
    "content": "The text describes techniques for training high-quality image denoising models using single instances of corrupted images. A novel blind-spot convolutional network architecture enables efficient self-supervised training and Bayesian distribution prediction for improved denoising performance, bringing the model on par with fully supervised deep learning techniques. The text discusses various models used for image restoration tasks and introduces NOISE2NOISE training, where pairs of corrupted images are used for training. This approach allows the network to learn to output the \"average\" image under certain statistical conditions, making it possible to train the restoration model using corrupted data without the need for clean images. In this paper, the focus is on self-supervised training for image restoration without the need for clean images. The assumption of additive Gaussian noise between pixels allows for denoising performance without concessions. The inspiration comes from the NOISE2VOID (N2V) training technique, which uses individual noisy images as training data. The algorithm for image restoration uses individual noisy images as training data, assuming zero-mean and independent corruption between pixels. It is based on blind-spot networks that do not include the center pixel in the receptive field, allowing the same noisy image to be used as both input and target for training. This self-supervised approach predicts output pixel values using surrounding context without a separate reference image. The novel blind-spot network architecture improves denoising quality by combining network output with data in the blind spot, using four branches with restricted receptive fields in different directions. This simplifies the architecture and avoids a four-fold increase in trainable weights. The convolutional blind-spot networks combine multiple branches with restricted receptive fields to avoid increasing trainable weights. By modifying each layer to have a receptive field contained within one half-plane, the resulting network includes the center pixel. The resulting network includes the center pixel, so feature maps are offset by one pixel before combining them. Different layers like concatenation, summation, and 1\u00d71 convolution can be used without modifications. For convolution layers, to restrict the receptive field of a zero-padding layer to extend only upwards, a downwards offset of k = h/2 pixels is equivalent to using a shifted kernel. Downsampling and upsampling layers in image restoration networks extend the receptive field in all directions by default. The downsampling and upsampling layers in image restoration networks extend the receptive field in all directions by default. To address this issue, a method is proposed to restrict the receptive field for the pair of downsampling and upsampling layers by applying an offset to the data. This allows for information transfer in specific directions within the block, improving the performance of blind-spot networks. In blind-spot networks, training involves disconnecting pixel position information flow, but at test time, the network can predict output distributions using a negative log-likelihood loss function. The network outputs vectors of means and covariance matrices for each pixel, allowing for maximum a posteriori estimation during image restoration. The network outputs vectors of means and covariance matrices for each pixel, parameterizing the per-pixel covariance matrix as an upper triangular matrix to ensure positive semidefinite properties. The negative log-likelihood loss function is optimized during training, with the determinant of the triangular matrix clamped to avoid numerical issues. To avoid numerical issues, the determinant of the covariance matrix is clamped to a small positive epsilon. Noisy images are corrupted by additive uniform Gaussian noise with known standard deviation. The network output is independent of noise in the center pixel, allowing for calculation of the actual uncertainty. The maximum a posteriori denoising procedure aims to find the most likely clean value for each pixel based on noisy input and network predictions. The noisy valuex and output distribution predicted by the network are based on the blind-spot neighborhood \u2126. Bayes' theorem is applied to obtain the MAP objective, expressed as pdfs of Gaussian distributions. The mean and argmax of the product of two Gaussian distributions are calculated. The U-Net architecture is used for baseline experiments and blind-spot networks, with specific differences in layer configurations. The decoder stage removes layer DEC CONV1C and combines receptive field restricted branches to generate 384 feature maps. These maps are processed through three 1\u00d71 convolutions with varying output channels. The network uses leaky ReLU activation and was trained using Adam with default parameters. Training data consisted of random 256\u00d7256 crops from the ILSVRC2012 validation set, with training continuing until 1.2M images were shown. Test images were corrupted with Gaussian noise, and denoising quality was evaluated on four datasets, including BSD300. In the BSD300 dataset, only 100 validation images are used. A single-channel denoiser is trained using the luminance channel of the training images. The blind-spot noise-to-noise networks use a convolutional architecture and are trained without masking. The denoising quality of the Full setup is comparable to N2N and N2C, surpassing standard blind-spot denoising methods. The Full method described in Section 3 is our blind-spot training and denoising approach. The study compares different denoising methods, including blind-spot training and denoising, L2 training, and NOISE2NOISE training. Results show that the Full setup is comparable to N2N in terms of denoising quality. The Per-comp. setup tends to produce color artifacts, highlighting the importance of expressing color outputs as multivariate distributions. The study compares different denoising methods, showing that self-supervised training is effective for learning deep denoising models. PixelCNNs generate novel images in a scanline order, conditioning pixel colors using previously generated pixels. The training utilizes masked convolutions to prevent looking at pixels that have not been generated yet. A blind spot in PixelCNNs refers to intentional exclusions of certain pixels. Bayesian statistics have been applied to denoising methods like Non-local means and BM3D. Our blind-spot training uses a convolutional network to map neighborhoods to distilled outputs, identifying and regressing numerous neighborhoods from noisy training data."
}