{
    "title": "ByQpn1ZA-",
    "content": "Generative adversarial networks (GANs) are generative models that involve a game between a generator and a discriminator to learn the data distribution. The goal is to reach a Nash equilibrium where both players minimize their own costs. Recent research suggests that minimizing the divergence between the training and model distribution is crucial for learning in GANs, but this view may be overly restrictive. The discriminator provides learning signal during GAN training by adjusting gradients. GAN training involves the discriminator providing learning signals in situations where divergence minimization may not be useful. Empirical evidence suggests that GANs can learn distributions even when divergence minimization predicts failure. Gradient penalties, inspired by divergence minimization, are beneficial in various contexts. This challenges the idea of GAN training solely as divergence minimization and suggests a focus on approaching Nash equilibria through different trajectories. Models based on a competition between a generator network G and a discriminator network D. G represents a probability distribution p model (x) and generates samples from a noise vector z. The discriminator D(x) distinguishes between real and fake inputs. The goal is to recover the true data distribution p data. Various GAN training variants aim to minimize divergences between p data and p model. The study aims to assess whether improvements in GAN methods are due to underlying divergence changes or learning dynamics. Experiments are conducted on synthetic tasks with known data distribution to compare new models against baseline methods. Evaluation measures are used on real data to understand new approaches better. Contributions include clarifying terminology and discussing different losses in GAN models. The non-saturating GAN is recommended for GAN implementations and is the standard in practice. Gradient penalties designed for Wasserstein GANs or minimax GANs also improve the non-saturating GAN, leading to improved sample quality and diversity. Non-saturating GANs can fit problems that other models cannot. Non-saturating GANs are effective in fitting problems that Jensen-Shannon divergence minimization cannot handle. They do not suffer from vanishing gradients when applied to widely separated Gaussian distributions. The theoretical analysis is based on a zero-sum game where the generator aims to generate samples with low probability of being fake. Non-saturating GANs recommend using an alternative cost function to ensure generated samples are real. The non-saturating objective is used in all experiments. When the discriminator minimizes optimally, maximizing with respect to the generator is equivalent to minimizing the Jensen-Shannon divergence. Wasserstein GANs modify the discriminator to emit an unconstrained real number. Wasserstein GANs modify the discriminator to emit unconstrained real numbers instead of probabilities. The cost function for WGAN omits log-sigmoid functions and enforces Lipschitz smoothness by clipping discriminator weights. Gradient penalties are proposed to approximate the earth mover's distance between data and model distributions. The DRAGAN approach introduces a gradient penalty for regret minimization, encouraging the discriminator to be linear around the data manifold. This helps bring the set of possible discriminators closer to a convex set of linear functions. The minimax version of the game is used to define the loss, with the generator maximizing J(D) instead of minimizing J(G). The proposed gradient penalties aim to reduce mode-collapse in GANs. Two penalties, GAN-GP and a gradient penalty, are added to the non-saturating GAN objective. Experiment 1 training dynamics are visualized in two dimensions, showing convergence to the data distribution. The non-saturating GAN succeeds in the parallel line thought experiment, while Jensen-Shannon divergence minimization fails. DRAGAN-NS introduces a gradient penalty for the discriminator, keeping the generator loss unchanged. The goal is to assess the effectiveness of gradient penalties in GAN variants outside their original scope. In this study, the effectiveness of gradient penalties in GAN variants is evaluated outside their original scope. Three models are compared to control different aspects of training, focusing on the benefits obtained from the gradient penalty for Wasserstein GANs and DRAGAN. The goal is to determine if the benefit comes from the earth mover's distance properties or the penalty itself. The Nash equilibrium of minimax GANs is characterized by divergence, with various approaches to reaching this point. Divergence minimization helps understand training outcomes, but GAN training differs from gradient descent on divergence. The Jensen-Shannon divergence may not align sharp data and model manifolds early in learning, leading to vanishing gradients in traditional GAN models. The original GAN paper discusses the issue of vanishing gradients in traditional GAN models due to flat areas in D(x). However, this does not apply to non-saturating GANs, which can bring the model distribution closer to the data distribution even when highly separated. The paper recommends using the KL divergence process for probability distributions supported on low dimensional manifolds. Non-saturating GANs can learn on low dimensional manifolds without suffering from vanishing gradients. The recommended loss function prevents gradient vanishing, allowing the model to fit widely separated Gaussians effectively. Loss does not vanish in non-saturating GANs, enabling them to bring together widely separated Gaussian distributions. The generator loss amplifies small differences in discriminator outputs to recover strong gradients, allowing training by changing the loss rather than the discriminator. Parameterizing loss functions in terms of samples from distributions, rather than density functions, helps solve the problem of no common support in Jensen-Shannon divergence. The text discusses the learning process of GANs on pathological tasks with low-dimensional data manifolds. It evaluates convergence properties of GAN variants on known parameter distributions. An experiment is conducted with synthetic data on a one-dimensional line embedded in a higher-dimensional space. The experiment involves generating synthetic training data on a 1-D surface within a higher-dimensional space using random parameters. The generator and discriminator models are designed accordingly, with the discriminator being more complex to learn non-linear boundaries. This setup aims to explore sharp, non-overlapping manifolds and test convergence properties of different GAN losses. In the second experiment, synthetic training data is generated on a 1-D line with an overcomplete generator. The generator parameterizes a multivariate Gaussian distribution to represent a manifold with higher dimensionality. Convergence is evaluated using the square Fr\u00e9chet distance between true and fitted Gaussian distributions. The Fr\u00e9chet distance is defined as the squared l2 norm of x. GAN variants were trained for 200000 steps, with the generator updated once and the discriminator updated 5 times per step. Gradient penalties stabilize training and improve convergence. Non-saturating GAN succeeds in converging to the 1D data manifold but performs weaker in higher dimensions. Non-saturating GAN models can suffer from decreased performance if the learning rate is fixed. Updating the discriminator multiple times per generator update does not lead to vanishing gradients, but scaling to 100 updates results in worse performance. Gradient penalties, like GAN-GP, help with scaling the number of discriminator updates. An over-capacity generator can capture data distribution effectively with non-saturating GAN training. The robustness of GAN models is assessed by varying hyperparameters in experiments. Non-saturating GAN models are sensitive to hyperparameters, but gradient penalties improve their robustness. Wasserstein GAN formulations are generally robust. Performance differences between gradient penalties are minimal in certain settings, especially with one latent variable in Experiment 1. In Experiment 1, the effectiveness of gradient penalties on GAN models is assessed using different datasets. Various GAN formulations are tested, including non-saturating GAN with gradient penalties and Wasserstein GAN with gradient penalty. The experiments use datasets like Color MNIST, CelebA, and CIFAR-10 with specific data dimensionalities. The gradient penalty coefficient \u03bb is set to 10, and batch normalization is used. The GAN model successfully converges on synthetic data distribution without batch normalization. Adam optimizer with specific parameters and batch size was used. No noise was added to discriminator inputs to avoid confounding factors. Training steps varied for different datasets. The experimental results on real data for different GAN models were obtained by training for varying numbers of steps and using different hyperparameters such as learning rates and latent sizes. The WGAN-GP model had 5 discriminator updates in real data experiments, while other models only had one. Visualization of experiment 2 training dynamics in two dimensions shows the impact of different GAN models at 0, 5000, and 10000 steps. The non-saturating GAN suffers from mode collapse without proper initialization, but adding a gradient penalty stabilizes training. Evaluation of GAN performance is challenging due to the lack of a single metric, so visual inspection and three metrics are used. In addition to visual inspection, three metrics are used to evaluate the performance of GANs: Inception Score for visual appeal, MS-SSIM for sample diversity, and an Improved Wasserstein independent critic for assessing overfitting and sample quality. Different discriminator and generator architectures are controlled for in experiments, with results compared to DCGAN and WGAN papers. Sensitivity analysis and top 10 results are reported for each metric. The sample diversity measure is crucial in evaluating GAN performance, with high diversity potentially indicating a failure to capture data distribution. Applying gradient penalties to non-saturating GANs leads to more stable training, reducing instances of severe mode collapse. However, mode collapse can still occur with gradient penalties. Different GAN variants show varying performance on different datasets, with some models proving more robust than others. The study compares the robustness of different GAN models with gradient penalties. Results are presented in a box plot format, showing quartiles and top 10 results for each model. Two Inception Score metrics for CIFAR-10 are reported, one using a standard Inception network and another using a VGG style network trained on CIFAR-10. The study evaluates the robustness of various GAN models with gradient penalties. Results are presented in a box plot format, showing quartiles and top 10 results for each model. Inception Score metrics for CIFAR-10 are reported using both a standard Inception network and a VGG style network trained on CIFAR-10. The evaluation includes sample diversity analysis, subtracting average pairwise image similarity, and showcasing results in Figure 8. The Independent Wasserstein critic results are shown in Figure 7. Gradient penalties improve the robustness of non-saturating GANs to hyperparameters. WGAN-GP struggles to learn the data distribution on CelebA, leading to higher sample diversity compared to the test set. This is evident in Figure 8 (a), which displays sample diversity across hyperparameters. The study shows that gradient penalties improve the performance of non-saturating GANs across hyperparameters. WGAN-GP is closer to the reference values for most hyperparameters, indicating better results. Adding normal noise to the test set increases diversity, with too much diversity suggesting failure to capture the data distribution and too little indicating mode collapse. The study compares different GAN models on CIFAR-10 dataset. Non-saturating GAN with gradient penalties produces better samples and higher Inception Scores. These models are faster to train than WGAN-GP but perform similarly, offering a better computation versus performance tradeoff. GANs with penalties, specifically WGAN-GP models, show a decrease in sample quality when updating the discriminator only once per generator update. The Independent Wasserstein critic performs best on Color MNIST and CIFAR-10 datasets, but struggles with CelebA. Mode collapse is detected by the sample diversity metric and the critic, with reduced sample quality linked to hyperparameter settings. The critic's low negative Wasserstein distance indicates capturing distribution differences and reducing sample diversity in settings. Non-saturating GANs excel in learning true data distribution on low-dimensional problems where Jensen-Shannon divergence fails. Gradient penalty regularizers enhance training dynamics and robustness. Evaluating non-saturating GANs with similar regularizers helps distinguish improvements from optimizing different divergences. The comparison between two gradient penalties on non-saturating GANs showed no clear winner in terms of regularization effect. Applying both penalties did not result in better models, possibly due to conflicting optimization considerations. Several other gradient penalties have been proposed for stabilizing GAN training, including f-GAN-GP and Fisher-GAN, each with unique approaches to penalizing discriminator outputs. The Fisher GAN introduces a penalty in the framework of integral probability metrics, using augmented Lagrangians instead of a penalty method like WGAN-GP. Different regularizers like DRAGAN and f-GAN-GP have been proposed with distinct theoretical considerations. Future research will explore how these regularizers interact and stabilize GAN training. When varying the discriminator update count per generator update, using 100 discriminator updates per generator update leads to a poor distribution fit in non-saturating GAN. GAN-GP scales better with more discriminator updates, but increasing them doesn't always improve the model's match to the true distribution. Generated samples and evaluation metrics on real data are presented."
}