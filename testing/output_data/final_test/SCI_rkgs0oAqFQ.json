{
    "title": "rkgs0oAqFQ",
    "content": "Graph convolutional neural networks have shown potential for zero-shot learning by being sample efficient due to shared statistical strength in the graph structure. However, the use of Laplacian smoothing in current approaches can dilute knowledge from distant nodes, impacting performance. To address this, a Dense Graph Propagation (DGP) module with direct links among distant nodes is proposed, allowing exploitation of the hierarchical graph structure through additional connections based on relationships to ancestors and descendants. Our method for zero-shot image classification outperforms state-of-the-art approaches by incorporating a weighting scheme based on the hierarchical graph structure, allowing for precise modeling of class relationships. Prior knowledge is integrated through semantic descriptions, word embeddings, and knowledge graphs to classify images from unseen classes accurately. The current state-of-the-art approach in zero-shot image classification utilizes knowledge graphs and deep graph convolutional neural networks (GCNs) to regress classifier weights for each class. GCNs balance model complexity and expressiveness by allowing nodes to pass knowledge to their neighbors. In recent work, it has been shown that GCNs perform Laplacian smoothing for easier classification tasks, but in regression, extensive smoothing dilutes information and hinders accurate regression. Graph propagation in GCNs leads to convergence of features to the same representation, washing out information. The proposed dense graph propagation for node 'Cat' involves receiving knowledge from all its descendants. The dense graph propagation for node 'Cat' involves knowledge exchange with descendants and ancestors, using weights \u03b1 k for nodes k-hops away. A shallow GCN outperforms with fewer layers, as too many layers hinder knowledge propagation. A model-of-models framework is employed for zero-shot learning, predicting logistic regression classifiers on CNN features. The dense connectivity scheme proposed involves connecting nodes directly to descendants/ancestors to include distant information. A weighting scheme based on the distance between nodes is added to consider the importance of nodes closer to a given node, improving knowledge propagation in the graph. The proposed Dense Graph Propagation (DGP) module adds minimal parameters, is computationally efficient, and balances model flexibility with good predictions for unseen classes. A two-phase training scheme is used to adjust the pre-trained CNN's feature extraction stage to newly learned classifiers. The first phase trains DGP to predict CNN weights, while the second phase fine-tunes the CNN weights using the predicted weights and optimizing the cross entropy loss on seen classes. The Dense Graph Propagation (DGP) module improves zero-shot learning by utilizing a hierarchical knowledge graph structure and a novel weighting scheme. Experimental results on the 21K ImageNet dataset show over 50% relative improvement compared to previous best results. DGP is trained to predict classifier weights for each node/class in a graph constructed from the knowledge graph. Graph convolutional networks are a class of graph neural networks that utilize a knowledge graph to represent nodes with word embeddings. The network has descendant and ancestor phases for knowledge propagation. These networks are efficient in sharing statistical strength between classes, making them highly sample efficient. They were introduced in BID2 and later improved with a filtering approach based on recurrent Chebyshev polynomials in BID6. BID13 further simplified the approach for scalability and robustness in semi-supervised learning tasks. The approach of graph convolutional networks (GCN) has been simplified for scalability and robustness in semi-supervised learning tasks. Various viewpoints on zero-shot learning have been considered, including manifold alignment, linear auto-encoder, and low-rank embedded dictionary learning approaches. One early method proposed a model-of-model class approach, where a model is trained to predict models based on their description. Another work trained a graph convolutional neural network to predict logistic regression classifiers on pre-trained CNN features. The BID31 approach uses GCNs to predict logistic regression classifiers on pre-trained CNN features for zero-shot learning tasks, achieving impressive performance. Their model, DGP, predicts CNN weights for each class to classify unseen classes. Zero-shot classification aims to assign test data points to unseen classes. In zero-shot learning, test data points are assigned to unseen classes using semantic representation vectors and word embeddings. A knowledge graph is used to predict classifiers for unknown classes. Each node in the graph represents a distinct concept/class, with each concept represented by a word vector. The model uses a knowledge graph with word vectors to predict classifiers for unseen classes. It employs a propagation rule for convolutions on the graph, with trainable weight matrices for each layer. The model is trained to predict classifier weights for known classes by optimizing a loss function. The DGP for zero-shot learning utilizes a hierarchical graph structure to classify new images using features extracted from a pre-trained CNN. It avoids dilution of knowledge by intermediate nodes through a dense graph connectivity scheme with descendant and ancestor propagation phases. The DGP for zero-shot learning uses a hierarchical graph structure with ancestor and descendant connectivity patterns to prevent knowledge dilution by intermediate nodes. Two adjacency matrices are introduced to connect nodes directly to their ancestors and descendants, allowing for access to knowledge in their extended neighborhood without modification by intermediate nodes. The DGP for zero-shot learning utilizes a hierarchical graph structure with ancestor and descendant connectivity patterns to prevent knowledge dilution by intermediate nodes. Two adjacency matrices are introduced to connect nodes directly to their ancestors and descendants, allowing access to knowledge in their extended neighborhood without modification. Additionally, a distance weighting scheme is proposed to weigh the contribution of neighbors based on graph distance, and training of the model is done in two stages to predict last layer weights of a pre-trained CNN. The DGP for zero-shot learning utilizes a hierarchical graph structure with ancestor and descendant connectivity patterns to prevent knowledge dilution by intermediate nodes. In the second stage, the CNN is trained by optimizing cross-entropy loss on seen classes, with the last layer weights fixed to predicted weights from the DGP. The ResNet-50 BID11 model is used, along with the GloVe text model BID25, for feature representation. The DGP model consists of two layers with feature dimensions of 2048. The model consists of two layers with feature dimensions of 2048 and the final output dimension corresponds to the number of weights in the last layer of the ResNet-50 architecture, 2049 for weights and bias. L2-Normalization is performed on the outputs and ground truth weights. Dropout with a rate of 0.5 is used in each layer. The model is trained for 3000 epochs with a learning rate of 0.001 and weight decay of 0.0005 using Adam. Leaky ReLUs with a negative slope of 0.2 are utilized. The proposed DGP model is implemented in PyTorch and training and testing are done on a GTX 1080Ti GPU. Finetuning is done for 20 epochs using SGD with a learning rate of 0.0001 and momentum of 0.9. In our study, we conducted finetuning for 20 epochs using SGD with a learning rate of 0.0001 and momentum of 0.9. The DGP was evaluated against previous state-of-the-art on the ImageNet dataset BID7 for zero-shot learning. The evaluation included tasks of \"2-hops\" and \"3-hops\" based on the distance of classes from the ImageNet 2012 1K classes. Additionally, we assessed performance with training categories as potential labels. The evaluation compared the DGP model to other approaches like Devise, ConSE, and EXEM for zero-shot learning on the ImageNet dataset. Different splits like \"2-hops+1K\", \"3-hops+1K\", and \"All+1K\" were considered, with training categories as potential labels. Devise linearly maps visual information to semantic word embeddings, ConSE projects image features into a semantic space, and EXEM creates visual class exemplars. EXEM BID4 creates visual class exemplars by averaging PCA projections of images from the same seen class. SYNC aligns semantic and visual spaces, adding phantom classes to connect seen and unseen classes. GCNZ BID31, the current state of the art, uses a GCN to predict last layer weights of a CNN. Our proposed SGCN model, utilizing non-symmetric normalization, outperforms previous methods on ImageNet datasets, showing significant improvements in accuracy. The two-stage finetuning approach in our DGP model yields better results compared to ConSE, EXEM BID4, and GCNZ BID31, with over 50% relative improvement in Top-1 accuracy on the 21K ImageNet \"All\" dataset. Our methods show significant improvements in accuracy, with a 50% relative improvement for Top-1 accuracy on the 21K ImageNet \"All\" dataset. DGP outperforms baseline models, especially on the \"All\" task, and consistently improves over the SGCN model. Ablation studies highlight the impact of finetuning and weighting of neighbors for the 2-hop scenario. The proposed weighting scheme in SGCN is crucial for the dense approach, with finetuning leading to improved results. Qualitative results show that DGP and SGCN provide coherent top-5 results, with DGP including the opener in the predictions. All methods struggle with predicting the opener, often predicting a plane instead. The prediction task on the dataset for zero-shot learning is challenging due to fine granularity classes like various types of squirrels, planes, and furniture. Results from testing classifiers show that SGCN and DGP outperform the previous state-of-the-art approach GCNZ, with SGCN performing better for low k in Top-k accuracy and DGP excelling for larger k. Baselines using ConSE with AlexNet and ResNet-50 are also included in the comparison. In the evaluation of zero-shot learning models, DGP outperforms SGCN for larger k in the Top-k accuracy measure. DGP tends to prioritize prediction for the closest training classes in Top-1 prediction. This tradeoff between unseen and seen classes can be controlled by including a novelty detector or using calibrated stacking to rescale prediction scores. Zero-shot learning models should perform well on both unseen and seen classes. In experiments analyzing zero-shot performance, the model's performance on 1000 seen classes is compared to the introduction of additional unseen classes. Results show outperformance of our methods over GCNZ on Hit@1 and Hit@2 accuracy. Weighting scheme validation shows that weighting allows our approach to weigh distance neighbors less. In the first stage, ancestors aggregate information from immediate descendants to distribute it later. Distant neighbors have less impact in the final stage. To ensure scalability, the adjacency matrix should be sparse. Our approach utilizes knowledge graph structures with few ancestors and descendants. The adjacency matrix for ImageNet hierarchy has low density. SGCN has 4,810,752 weights, while DGP adds additional weights for trainable parameters. In contrast to previous approaches, our proposed method DGP benefits from shallow networks for zero-shot learning. DGP exploits the hierarchical structure of the knowledge graph with a dense connection scheme to improve information propagation. Experiments show that DGP outperforms previous state-of-the-art methods. Future work aims to explore advanced weighting mechanisms to enhance DGP's performance further compared to SGCN. The qualitative results of the finetuned Graph Propagation Module (GPM) and Dense Graph Propagation Module (DGP) are compared to ResNet and GCNZ. Two-phase propagation and analysis of the number of layers show performance improvements in information propagation. The performance difference between SGCN, GCNZ, and reported results in BID31 is explained in the context of using additional hidden layers in the GCN for the 2-hops experiment. Results show stability as the number of classes increases from 2-hops to all in the dataset."
}