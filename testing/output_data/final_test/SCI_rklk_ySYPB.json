{
    "title": "rklk_ySYPB",
    "content": "In recent years, adversarial attacks and defenses have been proposed, revealing the non-robust nature of seemingly robust models. Provable robustness guarantees are sought after to address this issue. While existing models offer robustness against specific $l_p$-perturbation models, they lack guarantees against other $l_q$-perturbations. A new regularization scheme, MMR-Universal, for ReLU networks is proposed to enforce robustness against $l_1$ and $l_\\infty$ perturbations, leading to the first provably robust models against any $l_p$-norm for $p\\geq 1. The vulnerability of neural networks to adversarial manipulations poses challenges for safety critical systems like autonomous driving and medical applications. Neural networks are vulnerable to perturbations that can change their decisions, raising concerns about their reliability and making them susceptible to adversarial attacks. Various empirical defenses have been proposed, but more sophisticated attacks have shown these defenses to be ineffective. Even adversarially trained models are not always robust when attacked with certain perturbations. Various approaches have been proposed to address the vulnerability of neural networks to perturbations, including extending attack models and providing provable guarantees. New training schemes aim to enhance robustness against adversarial attacks. Various approaches have been proposed to enhance the robustness of neural networks against adversarial attacks. Recent studies focus on proving robustness against different types of perturbations, but most are limited to specific norms or attack types. This paper aims to achieve robustness against all l p -bounded attacks for p \u2265 1, addressing cases where none of the l p -balls are contained within each other. The paper aims to achieve robustness against all l p -bounded attacks for p \u2265 1, showing that certifying the union of l 1 -and l \u221e -balls is more complex than being robust in only one of them. A technique is proposed to train piecewise affine models that are simultaneously provably robust to all l p -norms with p \u2208 [1, \u221e]. The paper introduces a technique to train piecewise affine models that are provably robust to all l p -norms with p \u2208 (1, \u221e), independent of input space dimension. Experimental results demonstrate the effectiveness of the method on various datasets. The paper discusses ReLU networks and their robustness against adversarial manipulations, extending previous work on single l p -perturbations to simultaneous guarantees for all l p -perturbations. The method is applicable to piecewise affine activation functions like ReLU or leaky ReLU, showing promising results on different datasets. Croce et al. (2019b) describe the activation function \u03c3 as max{0, t} for ReLU in neural networks with L hidden layers. They present a recursive definition of the classifier f and the polytope Q(x) containing x. The forward pass through the network computes V (l) and b (l) for every layer, simplifying the composition of affine functions. The polytope Q(x) is defined by intersecting half spaces, allowing for the computation of distances to hyperplanes. The l p -robustness r p (x) of a classifier f at a point x, belonging to class c, wrt the l p -norm is defined as the optimal value of an optimization problem with constraints on the input. The smallest l p -distance to x of a point classified differently from c is r p (x), with guarantees provided by a theorem from Croce et al. (2019a). The paper discusses deriving bounds on the robustness r p (x) for any p \u2208 (1, \u221e) using information on r 1 (x) and r \u221e (x). Standard l p -norms inequalities do not yield meaningful bounds on the l p -robustness inside the union of the l 1 -and l \u221e -ball. Visualization of the l 2 -ball in the union of l 1 -and l \u221e -balls is presented in Figure 1. The largest l2-ball in the convex hull is larger than in the union of l1 and l\u221e-ball. The minimal lp-norm of the complement of this union and its convex hull is derived, taking into account specific information about x1 and x\u221e. Affine classifiers guarantee for B1 and B\u221e implies a guarantee for their convex hull C. The minimal lp-norm over Rd \\ C is characterized for any p \u2265 1, with results varying for d = 784 and d = 3072. The values provided by one approach are much larger than those of another. The minimal lp-norm over Rd \\ C is characterized for any p \u2265 1, with results varying for d = 784 and d = 3072. The values provided by one approach are much larger than those of another. The expression in Theorem 3.1 is exact, independent of dimension d, unlike the expression for the minimal lp-norm over Rd \\ U 1,\u221e. Visual and quantitative comparisons are provided in Figures 1 and 2, showing the differences in the l2-balls fitting inside U 1,\u221e or the convex hull C in R3. The blue line corresponding to the minimal l2-norm over Rd \\ C is significantly higher than the other approaches. The blue line for (6) is notably higher than the others in Figure 2, indicating an advantage that increases with dimensionality. The l p -balls in C can be larger than those in U 1,\u221e. Enlarging linear regions in piecewise affine networks can automatically fit l p -balls within them, leading to robustness guarantees. The robustness of a continuous piecewise affine classifier, such as a ReLU network, at a point x with respect to any l p -norm with p \u2265 1 is achieved by widening linear regions around training points using MMR-l p. This approach aims to make the classifier resistant to l p -adversarial attacks and easily verifiable. The novel geometrical motivation provided by Theorem 3.1 justifies MMR-Universal, enforcing l1 and l\u221e guarantees simultaneously. The loss function minimized during training includes the cross-entropy loss. The regularizer pushes polytope boundaries and decision hyperplanes to achieve robustness close to specified values. This enhances l p -robustness for p \u2208 (1, \u221e). The regularization parameters \u03bb 1 and \u03bb \u221e balance the weight of the l 1 -and l \u221e -term in the regularizer, along with the cross-entropy loss. The terms of MMR-Universal penalize misclassification by considering the k B closest hyperplanes, expanding linear regions around training points effectively. The regularization parameters \u03bb 1 and \u03bb \u221e balance the weight of the l 1 -and l \u221e -term in the regularizer, along with the cross-entropy loss. The terms of MMR-Universal penalize misclassification by considering the k B closest hyperplanes, expanding linear regions around training points effectively. The large number of hyperplanes defining each polytope influences the neighboring linear regions of Q(x), impacting the robustness bounds at x. Established methods to compute lower bounds on robustness are ineffective with normally trained models, as their effectiveness is related to the stability of ReLU units when perturbing the input x within a given l p -ball. MMR-Universal aims to have hyperplanes far from x in l p -distance to improve robustness certification. This allows for certifying models trained with MMR-Universal using methods from Wong & Kolter (2018) and Tjeng et al. (2019). The text discusses the comparison of models using MMR-Universal regularizer with state-of-the-art methods for robustness and adversarial training. Evaluation is based on robust test error within l p -balls with p \u2208 {1, 2, \u221e}. Lower bounds are determined by the fraction of points vulnerable to attacks within the l p -balls, evaluated using the PGD-attack. The text aims to be consistent with previous literature in choosing values of p. Equation (6) provides a value for l2-robustness, with p values chosen for robust test error computation. Adversarial examples with l1-attack and l\u221e-norm are evaluated, showing the difficulty of being robust in the union of l p -balls. CNNs are trained on MNIST and Fashion-MNIST datasets. In Table 2, test error (TE) is reported for CNNs trained on MNIST and Fashion-MNIST datasets with adversarial training using different regularizers. Lower (LB) and upper (UB) bounds on robust test error are also provided for l1, l2, and l\u221e norms. MMR-Universal is the only method that provides non-trivial upper bounds on robust test error for all datasets, outperforming existing methods in certifying the union of l1, l2, and l\u221e norms. The test error may slightly increase compared to other provably robust methods, but MMR-Universal shows superior performance in providing guarantees for adversarial examples. The MMR-Universal method offers robustness guarantees for multiple l p -balls, establishing a baseline for future research. The proof involves showing that the minimum l p -norm over R d \\ C lies on the boundary of C. The text discusses the conditions for a set S to define a face of a convex set C. If a set S contains vertices of \"positive type\" 1 e j, then it must have certain properties to be considered a face of C. The matrix P formed by the points in S must have full rank for the origin to belong to any hyperplane containing S, indicating that S spans a face of C. The text discusses the conditions for a set S to define a face of a convex set C. If S spans a face of C, then the matrix P formed by the points in S must have full rank. The hyperplane \u03c0 generated by S contains points b such that there exists a unique solution for the linear system P a = b. The vector v is the unique solution of P a = b, and any vector b \u2208 R d such that b, v = 1 belongs to \u03c0. H\u00f6lder inequality is applied to show that for any b \u2208 \u03c0, where 1 p + 1 q = 1. After applying H\u00f6lder inequality, a unique solution v is found for the linear system P a = b, where b \u2208 \u03c0. The vector v has components that are either 1 or -1, and the inner product between each row of A^T and v is a lower bound on the l1-norm of v. The linear system has a unique solution u, v = v1 when u_i = sgn(v_i) for every non-zero component of v. The vector v2 can only have one non-zero component, which is equal to a certain value. After applying H\u00f6lder inequality, a unique solution v is found for the linear system P a = b, where b \u2208 \u03c0. The vector v has components that are either 1 or -1, and the inner product between each row of A^T and v is a lower bound on the l1-norm of v. The linear system has a unique solution u, v = v1 when u_i = sgn(v_i) for every non-zero component of v. The vector v2 can only have one non-zero component, which is equal to a certain value. Thus, for S to define a face of C, h = k if \u03b1 > 0, h \u2208 {k \u2212 1, k} if \u03b1 = 0. Once v is determined, it can be shown that there exists b * \u2208 \u03c0 for which equality is achieved. If b * does not lie in a face of C, a contradiction arises, leading to the conclusion that the b * realizing equality lies in a face of C. After applying H\u00f6lder inequality, a unique solution v is found for the linear system P a = b, where b \u2208 \u03c0. The vector v has components that are either 1 or -1, and the inner product between each row of A^T and v is a lower bound on the l1-norm of v. The improvement of the robustness guarantee by considering the convex hull instead of the union is increasing with dimension and is \u2248 3. The percentage of adversarial perturbations given by the PGD-attack wrt l p with budget p which have l q -norm smaller than q is computed in Table 3. The most relevant statistics are about the relation between the l1-and l\u221e-perturbations. The adversarial examples found by l1-attacks are very different from those obtained by l\u221e-attacks, as the perturbations are non-overlapping and exploit diverse regions of the input space. Adversarial manipulations wrt l1, l2, and l\u221e do not overlap, with l2 adversarial examples contained in the l\u221e-ball for MNIST and F-MNIST datasets. The choice of norm p is meaningful, as the adversarial perturbations are distinct and do not intersect. The interaction of different kinds of perturbations changes depending on whether one considers empirical or provable robustness. Training for provable l_p-robustness does not necessarily yield non-trivial guarantees for l2. Models certified as robust wrt the l\u221e-norm have large upper bounds on robust test error in the l2-ball, indicating a distinction between empirical and provable robustness. Training for provable l p -robustness does not always guarantee provable l q -robustness for q = p, even with small lower bounds for both p and q. Upper bounds on robust test error are computed using different methods for l p -norms, with Wong & Kolter's method applicable to all l p -norms and Tjeng et al.'s method only for the l \u221e -norm due to its high computational cost. Wong & Kolter's method is more versatile, while Tjeng et al.'s method relies on presolvers for efficiency, particularly effective for l \u221e. The method of Wong & Kolter (2018) is applicable to all l p -norms, with tighter bounds for l \u221e compared to l 1 and l 2. The convolutional architecture used consists of two layers with 16 and 32 filters, followed by a fully connected layer. Various training models are employed, and models are trained using PGD-attack for different norms and epochs. The MMR-Universal experiments use a batch size of 128 and train models for 100 epochs using Adam. For MMR-Universal, batch size 128 is used for training models for 100 epochs with Adam optimizer. Learning rates vary for different datasets. Data augmentation techniques are applied on CIFAR-10 dataset. Training schedule for \u03bb p and hyperparameter grid search are utilized to enhance stability. Optimal values of hyperparameters are determined through empirical grid search. The optimal values of hyperparameters (\u03b3 p and \u03bb p) vary across datasets. For example, values for (\u03bb 1 , \u03bb \u221e ) used are (3.0, 12.0) for MNIST, (3.0, 40.0) for F-MNIST, (3.0, 12.0) for GTS, and (1.0, 6.0) for CIFAR-10. Test error is computed on the full test set, while upper and lower bounds on robust test error are calculated on the first 1000 points of the test sets using FAB-attack. The evolution of test error, upper bounds on robust test error, and upper bounds on test error under attacker exploitation are shown for each dataset during training. The statistics on the robustness are computed at various epochs using different methods and parameters. The upper bounds on the test error are shown for different l p -balls, with specific directions for the update step. The Liner Region Attack and MIP with a timeout of 120s are also utilized. The clean test error and upper bounds on robust test error are illustrated in Figure 3. The clean test error and upper bounds on the robust test error are evaluated at different epochs using various methods and parameters. The test error decreases across epochs, while the upper bounds generally improve during training, demonstrating the effectiveness of MMR-Universal. Training with MMR-l p +AT-l q on MNIST shows improved upper bounds, indicating the effectiveness of MMR-Universal. Testing with p, q \u2208 {1, \u221e} reveals that training with MMR alone does not guarantee robustness in all norms, even with adversarial training. The upper bounds reach 100% for at least one norm in both models analyzed. Note that results for l \u221e do not include the MIP formulation of Tjeng et al. (2019)."
}