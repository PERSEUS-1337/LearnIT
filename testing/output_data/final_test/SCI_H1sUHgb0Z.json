{
    "title": "H1sUHgb0Z",
    "content": "Supervised learning relies on annotated examples from noisy crowdsourcing platforms like Amazon Mechanical Turk. Practitioners collect multiple labels per example to mitigate noise. A new algorithm is proposed for modeling labels and worker quality from noisy crowd-sourced data, optimizing worker quality estimation and model updating. The algorithm proposed optimizes worker quality estimation and model updating from noisy crowd-sourced data. It can estimate worker quality with just one annotation per example and performs better when labeling many examples once. Experiments on ImageNet and MS-COCO confirm the algorithm's benefits in supervised learning with large annotated datasets. Most practitioners use crowdsourcing platforms like Amazon Mechanical Turk for cost-effective simple tasks due to the high expense of expert work. Crowd-workers provide noisy annotations due to varying skill levels and a compensation structure that prioritizes speed over accuracy. To address this, multiple labels are collected per example and aggregated through majority voting. Various algorithms have been proposed to estimate ground truth from noisy annotations since the 1970s, with BID4 suggesting a probabilistic model for estimating worker skills and ground truth. In the early 1970s, BID4 proposed a probabilistic model to estimate worker skills and ground truth labels using EM. BID27 and BID29 generalized the Dawid-Skene model by estimating example difficulty. Crowdsourcing and ML research often work in isolation, with few papers combining noisy labels and worker identities to estimate ground truth. This paper introduces a new supervised learning algorithm that combines modeling and crowd-sourcing to estimate worker qualities and improve model accuracy. The algorithm alternately models labels and worker quality using the EM algorithm, addressing a limitation of prior work. It shows that accurate worker quality estimates can be obtained even with only one label per example, as long as each worker labels enough examples. This approach overcomes a significant hurdle in achieving better model performance. This paper presents a new algorithm that combines modeling and crowd-sourcing to estimate worker qualities and improve model accuracy. The algorithm provides theoretical guarantees on performance and analyzes two alternating steps: estimating worker qualities and learning a model. It is shown that accurate worker quality estimates can be obtained with minimal labeling, validating the approach on various datasets. When the total annotation budget is fixed, it is best to collect a single label per training example for as many examples as possible. This paper applies the approach to classification problems, but the algorithm's main ideas can be extended to other supervised learning tasks. Traditional crowdsourcing tackles the challenge of aggregating noisy labels, with methods like majority voting or agreement-based algorithms that estimate worker skills and ground truth labels using EM or similar techniques. EM algorithm with spectral initialization achieves minimax optimal performance under the Dawid-Skene model, while a message-passing algorithm for estimating binary labels performs better than majority voting. Our algorithm outperforms majority voting in the low-redundancy setting, accurately estimating worker quality even with just one label per example. Previous crowdsourcing papers incorporate supervised learning models to estimate ground truth labels. The Dawid-Skene model is generalized and its parameters are estimated using supervised learning. A joint probability model is considered for observed image features, ground truth labels, and worker labels. The true labels are estimated using alternating minimization. Another joint probability model is proposed where the optimal labeling function gives the ground truth labels. Expectation maximization is used to learn the optimal labeling function and true labels. The supervised learning model is trained using intermediate predictions of labels. The curr_chunk discusses the limitations of existing algorithms in estimating worker quality for multi-class classification tasks. Unlike previous works that assume noiseless annotations, this work considers unreliable workers with varying skills. The algorithm proposed in this study uses an iterative estimation technique and incorporates worker quality parameters differently from other approaches. Theoretical results are not limited to linear classifiers, unlike some previous works. The work employs active learning to filter out examples with high confidence labels and collect additional labels for the remaining examples. The algorithm estimates ground truth labels using an EM-based approach. Several papers analyze the usefulness of repeated labeling based on worker quality and classifier expressiveness. BID16 argues that classifier expressiveness is crucial, but previous works do not utilize supervised learning predictions to estimate ground truth labels. BID20 introduced an unbiased loss function for binary classification with noisy labels, but the weights become unstable with high noise rates. BID23 and BID10 learn noise rates as model parameters, while BID7 trains individual softmax layers. Recent works have focused on noise-robust models and training individual softmax layers for experts. However, these approaches are not scalable to crowdsourcing scenarios with thousands of workers. The underlying true distribution generates pairs (X, Y) where Y has possible labels from set K. A pool of m workers provides noisy labels for samples X, with each worker selecting r random labels independently. In crowdsourcing scenarios, workers provide noisy labels for samples, with each worker selecting random labels independently. The redundancy factor r is assumed to be the same for each sample, but can vary. The confusion matrix \u03c0(a) represents the probability of a worker labeling an item in class k as class s, independent of the specific item chosen. The distribution of labels Z is determined by the confusion matrix. In crowdsourcing scenarios, workers provide noisy labels for samples. The confusion matrix represents the probabilities of correct and incorrect labeling. Workers are selected randomly from a pool, and a batch is assigned to each example. The learning algorithm sees corrupted labels and worker information. The goal is to learn a predictor function with minimal risk under the true distribution, using noisy labels to compute the loss function. The modified loss function involves estimating confusion matrices and true labeling function under the Dawid-Skene model. The likelihood function is maximized to estimate worker confusion matrices and true labeling function using the 'Model Bootstrapped EM' algorithm. In BID4, the 'Model Bootstrapped EM' (MBEM) algorithm is proposed to estimate confusion matrices and the true labeling function. MBEM converges under mild conditions with worker quality above a threshold and sufficient training examples. The iterative algorithm estimates the true labeling function given worker confusion matrices and vice-versa. BID20 suggests minimizing an unbiased loss function for learning the predictor function f. The weighted sum of the original loss over each possible ground truth label is calculated based on worker confusion matrices in binary classification. However, the weights become unstable when the probabilities of correct classification are close to 1/2, limiting practical usefulness. A new proposal suggests weighing the loss function according to the posterior distribution of the true label given observed labels and estimated confusion matrices. The proposed method suggests weighing the loss function based on the posterior distribution of the true label given observed labels and estimated confusion matrices. This approach is robust to noise levels and outperforms the unbiased loss function in practice. The paper proposes a method to estimate confusion matrices of workers with low redundancy using a supervised learning model. The EM algorithm is used to estimate ground truth labels and confusion matrices alternately. The paper proposes a method to estimate confusion matrices of workers with low redundancy using a supervised learning model. The alternating maximization algorithm updates estimates of ground truth labels and confusion matrices. The model is trained on majority vote labels and uses model predictions as estimates. The effectiveness of the estimate depends on the expressiveness of the hypothesis class and the model's robustness to noise. Model Bootstrapped EM is an iterative algorithm for efficient learning from noisy labels with small redundancy. It identifies workers as hammers or spammers based on their agreement with the model, and returns the best predictor function in the hypothesis class F by using a weighted majority vote. In Model Bootstrapped EM, weights of the loss function are computed using a weighted majority vote to estimate worker confusion matrices. The process involves multiple rounds to achieve substantial improvements over baselines. The algorithm initializes posterior distribution and estimates confusion matrices and prior class distribution. The guarantee on excess risk for the predictor function is provided. The excess risk for the predictor function f is guaranteed based on the VC dimension of the hypothesis class F. The accuracy of \u03c0 estimated in the second round is also guaranteed. The average worker quality is captured by \u03b1 and \u03b2, with a concise bound given for the special case when all workers are identical. The excess risk for predictor function f is guaranteed based on the VC dimension of hypothesis class F. The accuracy of \u03c0 estimated in the second round is also guaranteed. The average worker quality is captured by \u03b1 and \u03b2, with a concise bound given for the special case when all workers are identical. Theorem 4.1 states that for binary classification with 0-1 loss function, Algorithm 1 returns f and \u03c0 after 2 iterations, satisfying certain conditions with high probability. The excess risk for predictor function f is guaranteed based on the VC dimension of hypothesis class F. The accuracy of \u03c0 estimated in the second round is also guaranteed. The average worker quality is captured by \u03b1 and \u03b2, with a concise bound given for the special case when all workers are identical. Theorem 4.1 states that for binary classification with 0-1 loss function, Algorithm 1 returns f and \u03c0 after 2 iterations, satisfying certain conditions with high probability. Where the optimal choice of redundancy r is 1 when the worker quality (1 \u2212 \u03c1) is above a threshold, particularly if (1 \u2212 \u03c1) \u2265 0.825 then label once is the optimal strategy. The algorithm MBEM is optimal with r = 1 even for lower worker quality. Experimental results on various datasets confirm this. Comparison against baselines like MV, weighted-MV, EM, weighted-EM, oracle weighted EM, and oracle correctly labeled is conducted. The curr_chunk discusses the use of oracle models in training, with two models of worker skill: hammer-spammer and class-wise hammer-spammer. The confusion matrices are used to analyze the performance of these models. The curr_chunk discusses the generation of confusion matrices for worker skill models and the use of noisy labels in training. A Python implementation of the MBEM algorithm is available for download. The dataset consists of 60K images divided into 10 classes, with 50K images used for training and 10K for testing. The curr_chunk discusses using noisy labels generated from synthetic workers with confusion matrices for training a ResNet model on 50K images. The experiments are conducted with a 20-layer ResNet achieving 91.5% accuracy. The MBEM algorithm is run for 2 rounds with a uniform prior distribution. Results are reported with mean accuracy and standard error. Plots for CIFAR-10 dataset under different worker skill distributions are shown. In experiments using synthetic workers with confusion matrices, MBEM algorithm significantly outperforms baselines and closely matches Oracle weighted EM. Weighted-MV and weighted-EM perform better than MV and EM, confirming the effectiveness of weighing the loss function with posterior probability. MBEM excels at small redundancy, but EM works as well at large redundancy. When the total annotation budget is fixed, it is optimal to collect one label per example for as many examples as possible. Increasing redundancy from 1 to 5 improves the performance of weighted-EM, showing that collecting redundant annotations for fewer examples may be better for estimating worker qualities. MBEM consistently outperforms the standard EM algorithm, achieving the lowest generalization error with many singly annotated examples. Unlike standard EM, MBEM can estimate worker qualities even with singly annotated examples by comparing them with model predictions. The ImageNet-1K dataset contains 1.2M training examples and 50K validation examples, with a test set divided into 10K for validation and 40K for testing. Using a ResNet-18 model, top-1 accuracy is 69.5% and top-5 accuracy is 89% on ground truth labels. Simulated workers mislabel examples to only one of 10 possible classes, with a total of 1000 simulated workers used in the study. In experiments with a total annotation budget of 1.2M, redundancy varied from 1 to 9, with MBEM outperforming baselines by achieving the minimum generalization error. The real raw annotations collected from MS-COCO were used, with each image containing approximately 3 objects on average. The study used raw noisy annotations from MS-COCO with each image having around 3 objects on average. Workers labeled 80 possible objects with disagreements. The model was trained using ResNet-98 and independent binary classifiers for each object class. MBEM algorithm outperformed others in generalization F1 score. The study introduced a new algorithm, MBEM, for learning from noisy crowd workers. It significantly outperformed majority voting and EM at small redundancy levels. The findings suggest that labeling many examples once is better than labeling few multiple times when worker quality is above a certain threshold. The study introduced MBEM, a new algorithm for learning from noisy crowd workers, outperforming majority voting and EM at low redundancy levels. Future work includes incorporating the approach into active query schemes to route examples to annotators based on data and worker confusion matrices. The error in confusion matrix estimation is bounded by a formula with probability at least 1 - \u03b4. In the first round, the error in confusion matrix estimation is bounded by a formula with probability at least 1 - \u03b4. The second round applies Lemma A.1 with posterior distribution P \u03c0, bounding the error in \u03c0. Lemma A.2 is then applied to obtain the desired bound for the given probability of error \u03b4. The risk of decision function f with respect to the modified loss function \u03c0 is characterized by empirical \u03c0-risk on samples. The excess risk of decision function f under the modified loss function \u03c0 is computed using the VC dimension of hypothesis class F and a universal constant C. The inequality and equality used in the equations are derived from the minimizer of R \u03c0 ,D\u03c0 and the basic excess-risk bound. The 0-1 loss function and the definition of \u03b2 \u03c0 play a key role in the calculations. The excess risk due to the unbiasedness of the modified loss function \u03c0 is determined using the notations \u03c1 \u03c0 and \u03c4 \u03c0 for any function f \u2208 F. The excess risk of decision function f under the modified loss function \u03c0 is determined using the unbiasedness of \u03c0. The calculation involves the weighted majority vote of workers and the definition of \u03b1(y). The proof of Lemma A.2 involves variables A, B, C, D, E depending on a \u2208 [m], k, s \u2208 K."
}