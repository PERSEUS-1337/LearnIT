{
    "title": "SkxhzT5qIB",
    "content": "An end-to-end trainable approach for optical character recognition (OCR) on printed documents is presented. It involves predicting a two-dimensional character grid ('chargrid') representation of a document image and using object detection techniques to identify individual character instances. Our method for optical character recognition (OCR) outperforms previous approaches in accuracy, is easily parallelizable on GPU, and is faster and easier to train. OCR on printed documents is a well-known problem with various solutions available. Current state-of-the-art OCR solutions involve complex pipelines, while we treat OCR as a semantic segmentation and object detection task. Our new OCR pipeline, Chargrid-OCR, frames the OCR problem as an ultra-dense instance-segmentation task for characters without relying on pre-processing stages. It predicts a chargrid representation of the input document and introduces novel post-processing steps for fast and accurate OCR, outperforming line-based pipelines like Tesseract 4. Chargrid-OCR is an OCR method that predicts character segmentation masks and object bounding boxes in one step, without relying on pre-processing stages. It outperforms line-based OCR pipelines like Tesseract 4 by framing the OCR problem as an ultra-dense instance-segmentation task for characters. The character segmentation mask classifies each pixel into a character class and detects a bounding box around each character. The chargrid representation maps each pixel occupied by a character to a unique index. The model predicts the chargrid representation of the complete document using a semantic segmentation network and class agnostic object detection for individual character prediction. The model uses class agnostic object detection to predict character boxes for instance segmentation. The input is an image with text, and the output includes a segmentation mask (chargrid) and bounding boxes. The architecture is based on a fully-convolutional encoder-decoder structure with decoders for semantic segmentation. The model utilizes class agnostic object detection for character box prediction in instance segmentation. It employs a fully-convolutional encoder-decoder structure with two decoders for semantic segmentation and bounding box detection. The model is trained using categorical cross-entropy and Huber loss. Non-maximum suppression is applied to eliminate redundantly predicted box proposals, but the high number of proposals can lead to computational bottlenecks. To address this issue, a preliminary step is introduced before NMS. To speed up the object detection process, a preliminary step called GraphCore is introduced before NMS. A directed graph is constructed where each candidate pixel predicts the offset to the center of its box. By selecting only pixels towards the center of a bounding box, the number of candidates for NMS is reduced. Additionally, post-processing involves clustering characters to form word boxes based on predicted word centers, allowing for the prediction of rotated words. Ground-truth data in the form of character bounding boxes is required for each document input image. The dataset was generated by synthetically rendering pages from English Wikipedia content and scanned financial reports. Ground truth labels were obtained through data augmentation and OCR processing. The model was evaluated on various datasets including Business letters and UNLV using Word Recognition Rate. The model was evaluated on various datasets including Business letters and UNLV using Word Recognition Rate. The accuracy of OCR was measured using the Nm Nu+Nm formula, with Nm and Nu representing matched and unmatched words. Different versions of the model were trained and compared against Tesseract v3 and v4, with v4 being the state-of-the-art released in Oct 2018. The study evaluated different models trained on various datasets and compared them to Tesseract v3 and v4. The baseline model \"ChargridOCR-32\" outperformed Tesseract v3 but not v4. A model with higher capacity \"ChargridOCR-64\" trained on Wiki+EDGAR surpassed Tesseract on all datasets but required more computational resources. The study introduced a new end-to-end trainable optical character recognition pipeline based on computer vision approaches, outperforming Tesseract 4 in accuracy and run-time on various evaluation datasets."
}