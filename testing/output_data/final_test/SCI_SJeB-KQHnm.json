{
    "title": "SJeB-KQHnm",
    "content": "Machine learning models for question-answering are vulnerable to adversarial attacks by inserting a single nuisance sentence. A new approach decomposes QA into two stages: selecting relevant sentences and then selecting a span. Adversarial training improves the robustness of this two-stage approach significantly. Adversarial training significantly improves the performance of a two-stage question-answering model, leading to a 22-point increase in F1 score. Recent research has focused on making QA models more robust to adversarial attacks, with a two-stage model showing benefits in interpretability, efficiency, and robustness. This direction shows promise in enhancing the overall robustness of QA systems. In this work, the Mnemonic Reinforced Reader model is explored, utilizing a two-stage approach for question-answering. The model incorporates co-attention between question and context, as well as hand-crafted features like Part-of-Speech tags and Named Entity Recognition tags to achieve competitive performance. The approach aims to enhance robustness by filtering out irrelevant sentences in the context selection stage. In this paper, the focus is on adversarial training through data augmentation for question-answering models. The two-stage setup involves passing top-k sentences from the sentence selector to the span selection model. Results show the sentence selector's top-k accuracy for the SQuAD dataset. Several prior works consider sentence selection as a sub-task of question answering."
}