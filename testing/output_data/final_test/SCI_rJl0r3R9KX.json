{
    "title": "rJl0r3R9KX",
    "content": "Regularized Learning under Label shifts (RLLS) is a domain-adaptation algorithm that corrects label distribution shifts between source and target domains. It estimates importance weights using labeled source data and unlabeled target data, training a classifier on weighted source samples. A generalization bound for the classifier on the target domain is derived, independent of data dimensions but dependent on function class complexity. This is the first generalization bound for the label-shift problem without target domain labels. A regularized estimator for the small-sample regime is proposed, considering uncertainty in estimated weights. Experiments on CIFAR-10 and MNIST datasets show RLLS improves classification accuracy, especially in low sample and large-shift scenarios. Regularized Learning under Label shifts (RLLS) improves classification accuracy in low sample and large-shift scenarios compared to previous methods. When machine learning models are used in real-world settings, the distribution of the target data can differ significantly from the source data used for training. This discrepancy is relevant in various domains like cloud services and medical diagnostics. Label Shift addresses distribution shifts between source and target data distributions. Various ways to approach distribution shifts between a source data distribution P and a target data distribution Q, focusing on covariate shift and label shift scenarios. While covariate shift has been extensively studied, label-shift scenarios are also important in practical machine learning problems. In practical machine learning problems, label shift scenarios are important. Suppliers of machine-learning models may have diverse data sets for training but no control over label proportions during deployment. In medical diagnostics, disease distribution varies by location and time. Can data from a location with abundant data be used to diagnose a disease in a location with limited data efficiently? Label shift is more computationally tractable than covariate shift, as labels have lower dimensionality than inputs. Labels in machine learning scenarios often have lower dimensions than the inputs. The literature has limited studies on this simplified model. Different methods have been proposed to address label shift, such as kernel mean matching and importance weights estimation. The approach by Lipton et al. (2018) shows promising results on large-scale data by training a classifier on weighted data from a black-box classifier. This procedure is referred to as black box shift. This paper aims to address unanswered questions regarding black box shift learning (BBSL) and label shift setting. The goal is to provide theoretical understanding and practical methods for supervised learning on distributionally shifted data, focusing on efficient methods applicable to large-scale data with generalization guarantees. Our contribution in this work is trifold. Firstly, we propose an efficient weight estimator with good statistical guarantees without a requirement on minimum sample complexity. Secondly, we introduce a regularization method to address high estimation errors in low sample settings. Finally, we derive a dimension-independent generalization bound for the Regularized Learning under Label Shift (RLLS) classifier based on our weight estimator, improving weight estimation error and excess risk by a factor of k log(k). The proposed method aims to reduce error and excess risk of the classifier on reweighted samples by a factor of k log(k), where k is the number of classes. Empirical studies on CIFAR-10 and MNIST datasets show significant improvements in weight estimation and prediction accuracy for various shifts, sample sizes, and regularization parameters. Applying regularized weights fully results in smaller weight estimation error and higher accuracy, while partially applying regularized weights also leads to improved accuracy over unweighted methods. In the label shift setting, importance weights are defined between two domains using the exponent of the Renyi divergence. The goal is to find the hypothesis that minimizes the loss function in a finite sample setting, where samples are drawn from P. The empirical loss can be minimized with importance weighted samples, but the vector of importance weights is usually unknown in practice. In the label shift setting, importance weights are used to learn the classifier h from observations drawn from P. The empirical loss is minimized with estimated importance weights w, where w are estimates of the unknown weights. The weights w are estimated using a set of samples from the source distribution P, and guarantees for the resulting estimator h are provided based on the correlation between label distributions p and q. In label shift setting, importance weights are used to learn classifier h from observations drawn from P. The requirement q(y) \u2265 0 =\u21d2 p(y) \u2265 0 is a reasonable condition. Lipton et al. (2018) compute the inverse of the estimated confusion matrix C h to estimate the importance weight w. However, the estimated C \u22121 h can be arbitrarily bad for small sample sizes. In label shift setting, importance weights are used to learn classifier h from observations drawn from P. Lipton et al. (2018) propose a method to estimate importance weights using the inverse of the confusion matrix C h. However, this estimator has high variance with few samples and linear error for large k. To address these issues, a two-step procedure is proposed to compute importance weights, making the final classifier less sensitive to estimation performance. In label shift setting, importance weights are used to learn classifier h from observations drawn from P. Lipton et al. (2018) propose a method to estimate importance weights using the inverse of the confusion matrix C h. A \"decent\" classifier h 0 yields a full rank confusion matrix C h0. The confusion matrix C h0 and label distribution q h0 are unknown, only finite sample estimates C h0, q h0 are given. The reparameterized linear model with respect to \u03b8 is b := q \u2212 C1 = C\u03b8 when C is near singular. In label shift setting, importance weights are used to learn classifier h from observations drawn from P. Lipton et al. (2018) propose a method to estimate importance weights using the inverse of the confusion matrix C h. When C is near singular, the estimation of \u03b8 becomes unstable. To address this, a regularizing penalty term is added to push the shift towards 0. The proof of the lemma regarding \u03b8 is provided in Appendix B.1. The weight estimation procedure does not require a minimum sample complexity to obtain guarantees for BBSL. The complexity of obtaining guarantees for BBSL is in the order of \u03c3 \u22122 min. Lemma 1 improves upon the previous upper bound by a factor of k. A good choice of estimator h0 can decrease the upper bound in Lemma 1. The singular value \u03c3 min is close to zero when the model h0 is uncertain. Our choice for the alternative estimator in Eq. 3 with norm instead of norm squared regularization is motivated by cases with large shifts \u03b8. When a few samples from the target set are available or the label shift is mild, the estimated weights might be too uncertain to be applied. Therefore, we propose a regularized estimator defined as follows: w = (1 \u2212 \u03bb)1 + \u03bb(1 + \u03b8), where \u03bb closer to 1 indicates more reason to believe that 1 + \u03b8 is the true weight. The text discusses the generalization bound for a classifier trained on source data with estimated weights. It introduces the set G( , H) and Rademacher complexity measure, providing a theorem on the generalization bound for the classifier. The size of R n (G) is determined by the function class H and the loss function used. The analysis is also extended to finite hypothesis classes for further insight. The VC dimension of function class H and loss function determine the generalization bound. The user defines shifts \u03b8 to be robust against, with an upper bound suggested for label shift correction using Algorithm 1. The choice of \u03bb in the algorithm depends on sample sizes, with a rule provided for its selection. The practical implementation does not require knowing \u03c3 min in advance. The choice of \u03bb in Algorithm 1 depends on sample sizes, with a rule provided for its selection based on \u03c3 min estimation. The oracle thresholds vary with n q and \u03c3 min when n p is fixed, guiding the decision to use weighted or unweighted samples. The excess risk of the classifier remains constant with sample sizes, but shifts \u03b8 max can be much smaller than \u03b8 when \u03c3 min is very small. In the presence of deviation from label shift assumption, the true importance weights \u03c9(x, y) generalize the RLLS with high probability. Theoretical analysis is illustrated by running RLLS on artificially generated shifts on MNIST and CIFAR10 datasets. The dataset is separated into source and target pools before sampling. We split the dataset into source and target pools of equal size. Sampling is done to form source and target sets with the same number of data points. Various shifts are considered, including Tweak-One, Minority-Class, and Dirichlet shifts. The classes are uniform. The Dirichlet shift involves drawing a probability vector from the Dirichlet distribution with a concentration parameter \u03b1 for all classes. After artificially shifting the label distribution in the source and target sets, algorithm 1 is followed using a black box predictor, such as a two-layer fully connected neural network. Different shifted source data is used to train the predictor for more precise weight estimation. In order to compute \u03c9 = 1+ \u03b8 in Eq. (3), a built-in solver is used to solve the low dimensional problem min \u03b8 C\u03b8 \u2212 b 2 + \u2206 C \u03b8 2. Empirically, 0.01 times of the true \u2206 C yields a better estimator for label shift. The hyperparameter 0.001 affects the theoretical bound in Lemma. 1. A classifier is trained on the source samples weighted by \u03c9 using different neural networks for MNIST and CIFAR10. 20 datasets with label distributions are sampled for each shift parameter to evaluate the mean square estimation error and predictive accuracy. This procedure is compared with the black box shift learning method (BBSL). In experiments on the CIFAR10 dataset, weight estimation and prediction performance for Tweak-One source shifts were compared with the black box shift learning method (BBSL). The number of data points in both source and target sets was set to 10000. Shifts with \u03c1 > 0.5 were created, using a fixed black-box classifier trained on biased source data with tweak-one \u03c1 = 0.5. The MSE in weight estimation was relatively large. In experiments on the CIFAR10 dataset, weight estimation and prediction performance for Tweak-One source shifts were compared with the black box shift learning method (BBSL). The MSE in weight estimation is relatively large, and RLLS outperforms BBSL as the number of minority classes increases. The performance for all methods deteriorates as the shift increases. RLLS yields higher accuracy than BBSL across all shifts. The Dirichlet shift with parameters \u03b1 = [0.01, 0.1, 1, 10] is used to shift the set. Larger shifts in the target set make the predictive task easier, but may result in zero accuracy for all but one class. The macro-averaged F-1 score is computed to allow for a more comprehensive performance evaluation. Precision and recall are used to calculate this score, giving higher weight to minority classes. The MSE of weight estimation and performance comparison on accuracy and F-1 score are depicted in FIG4. For a large target shift case with \u03b1 = 0.01, the F-1 score for BBSL and unweighted classifier is low compared to RLLS, while accuracy is high. The predictive task becomes easier with a higher shift, leading to higher accuracy. Average accuracy of RLLS is presented in Figure 4 as a function of the number of target samples n q for different values of \u03bb. In a study with a source set size of n p = 1000, a Minority-Class source shift with fixed p = 0.01 and five minority classes was investigated. The use of intermediate \u03bb in equation (4) is motivated in Section 2.2, based on \u03b8 max , \u03c3 min. It is suggested that for target sample sizes slightly above the threshold, an intermediate value of \u03bb \u2208 (0, 1) could be sensible. Performance on MNIST for Minority-Class shifted source and uniform target was analyzed with different target sample sizes and \u03bb values using various predictors. Regularizing the influence of estimated weights allows for adjustment to uncertainty and generalization for various target sample sizes. Different plots in Figure 4 correspond to black-box predictors trained on more or less corrupted data. Fully weighted methods achieve better performance faster with a well-trained black-box. Weighted methods with \u03bb = 1 outperform BBSL in all settings for image datasets MNIST and CIFAR10. The relation between eigenvalue of confusion matrix \u03c3 min and target sample size n q is reflected in the performance improvement. Generalization error decreases faster with more samples for good predictors. Significant improvements are seen for large shifts and low sample regimes. However, there are cases where unweighted samples outperform both RLLS and BBSL. Weighted methods with \u03bb = 1 outperform BBSL in all settings for image datasets MNIST and CIFAR10. However, there are cases when the estimator trained on unweighted samples outperforms both RLLS and BBSL. The covariate and label shift assumptions follow naturally when viewing the data generating process as a causal or anti-causal model. The covariate shift assumption is important in machine learning methods to correct for distribution changes in data. Various techniques like importance weights estimation and binary discriminative classifiers are used to address this issue. Additionally, a minimax approach has been explored to handle shared conditional label distribution between different datasets. Ramaswamy et al. (2016) address the label shift problem by formulating it as a mixture of class conditional covariate distributions with unknown weights. They use the Neyman-Pearson criterion BID6 to estimate the class distribution q(y) and highlight challenges with existing methods, such as computational burden for large sample sizes and limitations with neural networks. Importance weighting methods like Shimodaira (2000) require estimating the density ratio beforehand, which is difficult in high-dimensional data. Generalization bounds based on importance weighting methods need the second order moments of the density ratio to be bounded. Recent advances in addressing label shift involve estimating importance weights q(y)/p(y) in low-dimensional spaces, with solutions proposed for large-scale data. Approaches like Bayesian methods suffer from the curse of dimensionality, but recent work provides theoretical analysis and guarantees for distribution shifts based on H-divergence between joint distributions. Our work provides the first generalization guarantee for the label shift scenario, introducing an importance weighting procedure that does not require prior knowledge of q(y)/p(y). Inspired by BBSL, our method RLLS offers a more robust importance weight estimator and generalization guarantees, especially for small sample sizes. Additionally, RLLS includes a sample-size-dependent regularization technique to improve the classifier in both regimes. This work is a crucial step towards addressing shifts in data distributions. In future work, the label shift assumption might be too simplified in the real world as x may also depend on attributes z. For example, in disease prediction, symptoms may depend on the city and living conditions. The label shift assumption holds in a slightly modified sense when P(X|Y = y, Z = z) = Q(X|Y = y, Z = z). If attributes Z are observed, importance weighting can be performed using our framework. It is uncertain if a final predictor is truly \"better\" or more robust just because it achieves higher target accuracy. In disease prediction, symptoms may depend on the city and living conditions. The label shift assumption holds when P(X|Y = y, Z = z) = Q(X|Y = y, Z = z). Finding a procedure to learn a robust model and achieve high accuracies on new target sets remains a challenge. The current choice of regularization depends on the number of samples rather than data-driven regularization. Active learning for disease-symptoms scenario involves diagnosing a limited number of patients in the target location to obtain high accuracy on the entire target set. In disease prediction, symptoms may vary based on location and living conditions. The label shift assumption is crucial for learning robust models with high accuracy on new target sets. The current framework aims to extend to active learning and cost-sensitive settings for querying labels. Weighting samples in the empirical loss may not affect the trained classifier in certain scenarios. The study leaves open the question of how importance weighting can enhance generalization in overparameterized settings. The section discusses experiments comparing weight estimation performance between RLLS and BBSL for different types of shifts, including the Tweak-one Shift. Results show that RLLS has smaller MSE and outperforms BBSL as the shift increases in terms of bias and variance. Figure 5 compares MSE of estimated weights using BBSL and RLLS on CIFAR10 with tweak-one and Dirichlet shifts on source and uniform target. Additional experiments in the appendix show weight estimation and classification performance under different levels of label shifts. Figure 7 illustrates weight estimation error and accuracy comparison under a minority-class shift with p = 0.001 and p = 0.01. RLLS generally outperforms BBSL in weight estimation and accuracy, except in cases with four classes where both methods perform poorly. Neural network trained on biased source data with tweak-one \u03c1 = 0.5 shows worse weight estimation and decreased accuracy as the shift in minority class increases. Figure 8 displays weight estimation and classification performance for Minority-Class source shift on MNIST. Large shifts of three or more minority classes with p = 0.005 were created using a fixed black-box classifier trained on biased source data. The MSE in weight estimation is relatively large, and RLLS outperforms BBSL as the number of minority classes increases. Performance for all methods deteriorates as the shift increases. RLLS shows higher accuracy than BBSL across all shifts in the CIFAR10 experiment under Dirichlet source shifts. Importance weighting does not help classification in large shift cases. In a large shift case, weighted methods show similar accuracy to unweighted methods. Performance of classifiers with different regularization \u03bb under a Dirichlet shift with \u03b1 = 0.5 is shown. More target samples are needed for fully weighted version \u03bb = 1 to outperform a more corrupted black-box classifier. The text discusses the mathematical definition of finite sample estimates for a black-box classifier, focusing on the estimation errors of C and b using concentration Lemmas. The context before this paragraph mentions the performance of classifiers with different regularization under a Dirichlet shift. The paragraph discusses concentration Lemmas for finite sample estimates of C and b in relation to a black-box classifier. It utilizes the Matrix Bernstein theorem and the Dilations technique to prove the statement of Lemma 1. The text also introduces the construction of self-adjoint random matrices using the dilation technique. The text discusses the application of the Matrix Bernstein theorem and the dilation technique to prove a lemma related to self-adjoint random matrices. The proof is based on propositions from previous works. The text discusses applying the Matrix Bernstein theorem and dilation technique to prove a lemma on self-adjoint random matrices. It involves rewriting probability vectors and bounding estimates separately, ultimately aiming to bound the difference between two functions. The text discusses bounding the difference between two functions by utilizing the weight estimation error and finite sample error. It involves using the Rademacher complexity and Cauchy Schwarz inequality to derive the desired bounds. The text discusses deriving tight generalization bounds using the Rademacher complexity and Cauchy Schwarz inequality. It introduces a ghost data set and corresponding ghost loss to achieve this. The key random variable in Lemma 4 helps in obtaining the desired bounds with probability at least 1 \u2212 \u03b4. The text introduces the use of Rademacher variables to derive generalization bounds, showing that each Martingale difference is bounded above. The text discusses bounding the absolute value of Martingale differences using Rademacher variables, introducing events C j and their compliments. It also shows how multiplying losses by -1 results in the same Rademacher complexity. The bound for G n is derived using a slack variable, resulting in |G n | \u2264 2R(G( , H)) + 2d \u221e (q||p) log(2/\u03b4) n + 2 d(q||p) log(2/\u03b4) n. The text discusses bounding Martingale differences using Rademacher variables and introducing events C j. It also shows how multiplying losses by -1 results in the same Rademacher complexity. The bound for G n is derived using a slack variable, resulting in |G n | \u2264 2R(G( , H)) + 2d \u221e (q||p) log(2/\u03b4) n + 2 d(q||p) log(2/\u03b4) n. Additionally, a similar analysis to Theorem 4 in Ying (2004) is noted. If the label shift assumption is slightly violated, the RLLS generalizes with high probability. The excess risk is defined with respect to the importance weight \u03c9. The bound on term (a) for any h \u2208 H is derived similarly to Eq. 10. The weight estimation analysis continues from the previous analysis. When the label shift assumption is slightly violated, an upper-bound on the error is provided by modifying the weight estimation analysis. The confusion matrix and label distribution on the target for the black box hypothesis are unknown, but finite sample estimates are available. The solution satisfies a simplified upper bound equation, ensuring generalization with high probability even when the assumption is violated. When the label shift assumption is slightly violated, an upper-bound on the error is provided by modifying the weight estimation analysis. The solution satisfies a simplified upper bound equation, ensuring generalization with high probability even when the assumption is violated. The resulting equation is \u03b8 \u2212 \u03b8 2 \u2264 1 \u03c3 min (2\u2206 C \u03b8 2 + 2\u2206 b + 2d e (q||p))."
}