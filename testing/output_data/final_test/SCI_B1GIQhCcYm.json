{
    "title": "B1GIQhCcYm",
    "content": "We perform unsupervised image to image translation between source domain $X$ and target domain $Y, preserving shared semantics. The task involves discarding source-specific information and incorporating target-specific information using a noisy prior distribution. To avoid generating samples solely explained by the prior distribution, we aim to minimize the mutual information between the generated sample and the prior sample. Architectural choices play a crucial role in maintaining shared semantics between domains $X$ and $Y. State of the art results are achieved in unsupervised image to image translation from MNIST to SVHN. Various methods use pixel-wise consistency metrics to preserve semantics, but this approach may be too strong for domains with different spatial characteristics. The problem statement and solution are illustrated in Figures 1 and 2. The translator in the model takes two inputs: the source input for translation and independent noise to simulate statistical variation in the target. The model is trained as a generator in a GAN to ensure the output resembles the target. The challenge lies in defining translation in terms of information content and distinguishing between important qualities and noise. Structural assumptions need to be incorporated into the model for effective translation. Incorporating structural assumptions into the model is crucial for effective translation. Recent works in representation learning, computer vision, and generative models operate on this assumption. Transfer is enforced to maintain spatial characteristics through architecture choice. Mutual information is used as an additional objective for the translator, with MINE showing it can provide a gradient signal for the generator. Incorporating structural assumptions into the model is crucial for effective translation. Recent works in representation learning, computer vision, and generative models operate on this assumption. Transfer is enforced to maintain spatial characteristics through architecture choice. Mutual information is used as an additional objective for the translator, with MINE showing it can provide a gradient signal for the generator. Given two domains X and Y as cat and dog images, the paper formalizes the problem of unsupervised translation and proposes an augmented GAN framework for image to image translation tasks. The approach aims to avoid degenerate cases by using mutual information to ensure competitive results on the transfer task. The generated images are explained by one input using information theory. The problem of unsupervised translation is formalized by assuming the existence of random variables U, V on a measurable space (S, \u03a3) such that X and Y are conditionally independent given U and V. The shared semantics between X and Y is represented by a directed probabilistic graphical model. The task involves understanding the need for different variables U and V in solving a problem. For instance, if X and Y represent different visual representations of digits, the shared semantics between them is the notion of a digit. However, due to uneven distribution of classes in the MNIST dataset, shared semantics cannot be modeled with a single random variable. Instead, shared semantics are modeled through a measurable space (S, \u03a3), with probabilities represented by separate variables U. The Domain Transfer problem involves finding a mapping T: X \u2192 Y and shared semantics (S, \u03a3) between domains X and Y, with probabilities represented by separate variables U and V. Assumptions require each variable to have a single representation in the shared semantics space, and for the semantics to be shared between X and Y. The quality of transfer depends on the ordered \u03c3-algebras on a sufficiently large subset S \u2282 R^n. The quality of domain transfer from X to Y depends on the expressiveness of shared semantics \u03a3. To achieve many-to-many transfer, additional variable \u03be captures the variability of Y|X. A deterministic map G: S \u00d7 \u039e \u2192 Y is used for domain transfer. Features in X independent of Y should be forgotten, and shared semantics should exclude these features. The inability to express shared semantics as a random variable poses challenges in domain translation. The quality of domain transfer from X to Y relies on the expressiveness of shared semantics \u03a3. The inability to express shared semantics as a random variable causes challenges in training a transfer mapping. Imbalance in frequencies of modes between variables X and Y affects the distribution matching. While no solution is proposed, awareness of this issue is highlighted. A potential remedy involves a loss function penalizing the distance of generated samples from the target support independently of their likelihoods. Having a shared semantics space of sufficient capacity is crucial for quality. The quality of domain transfer relies on the expressiveness of shared semantics. To prevent the transfer mapping from ignoring the source, the architecture of the network should model the shared semantics space. Mutual Information can be used to encourage the network to maintain dependence between X and Y. In Section 4.2, the text discusses maximizing mutual information (MI) between X and Y to maintain dependence in the network. Paired transfer involves access to pairs (x i , y i ) sampled from joint distribution P X,Y, which can be reduced to supervised learning. Generative Adversarial Networks (GANs) are powerful models for unsupervised learning and generative tasks. Generative Adversarial Networks (GANs) involve a generator creating samples that the discriminator cannot distinguish from real ones. Various GAN variants exist, such as Wasserstein GAN and CycleGAN, which focus on domain transfer. CycleGAN uses two generators and discriminators for domain X and Y, trained with combined loss including GAN objectives and Cycle Consistency Loss. ALICE has shown that maximizing conditional entropy is crucial for alignment in GANs. CycleGAN, a GAN variant for domain transfer, assumes shared semantics between domains X and Y. Mutual information is leveraged for learning deep representations, with recent models estimating mutual information for information transfer. The transfer network T involves sampling normal noise z and feeding it through F. The transfer network T involves sampling normal noise z through F and real data x through E to generate sample y. Mutual Information measures the expected reduction in entropy of X by observing Y, and relates to Kullback-Leibler divergence between joint distribution P XY and product of marginal distributions P X \u2297 P Y. In GAN setting, exact computation of mutual information is not tractable. BID2 propose Mutual Information Neural Estimation (MINE) to estimate divergence between distributions. They use a statistics network S\u03b8 parameterized by \u03b8. The method involves sampling from distributions and estimating expectations via Monte Carlo sampling. In image to image translation, they search among parametric mappings T to generate translated samples. In image to image translation, the process involves sampling x \u223c P X and \u03be \u223c N (0, I), feeding them through networks E, F, and G to get the translated sample y = T (x, \u03be). The search is done in a space of stochastic mappings T = {T Z |T Z = T (\u00b7, Z) for T \u2208T and Z \u223c N (0, I)}. Stochastic gradient descent and back-propagation are used for the search, with adversarial loss employed to generate realistic samples in Y. In image to image translation, the process involves sampling x \u223c P X and \u03be \u223c N (0, I), feeding them through networks E, F, and G to get the translated sample y = T (x, \u03be). To avoid failure modes, mutual information from MINE is used to encourage Y to depend on X. The network architecture and inductive bias play a crucial role in the network's decision-making process. The architecture and inductive bias are crucial for Image-to-Image translation. Networks can find transformations that meet generation objectives without preserving shared semantics. The choice of architecture constrains the functions the network can learn, aiming for functions close to the identity. The transfer network and discriminator are inspired by DCGAN, while statistic networks for mutual information use MINE. Downsampling is done with 4x4 kernels and stride 2, with ReLU activations in the transfer network and discriminator, and ELU activations in the statistic network. The transfer network and discriminator use ELU activations and Spectral Normalization for stability during training. Additional experiments with U-Net architecture are detailed in Appendix A. Non-saturating GAN loss is utilized, along with Adam optimizer with a learning rate of 0.0001. The mutual information penalty factor varies based on the task. Two types of Image-to-Image translation are studied, with the edge to shoes dataset showing that only a GAN loss is needed for alignment preservation. The curr_chunk discusses different types of image translation tasks, specifically focusing on alignment preservation using GAN loss. The MNIST to SVHN task is evaluated, along with results from the Edge to Shoes dataset. Qualitative comparisons are made between TI-GAN and CycleGAN, showing that GAN loss alone can achieve good results. The GAN loss alone can achieve good results in image translation tasks, as shown in the Edge to Shoes dataset. The MI penalty and cycle consistency may not be necessary, and noise Z has no effect due to the many-to-one mapping. Only a GAN loss was needed to achieve the desired results. Figure 3 and Figure 4 show samples of 64 \u00d7 64 Edge to shoes generated using different techniques. MNIST to SVHN task is challenging due to geometric differences between the datasets. No technique has performed well on this task before. Figure 5 compares results with and without mutual information objective on the MNIST to SVHN task. In experiments comparing transfer accuracy between MNIST and SVHN datasets, regularizing the network with mutual information improved performance. Using TI-GAN resulted in 95.56% accuracy on SVHN classification and 99.6% on MNIST classification. The shared semantic is well transferred, and independent variations are explained by the prior distribution. Using TI-GAN improved accuracy on the MNIST classification task to 99.6%. However, there was a lower accuracy on the SVHN to MNIST transfer task due to other factors of variation in the translation networks. The technique involves minimizing mutual information between generated samples and samples from the prior distribution. In this paper, an unsupervised image to image translation framework is presented. The technique involves minimizing mutual information between generated samples and samples from the prior distribution. One to many image translation can be achieved without using any consistency loss. The SVHN to MNIST task is harder than the MNIST to SVHN task. Changes are needed with the MNIST to SVHN task as it is harder than the SVHN to MNIST task. Experiments were conducted with UNet-like architecture BID16 with depth 2 or 3, showing generally worse results than the default architecture. However, the impact of Mutual information on the learnt model is clear, and the model outperforms Cycle GAN with the same architecture. All TI-GAN UNet models were trained with WGAN-GP BID7 and penalization of mutual information between noise and output. The text discusses experiments with UNet models for transferring images between SVHN and MNIST datasets using different techniques like WGAN-GP. The impact of mutual information on the model's performance is highlighted, showing better results than Cycle GAN."
}