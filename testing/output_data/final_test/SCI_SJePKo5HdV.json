{
    "title": "SJePKo5HdV",
    "content": "Compressed representations generalize better and are crucial for learning from limited or noisy labeled data. The Information Bottleneck method provides a principled approach for balancing compression and prediction. However, selecting the Lagrange multiplier \u03b2 is challenging, as it affects the learnability of the model. Improper selection of \u03b2 can lead to unlearnable representations. A sharp phase transition between unlearnable and learnable states arises as \u03b2 varies, defining the concept of IB-Learnability. The phase transition as \u03b2 varies defines IB-Learnability. Sufficient conditions for IB-Learnability are proven, guiding \u03b2 selection. The largest confident, typical, and imbalanced subset of training examples determine IB-learnability. A practical algorithm estimates the minimum \u03b2 for a dataset. Theoretical results are tested on various datasets, showing non-monotonic accuracy in \u03b2. Compressed representations generalize better, crucial for learning from limited or noisy labels. The Information Bottleneck objective function aims to retain as little information about X as possible. The Information Bottleneck (IB) framework aims to minimize the mutual information between observed variables X and Z, while maximizing the information about Y. The hyperparameter \u03b2 controls the balance between compression and prediction. IB has been extended and studied in various scenarios, including Gaussian variables, meta-Gaussians, and continuous variables using variational methods. The Information Bottleneck (IB) framework focuses on minimizing mutual information between observed variables X and Z while maximizing information about Y. The hyperparameter \u03b2 controls the balance between compression and prediction. This work addresses the issue of selecting \u03b2 and introduces the concept of IB-Learnability, showing that improperly chosen \u03b2 can lead to a failure to learn. The IB objective undergoes a phase transition when varying \u03b2, leading to IB-Learnability. Second-order variation yields conditions for choosing a good \u03b2. IB-learnability depends on confident, typical, and imbalanced training examples subsets, related to the Pareto frontier slope on the information plane. Results are demonstrated on synthetic datasets and MNIST, CIFAR10 under noisy labels. An algorithm estimates the onset of IB-Learnability accurately, matching theoretical predictions and empirical results. Discontinuities are observed in the process. The IB objective with Lagrange multiplier \u03b2 undergoes a phase transition, leading to IB-Learnability. The task is to find a conditional probability p(z|x) that minimizes IB \u03b2 (X, Y ; Z), where larger \u03b2 favors better predictions for Y. The IB objective with Lagrange multiplier \u03b2 undergoes a phase transition, leading to IB-Learnability. The selection of \u03b2 is done empirically, with Tishby et al. recommending \"sweeping \u03b2\". The concept of IB-Learnability is introduced to guide the choice of \u03b2, with conditions for IB-learnable cases defined. The IB objective with Lagrange multiplier \u03b2 undergoes a phase transition, leading to IB-Learnability. Necessary conditions for IB-Learnability are discussed, showing that \u03b2 > 1 is required. The range of \u03b2 for IB-Learnability is characterized, with \u03b2 0 as the threshold. The trivial representation is a stationary solution for the IB objective. The IB objective with Lagrange multiplier \u03b2 leads to IB-Learnability, with Lemma 1.1 providing a strategy for finding sufficient conditions. The key result is Theorem 2 (Confident Subset Suff. Cond.), stating that X and Y must not be independent for IB \u03b2 -learnability, with a lower bound on the Pareto frontier slope. The characteristics of a dataset leading to low \u03b2 0 include large confidence, typicality, and imbalance in subsets of examples. Theorem 2 leads to important corollaries for classification with noisy labels and deterministic mappings. The sufficient condition for IB \u03b2-Learnability in classification problems is \u03b2 > \u03b2 0 = 1, indicating that Y is not a deterministic function of X if \u03b2 0 > 1. Finite models with insufficient capacity may introduce effective class overlap, leading to a higher observed \u03b2 0 even when learning deterministic functions. Algorithm 1 in Appendix J can be used to empirically estimate \u03b2 for general classification tasks. Algorithm 1 in Appendix J can be used to empirically estimate an upper-bound \u03b2 0 for general classification tasks. The algorithm involves training a maximum likelihood model on the dataset to estimate p(y|x), then performing a targeted search to find a confident subset \u2126 x. This subset helps in estimating \u03b2 0, which can be used for learning with IB. This is particularly useful for noisy datasets. To test theoretical results and Algorithm 1, experiments were conducted on synthetic datasets, MNIST, and CIFAR10. Synthetic datasets were generated with varying class-conditional noise rates. The results showed that improperly chosen \u03b2 may hinder learning useful representations, emphasizing the importance of theoretically-guided \u03b2 selection. MNIST binary classification with added class-conditional noise was also performed. The study tested the impact of model capacity on learning onset using VIB models with different neuron numbers. Insufficient capacity leads to more uncertainty in predictions, as shown by larger \u03b2 0 for the n = 128 model. Results aligned well with theoretical predictions, confirming Algorithm 1's accuracy. Additionally, CIFAR10 forgetting was analyzed in relation to \u03b2 values. The study analyzed forgetting in CIFAR10 with varying \u03b2 values, finding discontinuities in the Pareto frontier. Lower \u03b2 values in regions with similar information yields had higher accuracy, indicating non-monotonic performance in some datasets. The study found non-monotonic performance in datasets where multiple values of \u03b2 cluster together. Reducing \u03b2 to achieve a specific point on the information plane may lead to better representations. Discontinuities were observed in prediction error vs. information in geometric clustering, suggesting a shared root cause for these phenomena. The onset of learning is determined by the largest confident, typical values. The onset of learning is determined by the largest confident, typical subset of examples. A practical algorithm for predicting the transition accurately, even with extreme label noise, was provided. A non-monotonic relationship between \u03b2 and accuracy was observed, related to discontinuities in the Pareto frontier of the information plane. The results offer guidance for choosing \u03b2 in the IB framework. The study raises questions about other phase transitions in learnability that may be explored in future work. In the Processing Systems paper, Ohad Shamir, Sivan Sabato, and Naftali Tishby discuss learning and generalization with the information bottleneck. The structure of the Appendix includes preliminaries, proofs of theorems, and conditions for IB \u03b2-learnability. The key result, Theorem 2, along with important corollaries, discussions, and an algorithm for estimation, are provided in the appendices. In Appendix K, details for experiments are provided. A perturbative function is added to functional F [f (x)], expanding it as DISPLAYFORM0. The linear and quadratic functionals of h(x) are defined. The Sufficient Condition 1 for IB \u03b2-learnability is proven, laying the foundation for further conditions and key results in the paper. Theorem 3 states a sufficient condition for IB \u03b2-learnability, requiring a perturbation function with specific properties. The proof involves necessary conditions for a functional to have a minimum, utilizing perturbative functions to calculate variations. Theorem 3 provides a sufficient condition for IB \u03b2-learnability, involving perturbation functions to calculate variations. Lemma 1.1 proof involves using Lemma 4.1 to derive the final expression. The two integrals are both 0, which is a sufficient condition for (X, Y) to be IB \u03b2-learnable. The proof is given in Appendix F, along with a construction for h(z|x) for Theorem 3. The geometric meaning of (\u03b2 0 [h(x)]) \u22121 is explained under a perturbation function. Theorem 5 provides a lower bound for IB \u03b2-learnability, stating that as long as \u03b2 \u22121 is lower than the slope of the Pareto frontier in the information plane, (X; Y) is IB \u03b2-learnable. By setting h(x) to be nonzero in a specific region \u2126 x and 0 otherwise, a stronger sufficient condition for IB \u03b2-learnability can be obtained. Theorem 5 provides a lower bound for IB \u03b2-learnability, stating that as long as \u03b2 \u22121 is lower than the slope of the Pareto frontier in the information plane, (X; Y) is IB \u03b2-learnable. By setting h(x) to be nonzero in a specific region \u2126 x and 0 otherwise, a stronger sufficient condition for IB \u03b2-learnability can be obtained. The numerator of the R.H.S. of Eq. (6) attains its minimum when h(x) is a constant within \u2126 x, leading to the confident subset sufficient condition for IB \u03b2 -Learnability. Theorem 5 establishes a lower bound for IB \u03b2-learnability, indicating that if \u03b2 \u22121 is less than the Pareto frontier's slope in the information plane, (X; Y) is IB \u03b2-learnable. Setting h(x) to be nonzero in region \u2126 x yields a stronger condition for IB \u03b2-learnability. The condition for IB \u03b2-learnability is that there exists an h(x) such that G[h(x)] < 0. Theorem 5 establishes a lower bound for IB \u03b2-learnability, indicating that if \u03b2 \u22121 is less than the Pareto frontier's slope in the information plane, (X; Y) is IB \u03b2-learnable. Setting h(x) to be nonzero in region \u2126 x yields a stronger condition for IB \u03b2-learnability. The condition for IB \u03b2-learnability is that there exists an h(x) such that G[h(x)] < 0. In the entire input space X, h(x) = const cannot satisfy the equation. By rearranging terms and simplifying, it is shown that the right-hand side of the equation is greater than 0. The left-hand side of the equation has a necessary condition that \u03b2 > 0, leading to the conclusion that h(x) must be constant for the equation to hold. This constraint implies that h(x) \u2261 const, and when written in the form of expectations, it is shown that the square function is convex. The square function is convex, and using Jensen's inequality, it is shown that Y must not be independent of X for a certain equation to hold. Additionally, a condition for IB \u03b2-learnability is derived, showing that h(x) must not be constant. This condition is further explained using expectations and constraints. Theorem 5 is proven, showing the necessary condition of \u03b2 > 1. The lower bound of the Pareto frontier slope at the origin is discussed, considering general stationary solutions for Z. Multiple phase transitions are examined by obtaining the stationary solution for the IB objective. The text discusses the use of Lagrangian multipliers in the context of the IB objective. It highlights the relationship between different equations and the concept of phase transitions in the Pareto frontier. The text also mentions the normalization of p(z|x) using \u03bb(x) and the self-consistent equation from previous research. The text discusses rewriting equations using Lagrangian multipliers for the IB objective. It presents a sufficient condition for IB \u03b2-learnability and discusses the denominator of a specific equation, showing when it equals 0. The numerator of Eq. FORMULA0 is positive, leading to a condition for IB \u03b2-learnability. The infimum for Eq. FORMULA2 is greater than or equal to that of Eq. (5), and the condition is invariant to invertible mappings of X. The condition for IB \u03b2-learnability is invariant to invertible mappings of X, as shown by Theorem 2. The sufficient condition for IB \u03b2-learnability involves class-conditional probabilities and a deterministic function of X. Theorem 2 shows that the condition for IB \u03b2-learnability is invariant to invertible mappings of X. The sufficient condition involves class-conditional probabilities and a deterministic function of X, with \u03b2 > 1 being a necessary and sufficient condition. The denominator of the equation is related to mutual information, and the numerator represents the density of \"rational mutual information.\" The numerator and denominator in the equation relate to mutual information and the density of \"rational mutual information.\" The characterization of \u2126 x suggests datasets with multiple learnability phase transitions, where a small region dominates the infimum, resulting in a small value of \u03b2 0. At exactly \u03b2 0, the current encoder may have no mutual information with the remaining classes in a new dataset X 1. The text discusses the concept of phase transitions in learning, where a model's capacity is measured using IB-Learnability. It also explores the trade-off between increasing I(Y; Z) and decreasing I(X; Z) in the Information Plane. The analysis in Appendix F delves into multiple phase transitions in datasets. The trade-off between increasing I(Y; Z) and decreasing I(X; Z) is described in FIG1. The threshold for IB \u03b2-Learnability is determined by the slope of the Pareto frontier at the origin. Theorem 2 provides lower bounds for this slope, indicating lack of IB \u03b2-Learnability for certain values of \u03b2. If the frontier is convex, optimality is achieved at different points depending on the value of \u03b2. The contraction coefficient \u03b7 KL measures how well a channel preserves distributions. The algorithm presented estimates the upper bound for \u03b2 0 in IB \u03b2-Learnability. The algorithm estimates the upper bound for \u03b2 0 in IB \u03b2-Learnability using a maximum likelihood model with tolerance \u03b5. It utilizes the Variational Information Bottleneck objective for a synthetic experiment with specific neural network configurations. The decoder is a neural net with 1 hidden layer of 128 neurons and ReLU activation. It uses a mixture of Gaussian prior with 500 components (256 for class overlap experiment), each a 2D Gaussian with learnable mean and log variance. The architecture for the MNIST experiment is similar, with Z having a dimension of 256 and a standard Gaussian prior with diagonal covariance matrix. Adam optimizer is used with default parameters, no regularization, learning rate of 10^-4, and learning rate decay of 1/(1+0.01*epoch). Training consists of 2000 epochs with batch size of 500, and a train-test split of 5:1. Accuracy is reported on the test set. The accuracy on the test set is reported with respect to the true labels. For estimating \u03b2 0,exp in FIG0, the mean and standard deviation of the accuracy for the lowest 5 \u03b2 i values are calculated. When \u03b2 i is greater than \u00b5 \u03b2 + 3\u03c3 \u03b2, it is considered as learning a non-trivial representation. The onset of learning is experimentally estimated by taking the average of \u03b2 i and \u03b2 i\u22121. A deterministic 28x10 wide resnet BID10 Zagoruyko & Komodakis, 2016) is trained, with the final 10 dimensional logits extended through another 3 layer MLP classifier to maintain identical network architecture with VIB models described later. During training, label noise was added dynamically based on a class confusion matrix. The mean label noise averaged 20% across 10 classes. After convergence, \u03b2 0 was estimated to be 1.0483. Subsequently, 73 VIB models were trained using a 28x10 wide resnet architecture for the encoder, with \u03b2 values ranging from 1.02 to 2.0. The models utilized a mixture of 500 fully covariate 10-dimensional Gaussians for marginal distributions. The VIB architecture used \u03b2 values ranging from 1.04 to 1.06, starting training at \u03b2 = 100 and annealing down to the target over 10,000 steps. Models converged within 20,000 additional steps and remained stable for the remaining 180,000 steps."
}