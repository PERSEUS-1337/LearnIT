{
    "title": "r1esnoAqt7",
    "content": "Revealing latent structure in data is a key area of research, introducing technologies like variational autoencoders and adversarial networks to advance unsupervised knowledge discovery in machine learning. The lack of suitable benchmarks for evaluating learned representations is a major challenge. To address this, Morpho-MNIST is introduced as a framework for assessing how well models represent specific data variations. This framework extends the MNIST dataset with morphometric analysis for quantitative comparison of models, identifying latent variable roles, and evaluating sample diversity. Quantifiable perturbations are proposed to test unsupervised and supervised methods on tasks like outlier detection and domain adaptation, aiming to drive progress in machine learning. The availability of well-curated datasets has driven major advances in machine learning, particularly in speech recognition, computer vision, and natural language processing. While supervised learning tasks have clear benchmarks for performance evaluation, representation learning poses a challenge due to the lack of suitable benchmarks. Despite active research in techniques like probabilistic autoencoders and adversarial learning, the field lacks reproducible ways to quantify performance progress. The lack of reproducible ways to quantify performance in representation learning has led to subjective evaluation methods. Visualisation techniques and visual inspection are commonly used, but they do not provide objective measures. To address this issue, Morpho-MNIST introduces shape metrics and perturbations for quantitative assessment. This aims to improve the evaluation of representation learning methods using the MNIST dataset. MNIST is widely used for representation learning, demonstrating success in disentangling latent variables capturing style variations. It allows reproducible comparisons and has easily measurable factors of variation, making it popular for research. The dataset MNIST allows reproducible comparisons with previous results in the literature, consists of small greyscale images for a ten-class classification problem, and has low computation and memory requirements. It is popular for new researchers to experiment with deep learning frameworks. The aim is to extend MNIST to bridge the gap between methodology-focused research and real-world applications benefiting from machine learning methods. We propose a new quantitative framework for assessing representation learning using true and generated digit images, focusing on measurable shape attributes like stroke thickness and length. These measurements can help identify the role of inferred representations and assess generative performance in terms of sample diversity and disentanglement of latent variables. This framework can be used to re-evaluate existing models and improve model samples. Our proposed quantitative framework assesses representation learning using shape attributes in digit images. The framework includes global and local perturbations to add complexity to the data manifold and improve model samples. These perturbations can be applied to other datasets for new insights into representation learning methods. The proposed perturbations aim to enhance representation learning in digit images, enabling various applications such as anomaly detection, classification from noisy data, domain adaptation, and characterizing latent representations. Additionally, datasets related to MNIST and images with generative factor annotations are discussed. The MNIST dataset, along with its variations like EMNIST and Infinite MNIST, have been augmented using different techniques such as affine transformations and elastic deformations. These perturbations aim to improve representation learning in digit images for various applications. Fashion-MNIST and notMNIST datasets contain images of clothing articles and character glyphs, respectively. Annotated datasets like BID22 and BID1 include 2D renderings of 3D faces and chairs with pose parameters and lighting conditions. The dSprites dataset consists of binary images of shapes with varying attributes. The availability of ground-truth values for attributes in datasets has led to increased use in evaluating representation learning algorithms. Evaluation methods have evolved from focusing on test log-likelihood to visual fidelity metrics based on Inception network features for generative models of images. Family of metrics proposed based on visual features extracted by Inception network BID26. Original Inception score BID23 focuses on class predictions' crispness, while Fr\u00e9chet Inception distance (FID) BID12 and kernel Inception distance (KID) BID2 compare high-level representations. BID0 suggests estimating distribution support using birthday paradox test, hindered by manual visual inspection. Various attempts made to quantify representation disentanglement performance, like BID13's simple classifier accuracy proposal. In BID13, a simple classifier is proposed to measure the accuracy of predicting fixed variation factors in a dataset. Other information-theoretic approaches involve KL divergence from latent dimensions or mutual information with generative factors. BID15 explores predictive accuracy of latent variables to generative factors. Morphometrics are crucial for characterizing shapes like MNIST digits. The image processing pipeline for extracting metrics and applying perturbations is described, along with computation details. The original 28x28 resolution of MNIST images may not be sufficient for analysis. To enable accurate morphological processing of MNIST images, the resolution is upscaled to 112x112, binarised, Euclidean distance transform computed, skeletonised, perturbed, and then downscaled back to the original resolution. This process captures subtle variations in contour shape and stroke thickness, producing high-quality images indistinguishable from the original. The morphometric attributes for each digit are calculated after applying steps 1-4 of the pipeline. The total length of the skeleton approximates the pen stroke length, indicating shape complexity. This method is more robust against rotations compared to pixel counting. The overall thickness of MNIST digits is a prominent factor of style variation. The overall thickness of strokes in MNIST digits is a key factor of style variation, influenced by pen thickness, force, and image rescaling. The slant angle of handwritten symbols also contributes to style variation, with OCR systems often 'deslanting' characters to reduce variance. The slant angle of handwritten digits is described using a deslanting methodology based on horizontal shear. Other shape attributes like width, height, and aspect ratio are measured by fitting a bounding parallelogram to each digit. Vertical and horizontal marginal cumulative distribution functions are computed using boundaries based on the slant angle. The bounds for a horizontal marginal CDF are chosen based on equal-tailed intervals containing 98% of the image mass in both directions. Transformations involve dilating or eroding a binarised digit image with a circular structuring element proportional to estimated stroke thickness. These perturbations serve as powerful data augmentation for training due to thickness variability in the original MNIST data. In addition to global transformations, local perturbations with variable location and extent are introduced for training. These perturbations involve warping pixel coordinates within a certain radius using a radial power transform. Parameters such as radius and strength are set accordingly, producing noticeable effects without exaggeration. The centre location for these perturbations is randomly selected along the estimated skeleton. The proposed procedure involves adding fractures to an MNIST digit by creating breaks in pen strokes. Multiple fractures are added to each digit to avoid confusion with gaps between strokes. Fracture locations are selected away from stroke tips and fork points, with orientation determined by the skeleton's second-order moments. The length of the fracture is estimated from the boundary EDT before being drawn onto the binary image. The proposed framework involves adding fractures to an MNIST digit by creating breaks in pen strokes. Fractures are drawn onto the high-resolution binary image with specific parameters to produce detectable perturbations. The framework can be used for characterizing sample distributions from generative models and finding associations between latent representations and morphometric attributes. Additionally, supervised tasks on the MNIST dataset augmented with perturbations are demonstrated in the appendix. The text discusses using generative models to visualize distributions and measure their agreement with true data distribution. Examples include a vanilla GAN and a \u03b2-VAE trained with different latent space dimensions. Visualization of morphometric distributions from these models is shown in FIG3, highlighting interpretable low-dimensional statistics for comparing generative model distributions. The text discusses comparing distributions learned by generative models using low-dimensional statistics. It proposes using kernel two-sample tests based on maximum mean discrepancy to compare distributions in a lower-dimensional space of morphometrics. Test results suggest a mismatch in the samples from the low-dimensional GAN compared to \u03b2-VAE and larger GAN models. The text discusses comparing distributions learned by generative models using low-dimensional statistics. It proposes using kernel two-sample tests based on maximum mean discrepancy to compare distributions in a lower-dimensional space of morphometrics. Test results suggest a mismatch in the samples from the low-dimensional GAN compared to \u03b2-VAE and larger GAN models. One suggestion is to use hierarchical agglomerative clustering on sample morphometric attributes to identify near-replicas, indicating mode collapse. This method can also be used in the birthday paradox test to estimate the support of the learned distribution. The experiment demonstrates that standard MNIST can be augmented with morphometric attributes to study representations computed by an inference model and assess disentanglement. The analysis involves measuring shape attributes of samples to assess disentanglement of a generative model and diagnose model failures. MAP estimates of latent codes are taken for each image, and correlation structures between generative factors and latent codes are studied. Partial correlation is computed to study the net effect of each latent code variable on morphometric attributes. The technique allows studying the first-order effect of each latent code, without hyperparameter tuning. Two settings were considered to assess disentanglement: one with categorical and continuous latent codes on plain MNIST digits, and another with an additional code to investigate thickness variations. The dataset used for training involved exaggerated thickness variations by interleaving plain, thinned, and thickened digit images randomly. The trained generative model, INFOGAN-B, was expected to recognize that thickness should be independent of other morphological attributes. INFOGAN-B's recognition network successfully learned to separate slant and thickness as the most prominent factors of style variation in the dataset. The dataset used for training involved exaggerated thickness variations by interleaving plain, thinned, and thickened digit images randomly. Interestingly, c 3 also associates with height, as thicker digits tend to be taller. The evaluation methodology described above is useful to investigate the behavior of the inference direction of a model, and can readily be used with datasets which include ground-truth generative factor annotations. This tells us little about the generative expressiveness of the model unless we trust that the inference approximation is highly accurate. Computed metrics show their potential by measuring generated samples and how their attributes relate to the latent variables used to create them. Results from a similar analysis to FIG4 are shown in FIG5, evaluated on samples from that model, indicating that the inference and generator networks have learned to consistently encode and decode the digit shape attributes. The networks have successfully encoded and decoded digit shape attributes. Traversals of the latent space were displayed in Fig. 7, showing variations in latent variables while holding others constant. Visual inspection was traditionally used to evaluate disentanglement and expressiveness of image models. Attempts were made to detect local perturbations like swelling and fractures in InfoGAN models. Additional Bernoulli latent codes were added to the model formulation for this purpose. The study used a dataset of plain, swollen, and fractured digits to evaluate a model's ability to capture perturbations. The addition of binary variables did not improve the model's ability to represent variations in the data. The Morpho-MNIST dataset provides tools to assess representation learning in generative models. This can be used to evaluate already trained models and potentially uncover new insights. The study utilized a dataset of plain, swollen, and fractured digits to assess a model's capability to capture variations. They plan to incorporate additional perturbations, like imaging artefacts, for increased complexity. Gaussian product kernel with bandwidths from Scott's rule was employed for density estimation. The bandwidth for a density estimation kernel is determined using a heuristic formula based on sample size and number of dimensions. The KDE bandwidths for real and sample data are calculated separately and squared to obtain the squared bandwidth of the MMD's Gaussian kernel. More sophisticated kernel selection procedures are available, such as optimizing test power. Further analysis tools include applying a relative MMD similarity test to rank trained models based on sample fidelity. Model criticism methodologies can also be adopted based on the MMD. The proposed framework introduces Morpho-MNIST for quantitative evaluation of generative models and supervised learning. Experiments demonstrate applications in digit recognition, abnormality detection, and thickness regression. Four models were evaluated: k-nearest-neighbours (kNN) and a support vector machine. These experiments can serve as baselines for unsupervised tasks like outlier detection and domain adaptation. The study evaluated different models for digit recognition using various datasets. kNN, SVM, MLP, and LeNet-5 were tested on plain digits, digits mixed with different patterns, and showed varying performance on local perturbations. kNN appeared to be the most robust, while LeNet-5 was affected by changes in local patterns. The study evaluated different models for digit recognition using various datasets. LeNet-5 showed high accuracy in detecting abnormalities in digits, likely due to its convolutional architecture's local invariances. The task of predicting normal or perturbed digits was more challenging than digit classification. Additionally, a regression task for digit thickness using the GLOBAL dataset mimicked medical imaging tasks. The convolutional model outperformed others in digit recognition, relying on local geometry for high accuracy."
}