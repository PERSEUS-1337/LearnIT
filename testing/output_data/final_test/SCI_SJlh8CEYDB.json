{
    "title": "SJlh8CEYDB",
    "content": "The study focuses on developing a Neural Logic Inductive Learning (NLIL) framework within inductive logic programming (ILP) to create interpretable machine learning systems. NLIL can efficiently learn first-order logic rules to explain patterns in data, outperforming state-of-the-art models by finding longer rules x10 times faster. It can scale to large image datasets like Visual Genome, explaining relationships between objects in images with globally consistent and commonsense interpretations. The recent success of deep learning models has raised concerns about their lack of interpretability and data-hungry nature. In contrast, logic programming methods like first-order logic offer explicit symbolic structures that can be understood by humans. This paper explores the learning to explain problem within inductive logic programming (ILP), aiming to learn first-order logic rules that explain data. The paper explores the learning to explain problem in ILP, seeking first-order logic rules to explain data. Differentiable ILP models combine neural and logic-based computation for rule search. \u2202ILP is a forward-chaining method using pre-defined templates to deduce new facts. The general ILP problem is NP-hard due to the exponential growth of the rule search space. The paper discusses the challenges of rule search space growth, variable binding problem, and rule instantiations in ILP. Most works limit search length and use template-based variable assignments. Multi-hop reasoning methods are proposed for KB completion tasks. Methods like NeuralLP can answer KB queries by finding relational paths. NeuralLP is efficient in variable binding and rule evaluation but limited in expressing complex rules and globally consistent explanations. NLIL is proposed as a differentiable ILP method for multi-hop reasoning in KB completion tasks. NLIL is a differentiable ILP method that extends the multi-hop reasoning framework for general ILP problems. It uses a divide-and-conquer strategy to search for longer rules efficiently. The method maintains global consistency of rules by splitting training into rule generation and evaluation phases. NLIL is widely applicable for model explanations in supervised learning scenarios, demonstrated on the Visual Genome dataset for learning explanations for 150 object classes over 1M entities. We demonstrate that learned rules maintain interpretability, have comparable predictive power to densely supervised models, and generalize well with less than 1% of the data. Recent works on interpretability focus on generating heatmaps or attention to explain classifier outcomes. A more effective explanation is through describing connections with other classifiers, such as explaining the presence of a person by leveraging its connection with other attributes. The curr_chunk discusses the connection between attributes to determine if a person is present, drawing from Inductive Logic Programming. It explains the components of a first-order logic system - entities, predicates, and formulas, with examples like Person : x \u2192 {0, 1}. Predicates can have multiple arguments, and logic variables like X can be instantiated into any object in X. The curr_chunk explains first-order logic entailments using logic variables and predicates. It defines the rule body as a general formula made of atoms with predicate symbols and logic variables, making the explanation transferrable and easily interpretable. The curr_chunk discusses the application of first-order logic rules in the context of relational knowledge bases and inductive logic programming. It mentions the task of learning FOL rules to entail target predicates and relates it to multi-hop reasoning tasks on knowledge graphs. The ILP problem is closely connected to reasoning on a KB with predicates. The task in ILP involves operating on a KB with predicates to find relational paths connecting query entities. Using adjacency matrices and path features, reasoning is done through multiple hops to compute the query score. The goal is to determine the appropriate number of steps and adjacency matrices for each hop. The task in ILP involves finding relational paths connecting query entities by determining the appropriate number of steps and adjacency matrices for each hop. This is achieved by learning the weighted sum of scores from all possible paths and matrices at each step using soft path selection and operator attention vectors. The attention generator T(x; w) is an RNN controller that generates a sequence of normalized attention vectors with v x as the initial input. Learning the relational path in multi-hop reasoning can be seen as solving an ILP problem with chain-like FOL rules. Compared to template-based ILP methods, this class of methods is efficient in rule exploration and evaluation. However, generating explanations for supervised models requires high rule expressiveness, which is limited in chain-like rule space. The ability to efficiently search beyond this space is still lacking. In the context of multi-hop reasoning methods, the difficulty lies in learning globally consistent FOL rules in the knowledge base. A hierarchical rule space is proposed to extend the chain-like space for more expressive rule learning. By converting the logic entailment equation into Skolem normal form, evaluation becomes easier. The functions in the equation can be arbitrary, allowing for efficient grounding and instantiation of variables. The functions in Eq. (7) can be arbitrary and are determined by deterministic functions. Each predicate is treated as an operator in a subspace of functions \u03a6 = {\u03d5 1 , ..., \u03d5 K }, where U and B are sets of unary and binary predicates. The operator of the unary predicate takes no input and returns a set embedding representing object entities that satisfy the predicate. For example, \u03d5 Inside (v x ) returns objects spatially containing the input box. Unary predicates like Car(X) have operators like \u03d5 Car () = M car 1, which return objects labeled as cars. Only the subspace \u03a6 of functions is used. The functions in Eq. (7) are determined by deterministic functions and each predicate is treated as an operator in a subspace of functions \u03a6. The subset \u0176 \u2286 Y is constrained from Eq.(1), where Y represents existential variables that can be represented by operator calls. FOL formulas complying with Eq. (7) can be converted into operator form and vice versa. The variable binding problem is equivalent to the path-finding problem, searching for the appropriate chain of operator calls. In section 2.2, the variable binding problem is discussed, focusing on finding the chain of operator calls to represent the variable in\u0176. Primitive statements are introduced to extend the notion of rules, with each statement mapping input space to a confidence score using the sigmoid function. Primitive statements are introduced to extend the notion of rules, with each statement mapping input space to a confidence score using the sigmoid function. The unary operator \u03c8 is given a dummy input x for notation convenience. Eq.(9) replaces the target vx into another relational path, allowing for the representation of correlations between variables. This enhances the expressive power of learned rules by representing tree-like factor graphs. The relational paths in Eq.(6) are summed with a single path attention vector s\u03c8, which can be further relaxed into weighted sums. The notion of rules is extended with primitive statements mapping input space to confidence scores. Separate vectors are assigned for each argument of the statement. The rule search space is expanded by exploring logic combinations of primitive statements using soft logic operations. The formula set at each level is defined to represent logic combinations. The logic combination space is defined by concatenating formula sets with their logic negation. Each level searches for a limited number of logic and combinations from the previous level. The final level is the union of all previous sets, allowing for the collection of rules. Eq.(11) does not explicitly forbid trivial rules. The logic combination space is defined by concatenating formula sets with their logic negation. Each level searches for a limited number of logic and combinations from the previous level. The final level, L, is the union of previous sets. Eq.(11) does not explicitly forbid trivial rules. Introducing nonexistent queries during training helps alleviate this issue. Rule selection can be parameterized into a weighted-sum form with respect to attentions. Attention tensors are defined as S f , S f \u2208 R L\u22121\u00d7C\u00d72C. The best explanation is selected and the score for each query is computed using the Iterate Concat attention vector over F L. An overview of the relaxed hierarchical rule space is illustrated in Figure 3. The relaxed hierarchical rule space, defined by attention parameters, aims to generate data-independent FOL rules for target predicates. Learnable embeddings of predicates and attention generation models are utilized to achieve this goal. The attention generation model uses a stack of three Transformer networks to simulate evaluation processes. MultiHeadAttn module calculates compatibility between query and value, generating attention matrices. The operator transformer module alters the embedding matrix for a target predicate, making rule generation predicate-specific. It uses learnable operator query embeddings and aggregates outputs with MultiHeadAttn. The path attention is generated based on argument encodings. The operator transformer module uses learnable operator query embeddings to alter the embedding matrix for a target predicate, making rule generation predicate-specific. It aggregates outputs with MultiHeadAttn based on argument encodings. The compatibility between paths and arguments is computed with MultiHeadAttn, and a FeedForward is used to aggregate the selections. The formula attention is generated using learnable queries and embeddings, and the compatibility between logic, arguments, and previous formulas is computed with MultiHeadAttn. The training of NLIL consists of two phases. The training of NLIL consists of two phases: rule generation and rule evaluation. During generation, attentions are obtained for all P * s. In the evaluation phase, a mini-batch of queries is sampled and formulas are evaluated. Negative queries are sampled to prevent learning trivial rules. The objective is to minimize the loss, with attentions back-propagated through Transformer networks for end-to-end training. Results from operator calls and logic combinations are averaged via attentions during training. During training, operator calls and logic combinations are averaged via attentions. The model is evaluated with explicit FOL rules extracted from distributions over random variables. Sampling is replaced with arg max to focus on the best rules. NLIL is compared with KB completion methods on ILP benchmarks and can learn FOL explanations for object classifiers with scene-graphs. NLIL can overcome the infeasibility of classical ILP methods by using efficient stochastic training. It is evaluated with NeuralLP, \u2202ILP, TransE, and RotatE on benchmark datasets like ES, FB15K-237, and WN18. NLIL is evaluated on benchmark datasets like ES, FB15K-237, and WN18, showing results in Table 1. Compared to NeuralLP, NLIL yields promising results. NLIL achieves slightly higher scores than NeuralLP on FB15K-237 and WN18 benchmarks due to favoring symmetric/asymmetric relations or compositions of a few relations. However, NLIL is significantly outperformed by RotatE on FB15K, as NLIL searches over a highly constrained symbolic space. Despite this, NLIL's learned rules are still reasonably predictive, comparable to TransE. Additionally, NLIL can explore longer rules efficiently. NLIL can efficiently explore longer rules compared to NeuralLP, as demonstrated by the scalability for long rules. The search time for length 32 in NLIL is similar to that for length 3 in NeuralLP. This ability extends NLIL's applications beyond canonical KB completion to tasks like visual object detection and relation learning. By learning FOL rules, supervised models can generate scene-graphs for each image, representing a relational KB for ILP. The text discusses using ILP to learn FOL rules on a relational KB generated by supervised models. Experiments are conducted on the Visual Genome dataset, with scene-graphs converted to KBs. ILP is performed to explain the top 150 objects, and the learned rules are evaluated for object class label prediction. NLIL is compared with supervised baselines MLP-RCNN and Freq for object label prediction on a held-out set. NLIL achieves a comparable score on R@1 solely relying on KBs with sparse binary labels, outperforming Freq significantly. The supervised method achieves the best scores due to highly informative visual features. Neural Logic Inductive Learning (NLIL) outperforms Freq significantly in object label prediction, showcasing the ability to learn explanatory rules beyond superficial correlations. NLIL demonstrates data efficiency and transferability, maintaining high accuracy with less than 1% of the training set. The proposed differentiable ILP framework scales effectively to large datasets, offering a scalable method for explaining decisions of supervised models. Traditional ILP methods like AMIE+ and RLvLR rely on explicit search-based rule mining with pruning techniques, scaling to large knowledge bases. However, the algorithm complexity grows exponentially with the size of variables and predicates, limiting rule expressiveness to Horn clauses of less than 3 length. These methods use hard matching and discrete logic for rule search, lacking tolerance for ambiguity compared to differentiable approaches. The state-of-the-art forward-chaining methods focus on rule learning with predefined templates in the form of Horn clauses. Rules are evaluated by applying them to a background set of facts until no new deductions can be made, then compared to a ground-truth set. While these rules are data-independent and interpretable, the deducing phase can become infeasible with larger background sets. \u2202ILP has proposed a fixed number of steps to alleviate this issue, but scalability remains a challenge. Differentiable ILP methods like NTP and NLM offer efficient rule evaluation and learning on KBs, but scalability remains a challenge due to limited expressiveness and tensorized operations. NLM can handle deductive and inductive learning but struggles with real-world KBs due to permutation operations. Multi-hop reasoning methods like NeuralLP construct rules on-the-fly for specific queries, using a flexible ILP setting. This approach is highly scalable for learning rules on large datasets like FreeBase, but it reasons over a single chain-like path sampled through random walks independent of the task context. Link prediction with relational embeddings involves using learnable embeddings for KB relations to predict links with scoring functions. Various methods such as mapping KB relations into vector space and parameterizing relations into neural networks have been proposed. These approaches use embeddings for predicting links directly, unlike NLIL which uses predicate embeddings for generating data-independent rules. NLIL uses predicate embeddings for generating data-independent rules, which involves complex ILP procedures due to vast search spaces and variable binding. NLIL uses predicate embeddings for generating data-independent rules, involving complex ILP procedures with vast search spaces and variable binding. Different bindings of variables in formulas lead to different meanings, with O(n^n) possible assignments for a formula with n arguments. Existing ILP works either use pre-defined templates or chain-like variable references, limiting rule expressiveness. Evaluating a formula candidate is costly, requiring grounding or instantiation of variables with actual entities. Each variable in a formula can be grounded independently, resulting in O(C^n) grounded formulas, where C is the total number of entities. NLIL uses predicate embeddings for generating data-independent rules with complex ILP procedures. Evaluating formulas involves instantiating variables into possible combinations, which can be infeasible in domains like object detection. Forward-chaining methods like \u2202ILP scale exponentially in grounding space size. Experiments are conducted on a machine with specific specifications. Various baseline models are used with separate Transformer blocks for each target predicate in NLIL. Experiments are conducted on a machine with i7-8700K, 32G RAM, and one GTX1080ti. The embedding size is d = 32, with 3 layers of multi-head attentions for each Transformer network. The number of attention heads is set to 4 for encoder and the first two layers of the decoder. For KB completion task, the number of operator calls T = 2 and formula combinations L = 0 are used. In FB15K-237, binary predicates are grouped hierarchically into domains for rule body construction. For the VG dataset, T = 3, L = 2, and C = 4 are set for rule body construction. Evaluation metrics include Mean Reciprocal Ranks (MRR) and Hits@10. MRR is the average reciprocal rank of queries in ranking lists, while Hits@10 is the percentage of queries ranked within the top 10."
}