{
    "title": "H1BO9M-0Z",
    "content": "Learning high-quality word embeddings is crucial for better performance in various learning tasks. Traditional embeddings trained on large corpora may not be optimal for domain-specific tasks with limited data. This paper proposes a lifelong learning approach to generate domain embeddings by leveraging knowledge from past domains and a small new domain corpus. The method utilizes a meta-learner to provide word context similarity information effectively. The proposed method effectively learns new domain embeddings from a small corpus and past domain knowledge. It shows that general-purpose embeddings trained on a large scale corpus are sub-optimal for domain-specific tasks. Word embeddings have been effective in various NLP tasks, capturing syntactic and semantic information associated with words. The \"secret sauce\" of training word embeddings lies in turning a large-scale in-domain corpus into domain-specific embeddings. The \"secret sauce\" of training word embeddings involves turning a large-scale in-domain corpus into billions of training examples. However, real-world learning tasks often do not meet the assumptions of having a large training corpus closely related to downstream tasks. General-purpose embeddings trained on a large corpus may underperform on domain-specific tasks due to the mismatch in domain relevance. The limited domain corpus can lead to sub-optimal performance on domain-specific tasks. One solution is to use transfer learning for training domain-specific embeddings, but this method relies on out-of-domain embeddings and does not expand the in-domain corpus. Additionally, manually identifying similar source and target domains is a common assumption in these methods. Lifelong machine learning (LML) is a continual learning paradigm that retains knowledge from past tasks to help with new tasks. In the context of word embedding, the system generates word embeddings for new domains based on previous domain corpora. The main challenges of generating word embeddings for new domains include identifying useful past domain knowledge and automatically identifying such information without human intervention. The system aims to learn how to identify similar words in different domains for a given word in a new domain, which falls under metalearning. The paper proposes the concept of lifelong word embedding, which has not been explored before and could benefit various downstream learning tasks. The proposed lifelong embedding learning method leverages meta-learning to aggregate knowledge from past domain corpora for generating embeddings in new domains. Previous methods for word embeddings have used complex neural network architectures, but a recent unsupervised model called skip-gram simplifies this process by predicting surrounding words in a context window. However, these embeddings may not be optimal for domain-specific tasks. Our work focuses on lifelong machine learning (LML) for word embedding, which is different from transfer learning. LML aims to leverage past domain knowledge for generating embeddings in new domains, addressing the problem of uncertain relevance and lack of guidance in learning from past domains. This approach is distinct from traditional supervised and unsupervised methods in word embedding. The proposed method leverages meta-learning to accumulate knowledge during lifelong learning by learning domain-level word context similarity from past domain corpora. The system uses a meta-learner to catch useful past domain knowledge when a new domain arrives. The meta-learner plays a central role in identifying useful knowledge from past domains to help the new domain. It uses a pairwise network to find similar words in past domains, then combines co-occurrence knowledge with the new domain corpus to train new domain embeddings. The challenge lies in determining what knowledge to borrow from past domains. In BID2; BID31, it is assumed that shared words between domains have similar meanings, but borrowing knowledge from a non-relevant domain can be harmful to word embeddings. For example, the word \"java\" has different meanings in programming and restaurant contexts. A meta-learner is used to learn general word context similarity from multiple domains, with m domains sampled from n domains. Experiments are conducted on hundreds of domains, with m domains held out to train the meta-learner. The meta-learner is trained on hundreds of domains, with m domains held out for training. It takes pairs of words from similar or different domains as input and determines if they are from the same domain. Words in domain corpora are characterized by their co-occurrence counts with frequent words. Top frequent words over m domains are denoted as Vwf. Subcorpora are sampled from each domain corpus for analysis. The meta-learner is trained on pairs of word features from different domain sub-corpora. It selects chunks from each domain corpus and uses top frequent words as training examples. Pairwise meta-learner is trained on positive and negative examples to determine if words are from the same domain. The text discusses training a meta-learner on pairs of word features from different domain sub-corpora. A neural network is used to learn pairwise domain-level word context similarity, with a focus on efficiency and memory optimization for high-throughput inference in lifelong learning settings. The text discusses training a meta-learner on pairs of word features from different domain sub-corpora using a neural network. The network includes a shared fully-connected layer, a cosine function for similarity, and a sigmoid layer for predictions. The trainable weights focus on learning continuous features for words, serving as general word embeddings. The meta-learner is trained on a hold-out domain set and then fine-tuned on a new domain corpus. The lifelong learning system described in this section utilizes a base meta-learner M trained on n \u2212 m domains and a new domain corpus D n+1. Knowledge is stored in a knowledge base K, which includes vocabularies, domain corpora, and word features. The system fine-tunes the base meta-learner for the new domain, resulting in a fine-tuned meta-learner M n+1. The lifelong learning system fine-tunes the base meta-learner for a new domain by retrieving past domain knowledge and storing useful information for embedding training. Relevant words from past domains are retrieved and stored for future use. The lifelong learning system fine-tunes the base meta-learner for a new domain by retrieving and storing relevant words from past domains. The fine-tuned meta-learner finds similar words with a probability higher than a threshold, controlling the quality of accumulated words. The goal is to learn a vector representation for each word in the new domain corpus using the skip-gram model. The skip-gram model aims to learn word vectors by predicting context words in a corpus. It can handle large corpora with billions of training examples to train word vectors for similarity with context words. However, smaller domain corpora may not benefit from this scale of training. The skip-gram model is used to learn word vectors by predicting context words in a corpus. However, for smaller domain corpora, a random sequence of words from other domains may not accurately reflect the word distribution. To address this issue, augmented word co-occurrence information is integrated into the skip-gram model for new domain corpora. The study presents evaluations of a new approach that integrates augmented word co-occurrence information into the skip-gram model for smaller domain corpora. The effectiveness of the approach is assessed through various domain-specific downstream tasks using Amazon Review datasets. The study evaluates a new approach integrating augmented word co-occurrence info into the skip-gram model for smaller domain corpora. Three new domains (\"Computer Components\", \"Cats Supply\", \"Kitchen Storage and Organization\") are selected for product type and sentiment classification tasks. \"Laptops\" domain is chosen for aspect extraction. Each new domain corpus is limited to 10 MB and 30 MB. 56 domains are randomly selected for meta-learner training. Validation and testing domains have no overlap with training domains. The validation and testing domain corpora do not overlap with the training domain corpora, leading to a more general meta-learner for unseen new domains. Sub-corpora are sampled from each domain, limited to 10 MB, with 5000 top words selected as features. Pairwise examples are obtained by selecting 500 words from each domain. The meta-learner achieves an 81% f1-score. Further fine-tuning is done for each new domain, with 3500 training examples, 500 validation examples, and 2000 testing examples. The testing f1-score is reported, and a threshold of delta = 0.7 is empirically set. The f1-score is shown in TAB0, with a threshold set at delta = 0.7. Embedding layers with dimensions of 300 are used for downstream tasks, frozen during training to reduce model and data influence. A Bi-LSTM model with an input and output size of 128 is applied on top of the embedding layer for task-specific feature learning. Many-to-one Bi-LSTMs are used for classification tasks, except for aspect extraction which utilizes many-to-many Bi-LSTM for sequence labeling. The curr_chunk discusses different types of word embeddings used in downstream tasks, including No Embedding (NE), fastText, and GoogleNews. It highlights the limitations of using Wikipedia corpus for specific domains and compares its size to Amazon Review datasets. The curr_chunk discusses various pre-trained word embeddings such as GoogleNews, GloVe. Twitter.27B, GloVe.6B, and GloVe.840B, each based on different datasets with varying token counts. It mentions that GloVe.840B, trained from Common Crawl, is the largest corpus but may not perform optimally on domain-specific tasks like classifying Amazon product reviews. The curr_chunk discusses the creation of multi-class classification sub-tasks using randomly selected domains from Amazon product categories. Three domains chosen are Computer Components, Kitchen Storage and Organization, and Cats Supplies. Each sub-task has a specific number of classes based on the availability of reviews. Testing data consists of 10,000 reviews for each sub-task, with the remaining data split for training and validation. Accuracy is the evaluation metric used, and each sub-task is trained and evaluated multiple times for consistency. The dataset used is from SemEval-2014 Task 4: Aspect-based. The curr_chunk discusses using the SemEval-2014 Task 4 dataset for aspect-based sentiment analysis in the Laptop domain. The dataset contains annotated Laptop aspects and polarities, with 3045 training examples and 800 testing examples. Lifelong embedding is trained on the Amazon Review Dataset's Laptop domain corpus, showing good performance in aspect extraction. The results are averaged over 10 runs, with a focus on precision, recall, and F1-score. The study highlights the importance of both general and domain-specific embeddings for aspect extraction. The curr_chunk discusses sentiment classification using domain-specific embeddings and polarity words to determine sentiment in reviews. The results are based on 6000 positive and 6000 negative reviews from 3 domains, with 10000 reviews used for testing. The performance of domain-specific baselines is similar, and leveraging domain corpus reduces the impact of non-polarity information in embeddings. Sentiment classification relies on words like \"good\" or \"bad\" to determine sentiment. The curr_chunk discusses expanding domain-specific training corpus for sentiment classification, focusing on improving performance by leveraging larger scale domain-specific data. The method involves combining existing pre-trained embeddings with domain-specific embeddings to enhance results. The curr_chunk introduces a method that improves domain-specific parts of embeddings by concatenating them with existing pre-trained embeddings. This approach allows for leveraging a larger corpus and enhancing performance in downstream tasks. The method involves a lifelong word embedding learning process that effectively generates new domain embeddings using a meta-learner. The proposed method involves a meta-learner providing word context similarity information on domain-level to improve domain-specific embeddings. Experimental results demonstrate its effectiveness in learning new domain embeddings from a small corpus and past domain knowledge."
}