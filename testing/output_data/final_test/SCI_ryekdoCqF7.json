{
    "title": "ryekdoCqF7",
    "content": "Generative neural networks aim to map a standard distribution to a complex high-dimensional distribution representing real-world data. A training framework is proposed to incrementally capture diversity in the target space using generative adversarial networks. The algorithm converges to the optimal distribution, projecting the real distribution onto the network's distribution space. Generative Adversarial Nets (GAN) BID5 is a framework for estimating generative models by training two target network models simultaneously. Generative Adversarial Networks (GAN) involve a training framework where a generator creates samples resembling real data, while a discriminator distinguishes between generated and real data. This process aims to minimize divergences like Shannon divergence. The goal is to find a distribution in the generator's range that best approximates the data distribution. The range is defined by the input latent variable and architecture. The real data distribution is typically high dimensional, making it difficult to perfectly describe. The goal is to find the I-projection BID2 of the real data distribution on the generator's range. If the range is convex, the optimal distribution in the generator can approximate the real data set. However, if the range is non-convex, using multiple generators with a convex combination can better approximate the data distribution. In this paper, a sequential training procedure is proposed to improve performance by adding generators one by one without retraining previous ones. An objective function tailored for incremental training is derived, maximizing marginal contribution when adding a new generator. This approach aims to better approximate the real data distribution by using a convex combination of generators. The algorithm proposed in the study aims to improve performance by adding generators sequentially without retraining previous ones. It maximizes marginal contribution when adding a new generator and converges to the projection of real data distribution to the convex hull of the ranges of generators. Experimental results demonstrate the algorithm's ability to overcome local optimal issues and reduce divergence between mixture distribution and real data efficiently. Recent research has focused on enhancing generative adversarial neural networks. The Unrolled GAN improves the discriminator by optimizing the objective during training to stabilize it and reduce mode collapse. D2GAN uses two discriminators to treat different modes fairly and avoid mode collapse. DFM incorporates a Denoising AutoEncoder into the generator's objective to minimize reconstruction error. McGan utilizes mean and covariance feature matching to stabilize GAN training. Our work focuses on enriching the expressiveness of the generator by combining multiple generators, unlike previous works that concentrate on improving the discriminator. Wang et al. (2016) proposed self-ensembling GANs and Cascade GAN as heuristic methods to stabilize training, but with no theoretical guarantee. Several methods have been proposed to improve training in GANs, such as MGAN, multi-agent GANs, MIX+GAN, and AdaGAN. These methods aim to enhance diversity and stability in training, but they require training multiple generators simultaneously and lack flexibility in adjusting the number of generators. Additionally, AdaGAN utilizes a reweighting scheme on the dataset to focus on previous bad training data. In Section 5, a comparison is made between a new algorithm and AdaGAN, focusing on their approach to training data. The new algorithm, GAN BID5, uses latent variables to generate samples that approximate the target distribution in a high-dimensional space. It minimizes the f-divergence between real and generated data distributions. The f-GAN minimizes the f-divergence between real and generated data distributions. A novel framework is proposed to train multiple generators sequentially, avoiding issues like mode collapse by maintaining a group of generators and rebalancing weights. The text describes a method to train multiple generators sequentially to avoid issues like mode collapse. It involves adding a new generator at each step, rebalancing weights, and defining a distribution range for each generator in a group. This approach aims to improve performance and address the local optima problem. The text discusses using a generator group to enhance performance and address local optima problems. An incremental training algorithm is proposed to sequentially add generators to the group, with a focus on maximizing the contribution of each generator to the group. The algorithm aims to produce the desired distribution while avoiding mode collapse. The text discusses maximizing the contribution of each generator in a group to enhance performance and avoid mode collapse. Different loss functions are used for each generator, with a focus on minimizing the distance between the generated distribution and the real distribution. The \u03c72-divergence is introduced as a special case of the f-divergence, with the latter being well-approximated by the former when distributions are close. The text discusses the use of \u03c72-divergence as a special case of f-divergence for minimizing the distance between generated and real distributions in a group of generators. The objective function equation is rewritten for \u03c72-divergence, and adversarial training is conducted using an auxiliary discriminator T. The target distribution for each generator depends on the real distribution and previous generators, leading to enhanced performance and avoidance of mode collapse. The text introduces an incremental training algorithm for a group of generators, showing that the output distribution will converge to the closest one to the target distribution. The algorithm optimizes each generator to minimize the distance between the target and generated distributions. The algorithm optimizes each generator to minimize the distance between the target and generated distributions, converging to the optimal distribution within the convex hull of the target distribution. The algorithm optimizes generators to minimize distance to target distribution in a Hilbert space. It converges to the optimal distribution within the convex hull of the target distribution. The algorithm can converge to new optimal distribution with finite change in target distribution. Our algorithm generalizes dynamic online settings and improves performance of mixture distributions as the number of generators increase. Experiments were conducted on Gaussian, CelebA, and MNIST datasets using Adam optimizer with specific parameters. In BID14, an auxiliary neural network is trained to measure the divergence between generated and real data. The network's architecture is similar to the discriminator used in experiments, trained for 50 epochs. Experiments are conducted in R2 space with data sampled from Gaussian distributions. In BID14, an auxiliary neural network measures divergence between generated and real data in R2 space sampled from Gaussian distributions. In a high dimensional space, generators approximate data distribution with increasing number covering data away from the centre to gain marginal profit. The dimension of z is reduced to 1 for simplified network architecture. Our algorithm outperforms AdaGAN BID15 and Orignal GAN in terms of converging to the real distribution quickly and achieving the best performance. Training up to 20 generators with the same starting generator, we measure D \u03c7 2 (p||q) between real and generated distributions. Our algorithm approaches p real faster and achieves the best performance among all three methods. Our algorithm outperforms AdaGAN and Original GAN in quickly converging to the real distribution and achieving the best performance. Training up to 22 generators on the MNIST dataset, we use z \u223c N (0, 1) as the latent variable. Our algorithm gradually approximates the real data distribution, showing superior performance compared to Original GAN but inferior to AdaGAN initially. As the number of generators increases, AdaGAN encounters a bottleneck while our algorithm and Original GAN continue to approximate the real distribution. Further training up to 100 generators shows both our algorithm and Original GAN gradually converging to the real data distribution. Our algorithm shows faster convergence to the real data distribution compared to AdaGAN and the original GAN. The distance decreases as the number of generators increases, with our algorithm achieving better performance. Interestingly, while the original GAN tends to search for a distribution closer to the real data, our algorithm searches for a complementary distribution within the generators' group. Our algorithm outperforms AdaGAN and the original GAN in convergence to the real data distribution. The distance decreases with each additional generator, showing better performance. Our algorithm searches for a complementary distribution within the group of generators, unlike the original GAN which aims for a distribution closer to the real data. The algorithm improves convergence compared to AdaGAN and the original GAN by finding a complementary distribution among generators. The distance decreases with each additional generator, leading to better performance. The algorithm aims for a distribution within the group of generators, unlike the original GAN which targets a distribution closer to the real data. The text discusses bounding d n+1 by p + nT n and the projection of \u03a0 on \u2212nT n. The algorithm improves convergence by finding a complementary distribution among generators, leading to better performance. The text discusses bounding d n+1 by p + nT n and the projection of \u03a0 on \u2212nT n. The upper bound is increasing in d n, with a proof that d * n \u2264 n + \u221a nd. The proof of corollary 1 involves changing the optimal projection of target distribution from \u03c1 to \u03c1 after n 0 iterations. Finally, for KL-divergence and \u03c7 2 -divergence, the corresponding functions are f KL (t) = t log(t) and f \u03c7 2 (t). The monotonicity of F(t) implies F(t) min \u2265 -0.42."
}