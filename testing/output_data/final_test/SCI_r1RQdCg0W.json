{
    "title": "r1RQdCg0W",
    "content": "Merged-Averaged Classifiers via Hashing (MACH) is a $K$-classification algorithm that reduces memory and inference costs compared to traditional classifiers. It only requires $O(d\\log{K})$ memory and $O(K\\log{K} + d\\log{K})$ operations for inference. MACH uses universal hashing to handle large numbers of classes efficiently, achieving a classification accuracy of 19.28\\% on the ODP dataset with 100,000 classes and 400,000 features using a single Titan X GPU. MACH achieves 19.28% classification accuracy on a dataset, outperforming a baseline with 9% accuracy and a much larger model size. It allows training of fine-grained imagenet dataset with 21,000 classes on a single GPU, demonstrating efficiency in extreme multi-class classification tasks. The growth in the number of classes or labels of interest is a well-known phenomenon in AI. Many hard AI problems can be modeled as massive multi-class problems, leading to significant improvements in NLP tasks like machine translation and word embeddings. Public datasets with a large number of classes, such as Microsoft's ODP data with over 100,000 classes, are readily available. The popularity of word classification has led to the development of state-of-the-art models for large datasets with vocabulary sizes running into billions. The document discusses the challenges of deploying classifiers with a large number of classes, such as the Imagenet dataset with over 21,000 classes. The memory requirements scale linearly with the number of classes, making it difficult to deploy models with high-dimensional datasets. For example, a simple logistic regression model for an ODP dataset with 400,000 features and 100,000 classes would require 160 gigabytes just to store the model parameters, posing a significant deployment cost. This issue also applies to deep networks with softmax output layers, where the final layer can become a memory bottleneck during inference. The final layer in deep networks is a memory bottleneck, and inference with linear classifiers is computationally expensive. Training with large parameter spaces, like the 40 billion in the ODP dataset, is challenging due to non-parallelizable iterations and time-consuming convergence. Existing methods require distributed clusters or large server machines with significant RAM. Recent studies focus on reducing prediction time by increasing model size, with two main approaches identified. Memory is a primary barrier in extreme classification, with methods like BID13 and BID15 aiming to reduce prediction time by using locality sensitive hashing and smartly learned trees. However, these approaches come with increased memory requirements and complexity, impacting parallelism during inference. In extreme classification, reducing memory is a challenge. Various methods like hashed nets and Huffman compression aim to compress the parameter space to save memory. However, the compression and decompression process for accessing parameters can lead to costly overheads. In extreme classification, reducing memory is a challenge. Various methods like hashed nets and Huffman compression aim to compress the parameter space to save memory, but this can lead to costly overheads. Most compression methods only provide a constant factor improvement without formal guarantees. Dimensionality reduction techniques focus on decreasing factors d and K for computations and memory reduction. Multi-label and structured predictions involve tasks with a large number of classes, but exploiting structure can help reduce computations and memory. Our focus is on reducing computations and memory in K-class classification without assuming any relations between classes. Existing methods trade off inference time with memory, but our approach aims to reduce both simultaneously. This work introduces a novel method for K-class classification that provides theoretical guarantees on the tradeoffs. The work introduces a hashing based algorithm MACH for K-class classification, reducing model size and computational complexity. MACH uses random hash functions to assign classes to buckets, simplifying the classification problem. The algorithm is parallelizable and provides theoretical guarantees on computation accuracy tradeoffs. The algorithm MACH provides strong theoretical guarantees on computation accuracy tradeoffs, achieving 19.28% accuracy on the ODP dataset with only 1.2GB model size. It outperforms previous accuracy on the dataset and requires only a single GPU. The MACH algorithm achieves high accuracy on the ODP dataset with a small model size of 1.2GB. It outperforms previous models and requires only a single GPU for training. The one-vs-all classifier reaches 9% accuracy with 160GB data and needs high-memory servers. Training MACH on a single Titan X GPU takes 7 hours, but with 25 GPUs, it only takes 17 minutes. Linear classifiers can be trained on fine-grained imagenet features with 21000 categories in 23 hours on a single Titan X or in an hour with 20 GPUs. This work demonstrates training linear classifiers over 100,000 classes on a single GPU and fine-grained Imagenet with 21000 classes on a single GPU, showcasing the power of MACH for extreme classification scenarios. The MACH algorithm introduces Merged-Averaged Classifiers via Hashing for extreme multi-class classification. It utilizes universal hashing to reduce computations and memory usage. The algorithm is the first of its kind in the classification literature to demonstrate the benefits of universal hashing. The MACH algorithm proposes a method of reducing computations and memory in extreme multi-class classification by randomly merging classes into meta-classes using universal hashing. This approach involves running off-the-shelf classifiers on the meta-classes and aggregating the results from multiple classifiers during prediction. The algorithm is theoretically sound and requires only log K memory, with connections to compressed sensing and heavy hitters literature. The MACH algorithm reduces computations and memory in multi-class classification by merging classes into meta-classes using hash functions. Each hash function maps classes into buckets, allowing for parallel training of classifiers on the transformed data. Meta-classifiers can only classify among merged meta-classes, with probabilities denoted as Pjb for each classifier. During prediction, the algorithm estimates the probability of class i using the expression Pj hj(i)(x). The classification rule is arg max i Pr(y = i|x) = arg max i \u03a3j=1 Pj hj(i)(x), where the predicted class is the one with the highest sum of probabilities. The details are outlined in algorithms 1 and 2, with the total model size of MACH being BRd. The total model size of MACH is BRd to store R models of size Bd each. Prediction cost requires RBd multiplications for meta probabilities and KR computations for each class. No assumptions are made on classes or dependencies. R independent B-class classifiers are used, modeling probabilities with 2-universal hash functions. The MACH model uses R independent B-class classifiers with 2-universal hash functions to model probabilities. The memory and computational complexity for prediction are O(Kd) for a d-dimensional dataset. The MACH model uses R independent B-class classifiers with 2-universal hash functions to model probabilities. The computational complexity for prediction is O(Kd). The memory complexity is roughly O(BR + KR). To identify the final class with high probability, BR \u2248 O(log K) is sufficient. Classes c1 and c2 are indistinguishable under MACH if they fall in the same meta-class for all R hash functions. With R independent B-class classifier models, any two original classes c1 and c2 will be indistinguishable with probability at most Pr(classes i and j are indistinguishable). The MACH model ensures that all pairs of classes are distinguishable with high probability by using R independent B-class classifiers with 2-universal hash functions. The memory complexity is reduced to O(log Kd) from O(Kd) with approximations, guaranteeing distinguishability with probability 1 - \u03b4. The inference cost is 2 log DISPLAYFORM11, significantly smaller than Kd for high dimensional datasets. A generic classifier outputs probabilities p i, which can be compressed to log K = BR numbers. Identifying arg max p i with p i = 1 and max p i \u2265 1 m p i is a classical heavy hitter problem in classification. The Count-Min sketch BID6 algorithm is commonly used to find heavy hitters in data streams. By using R universal hashes with B range, we can identify heavy hitters with good signal-to-noise ratio. This method connects compressed sensing and sketching algorithms with extreme K-class classification, showcasing advancements in computational problem-solving. Public benchmarks like the ODP dataset are used in this work. The study utilizes two large public benchmarks from BID7: the ODP dataset and Fine-grained Imagenet. ODP is a multi-class dataset extracted from the Open Directory Project, featuring bag-of-words document samples with 105,033 categories. Imagenet consists of features from a CNN trained on ILVSRC2012, with 21,841 fine-grained object categories. These datasets cover different domains. The datasets used in the study cover different domains - images and text. Only one published work has successfully trained a standard linear classifier on these challenging datasets. Experiments were conducted on a server with specific hardware, using Tensorflow for training models and OpenCL for computing scores. Codes and scripts are available on Github for reproducibility. Three published methods have reported results on these large benchmarks. Our proposal MACH is the only method that reduces model size compared to OAA, LOMTree, and Recall Tree. These methods are taken from BID7 and have larger model sizes than OAA. Our system cannot run these methods due to memory limitations, as they require more than 160GB model file while our system has 64GB capacity. Our system has a 64GB capacity, limiting the models we can run. Using MACH, we compared accuracy on two datasets by varying B and R. MACH outperformed OAA, achieving 18% accuracy compared to 9%. Even with B = 32 and R = 25, we achieved over 15% accuracy with a significantly reduced model size of 1.2GB, compared to OAA's 160GB requirement. MACH outperformed OAA in model size reduction, achieving 480x smaller size with R = 50 and B = 4, requiring only 0.3GB. MACH cancels noise for better generalization, while other baselines may suffer from feature hashing loss. On Imagenet, MACH achieved 11% accuracy with R = 20 and B = 512, using 2 times less memory than OAA. OAA achieved 17% accuracy, but MACH can run at any memory budget. With MACH, training is easy as it only requires running small logistic regression parallelized over multiple GPUs. The prediction time involves computing probabilities of meta-classes and aggregating them sequentially. Running time decreases with more machines due to MACH's parallelism. MACH allows for easy training with logistic regression on multiple GPUs and faster wall clock times compared to RecallTree. It enables training of large datasets on a single GPU, and the hope is for its adoption in practice."
}