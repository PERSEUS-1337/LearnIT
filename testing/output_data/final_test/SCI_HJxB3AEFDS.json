{
    "title": "HJxB3AEFDS",
    "content": "We introduce a novel method for converting text data into abstract image representations, allowing image-based processing techniques to be applied to text-based comparison problems. The method is applied to entity disambiguation of inventor names in US patents, achieving highly accurate results. This text-to-image representation method could be used for other NLP comparison problems or simultaneous classification tasks. The text discusses the challenges of identifying individuals in databases of patent applications and academic publications due to similar or ambiguous names. Resolving this ambiguity is crucial for accurately assigning patents to the correct individuals. Machine learning algorithms are used for automated disambiguation of inventor names in databases, outperforming traditional methods. Researchers select string similarity measures as input for these algorithms. The novel approach introduces a new method for representing text-based data, allowing image classifiers to perform text classification. This representation enables machine learning algorithms to learn features from the data instead of relying on pre-defined string similarity measures. The name disambiguation problem is treated as a classification issue, assessing pairwise comparisons between inventor records. The text-to-image representation method converts associated text for each pairwise comparison. Our text-to-image representation method converts text strings into a 2D color image, allowing image processing algorithms to be applied to text-based natural language processing problems. By combining this method with a convolutional neural network, we achieved highly accurate results in inventor name disambiguation studies. In inventor name disambiguation studies, various measures of string similarity, such as n-grams, edit distance, and phonetic algorithms, are used to automate discrimination decisions with high accuracy (F1: 99.09%, precision: 99.41%, recall: 98.76%). String similarity measures are used in inventor name disambiguation algorithms and machine learning models. These measures can be inputted into random forest models for classification tasks. Additionally, CNNs have been utilized in image processing and text classification applications. Neural networks, including character-level CNNs, have been used for text classification and pairwise comparison decisions in various applications such as images, image patches, sentences, signatures, and faces. Siamese neural networks connect two identical sub-networks for processing multiple images simultaneously. Single 2-dimensional RGB images are generated for pairwise record comparison, allowing image classification networks to process them with minimal modification. The text discusses using neural networks, specifically the \"AlexNet\" image classification network, to classify text records based on pairwise comparison images. Two labelled datasets, the \"IS\" dataset of Israeli inventors and the \"E&S\" dataset of patents filed by engineers and scientists, were used to train the neural network. The datasets contain unique IDs for inventor-name records from different patents. The inventor disambiguation algorithm involves removing duplicates, blocking names by last name, generating pairwise comparison-map images, and training a neural network using manually labeled data. The inventor disambiguation algorithm involves training a neural network to classify pairwise record comparisons as matches or non-matches, then converting match probabilities into inventor clusters with unique IDs for disambiguated inventor names. This process improves computational efficiency by grouping similar records before pairwise comparisons. In the inventor disambiguation algorithm, records are grouped into clusters for pairwise comparisons. A new method converts text into image representations for classification using neural networks. The process involves defining a 2D character layout and generating comparison-map images for text classification. The layout of the \"string-map\" is illustrated in Figure 1, where colors are added to pixels of each letter in a word and connecting lines. The final string-map for a word like \"JEN\" is shown in the right-most image. By adding the string-map of another word to the green channel of the same RGB image, a pairwise comparison of the two words is represented. This method is used for generating string-maps for each variable in an inventor name record. The \"recordmap\" combines various variables in an inventor name record into a single image. A \"comparison-map\" is created by stacking two record-maps into an RGB image, with similar records showing more yellow and dissimilar records showing more red and green. The neural network learns to identify features in comparison-map images to discriminate between matched/non-matched records. The layout of the string-map in Figure 1 was chosen heuristically to emphasize consonants over vowels and group similar letters together. The heuristic layout of comparison-map images aims to simplify feature recognition for record matching using neural networks. The method involves converting text into a 2D RGB bitmap for classification, leveraging existing image classification networks with minimal adjustments. The network learns features independently from the data, rather than relying on predefined feature vectors. Performance comparisons between heuristic and random layouts show similar results. The method involves converting text into a 2D RGB bitmap for classification, leveraging existing image classification networks with minimal adjustments. The neural network can potentially learn to ignore certain shapes of common words that are not useful for discrimination decisions. The novel disambiguation algorithm performs well under multiple different choices of alternative string-maps. The text-to-image conversion method can be applied to various text-based comparison problems and combined with image classifiers for classification tasks. The method is demonstrated using the AlexNet CNN, originally designed for color image classification, with slight modifications for pairwise comparison-map images. The text-to-image conversion method using AlexNet CNN is applied to classify pairwise comparison-map images into match/non-match classes. Trained neural network assigns match probabilities to patent data, which are then converted into linked \"inventor groups\" using a clustering algorithm based on pre-selected probability threshold. The clustering algorithm is applied to group inventors based on link strength, removing weakly-linked records. Different parameter values affect precision and recall trade-offs. After clustering, each patent-inventor pair is assigned a unique ID, completing the disambiguation process. The labelled datasets are divided for training and testing, and a neural network is trained to distinguish between matched and non-matched pairs. The labelled datasets are randomly split into training and test data for a neural network to discriminate between matched and non-matched pairs. The network is trained using 75% of the training data, with the remaining 25% used for validation to prevent overfitting. Duplicate removal and blocking are performed on the data, generating comparison-map images for pairwise record comparisons. The trained network is then applied to bulk patent data to generate match/non-match probabilities for all pairwise comparisons within blocks. The disambiguation algorithm evaluates match/non-match probabilities for pairwise comparisons within blocks of patent data. Different threshold values for comparison probability and linking proportion are tested to find the optimal trade-off between precision and recall, based on the highest F1 score. Performance is assessed using labelled test data to estimate precision, recall, splitting, and lumping metrics. The disambiguation algorithm evaluates pairwise links within labelled test data to find the optimal trade-off between precision and recall, using the F1 score as the primary measure. Results from two example runs of the algorithm are compared, showing the best F1 scores obtained using different string-map character orders. The inventor disambiguation algorithm performs well compared to previous studies, outperforming the state-of-the-art study by Kim et al. (2016) and achieving a higher F1 score than Yang et al. (2017). Results are also compared to studies using alternative datasets, showing slightly less equitable comparisons due to variations in F1 scores when evaluated on different datasets. The disambiguation algorithm's performance is competitive with other state-of-the-art algorithms, achieving the highest F1 score in Table 3. Comparisons are made with alternative string-maps, including random character order layouts. The study compares the disambiguation algorithm's performance with alternative string-maps, including random character order layouts. Different settings of comparison probability threshold and linking proportion threshold were used to evaluate precision, recall, and F1 scores for each alternative string-map. Our method of converting text into abstract image representations facilitates robust feature learning for various string-map structures. The name disambiguation algorithm combines image processing with NLP, allowing image classifiers to perform text classification with high accuracy (F1 score: 99.09%). The disambiguation algorithm showed high accuracy (F1 score: 99.09%) and was robust to variations in string-maps. It can be adapted for other NLP tasks like author name disambiguation. The algorithm could potentially process records with text and image data by combining them for comparison. Duplicate inventor name records with identical fields can be easily identified and removed. The disambiguation algorithm efficiently removes duplicate inventor name records by grouping them into blocks based on last names. Each group is processed, assigning a unique inventor ID to the first record and the same ID to all removed duplicate records within the group. Pairwise comparisons are then made within these blocks, ensuring accurate disambiguation. The disambiguation algorithm groups patent-inventor name records by the first three letters of the last name. Large blocks are divided into smaller blocks by increasing the number of letters used for blocking to improve efficiency. This process continues by further subdividing blocks based on the first four, five, six letters of the last name if the number of records within a block exceeds a threshold. The disambiguation algorithm groups patent-inventor name records by the first three letters of the last name, then further subdivides blocks based on increasing numbers of letters for efficiency. The algorithm uses a threshold of n b = 100 for computational efficiency. There is a maximum limit to recall attainable by the algorithm due to some inventors' records being separated across different blocks. The blocking procedure on the dataset is followed by estimating the maximum recall limit using known pairwise matches in the labelled data. The algorithm uses a larger string-map for patent-inventor records with multiple assignees or co-inventors to prevent pixel saturation. Different string-maps are used for IPC codes. The AlexNet network architecture is modified for classification of pairwise comparison-map images. The algorithm modifies the AlexNet network architecture for classification by altering hyperparameters and using a larger string-map for assignees and co-inventors. Default settings for the DIGITS solver are used with a sigmoid decay function for learning rate adjustment. A 2-neuron softmax output layer is used for probability distribution. The algorithm modifies the AlexNet network architecture for classification by altering hyperparameters and using a larger string-map for assignees and co-inventors. Default settings for the DIGITS solver are used with a sigmoid decay function for learning rate adjustment. A 2-neuron softmax output layer is used for probability distribution, but transformations like altering input images and random cropping are not used due to the self-consistency of the images. The clustering algorithm converts pairwise match probabilities into groups of records belonging to a single unique inventor. The inventor group linking algorithm involves converting pairwise match probabilities into binary classes based on a threshold value. It combines sub-groups with enough links into one group and assigns UIDs to isolated records before grouping them. The inventor group linking algorithm combines records based on link strength, removing weakly-linked records to reduce false positive matches. Outside-group links are also recorded. Isolated records are then combined with inventor groups if link thresholds are met. The inventor group linking algorithm combines records based on link strength, removing weakly-linked records to reduce false positive matches. Isolated records are then combined with inventor groups if link thresholds are met. For each resulting inventor group, assign an identical UID to all patent-inventor name records within the group. Random string layouts are analyzed in different scenarios. The text discusses different string-map layouts for co-inventors and assignees, including random character order and pixel co-ordinate layout. It also mentions a comparison-map for smaller string-maps and a record-map layout associated with it."
}