{
    "title": "BJ8c3f-0b",
    "content": "Our approach, based on auto-encoding sequential Monte Carlo (AESMC), utilizes sequential Monte Carlo (SMC) efficiency and deep neural networks' flexibility to model complex conditional probability distributions. We introduce a new training procedure to enhance model and proposal learning, offering a fast and scalable method for simultaneous model learning and proposal adaptation in deep generative models. AESMC, based on SMC, offers improved model learning compared to VAEs and IWAEs. Experiments on time-series data show effective latent space representation for reconstruction and prediction. The method combines SMC efficiency with deep neural networks for modeling complex conditional probability distributions. In this work, new theoretical insights are provided for evidence lower bounds (ELBOs) and proposal learning efficiency. A new training procedure is developed by expressing the gap between ELBO and log marginal likelihood as a Kullback-Leibler (KL) divergence. This allows for investigating algorithm behavior when the KL divergence becomes zero, implying equal proposal distributions to posterior distributions in the IWAE case. The AESMC case has implications for proposal distributions and intermediate targets learned. State-space models (SSMs) are probabilistic models over latent variables x 1:T and observed variables y 1:T. An adaptation to the AESMC algorithm, called alternating ELBOs, uses different lower bounds for updating model and proposal parameters, improving model learning and proposal adaptation. In state-space models (SSMs), inference is challenging for non-linear, non-discrete, and non-Gaussian models, requiring approximate methods like Sequential Monte Carlo (SMC). SMC performs inference on a sequence of target distributions in SSMs, often taken as (p \u03b8 (x 1:t |y 1:t )) T t=1. Model learning involves maximizing the marginal likelihood p \u03b8 (y 1:T ) in the family of models parameterized by \u03b8. Sequential Monte Carlo (SMC) is a method used for inference in state-space models (SSMs) that are non-linear, non-discrete, and non-Gaussian. SMC involves sampling from a sequence of target distributions and computing weights for particles. The algorithm is scalable to large T due to its sequential nature and resampling step. Sequential Monte Carlo (SMC) is a scalable method for inference in state-space models (SSMs). The resampling step in SMC allows the algorithm to focus on promising particles based on new observations, preventing weight divergence. IWAEs provide a lower bound on log likelihood using generative and inference networks. The optimization is done through stochastic gradient ascent (SGA) with reparameterization. Sequential Monte Carlo (SMC) is a scalable method for inference in state-space models (SSMs) that uses stochastic gradient ascent (SGA) with reparameterization. AESMC implements model learning, proposal adaptation, and inference amortization similarly to VAE and IWAE, using SGA on an empirical average of the ELBO over observations. The AESMC ELBO is based on the SMC marginal likelihood estimator, forming a lower bound to the log marginal likelihood. The AESMC ELBO is a lower bound to the log marginal likelihood, optimized using SGA with reparameterization. It involves sampling x until the particle-weight trajectory is obtained, allowing for an estimator of the marginal likelihood. Minibatches are used for gradient updates to form an unbiased estimator. The text discusses obtaining an estimator for the marginal likelihood by making the sampling of latent variables independent of (\u03b8, \u03c6) through reparameterization. Various gradient estimators are explored, with the conclusion that omitting additional REINFORCE terms reduces variance despite introducing a small bias. The gap between ELBOs and the log marginal likelihood is expressed as a KL divergence. The text discusses the gap between ELBOs and the log marginal likelihood as a KL divergence, presenting claims and propositions in Appendix B. Insights into AESMC behavior and advantages/disadvantages of using different ELBOs motivate proposal learning algorithm in Section 4. Definition 1 introduces a standard identity for variational inference and VAEs, with a key observation for expressing a bound for general ELBOs. The text discusses expressing a bound for general ELBOs using KL divergence, presenting claims and propositions in Appendix B. Claim 1 relates a non-negative unbiased estimator to the normalizing constant Z P, with implications for IWAEs. In the context of ELBOs, maximizing the ELBO involves investigating the target and sampling distributions. For VAE and IWAE, maximizing the ELBO is possible by setting the proposal distributions equal. However, for AESMC, achieving the maximum ELBO requires flexibility in learning intermediate target distributions. To achieve the maximum ELBO in AESMC, it is essential to learn a specific factorization of the generative model, not just individual proposals. Propositions 1 and 2 formalize the conditions for equal target distributions and the consequences of not meeting these conditions. This highlights the importance of flexibility in learning intermediate target distributions for maximizing the ELBO in AESMC. For most parameterizations, it is impossible to learn a perfect proposal that tightens the bound in AESMC. ELBO SMC encodes crucial information about the generative model's factorization on inference. SMC is a more powerful inference algorithm than importance sampling, allowing for tackling more ambitious model learning problems. Unlike importance sampling, most problems in SMC have no perfect solution. ELBO SMC outperforms ELBO IS in learning better models due to the inability to achieve a perfect proposal and the sub-optimality of the optimization process. It is crucial to consider the merits of different ELBOs for proposal learning in SMC algorithms. When assessing different ELBOs for proposal learning, the number of particles K can impact the gradient estimators for ELBO IS and ELBO SMC. Using a larger K can lead to tighter bounds but may be harmful for proposal learning in IWAE and AESMC. This is because the accuracy of estimating P can be achieved with various proposal parameters, causing the gradient magnitude to decrease as K increases. As a result, the standard deviation of the gradient estimate relative to the problem scaling actually increases. This effect is illustrated in FIG4 with a kernel density estimator for the gradient estimate distribution at different K values. Increasing the number of particles K can impact the gradient estimators for ELBO IS and ELBO SMC. As K increases, the expected gradient estimate decreases faster than the standard deviation, leading to a higher relative standard deviation. This can result in poor performance as there is an equal probability of the estimate being positive or negative for K > 10, causing instability in parameter updates. In contrast, for K = 1, the gradient estimate is more likely to be positive, leading to clear drift in gradient steps. The critical difference is that \u2207 \u03b8 ELBO does not decrease in magnitude as K increases for model learning. Increasing the number of particles K can impact gradient estimators for ELBO IS and ELBO SMC. As K increases, the gradient estimate decreases faster than the standard deviation, leading to higher relative standard deviation and potential poor performance. The critical difference is that \u2207 \u03b8 ELBO does not decrease in magnitude as K increases for model learning. To address these issues, the ALT algorithm updates (\u03b8, \u03c6) in a coordinate descent fashion using different ELBOs and gradient estimates for each. In an optimization step, estimators for \u2207 \u03b8 ELBO and \u2207 \u03c6 ELBO are obtained with different numbers of particles. Using A \u03b8 = SMC and A \u03c6 = IS with large K \u03b8 and small K \u03c6 may improve model and proposal learning. Experimental results show that this approach can enhance both model and proposal learning. The study investigates the impact of using more particles or a better inference procedure on proposal learning. It compares AESMC to IWAE and explores improving the model and proposal with ALT. Results show optimizing ELBO SMC leads to better generative models than ELBO IS, especially when using more particles. The study extends findings to high-dimensional observation spaces using neural networks, such as the Moving Agents dataset. The study compares the impact of using more particles or a better inference procedure on proposal learning. It shows that optimizing ELBO SMC leads to better generative models than ELBO IS, especially with more particles. The study extends findings to high-dimensional observation spaces using neural networks. The study investigates the impact of increasing the number of particles on the quality of the learned parameter \u03c6 in a latent variable model. Results show that as the number of particles increases, the quality of \u03c6 compared to the analytic posterior decreases. Additionally, optimizing ELBO SMC for model learning with more particles improves model learning but worsens proposal learning. The ALT algorithm is proposed to address this issue, leading to faster model learning with a more accurate proposal distribution. Extensive experiments in Appendix C.3 compare AESMC and IWAE on stochastic video sequences with N = 5000 image sequences. Each sequence has T = 40 images with a stochastic agent performing a random walk. The dataset is inspired by BID8 but with a stochastic agent movement. The text describes a stochastic agent performing a directed random walk through an image using a Variational Recurrent Neural Network (VRNN). The VRNN introduces a stochastic latent state at each timestep to better model complex long-range variability in stochastic sequences. Architecture and hyperparameter details are provided in Appendix C.1. The text discusses models trained with IWAE and AESMC, showing that AESMC outperforms IWAE with more particles improving ELBO. Different generative models were inspected, with AESMC showing stability compared to ALT. AESMC utilizes a new ELBO objective based on the SMC marginal likelihood estimator, optimized using SGA and the reparameterization trick. Our approach optimizes the ELBO objective using SGA and the reparameterization trick, leveraging the efficiency of SMC in models with intermediate observations. It outperforms the IWAE objective for structured problems, providing better generative model training due to superior inference and tighter bounds. Additionally, we propose a method to express bias induced by log marginal likelihood estimators as a KL divergence on an extended space. In investigating the implications of zero KLs for IWAE and AESMC, we find that achieving zero KL in AESMC requires learning SMC intermediate target distributions corresponding to marginals of the target distribution. In the distribution optimization process, a new method called alternating ELBOs is introduced to address issues with variational bounds. This method aims to improve model and proposal learning by obtaining an unbiased estimator for the gradient. The estimator has higher variance if the first term is included, as demonstrated in a figure. The normalized target density is derived and integrated to marginalize out variables in the support. The text discusses the derivation of target distributions and their unnormalized versions in the context of distribution optimization. It introduces a method called alternating ELBOs to improve model and proposal learning by obtaining an unbiased estimator for the gradient. The normalized target density is integrated to marginalize out variables in the support, leading to the rearrangement of equations to establish equality between certain distributions. The text discusses the derivation of target distributions and their unnormalized versions in the context of distribution optimization. It introduces a method called alternating ELBOs to improve model and proposal learning by obtaining an unbiased estimator for the gradient. The normalized target density is integrated to marginalize out variables in the support, leading to the rearrangement of equations to establish equality between certain distributions. The equations show that the density must be constant with respect to the variables for all time steps. The VRNN architecture details include generative model and proposal distribution specifications, with network configurations for encoding and decoding visual input using convolutional layers and fully connected layers. Transposed convolutions are used for decoding. The VRNN architecture uses transposed convolutions for decoding with stride s = 1 and padding p = 0 for the first layer. A GRU is used as RNN and ReLUs are used between fully connected layers. The proposal and generative model share the component \u03d5 y \u03c6,\u03b8, with \u03c6 = \u03b8 for training. Visual predictions are compared for models learned by IWAE and AESMC using five particles for easier visualization. The VRNN architecture uses transposed convolutions for decoding with a GRU as RNN. Visual predictions are compared for models learned by IWAE and AESMC using five particles. The model predicts stochastic movement over 17 timesteps into the future, with AESMC showing more consistent quality predictions compared to IWAE. AESMC consistently provides higher quality predictions compared to IWAE when optimizing ELBO objectives with different numbers of particles. Training with ELBO SMC with K train = 1000 results in worse performance for inference using SMC, while training with ELBO IS with any number of particles K train improves performance. Increasing the number of particles for testing improves inference quality. Increasing K test improves inference quality, while increasing K train worsens it. Different combinations of training and testing algorithms show varying levels of inference quality. The larger the square in the graph, the worse the inference."
}