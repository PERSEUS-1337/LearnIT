{
    "title": "B1Gi6LeRZ",
    "content": "Deep learning methods have achieved high performance in sound recognition tasks. A novel learning method called Between-Class learning (BC learning) is proposed for deep sound recognition. This method focuses on learning a discriminative feature space by recognizing between-class sounds. By mixing two sounds from different classes with a random ratio, BC learning aims to enlarge Fisher\u2019s criterion in the feature space and regularize the positional relationship among feature distributions. Experimental results demonstrate improved performance on various sound recognition networks and datasets. BC learning improves sound recognition performance on various networks and datasets. A new deep sound recognition network (EnvNet-v2) trained with BC learning surpasses human-level performance. CNNs have been successful in tasks related to series data like speech recognition. Researchers have achieved high performance in sound recognition tasks using CNNs. Quality and quantity of training data are crucial for machine learning, especially for deep learning. Various approaches have been proposed to improve sound recognition performance in machine learning, including data augmentation and using external data or knowledge. A novel third approach called Between-Class learning (BC learning) is introduced to learn a discriminative feature space for deep sound recognition. Between-Class learning (BC learning) aims to create a discriminative feature space by recognizing between-class sounds. This is achieved by mixing two sounds from different classes and training the network to output the mixing ratio. BC learning enhances the variation of training data, enlarges Fisher's criterion BID5, and regularizes the positional relationship among feature distributions. Experimental results demonstrate improved performance on various sound recognition networks and datasets. BC learning improves sound recognition performance on various networks and datasets. A new deep sound recognition network, EnvNet-v2, achieved a 15.1% error rate on ESC-50 dataset, surpassing human level. BC learning differs from traditional data augmentation methods by training the model to output mixing ratios, enhancing generalization ability. The aim is to improve generalization ability by generating additional training data likely to appear in testing phase. BC learning enhances classification performance by predicting mixing ratios between classes, a novel approach. Recent deep learning methods for sound recognition include applying CNNs to log-mel features extracted from raw waveforms. Piczak created a 2-D feature-map using log-mel features extracted from raw waveforms, which were then classified with a 2-D CNN. The log-mel feature-map shows locality in both time and frequency domains, allowing accurate classification with CNN. Researchers have also proposed methods to learn sounds directly from 1-D raw waveforms, including feature extraction with networks like SoundNet. Researchers have proposed various networks for sound recognition, such as SoundNet, BID3, and EnvNet, using 1-D and 2-D convolutional and pooling layers. Learning from raw waveforms remains a challenge due to limited training data, but these systems show performance comparable to Logmel-CNN. Approaches to achieve high sound recognition performance include data augmentation methods like cropping BID16 BID2 BID25 for efficient use of limited training data. Training the network with short sections of the sound input rather than the whole section is also effective. Approaches to achieve high sound recognition performance include data augmentation methods like time stretching, pitch shifting, and mixing multiple training examples. Our method differs by employing a mixing ratio between different classes for training. Additionally, utilizing external data/knowledge for learning rich sound representations has been proposed. The study focused on learning rich sound representations using image and sound pairs from an unlabeled video dataset. They transferred knowledge from pre-trained image recognition networks to a sound recognition network, achieving 74.2% accuracy on the ESC-50 dataset. A novel learning method for deep sound recognition, BC learning, was proposed, utilizing a mixing ratio between different classes for training. BC learning is a novel method for deep sound recognition that involves mixing two training examples from different classes using a random ratio. This mixed data is then input to the model for training, optimizing it to output the mixing ratio. The method aims to create a discriminative feature space and uses mini-batch stochastic gradient descent for optimization. Mixing of examples is not done during the testing phase. The method of BC learning involves mixing two training examples from different classes using a random ratio. This mixing process includes combining the data and labels with the ratio, and then mixing the sounds based on a specific formula that considers sound energy. When mixing sounds in BC learning, using Eqn. FORMULA0 may not accurately represent the dominant sound if there is a large difference in sound pressure levels. Instead of using a fixed ratio, a new coefficient p(r, G1, G2) is proposed to mix sounds based on their sound pressure levels. This approach aims to maintain the auditory perception ratio in the mixed sound. The hypothesis is that the network's perception ratio aligns with the amplitude ratio due to the homogeneity property of CNN components. An equation is derived to calculate the amplitude ratio for mixing sounds. The proposed mixing method in BC learning uses a coefficient p to mix sounds based on their sound pressure levels. The method outperforms Eqn. FORMULA0 in experiments. Sound pressure levels are calculated using A-weighting to account for human auditory perception. Short windows are created to calculate a time series of A-weighted sound pressure levels, with G defined as the maximum of the series. The model function f and parameters \u03b8 are used with mini-batch data to obtain outputs. KL-divergence is used as the loss function instead of cross-entropy, optimized with back-propagation and stochastic gradient descent. BC learning enlarges Fisher's criterion by training the model to output the mixing ratio between classes. BC learning enlarges Fisher's criterion by training the model to output the mixing ratio between classes in the feature space. A mixed sound mixr(x1, x2) is projected near the internally dividing point of f(x1) and f(x2). By adding waveform data of two sounds, a new sound can be generated, and humans can recognize both sounds in the mixed sound. The input space's internally dividing point corresponds to that of the semantic feature space, especially for sounds. The feature distribution of mixed sounds of class A and class B is located near the internally dividing point of the original feature distribution of class A and B. The variance of the mixed sounds is proportional to the original feature distribution of class A and B. Visualizing the feature distributions of the standard-learned model using PCA confirms this hypothesis. The mixture of two sounds is projected near the dividing point of two features, with features distributed between two classes. Fisher's criterion determines the overlap of mixed sounds with class distributions, affecting the model's ability to output the mixing ratio. BC learning penalizes situations with large overlap, encouraging the model to output the mixing ratio. BC learning penalizes large overlap between classes in the feature space, enlarging Fisher's criterion. It also regularizes the positional relationship among class feature distributions. Standard learning may misclassify mixed sounds, as shown in a model output example. The model classifies mixed sounds as baby cry within a specific mixing ratio range. BC learning prevents misclassification by training the model to output the mixing ratio instead of different classes. This approach avoids decision boundary issues between classes. The feature distributions of the three classes form an acute-angled triangle in the feature space. BC learning improves generalization ability by enlarging Fisher's criterion and regularizing the positional relationship among classes. Various sound recognition networks were trained using standard and BC learning on datasets like ESC-50, ESC-10, and UrbanSound8K to demonstrate the effectiveness of BC learning. The datasets ESC-50, ESC-10, and UrbanSound8K contain a total of 2,000, 400, and 8,732 examples with varying numbers of classes. Preprocessing involved converting sound files to monaural 16-bit WAV files and using K-fold cross-validation for evaluation. A simple preprocessing and data augmentation scheme was applied, including padding and cropping sound inputs during training. During testing, sound inputs were padded with zeros and cropped into 10 sections for input to the network. Input data was normalized to a range of -1 to +1. Models were trained using Nesterov's accelerated gradient with specific settings. BC learning requires more training epochs compared to standard learning to prevent overfitting. In the learning setting, various existing networks were trained with BC learning, doubling the training epochs. Networks included EnvNet BID25, SoundNet5 BID2, M18 BID3, and Logmel-CNN + BN. Results showed improved performance on all datasets. The performance of networks on ESC-50, ESC-10, and UrbanSound8K improved by 4.5-6.4%, 1.5-4.0%, and 1.8-4.8% respectively. A deep sound recognition network called EnvNet-v2, based on EnvNet, was trained with both standard and BC learning, showing improved performance. EnvNet-v2 has a higher sampling rate and more layers compared to EnvNet. The results are detailed in TAB1 and training curves are shown in FIG3. The performance of EnvNet-v2 improved significantly with BC learning, outperforming other networks on ESC-50, ESC-10, and UrbanSound8K datasets. The error rate of EnvNet-v2 trained with BC learning was the lowest on ESC-50 and UrbanSound8K. The comparison between standard and BC learning with stronger data augmentation showed the successful utilization of deep networks with BC learning. The results show that EnvNet-v2 performance significantly improved with BC learning, surpassing human performance on ESC-50. BC learning is beneficial for various networks, datasets, and data augmentation schemes, consistently improving performance. The experiments conducted used different numbers of training epochs, with BC learning requiring more epochs for improved performance on ESC-10 and ESC-50 compared to standard learning. BC learning consistently improves performance with a sufficiently large number of training epochs, especially when dealing with many classes. The experiments showed that BC learning improves performance with a large number of classes. Ablation analysis was conducted on EnvNet trained on ESC-50, comparing mixing methods and labels. The proposed mixing method using Eqn. 2 and A-weighting performed the best, while the proposed ratio label of t = r t 1 + (1 \u2212 r) t 2 also showed the best performance. The experiments showed that using a ratio label of t = r t 1 + (1 \u2212 r) t 2 performed the best. Applying a single label of the dominant sound improved performance compared to standard learning. Using a multi-label and sigmoid cross entropy loss also showed better performance, but not as good as the ratio label. The model learned between-class examples more efficiently with the ratio label. Investigating the relationship between performance and the number of mixed sound classes showed that mixing methods and labels play a crucial role in improving performance. The experiments showed that using a ratio label of t = r t 1 + (1 \u2212 r) t 2 performed the best, with N = 2 showing the best performance. Mixing more than two sounds led to increased training data variation but did not efficiently achieve desired results. The enlargement of Fisher's criterion and regularization of positional relationships among feature distributions were identified as key factors in performance improvement. Mixing two examples within the network improved performance, especially when done near the input layer. Mixing in the input space was found to be the best choice as it did not require additional computation and was easy to implement. The proposed BC learning method enhanced deep sound recognition across various networks and datasets. The study improved performance in sound recognition by introducing BC learning with a deeper network called EnvNet-v2. BC learning is a powerful method that enhances various sound recognition techniques by learning discriminative feature spaces from between-class examples. This innovative approach surpasses human-level performance and has the potential to improve tasks in other modalities. EnvNet-v2 is a deep network with 10 convolutional layers, 3 fully connected layers, and 5 max-pooling layers. It uses a sampling rate of 44.1 kHz for rich high-frequency information. The network extracts short-time frequency features and incorporates successful network advantages. The EnvNet-v2 network consists of 10 convolutional layers, 3 fully connected layers, and 5 max-pooling layers. It hierarchically extracts temporal features by stacking convolutional and pooling layers with decreasing kernel sizes. Output predictions are made using fc11-fc13 and softmax activation. ReLU activation is applied to hidden layers, batch normalization to conv1-conv10 outputs, and dropout to fc11 and fc12 outputs. Weight initialization is used for all convolutional layers. The weights of each fully connected layer in the BID7 network are initialized using a Gaussian distribution with a standard deviation of \u221a 1/n, where n is the input dimension of the layer."
}