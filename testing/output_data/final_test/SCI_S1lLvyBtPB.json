{
    "title": "S1lLvyBtPB",
    "content": "In real-world machine learning applications, outliers and noise are common, making it difficult to obtain clean training data for standard deep autoencoders. In this paper, an unsupervised method based on subset scanning over autoencoder activations is proposed for anomaly detection in images. The method combines detection with reconstruction error and subset scanning scores to improve anomaly score without retraining. It allows inspection and visualization of anomalous nodes in the reconstruction error space and can be used for anomaly detection in inner layers of the autoencoder. An unsupervised method using subset scanning over autoencoder activations is proposed for anomaly detection in images. This approach combines detection with reconstruction error and subset scanning scores to improve anomaly score without retraining. Anomalous inputs can include adversarial noise samples, human annotation errors, etc. The goal is to quantify, detect, and characterize data generated by an alternative process. Anomalies are classified as observations that deviate from the learned model. Large outliers and rare anomalies from diverse sources make it challenging to obtain labeled datasets for all possible anomalies/attacks. Autoencoders, unlike Convolutional Neural Networks, do not require labels as the expected output is the input data. Anomaly detection can be performed by analyzing the reconstruction error distribution. Using autoencoders for anomaly detection relies on a properly trained model with clean data. By training the autoencoder with corrupted samples mapped to clean ones, it learns a vector field pointing towards the manifold of clean samples. This vector field helps map perturbed data back to its clean representation. More details on the autoencoder architecture and training setup can be found in Section A.4. Subset scanning frames the detection problem as a search for subsets of data maximizing a scoring function, typically a likelihood ratio. Subset scanning methods can enhance anomaly detection in autoencoders without retraining by searching for subsets of node activations with higher scores. This approach combines detection with reconstruction error and subset scanning scores to improve anomaly detection without the need for retraining. The ability to identify and visualize anomalous nodes in the reconstruction error space is also provided. Subset scanning methods can enhance anomaly detection in autoencoders by searching for subsets of node activations with higher scores. This approach combines detection with reconstruction error and subset scanning scores to improve anomaly detection without retraining. Visualizing anomalous nodes in the reconstruction error space is also possible. The highest mutual information exchange with the adversarial input occurs in the first layers of the autoencoder. The highest mutual information exchange with adversarial input occurs in the first layers of the autoencoder, leading to a divergence in subset scores distributions. Machine learning models are vulnerable to adversarial perturbations, requiring methods to enhance robustness. Some methods involve retraining with altered loss functions to increase perturbation resistance. Our work focuses on anomaly detection for adversarial images without prior knowledge of the attack or labeled examples. We do not rely on data augmentation or specialized training techniques, making it a challenging but realistic problem. Autoencoders are used as anomaly detectors, and various adversarial attack models are discussed. Autoencoders can model training data distribution, making them suitable for anomaly detection. Neural networks, like adversarial autoencoders, are effective for anomaly detection. Beggel et al. (2019) propose a robust Anomaly Detection with ITSR and Adversarial Autoencoders, addressing the limitations of conventional autoencoders in the presence of anomalies. Zhai et al. (2016) demonstrate that using a criterion based on an energy score yields better results than the reconstruction error criterion. In this work, subset scanning applied to autoencoders is proposed as an unsupervised anomaly detector that can be used with any pre-trained autoencoder network. The approach focuses on anomaly detection using an energy score criterion and an anomaly regularizing penalty based on L p -norms during training. The method aims to improve detection capabilities compared to traditional approaches that rely on clean training data or complex autoencoder architectures. In this study, models target classifiers using untargeted attacks like Basic Iterative Method (BIM), Fast Gradient Signal Method (FGSM), and DeepFool (DF). These attacks aim to find perturbations in the original sample to create adversarial samples. FGSM is fast but not optimal, using the gradient sign to change pixel values. BIM is an extension of FGSM, applying noise iteratively. DF algorithm by Moosavi-Dezfooli is also discussed. The DF algorithm by Moosavi-Dezfooli computes optimal adversarial perturbations for misclassification in a binary classifier. Subset scanning is used for anomalous pattern detection by identifying the most anomalous subset of observations based on a scoring function. The scoring functions F (S) used in this work are discussed in the next section. Subset scanning offers heuristic alternatives like \"top-down\" and \"bottom-up\" methods. Top-down approaches detect global patterns and then find smaller anomalous groups, while bottom-up approaches aggregate anomalous data points into clusters. However, treating the detection problem as a subset scan faces computational challenges due to the exponential number of subsets. The LTSS property reduces search space from 2N to N for datasets with N records, ensuring identification of the highest-scoring subset. Non-parametric scan statistics are used due to skewed and bi-modal activation distributions in layers, making minimal assumptions on node activation distribution. Non-parametric scan statistics quantify anomalous node activations based on p-values. Subset scanning efficiently identifies interesting patterns in groups of p-values. Non-parametric scan statistics quantify anomalous node activations based on p-values. To maximize the non-parametric scan statistic, subset scanning efficiently identifies interesting patterns in groups of p-values. Three steps are involved in using non-parametric scan statistics on neural network activation data: forming a distribution of expected activations, scoring test images by comparing activations to baseline, and quantifying anomalousness by finding the subset of nodes that maximize the scan statistic. The non-parametric scan statistic quantifies anomalous node activations based on p-values. Test images are converted to vectors of p-values, with the assumption that anomalies will result in some p-values appearing extreme. Non-parametric scan statistics are used to identify and quantify this set of p-values. The Berk-Jones test statistic is utilized to quantify anomalous node activations based on p-values. It compares observed and expected proportions of significant p-values, showing greater power than other statistics like the Kolmogorov-Smirnov test and Higher-Criticism. The NPSS statistic has greater power than weighted Kolmogorov statistics and can efficiently evaluate anomalous node activations. It satisfies the linear-time subset scanning property, allowing for exact maximization over subsets of data by ranking nodes based on a priority function. The priority of a node is determined by the proportion of p-values less than \u03b1, making it either 1 or 0. The NPSS statistic prioritizes node activations based on p-values, with a threshold \u03b1 determining anomaly status. Sorting nodes by p-values allows for subset optimization, ensuring the highest-scoring subset is selected. This approach reduces search space while guaranteeing optimal subset identification for test images. The optimal \u03b1 threshold and subset size can vary for different test images. Noised images tend to return larger subsets of nodes and have lower thresholds than clean images. Noised test images have higher scores than clean test images. Autoencoders learn the underlying manifold of training data to reconstruct input as output. The architecture of an autoencoder consists of an encoder and a decoder, with the encoder reducing dimensionality and the decoder reconstructing the original sample. Anomalous pattern detection can be done by analyzing reconstruction errors. Two experiments proposed involve subset scanning scores distributions and information reduction in the encoder layers. In the untangling phase of information reduction in the autoencoder, the connection between subset scanning methods and reconstruction error space is explored. Results show that under BIM adversarial noise, a larger number of nodes with smaller p-values lead to a higher subset score compared to clean images. This highlights the efficiency of choosing \u03b1 to maximize the score for each subset. The LTSS property allows efficient selection of \u03b1 to maximize image scores. Subset size includes nodes with p-values below \u03b1 threshold. Baseline methods, datasets, evaluation metric, adversarial noise generation, and autoencoder architecture are described. CNN models trained for MNIST and Fashion-MNIST with test accuracies of 0.992 and 0.921 respectively. Autoencoder network trained on both datasets with test reconstruction errors of 0.284 and 0.095. Clean training datasets are essential in real-world applications. In real-world applications, clean training datasets are not always guaranteed due to human errors and poisoning techniques. The autoencoder was trained with different levels of data poisoning using BIM attack on Fashion-MNIST. Subset scanning was evaluated on reconstruction error and patterns across adversarial attacks and datasets. Subset scanning was applied across all layers of the autoencoder to analyze detection power. 7000 validation images were used to generate the background activation distribution, forming the expectation of \"normal\" activation behavior. The remaining 3000 images were divided into a \"Clean\" and an \"Adversarial\" sample for experiments, focusing on successful attacks like DF, FGSM, and BIM. Anomaly detection was evaluated on the MNIST dataset. The study evaluated anomaly detection using subset scanning on the MNIST and Fashion-MNIST datasets. MNIST consists of 60000 training images and 10000 test images of handwritten digits, while Fashion-MNIST includes 70000 grayscale images of fashion products from 10 categories. Adversarial attacks were implemented for subset scanning experiments, with a focus on hyperparameter selection for the Basic Iterative Method. The hyperparameter selection for adversarial attacks like BIM, FGSM, and DeepFool was described. Parameters controlling pixel changes and noise addition were specified. Smaller values make patterns subtler but less likely for attacks to succeed. DeepFool used standard values and iterations. Adversarial samples were generated for datasets using the Adversarial Robustness Toolbox. The effectiveness of subset scanning over an autoencoder to distinguish different types of adversarial attacks images was measured using the Detection Power metric AUROC. Results for reconstruction error and activations space in the first convolutional layer were shown. The first convolutional layer in Figure 3 shows high detection power for subset scanning across different datasets and adversarial attacks. Table 1 demonstrates that the initial layers maintain a performance between 0.96 to 1.0 for detection power, especially conv 2d 1 and max pooling 2d 1. The ROC curves and subset scores distribution for BIM and FGSM attacks on Fashion-MNIST are illustrated for conv 2d 1 in Figure 3. In experiments with 1% and 9% noise in training, subset scanning maintained high detection power above 0.82. Performance differences were observed between Fashion-MNIST and MNIST datasets, possibly due to autoencoder loss. Preliminary tests showed a correlation between lower autoencoder loss and increased detection power in subset scanning. A poorly-trained autoencoder with high loss makes it harder to distinguish clean from noised data. Subset scanning has higher detection power than Mean Reconstruction Error distributions under clean and noise samples. It is an interesting technique to explore anomalous nodes in the input image. Detection power for individual subset scanning over reconstruction error space is shown in Table 2 for different datasets and adversarial attacks. In this work, a novel unsupervised method for adversarial noise detection using off-the-shelf autoencoders and subset scanning was proposed. Subset scanning was shown to enhance detection strength against various adversarial attacks on images across different datasets without the need for retraining or complex autoencoder structures. Significant variations in detection performance were observed based on dataset, autoencoder architecture, and training setup. The study demonstrated the effectiveness of subset scanning in detecting adversarial noise in images using autoencoders. It showed a correlation between reduced loss in the autoencoder and improved detection power. The method can identify anomalous nodes in input images and characterize them as noisy samples. Detection performance remained high across different noise attacks, datasets, and autoencoder architectures. Subset scanning can be applied to autoencoders for unsupervised anomaly detection in neural networks. It identifies images with higher-than-expected activations at specific nodes, serving as a novel anomaly detector. This method has been previously used in classifier neural networks like CNNs and ResNet. The subset scanning method can be applied to autoencoders for unsupervised anomaly detection in neural networks. It identifies images with higher-than-expected activations at specific nodes, serving as a novel anomaly detector. The evaluation involves training the network on a dataset, extracting flattened layers, and analyzing subset scores for test sets of images with different levels of noise. The results show that test sets with more noised images have higher subset scores, indicating potential anomalies. The autoencoder is trained using a sigmoid and upsampling layers. Non-parametric scan statistics are used to analyze node activations, considering only 1-tailed p-values due to the ReLu activation function. Alternative activation functions like tanh and sigmoid could affect the interpretation of extreme activations. The non-parametric scan statistics (NPSS) operate on p-values to evaluate evidence for violations of H0 in a subset S. NPSS uses the Berk-Jones scoring function, which includes the Kullback-Liebler divergence. Another scoring function is the Kolmogorov-Smirnov test statistic, known for its sensitivity. The LTSS property is the Kolmogorov-Smirnov test statistic, known for its sensitivity to deviations in the center of a distribution. Another test, Higher-Criticism, normalizes by the standard deviation and is more sensitive to small subsets with extreme p-values. Non-parametric scan statistics are used to quantify larger-than-expected activations in the presence of a large skew and sometimes bi-modal distribution."
}