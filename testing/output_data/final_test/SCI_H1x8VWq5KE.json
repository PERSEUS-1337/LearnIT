{
    "title": "H1x8VWq5KE",
    "content": "Coalition operations are crucial for responding to global incidents requiring humanitarian assistance. Secure multi-party computation can facilitate cooperation among nations and organizations while maintaining privacy. The focus is on aid delivery scheduling post-natural disasters. Quantitative information flow analysis helps prevent data leaks. The field of quantitative information flow helps data owners understand privacy vulnerabilities in scheduling operations for coalition operations, including Humanitarian Assistance and Disaster Relief (HADR). Collaboration among nations and organizations is increasing due to mutual interests, especially in response to global incidents. With the rise in humanitarian crises from adverse weather events, coalitions involve government, military, and non-governmental organizations. Coalitions face challenges in collaborating without compromising national interests. Information security mechanisms focus on limiting access, leading to undersharing issues. Access control mechanisms enable selective sharing, but some tasks require withholding information. For instance, scheduling aid delivery after disasters necessitates sharing sensitive data. International response to natural disasters involves multiple countries and NGOs providing aid such as water, medicine, and fuel. Coordination among contributors is crucial but hindered by the reluctance to share sensitive information like aid availability and ship locations. Secure multi-party computation (MPC) protocols offer a solution for coalition collaboration without compromising private data. In our work, we utilize secure multi-party computation (MPC) to enable privacy-preserving computations for scheduling aid delivery tasks. We also incorporate quantitative information flow (QIF) to measure potential data leaks and adjust the scheduling process accordingly to maintain data privacy within acceptable limits. The paper discusses using secure multi-party computation and quantitative information flow to ensure privacy in aid delivery scheduling. It outlines the aid distribution task, describes data belonging to coalition members, and explains how these methods are employed in an adaptive workflow framework. The focus is on assessing and adapting to the vulnerability of private information during scheduling to meet privacy requirements. The paper discusses using secure multi-party computation and quantitative information flow to ensure privacy in aid delivery scheduling. It involves Aid Provider nations with ships delivering aid to ports of an Aid Recipient nation before a deadline. Assignments include port, berth, and docking time, optimizing load-balancing criteria. The paper discusses using secure multi-party computation to optimize load-balancing in aid delivery scheduling, ensuring privacy by combining private information from multiple parties. In aid delivery scheduling, secure multi-party computation (MPC) is used to address privacy concerns by computing functions without revealing private inputs. MPC protocols allow multiple participants to share computation without disclosing private information. Circuit-based MPC approaches are commonly used, although they may require unrolling loops and have performance implications. Our scenario utilizes a circuit-based MPC approach for privacy analysis and adaptive scheduling. MPC is a powerful tool for various use cases, such as splitting private keys among hosts to enhance security. It can also facilitate collaborative supply-chain planning without compromising sensitive data. Each data owner provides private input to an MPC circuit designed to keep inputs confidential from other participants. The MPC circuit allows participants to collectively compute solutions to planning and scheduling optimization problems while keeping inputs confidential. Creating a single MPC circuit for full scheduling optimization is impractical, so the solution involves decomposing the task into steps like collecting relevant inputs and determining port compatibility constraints. The Aid Provider ship draft is compatible with the harbor depth in the port. The Aid Recipient port has sufficient offload capacity. Determine feasible berths in each port that meet ship/berth compatibility and availability constraints. Schedule aid ships across possible arrival times to balance loads across ports. Steps A and B involve information gathering and computation, respectively. Step 1 - Secure multi-party circuits are used in the workflow for tasks performed by individual participants. Step B involves computation over private inputs from the Aid Provider and Aid Recipient. Steps C and D combine private inputs with intermediate results. Three circuits are used: a two-party circuit for physical compatibility test in Step B, a two-party circuit for viability test in Step C, and an N-party circuit for optimizing berth allocation in Step D.\n\nStep 4 - Secure multi-party circuits are used in the workflow for tasks performed by individual participants. Step B involves computation over private inputs from the Aid Provider and Aid Recipient. Steps C and D combine private inputs with intermediate results. Three circuits are used: a two-party circuit for physical compatibility test in Step B, a two-party circuit for viability test in Step C, and an N-party circuit for optimizing berth allocation in Step D. The workflow involves a greedy approach to load balancing across ports using ship-port-berth solutions. The Lumen agent technology is utilized for adaptive workflow capability. The process includes selecting ports with fewest assignments, adding earliest ship-port-berth-unload times to the solutions list, and matching solution approaches to aid distribution scheduling problems. The text discusses using secure multi-party computation to address scheduling and optimization problems, specifically focusing on the Millionaires' Problem as a use case. It explores how private data can be inferred from computation results without revealing actual values, highlighting the tradeoffs between efficiency and privacy. Private inputs in secure multi-party computation determine the level of inference possible about inputs from the result. For instance, in an example where Alice and Bob compute their net worth mean, Alice could deduce Bob's net worth using her input and the mean result. This highlights the challenge of reasoning informally about adversaries' abilities as scenarios grow in complexity. Quantitative Information Flow (QIF) is used to address these concerns by quantifying an adversary's inference capabilities based on information-theoretic bounds. A QIF analysis involves transforming a program into a model representing the relationship between private inputs and outputs. This model uses information-theoretic channels to map prior distributions on private data to posterior distributions. It supports adaptive workflows to predict what an adversary could learn from private inputs and how much they could infer from specific results. Games can be constructed to quantify the adversary's inference capability by measuring their chances of guessing private data. The vulnerability of private data is determined by the probability an adversary can correctly guess it. In the \"prior game,\" the defender selects a private input value from a prior distribution, and the adversary guesses based on their knowledge of this distribution. Adversaries, such as coalition partners or third parties, try to infer private data by observing public results. The adversary's inference capability can be quantified through games measuring their chances of guessing private data. In the \"prior game,\" the defender selects a private input value from a uniform distribution over the space of secrets, and the adversary tries to guess it. In the \"posterior game,\" the defender shares only the result of the computation with the adversary, who then tries to guess the private input. The vulnerability of private data is determined by the adversary's chances of correctly guessing it in both games. The vulnerability of private data is determined by the adversary's chances of correctly guessing it in both the prior and posterior games. Care must be taken in choosing a prior belief to ensure that the metric reflects reality. A predictive-mode adaptation strategy based on QIF predictive leakage is used to predict how much private data will be leaked before computation. Monte Carlo simulation can approximate predictive leakage in scenarios where precise leakage calculation is infeasible. Incorporating predictive leakage metrics into workflows allows for identifying higher-risk situations where workflow adaptation may be necessary. The posterior-mode adaptation strategy is based on QIF dynamic leakage, providing more accurate assessments of revealed information during a computation. The HADR aid delivery problem serves as a foundation for analyzing adaptive workflows in a privacy-aware setting, using the notion of vulnerability to inform decision-making. In a privacy-aware setting, vulnerability informs decision-making by assessing risk to private data. A simplified HADR aid delivery scenario involves a ship's location (ship_loc) as the only private data. Pseudo-code determines if the ship can reach a port within a deadline based on distance and speed. An adversary's prior belief influences their attempt to access private data. In a privacy-aware setting, vulnerability assesses risk to private data. The adversary's prior belief influences their attempt to access private data, with a uniform prior assumption for simplicity. When ship S responds to a query, the adversary can observe the output to update their posterior belief. The adversary can infer the ship's location based on the output of the query, ruling out possible locations within a certain radius. Regardless of the query result, subsets of possible values for the private data can be eliminated. The posterior vulnerability is determined by the number of possible locations. Cooperation is important in this scenario. The coordinator may need to query S multiple times to determine its location within a ring formed by two overlapping circles. Adding another port can further narrow down S's location within a small tolerance. In the full HADR scenario, an adversary can gain knowledge about a ship's position by intersecting circles. Prior vulnerability allows the adversary to have an idea of possible secret values before any computations. Analysts must choose appropriate ranges for private data when analyzing a system. The choice of prior vulnerability in a ship's location is crucial and can be influenced by domain knowledge. The prior belief over ship position affects the vulnerability metric significantly. Predictive vulnerability helps in resource-constrained systems to predict resource usage for certain actions. Private data is also a form of valuable information. Predictive vulnerability can be applied to assess the impact of planned actions on private data. Different methods depend on system constraints. An approximate method allows analysts to calculate vulnerability outcomes. The method uses Monte Carlo simulation to calculate a histogram of vulnerability outcomes without accessing private data. Analysts can focus on higher vulnerability areas for privacy preservation. This method is adaptable for scenarios where some private data is accessible. The method uses Monte Carlo simulation to calculate vulnerability outcomes without accessing private data. Analysts can focus on higher vulnerability areas for privacy preservation. Posterior vulnerability can be calculated after each step, providing an exact analysis of future data vulnerability. Monte Carlo simulation predicts vulnerability of a ship after completing Step C. The Monte Carlo simulation method calculates vulnerability outcomes without accessing private data. Posterior vulnerability can be calculated after each step, providing an exact analysis of future data vulnerability. In Step C, the median predicted vulnerability is significantly higher than after Steps A+B alone, indicating more information is revealed. Ship #9's posterior vulnerability in Step C is lower than the median predictive result, suggesting it reveals less private data. The vulnerability assessment computed by the QIF capability provides insights to data owners on the security of private information they wish to protect. These insights are used to adapt the scheduling process in order to adhere to privacy objectives within the workflow manager. The QIF capability is used in predictive and posterior modes to estimate and track leakage when performing tasks. If aggregate leakage exceeds thresholds, a remediation strategy is invoked to reduce impacts on private data. The Lumen-based adaptive workflow engine includes remediation strategies to reduce impacts on private data by adjusting deadlines to reveal less information about ship position and speed values. Privacy thresholds are implemented using an existing policy framework within Lumen to impose boundaries on the behaviors of autonomous agents. The Lumen-based adaptive workflow engine includes remediation strategies to reduce impacts on private data by adjusting deadlines to reveal less information about ship position and speed values. Privacy policies are used to impose boundaries on the behaviors of autonomous agents, with examples provided for Aid Provider and Aid Recipient nations. Sample vulnerability assessments for private data (max-speed, location) are shown before and after computations, displaying the QIF-derived vulnerability level. The display shows QIF-derived vulnerability levels with colored bars representing likelihood of guessing private data. Future work includes predictive vulnerability assessments of entire workflows before execution. Analogies can be drawn to prior work on estimating resource usage in workflows. Predictive QIF techniques are needed for generating useful assessments before executing workflows. These techniques should go beyond worst-case scenarios to be more valuable for vulnerability assessment tasks. Scalability remains a challenge for QIF techniques in systems with complex variable relationships, but some progress has been made in enhancing static analysis techniques. Further work is needed to scale QIF analysis for arbitrary channels. Further work is required to scale QIF analysis for arbitrary channels, with a focus on designing Domain Specific Languages for scenario description and analysis. The challenge of collaborating in coalitions without compromising interests is addressed in this paper through secure multi-party computation for aid delivery scheduling. The paper addresses the challenge of secure multi-party computation for aid delivery scheduling and introduces quantitative information flow (QIF) to assess the vulnerability of private data in computations. This assessment helps adapt the scheduling algorithm to meet accepted vulnerability thresholds set by data owners."
}