{
    "title": "BJGfCjA5FX",
    "content": "We propose Pairwise Augmented GANs, a novel autoencoding model where a generator and encoder are trained adversarially to sample realistic objects and map data distribution to latent space. An augmented adversarial reconstruction loss is introduced to ensure good reconstructions by comparing objects based on content rather than exact match. Experimental results show competitive sample generation and reconstructions on MNIST, CIFAR10, CelebA datasets, with good quantitative results on CIFAR10. Deep generative models are highlighted as powerful tools for sampling complex objects from low dimensional manifolds. Generative models like VAEs and GANs are used to sample complex objects from low dimensional manifolds. VAEs encode objects into a latent space but require careful likelihood choice, while GANs produce higher quality images without relying on explicit likelihood. However, GANs lack an important encoding property for practical applications like semi-supervised learning and object manipulation. VAE-GAN hybrids are of interest for learning latent representations and generating high-quality objects. Standard reconstruction losses in hybrid models enforce unnecessary details, hindering accurate reconstructions. In this paper, a novel autoencoding model is proposed to match distributions in the data space and latent space independently. An augmented adversarial reconstruction loss is introduced to improve reconstructions by enforcing a discriminator to consider content invariant to stochastic augmentation. This approach is called Pairwise Augmented Generative Adversarial Networks (GANs). In this approach, Pairwise Augmented Generative Adversarial Networks (PAGANs) are introduced to enhance training robustness. A new metric, Reconstruction Inception Dissimilarity (RID), is proposed to measure reconstruction quality, showing superior performance on various datasets. PAGANs outperform existing VAE-GAN hybrids in Inception Score and Fr\u00e9chet Inception Distance, except for a recent method on the CIFAR10 dataset. The goal is to match the true distribution to the model distribution induced by the generator. In PAGANs, the model distribution p \u03b8 (x) is induced by the generator G \u03b8 : z \u2212 \u2192 x from a prior p(z). An adversarial discriminator is introduced to match distributions p * (x) and p \u03b8 (x). The training involves a minimax game between the generator G \u03b8 and discriminator D \u03c8. The optimal discriminator D \u03c8 * ensures reconstructions correspond to the source object x with defined random augmentations. The PAGANs model uses a minimax game to train the adversarial distance between reconstructions and augmentations of the source object x. The discriminator D \u03c8 classifies pairs (x, y) into real or fake classes based on source object x and random augmentations. The minimax problem aims to match distributions r(y|x) and p \u03b8,\u03d5 (y|x) by finding the optimal discriminator D \u03c8 *. The optimal discriminator D \u03c8 * is determined by a fixed generator G \u03b8 and encoder E \u03d5. The value function V (\u03b8, \u03d5, \u03c8) is linked to the Jensen-Shanon divergence between r(y|x) and p \u03b8,\u03d5 (y|x). If r(y|x) = \u03b4 x (y), the discriminator learns an indicator I{x = y}. The stability of the objectives depends on the degeneracy of r(y|x), with non-degenerate distributions leading to a more stable value function. The value function V (\u03b8, \u03d5, \u03c8) is crucial for stability in practice. To optimize the generator and encoder, we need to optimize two value functions: the generator's objective and the encoder's objective. The training procedure involves drawing samples, computing losses, and updating networks until convergence. To speed up training, more stable objectives are used. The model can be extended to f-PAGANs and WPAGANs, with detailed analysis in the appendix. Recent papers explore different ways to build a generative model with an encoder part, such as applying adversarial training in the VAE framework or introducing the discriminator as part of a data likelihood. Another approach is to train the generator and encoder simultaneously in an adversarial way to match joint distributions. The ALICE model addresses non-identifiability issues in the ALI model by introducing an additional entropy loss. The ALI model introduces an additional entropy loss to address non-identifiability issues. Different approaches like cycle-consistency, optimal transport, and adversarial reconstruction are explored in models like BID27, BID34, BID10, and PAGANs. The PAGAN model matches marginal distributions in data and latent space independently. Experimental validation of the model is conducted. In this section, the model is experimentally validated by comparing PAGAN with other methods using Inception Score and Fr\u00e9chet Inception Distance. Reconstruction Inception Dissimilarity (RID) is introduced to measure reconstruction quality. The importance of adversarial loss and augmentations is demonstrated in the last two experiments. The architecture choice includes deterministic DCGAN for generator and discriminator networks, with the encoder network outputting a factorized normal distribution. The discriminator architecture consists of a 2-layer MLP with 512, 256 hidden units. Default hyperparameters are used from the repository. For augmentation, a combination of reflecting 10% pad and random crop is used. The prior distribution is a standard N(0, I). Inception Score and Fr\u00e9chet Inception Distance are evaluated using tensorflow 1.10.1. To optimize objectives, a discriminator working on pairs (x, y) is needed, implemented through image concatenation. Concatenating widthwise is found to be the most stable approach. Our model outperforms all other methods in terms of Fr\u00e9chet Inception Distance (FID) and Inception Score on the CIFAR10 dataset. Quantitative results are provided in TAB0, with additional visual results in Figure 2 and more datasets in Appendix E.3. The traditional approach to estimate reconstruction quality is through RMSE distance, but it lacks content awareness. We introduce a new metric, Reconstruction Inception Dissimilarity (RID), based on a pre-trained classification network. Low RID indicates minimal content change after reconstruction. The new metric, Reconstruction Inception Dissimilarity (RID), is introduced to measure content change after reconstruction. RID is compared to RMSE using a vanilla VAE on CI-FAR10 dataset, showing higher RID values for VAE reconstructions compared to augmented images. This indicates that RID allows for a fair comparison of reconstruction quality. The importance of adversarial loss in improving reconstruction quality is demonstrated in the experiment. Results show that a model without adversarial loss performs worse in generation, with a significant drop in reconstruction quality measured by RID. Visual results confirm these findings, highlighting the necessity of adversarial reconstruction loss for better performance. The experiment demonstrates that a model without augmentation fails to achieve good reconstruction and generation properties. Adversarial reconstruction loss works significantly better with augmentation, which should be non-deterministic, preserve image content, and make pixel-wise comparison difficult for the discriminator. The proposed framework includes an augmented adversarial reconstruction loss and introduces RID to estimate reconstruction quality. RID allows for content-based comparison of reconstructed images, highlighting the value of augmentation in experiments. The augmented adversarial loss is crucial for achieving good reconstructions and generated images in the framework. Future work may explore more complex architectures for better performance. Different augmentation strategies could be considered besides random shift. Propositions 1 and 2 provide insights into the optimal discriminator and the minimization of the value function in the framework. In the context of achieving good reconstructions and generated images, the optimal discriminator D \u03c8 * minimizes the expected Jensen-Shanon divergence between r(y|x) and p \u03b8,\u03d5 (y|x). Augmentation choice is crucial and should be problem-specific, with a stochastic augmentation recommended. A random shift of an image by a small margin can create quality reconstructions, but large shifts may introduce artifacts. Experimentation is needed to determine the effects of augmentation on reconstructions. In this experiment, the effects of padding and random crop augmentation on reconstructions were investigated. Different padding sizes were chosen and metrics such as FID, RID, and IS were plotted to guide the selection of padding size. Larger padding sizes resulted in undesirable effects in reconstructions, while more aggressive augmentation led to slightly better visual quality. Gaussian blur and random contrast augmentations were found to lead to unstable training and unsatisfactory results. In this experiment, padding and random crop augmentation effects on reconstructions were investigated. Larger padding sizes led to undesirable effects, while aggressive augmentation resulted in slightly better visual quality. Gaussian blur and random contrast augmentations caused unstable training and unsatisfactory results. The study concluded that good augmentation should preserve image content and force the discriminator to consider content. The value function (\u03b8, \u03c8) is determined by the Fenchel conjugate of f BID25. The optimal T \u03c8 * (x) for fixed parameters \u03b8 is f p * (x). The value function V (\u03b8, \u03c8 * ) for optimal parameters \u03c8 * is the f-divergence between distributions p * and p \u03b8 BID25."
}