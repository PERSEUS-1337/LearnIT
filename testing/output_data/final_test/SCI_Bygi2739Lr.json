{
    "title": "Bygi2739Lr",
    "content": "The phase problem in diffraction physics is a long-standing challenge due to the missing phase information. A new Deep Neural Network, Y-net, has been introduced for electron microscopy to solve this problem using a semi-supervised learning approach. This approach combines supervised training for reconstruction with unsupervised training for physics-based regularization, resulting in a more accurate and data-efficient solution compared to traditional methods. The Y-net model is more data-efficient and accurate than traditional methods for solving the phase problem in diffraction physics. Future advances in materials science rely on determining a material's electron density with atomic resolution, achievable through 4D-STEM computational imaging. In 4D-STEM, a picometer-sized electron beam is scanned across the material to collect diffraction patterns at each spatial location, resulting in a 4-D dataset. Successful inversion of this data can provide high-resolution electron density maps of materials. Decoding electron diffraction patterns is a challenging inverse problem due to strong quantum interactions and incomplete data. A Deep Neural Network is introduced to solve the phase problem in 4D-STEM, reconstructing electron density and wavefunction. The approach is extendable via differentiable programming. The fast-electron Schr\u00f6dinger equation describes the interaction between an electron beam's wavefunction and a material's scattering potential. Solving this equation can determine the local electronic density. However, obtaining this information purely from experimental data, which only provides diffraction patterns, is challenging. Various iterative phase-retrieval techniques have been developed to solve the phase problem in electron diffraction patterns. However, most existing techniques are not generally applicable to 4D-STEM due to strong electron-matter interactions. The text discusses a DNN architecture designed to solve the phase problem in optics by outputting both the initial complex scalar wave-field and the scattering potential. The architecture includes two decoder branches to minimize a learned regularization related to the input data. The Y-net approach utilizes physics-based constraints to train the model in an unsupervised manner, in addition to supervised learning on known ground truth data. The overall loss function includes terms for inversion errors and input reconstruction error, combining previous Deep Learning approaches for solving inverse problems. The Y-net approach uses physics-based regularization in addition to supervised learning to train the model for solving inverse problems. The regularization term is based on the thin-object approximation in phase-retrieval techniques, providing gradients for training the decoder branches. Training involves supervised steps with true labels followed by unsupervised steps. The Y-net approach combines physics-based regularization with supervised and unsupervised training steps to train the model for solving inverse problems. The unsupervised steps involve gradient-descent on input reconstruction loss without applying gradients to the encoder branch. Training is repeated throughout the training run, with 5-10 unsupervised steps following each supervised step. Results show that the Y-net model trained in a semi-supervised fashion outperforms purely supervised training in terms of reconstruction quality and data efficiency. By combining supervised and unsupervised learning, a new DNN architecture called Y-net was trained to solve inverse problems with physics-based regularization. This approach led to significantly improved reconstruction quality and data efficiency compared to model-based iterative reconstructions. The framework is being extended by replacing the learnable regularization with the full forward model using techniques from differentiable programming."
}