{
    "title": "R42147",
    "content": "The DOE Weatherization Assistance Program, created in 1976, helps low-income families reduce energy bills by improving household energy efficiency. Eligible measures include insulation, heating equipment, windows, water heaters, and air conditioners. The program aims to enhance energy efficiency, reduce energy costs, and enhance health and safety for vulnerable groups like the elderly, handicapped, and children, especially after the 1973 oil crisis. The Low-Income Home Energy Assistance Program (LIHEAP) was created to help low-income households with energy bills, especially senior citizens on fixed incomes. Initially focused on low-cost measures like window coverings and caulking, the program later allowed states to use up to 25% of funds for weatherization without a waiver. The emphasis of weatherization measures shifted from emergency and temporary to more permanent and cost-effective solutions, including storm windows, attic insulation, heating and cooling system upgrades. Home energy audits became crucial in selecting the most cost-effective measures. The DOE's Weatherization Program focuses on providing cost-effective energy efficiency measures to vulnerable groups, including the elderly, people with disabilities, and families with children. The program, implemented nationwide, targets households with elderly or disabled members, with a focus on low-income eligibility. Low-income households, with an average income of $18,624, have a higher energy cost burden of about 10% compared to non-low-income households at 3.3%. Despite lower energy usage and bills, the disparity in costs is not proportional to income. The Department of Energy (DOE) allocates funding to states and territories for energy assistance programs. Low-income households have a higher energy burden of 10% compared to non-low-income households at 3.3%. Households receiving energy payment assistance have an even higher burden of 11.5% of income. Funds are used for purchasing energy efficiency materials and making energy-related repairs. DOE reserves funds for national training and technical assistance activities. DOE allocates funding for T&TA activities at state and local levels, with a temporary increase to 20% under the Recovery Act. State programs receive the remaining funds through base and formula allocations. A fixed base allocation was set to prevent large swings in funding. In FY2010, a new program for \"Innovations in Weatherization\" was funded to increase low-income home weatherization and reduce federal costs per home. The DOE aims to increase the number of low-income homes weatherized and reduce federal costs per home through partnerships with traditional weatherization providers. The distribution of funding across states is based on factors like low-income population, climatic conditions, and residential energy expenditures. The DOE's Weatherization Assistance Program (WAP) aims to reduce financial burden on low-income households by prioritizing funding for national training and technical assistance activities, followed by state and local levels, base allocation to states, and formula allocation if funds exceed $209.7 million. Funding continuity has been inconsistent for WAP program. The Weatherization Assistance Program (WAP) funding has been inconsistent, with occasional spikes and proposals to eliminate funding. Historical funding trends show variations, with nearly $8.7 billion appropriated from FY1977 to FY2008. The Recovery Act in FY2009 added $5.0 billion, showing an alternating pattern of support between administration and congressional viewpoints. The Weatherization Assistance Program has had fluctuating funding levels, with a high of $500 million in FY1979 and a low of $150 million in FY1996. Funding has been on a downward trend since FY1979, except for the FY2009 Recovery Act. In 8 out of 34 years, the administration requested zero funding for the program. Congress approved nearly the same funding level as requested in 7 out of 35 years. In 20 out of 35 years, congressional appropriations differed significantly from administration requests, with differences exceeding 20% or $50 million. In 10 years, funding levels exceeded administration requests by more than $200 million. The Weatherization Program began in FY1977 during the Ford Administration and saw rapid funding increases during the Carter Administration. The Carter Administration requested $428.2 million for the Weatherization Program, which was approved by the 96th Congress. The Reagan Administration later rescinded $26.2 million from the FY1981 appropriation, reducing program funding to $376.6 million. In FY1982, the Reagan Administration proposed zero funding for the program and planned to restructure it as a block grant under the Department of Housing and Urban Development. The Energy Conservation Grants account consolidates financial and technical assistance programs proposed for termination in FY1983. Budget reductions are due to rising energy costs and private investment in conservation efforts. Despite zero request, Congress approved nearly $473 million in 2010 dollars for FY1983. Despite zero funding requests from the Reagan and George H.W. Bush Administrations in the 1980s and early 1990s, appropriations for the Energy Conservation Grants account steadily decreased to about $258 million in 2010 dollars by FY1989. The Clinton Administration then requested a significant increase to $332 million in 2010 dollars for FY1994, which was mostly approved by Congress. Subsequent requests in the mid-1990s were met with varying levels of funding approval. In FY1997 through FY2001, the Administration's requests for energy conservation grants ranged from $190 million to $200 million in 2010 dollars. Congress generally approved $20 million to $40 million less than those requests. In FY2001, Congress approved about $187 million in 2010 dollars, which was close to the requested amount. President George W. Bush's National Energy Policy Report emphasized the importance of improving national energy security and assisting vulnerable Americans during supply emergencies and extreme weather. The report highlighted the cost-effectiveness of the program, with each dollar spent on home weatherization generating $2.10 worth of energy savings. The Bush Administration aimed to increase support for the Weatherization Assistance Program, recommending a $1.2 billion funding increase over ten years to double spending on weatherization. The FY2002 Budget includes a $120 million increase for weatherization, with funding reaching $277 million in constant 2010 dollars. Funding steadily increased until FY2006, then decreased to $232 million in FY2008. The program was rated \"moderately effective\" in 2003, coordinating well with other government programs and achieving its goals. The George W. Bush Administration requested termination of the Weatherization Program in FY2009 due to higher benefit-to-cost ratio of DOE's Energy Efficiency programs. Funding was redirected to R&D programs with a 20 to 1 benefit to cost ratio, compared to Weatherization's 1.53 to 1 ratio. Under the Obama Administration, the Weatherization Program received a major funding increase of $5 billion from the Recovery Act to weatherize 600,000 homes, aiming to reach one million homes annually. Amendments allowed more cost-effective measures with a higher cost ceiling per dwelling. The Recovery Act aimed to stimulate the economy, create jobs, and make energy infrastructure investments. The Recovery Act allocated $5 billion to DOE's Weatherization Program, which was considered \"shovel ready\" with established infrastructure and easily measurable impact on job creation and energy conservation. The Recovery Act allocated $5 billion to DOE's Weatherization Program, aiming for prompt job creation and economic stimulation. The program was modified to include new labor requirements like \"prevailing wage\" and training. Grantees faced delays in starting work due to the new wage rate requirements, impacting the delivery of weatherization activities funded by the Recovery Act. Recovery Act-funded weatherization activities faced delays in reaching full momentum due to training requirements for program personnel. Recession-driven budget shortfalls and staff furloughs in certain states further hindered progress. Progress in implementing the Recovery Act-funded weatherization program was hindered by state-wide furloughs and budget delays, leading to a lack of staff and spending authority. Despite proactive steps taken by DOE, little progress was made in weatherizing homes by early 2010. The DOE Inspector General found that only a small percentage of Recovery Act weatherization funds had been spent, leading to a lack of progress in weatherizing homes and job creation. Low spending rates by state and local grant recipients fell significantly short of goals, with modest income residents not benefiting as promised. The IG report found that challenges in the Recovery Act-funded Weatherization Program caused a nine-month delay in achieving goals. Despite efforts, the program's complexity made synchronization difficult among federal, state, and grant sub-recipients. The IG report identified barriers to delivering Recovery Act-funded weatherization services, including state budget issues, staff availability, and regulatory changes. Performance assessments and evaluation studies were conducted to review program management processes and impacts. Performance assessment and evaluation studies are essential for supporting the Government Performance and Results Act (GPRA) and the Office of Management and Budget's concerns for federal program management. Performance assessments focus on management responsibilities and budget processes, using anecdotal data collected over a shorter time-frame. In contrast, evaluation studies gather comprehensive data over a longer time-frame to reveal the net impacts and cost-effectiveness of program operations. GPRA established requirements for federal agencies to conduct regular performance assessments based on management by objectives and strategic planning. OMB leads GPRA implementation in cooperation with federal agencies. The Government Performance and Results Act (GPRA) requires federal agencies to prepare strategic plans, performance budgets, and annual performance reports to improve Congressional decision-making. OMB leads GPRA implementation in cooperation with federal agencies, fulfilling legal requirements for performance planning and reporting. The Department of Energy (DOE) has integrated responses to GPRA requirements into its strategic plan, annual performance report, and budget request. Since 2002, DOE has worked with OMB to assess programs using the Performance Assessment Rating Tool (PART). Circular A-11 defines program assessment and evaluation as objective measurements and analysis of program effectiveness. The Department of Energy (DOE) integrates responses to GPRA requirements into its strategic plan, annual performance report, and budget request. Program evaluations should be conducted independently with sufficient scope and quality. DOE's Weatherization Program has been assessed using various evaluation methods, with GPRA-driven assessment tools focusing on broader agency missions. The Department of Energy (DOE) has a history of directing the Oak Ridge National Laboratory (ORNL) to conduct evaluation impact studies on its Weatherization Program. In 1993, a major evaluation report was published, establishing impact evaluation studies as a key feedback component for program design changes and improvements. GPRA stimulated the emergence of less in-depth performance assessments with a shorter-term budget focus. Both types of studies aim to provide feedback for improving program operations. A performance audit was conducted by DOE's Office of the Inspector General to assess the program's performance and management against objective criteria. The audit covered Program Year 2000 to 2002 with a budget of $518 million. The purpose was to determine if the program was properly administered and achieving its goals. The audit found a well-established structure for fund transfers to state and local agencies. The Inspector General found that state and local agencies receive funding from various sources for weatherization programs. Around 900 agencies received funding ranging from a few thousand dollars to $4 million in Program Year 2001. The IG identified reporting issues related to administrative costs and the number of households weatherized by local agencies. The Inspector General found that local agencies inappropriately charged administrative expenses as direct program costs for weatherization programs, potentially exceeding statutory limitations. The DOE Program Office should work closely with states and agencies to minimize administrative costs and ensure accurate reporting. The Inspector General found that local agencies improperly reported the number of households weatherized, leading to distorted program results and potential exaggeration of program efficiencies. DOE has addressed concerns about distorted efficiency measures by calculating benefit/cost ratios based on average cost per home. The Performance Assessment Rating Tool (PART) developed by the Office of Management and Budget in 2002 assesses program planning, management, and performance against outcome-oriented goals to improve program effectiveness and inform funding decisions. PART helps managers identify and rectify performance problems. The Performance Assessment Rating Tool (PART) aims to unify annual performance targets with long-term goals, track program performance evolution through reassessments, and implement OMB recommendations for program improvement. Program offices report actions taken to OMB semi-annually, using performance data to inform budget decisions. The Performance Assessment Rating Tool (PART) helps agencies make budget decisions and improve results by asking questions in four areas: program purpose, performance measurement, evaluation, and strategic planning, program management, and program results. Programs must use performance assessment to earn a high PART rating and continually improve efficiency. The DOE Weatherization Program was found to be performing at a \"moderately effective\" level in a PART report. The DOE Weatherization Program was rated as \"moderately effective\" by the PART assessment. The program met its annual performance target for weatherizing homes but lacked a current, comprehensive, and independent assessment of performance. The assessments conducted by Oak Ridge National Lab were based on old data, leading to the program's moderately effective rating. The DOE Weatherization Program was rated as \"moderately effective\" by the PART assessment. OMB noted issues with state and local agencies' reporting on program management. DOE responded by conducting an independent analysis and addressing audit recommendations. The PART assessment report included trend data on key performance measures and a benefit-cost ratio based on energy savings and program costs. The PART assessment reported an average energy savings per household of 29.1 million MBtu with benefit-cost ratios ranging from 1.19 to over 2.00. The program's benefit-cost ratio fluctuated over the years, depending on EIA estimated long-term energy prices. Independent evaluations were conducted regularly to support program improvements and evaluate effectiveness. The program does not conduct annual evaluations on a national basis due to cost constraints and limited changes in program activities. Oak Ridge National Laboratory (ORNL) is contracted to develop evaluation methodologies and provide periodic reports on state grantee-level performance. ORNL also conducts selective evaluations in areas with below-average performance or strategic program interest but limited evaluation data. The program relies on Oak Ridge National Laboratory (ORNL) for evaluation methodologies and reports on state grantee performance. To ensure independence, future assessments should involve alternative contractors or third-party assessments. The Government Accountability Office (GAO) defines performance audits broadly as providing objective analysis for improving program performance, reducing costs, facilitating decision-making, and enhancing public accountability. According to GAO, a performance audit may include analyzing cost-effectiveness and program operations. The Recovery Act directed GAO to conduct bimonthly reviews on states' use of funds, including the DOE Weatherization Program. GAO describes these reviews as performance audits. In December 2009, GAO published a performance audit report on Recovery Act funds used by states and localities. GAO conducted a performance audit on Recovery Act funds, including the DOE Weatherization Program. By the end of FY2009, states had spent 2% ($113 million) of weatherization funds and completed 1% (7,300) of targeted homes. Delays in contracts were due to staff capacity and labor requirements. In May 2010, GAO reported that by mid-FY2010, states had spent 13% ($659 million) and completed 13% of targeted homes. GAO provided observations on program implementation and recommendations. In late December 2011, the GAO released a report on the status of Recovery Act funding for the DOE Weatherization Program. The study examined fund status, implementation challenges, energy and cost savings, and employment data quality. Findings included $3.46 billion spent out of $4.75 billion allocated, decreasing implementation challenges, and positive progress by recipients. The DOE Weatherization Program had allocated $4.75 billion, with $3.46 billion spent. Recipients reported declining implementation challenges, with an average cost of $4,900 per home and 563,000 homes weatherized. DOE projected exceeding the target of 607,000 homes by March 2012. GAO found improved data quality. DOE reports assessed energy cost savings and benefits, with a comprehensive evaluation in 1993. The DOE Weatherization Program, the nation's largest residential conservation program, was evaluated for energy savings and cost-effectiveness in PY1989. The report assessed single-family dwellings, mobile homes, and small multifamily dwellings, estimating a benefit-cost ratio of 1.09 for the program and 1.72 when including non-energy benefits. After the 1993 National Evaluation report, DOE relied on ORNL's metaevaluations to assess program energy savings and cost effectiveness. ORNL conducted three key metaevaluations from 1990 to 2005, finding higher energy savings of 18% to 24% compared to the 1989 data. The 1997 metaevaluation study compared cost-effectiveness using three perspectives: program, installation, and societal. The study found that energy savings ranged from 18% to 24%, showing significant improvement over the 1993 National Evaluation. The use of advanced weatherization procedures contributed to the expected improvement in program performance. The 1997 metaevaluation study compared cost-effectiveness using three perspectives: program, installation, and societal. Energy savings ranged from 18% to 24%, showing significant improvement over the 1993 National Evaluation. State-level evaluations offer useful benchmarks of progress between large-scale national assessments. ORNL conducted a 1999 metaevaluation synthesizing results from 10 individual evaluation studies of state weatherization efforts. The study aimed to identify average energy savings of households in states providing information. The 1999 study aimed to identify average energy savings of households in states providing information. Program-induced savings continued at a higher rate than in the 1993 national evaluation, with no major changes in program structure or practices. ORNL used the same assumptions and procedures as previous studies to make benefit-cost ratios comparable. The 2005 metaevaluation of a weatherization program nationwide estimated average household energy savings at 30.5 million British thermal units (MBtu) per year with a benefit/cost ratio of 1.34 from the program perspective. The study aimed to update findings from the 1993 national evaluation, using a 20-year lifetime assumption and a 4.7% discount rate. Three benefit-cost perspectives (program, installation, societal) were examined, with higher benefit-cost ratios in 1996 and 1999 compared to 1993. The 2005 metaevaluation by ORNL updated findings from the 1993 national evaluation of weatherization programs. Data from 38 studies in 19 states between 1993 and 2005 were analyzed. ORNL made improvements by expanding the time and geography range, aggregating data by state, and combining studies into a single state value. The 2005 ORNL metaevaluation updated findings from the 1993 national evaluation of weatherization programs by analyzing data from 38 studies in 19 states. The studies were combined into a single state value to prevent skewed results, and a weighted average was used to account for multiple studies, with larger states contributing more heavily to the analysis. Table 3 shows benefit-cost values in various ORNL metaevaluations, with similarities among the values not surprising. The 2005 ORNL metaevaluation focused on energy savings in homes heated by natural gas, with statistically significant differences in savings compared to the 1993 national evaluation. However, the sample examined may not fully represent the nation as a whole. Actual benefit-cost values are likely higher than reported for natural gas savings. The 2005 ORNL metaevaluation found higher benefit-cost ratios for energy savings in homes heated by natural gas compared to the 1993 national evaluation. The study highlighted the need for a new national evaluation to validate findings and address shortcomings in the metaevaluation method. The 2005 ORNL metaevaluation found higher benefit-cost ratios for energy savings in homes heated by natural gas compared to the 1993 national evaluation. A new national evaluation is needed to thoroughly explore the current operations and achievements of the Weatherization Program across the entire nation. DOE has engaged APPRISE, a nonprofit analytical organization, to conduct the second national evaluation. The Recovery Act provided funding and new requirements for the Weatherization Program. ORNL prepared a technical memo to update estimates using the National Energy Audit Tool. The memo projected program performance based on typical homes in each state, considering building type, heating fuel, prices, and weather conditions. ORNL used the Weatherization Assistant residential audit package to estimate annual energy savings under new parameters set by the Recovery Act. The estimated annual savings for heating and cooling projected for FY2010 were 29.0 MBtu per household, compared to 30.5 MBtu in the 2005 metaevaluation. The Recovery Act increased the average per-unit investment cost ceiling to $6,500, leading to a higher total energy savings. ORNL projected a 2010 benefit-cost ratio of 1.80, with most of the increase attributed to changes in energy prices from 2003 to 2010. The Recovery Act increased the average per-unit investment cost ceiling to $6,500, leading to higher total energy savings. ORNL projected a 2010 benefit-cost ratio of 1.80, with changes in energy prices from 2003 to 2010 impacting the ratio. The program benefit-cost ratio varied by region, fuel type, housing type, and adjusted average cost ceiling provided under the Recovery Act. The projected 2010 societal benefit/cost ratio is 2.51, similar to the ratio in 2005. ONRL emphasized the need for a new national evaluation due to limitations in available data on energy-related housing characteristics and cost variations. The projected 2010 societal benefit/cost ratio is 2.51, similar to the ratio in 2005. ONRL emphasized the need for a new national evaluation due to limitations in available data on energy-related housing characteristics and cost variations. Characteristics of the housing stock and types that will be weatherized with expanded revenues need more accurate data from the National Evaluation effort. The methodology used for estimates differs from previous metaevaluations due to recent program changes impacting household savings. The 2005 metaevaluation results only reflect natural gas heated homes, not accounting for heating fuel diversity or potential cooling savings. The methodology used did not adjust for variations in housing stock or location-specific energy prices. ONRL acknowledges the limitations in the findings, stating they do not provide a statistically valid representation of the program's performance. The DOE's Weatherization program is undergoing assessments and evaluations to improve its operations. Three activities are being conducted to evaluate the program: a strategic assessment by Deloitte, an impact study for PY2007 through PY2008, and an impact evaluation for the Recovery Act period of PY2009 through PY2011. These activities aim to provide a better estimate of the program's effectiveness until more rigorous results are available from the new National Evaluation. The Weatherization Assistance Program Office has contracted Deloitte LLP to conduct a strategic assessment of the program, focusing on objectives, impact metrics, delivery vehicles, and finance mechanisms. This study aims to identify improvements in program design and delivery, addressing the need for a comprehensive evaluation to ensure objectives are met and energy savings estimates are valid. DOE recognizes the importance of updating evaluations due to policy, procedure, and technology changes since 1993. The DOE is planning a second national evaluation of the Weatherization Assistance Program to assess the impact of new policies and technologies. The 1993 evaluation led to significant program changes, and DOE anticipates similar outcomes from the upcoming evaluation. ORNL released a plan for a second national retrospective evaluation of the Weatherization Assistance Program, incorporating new funding sources, management principles, audit procedures, and energy efficiency measures. The evaluation will be conducted by a competitively selected independent contractor team led by APPRISE to assess program performance for PY2007 and PY2008. Performance measures will include program costs and benefits, with a comprehensive savings analysis including post-weatherization billing data. The DOE's evaluation of the Weatherization Assistance Program includes collecting a full year of post-weatherization billing data to determine energy savings in 2007 and 2008. Analytical approaches will be used, and billing histories will be collected for weatherized homes and comparable non-weatherized homes. A national sample of 400 local weatherization agencies will provide data, which will be normalized using analytic methods like the Princeton Scorekeeping Method (PRISM). The evaluation is expected to be completed by Fall 2012. The DOE's evaluation of the Weatherization Assistance Program includes using three analytic methods, such as the Princeton Scorekeeping Method (PRISM), to assess energy savings and cost-effectiveness. Cost information for weatherized homes will be collected to calculate a benefit-cost ratio. Nonenergy benefits will be quantified and categorized into utility, occupant, and societal benefits. Weatherization benefits utility providers by reducing arrearages and service shutoffs, while occupants benefit from increased home comfort. The Weatherization Assistance Program benefits utility providers by reducing arrearages and service shutoffs. Occupants benefit from increased home comfort, health, safety, and property value. Society benefits from reduced greenhouse gas emissions, pollution, and water conservation. The program also boosts local employment and economic activity. The DOE plans to evaluate program processes through surveys, case studies, and a field study, with a focus on program operations, training, and quality assurance. The Recovery Act allocated $5 billion over two years to expand the weatherization program. The $5 billion allocated over two years for an expanded weatherization program has sparked significant interest due to its potential energy and cost savings. A comprehensive evaluation funded by DOE aims to assess program effectiveness and improve performance. GAO has reviewed the evaluation plan and found it to be methodically sound. The program has undergone significant changes post-Recovery Act, including a 300% increase in weatherization activity and the recruitment of an expanded workforce. The weatherization program underwent significant changes post-Recovery Act, including a 300% increase in activity and recruitment of an expanded workforce. Program funds were increased for training and technical assistance, states received large funding increases, and innovations were implemented in program delivery and management. DOE set aside funds to support innovations in program funding and design, and major changes were made to accommodate the funding expansion. The average cost per unit for weatherization was increased to $6,500, and wages for workers were subjected to prevailing wage requirements. The evaluation for 2009-2011 will be similar to the retrospective evaluation for 2007-2008, with a focus on energy savings and cost-effectiveness. Funding and provisions have had a significant impact on the weatherization community, leading to special process evaluation studies as part of the Recovery Act evaluation project. The Recovery Act evaluation project includes special process evaluation studies on Davis-Bacon requirements and changes in the national weatherization community. ORNL published a plan detailing the impact and process components of the assessment. The evaluation activities are scheduled from the second quarter of 2011 to the first quarter of 2014. Congress mandated that weatherization projects funded by the Recovery Act must adhere to Davis-Bacon labor rules, with the Department of Labor responsible for determining prevailing wages in the construction industry. The DOE is evaluating the impact of Davis-Bacon requirements on the cost-effectiveness of the Weatherization Assistance Program. The increased funding from the Recovery Act led to changes in the national weatherization network, affecting relationships between state and local agencies. The evaluation will also assess how the Recovery Act influenced the use of contracts for weatherization services and the recruitment and training of new labor force members. The evaluation design aims to uncover new information about the program, including estimated energy savings, cost-effectiveness, and non-energy benefits. It will also assess the effectiveness of recruiting and training weatherization crew members and their work opportunities outside of the DOE program. Insights into energy savings from specific measures and the strengths and weaknesses of different selection methods will be explored. Program operational data for different levels of home investments and eligibility will be produced. The OMB Inspector General criticized DOE for relying heavily on in-house staff from ORNL for evaluation studies. There is a debate over the objectivity of in-house evaluations and the need for independence in evaluation organizations. DOE responded to criticism by hiring an outside contractor for a competitive evaluation process. The DOE engaged in a competitive process to hire an outside contractor, APPRISE, for national evaluations. Professors debate the benefits of using outside contractors for federal program evaluations to improve independence and objectivity. Charles Metcalf emphasizes the importance of control over research processes for evaluation independence. Charles Metcalf emphasizes the importance of control over research processes and reporting for evaluation independence. He argues that client authority can give significant control over evaluation content, but independence and objectivity are promoted by maturity of the contractor organization, reputation, formal agreements, and research transparency. Major evaluation contractor organizations like Mathematica Policy Research (MPR), Abt Associates, MDRC, and RAND have established objectivity and independence as core values over the past 40 years. Major evaluation contractor organizations like RAND have successfully defended objectivity and independence in their conduct with funding organizations. The ability to establish a reputation for objectivity enables longevity and independence from any single administration. The agency's ability to maintain objectivity and quality of work is crucial for longevity in policy research. Metcalf argues that the agency's influence on content is limited by evaluation contracts, where ownership and control of research products are defined by the client. Researchers and clients often agree on methodology and report scope in advance to prevent surprises and protect both parties. Metcalf emphasizes the importance of research transparency in evaluation contracts, comparing it to academic research. He highlights that openness is ensured in federal program evaluations through the competitive procurement process and the Freedom of Information Act. The agency's influence on content is limited by evaluation contracts, where ownership and control of research products are defined by the client. Researchers and clients agree on methodology and report scope in advance to prevent surprises and protect both parties. The contractor has the right to request and release their own research reports under the FOIA, allowing dissemination of results. Metcalf notes that evaluation contractors have similar rights to researchers in academic institutions, including sharing research results through conferences and publications. Third parties play a role in evaluations, emphasizing the importance of making research reports available to the public. Professor Metcalf and Professor Reingold both emphasize the importance of third party involvement in research evaluation. They believe that using external evaluation contractors can enhance research credibility and independence, ultimately serving an accountability function. The rationale for contracting out program evaluation is to establish independence by creating a clear division of labor between evaluators and program managers. Independence is typically ensured through the selection process of external contractors who are free from biases and have control over the evaluation design. Reingold argues that agency funding control, contractor self-interests, and lack of competitiveness in the selection process undermine the independence of contracted program evaluations. Reingold argues that contractor organizations have a financial self-interest in accommodating agency wishes, potentially compromising the independence of program evaluations. The independence of program evaluations can be compromised when program staff influence the selection of firms to conduct evaluations, leading to biased findings. This undermines the competitive selection process and threatens objectivity from both agency and contractor perspectives. Reingold highlights threats to independence in evaluation contracting from program and contractor interests. He suggests two policy options to improve independence: substituting grants for contracts or expanding third-party involvement. This debate continues to focus on reducing threats to evaluation independence. Professor Jacob Klerman emphasizes the challenges to contractor evaluation independence, citing threats from the self-interests of funders, contractors, and third parties. He suggests modifying formal contract agreements to address these issues, highlighting the inherent tension between funders and contractors. Klerman argues that unspoken goals and biases can influence evaluation projects, echoing concerns raised by Reingold about the politicization of evaluations. The funder's desire for positive evaluation results can impact program funding and job security for evaluation staff. Contractors may tailor their evaluations to please funders for future business opportunities. Klerman suggests involving a third party to balance funder and contractor interests, but acknowledges potential bias from the third party's own goals. Klerman discusses the balance of interests between funders, contractors, and third parties in evaluations. He suggests improving independence through clear contractual mechanisms that prioritize high-quality evaluations over policy or organizational goals. Klerman recommends establishing a clear separation between an official evaluation report and a contractor's analysis. The funder would have rights to the official report but not to change the contractor's text. The contractor would retain rights to publish findings. Klerman's strategy includes 19 approaches to modify evaluation contracts for improved independence. The Metcalf-Reingold debate focuses on approaches to ensure program evaluation independence, including limiting the funder's control over the research process and report release. Other national governments, like the UK's DFID, also prioritize independence in evaluations for credibility and reliability. Evaluation independence, quality, and credibility are essential for evaluation excellence. The DFID assessment highlights that while independence is crucial, there are limits to how far it should be taken. Optimum independence is emphasized, combining intellectual detachment with empathy and understanding to engage stakeholders and maintain evaluation integrity. The acid test of evaluation professionalism is to maintain trust while upholding integrity. Extreme independence can lead to isolation, hindering access to information and decision makers. The challenge lies in achieving full independence without becoming isolated. Different parties in evaluation may have biases, requiring a balance to be struck. Different approaches in evaluation can shift power dynamics between funders, contractors, and third parties, with varying costs and timeframes. Maintaining a balance is crucial, especially in situations with problematic behaviors. Klerman suggests modifying client-contractor relationships to address tensions and preserve objectivity. The Department of Energy emphasizes the need for independent experts to conduct evaluations, even if staff commission the study. The Department of Energy recommends that evaluation contractors should have independence and no conflicts of interest. Program staff can work with the contractor initially but should maintain a separation for most of the evaluation study. To ensure contractor independence, a panel of external experts should review the contractor's work. The Department of Energy recommends that external experts review the contractor's work to ensure evaluation independence and credibility. This separation helps maintain the integrity of the evaluation methodology and study, addressing concerns about the independence of evaluation studies commissioned by the program being evaluated. The selection process for evaluation independence is crucial. Questions arise about the competitiveness of selecting Deloitte and APPRISE. Transparency and third-party involvement are key factors in ensuring independence. Objective indicators are needed to gauge transparency and third-party balance in the evaluation process. The debate between Metcalf and Reingold suggests using third-party organizations like Congress, GAO, and National Academy of Sciences for a more active role in managing the program evaluation process. This includes having outside agencies ensure independent contractor evaluation work. The debate suggests involving third-party organizations like Congress, GAO, and National Academy of Sciences in managing the evaluation process independently. This includes transferring the contractor selection process to agencies like the Office of the Inspector General or DOE IG. The historical data and funding chart for the DOE Weatherization Assistance Program are also provided."
}