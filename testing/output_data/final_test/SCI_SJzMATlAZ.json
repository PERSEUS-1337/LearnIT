{
    "title": "SJzMATlAZ",
    "content": "Clustering high-dimensional datasets is challenging due to less informative interpoint distances. A clustering algorithm is presented that combines nonlinear dimensionality reduction and clustering. Data is embedded into a lower-dimensional space using a deep autoencoder optimized during the clustering process. This approach does not require prior knowledge of the number of clusters and is formulated as optimization of a global continuous objective. Experimental results show that the algorithm outperforms state-of-the-art clustering schemes, including those using deep networks. Clustering high-dimensional datasets remains a challenge despite various methods like center-based and spectral approaches. High dimensionality hinders algorithm assumptions, leading to the development of techniques combining dimensionality reduction and clustering for better results. Recent approaches have aimed to overcome limitations of linear subspace clustering by constructing a nonlinear embedding for clustering high-dimensional datasets. These methods optimize the embedding to reveal latent cluster structures, but still rely on classic clustering formulations with limitations such as requiring the number of clusters to be set beforehand. Algorithms for clustering often require setting the number of clusters beforehand and involve discrete reconfigurations of data points. Integrating them with optimization procedures that modify data embedding is challenging. A new approach is sought for joint nonlinear embedding and clustering to address limitations of prior methods. The goal is to optimize a single continuous objective that can be solved using scalable gradient-based solvers without the need to predefine the number of clusters. In this paper, a formulation for joint nonlinear embedding and clustering is presented, rooted in Robust Continuous Clustering (RCC). The approach aims to optimize a continuous objective without the need to predefine the number of clusters, overcoming challenges of existing methods. The paper presents a simpler integration of the RCC objective with dimensionality reduction for deep nonlinear embeddings. This approach avoids complex optimization schemes and dual variables, optimizing data embedding and clustering simultaneously in a low-dimensional space using gradient-based solvers. The algorithm is evaluated on high-dimensional image and document datasets. The algorithm presented in the paper integrates the RCC objective with dimensionality reduction for deep nonlinear embeddings. It optimizes data embedding and clustering simultaneously in a low-dimensional space using gradient-based solvers. Experiments show that this approach outperforms state-of-the-art clustering algorithms on high-dimensional datasets of images and documents. The algorithm integrates the RCC objective with dimensionality reduction for deep nonlinear embeddings. It optimizes data embedding and clustering in a low-dimensional space using gradient-based solvers. A regularizer is introduced to constrain the embedding to maintain the structure of the original high-dimensional dataset. To construct a faithful embedding of the original data, a low-dimensional image is needed. Clustering of the low-dimensional embedding can be done using classic clustering frameworks like k-means or agglomerative approaches. However, traditional clustering algorithms have a discrete structure, making it challenging to coordinate clustering with the optimization of embedding parameters. The recent RCC formulation introduces a set of representatives Z and optimizes a nonconvex objective to perform continuous clustering by balancing two objective terms. The formulation ensures representatives stay near datapoints and encourages them to merge, offering advantages in optimization. The Deep Continuous Clustering (DCC) algorithm optimizes a formulation that reduces clustering to optimization of a fixed continuous objective. It allows each datapoint to have its own representative in Z without prior knowledge of the number of clusters. The algorithm integrates the reconstruction objective and the RCC objective, optimizing a more expressive nonlinear embedding parameterized by \u2126. DCC optimizes a global objective directly without relying on closed-form solutions, using modern gradient-based solvers. The mappings F \u03b8 and G \u03c9 are performed by an autoencoder with fully-connected or convolutional layers. The graph E is constructed on X using the mutual kNN criterion and minimum spanning tree to ensure connectivity. M-estimators \u03c1 1 and \u03c1 2 pull representatives of a true cluster into a single point. The estimators \u03c1 1 and \u03c1 2 aim to bring representatives of true clusters together while ignoring connections across clusters. Parameters control the radii of convex basins, weights balance datapoint contributions, and \u03bb balances data and pairwise loss. Objective (3) is optimized using stochastic gradient descent, updating each z i only via corresponding loss and pairwise terms. In optimizing objective (3) using stochastic gradient descent (SGD), the autoencoder parameters \u2126 are updated via all data samples, while each z i is updated only via its corresponding loss and pairwise terms. To address the imbalance in update rates between Z and \u2126, an adaptive solver like Adam is recommended. Sampling subsets of edges from the graph E for minibatches is necessary due to pairwise terms connecting datapoints outside the minibatch. This approach requires careful construction of minibatches to ensure effective optimization. The rebalanced minibatch loss is calculated by weighing the contribution of each datapoint in the minibatch. Gradients of the low-dimensional embedding and representatives are computed and propagated to the parameters. The embedding parameters are initialized using the stacked denoising autoencoder framework, with noise introduced during pretraining. The embedding parameters are initialized using the stacked denoising autoencoder framework with noise introduced during pretraining. Encoder-decoder layer pairs are pretrained sequentially, and the entire SDAE is fine-tuned using the reconstruction loss. A continuation scheme is used to alleviate nonconvexity in estimators, gradually sharpening them until a threshold is reached. The embedding parameters are initialized using the stacked denoising autoencoder framework with noise introduced during pretraining. A continuation scheme is used to alleviate nonconvexity in estimators, gradually sharpening them until a threshold is reached. DCC monitors the computed clustering by constructing a graph at the end of each epoch and comparing cluster assignments. If minimal changes occur, the algorithm outputs the clustering and terminates. The DCC algorithm conducts experiments on high-dimensional datasets covering various domains without supervision. It is compared to 12 baselines, including classic and deep clustering algorithms. The DCC algorithm is compared to 12 baselines, including SEC, LDMGI, RCC, RCC-DR, DEC, JULE, DCN, and DEPICT, which are deep clustering approaches using deep networks for clustering. The key difference lies in the loss function and optimization procedure compared to prior formulations based on KL-divergence clustering, agglomerative clustering, and k-means. DCC optimizes a robust continuous loss without prior knowledge of the number of clusters. Experimental results are reported for two autoencoder architectures: fully-connected and convolutional. The autoencoder architecture follows parametric t-SNE for fully-connected and is modeled on JULE for convolutional. The autoencoder architecture used in the study is based on JULE BID38, with the number of layers dependent on image resolution. The reduced space dimensionality is set to d = 10, with no dataset-specific hyperparameter tuning. SDAE pretraining and finetuning start with a learning rate of 0.1, decreasing by a factor of 10 every 80 epochs. Each layer is pretrained for 200 epochs, and finetuning is done for 400 epochs. For m-kNN graph construction, the nearest-neighbor parameter k is set to 10. For graph construction, the nearest-neighbor parameter k is set to 10 using the cosine distance metric. The Adam solver with default learning rate of 0.001 and momentum 0.99 is used. DCC was implemented with PyTorch library. Baselines like k-means++, DBSCAN, and AC-W used SciPy library implementations. Hyperparameter search was performed for maximizing performance of certain baselines. DCN approach utilized different network architectures for each dataset. Results were reported using dataset-specific architecture for YTF, Coil100, and YaleB, while MNIST's reference architecture was used. Clustering accuracy was measured using NMI and ACC, but to address biases, AMI was used. AMI ranges from 0 to 1, with higher values indicating better performance. Results are summarized in Table 1, showing that fully-connected DCC outperformed DCN and DEC in deep clustering methods. The performance of deep clustering methods varies on different image datasets. DEPICT and JULE show lower performance on certain datasets. The GDL algorithm did not scale well on the full MNIST dataset. DCC performs on par or better than prior deep clustering formulations without relying on deep networks. DCC performs on par or better than prior deep clustering formulations without relying on a priori knowledge of the number of ground-truth clusters. Importance of joint optimization is analyzed by comparing dimensionality reduction and clustering jointly versus separately. Results show that baseline algorithms benefit from dimensionality reduction. The accuracy of baseline algorithms improves with dimensionality reduction, but DCC using joint optimization outperforms them. DCC surpasses stagewise SDAE embedding followed by RCC. Performance drops on Coil100 and YaleB datasets due to limitations of fully-connected SDAE. Clustering algorithms perform better in reduced space produced by DCC. The performance of clustering algorithms improves significantly when optimizing a low-dimensional embedding using DCC before clustering in the learned embedding space. Clustering accuracy is lower than DCC's accuracy, but all algorithms show improvement in the reduced space discovered by DCC. Visualization using Barnes-Hut t-SNE is provided in FIG0. The Barnes-Hut t-SNE method was used to visualize a subset of 10K datapoints from the MNIST dataset. The DCC embedding showed well-defined clusters corresponding to ground-truth classes without supervision. DCC's robustness to the dimensionality of the latent space was studied, with varying dimensions between 5 and 60. The performance of DCC was compared to DEC and k-means++ on the output of SDAE. The results of clustering algorithms DCC, DEC, and SDAE+k-means were analyzed for accuracy with increasing dimensionality. DCC was found to be more robust to higher dimensions compared to DEC and SDAE, showing a smaller decrease in accuracy. The algorithm presented performs dimensionality reduction and clustering using a deep network without prior knowledge of the number of clusters. Nonlinear optimization is used to optimize a global objective, and a convolutional encoder-decoder architecture is utilized for the process. The algorithm utilizes a convolutional encoder-decoder architecture for dimensionality reduction and clustering. Hyperparameters such as k, d, and M are fixed values across all datasets, with M being architecture-specific. The algorithm uses a convolutional encoder-decoder architecture for dimensionality reduction and clustering with fixed hyperparameters. Results are reported based on ACC and NMI measures, with automatic setting of \u03bb, \u03b4 i , \u00b5 i. ACC and NMI counterparts to Table 1 and FIG1 are provided."
}