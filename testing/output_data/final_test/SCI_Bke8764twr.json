{
    "title": "Bke8764twr",
    "content": "Presence of bias and confounding effects is a critical challenge in machine learning applications, leading to debates. Solutions include enhancing datasets to reduce biases or using available data to build models. Traditional statistical methods may not be applicable to deep learning, so a proposed method based on adversarial training aims to learn unbiased features. The new method incorporates an adversarial loss function to learn unbiased features that are uncorrelated with confounding biases. Results show superior prediction performance across various datasets. The code is available at http://blinded_for_review/. Machine learning models for tasks like disease prediction and face recognition can be affected by confounding variables like age, sex, and race. Bias in the data can lead to the predictor learning the influence of the confounder instead of actual discriminative cues. To address this, biases can be accounted for in the model using methods like randomization, matching, standardization, or stratification. Confounding variables in machine learning models can be controlled through standardization, stratification, or regression analysis to remove their influence on the input variables. However, regression analysis may not work well for input variables like pixel intensity values in images, which are variant across images. This limitation prevents the use of regression approaches in conjunction with deep learning methods. Regression approaches are not suitable for deep learning methods due to the variant pixel intensity values in images. BR-Net shows stable patterns across shade categories and improves accuracy, especially for darker shades. The text discusses a feature learning scheme that aims to produce unbiased features for class labels while addressing confounding variables in convolutional neural networks. It introduces an adversarial loss function to quantify the statistical dependence between learned features and bias variables, improving upon commonly used loss functions like cross-entropy or mean-squared error. The Bias-Resilient Neural Network (BR-Net) strategy improves upon traditional loss functions by injecting resilience towards bias during training to produce confounder-invariant features. It is evaluated on synthetic and medical imaging datasets, showing unbiased features for controlled confounding variables and predicting HIV diagnosis from MRIs. HIV disease accelerates brain aging, potentially leading to misinterpretation of predictors. BR-Net is evaluated for gender classification using different backbones pre-trained on ImageNet and shows improved results for darker faces compared to other methods. Fair machine learning models aim to address bias in training datasets, with recent efforts focused on creating fairer datasets. BR-Net demonstrates impartial feature learning and improved gender prediction performance, particularly for darker faces. In this work, the focus is on using existing data to build models that are mindful of biases by learning impartial features. Domain-Adversarial Training, introduced by Ganin et al. in 2016, utilizes adversarial training for domain adaptation tasks. Various works have expanded on this idea by exploring different loss functions, domain discriminator settings, and cycle-consistency to close the domain gap. The goal is to learn bias-resilient models with features that are invariant to specific biases. In the literature, various methods have been proposed for learning features that are invariant to specific factors in the data, including information obfuscation, regularization-based approaches, and domain-adversarial training strategies. These techniques aim to mitigate bias and learn impartial features that are resilient to specific biases. Previous research has proposed methods to learn unbiased features, including information obfuscation, regularization, and domain-adversarial training. However, existing adversarial loss functions fail to address biases with continuous or ordinal values. A new loss function based on correlation coefficient is introduced to mitigate bias effects on learned features. Distribution matching techniques, which aim to learn distributionally robust techniques, have also been explored in the literature. Our correlation-based analysis minimizes bias-predictive power in learned features for individual data points, harmonizing data distribution on a population level. An end-to-end architecture is proposed for training deep neural networks to classify images without bias from confounders. The architecture in Fig. 2 is similar to domain-adversarial training approaches. It involves a Feature Extraction (FE) network to extract features from input images, a Classifier (C) to predict class labels, and a Bias Predictor (BP) network to predict bias variables. The networks have trainable parameters and work together to minimize classification loss while maximizing bias predictor loss. The architecture involves a Feature Extraction (FE) network, a Classifier (C), and a Bias Predictor (BP) network. The classification loss is defined by \u0177im = C(FE(Xi; \u03b8fe); \u03b8c), and the adversarial component by bi = BP(FE(Xi; \u03b8fe); \u03b8bp). Adversarial training aims to remove statistical association with bias variables, not maximize prediction error. Using MSE for adversarial training may lead to ill-posed optimization and oscillation. The architecture involves a Feature Extraction (FE) network, a Classifier (C), and a Bias Predictor (BP) network. Adversarial training aims to remove statistical association with bias variables, not maximize prediction error. To address ill-posed optimization and oscillation, a surrogate loss is defined for predicting bias confounders and quantifying statistical dependence. The overall objective of the network is defined with a trade-off controlled by hyperparameter \u03bb, similar to GAN and domain-adversarial training. The architecture involves a Feature Extraction (FE) network, a Classifier (C), and a Bias Predictor (BP) network. Adversarial training aims to remove statistical association with bias variables. The optimization objective is to minimize classification loss while maximizing bias prediction loss. Zero-covariance guarantees mean independence between bias variables and features, a stronger form of statistical independence. The architecture includes a Feature Extraction (FE) network, a Classifier (C), and a Bias Predictor (BP) network. Adversarial training aims to eliminate statistical association with bias variables by minimizing classification loss and maximizing bias prediction loss. Mean independence between bias variables and features is ensured through zero-covariance. The architecture consists of a Feature Extraction (FE) network, a Classifier (C), and a Bias Predictor (BP) network. Adversarial training enforces mean independence between bias variables and features to eliminate statistical association. The theorem validates the strategy by ensuring zero-correlation between certain variables, preventing BP from optimizing for increased correlation. The training process involves back-propagating losses to update parameters iteratively. In the present study, the training process involves updating parameters iteratively by minimizing different loss functions for each subnetwork. The correlation operation is used for the bias effect removal component, calculated over each training batch. Different architectures are used for the Feature Extraction (FE), Classifier (C), and Bias Predictor (BP) networks. The method is evaluated on three different scenarios, including a synthetic scenario. In this section, our method is evaluated on three scenarios: a synthetic experiment to validate assumptions, predicting HIV diagnosis from brain MRIs with age confounding, and predicting gender from face images while controlling for race variables. BR-Net is compared with baselines, emphasizing its aim to remove prediction-bias association for improved performance. The comparison methods for BR-Net in the Gender Shades PPB experiment include Multi-Task and CatGAN baselines, highlighting the importance of correlation loss in addressing bias and confounding effects in image datasets. We create a synthetic dataset with two groups of 512 images each, generated by 4 Gaussians controlled by \u03c3 A and \u03c3 B. Group 1 has \u03c3 values sampled from U(1, 4) while Group 2 has stronger intensities sampled from U(3, 6). Gaussian noise with std. dev. 0.01 is added. The difference in \u03c3 A between groups is the discriminative cue, while \u03c3 B is a confounder. The BR-Net is trained on the dataset to predict group labels based on diagonal Gaussians and control for \u03c3 B. After training the FE Network with 3 stacks of convolution/ReLU/max-pooling layers, BR-Net achieves 89% training accuracy and BR-Net w/ MSE achieves 90%. The baseline model achieves 95% accuracy, indicating reliance on confounding effects \u03c3 B for predicting group labels. The squared distance correlation (dcor 2) is measured to investigate the association between learned features and \u03c3 B. The method successfully removes the statistical association with \u03c3 B as the distance correlation drops dramatically with training iterations. The baseline model without the BP component constantly yields high correlation, while the proposed method results in a space with no apparent bias, confirmed by the 2D tSNE projection of the learned features. Our method successfully removes bias from the confounding variable \u03c3 B. The study involves predicting HIV diagnosis based on brain MRIs, with HIV patients being older than control subjects. MRIs are processed and classification accuracy is measured using 5-fold cross validation. Data augmentation is used to balance the training set for predicting HIV diagnosis based on brain MRIs. The ConvNet is built on half of the 3D volume, with a feature extractor yielding 4096 intermediate features. Adversarial loss back-propagation is only performed for the control group to estimate confounding effects reliably. Each point in the control cohort is color-coded by age. Our method, BR-Net, shows the most accurate prediction for HIV diagnosis based on brain MRIs, outperforming other methods like 3D CNN and Resid+SVM. It effectively learns discriminative features while controlling for confounders, resulting in high balanced accuracy, AUC, and F1-score. The baseline tends to predict most subjects as CTRLs due to a wider age distribution in the CTRL group. BR-Net shows balanced true positive and true negative rates when controlling for age as a confounder, resulting in reliable predictions. The distance correlation between features and confounders decreases with adversarial training, unlike the baseline 3D CNN model. The t-SNE projection visualizes the learned feature spaces. The baseline model's feature space shows bias towards age, while our method results in a space without age bias. Another experiment involves gender prediction from facial images in the GS-PPB dataset, using the Fitzpatricksix-point labeling system for skin classification. To train models on the GS-PPB dataset, VGG16 and ResNet50 backbones pre-trained on ImageNet are used. The models are fine-tuned to predict gender based on face images with 5-fold cross-validation. The resulting models have bias towards shade due to fewer cases of darker faces in ImageNet. BR-Net considers 'shade' as a bias variable. Results are compared with a multi-task baseline and a model using entropy loss for categorical prediction. BR-Net outperforms other methods on average in predicting gender based on face images. Other methods show inconsistent recognition capabilities for different 'shade' categories, especially on darker faces. The features learned by BR-Net result in a more uniform distribution of subjects compared to other methods. The study visualizes saliency maps for gender prediction using BR-Net, showing more stable patterns across all 'shade' categories compared to the baseline. BR-Net focuses on specific face regions and encourages unbiased feature learning for prediction tasks. The study highlights the importance of bias-resilient models like BR-Net in machine learning. It emphasizes the need to account for bias in data during training to avoid spurious associations and erroneous decisions. Future work could explore strategies like deep canonical correlation analysis. For future work, exploring strategies such as deep canonical correlation analysis can be considered to enhance the adversarial component."
}