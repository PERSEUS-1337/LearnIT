{
    "title": "Hyg4kkHKwH",
    "content": "The primate visual system uses long-range horizontal connections to create robust representations of the external world, which are essential for various cortical processes. V1Net, a novel convolutional-recurrent unit, incorporates these connections to improve object recognition performance under perceptual noise. The Texturized Challenge is introduced as a benchmark to evaluate V1Net against other models. V1Net is evaluated against control models with/without recurrent processing using noise. An ablation study demonstrates the importance of neurally inspired horizontal connections for object boundary detection. Several biologically plausible connectivity patterns emerge in V1Net trained on natural images. The findings suggest increased similarity to biological visual systems and highlight the importance of recurrent contextual processing for robust visual representations. Visual models have been developed by neuroscience and computer vision communities, aiming to account for findings from single-cell neurophysiology and furthering the state-of-the-art in computer vision. Two broad families of models have emerged, with one focusing on directly modeling types of neuronal responses and the other, such as Deep Convolutional Networks (DCNs), being inspired by earlier works on characterizing receptive fields in the cat striate cortex. Deep Convolutional Networks (DCNs) are inspired by earlier works on characterizing receptive fields in the cat striate cortex and aim to optimize performance on various computer vision benchmarks. Despite their impressive performance, recent work highlights their deficiencies compared to primate vision. The motivation is to reverse-engineer cortical contextual processing principles mediated by long-range horizontal connections using DCNs. Horizontal connections fill-in sensory inconsistencies systematically. V1Net is a novel recurrent unit inspired by visual neuroscience and Gestalt psychology literature on cortical horizontal connectivity. It aims to bridge the gap between artificial and biological visual representations by complementing DCNs with the ability to fill-in sensory inconsistencies and bind neighboring features together for stable perception. The V1Net model is introduced in Section 3, with its mathematical formulation and working explanation. Experimental results are demonstrated in Section 4, including the Texturized Challenge benchmark. In Section 4, experimental results are presented, including the Texturized Challenge benchmark and an ablation study of V1Net's horizontal connections using the BSDS500 boundary detection benchmark. The study demonstrates biologically plausible horizontal connections in V1Net for boundary detection tasks. Additionally, qualitative results of V1Net's zero-shot domain transfer from natural to stylized images are discussed, along with plans for future work in computational models of visual perception. Introduced hierarchical visual models inspired by computations in the visual cortex for robust object recognition, including the CORNet model. Research has explored cortically inspired models and incorporating long-range spatial dependencies into deep convolutional networks. Interest lies in utilizing dynamical systems to model early visual perception. Recent advancements in hardware and software have led to the development of biologically plausible models of vision using Recurrent Neural Networks (RNNs). Studies have shown the importance of recurrence in core object recognition routines, with architectures equipped with recurrent and feedback interactions being ideal for object recognition. The emergence of architectures with recurrent and feedback interactions is ideal for object recognition. Evidence for neural plausibility is provided by explaining neural data from the visual cortex of awake primates. The horizontal Gated Recurrent Unit (hGRU) is relevant to the proposed V1Net, but there are key differences in design and connection dynamics. V1Net's computations do not follow a specific order like hGRU, with a nonlinear shunting inhibition mechanism implemented disynaptically. The nonlinear shunting inhibition mechanism in V1Net is implemented disynaptically, inhibiting excitatory cells that synapse onto simple cells in a facilitatory fashion. Recurrent-convolutional neural networks model V1Net's computation, with horizontal connections creating push-pull integration at each neural site. The V1Net cell is derived from a ConvLSTM cell, with horizontal connections implemented using distinct convolutional filter banks. The V1Net cell utilizes convolutional filter banks to model horizontal connectivity between feedforward 'simple-cells', integrating inhibitory and excitatory influences to compute the current memory cell and hidden state. The V1Net cell computes the current memory cell and hidden state using convolutional filter banks to model horizontal connectivity between feedforward 'simple-cells'. Neurons in the horizontal kernels have receptive fields that grow with each recurrence iteration, scaling their horizontal connectivity proportionately. The internal workings of V1Net are compared to a standard ConvLSTM unit, with equations showing how V1Net selectively scales horizontal influences. The V1Net cell, compared to a ConvLSTM cell, shows similar representation dynamics. Converting a ConvLSTM into a V1Net involves adding transparent components. In DCNs, information flow is restricted within convolution kernels, which may not be ideal for tasks like object recognition in the presence of noise. V1Net's long-range horizontal connections address this by grouping elements for holistic object representation within a DCN layer. The V1Net model introduces horizontal connections in DCN layers to efficiently group elements for robust object representation, especially in scenarios like multi-digit recognition under noise and clutter. These connections facilitate the selective linking of like-oriented elements within a neighborhood, enhancing the model's ability to classify objects accurately. The V1Net model uses horizontal connections to group like-oriented elements in a neighborhood, facilitating object recognition by suppressing irrelevant elements and reducing the need for memorization of all object configurations. This decluttering effect allows the model to recognize digits under clutter with fewer examples and parameters compared to a standard DCN. The V1Net model, utilizing horizontal connections, aids in object recognition by decluttering and reducing the need for memorization of object configurations. It is hypothesized to generalize to unseen pairs of objects during test-time. Experimental results include the Texturized challenge for robust object recognition and boundary detection on natural images from BSDS500. The 'Texturized challenge' assesses models' ability to recognize object shape under noise and texture uncertainty using images from the CIFAR 10 dataset. By manipulating the phase and magnitude signals of images in Fourier space, local perceptual noise can be added to object textures while preserving overall object identity. Corrupting the phase while retaining the magnitude affects object identity, highlighting its importance. The Texturized Challenge involves generating images by combining Fourier magnitude from different CIFAR10 samples, adding local noise while preserving object shapes. Human recognition remains robust to this challenge, as shown in Fig. 4. The challenge involves comparing V1Net to two other models without horizontal connections. Test-time classification accuracy was evaluated on images from the Texturized challenge, showing results for 4 difficulty levels. The evaluation compared models with different levels of task difficulty based on noise in Fourier magnitude. Feedforward models were less robust to noise compared to recurrent models, supporting the idea that recurrent processing aids visual recognition. Additionally, the V1Net model with horizontal connections showed superior performance in terms of robustness. The proposed V1Net model, with horizontal connections, demonstrated improved robustness compared to recurrent control models like ConvLSTM. The model was evaluated on boundary detection tasks using natural images from BSDS500 dataset. Three different lesions of V1Net were compared, including a standard ConvLSTM without horizontal connections as a baseline. The V1Net model with horizontal connections showed higher precision in boundary detection compared to parameter-matched control models. Horizontal connections were found to increase precision and accuracy in boundary detection tasks. The importance of recurrent processing and horizontal connections in object boundary detection was highlighted in the study. Results showed that nonlinear horizontal connections play a pivotal role in boundary detection, with a speed-accuracy tradeoff observed in different variants of the V1Net model. The study highlighted the impact of standard techniques on improving performance in computer vision benchmarks. Training a V1Net model with online data augmentation and a larger batch size improved performance on evaluation metrics, approaching state-of-the-art object boundary detection methods. Visualization of learned horizontal connection patterns in the model revealed 'center-surround' and 'association-field' patterns. The study demonstrated that V1Net's connection patterns resemble 'center-surround' and 'association-field' receptive fields, with horizontal connections facilitating border-sensitive cells for object boundary detection in natural images. The model's biologically realistic horizontal connections aid in predicting object boundaries by providing strong signals of the object's extent and suppressing spurious boundaries. V1Net's ability to generalize to style-transferred stimuli from Stylized-Imagenet was tested, showing robust object boundary detection. The model's long-range horizontal connections enable it to learn global features, allowing it to detect boundaries without explicit supervision, even with stylized object textures. Connections in visual neuroscience are crucial for creating invariant visual representations. A neurally-inspired recurrent neural network model of long-range horizontal connections was developed, showing importance for artificial vision systems. The model demonstrated robust visual representations on various challenges and benchmarks. The emergence of biologically plausible horizontal connection patterns from V1Net suggests a strong similarity to primate early visual areas. The model also generalized to images with stylized textures in a zero-shot manner, showcasing the potential of using biological vision inspiration to advance artificial vision. Currently, research is focused on incorporating learned top-down feedback connections in a deep convolutional network along with V1Net to improve semantic segmentation models. The architecture used fits into a 3 layer hierarchical structure paralleling the early visual circuit from Retina to V1. Additionally, there is ongoing analysis of the match between V1Net's internal representations and experimental recordings from the primate visual cortex. The ConvLSTM models in the experiment utilize different convolution kernels for horizontal connections, with larger dimensions for excitatory connections than inhibitory connections to facilitate short-range inhibitory and long-range excitatory connections. The V1Net model also includes 5x5 2-D convolutions for shunting horizontal connections. In the experiment, the recurrent input X t is set to the feedforward convolutional feature representation from the bottom layer. A V1Net block is inserted between conv-2 and conv-3, using the activation map of conv-2 to set X t. The models were implemented using TensorFlow framework, with 6 timesteps found suitable for accurate object boundaries. Hyperparameters include minibatch size (6), learning rate (1e-4), and optimization algorithm (rmsprop). Data augmentation techniques were used for the BSDS500 experiments. In the experiment, data augmentation techniques were used to expand the BSDS training set, including random brightness and contrast variation, rotation, and flipping. Models were trained on a single NVIDIA 2080 GPU, with specific configurations for the Retina and LGN layers. The size of convolution kernels in the last layer was adjusted for CIFAR-10 images. Boundary predictions from V1Net on the BSDS500 test set are shown in the attached figure. Boundary predictions from V1Net on the BSDS500 test set are displayed in Figure 9."
}