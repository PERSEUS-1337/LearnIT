{
    "title": "Byg0DsCqYQ",
    "content": "Conditional generative adversarial networks (cGAN) have significantly improved conditional image generation in computer vision. However, cGANs are prone to large errors in output, making them unreliable for real-world applications. To address this issue, a novel model called RoCGAN has been introduced, which utilizes structure in the target space to enhance robustness to noise. RoCGAN outperforms existing cGAN architectures in various domains, including images. Conditional Generative Adversarial Networks (cGAN) have advanced image generation but suffer from output errors. RoCGAN, a new model, improves robustness by leveraging target space structure, outperforming cGAN in various domains. The unsupervised module complements supervision in training neural networks, allowing exploration of unlabelled data structure without extra computational cost during inference. Rasmus et al. and Zhang et al. modified encoder networks with decoder modules for dense regression. In dense regression, both bottom-up and top-down modules exist by default, making it challenging to extend methods to regression tasks. A novel conditional GAN called 'Robust Conditional GAN' (RoCGAN) is proposed, incorporating implicit constraints in latent subspaces. The model includes two pathways - one for regression and the other for unsupervised learning in the target domain. The two pathways share a similar network structure with shared weights in the decoders. The RoCGAN model includes two pathways - one for regression and the other for unsupervised learning in the target domain. The shared weights in the decoders promote semantically similar latent representations, constraining the output to span the target subspace. The unsupervised pathway allows utilization of all target domain samples, while during inference, the testing complexity remains the same as in cGAN. In RoCGAN, an autoencoder is learned in the target manifold to restrict the output of the regression. The RoCGAN model introduces a novel approach that combines regression and unsupervised learning in the target domain. It shares theoretical properties with the original GAN, such as convergence and optimal discriminator. Experimental results show that RoCGAN outperforms the state-of-the-art cGAN and recent methods in various tasks, demonstrating its effectiveness in handling intense noise and natural image data. The RoCGAN model introduces a novel approach that combines regression and unsupervised learning in the target domain. It aims to promote robustness in dense regression tasks by scrutinizing model performance under noise and adversarial perturbations. Experimental analysis for two tasks shows how RoCGAN can be used in semi-supervised learning with lateral connections from encoder to decoder. Conditional image generation is a popular task in computer vision, with approaches like cGAN and 'pix2pix' by Isola et al. (2017) being the main alternatives. Pix2pix includes modifications such as lateral skip connections, accepting pairs of source/gt and source/model output images in the discriminator, and additional content loss terms in the generator. These modifications improve visual outcomes, but the lack of direct supervision remains a challenge. Regularization terms in the loss function can help address this issue. Regularization terms in the loss function, like feature matching, can provide stronger supervision in conditional image generation tasks. Salimans et al. (2016) introduced a method of feature matching in the discriminator to match low-dimensional distributions, showing empirical success. Adversarial attacks have also been explored as a new research direction. Adversarial attacks in image classification can be defended against using techniques like Fortified networks and RoCGAN. These methods aim to prevent classification errors caused by perturbing input samples with imperceptible noise. Additionally, combining supervised and unsupervised learning has been used to enhance classification performance. In the Ladder network, Rasmus et al. (2015) modify a typical bottom-up network for classification by adding a decoder and lateral connections between the encoder and the decoder. They utilize the augmented network with two pathways during training: labelled input samples are fed to the initial bottom-up module, and input samples corrupted with noise are fed to the encoder-decoder with lateral connections. This autoencoder pathway strengthens the network's resilience to samples outside the input manifold and improves classification performance. Constraints in manifolds were traditionally addressed with component analysis, such as Canonical correlation analysis (Hotelling, 1936) for finding common subspaces that maximally correlate. The recent work by Murdock et al. (2018) combines neural networks with classic component analysis. The proposed RoCGAN leverages structure in the output space by using two pathways in the generator. Theoretical properties of RoCGAN are studied in the appendix, showing similarities with the original GAN. RoCGAN shares properties with the original GAN, consisting of a generator and discriminator module optimized with gradient descent methods. The generator samples from a prior distribution and models the target distribution, while the discriminator distinguishes between generated samples and the target distribution. Conditional GAN extends the formulation by providing the generator with additional labels. The adversarial loss is expressed as a min-max problem. The adversarial loss in RoCGAN is a min-max problem where the generator and discriminator parameters are denoted as w_G and w_D. Feature matching and content loss are included in the loss function to improve outcomes. RoCGAN's generator has two pathways compared to the original cGAN's single pathway. RoCGAN introduces two pathways in the generator: reg pathway for regression and AE pathway for unsupervised learning. Both pathways use encoder-decoder networks with shared decoder weights to prevent large errors. The discriminator remains the same as cGAN, taking inputs from the reg pathway and target samples. The notation abbreviates AE and G modules for clarity. The RoCGAN model introduces two pathways in the generator: reg pathway for regression and AE pathway for unsupervised learning. The unsupervised module contributes a loss term to minimize the distance between the encoders' outputs. The final loss function combines the original cGAN loss terms with additional terms for the AE pathway. Future plans include replacing the latent loss term with a kernel-based method. The RoCGAN model introduces two pathways in the generator for regression and unsupervised learning. Future plans involve replacing the latent loss term with a kernel-based method or a learnable metric for matching distributions. Skip connections in the generator allow for deeper layers to capture abstract representations, but their effects in the representation space are not well-studied. The challenge of training the longer path without skip connections can be addressed by maximizing variance. To address the challenge of training the longer path without skip connections, a loss term is added to penalize correlations in representations, encouraging diverse and useful information capture. The decov loss minimizes the covariance matrix, promoting diagonalization without restricting variance. Similar approaches by Valpola (2015) also aim for decorrelation in every layer, favoring an identity covariance matrix while penalizing smaller eigenvalues. The decov loss minimizes the covariance matrix, promoting diagonalization without restricting variance. An experiment on synthetic data compares the original generator with a novel two pathway generator using a network with two fully connected layers. Inputs/outputs span a low-dimensional space dependent on x, y \u2208 [\u22121, 1]. The input vector [x, y, e 2x] and output vector [x + 2y + 4, e x + 1, x + y + 3, x + 2] are showcased. The two pathway network projects inputs into a two-dimensional space and maps them to a four-dimensional space. The network is trained with separate modules and pre-trained weights. During testing, 6,400 new points are sampled, and the two pathway generator outperforms the baseline with fewer errors. The implementation of RoCGAN is based on previous cGAN works, with a focus on duplicating the encoder/decoder, sharing decoder weights, and adding additional loss. The model aims to approximate target manifolds more effectively than the baseline, despite having the same parameters during inference. The RoCGAN model improves target manifold approximation by duplicating encoder/decoder, sharing weights, and adding extra loss terms. Hyper-parameters \u03bb l = 25, \u03bb ae = 100, and \u03bb decov = 1 are used, with decov loss reducing correlations in longer paths. Auxiliary experiments include ablation study on hyper-parameter significance, additional architectures, and resilience to adversarial examples in regression. Model shows robustness to various hyper-parameter values and noise levels. The model is robust to various hyper-parameter values and noise levels. Two categories of images are experimented with: natural scenes and faces. The network used has four layers in the encoder and decoder. Two inverse tasks, denoising and sparse inpainting, are evaluated. Images are corrupted during training and testing for these tasks. The study evaluates different methods for image denoising and sparse inpainting, including cGAN, OneNet, and Adversarial Autoencoder (AAE). AAE is trained with images in the target space and shows promising results in reconstruction during testing. In the experimental setting, AAE serves as an upper performance limit for RoCGAN/cGAN. The '4layer' baseline/RoCGAN is trained with images from natural scenes, with VOC 2007 Challenge BID4 samples as the training set and tiny ImageNet BID3 samples as the testing set. Quantitative evaluation using SSIM shows RoCGAN outperforming OneNet, with a margin of 0.05 (10-13% relative improvement) in both inverse tasks. RoCGAN also exhibit more robustness to additional noise in testing images. When additional corruption is applied to testing images, RoCGAN shows improved robustness compared to the baseline cGAN. Qualitative results are illustrated in Figure 4, showcasing the output of RoCGAN in denoising and sparse inpainting tasks for faces and natural scenes. The implicit constraints of the AE pathway contribute to this improvement. Quantitative results in Table 1 further support the superior performance of RoCGAN in both faces and natural scenes scenarios. In the '4layer' network, results show superior performance in denoising and sparse inpainting tasks for faces and natural scenes. The model outperforms the baseline and OneNet significantly, especially with more intense corruptions. The training set includes MS-Celeb with 3-4 million samples, and the testing set is the whole Celeb-A with 202,500 samples. The large datasets allow for extensive validation of the model. The RoCGAN model introduces a new conditional GAN for learning better latent representations, even in the presence of noise. It includes an autoencoder pathway in the target domain and enforces weight sharing between decoders to output images within the target manifold. The RoCGAN model enforces constraints on the reg pathway to output images within the target manifold. Additional insights, theoretical analysis, and experiments are included in the following sections of the appendix. These sections validate the RoCGAN constraints, provide a theoretical analysis, implement different networks to assess performance gains, and conduct an ablation study on hyper-parameter sensitivity and robustness to noise. The output vector of the synthetic experiment is detailed, and the nature and convergence properties of deep networks are discussed. The linear equivalent of deep methods is explored by focusing on the generators in RoCGAN. By dropping non-linear units, the linear autoencoder is analyzed. The AE approximates the target manifold of the data robustly under mild conditions. The linear autoencoder approximates the target manifold of the data robustly. The output of the generator spans the subspace learned with the AE. A visual example illustrates how a projection to a target subspace can constrain the image. RoCGAN shares properties with the original GAN. The optimal discriminator is derived and the optimal value of L adv (G, D) is computed. The optimal discriminator maximizes L adv by matching the model distribution. The global minimum of L adv is reached when the model distribution matches the data distribution. The optimal discriminator maximizes the adversarial loss by matching the model distribution to the data distribution. Experimental results show that RoCGAN outperforms other methods. Table 2 confirms RoCGAN outperforms compared methods, especially in cases of intense noise. Additional visualizations are provided in FIG0. Table 4 shows quantitative results for the '4layer' network in faces and natural scenes, with evaluations on corruptions similar to training and additional corruptions. The experimental results with Imagenet dataset confirm RoCGAN's superior performance over cGAN in various settings, including different network architectures. The AAE serves as a benchmark for encoder-decoder representation power. The study aims to showcase RoCGAN's advancements without focusing on finding the best architecture. The study introduces alternative cGAN models '5layer', '6layer', and '4layer-skip' to evaluate their performance compared to the baseline cGAN. Results show improvements in '5layer' and '6layer' networks over the '4layer' case, but '6layer' does not outperform '5layer'. The study compares different cGAN models, showing improvements in '5layer' and '6layer' networks over the '4layer' case. However, the '6layer' networks do not outperform their '5layer' counterpart due to the difficulty of training deeper networks without additional regularization techniques. The denoising and sparse inpainting results cannot be directly compared, but the model consistently outperforms the baseline in all cases. The study evaluates the performance of different cGAN models, with the '4layer' and '4layer-50k' protocols showing varying results for denoising and sparse inpainting tasks. The new model demonstrates up to 15% improvement in performance with additional noise during inference time. Additionally, the model can utilize unsupervised data for learning, supporting semi-supervised learning with RoCGAN. The RoCGAN model is trained with 50,000 images in the reg pathway and all available unlabelled samples in the AE pathway. Performance drops in semi-supervised cases compared to full training, but RoCGAN performs significantly better than cGAN. Additional examples in the target domain benefit RoCGAN, allowing the AE pathway to learn a more accurate representation. The goal is to map each input image to its target image, and the study assesses domain-specific performance for faces using cosine distance distribution plot. To evaluate faces' domain-specific performance, the study uses the cosine distance distribution plot (CDDP) and recognition embeddings. Ground-truth identities are not available, so the target image's embedding is considered as the reference. Quantitative results show improvement in RoCGAN's semi-supervised training compared to fully supervised training. The plot compares output pairs for similarity assessment. The plot compares output pairs for similarity assessment using cosine distance distribution plot (CDDP) and recognition embeddings. AAE has embeddings closer to target embeddings, while RoCGAN outperforms cGAN in proximity to target embeddings. All images are resized to 64 \u00d7 64 \u00d7 3. In this work, images are resized to 64 \u00d7 64 \u00d7 3 and random patches are cropped during training. The ADAM optimizer with a learning rate of 2 \u00b7 10 \u22125 is used, with batch sizes of 128 for faces and 64 for natural scenes. The network architectures for the generator and discriminator are detailed in tables 6-9. An ablation study is conducted on RoCGAN, exploring hyper-parameters, loss terms, and additional noise effects. The experiments focus on face denoising with SSIM as the similarity metric. The discriminator structure remains consistent in all experiments. Three new loss terms (L lat, L AE, L decov) are introduced compared to the baseline cGAN, requiring validation of three new hyper-parameters. Experimentation involved scrutinizing one hyperparameter at a time while keeping the others constant. Optimal values of hyper-parameters may vary per case/network, but in this study, they remained constant. The search space for each term is determined by theoretical properties and intuition. Different values for the \u03bb l are assessed, with results showing resilience to precise selection. Despite best results with \u03bb ae = 250, \u03bb ae = 100 is chosen as it resonates with intuition. The \u03bb decov value is chosen as 1 for experiments, with the model accepting a range of values without significant impact on results. The '4layer-skip' network is more sensitive to \u03bb decov than other parameters, with experiments conducted by setting \u03bb * = 0 alternately. The experimental results show that the latent loss is crucial for the model in the no-skip case but less significant in the skip case. Quantitative results for setting \u03bb * = 0 are presented in Table 13. RoCGAN/cGAN resilience to noise is evaluated by introducing additional noise in the denoising task. Both networks are trained with 25% noise, and their performance is assessed with additional noise of the same or different types. In the experiment, noise is abbreviated as x/y where x represents the amount of noise in denoising task and y in sparse inpainting task. The networks are tested with increasing noise levels and RoCGAN shows more resilience to noise compared to cGAN. The performance difference is illustrated through SSIM values and histograms in FIG0. The experiment tested noise levels in denoising and sparse inpainting tasks. RoCGAN showed more resilience to noise compared to cGAN, as illustrated in SSIM values and histograms in FIG0. Additionally, the study explored adversarial attacks on deep classifiers. The authors investigated adversarial attacks in image-to-image translation tasks, exploring the effects of perturbations on the network's output. Their model generated more realistic images compared to the baseline, even under challenging noise conditions. The study also examined the robustness of cGAN and RoCGAN models to adversarial examples. In this section, the authors explore how adversarial examples can affect robust models designed to withstand them. They use the FGSM method to generate adversarial examples by modifying the source signal with perturbations. The evaluation includes setting hyper-parameters and loss functions for target and generated images."
}