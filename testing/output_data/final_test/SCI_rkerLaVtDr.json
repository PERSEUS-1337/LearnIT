{
    "title": "rkerLaVtDr",
    "content": "In this work, a novel upper bound for target error in unsupervised domain adaptation is proposed. Deep neural networks can learn transferable features that generalize well to new tasks. Previous studies provided an upper bound for target error by minimizing source error and distance between marginal distributions. However, existing methods often overlook joint error, leading to mixed samples from different classes. To address this issue, a new upper bound considering joint error is introduced, allowing for proper penalization of undesirable cases. Additionally, a constrained hypothesis space is utilized for further improvement. The proposal introduces a novel upper bound for target error in unsupervised domain adaptation, utilizing a constrained hypothesis space and a cross margin discrepancy to measure dissimilarity between hypotheses. Empirical evidence demonstrates superior performance in image classification error rates on standard domain adaptation benchmarks. The advent of deep convolutional neural networks has revolutionized visual learning, but traditional machine learning's fixed distribution assumption limits real-world applicability. Domain adaptation (DA) aims to transfer knowledge from a labeled source distribution to an unlabeled target distribution. Unsupervised domain adaptation (UDA) is the most challenging case where no target labels are available. Ben-David et al. (2010) suggest minimizing target error by bounding model error on the source data and reducing distribution discrepancies between domains. Deep neural networks have strong representation power, making them suitable for this task. Deep neural networks are used in domain adaptation to minimize distribution discrepancies between domains. Two main strategies are employed: matching statistics and adversarial learning. Despite their success, feature distribution matching schemes have a limitation in joint distributions of features. This work addresses the limitation of feature distribution matching schemes in domain adaptation by incorporating joint error to penalize undesired overlap. Experimental results show that the proposed method outperforms other approaches in various classification tasks. The contributions of this work include proposing a novel upper bound, constructing a constrained hypothesis space, and introducing a novel measurement called cross margin discrepancy. These advancements aim to reduce the gap between source and target domains in domain adaptation. Transfer Component Analysis (TCA) uses Maximum Mean Discrepancy (MMD) to align hidden representations in deep neural networks across domains. AdaBN adjusts batch normalization statistics from source to target without additional parameters. Ganin & Lempitsky (2015) and Tzeng et al. (2017) utilize generative adversarial networks for domain-invariant feature learning. In the classification and adversarial learning stages, a feature extractor is used for the target domain. Various methods for distribution alignment, such as image-to-image translation, have been proposed by different researchers. These methods aim to bring source and target domains closer together and mix samples with different class labels. Long et al. (2018) propose conditional adversarial domain adaptation, which relies on pseudo-labels for training objective back-propagation in unsupervised domain adaptation, treating it as a binary classification task. The text discusses the optimal labeling functions on source and target domains, along with the error metrics and bounds associated with them. It also mentions the equivalence of certain proposals to optimal joint error bounds. The text discusses optimizing target risk by introducing a feature extractor to strengthen the min-player in a minimax game within a hypothesis space. The overall optimization problem involves minimizing a term while considering the arbitrary nature of the supreme term within the hypothesis space. The text discusses constraining the hypothesis space to obtain a tight bound for optimizing target risk. The constrained subspace for H1 is straightforward, while for H2, constructing a hypothesis space that likely contains fT is challenging due to lack of true labels in the target domain. Matching distributions of source and target domains can help assume fT \u2208 Hsc in the ideal case. In the context of constraining the hypothesis space to optimize target risk, two proposals are presented based on different constraints. The first proposal involves choosing a small value for the hyper-parameter \u03b3 to avoid the worst case scenario of mixed class samples. The second proposal uses a weighted source risk to approximate the behavior of classifiers for the target domain. The approximate target domain is based on pseudo labels obtained from the prediction of h during training. It assumes an intersection between two hypothesis spaces, H 2. The training objective is explained with the assumption for H 2, illustrated in Fig. 2. The feature extractor behavior is constrained to move target samples inside f 2 to reduce the training objective. The margin theory by Koltchinskii & Panchenko (2002) introduces a margin loss for quantifying the discrepancy between hypotheses f1 and f2. This margin loss, known as cross margin discrepancy, aims to improve the reliability of the proposed method by measuring the difference between two hypotheses over a distribution D. The cross margin discrepancy is a measure of the difference between two hypotheses f1 and f2 over distribution D. It involves margin loss for f1 on D f2 and margin loss for f2 on D f1, using the logarithm of softmax as the score function. A dual form is defined to mitigate exploding or vanishing gradients during adversarial learning, resembling the objective of a generative adversarial network. The feature extractor is trained to increase the probability of opponents in order to minimize discrepancy without unnecessary oscillation. When training the extractor in GANs, an alternative term is maximized instead of directly minimizing, to avoid the original term becoming close to zero. A new form of discrepancy measurement is defined when the two hypotheses eventually agree on some points. This discrepancy measurement helps alleviate instability in adversarial learning. The proposed cross margin discrepancy helps prevent instability in adversarial learning by keeping the gradient small near the decision boundary. Zhang et al. (2019) introduce a margin-aware generalization bound based on scoring functions and a new divergence MDD. The training objective in MDD aims to minimize margin disparity. The proposed method aims to minimize margin disparity in adversarial learning by using task-specific classifiers to separate decision boundaries on the source domain. This approach helps the extractor produce features close to the support of source samples, preventing instability. The proposed method minimizes margin disparity in adversarial learning by using task-specific classifiers to separate decision boundaries on the source domain. The upper bound optimization is relaxed by taking the supreme to form an optimizable objective. The experiment assesses the proposal in four adaptation scenarios using commonly used digits datasets in an unsupervised fashion. Our proposal outperforms competitors in most settings, except for one compared with GPDA. Their solution involves data augmentation through sampling, which we avoid. By combining upper bound with joint error, we achieve success in scenarios where label functions differ. Reliable pseudo-labels lead to improved generalization performance. Our proposal improves generalization performance by leveraging advantages and sensitivity to hyper-parameter \u03b3. Setting \u03b3 = 1 yields best performance in most cases, while in MNIST \u2192 SVHN, \u03b3 = 0.1 is optimal due to a significant domain shift. We outperform MCD, highlighting the importance of hypothesis space constraint and joint error in adaptation. Simply minimizing distribution discrepancy may not guarantee reliable adaptation. The study demonstrates the importance of joint error and the superiority of cross margin discrepancy in accelerating convergence for object classification on the VisDA dataset. The dataset consists of synthetic and real images, presenting a challenging adaptation task. The study shows that the proposed method outperforms competitors in all settings on the VisDA dataset, which has a more complex image structure than digits. Some distribution matching methods perform worse than simple statistic matching methods, highlighting the importance of considering joint error. Performance drops when relaxing constraints, leading to confusion. The study demonstrates the superiority of the proposed method over competitors on the VisDA dataset, emphasizing the importance of joint error. Relaxing constraints leads to confusion, with a drop in performance. The adaptation performance is tested for different parameters, showing a drastic decrease in prediction accuracy beyond a certain threshold. The proposed upper bound considers joint error and a tighter bound with constraints on the hypothesis space is pursued. A novel cross domain discrepancy is adopted for dissimilarity measurement. The study introduces a novel cross-domain discrepancy for dissimilarity measurement to address instability in adversarial learning. Results suggest that learning an invariant representation alone may not ensure good generalization in the target domain, emphasizing the importance of joint error, especially with significant domain shifts. The approach aims to advance unsupervised domain adaptation by aligning conditional distributions without relying on pseudo-labels from the target domain. In an experiment using the Office-Home dataset, a ResNet-50 model pretrained on ImageNet is fine-tuned with a 2-layer fully-connected network for classification. The model utilizes batch normalization, dropout, and SGD optimization with Nesterov momentum. The ResNet-50 model is fine-tuned using SGD with Nesterov momentum fixed at 0.9, batch size 32, and learning rate adjusted according to Ganin et al. (2016). The adaptation accuracy of the source-only method is low, indicating a significant domain shift. Simply minimizing the source-target discrepancy may not work as it can increase joint error when aligning distributions. The proposal incorporates joint error into the target error upper bound, improving performance especially with large domain shifts. The Office-Home dataset and Office-31 dataset are used to verify the effectiveness of domain adaptation algorithms. In this experiment, a ResNet-50 model is fine-tuned using SGD with Nesterov momentum fixed at 0.9, batch size 32, and learning rate adjusted according to Ganin et al. (2016). The adaptation algorithm involves three diverse domains - Amazon, Webcam, and DSLR - with 4,652 images in 31 unbalanced classes. Results on Office-31 dataset show the advantage of the proposed method in handling mixed class samples during distribution matching. Our method demonstrates an advantage in penalizing undesired matching between source and target distributions. However, in tasks A\u2192W and A\u2192D, our proposal shows high variance and poor performance, especially in A\u2192W, possibly due to the noise in the Amazon dataset affecting the reliability of source classifiers and harming convergence."
}