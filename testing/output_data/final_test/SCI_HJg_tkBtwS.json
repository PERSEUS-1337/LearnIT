{
    "title": "HJg_tkBtwS",
    "content": "Answering questions about data involves understanding the influence of input variables on the response. Machine learning models can help test relationships between variables. Proper test statistics, such as f-divergences like KL-divergence, can determine feature importance even when other features are known. These statistics can be used to find important features at the individual sample level. Our method demonstrates the ability to identify important features at the individual sample level across various datasets, outperforming baselines. It can pinpoint significant genes, predictors for hospital readmission, and distinguishing features in image classification tasks. Model interpretation techniques aim to make models more interpretable by selecting key features for a response, but the interpretation is influenced by the population distribution. Interpreting a model involves understanding the population distribution of data through the lens of the model. Existing methods have limitations in working with specific models, test statistics, or auxiliary models for interpretation. Feature selection methods that work in a black-box manner should not require a particular structure in models used. Assessing the population distribution can be done by testing if a response is independent of a feature given the rest of the features. Proper test statistics are essential for conditional randomization tests to capture relationships between variables. The KL-divergence is a useful metric for measuring the divergence between distributions, simplifying estimation, and allowing for reuse of model structures. The proposed procedure, AMI-CRT, uses regressions to simulate data from the null for each feature and compares the additional mutual information (AMI) of the original data to the simulations. This method addresses the issue of \"instance-wise feature selection\" by identifying relevant features for individual data points. The proposed procedure, AMI-CRT, uses regressions to simulate data from the null for each feature and compares the additional mutual information (AMI) of the original data to the simulations. This method addresses the issue of \"instance-wise feature selection\" by identifying relevant features for individual data points. Several methods have been proposed for instance-wise feature selection, including local perturbations and fitting simpler auxiliary models. The conditions for instance-wise feature selection with predictive models are not well developed, but this work aims to establish sufficient conditions for it. The AMI-CRT procedure uses regressions to simulate data for each feature and compares the additional mutual information (AMI) to identify relevant features for individual data points. Feature selection aims to find important features that improve predictions, formalized through conditional independence. In a finite sample setting, statistical hypothesis tests are used to assess conditional independence. In the finite sample setting, a conditional randomization test (CRT) defines a hypothesis test for conditional independence. CRTs compute a test statistic for each feature using data samples. The p-value for a CRT is uniform under smoothness constraints, as it computes the cumulative distribution function of the test statistic under the null. CRTs provide a general method for conditional independence testing but leave the choice of test statistic unspecified. Proper test statistics are introduced to address limitations in testing for conditional independence. These statistics ensure that p-values converge to 0 when rejecting the null hypothesis and are uniformly distributed otherwise. The power to reject the null hypothesis must be 1 under the alternate hypothesis, implying that p-values must approach 0. Proper test statistics in a CRT select features as data grows, similar to a scoring rule. Proper test statistics, like divergences, measure the closeness between two distributions in a probabilistic prediction model. Divergences are used as test statistics to ensure calibration and proper estimation in a CRT. In a CRT, using a divergence like distributionq j =q j ( x j | x \u2212j )q(y, x \u2212j ) requires estimates of conditional distributions: q(x j | x \u2212j ), q(y | x), q j (y | x j , x \u2212j ), and q(y | x \u2212j ). The first distribution is necessary for any CRT, while the third distribution involves a regression model with corrupted inputs. Developing new model structures may be necessary for the last distribution, especially when conditioning on a subregion of an image. The KL-divergence simplifies the computation by removing the need to estimate distributions, reducing computation and allowing reuse of training infrastructure. The expected KL-divergence, known as additional mutual information (AMI), computes the p-value. The expected value of \u03b4 j for p-value estimation in Equation (1) requires estimation from a finite sample. D N is a collection of N datapoints sampled iid from q(x, y), while D j,N is sampled iid from q(x \u2212j , y)q( x j | x \u2212j ). Models for x to y and ( x j , x \u2212j ) to y are built using training and test sets split from data D N. Parameters \u03b8, \u03b2 are used to fit distributions q \u03b8 ( x j | x \u2212j ) and q \u03b2 (y | x) on the training set, and q \u03b3 (y | x j , x \u2212j ) on the training part of D j,N. Monte Carlo estimation is used to compute the expectations in \u03b4 j. To speed up the computation of AMI-CRT, a shared model is used for q \u03b8 ( x j | x \u2212j ) and q \u03b2 (y | x), while q \u03b3 (y | x j , x \u2212j ) is recomputed for each replication. The averaged model, combining q \u03b2 (y | x) and q \u03b3 (y | x j , x \u2212j ), is utilized to estimate \u03b4 j. Averaging ensures uniform p-values under the null hypothesis. The FAST-AMI-CRT procedure involves averaging models to improve performance. Averaging helps to address variance in models trained on the same distribution. The averaged model provides advantages such as being more conservative and requiring only one null model per feature. This approach guards against errors in estimating the complete conditional distribution and can be implemented using standard regression models. The FAST-AMI-CRT procedure involves averaging models to improve performance by using standard regression models like logistic regression, neural networks, and random forests. Nonparametric regression can also be utilized. The choice of estimator should be based on validation data. Instance-wise feature selection (IWFS) is used to identify important features on a per-sample basis by considering the probability of observing a specific label given a set of features. The candidate definition for important features involves observing a label y given a set of features x. While Definition 2 can identify important features, it may also select unimportant ones. In a data generating process example, selecting the wrong feature as important can occur, even with access to the true conditional distribution q(y | x). The formulation in Definition 2 for selecting important features can be problematic as noise can act as a \"selection\" mechanism. Predictive models may not be sufficient for instance-wise feature selection, but under certain conditions, it is possible to identify a set of features that contribute to predictions. Instance-wise feature selection methods, such as IWFS (1995), do not assume data distribution and allow for feature selection on a per-instance basis. These methods can be compared to traditional feature selection techniques. By using the same estimators as AMI-CRT or FAST-AMI-CRT, an IWFS procedure can be constructed. The process involves manipulating probabilities and using Jensen's inequality to determine feature importance. If the inequality is strict, the feature is considered important, while equality indicates an unimportant feature. Inequality can introduce slack in feature relevance testing, but Proposition 1 shows this is not an issue. Equation (5) can determine feature importance through equality testing. An example in Appendix C.2 illustrates how Equation (5) scores can rank features. This method is termed AMI-IW and is similar to FAST-AMI-CRT. The procedure uses estimators from FAST-AMI-CRT to compute instance-wise logprobability differences. In AMI-IW, a null estimator is used for q j (y | x j , x \u2212j) and a mixture of estimators can be used at the cost of power. Comparison is made with AMI-CRT and FAST-AMI-CRT on performance metrics. HRTs construct tests using a loss function, with 0-1 loss being studied in experiments. AMI test-statistic is used with HRT in specific settings, called ami-hrt, which is shown to be better calibrated than 0-1 HRT. The regression approach using conditional categorical distribution parameterized with neural networks is used to model q(x j |x \u2212j ) for experiments. Simulations are conducted to evaluate each selection method, including using the xor dataset to test feature informativeness. The orange dataset is used to test nonlinear functions of x, with experiments on instance-wise feature selection methods. Features are selected based on p-values for methods using CRTs or HRTs, while importance scores are used for baselines without p-values. Noise is also introduced to evaluate feature selection effectiveness. The importance scores are used to select features in methods that do not produce p-values. The mean area under the ROC curve is presented for xor and orange datasets, showing most methods solve the task well except for corr-crt. The ami-crt achieves a higher AUROC than baselines, while fast-ami-crt performs similarly. To control the false discovery rate, a threshold for importance scores must be chosen. The calibration of p-values across ami-crt is investigated for feature identification. The calibration of p-values across different methods is investigated for feature identification. CRT-based methods produce independent p-values, while loss-hrt produces deflated and non-uniform p-values, leading to incorrect identification of null features as important. The fast-ami-crt method strikes a balance between hrt and ami-crt by generating well-calibrated p-values with only one null model per feature. Comparing refitting (CRTs) and not refitting (HRTs) methods, it is found that refitting protects against poor approximations of q(x j | x \u2212j). The p-value distribution for fast-ami-crt is uniform, while both HRT methods show significantly non-uniform distributions. The fast-ami-crt method provides well-calibrated p-values with only one null model per feature. Comparing refitting and not refitting methods, refitting protects against poor approximations. The p-value distribution for fast-ami-crt is uniform, while HRT methods show significantly non-uniform distributions. In instance-wise feature selection, different tests are performed for each selection method, with ami-iw achieving the highest precision. In the noisy-selector task, there is a decrease in scores across all methods, with the largest decrease for ami-iw and loss-hrt. The noise in sampling the response obscures important features, leading to reduced performance. Despite this, ami-iw performs the best by identifying the selector variable x1 in almost every sample. Linear methods like lime fail due to the highly non-linear selection mechanism. rf and corr-crt do not assign importance at the individual sample level, resulting in less meaningful scores per instance. The study focuses on genomic analysis of Celiac disease, analyzing single nucleotide polymorphisms (SNPs) for each individual in the dataset. The dataset contains SNPs for individuals with Celiac disease. After preprocessing, 1759 SNPs remain. The study uses methods to identify SNPs contributing to the disease. Results are shown in Table 4 with FDR-control. Features are selected based on p-values at a theoretical FDR of 20%. In the study on SNPs related to Celiac disease, 40 SNPs from the dataset are compared to previous research. Ami-crt is found to outperform other methods, with fast-ami-crt performing similarly. Corr-crt selects a large number of features but with low precision due to correlations among SNPs. AMI-based methods show better precision and recall compared to loss-hrt. The dataset used for hospital readmission analysis includes ten years of medical logs from over 130 hospitals. Features include time spent in the hospital, doctor's specialty, age, and diagnostic information. Labels represent readmission events within 30 days, after 30 days, or no readmission. Due to class imbalance, readmitted patients were grouped together. A random forest classifier with 100 estimators was used to model q(y|x), achieving the highest AUROC compared to benchmarks. The ground truth features from clinical validation by Strack et al., 2014 are used to compute ROC curves for different selection methods. Ami-crt and fast-ami-crt show higher AUROC than state-of-the-art approaches, while loss-hrt performs well with low power at false positive rates. These methods do not assume independence between relevant and irrelevant features, unlike lime and shap. The task involves differentiating between ambulances and police vans based on a few distinguishing features. To differentiate between ambulances and police vans, a generative inpainting model is used to model the distribution of patches in the image. A VGG-16 network is utilized to model the conditional distribution. Log-probability differences are computed using generated samples for each patch to perform instance-wise testing. Results of the AMI-IW method are shown in Figure 2, displaying original images of ambulances and police vans with masked patches. The model used achieves 90% accuracy on a test set by using relevant details like words on vehicles to distinguish between ambulance and policevan classes. It ignores shared features across classes and determines relevant features on an instancewise level. Comparison to LIME and SHAP methods is also provided in Figures 6 and 7. The model achieves 90% accuracy by using details like words on vehicles to distinguish between ambulance and policevan classes. LIME and SHAP methods perform well but miss identifying writing on the vehicles. AMI-CRT is developed for testing conditional independence of features, allowing for less computation with FAST-AMI-CRT. FAST-AMI-CRT is a method that requires less computation than AMI-CRT and is robust to poor estimation of the null conditional. It includes AMI-IW, an instance-wise feature selection method that outperforms popular methods in various tasks such as identifying biologically significant genes and selecting indicative features for predicting hospital readmissions. The assumptions for proving t as a proper test statistic involve the continuity of cumulative distribution functions, access to complete conditionals, and showing that t(E n ) is a consistent estimator. The p-values are shown to be zero under the alternate hypothesis and uniformly distributed under the null, converging to a delta mass at 0. The distribution of the p-value is derived based on the cumulative distribution function of the test statistic. Discontinuities may occur when certain events happen with non-zero probability, affecting the range of possible p-values. To address this, the indicator function in the test statistic can be replaced with a function involving a continuous uniform random variable. In this example, the distribution of p-values is modified to ensure uniformity, addressing discontinuities that may occur. The sufficiency condition for feature selection is discussed, showing that the current definition may not reject unimportant features. Probability distributions are outlined, and the importance of instances in the data generating process is highlighted for a faster framework. The HRT framework offers a speedup by avoiding refitting estimators. A quantile-quantile plot of null p-values for FDR-controlling feature selection methods is shown. Table 6 displays significant SNPs selected by AMI-CRT. Standard pre-processing techniques were applied to the hospital readmission dataset. Laboratory tests and medications were administered during the encounter. Labels were binarized for readmission events. Categorical features were encoded using one-hot encoding. Missing values were imputed with the median and the \"weight\" feature was dropped. A neural network was used for complete conditional regression. Continuous values were discretized into bins and predicted using a neural network. Instance-wise feature selection results on ImageNet data using AMI-CRT were shown in Figure 5. Instance-wise feature selection on ImageNet data using AMI-CRT, LIME, and SHAP was compared. AMI-CRT identified patches relevant for distinguishing between ambulances and policevans, while LIME focused on image features like wheels and lights. SHAP highlighted distinguishing symbols but occasionally missed relevant text. The results are shown in Figures 6 and 7. The second and fourth columns display patches with non-zero AMI with the label, in relation to other patches."
}