{
    "title": "r17Q6WWA-",
    "content": "Convolutional neural networks (CNN) are widely used in vision-related domains, but are limited by data scarcity. Multi-task learning (MTL) has been proposed to address this issue by leveraging domain-specific information from related tasks. The Deep Collaboration Network (DCNet) is a novel approach that connects task-specific CNNs in a MTL framework to improve knowledge sharing. The Deep Collaboration Network (DCNet) connects task-specific CNNs in a MTL framework using non-linear transformation blocks. Skip connections deactivate unrelated task-dependent features, leading to improved performance in facial landmark detection datasets. Experimental results show a 24.31% relative improvement in landmark failure rate compared to other MTL approaches. The approach allows knowledge sharing by leveraging domain-specific features at different depths related to tasks. Convolutional neural networks (CNNs) have become the leading approach in vision-related tasks by creating a hierarchy of abstract concepts from input images. Training deep networks is challenging due to issues like vanishing/exploding gradients and a large number of parameters to be learned. Previous works have used pre-trained networks on large image datasets as a starting point for gradient optimization. Recent advances in machine learning have shown the value of multi-task learning (MTL) in improving generalization by leveraging domain-specific information from related tasks. This approach has become dominant in the field, with opportunities for novel contributions in MTL due to advancements in neural networks. The core contribution of this approach is efficiently gathering more information from related tasks to enhance a network's performance on its main task. Neural networks have enabled novel contributions in multi-task learning (MTL), with applications in various fields such as pedestrian detection, natural language processing, face recognition, and object detection. MTL is gaining popularity in the deep learning community as a way to address data scarcity. MTL strategies include hard and soft parameter sharing, with recent results showing the effectiveness of a central CNN with separate task-specific fully connected layers. Hard parameter sharing reduces the risk of overfitting. Soft parameter sharing is proposed as an alternative to hard parameter sharing in multi-task learning to prevent overwhelming shared layers with noise from specific tasks. It separates hidden layers into task-specific models while allowing knowledge sharing. Recent works have explored methods such as regularizing task-specific parameters, training shared and private LSTM submodules, partitioning hidden layers, and using tensor normal priors to improve performance. In the domain of continual learning, progressive network BID20 has shown promising results for cross-domain sequential transfer learning by employing lateral connections to previously learned networks. A novel approach called deep collaboration network (DCNet) is introduced in this paper, which connects task-specific networks in a soft parameter sharing multi-task learning framework. The collaborative block, a novel knowledge sharing mechanism, aggregates task-specific features into global features and merges them back into each task-specific network. This block can be easily integrated into existing architectures to enable multi-task learning. The paper introduces a collaborative block for multi-task learning, which improves facial landmark detection compared to other approaches. The training framework's objectivity is evaluated by varying task contributions, and knowledge sharing is enabled through the collaborative block in a DCNet. The paper also discusses related works on multi-task learning, facial landmark detection, and the architectural details of the proposed approach. The paper discusses landmark detection for AlexNet and ResNet18 with MTL frameworks, including a proposed DCNet. It compares linear and non-linear feature map sharing approaches, highlighting the benefits of non-linear combinations for richer relationships in deep networks. Our approach for facial landmarks detection simplifies the training process by not requiring task-dependent hyper-parameters like the TCDCN method. It utilizes transformation blocks with batch normalization, ReLU, and convolutional layers based on recent advances in residual networks. Our proposed approach simplifies facial landmarks detection training by utilizing transformation blocks with batch normalization, ReLU, and convolutional layers based on recent advances in residual networks. It integrates no additional hyper-parameter tuning experiments and aggregates same-level features of multiple CNNs for feature fusion. This is different from HyperFace, which fuses intermediate layers of a single CNN. Our approach simplifies facial landmark detection by aggregating features from multiple CNNs independently at different depths. Unlike HyperFace, our method is not specific to any network and can be added to any architecture without modification. Facial landmark detection is crucial for tasks like face recognition, validation, and feature detection. Facial landmark detection is challenging due to various factors like lighting conditions, head poses, and facial expressions. FLD datasets not only contain facial landmark positions but also other labels like gender recognition and smile recognition, making them ideal for evaluation. Facial landmark detection datasets are well-suited for evaluating multi-task learning frameworks. The proposed approach aims to connect task-specific networks by sharing domain-specific information through non-linear transformations. Unlike traditional methods, this approach allows for complex transformations and proper network connectivity. The collaborative block is illustrated in Figure 1, showing the feature maps of five task-specific networks being concatenated and transformed. The proposed approach connects task-specific networks by sharing domain-specific information through non-linear transformations. Feature maps are concatenated and transformed to create task-specific feature maps, which are then added back to the input feature map using skip connections to produce final outputs. The network is decomposed into blocks to facilitate understanding and explicit connection of feature maps at different depths. Our approach connects task-specific feature maps through a collaborative block. The goal is to combine all task-specific feature maps into a global feature map for unified knowledge. The structure includes batch normalization, ReLU activation, and convolution operations. The collaborative block connects task-specific feature maps by combining them into a global feature map using batch normalization, ReLU activation, and convolution operations. Inspired by recent advances in residual networks, the block includes identity skip connections to help integrate domain-specific information from related tasks. This allows for easier learning of proper mappings and parameter adjustments towards zero. The collaborative block integrates task-specific networks by combining them into a global feature map with identity skip connections. This helps in adjusting parameters towards zero and allows for easier learning of proper mappings. The depth at which the collaborative block is inserted influences the relevance of each task towards another, with low-level features being more beneficial for some tasks. Landmark localization and pose detection benefit from low-level features for better localization, while tasks like face detection and gender recognition utilize high-level features. The collaborative block in the Deep Collaboration Network (DCNet) deactivates different residual mappings based on task relevance. This approach integrates task-specific networks into a global feature map, enhancing parameter adjustment and mapping learning. Our proposed approach in the Deep Collaboration Network integrates task-specific networks into a global feature map, achieving the lowest failure rates overall. The multi-task learning framework is detailed, focusing on facial landmark detection tasks. Ablation studies and task importance experiments are conducted to analyze the approach's effectiveness in predicting specific facial landmarks. The dataset defines standard facial landmarks like mouth corners, nose tip, and eye center, with related tasks such as gender, smile, glasses recognition, face orientation. Tasks are treated as classification problems, with face orientation and FLD divided into bins for prediction. In facial landmark detection, the image is divided into bins for predicting landmark labels. The landmark failure rate metric is used to evaluate performance, with a normalized mean distance greater than 10% considered a failure. An experiment was conducted on the MTFL dataset, which includes face images annotated with facial landmarks and attributes like gender, smile, glasses, and face profile. The study involves facial landmark detection with attributes like gender, smile, glasses, and face profile on the MTFL dataset. Four sets of experiments were conducted using different pre-trained and un-pretrained networks. Results show example predictions with successes and failures, highlighting ground truth and predictions for the related tasks. The study compares different approaches for facial landmark detection on the MTFL dataset, including single-task learning, multi-task learning, HyperFace network, TCDCN, and Cross-Stitch approach. Results show that the proposed DCNet achieved the lowest failure rates, with 19.99% and 19.93% using un-pretrained and pre-trained AlexNet as the underlying network. The study compared different approaches for facial landmark detection on the MTFL dataset. The proposed DCNet achieved the lowest failure rates, with 15.32% and 14.34% using ResNet18. Significant improvements were seen when using AlexNet as the underlying network. Connecting task-specific networks with the approach proved to be more efficient than increasing the number of parameters. The study compared different approaches for facial landmark detection on the MTFL dataset. The proposed DCNet achieved the lowest failure rates, with 15.32% and 14.34% using ResNet18. Connecting task-specific networks with the approach proved to be more efficient than simply increasing the number of parameters. In a second experiment, domain adaptation was performed on the AFW dataset BID33, resulting in 377 face images processed with facial bounding boxes. The DCNet approach achieved the best results overall, with failure rates of 43.77% and 45.62% using pre-trained AlexNet, and 37.75% and 37.84% with ResNet18. This outperformed other approaches significantly. The DCNet approach showed significant improvements in performance with different underlying networks. When using an un-pretrained AlexNet, it achieved the highest improvement, while with a pre-trained ResNet18, it also showed a notable increase in performance. Interestingly, approaches with pre-trained ResNet18 outperformed those with pre-trained AlexNet, leading to lower failure rates. In contrast to AlexNet, ResNet18 showed better performance in domain adaptation, with a lower failure rate for both pre-trained and un-pretrained models. Additionally, the influence of training examples on Multi-Task Learning (MTL) was evaluated using the AFLW dataset, which contains 21 facial landmarks and 3 related tasks. The AFLW dataset contains 2,111 images with 21 facial landmarks and 3 tasks (gender, glasses, face orientation). Face orientation is divided into 14 bins for roll, yaw, and pitch. A pre-trained ResNet18 was used to compare different training approaches, showing slow convergence but outperforming others in most cases. The experiment involved training on varying image numbers with different train/test ratios. The experiment involved training on varying image numbers with different train/test ratios. The approach obtained the best performance in all cases except the first one, showing improvements with train/test ratios from 0.3/0.7 to 0.9/0.1. The networks are over-fitting the small training set, but better performance was achieved using the approach. Figure 6 shows the landmark failure rate progression for each network at different train/test ratios. Our approach exhibits slow convergence initially. In Figure 7, our approach outperformed XS in 86 out of 100 tries, demonstrating its superiority. Our approach shows slower convergence compared to other methods, with convergence occurring around epoch 100. The convergence epoch increases as the number of training images decreases. Despite the slower convergence rate, our approach achieves similar train failure rates and better generalization abilities, resulting in a smaller train-to-test gap. Notably, the XS network exhibits relatively high failure rates, despite performing similarly or better than other approaches in previous experiments. Our approach, despite slower convergence, achieves similar train failure rates and better generalization abilities compared to other methods. XS network shows high failure rates, even though it performs similarly or better in previous experiments. In a new experiment using a pre-trained ResNet18, our approach outperforms XS in landmark failure rate improvement by training each network 100 times with randomly sampled task weights. In 86 out of 100 tries, our approach showed a positive failure rate improvement compared to XS, with a median improvement of 3.14% and a maximum of 8.45%. The results indicate that our approach consistently outperforms XS, even when task weights are randomly sampled. Additionally, an ablation study using the MTFL dataset with an un-pretrained ResNet18 as the base network further confirms the performance improvements of our approach. The experiment evaluates the impact of removing task-specific network contributions by masking their feature maps at the input of the central aggregation transformation. Results from the ablation study on the MTFL dataset with an un-pretrained ResNet18 show the effect on landmark failure rate, with blocks of high saturated color having a significant impact on performance. The ablative study on the impact of color on performance in the collaborative ResNet18 architecture showed that high-level face profile features have a large influence, indicating domain-specific information sharing. The study involved zeroing out designated feature maps during concatenation, with results presented in Figure 8. Removing features from the facial landmark detection network significantly increases landmark failure rate, with a negative relative change of 29.72% and 47.00% in failure rate by removing features from B3 and B2 respectively. This shows that the main-task network contributes to and feeds from the global features computed by the central aggregation transformation. The facial landmark network's task-specific features influence the quality of global features, which in turn affect subsequent task-specific features. B5 from the face profile task has the highest impact on failure rate, with an 83.87% decrease when its features are removed. Features from head-related tasks improve landmark predictions due to their influence on face orientation. B5 has the highest-level features among all blocks. The deep collaboration network (DCNet) connects task-specific networks in multi-task learning by implementing feature connectivity and sharing through non-linear transformations. It incorporates skip connections and residual mapping for improved training behavior, leveraging domain-specific information and improving knowledge sharing with better network connectivity. Our collaborative blocks in DCNet aggregate task-specific feature maps into a global feature map and merge it back into each task-specific network. They can be integrated into existing architectures for multi-task learning. DCNet outperformed state-of-the-art approaches on MTFL, AFW, and AFLW datasets, including cross-stitch networks. Task-specific networks in DCNet successfully incorporated features with varying levels of abstraction, showing improved flexibility and performance. Further evaluation on other MTL problems is recommended. Our proposed approach in DCNet outperformed state-of-the-art methods on various datasets. Future works could explore applying our method to other multi-task learning problems, such as incorporating domain-information into recurrent networks for natural language processing tasks."
}