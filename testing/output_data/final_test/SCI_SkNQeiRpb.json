{
    "title": "SkNQeiRpb",
    "content": "This paper introduces a new model for rating prediction in recommender systems, outperforming previous models on a Netflix dataset. The model is a deep autoencoder with 6 layers, trained end-to-end without pre-training. It shows that deep models generalize better, require non-linear activation functions, and benefit from regularization techniques like dropout. A new training algorithm using iterative output re-feeding improves performance and training speed. The code is publicly available. Recommender systems are used by sites like Amazon, Netflix, and Spotify to suggest items to users. Recommender systems can be context-based or personalized, with personalized recommendations using collaborative filtering to predict user interests based on similar tastes. The goal is to improve prediction accuracy, as seen in the Netflix Prize contest. To improve the accuracy of predicting user ratings for films using collaborative filtering, training deep autoencoders with scaled exponential linear units (SELUs) can solve optimization issues without layer-wise pre-training or residual connections. Heavy dropout with a high drop probability of 0.8 is used to prevent overfitting in relatively small publicly available datasets for collaborative filtering. Deep learning has led to breakthroughs in various fields like image recognition and natural language understanding. There is a growing interest in using deep learning for recommender systems. Different approaches like restricted Boltzman machines, autoencoders, feed-forward neural networks, and recurrent recommender networks have been used. Adapting deep autoencoders for dimensionality reduction tasks is also common. Deep learning has been applied to recommender systems, with approaches like I-AutoRec and U-AutoRec for collaborative filtering. Matrix factorization techniques like ALS and probabilistic matrix factorization are popular. The Netflix Prize competition inspired robust systems incorporating temporal information, leading to models like TimeSVD++ and recurrent recommender networks. Our model, inspired by U-AutoRec, trains deeper models using SELUs, high dropout rates, and iterative output re-feeding. An autoencoder aims to obtain a d-dimensional representation of data by minimizing the error measure between x and f(x). Autoencoders are useful for dimensionality reduction and are a generalization of PCA. In our model, the autoencoder uses feed-forward neural networks with SELU units in hidden layers. The decoder mirrors the encoder architecture, with weights constrained to be equal to transposed encoder weights. This constrained autoencoder has almost two times less parameters. The constrained autoencoder in the model has fewer parameters than the unconstrained one. During forward pass and inference, the model takes a sparse user representation and predicts ratings for all items in the corpus using Masked Mean Squared Error loss. The input is sparse as users realistically rate only a tiny fraction of items. Bayesian approaches can help overcome the issue of sparse input data in model training. In an ideal scenario with a perfect output from an autoencoder, the predicted ratings for all items accurately match the user's future ratings. To enforce a fixed-point constraint, iterative dense re-feeding steps are added to each optimization iteration. To overcome sparse input data, Bayesian approaches can be used in model training. Iterative dense re-feeding steps are added to each optimization iteration to enforce a fixed-point constraint. The process involves computing gradients, performing weight updates, and predicting future ratings based on past ones. The original Netflix Prize training set is split into training and testing intervals based on time for evaluation. For experiments, data sets are split so each rating has 50% chance in subsets. Users/items not in training set are removed. Batch size of 128, SGD with momentum 0.9, LR 0.001 used. Xavier initialization for parameters. No layer-wise pre-training like BID20. Tested activation functions: sigmoid, RELU, RELU6. AutoEncoder has encoder and decoder neural networks fused on \"representation\" layer z. Encoder has 2 layers e 1 and e 2, decoder has 2 layers d 1 and d 2. The study tested various activation functions (ELU, SELU, LRELU) on a 4-layer autoencoder with 128 units in each hidden layer. ELU, SELU, and LRELU outperformed other functions like SIGMOID and RELU. The key properties for successful training were identified as having a non-zero negative part and an unbounded positive part. In this study, SELU activation units were found to be important for successful training in a setting with a large dataset from Netflix. The first layer of the encoder has d * n + d weights, where d is the number of units in the layer. Overfitting can occur even with small values of d, but adding more layers can help improve generalization. In experiments, adding more layers in the model showed a positive correlation with evaluation accuracy. However, blindly adding too many layers resulted in diminishing returns. It was found that having too many small layers eventually hits diminishing returns, prompting further experimentation with model architecture and hyper-parameters. Our most promising model architecture consists of 3 encoder layers (512, 512, 1024), a coding layer of 1024, and 3 decoder layers (512, 512, n). To prevent overfitting, we applied dropout with a high drop probability of 0.8 on the encoder output only. Iterative dense re-feeding further improved evaluation accuracy for our 6-layer model. Applying dense re-feeding and increasing the learning rate improved evaluation RMSE from 0.9167 to 0.9100. The best checkpoint had a test RMSE of 0.9099, significantly better than other methods. The best model achieved a test RMSE of 0.9099, outperforming other methods like RRN, T-SVD, and I/U-AR. Despite not considering temporal dynamics, it still excelled in future rating prediction. The model trained on \"Netflix 3 months\" data had significantly worse performance compared to \"Netflix full\". Deep learning has revolutionized machine learning, including recommender systems. Very deep autoencoders can be trained successfully on small data using dropout and scaled exponential linear units. Iterative output re-feeding improves collaborative filtering, learning rate, and generalization performance. Our model, without additional temporal signals, outperforms other approaches in future rating prediction. User-based models are more practical than item-based models in real-world recommender systems due to the higher number of users. Sampling items instead of users can be acceptable when scaling personalized recommender systems."
}