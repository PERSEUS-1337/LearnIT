{
    "title": "HygfXWqTpm",
    "content": "The SHINRA project aims to structure Wikipedia through collaborative construction to create a well-organized knowledge base for NLP applications. Existing knowledge bases like CYC, DBpedia, and Wikidata have coverage and coherence issues, prompting the need for a new approach. The project involves a shared task to structure Wikipedia and address these challenges. The SHINRA project aims to structure Wikipedia through collaborative construction to create a well-organized knowledge base for NLP applications. The automatic knowledge base construction shared-tasks have been popular for decades, but are limited to comparing system performances on test data. To improve this, changes are proposed such as designing tasks to construct knowledge bases, making system outputs public, and repeating tasks with larger training data. \"SHINRA2018\" implemented these changes. In \"SHINRA2018\", the project aimed to extract values of pre-defined attributes from Japanese Wikipedia entities. Participants were given 600 training data to submit attribute-values for remaining entities in the same category. 100 data per category were used to evaluate system output. In \"SHINRA2018\", participants extracted values from Japanese Wikipedia entities. A preliminary ensemble learning showed F1 score improvements on 5 categories. Three tasks were planned for 2019: ML categorization, JP-5 extraction, and JP-34 extraction. Based on the \"Resource by Collaborative Contribution (RbCC)\" scheme, a shared task was conducted to structure Wikipedia, attracting participants whose results were used to build a knowledge base. Results from previous shared tasks were often underutilized, so a project was initiated on AKBC to gather and utilize system results through ensemble learning. Organizers did not disclose test data to participants, leading them to run their systems on all Wikipedia entities. This approach allowed for the generation of improved results compared to the best system through ensemble learning. The \"SHINRA2018\" project under the RbCC scheme involves extracting attribute values from Wikipedia pages for Japanese entities categorized into 200 ENE categories. Participants run their systems on all entities to gather structured information, which is later used to build a well-structured Knowledge Base through ensemble learning methods. The results are made public for collaborative knowledge construction. The \"SHINRA2018\" project involved extracting attribute values from Wikipedia pages for Japanese entities in 200 ENE categories. Participants submitted attribute-values for entities in training data, with hidden data used for evaluation. 8 groups submitted results based on 15 systems, showing significant improvements through ensemble learning. Wikipedia is a valuable knowledge base, but not machine-friendly. The goal is to transform Wikipedia data for machine processing. The goal of the project is to transform Wikipedia into a machine-readable format by structuring it using automatic knowledge base construction. Various machine-readable knowledge bases like CYC, DBpedia, YAGO, Freebase, and Wikidata have issues that need to be addressed. To solve these problems, a project was started to create a cleaner ontology definition for Wikipedia. Automatic knowledge base construction shared-tasks have been popular for decades, particularly in Information Extraction and Knowledge Base population. The project aims to transform Wikipedia into a machine-readable format by structuring it using automatic knowledge base construction. The SHINRA2018 task focuses on designing a shared-task to construct a knowledge base rather than just evaluating on limited test data. It also emphasizes making the outputs of all systems open to the public for ensemble learning to create better results. The SHINRA2018 project, known as \"Resource by Collaborative Contribution (RbCC)\", aims to extract values of pre-defined attributes from Wikipedia entity pages. They used Extended Named Entity (ENE) categories and attributes for each category. The task focused on 5 categories: person, company, city, airport, and chemical compound. Participants were provided with 600 training data for each category to extract attribute values. Participants in the SHINRA2018 project were given 600 training data for each of the 5 categories to extract attribute values from Japanese Wikipedia. They had to submit attribute-values for all remaining entities in the categories, with 100 data used for evaluation. All outputs were shared among participants for ensemble learning to create a better knowledge base. Ensemble learning in SHINRA2018 project led to cleaner knowledge base construction. Structured knowledge bases are vital in Natural Language Processing. Projects like CYC, DBpedia, Yago, Freebase, and Wikidata aim to construct these bases. Shared-tasks like KBP and CoNLL focus on knowledge base structuring techniques. Issues in these projects need to be addressed. CYC ontology is a significant common sense knowledge base. The CYC ontology and DBpedia projects aim to construct structured knowledge bases, but face challenges such as high costs, accuracy issues, and inconsistencies. While CYC used human labor to create knowledge, DBpedia was created by non-experts, leading to inaccuracies like instances being incorrectly categorized. DBpedia contains many inconsistencies in its category hierarchy and attributes organization. YAGO and Freebase are other projects aiming to create structured knowledge bases, with YAGO using attributes from infoboxes and Freebase relying on crowdsourcing. However, Freebase lacks organization and coherence due to unorganized crowds, leading to its integration into Wikidata, which aims to be a structured knowledge base based on crowdsourcing. Wikidata, like Wikipedia and Freebase, suffers from inconsistencies and lack of coherence in its structured knowledge base. This is evident in the biased properties, ambiguous entities, and category inconsistencies present. The integration of Freebase into Wikidata aims to address these issues and establish a well-designed ontology. The KBP project, organized by NIST, aims to construct a structured knowledge base from non-structured documents. It includes tasks like Entity Discovery and Linking (EDL) and Slot Filling for extracting attribute information. KBP focuses on limited entity types like Person, Location, and Organization. In contrast, FIGER project identifies 112 types of named entity classes but lacks attribute definitions for each category. The importance of a top-down designed ontology for named entities is highlighted in the context of existing knowledge bases like DBpedia, Freebase, and Wikidata, which suffer from inconsistent entries and imbalanced ontologies due to their bottom-up creation. To address this, the \"Extended Named Entity (ENE) hierarchy\" was employed in the project, featuring 200 fine-grained entity categories in a 4-layer hierarchy with attribute definitions for each category. The Extended Named Entity (ENE) hierarchy features 200 fine-grained entity categories in a 4-layer hierarchy with attribute definitions for each category, including new named entity types such as \"products\", \"event\", and \"position\". Attributes for categories like \"airport\" include details like \"IATA code\", \"ICAO code\", and \"number of users per year\". Refer to the complete definition for more information. The shared-task of attribute-value extraction on Wikipedia entities involves assigning categories to entities, annotating 782,406 entities of Japanese Wikipedia, excluding less popular entities and non-entity pages, and conducting machine learning followed by human checking. The shared-task involves evaluating data categorization accuracy, with 98.5% accuracy observed. The task is to extract attribute-values from Wikipedia entities, focusing on 5 categories: \"person\", \"city\", \"company\", \"airport\", and \"chemical compound\". The task involves extracting attribute-values from Wikipedia entities in 5 categories: \"person\", \"city\", \"company\", \"airport\", and \"chemical compound\". \"Airport\" was chosen for its well-structured infobox, while \"chemical compound\" lacks important information like \"usage\" and \"production method\". 600 training data for each category were provided in JSON format, with participants extracting attribute-values from Wikipedia pages. The evaluation involves extracting attribute-values from Wikipedia pages of entities in different categories without notifying participants of the specific entities used for evaluation. Results are reported by precision, recall, and F1 scores. Systems submitted before the deadline are formal results, while those submitted after are reference results. In ensemble learning experiments, all results are used to achieve the best outcome. The data preparation process involved using three types of annotators: experts in linguistic data construction, supervised students, and crowdsourcing workers (Lancers). The cost and accuracy of annotation varied among the annotator types, with crowdsourcing showing high coverage. The crowdsourcing strategy for data annotation involved three stages: identifying sections with attribute-values, extracting values, and verifying the accuracy of the extracted values. This careful approach led to high coverage. Both experts and crowdsourced workers were used for annotation. The data annotation process involved experts and crowdsourcing, with high inter-annotator agreements. Participants had five months to develop systems for SHINRA2018, with 16 systems submitted. The participants developed a hand-made pattern for attribute-value extraction using \"DL\" (Deep Learning) and adapted the open source QA system \"DrQA\" for the SHINRA2018 shared-task. They transformed infobox information into sentences and questions to extract attribute-values. Results showed Unisys's DrQA system performed best in three categories. The method handled all attributes in a single system, regardless of infobox or explanation. The method handles all attributes in a single system, benefiting from larger training data. TUT's pattern system excelled in the airport category with one infobox template. \"Resource by Collaborative Contribution (RbCC)\" aims for a more accurate KB than a single system. Ensemble learning was tested on all system outputs to evaluate RbCC's potential. Ensemble learning methods like Bagging, Boosting, and stacking have been studied in the past to combine multiple ML systems for higher accuracy. In this experiment, the stacking method was found to be most suitable for combining system outputs. However, simpler methods like simple voting and weighted voting were initially tested. The experiment compared the simple voting method with the weighted ensemble method for combining system outputs. The simple voting method assigns a score based on the number of systems outputting a value, while the weighted ensemble method assigns scores based on system accuracy. Threshold determination and cross-validation were consistent between the two methods. The experiment compared the simple voting method with the weighted ensemble method for combining system outputs. The baseline method combines the best system outputs for each category, showing improvements in precision, recall, and F1 score. The ensemble methods outperform the baseline, with the weighted voting method showing the highest improvement in F1 score. The SHINRA2019 project plans to continue the success of the SHINRA2018 project by conducting a multi-lingual categorization task in 9 languages with the largest number of active users. The first task is to categorize entities in these languages as they have more users than Japanese Wikipedia. The SHINRA2019 project aims to categorize entities in 9 languages using existing data from Japanese entities. There are links between equivalent Wikipedia entities in different languages, providing a large training data set for categorization tasks. At SHINRA2019, participants have a lot of information for the categorization task. JP-5 task involves extracting attribute-values for 5 categories. In SHINRA2018, values were prepared without contexts, making it difficult to extract the exact context. However, in SHINRA2019, attribute values will be annotated in the text to extract the exact context for the value. The training data size will be expanded from 600 to 1500 for categories \"person\", \"company\", and \"city\" using the ensemble system. The project will follow a bootstrapping scheme year by year. JP-30 task aims to extract attribute-values for 30 new categories. Despite the small training data size of 100, testing will focus on 7 subcategories of Geographical Political Entities (GPE), 8 subcategories of terrain, and organizational entities. The similar types and attributes may exist despite the smaller training data. The project aims to expand training data size using ensemble learning techniques. A scheme of knowledge base creation called \"Resource by Collaborative Contribution\" was proposed. The Japanese Wikipedia structuring project, SHINRA2018, showed promising results with 8 participating groups. The RbCC scheme led to significant improvement in extracting attribute-values from Japanese Wikipedia pages. The SHINRA2018 project showed significant improvement in extracting attribute-values from Japanese Wikipedia pages. A big improvement was achieved in the \"airport\" category, and an average of 8 F-score improvement was seen using weighted voting methods. SHINRA2019 will focus on multi-lingual categorization, attribute-value extraction in 5 categories, and attribute-values in 30 new Japanese categories. The project aims to expand the idea of RbCC scheme beyond its current tasks and resources."
}