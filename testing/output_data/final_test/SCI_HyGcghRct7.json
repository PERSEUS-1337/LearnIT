{
    "title": "HyGcghRct7",
    "content": "We propose a new learning-based approach to solve ill-posed inverse problems in imaging, particularly in cases where ground truth training samples are rare and the problem is severely ill-posed. This approach involves learning an ensemble of simpler mappings from data to projections of the unknown image, followed by combining the projections to form a final reconstruction. The method is shown to be more robust to measurement noise and corruptions not seen during training compared to directly learned inverses. A linear system y = Ax + \u03b7 models various imaging inverse problems, where y is the measured data, A is the forward operator, x is the object being probed, and \u03b7 is the noise. The inverse problem is often ill-posed due to poor conditioning of A or M < N. Traditional methods minimize an objective functional regularized with a norm (e.g. total variation) to promote properties like sparsity or smoothness in reconstructions. This paper focuses on situations with very sparse measurement data. In this paper, the focus is on situations with very sparse measurement data, where traditional regularization schemes struggle to reconstruct the unknown model. Deep neural networks, such as generative models, have shown promise in addressing these challenges, particularly in geophysical applications where ground truth models for training are scarce. In situations with sparse measurement data, traditional regularization schemes struggle to reconstruct the unknown model. Deep neural networks, like generative models, show promise in addressing these challenges, especially in geophysical applications with limited ground truth models for training.GANs require many ground truth models for training and cannot be applied to problems with few available models. Methods less sensitive to the training dataset are needed for such cases. In moderately ill-posed problems, conventional methods and total variation approaches provide correct structural information. However, in severely ill-posed problems with insufficient ground truth data, neither classical techniques nor neural networks can recover salient geometric features. In this paper, a two-stage method is proposed to solve ill-posed inverse problems using random low-dimensional projections and convolutional neural networks. The method decomposes the problem into simpler learning problems and combines estimates from different subspaces to convert the original problem into a deconvolution task with localized measurements. The method proposed in this paper decomposes ill-posed inverse problems into simpler learning problems using random low-dimensional projections and convolutional neural networks. By combining estimates from different subspaces, the original problem is transformed into a deconvolution task with localized measurements, improving reconstruction quality and robustness to errors. This technique is particularly useful in domains with limited ground truth images. Machine learning papers on biomedical imaging are growing rapidly, with a focus on reconstruction from subsampled or low-quality data. Beyond biomedical imaging, machine learning techniques are also being applied in geophysical imaging, albeit at a slower pace due to the lack of standard open datasets. Existing methods include non-iterative approaches that learn a feed-forward mapping from measured data to the model. The text discusses the use of neural networks in reconstructing images from lower dimension subspace projections. Different methods are compared, with some focusing on speed and others on data consistency enforcement. Additionally, a generative model approach is mentioned in the context of compressed sensing. The text discusses a method for training generative networks with few ground-truth samples and addresses dataset bias. It connects to sketching and learning via random features, proposing a two-stage approach for solving inverse problems. The method proposed focuses on solving linear finite-dimensional inverse problems by using projection estimates. It aims to reconstruct large N-pixel images from a discrete image x, assuming an injective map from x to y and the existence of an L-Lipschitz inverse G. The method reconstructs large N-pixel images from a discrete image x using projection estimates, assuming an injective map from x to y and an L-Lipschitz inverse G. X is assumed to be a low-dimensional manifold embedded in R^N of dimension at most M, with the existence of a large L due to ill-posedness. The map from data y to a projection of model x into a K-dimensional subspace S is non-linear, with the expected Lipschitz constant evaluated for the map from y to the projection. Random projections reduce the Lipschitz constant by a factor of K/N on average, making learning tasks easier with exponentially fewer samples. Using piecewise-constant subspaces can lead to exponential improvements in Lipschitz stability, especially in inverse problems like inverse scattering. Using piecewise-constant subspaces over random Delaunay triangle meshes can lead to exponential improvements in Lipschitz stability. Sampling sets of points from a uniform-density Poisson process to construct Delaunay triangulations, we create subspaces of piecewise-constant functions. Instead of learning the \"hard\" inverse mapping, an ensemble of simpler mappings is proposed, each approximated by a convolutional neural network. We approximate G \u03bb using a convolutional neural network parameterized by trained weights. Reconstruction starts with non-negative least squares computed from measured data y. The weights are chosen by minimizing empirical risk over training models and non-negative least squares measurements. Projections onto random subspaces transform the problem into estimating DISPLAYFORM0. Projection matrix construction involves consistent mapping of columns of B \u03bb. The matrix is represented as P S = W W \u2020, where W is a matrix with Gaussian entries. The mapping q \u03bb estimates expansion coefficients of x in the basis for subspace S \u03bb. The reformulated problem for estimating x is given by DISPLAYFORM1 with TV-seminorm x TV as regularization. Experimental results show that for large K\u039b, the regularization \u03d5(x) is not necessary. Using x TV regularizer directly fails to recover the model structure. The large Lipschitz constant of the true inverse map G suggests that as the number of mesh subspaces \u039b increases, their direct sum grows large. As the number of mesh subspaces \u039b grows large, the Lipschitz properties of G deteriorate. The unregularized inverse mapping in y \u2192 x is denoted by G. The estimate involves \u03c3 min (B) and L K, reflecting that individual projections are easier to learn but full-resolution reconstruction remains ill-posed. Estimates of individual subspace projections provide correct local information, converting non-local measurements into local ones accurately. In a numerical experiment with a reformulated problem, a random block matrix B is used for reconstruction. Results show increasing localization around non-zero pixels as the number of triangles per subspace and subspaces per reconstruction increase. This phenomenon can be modeled by convolution. The phenomenon of increasing localization around non-zero pixels in a numerical experiment can be modeled by convolution. A kernel \u03ba(u) exists such that E x = x * \u03ba, where \u03ba(u) is isotropic. Stacking more meshes with a smaller number of triangles, rather than more triangles, leads to more robust estimation of local averages and recovery of geometric structure. The method's benefits are demonstrated in linearized traveltime tomography, applicable to any inverse problem with scarce data. In traveltime tomography, the task is to reconstruct a spatial slowness map from wave travel times measured between sensors. The problem data is modeled as integral along line segments in a continuous slowness map. Experiments use a 128x128 pixel grid with 25 sensors and corrupt measurements with Gaussian noise. Random Delaunay meshes with 50 triangles are generated, and projector matrices compute average intensity over triangles for a piecewise constant approximation. The text discusses two architectures, ProjNet and SubNet, for estimating projections in different subspaces. ProjNet is inspired by FBPConvNet and U-Net, with the network output constrained to a projector. Projection estimates from multiple ProjNets are combined using regularized linear least-squares to reconstruct the model. However, a drawback is the need to train a separate ProjNet for each subspace, leading to the motivation for the SubNet architecture. The SubNet architecture is designed to handle multiple subspaces, allowing for visually smoother reconstructions without additional regularization. However, this may result in slightly less precise projections and potentially degraded performance. The signal-to-noise ratio (SNR) is used as a quantitative measure, with ProjNets trained on 130 different meshes and SubNet trained on 350 meshes at various noise levels for comparison. The SubNet is trained with 350 meshes and compared with a U-net baseline network. The baseline network has the same architecture as SubNet but uses non-negative least squares reconstructions as input. This architecture is used as a baseline in recent learning-based inverse problem works and inspires other architectures. The best performing baseline network is selected from multiple networks with a comparable number of trainable parameters to SubNet. The method is tested on a different dataset to simulate lack of training data and demonstrate robustness. Our method demonstrates robustness against data corruption by training on different input noise levels and achieving better SNRs compared to the baseline. Direct reconstruction is unstable when trained on clean data and tested on noisy measurements, often producing artifacts. This is crucial for applications in geophysics. Our method accurately captures cavity shapes in geophysics applications, unlike direct inversion which can produce incorrect geometries. The direct method fails to recover coarse geometry in x-ray images with Gaussian noise, while our approach consistently captures geometric features. Training with various datasets yields comparable reconstructions, showcasing the robustness of our method. Our method improves geometry estimates in imaging by decomposing unstable mappings into stable ones, using piecewise-constant Delaunay subspaces. This approach is more robust against noise compared to direct learning of the inverse map. Our method improves geometry estimates in imaging by decomposing unstable mappings into stable ones using piecewise-constant Delaunay subspaces. It is more robust against noise and corruptions compared to directly learning the inverse map. Regularizing via projections allows our method to generalize across training datasets and produce better reconstructions quantitatively and qualitatively. Future work includes estimating Lipschitz constants, studying extensions to non-linear problems, and developing concentration bounds for the equivalent convolution kernel. This work is supported by the National Science Foundation and NVIDIA Corporation. The research conducted in Urbana-Champaign, supported by NVIDIA Corporation, focuses on the need for non-linear operators in estimating projections using neural networks. The study discusses the use of linear operators and idempotent operators in projecting x onto a known subspace. The least squares minimizer for the linear operator F is determined to be B \u03bb (AB \u03bb ) \u2020. The linear operator F's least squares minimizer is B \u03bb (AB \u03bb ) \u2020, but due to R(F) = S \u03bb = R(A *), the projection F A is oblique, not orthogonal. The oblique projection's nullspace is N(A) = R(A * ) \u22a5, resulting in far-from-orthogonal projections when subspaces are randomly chosen. The linear operator F's least squares minimizer is B \u03bb (AB \u03bb ) \u2020, but due to R(F) = S \u03bb = R(A *), the projection F A is oblique, not orthogonal. To obtain orthogonal projections onto random subspaces, non-linear operators must be used. Linear reconstruction operators result in projections that live in the column space of W A, while a non-linear map is guaranteed by construction when A is injective on X. Numerical experiments in Figures 9 and 10 demonstrate the performance difference between linear oblique projectors and non-linear learned operators for image projection into random subspaces. The linear approach for image projection into random subspaces involves obtaining coefficients using the linear oblique projection method, followed by non-linear reconstruction. Total-variation regularization is used for 130 subspace reconstruction, with optimization of hyperparameters for the highest SNR. The final image reconstruction is done similarly to ProjNet and SubNet methods. The network architecture for ProjNet and SubNet involves downsampling and upsampling layers with skip connections. Each ProjNet output is constrained to a single subspace using a subspace projection operator. SubNet is a single network trained for reconstruction. SubNet is a single network trained over multiple subspaces, with each SubNet trained to give projection estimates over 350 random subspaces. This approach allows for scaling to any number of subspaces without the need to train new networks for each. The use of projection estimates in SubNet results in higher SNR and better estimates of coarse geometry compared to direct inversion. All networks are trained using the Adam optimizer. In SubNet, the network is trained to reconstruct a projection into one subspace by concatenating the subspace basis to the non-negative least squares reconstruction. The method consistently provides better SNR and captures features that the direct reconstruction misses, which is crucial in geophysical imaging. Additionally, reconstructions on actual geophysics images from the BP2004 dataset show the effectiveness of the approach. The shapes dataset used random ellipses, circle, and rectangle patches for training. In Section 4, multiple ProjNets are trained on different low-dimensional subspaces. An ensemble of direct networks is also trained and evaluated for robustness. The proposed method shows more robustness in test scenarios, especially with erasures. In FIG4, the erasure model with p = 1/8 is considered, where most direct network reconstructions fail to capture the original image structure. In TAB8, reconstructions from erasure corruption mechanism are summarized with SNRs. Direct networks perform well with same noise levels but our method is more robust to changes. Original FIG4 shows reconstructions from direct inversion networks with 10dB noise under erasure corruptions model, where most fail to capture key structure."
}