{
    "title": "HyeSin4FPB",
    "content": "Predicting outcomes and planning interactions with the physical world using machine learning has been a long-standing goal. A novel hierarchical predictor-corrector scheme enables neural networks to understand and control complex nonlinear physical systems over long time frames. This approach involves splitting the problem into planning optimal trajectories and inferring control parameters, both trained end-to-end using a differentiable PDE solver. Our method enables artificial intelligent agents to control physical systems described by PDEs like the Navier-Stokes equations. It aims to optimize control through differentiable solvers and the adjoint method, moving away from iterative optimization methods. The text discusses the challenges of optimizing high-dimensional systems using differentiable solvers and the adjoint method. Direct optimization through gradient descent is resource-intensive, leading to the need for more advanced methods like multiple shooting and collocation. However, these methods still require computationally intensive iterative optimization at test time. The use of data-driven models, such as deep learning, is motivated by the need for faster decision-making in specialized environments with limited reaction times. The text presents a novel deep learning approach for representing solution manifolds in physical environments, significantly faster than iterative optimization techniques. It utilizes a hierarchical predictor-corrector scheme to control complex high-dimensional systems by combining models specialized to different time scales. The models are trained using a differentiable PDE solver to provide feedback on interactions, enabling them to avoid local minima. The method presented utilizes a hierarchical predictor-corrector scheme to control high-dimensional systems governed by advection-diffusion PDEs. It outperforms classic optimization techniques by avoiding local minima and provides stable control for longer time spans. Previous works have also explored improving PDE solutions and using PDE formulations for optimization. Deep learning techniques such as graph neural networks, continuous convolutions, and data-driven turbulence models have been used in various applications. Fully-convolutional networks were trained for pressure inference, and temporal updates in reduced spaces were learned via the Koopman operator. Deep networks have also been applied to predict chemical properties and the outcome of chemical reactions. Differentiable solvers have shown utility in different settings, including developing differentiable simulators for rigid body mechanics and manipulation planning. Specialized solvers have been developed for various applications such as inferring protein structures, interacting with liquids, controlling soft robots, and solving inverse problems involving cloth. These works leverage automatic differentiation in deep learning pipelines. While previous works focus on Lagrangian solvers, this work addresses grid-based solvers suitable for dense, volumetric phenomena. The adjoint method is commonly used in these applications. The curr_chunk discusses the use of reverse mode differentiation in machine learning frameworks and introduces a differentiable PDE solver called \u03a6 Flow that integrates with TensorFlow and PyTorch. It presents a physical system described by a PDE and introduces an agent that can interact with the system by controlling certain parameters. The agent introduced can interact with the system by controlling parameters, modeled as a function computing F(t). Deep networks are employed for agents targeting solution manifolds of F(t) with imperfect information modeled by defining the observable state of u as o(u). The control task involves reconstructing a trajectory u(t) that matches initial and target observable states while minimizing force applied within the simulation domain. If direct control of an observable dimension is not possible, an approximation of the target state is settled for. The objective function combines the observation loss with a regular solver that moves the system forward in time via Euler steps. This method is not well-suited for optimization problems due to the computational expense of computing a full trajectory for each optimizable parameter. Differentiable solvers efficiently compute derivatives with respect to inputs, enabling gradient-based optimization of control parameters over multiple time steps. Various techniques, such as single shooting, iteratively adjust initial guesses for optimal trajectories by simulating dynamics and backpropagating losses. Replacing F (t) with an agent F (t|o t , o * ), parameterized by a deep network, enables simple training. A chain of control force estimators (CFEs) is optimized, involving linked copies of the agent for each frame in a sequence. Gradients pass through nonlinear simulation steps, which can be computationally expensive. When the reconstruction u closely matches the optimal trajectory, gradients are small and backpropagation is safe. However, for large \u2206u, the approximation breaks down, especially at the start of optimization. Alternatives to single shooting in optimization include multiple shooting, collocation schemes, and model reduction to improve convergence and efficiency. Multiple shooting splits the trajectory into segments with defect constraints, while collocation schemes model trajectories with splines. Model reduction can reduce dimensionality or nonlinearity of the problem. In this work, single shooting and its variants are used as baseline comparisons for trajectory optimization. Differentiable physics loss functions are highlighted as superior to supervised losses for better optimization results. The combination of supervised and differentiable physics losses is employed in training machine learning models. Differentiable physics losses are preferred over supervised losses due to their ability to optimize for the desired objective directly, unlike supervised losses which can only measure error at a single time step and lead to suboptimal predictions. This is especially beneficial for optimal control problems with multiple possible outputs for one input. Differentiable physics losses allow for direct optimization of the desired objective, requiring a differentiable solver to backpropagate gradients through the simulation. This approach enables chaining multiple time steps together, providing feedback on decision-making and handling of states without the need for ground truth, leading to natural convergence towards a solution for multi-modal problems. To interact optimally with a physical system, an agent needs to build an internal representation of an optimal observable trajectory and learn the actions to move the system along that trajectory. This process is similar to the predictor-corrector method, where predictions are made and corrections are applied to refine the trajectory. Splitting the agent into two neural networks, an observation predictor (OP) network and a corrector network (CFE), helps in planning out a trajectory and estimating control forces to follow it closely. The prediction stage incorporates knowledge about longer time spans by modeling it as a temporally hierarchical process, recursively dividing the problem into smaller subproblems. The OP predicts the optimal center point between two states at different times, enabling scaling to arbitrary time frames or resolutions. The OP enables scaling to arbitrary time frames by training unique models for each time scale, simplifying training and not significantly increasing model complexity. By using factors of two for time scales, the number of required models scales with O(log 2 n). With the CFE and OP as building blocks, algorithms for solving the control problem can be assembled and trained. The algorithm for prediction refinement, based on using the finest scale OP for predictions and refining them after the solver computes the next state, is detailed in Appendix B. Starting with a simple combination of CFE and OP invocations, predictions are made at various time points before evaluating the actual trajectory step by step. The algorithm evaluates the trajectory step by step, computing control forces and predictions. It can result in oscillations and jittering due to physical constraints and approximation errors. Changing the execution order can alleviate these issues. The staggered execution scheme in the algorithm allows for future predictions to consider deviations from the predicted trajectory, preventing divergence. This scheme corrects most predictions but leaves some unmodified, such as the prediction at t n/2. The prediction refinement scheme, outlined in Algorithm 1, addresses the issue of blurred predictions by re-evaluating existing predictions as the simulation progresses in time. This algorithm optimally updates predictions at finer time scales based on a sequence of other predictions, preventing divergence and ensuring accurate reconstruction. The prediction refinement algorithm optimally updates predictions at finer time scales based on a sequence of other predictions, continually refining the center prediction until the reconstruction reaches the final frame. The prediction refinement algorithm updates predictions at finer time scales based on a sequence of other predictions, improving the quality of the learned control function. It incurs a small computational overhead but offers significant gains in accuracy. The method is evaluated on controlling physical PDEs in various test environments of increasing complexity. The study quantifies accuracy in two-dimensional problems involving incompressible fluid and complex boundaries with indirect control. Burger's equation, a nonlinear PDE describing the time evolution of a single field, is analyzed. Results of an ablation study comparing forces applied by differently trained models are presented in Table 1. The CFE chain variant uses a neural network to infer force without intermediate predictions. Training with the objective loss greatly improves reconstructions by correcting temporal evolution. Implementing CFE hierarchically predicts intermediate states, producing stable trajectories that converge to the target state. The supervised method produces stable trajectories that converge to the target state with high accuracy, despite not using physics-based gradients. Differentiable physics loss significantly improves reconstruction quality, making solutions closely resemble ideal trajectories. Prediction refinement scheme further enhances accuracy, with small differences compared to staggered execution. Classic shooting-based optimization requires around 60 steps to match staggered execution quality, despite faster convergence. Starting with a fast convergence, the classic optimization reaches an optimal value of 10.2 after 300 iterations. Our method as an initial guess pushes the optimum slightly lower to 10.1, showcasing the advantages of our approach. Applying our algorithm to two-dimensional fluid dynamics problems, we deal with the complexities of the Navier-Stokes equations. We consider a velocity field subject to hard constraints and a passive density moving with the fluid. Testing on a 128x2 grid with over 16,000 control parameters, we train the OP. Our method, trained on a 128x2 grid with over 16,000 control parameters, is compared to classic shooting algorithms for incompressible flow problems. While all methods approximate the target state well, there are differences in force applied, with supervised technique exerting more force. Prediction refinement scheme produces smooth transitions with half the loss compared to non-refined variants. The comparison of methods for incompressible flow problems shows that our model achieves accuracy almost instantly, while other approaches require 1500 iterations. The experiment introduces obstacles to the fluid control problem, limiting the controlled area. The goal is to move smoke into specific areas using control forces. The experiment introduces obstacles to the fluid control problem, limiting the controlled area. Control forces can only be applied in the peripheral regions, with 5000 continuous control parameters needed to construct a directed velocity field in the central region. Trajectories are inferred using a trained CFE network to move smoke into desired buckets. Hierarchical predictions and trained OPs manage to maneuver 99.22% \u00b1 0.15% of the smoke into desired buckets with 19.1% \u00b1 1.0% less force. Comparatively, direct optimization has a lower success rate of 82% and takes significantly longer to evaluate than the trained model. The deep learning model, in conjunction with a differentiable physics solver, successfully predicts and controls complex physical systems. The hierarchical predictor-corrector architecture allows the model to reconstruct long sequences by treating physical behavior on different time scales separately. Using a differentiable solver greatly benefits solution quality as networks can quickly infer solutions. In experiments, hierarchical inference schemes outperform traditional agents by learning to plan ahead. Observations are added to restrict information available to the learning agent. Learning approaches won't replace iterative optimization, but can learn solution manifolds for optimal control trajectories. Fast inference is crucial for time-critical applications and can enhance classical solvers for better solutions. Our solver, supported by the ERC Starting Grant realFlow, is publicly available on GitHub and implemented using machine learning frameworks like TensorFlow and PyTorch. It benefits from automatic differentiation and tight integration with neural networks. The implementation of building blocks for solving PDEs is outlined, including the use of staggered grids in experiments. In Section 6, staggered grids are used for tracking velocities in experiments involving PDEs. The marker-and-cell method is adopted, with densities stored in a regular grid and velocities in a staggered grid. Staggered grids sample vector fields in a staggered form, reducing discretization errors but complicating operations that combine vector fields with regular fields. Buoyancy operations apply an upward force proportional to smoke density by interpolating the density to the staggered grid. Transport operations are also conducted using staggered grids for velocities. The smoke density is interpolated to the staggered grid for buoyancy operations. Differential operators for vector fields on staggered grids are implemented in TensorFlow. These operators include gradient, divergence, curl, and Laplace in various dimensions. All differential operators are local operations acting on a small neighborhood of grid points. In machine learning, differential operators can be implemented as convolution operations with fixed kernels, but this method scales poorly with system dimensionality. To address this, n-dimensional operators are expressed using tensor operations. For example, in 1D gradient computation, a staggered grid can be achieved through a 1D convolution or vector subtraction operation. In low-dimensional settings, the convolution operation is faster. In higher dimensions, the vector-based convolution is faster and more practical, avoiding unnecessary computations. Advection in PDEs involves moving values in a field using a vector field, implemented with a semi-Lagrangian step. The origin location is determined by following the vector backwards in time and linearly interpolating between neighboring grid cells. Gradients can be provided by the framework for solving Poisson problems in incompressible fluids governed by the Navier-Stokes equations. The numerical solver finds a pressure value that satisfies the constraints \u2207 \u00b7 v = 0 and \u2207 \u00d7 p = 0, known as Chorin Projection or Helmholtz decomposition. Solving for pressure is equivalent to solving a Poisson problem with a sparse matrix A. The Navier-Stokes equations are solved by computing the advection and diffusion of density and velocity, applying viscosity and buoyancy forces, and enforcing incompressibility through pressure solving. The staggered execution scheme recursively splits sequences to advance the simulation in time. The prediction refinement scheme involves performing more predictions by cutting Sol in half and doubling the number of evaluations. The total number of predictions depends on the sequence length and time steps. The recursive algorithm Reconstruct[u0, on, o2n] is used to reconstruct sequences, with each invocation resulting in one or three evaluations. Neural networks in this work are based on a modified U-net architecture. The modified U-net architecture used in this work includes residual blocks instead of regular convolutions for each level. The network for predicting observations for the fluid example consists of two feature maps for the current state and target state, followed by five residual blocks decreasing resolution and increasing feature maps. Each block performs convolutions with specific kernel sizes and strides. The modified U-net architecture includes residual blocks instead of regular convolutions for each level. The decoder part of the network translates features into spatial content by upsampling feature maps and concatenating them with the output of the previous block. The network produces one feature map at the original resolution. Depending on the problem dimensionality, 1D or 2D convolutions are used. The network for the indirect control task produces two output feature maps. The modified U-net architecture includes residual blocks instead of regular convolutions for each level. It produces two output feature maps representing velocity (v x , v y ). Four feature maps of the lowest resolution are fed into a dense layer, concatenated with other feature maps before upsampling. Networks were implemented in TensorFlow and trained using the ADAM optimizer on an Nvidia GTX 1080 Ti with batch sizes ranging from 4 to 16. Supervised training converges within a few minutes with a decreased learning rate. Training with the differentiable solver starts with a learning rate of 10^-4. For the fluid examples, optimization steps are time-consuming, taking 1-2 seconds for 2D fluid problems. The experiment simulates Burger's equation on a 1D grid with 32 samples over 32 time steps, showcasing shock wave behavior. The networks run for about 100,000 iterations over one to two days. When opposing waves clash, they weaken until only the stronger wave survives. All 32 samples are observable and controllable, ensuring trajectories reach the target state. The quality of a solution is measured by the applied force over time. Network training involves using the same architecture for CFE chains and observation prediction models, trained on randomly generated scenes with constant driving forces. In each time step, a constant Gaussian force with randomized parameters is applied to steer the system away from its natural evolution. Constant forces have a larger impact than temporally varying forces, which can cancel out over time. The ground truth sequence is a near-perfect but not necessarily optimal trajectory. Networks are pretrained with a supervised observation loss, and trajectories are shown in Figures 4 and 8. OP networks are trained end-to-end with an objective loss function after pretraining. For this experiment, networks are trained end-to-end with a mean squared difference observation loss function. Results show that the hierarchical models outperform the CFE chains in inferring control forces, with the supervised version deviating from an optimal trajectory. Learning to anticipate physical behavior over time is challenging for the model. The hierarchical models require less force and learn to converge towards the target state efficiently. The methods using the differentiable solver outperform supervised counterparts by finding more efficient trajectories with less force. Using a differentiable solver, models can learn to apply forces more efficiently to reach the target state with up to 13% less force than the ground truth. This is achieved by initially applying more force at a specific point and then correcting any overshoot by applying a negative force later on. Our method allows models to reach the target state with up to 13% less force than the ground truth. The formulation of the loss suppresses force spikes, making large forces exponentially rare. Comparisons to a single-shooting baseline show near-optimal solutions with higher computation times. Classic optimization uses the ADAM optimizer with a learning rate of 0.01 and converges after around 300 iterations. The quick convergence of the staggered prediction scheme, requiring only around 60 iterations, can be attributed to the simple setup dominated by linear effects. Computation times were recorded on a single GTX 1080 Ti, with 100 examples run in parallel to reduce GPU instruction queuing overhead. The incompressible Navier-Stokes equations model fluid dynamics, including turbulent behavior, a challenging and unsolved problem in classical physics that demands significant computational effort. The Navier-Stokes equations for incompressible two-dimensional gas with viscosity are computationally intensive. The gas velocity is controlled with hard constraints, and low viscosities like air are targeted. For fluids with higher viscosity, a Poisson solver can be used to solve a diffusion equation. In order to create a challenging environment for training networks, a minimal amount of diffusion is used in the physical model. The system involves a velocity field v and a smoke density distribution \u03c1, with the evolution of \u03c1 described by an equation. The velocity field is hidden from observation, and the CFE network outputs a vector potential \u03a6 using stream functions. The CFE network outputs a vector potential \u03a6 for velocity updates, simplifying the incompressibility condition of the Navier-Stokes equations. Training datasets for flow reconstruction and shape transition tasks have over 16,000 control parameters. The flow reconstruction dataset consists of ground-truth sequences simulated for 64 time steps, with resulting smoke density as the target state. To handle open domain boundaries in simulations, the smoke that leaves the domain is removed by running the simulation backwards in time. Initial and target states for shape transitions are randomly selected from a library of geometric shapes. A sequence length of 16 is chosen for shape transition results, as it captures all relevant behavior. Linear interpolation in the advection step causes density and velocity to spread out. The linear interpolation in the advection step causes density and velocity to spread out over time, making it difficult to match target states precisely. Pretraining the CFE on a natural flow dataset with supervised loss improves accuracy, while using a differentiable solver with an observation loss further enhances the inferred force accuracy without compromising the ground truth match. The blur function with varying radius helps smooth gradients and create non-zero gradients where prediction and target do not overlap. Training involves decreasing the radius gradually and adjusting the loss function to ensure accuracy. Different models are trained for natural flow reconstruction and shape transition, all based on the same CFE model. OPs are pre-trained independently before joint training with objective loss and a differentiable solver to find the optimal trajectory. The importance of combining supervised and unsupervised training for challenging learning objectives is illustrated in this example. The supervised predictions are blurry due to averaging over all ground truth sequences, while the differentiable physics solver largely resolves this issue. Comparisons of different losses are shown in Fig. 10, highlighting the differences between the three methods. The differentiable physics solver improves predictions by resolving issues with long-term deviations. Training data allows networks to transform shapes at random locations, enabling accurate inference of control force sequences. Target shapes are closely matched, and the refined predictions are conditioned on previous states. More details can be found in the supplemental material. The curr_chunk discusses generalizing the method to multiple shapes evolving within the same domain by splitting the reconstruction task into prediction and correction. This allows for classical processing or filter operations to be applied to the intermediate predictions. The control force is inferred on the joint system for each shape transition, with the resulting force applied individually to each sequence. The smoke density predictions are combined before passing them to the network. The force is applied individually to each sequence to prevent smoke from one transition affecting another target state. Evaluation of force strengths shows that large values are rare due to using a L2 regularizer. Different execution schemes show varying levels of force required, with supervised training resulting in trajectories with reduced continuity and larger forces. In a more complex test environment, the network struggles to directly match the target. The network faces increased complexity in controlling fluid volume due to obstacles and solid boundaries, with over 5000 control parameters per step. The domain has three target regions for smoke transport, requiring indirect control as smoke density is outside the controlled area. The model must consider incompressibility to influence velocity outside the controlled area. The model skips pretraining and directly trains the CFE using a differentiable solver, while the OP networks are trained as before. Evaluation measures how much smoke density ends up inside the buckets and the total force applied. The resulting model puts 89% \u00b1 2.6% of the smoke into the target bucket on average. The model trained with the full algorithm moves 99.22% \u00b1 0.15% of the smoke into the target buckets with 19.1% \u00b1 1.0% less force. Using the ADAM optimizer with a learning rate of 0.1, the gradients quickly guide the smoke flow in the right direction. After optimization, around 82.1 \u00b1 7.3% of the smoke ends up in the correct bucket. When optimizing F (t) with the objective loss L, stream functions are used to ensure incompressibility. The single-shooting algorithm struggles with the Navier-Stokes setup due to noisy gradients, leading to artifacts in reconstructions. The single-shooting optimizer struggles with noisy gradients in the Navier-Stokes setup, leading to undesirable local minima. To address this, a multi-scale shooting method is employed, which iteratively refines the trajectory on a coarsely discretized version of the problem. This approach converges reliably for all examples by using an exponential learning rate decay and the ADAM optimizer for control variable updates. The objective loss is decomposed into observation loss and force loss in Figure 15. Initially, force loss is small due to velocity initialization. Observation loss dominates for the first 1000 iterations, leading to excessive force application. As optimization progresses, the trajectory refines to use less force. Trajectories predicted by the neural network method align with those from the MS optimization, requiring less tuning. The MS optimization took 131 seconds on a GTX 1080 Ti for a 16-frame sequence. The network inference time for a single 16-frame sequence took 0.5 seconds on a GTX 1080 Ti graphics card. The model has successfully learned a large class of physical behaviors and can reach the intended goal with the right amount of force. The complexity of individual solutions is highlighted by the large number of iterations required for optimization. Comparing solutions between the MS algorithm and the network, the former often finds unintuitive solutions with noticeable detours. The network benefits from representing the solution manifold instead of aiming for single task optimizations. It provides a global view and effectively regularizes the inference of new solutions. The shooting optimizations rely on local gradients or manually crafted schemes, while our method supports multi-resolution optimization by initializing with velocities inferred by the networks. The reconstructed trajectory from the neural-network-based method closely approaches the optimum. The reconstructed trajectory from the neural-network-based method closely approaches the optimum without the need for a multi-resolution approach. A visual overview of selected sequences is provided in Fig. 18, showcasing natural flow, shape transitions, and indirect control examples. The supplemental material highlights differences between unsupervised, staggered, and refined versions of the approach."
}