{
    "title": "Hkf2_sC5FX",
    "content": "In lifelong learning, the efficiency of current approaches is investigated in terms of sample complexity, computational and memory cost. A new evaluation protocol is introduced where learners observe each example only once and hyper-parameter selection is done on a small set of tasks. A new metric for measuring how quickly a learner acquires a new skill is proposed. An improved version of GEM, called Averaged GEM (A-GEM), is introduced, which is computationally and memory efficient while maintaining performance. In lifelong learning, A-GEM is shown to have the best trade-off between accuracy and efficiency among various algorithms. It emphasizes the importance of quickly adapting to new skills with minimal training data, moving towards more realistic human learning experiences. In lifelong learning, the learner can acquire new skills quickly with minimal training data by reusing knowledge from past related tasks. The model needs to be constrained in terms of compute and memory to learn from a stream of data efficiently. The current training and evaluation protocols for lifelong learning do not meet the requirements of learning from a stream of data with limited samples, memory, and compute. The popular training paradigm involves multiple passes over the data, but ideally, the model should only need a few samples provided one-by-one in a single pass. Some algorithms work well in a single-pass setting but require a lot of computation or memory that scales with the number of tasks, hindering their deployment. In this work, a new evaluation methodology and algorithm are proposed to efficiently learn from a stream of tasks with limited samples, time, and memory. The proposed learning paradigm involves cross-validation on a separate set of tasks for training and evaluation. Building upon the GEM BID15 algorithm, a variant called A-GEM is introduced, which significantly speeds up training time while maintaining performance in a single-pass setting. In this work, a new learning paradigm called A-GEM is introduced to improve few-shot learning performance by using compositional task descriptors. A new metric to measure learning speed is also introduced. Experiments show that A-GEM has a better trade-off between accuracy and computational cost, and algorithms improve their ability to learn new tasks quickly with compositional task descriptors. The current learning protocol for lifelong learning involves multiple passes over data and hyperparameter tuning on validation sets. A new learning protocol is introduced to emphasize learning quickly from data with only a single pass. The new learning protocol involves two streams of tasks with ordered sequences of datasets. CV is used for cross-validation, D CV for hyper-parameter selection, and D EV for final training and evaluation. Regularization-based approaches for lifelong learning are sensitive to the choice of regularization hyper-parameter. Regularization hyper-parameter sensitivity in learning BID29 is addressed by introducing set D CV for practical tuning. Training and testing occur on D EV with a single pass over the data. Each dataset example includes input, task descriptor, and target vector. The goal is to learn a predictor f \u03b8 : X \u00d7 T \u2192 Y to map test pairs to targets. Evaluation metrics include Average Accuracy (A) and Forgetting Measure (F). The Learning Curve Area (LCA) is a new measure introduced alongside Average Accuracy (A) and Forgetting Measure (F) BID4 to capture how quickly a model learns. It evaluates the model's performance on all tasks after each mini-batch presentation. The Average Accuracy (A) is the average accuracy on all tasks after the last task has been learned. The Average Accuracy (A) is the most commonly used metric in LLL, measuring the accuracy on all tasks after the last task has been learned. Forgetting Measure (F) quantifies the average forgetting after continual training with all mini-batches up to task k. Measuring forgetting after all tasks have been learned is crucial for understanding accuracy drop on past tasks and how quickly a model can learn new tasks. Learning Curve Area (LCA) evaluates the model's performance on all tasks after each mini-batch presentation. The Learning Curve Area (LCA) metric defines the average performance of a model on tasks after training for all T tasks. It measures the speed of learning and discriminates between models that learn quickly from few examples. This metric aims to evaluate the model's performance and learning speed, providing insights into how well the model learns new tasks. In the evaluation protocol for LLL, a new metric measures learning speed. GEM BID15 algorithm is efficient but intensive. A-GEM is a variant to speed up learning. Compositional task descriptors enhance learning in few shot regime. GEM avoids forgetting by storing episodic memory for each task. It allows positive backward transfer, unlike other methods. GEM algorithm addresses forgetting by projecting gradient updates to maintain angle bounds between loss gradient vectors of previous tasks and current task. It solves a quadratic program efficiently in dual space, resulting in a smaller problem with fewer variables. The solution v* to the optimization problem allows for computed projected gradient updates in training. A more efficient version of GEM, called Averaged GEM (A-GEM), is proposed to alleviate the computational burden. While GEM ensures that the loss of each individual previous task does not increase, A-GEM focuses on ensuring that the average episodic memory loss over previous tasks does not increase during training. A more efficient version of GEM, Averaged GEM (A-GEM), aims to reduce computational burden by replacing constraints with a single constraint based on past task gradients computed from episodic memory. This allows for quick optimization solving and is memory efficient compared to GEM. A-GEM is a more efficient version of GEM that reduces computational burden by using past task gradients from episodic memory, resulting in faster optimization solving and improved memory efficiency. In this section, we discuss improving forward transfer for LLL methods like A-GEM by using compositional task descriptors shared across tasks. These descriptors, such as attribute values of objects, help speed up learning of new tasks. In few-shot learning, a joint embedding space is learned between image features and attribute embeddings. The model includes a feature extraction module and a task embedding module. The feature extraction module is a multi-layer feed-forward network, while the task embedding module is a parameter matrix for attribute look-up. In few-shot learning, a joint embedding space is learned between image features and attribute embeddings. The task descriptor embedding is constructed by concatenating class embedding vectors. Parameters are learned through minimizing cross-entropy loss. Different dataset streams are considered, including Permuted MNIST, a variant of the MNIST dataset with random pixel permutations. Split CIFAR BID29, Split CUB, and Split AWA are incremental versions of existing datasets, each consisting of subsets of classes. Split CIFAR involves randomly sampling 5 classes without replacement from CIFAR-100, Split CUB splits 200 bird categories into 20 subsets, and Split AWA constructs tasks by sampling 5 classes with replacement from 50 animal categories. Classes may overlap among tasks, but each task competes against a different set of classes to ensure each training example is only seen once. For Split AWA, classifier weights are randomly initialized within each head without transfer from previous occurrences of classes. Attributes of classes are stacked together to form a descriptor. Different architectures are used for different datasets: fully-connected network for Permuted MNIST, reduced ResNet18 for Split CIFAR, and standard ResNet18 for Split CUB and Split AWA. In a dataset stream, models use the same architecture and are optimized via stochastic gradient descent with mini-batch size of 10. The joint-embedding model version is denoted by '-JE'. Cross-validation is done on the first 3 tasks, followed by reporting metrics on the remaining 17 tasks after a single training pass on each task. A-GEM is compared against various baselines and state-of-the-art LLL approaches. VAN is a single supervised learning model trained continually without regularization. ICARL BID17 is a class-incremental learner that uses nearest-exemplar-based classifier and avoids catastrophic forgetting by regularizing over feature representation of previous tasks using knowledge distillation. In a dataset stream, models are optimized via stochastic gradient descent with mini-batch size of 10. A-GEM is compared against various baselines and state-of-the-art LLL approaches. The amount of episodic memory per task used in ICARL, GEM, and A-GEM varies. The network weights are randomly initialized for different datasets. The network weights are randomly initialized for different datasets. A pre-trained ImageNet model is used for CUB due to its small dataset size. A multi-task baseline, MULTI-TASK, violates the LLL assumption. A-GEM achieves the best average accuracy on all datasets except Permuted MNIST, where PROG-NN performs better due to a large number of training examples. PROG-NN has the worst memory cost by the end. PROG-NN has the worst memory cost due to its large size, running out of memory in large scale setups. A-GEM and GEM perform similarly in accuracy, but A-GEM is much faster and has lower memory cost. EWC and similar methods slightly outperform VAN in a single pass setting, but require over-parameterized architectures to work well. PROG-NN has no forgetting, while A-GEM and GEM have the lowest forgetting among methods with fixed capacity architectures. A-GEM and GEM show low forgetting with fixed capacity architectures. A-GEM performs better in terms of average accuracy and efficiency compared to other methods. Task descriptors improve accuracy, with A-GEM being the top performer. Joint-embedding models with task descriptors enhance LCA performance. A-GEM offers the best trade-off between accuracy and efficiency. Task descriptors speed up learning in few-shot scenarios. Continual or Lifelong Learning (LLL) methods, such as A-GEM, show improved performance in few-shot scenarios and zero-shot learning over time. Joint embedding models with compositional task descriptors offer a clear advantage, with A-GEM performing the best. These models become more efficient with forward transfer, indicating progress in learning efficiency. Methods for Lifelong Learning (LLL) focus on learning from few examples using memory efficient models. Episodic memory-based methods require more memory at training time but can work better in single pass settings. Task descriptors have been advocated for LLL, but previous approaches may not be computationally efficient for deep nets. Task descriptors have also been used in Reinforcement Learning by others. In the study of Lifelong Learning (LLL), the A-GEM approach was found to have the best balance between accuracy and computational/memory cost. Compared to other methods, A-GEM is significantly faster and requires less memory. Using task descriptors can improve few-shot performance, with A-GEM often outperforming other methods. There is still a performance gap between LLL methods. The study highlights a performance gap between LLL methods, such as A-GEM, trained in sequential vs. non-sequential settings. Task descriptors aid few-shot learning, but the transfer of knowledge remains limited. Future research will focus on addressing these issues. The appendix provides dataset summaries, details on the A-GEM algorithm, and comparisons with GEM and S-GEM variations. Detailed experiment results are presented in Figures 1 and 2. In Sec. E, detailed experiment results for Figures 1 and 2 are provided. Sec. F discusses the need for over-parameterized architectures and multiple data passes for regularization-based approaches like EWC to perform well. Sec. G presents the hyperparameter grid used for cross-validation and optimal values for different models. Sec. H describes the joint embedding model. The update rule of A-GEM is also explained. The optimization objective of A-GEM is described in Eq. 10, where g is replaced with z. The dual of the optimization problem is derived and the A-GEM update rule is recovered by putting the solution in the equation. Empirical analysis comparing A-GEM and GEM is also discussed. The frequency of constraint violations is compared between GEM and A-GEM on Permuted MNIST and Split CIFAR datasets. A-GEM shows fewer violations as the number of tasks increases, leading to better computational efficiency. The gap between GEM and A-GEM widens with more tasks, highlighting the higher computational and memory overhead of GEM. In experiments comparing GEM and A-GEM, the memory overhead of GEM increases with more tasks. A-GEM shows better computational efficiency with fewer constraint violations as tasks increase. Additionally, a new variant called Stochastic GEM (S-GEM) randomly samples constraints to avoid loss increase from previous tasks. In experiments comparing GEM and A-GEM, the memory overhead of GEM increases with more tasks. A-GEM shows better computational efficiency with fewer constraint violations as tasks increase. A new variant called Stochastic GEM (S-GEM) randomly samples constraints to avoid loss increase from previous tasks. S-GEM performs slightly worse than GEM, requiring over-parameterized architectures and multiple passes over task samples for optimal performance. Regularization-based approaches suffer in single-pass settings with few training samples as parameters cannot be estimated well. They do not enable positive backward transfer, hurting performance on tasks with limited data. In multi-epoch settings, regularization-based approaches perform better as un-regularized models overfit more to current data. Permuted MNIST and Split CIFAR datasets are used for experiments with two-layer fully-connected architectures. For MNIST and CIFAR datasets, two architecture variants are tested: a two-layer fully-connected network with 256 units per layer (-S suffix) and 2000 units per layer (-B suffix) for MNIST, and ResNet-18 with reduced feature maps (-S suffix) and standard ResNet-18 (-B token) for CIFAR. Experiments are conducted on VAN and EWC with increasing epochs for Permuted MNIST and CIFAR. Results show that average accuracy improves significantly with more epochs only when EWC is applied to the larger network. In experiments with VAN and EWC on Permuted MNIST and CIFAR datasets, EWC performs similarly to VAN on Split CIFAR in a single epoch setting. Hyper-parameters grid considered for experiments are cross-validated using T CV tasks. The joint embedding model discussed in the main paper consists of feed-forward neural networks with specific parameters for each module. The curr_chunk discusses the construction of a shared matrix of dimensions C k \u00d7 A by concatenating class attribute vectors of C k classes."
}