{
    "title": "HklUCCVKDB",
    "content": "Continual learning involves learning new tasks without forgetting previous ones, which is challenging without access to previous data and with a fixed model capacity. Current regularization-based algorithms require extra computation to measure parameter importance. In contrast, Uncertainty-guided Continual Bayesian Neural Networks (UCB) adjust the learning rate based on weight uncertainty, helping to identify what to remember and what to change to prevent catastrophic forgetting. A variant of the model uses uncertainty for weight pruning. Our UCB approach retains task performance after pruning by saving binary masks per tasks, showing superior performance on diverse object classification datasets. Continual learning, also known as lifelong learning, addresses the challenge of catastrophic forgetting in artificial learning systems. Continual learning aims to prevent catastrophic forgetting by identifying and penalizing important parameters from previous tasks, or by freezing them and allowing adaptation of remaining parameters. An alternative approach is to use implicit uncertainty-guided importance representation, which can be achieved through Bayesian approaches to neural networks. Bayesian neural networks use distributions to represent parameters, accounting for uncertainty. Variational inference approximates posterior distributions with Monte Carlo sampling. These networks act like ensembles, reducing prediction variance with minimal parameter increase. The mean and variance of latent distributions characterize parameter importance, enabling continual learning by adjusting learning rates. Bayesian neural networks use distributions to represent parameters, accounting for uncertainty. Variational inference approximates posterior distributions with Monte Carlo sampling. The evolution of weight distributions through learning tasks is illustrated, showing how learning rates are adjusted based on parameter uncertainties. The evolution of weight distributions in Bayesian neural networks shows that uncertain parameters adapt more quickly when learning multiple tasks. Uncertain parameters have larger uncertainties after the first task, allowing them to learn more tasks efficiently. Learning rates are adjusted based on parameter uncertainties to facilitate learning consecutive tasks. The text discusses the concept of uncertain parameters in Bayesian neural networks and how they can adapt quickly when learning multiple tasks. A new method is proposed to adjust learning rates based on parameter uncertainties, with a hard-threshold variant to decide which parameters to freeze. Experimental validation is conducted to compare the approach to prior methods on single datasets split into tasks and learning a sequence of different datasets. The approach discussed does not rely on task boundaries at inference time, supporting a \"single head\" scenario for all tasks. Evaluation metric for this model is termed \"generalized accuracy\". Continual learning approaches are categorized into dynamic architectural, memory-based, and regularization methods. The architecture grows while storing new knowledge in various forms without altering past knowledge. Progressive networks and Dynamically Expandable Network are dynamic architectural methods that expand their network capacity in response to new tasks. In contrast, memory-based methods like Gradient episodic memory store previous information for later use. These approaches aim to prevent the model from deviating from its gradient updates. Regularization methods prevent significant changes to learned representations for previous tasks by enforcing constraints on weight parameters or the objective function. Elastic weight consolidation (EWC) is inspired by Bayesian learning and focuses on preserving important parameters. Recent approaches combine external data, distillation loss, and confidence-based sampling to mitigate forgetting. In Elastic Weight Consolidation (EWC), important parameters are identified based on the Fisher information matrix. Synaptic Intelligence (SI) and Memory-aware Synapses (MAS) also prioritize parameters based on their contribution to the loss function. MAS offers an online method for computing importance adaptive to the test set. PackNet utilizes iterative pruning to restrict gradient updates on important weights. Bayesian approaches in learning neural networks have been studied for decades, with various methods proposed such as Laplace approximation, Hamiltonian Monte Carlo, variational inference, and probabilistic backpropagation. Variational continual learning uses Bayesian techniques to maintain information learned on previous tasks. Variational continual learning uses Bayesian inference to perform continual learning by updating the posterior distribution based on new task data. It can mitigate forgetting by using a core-set of previous task data. In contrast, our approach relies on Bayesian neural networks' predictive uncertainty for continual learning without using episodic memory. Additionally, while a fast natural gradient descent method for variational inference exists, we use classic gradient descent in our work. The text discusses the use of natural gradient descent methods as an alternative to classic gradient descent in Variational Continual Learning (VCL) and Elastic Weight Consolidation (EWC) methods. Tseran et al. (2018) introduce modifications to VCL called Natural-VCL (N-VCL) and VCL-Vadam, utilizing Gaussian natural gradients in the Adam optimizer. These methods aim to improve performance by incorporating a coreset of previous examples and estimating the VCL objective using a Gauss-Newton approximation. The text introduces a method to estimate the VCL objective function using natural gradient descent and Riemannian geometry. VCL-Vadam is a simplified version of N-VCL that uses Vadam to update gradients with Gaussian noise. The method adapts the learning rate within Adam optimizer at every time step. In this section, we review the Bayes-by-Backprop (BBB) framework introduced by Blundell et al. in 2015 for learning a probability distribution over network parameters. Bayesian models involve drawing latent variables from a prior density p(w) related to observations through the likelihood p(x|w). The posterior distribution p(w|x) is inferred using this framework, which acts as a regularizer and shows comparable performance to dropout on the MNIST dataset. Variational inference offers a faster solution than MCMC sampling for approximating the posterior distribution in Bayesian models. It uses optimization techniques to approximate the posterior distribution, making it more scalable for large datasets and models. Inference methods utilize fast optimization techniques like stochastic or distributed methods to explore data models quickly. Variational inference calculates conditional probability distributions over latent variables by finding the closest proxy to the exact posterior through optimization. It assumes a family of probability densities over latent variables parametrized by \u03b8 and aims to find the closest member to the true conditional. The objective is to minimize the Kullback-Leibler divergence between the approximate conditional probability distribution and the true conditional probability distribution by using variational inference with a Gaussian pdf. The variational posterior is sampled using Monte Carlo samples, and the prior is a scale mixture of two Gaussian pdfs with different variances. In this work, a framework using a mixture of two Gaussian pdfs with different variances is proposed for learning sequential tasks without forgetting. The Uncertainty-guided Continual learning approach with Bayesian neural networks (UCB) utilizes per-weight uncertainties to regulate parameter changes. This method aims to reduce forgetting by regularizing changes in the model representation based on parameters' importance. The Uncertainty-guided Continual learning approach with Bayesian neural networks (UCB) uses per-weight uncertainties to regulate parameter changes. Importance of parameters is determined by setting it inversely proportional to the standard deviation \u03c3, representing parameter uncertainty. Learning rate is scaled for each parameter distribution based on its importance to reduce changes in important parameters while allowing less important parameters to alter more for learning new tasks. The UCB method uses per-weight uncertainties to regulate parameter changes, with importance determined by the standard deviation \u03c3. Adapting the learning rate for \u03c1 yields high accuracy and low forgetting. UCB does not require additional memory or tracking parameter changes like pruning or weight regularization methods. UCB-P is a variant related to weight pruning for network compression. In Bayesian neural networks, weight pruning is adapted to measure importance using statistically-grounded uncertainty. Parameters are represented by probability distributions with mean and standard deviation, preventing forgetting by saving task-specific binary masks. This approach differs from regular deep neural networks by considering both mean and standard deviation. Signal-to-noise ratio (SNR) is used to measure parameter importance in neural models. Higher SNR indicates more importance for model predictions. Algorithm 1 outlines Uncertainty-guided Continual Learning with Bayesian Neural Networks. Algorithm 2 describes the process of updating learning rates in Uncertainty-guided Continual Learning with Bayesian Neural Networks. Algorithm 3 outlines a similar process for UCB-P, where parameters with low signal-to-noise ratio are pruned. The text describes a method for pruning parameters with low importance based on signal-to-noise ratio in continual learning. Pruned parameters are marked with a binary mask for future tasks, while important parameters remain fixed. The approach is evaluated in class-incremental learning scenarios with multiple datasets. The text describes a method for pruning parameters with low importance based on signal-to-noise ratio in continual learning. The approach is evaluated in class-incremental learning scenarios with multiple datasets, including Split MNIST, permuted MNIST, FaceScrub, CIFAR100, NotMNIST, SVHN, CIFAR10, TrafficSigns, and FashionMNIST. No data augmentation was used in the analysis. In the Bayesian framework, three models are compared: fine-tuning (BBB-FT), feature extraction (BBB-FE), and joint training (BBB-JT). These models do not consider the importance of parameters. Additionally, ordinary neural networks are used for comparison (ORD-FT, ORD-FE, ORD-JT). State-of-the-art approaches like Elastic Weight Consolidation are also compared. No data augmentation was used in the analysis. In comparison to state-of-the-art approaches like Elastic Weight Consolidation (EWC), Incremental Moment Matching (IMM), Learning Without Forgetting (LWF), Less-Forgetting Learning (LFL), PathNet, Progressive neural networks (PNNs), and Hard Attention Mask (HAT), our method focuses on regularization-based techniques. We only compare against baselines that do not utilize episodic or coreset memory. Hyperparameter tuning is done differently, relying only on the first two tasks and their validations. In our experiments, we focus on regularization-based techniques and compare against baselines that do not use episodic or coreset memory. We rely on the first two tasks for hyperparameter tuning and validation set split. Training details include using stochastic gradient descent with a batch size of 64 and a learning rate of 0.01, decaying it by a factor of 0.3 once the loss plateaus. In the experiments, regularization-based techniques are focused on, comparing against baselines without episodic or coreset memory. The performance drop is computed for various pruning percentages, with a threshold chosen to limit drop. Mask size selection is done without knowledge of future tasks. A uniform distribution of pruning ratios is used, with specific ratios chosen to minimize forgetting. Parameter importance is analyzed to maximize accuracy and minimize forgetting. In experiments, regularization techniques are compared against baselines without episodic memory. Performance drop is computed for different pruning percentages, with a threshold to limit drop. Mask size selection is done without knowledge of future tasks. Parameter importance is analyzed to maximize accuracy and minimize forgetting, with a focus on achieving maximum BWT. In Section 6, the UCB model is shown to work without task labels at inference time using a \"single head\" architecture. Results for class incremental learning of MNIST are presented, with comparisons to Bayesian and non-Bayesian neural networks. Bayesian fine-tuning and joint training show consistent performance across experiments. In experiments, Bayesian fine-tuning and joint training outperform ORD-FT and ORD-JT. VCL-Vadam shows higher accuracy than VCL and VCL-GNG. UCB surpasses all baselines in average accuracy, including VCL-Vadam. Results on 2-Split MNIST incrementally learning are compared against PackNet, HAT, and LWF. Permuted MNIST is a variant of the dataset used to evaluate continual learning approaches. UCB outperforms other models in accuracy, with a small network achieving 91.44% accuracy. Comparisons are made with other models like SI, EWC, and HAT. UCB outperforms other Bayesian approaches in accuracy, with a BWT of 0.03%. Adding memory significantly improves performance, as seen with VCL-GNC achieving 94.37% accuracy with a memory size of 200. In larger networks, UCB achieves 97.42% accuracy, outperforming all baselines including HAT. BBB-FT also shows reasonable performance despite not being penalized for forgetting. In an experiment involving class incremental learning of CIFAR10 and CIFAR100, UCB-P exhibits reasonable negative BWT values, outperforming IMM and LWF baselines. Table 2c compares ACC and BWT results of UCB-P, UCB, and BBB against various continual learning baselines, with PNN and PathNet being the only zero-forgetting-guaranteed approaches. Some baselines like PathNet, LWF, and LFL do not perform better than naive accuracy achieved by feature extraction. In a class incremental learning experiment with CIFAR10 and CIFAR100, UCB-P shows negative BWT values, outperforming IMM and LWF. Comparing ACC and BWT results of UCB-P, UCB, and BBB against various baselines, PNN and PathNet are the only zero-forgetting approaches. Some baselines like LWF and LFL do not surpass naive accuracy achieved by feature extraction. HAT exhibits zero forgetting behavior and outperforms EWC and UCB-P in ACC. Despite slightly higher forgetting, UCB achieves an overall accuracy of 79.4%. UCB-P outperforms PNN by 3.6% in ACC, while HAT shows -0.1% BWT. UCB achieves 2.4% higher ACC than HAT. UCB can be used without task information at test time by using a single head with total outputs for all tasks. The ACC reduction for UCB transitioning from multi-head to single head is 0.3%, 2.6%, 5.1%, and 4.1% for different experiments. In more challenging conditions, UCB and BBB-FT were evaluated with a metric covering classes across all tasks, showing a small performance reduction in confusion of similar class labels. The performance degradation from ACC to Generalized ACC ranged from 0.2% to 3.1% for different tasks, indicating UCB's competitive performance in realistic conditions without task information at test time. The approach focuses on direct utilization instead of computing additional task-dependent measurements of importance. In this work, a continual learning formulation with Bayesian neural networks called UCB is proposed. It uses uncertainty predictions to preserve important parameters through a binary mask (UCB-P) or allow them to change based on uncertainty for learning new tasks (UCB). The probabilistic uncertainty distributions per weight aid in learning short and long sequences of benchmark datasets, outperforming state-of-the-art models like HAT. The choice between UCB variants depends on the application. UCB variants, UCB-P and UCB, offer different benefits. UCB-P saves a binary mask per task to prevent forgetting, while UCB allows for more learning flexibility without additional memory. UCB can be used in single head settings where task information is unknown during inference, making it competitive for continuous data streams. Additionally, UCB can be deployed in scenarios where task information is unavailable at test time. In this section, the UCB model on MNIST is examined, evaluating parameter regularization, importance measurement, and the effect of samples drawn from the posterior. The search space for hyperparameters in the Bayes-by-backprop (BBB) algorithm is shown in Table 5, used for tuning on the validation set of the first two tasks. The search space for hyperparameters in BBB is provided by Blundell et al. (2015), including parameters for log \u03c3 1, log \u03c3 2, and \u03c0. Network architecture details are given for different experiments, with a focus on matching the total number of parameters between Bayesian neural networks and regular neural networks for fair comparison. ResNet18 is used for multiple datasets learning scenarios, with varying parameter counts. Baselines in the study are primarily based on AlexNet structure, and switching to ResNet18 resulted in performance degradation. The study compared the performance of AlexNet and ResNet18 on CIFAR10/100 using UCB and HAT methods. Results showed that switching to ResNet18 led to performance degradation. UCB used multiple samples for robustness and regularization on mean values. The number of samples chosen was 10 for all experiments. Additional results were presented for 2-split MNIST and complementary results for other tables. The study compared AlexNet and ResNet18 on CIFAR10/100 using UCB and HAT methods. Results showed performance degradation when switching to ResNet18. UCB used multiple samples for robustness and regularization on mean values, with 10 samples chosen for all experiments. Additional results were presented for 2-split MNIST and complementary tables."
}