{
    "title": "HJIoJWZCZ",
    "content": "We propose Adversarial Dropout Regularization (ADR) as a novel domain adaptation method to improve target classification accuracy by encouraging the generator to output more discriminative features for the target domain. This approach replaces the traditional domain classifier with a critic that detects non-discriminative features using dropout on the classifier network, helping the generator avoid generating ambiguous features near class boundaries. Our ADR approach improves target classification accuracy by encouraging the generator to create better features, leading to significant enhancements in unsupervised domain adaptation for image classification and semantic segmentation tasks. Recent methods for unsupervised domain adaptation focus on reducing the discrepancy between source and target features through adversarial learning. The approach involves dividing the base network into a feature encoder G, classifier C, and domain classifier network D. The encoder G is trained with an adversarial loss to align features across domains, but a drawback is that the critic only predicts domain labels and overlooks category information. This can lead to the generator creating non-discriminative features close to class boundaries, impacting the source model's classification accuracy. In unsupervised domain adaptation, a novel adversarial alignment technique is proposed to preserve class boundaries by considering decision boundaries between classes. The technique involves altering the classifier boundary slightly to measure the change in posterior class probability, forcing the generator to create more discriminative features. This approach aims to overcome limitations of existing methods that overlook category information, leading to misclassification near class boundaries. Adversarial Dropout Regularization maximizes posterior discrepancy to make the classifier sensitive to nondiscriminative points near decision boundaries. Unlike previous methods aligning distributions globally, this technique aligns target features away from decision boundaries. Our ADR approach aligns target features away from decision boundaries, trained with feedback from the classifier C. It is applicable to various domain adaptation problems and can be used in semi-supervised learning and training of generative models like GANs. Extensive experiments show its superiority over existing methods in challenging domain shifts. Domain adaptation methods aim to align feature distributions of source and target domains, motivated by theoretical results that minimizing domain divergence lowers error on the target domain. Many deep learning works use distribution matching in hidden layers like CNNs, but often overlook the relationship between decision boundaries and target features. Some semi-supervised learning methods utilize low-density separation to place boundaries in areas with unlabeled samples. Our method focuses on achieving low-density separation for deep domain adaptation by adjusting the decision boundary to detect target samples sensitive to the movement, allowing them to exist relatively close to the boundary compared to source samples. This approach contrasts with entropy minimization used in previous works, where the boundary is placed where unlabeled samples are sparse. Our approach aims to achieve low-density separation in deep domain adaptation by adjusting the decision boundary to detect target samples sensitive to movement. In contrast, a new baseline method focuses on minimizing the entropy of target samples' output probability. This method, similar to our approach, aims for low-density separation. Dropout is a technique used to prevent overfitting in deep networks by randomly dropping units during training. Dropout is used to prevent overfitting in deep networks by sampling from thinned networks during training. It encourages robustness to noise and is used adversarially to regularize the feature generation network G. This approach is different from existing methods and aims to generate noise-robust features. The network is trained with labeled source images and unlabeled target images to achieve low-density separation in deep domain adaptation. The feature generation network G and network C act as the main classifier and critic in training with labeled source images and unlabeled target images. The critic C is sensitive to target samples near the decision boundary by perturbing its decision boundary and measuring the change in posterior class probability. The feature generation network G is trained to generate target features far from the decision boundary, avoiding ambiguous features. The weights of G can be initialized with pre-training on auxiliary datasets or random weights, while the critic C uses random initialization. Dropout is utilized to perturb the critic's boundary and measure sensitivity, improving the training procedure. Adversarial dropout is discussed as a method to enhance neural network training. The network utilizes dropout to select different classifiers for each sample during training. Input features are forwarded to two classifiers, C1 and C2, with nodes dropped each time. The critic aims to increase the difference between the predictions of C1 and C2 near the boundary by measuring sensitivity using KL divergence. The ADR approach uses the symmetric Kullback Leibler (KL) divergence to update G and C for minimizing sensitivity on target inputs and maximizing sensitivity on target inputs, respectively. The method requires C and G to classify source samples correctly and imposes three key requirements. The training process involves three steps: 1) C is trained as a classifier to classify source samples correctly, 2) C is trained as a critic to detect target samples near the boundary, and 3) G learns to minimize sensitivity to move target samples away from the boundary. In the training process, C's parameters are updated to maximize sensitivity and learn discriminative features for source samples. C 1 and C 2 are randomly sampled, and G is trained to move target samples away from the decision boundary by minimizing sensitivity. The parameters of C and G are updated in every step following defined objectives. The neurons in the last hidden layer do not learn diverse features. Adversarial dropout method encourages different neurons to learn different characteristics, resulting in diverse boundaries. The output combines shared and unshared nodes to maximize sensitivity and minimize sensitivity. The Adversarial Dropout (ADR) method encourages the feature generator to obtain noise-robust target features, while the classifier is trained to be sensitive to noise. Another classifier C is introduced to improve final accuracy by not being sensitive to noise. In the experiment, a classifier C is trained with features from a generator G, not sensitive to noise, and compared with another classifier C for image classification accuracy. Using synthetic \"two moons\" data, the decision boundary of each neuron is observed to show that ADR encourages learning different input characteristics. A six-layered network is trained with Batch Normalization and ReLU activation function. The experiment involved training a classifier with features from a generator using Batch Normalization and ReLU activation function. The neurons in the last layer were visualized to show the learned boundaries. Results indicated that the proposed method achieved 96% accuracy compared to 84% for the non-adapted model. The neurons in the proposed method demonstrated greater diversity in learning distinctive boundaries sensitive to noise from target samples. The proposed method achieved 96% accuracy, compared to 84% for the non-adapted model. Experiments on adaptation between digits datasets (MNIST, SVHN, USPS) were conducted following a protocol of unsupervised domain adaptation. The method was compared with previous approaches, using fixed hyper-parameters and a Batch Normalization layer for stabilization. Adam optimizer with a learning rate of 2.0 \u00d7 10 \u22124 was used. The proposed method achieved better performance than existing methods, with improved accuracy on the adaptation task from SVHN to MNIST. The learning curve in FIG2 shows that as sensitivity loss increases, target accuracy improves, indicating the feature generator learns to fool the critic for better results. The critic network learns to capture non-essential features, leading to decreased accuracy in adaptation from SVHN to MNIST. The classifier C, trained to be noise-insensitive, consistently outperforms the critic network. The proposed method based on entropy minimization shows good performance compared to existing methods, effectively reducing entropy in target samples. Our method decreases entropy in target samples by moving them away from the decision boundary, showing different behavior compared to existing methods. In experiments on object classification, our method is evaluated on fine-tuning a pretrained CNN using the VisDA Challenge benchmark, focusing on adapting from synthetic to real images. The source domain consists of synthetic 2D images from 12 object classes, while the target domains consist of real images. Our method outperformed other distribution matching methods and a new baseline in fine-tuning networks pretrained on ImageNet. The experiment on ResNext showed improvement over the source only model, but did not perform as well due to larger domain shifts. In adaptation experiments for semantic image segmentation, our method outperformed other distribution matching methods. We retrained a classifier on features generated by a generator due to GPU memory limitations, resulting in improvement in both networks. The training procedure was the same as in classification experiments, using ResNet50 pretrained on ImageNet and an FCN based network. We utilize Dilated Residual Networks (DRN) 105 layered model BID32 for semantic segmentation, outperforming ResNet50. Our proposed method shows superior performance compared to existing methods, with a retrained classifier for our generator. The network architecture details are included in the appendix, with a fully-convolutional network for the classifier and a batch size of 1 due to memory constraints. Our network model, DANN, includes a domain classifier network for pixel features. ADR significantly improves mean IoU compared to other models, outperforming state-of-the-art methods. Applying ADR to DRN results in a higher accuracy increase than with ResNet50. However, the ENT method performs poorly on synthetic-to-real shifts. Our method demonstrates improvement in example input images and segmented results compared to the Source Only model. In this paper, a novel approach called Adversarial Dropout Regularization (ADR) is introduced for aligning deep representations in semantic segmentation tasks. ADR generates discriminative features for the target domain without requiring target domain labels. The method outperformed baseline methods in extensive domain adaptation experiments, including entropy minimization, and achieved state-of-the-art results on adaptation from GTA5 to Cityscapes. The method described in the curr_chunk aims to move target samples away from the decision boundary by training Generative Adversarial Networks. Techniques used in training GANs can be applied to achieve this goal, such as training the critic to classify real samples and move unlabeled real images away from the boundary. The generator is trained to generate fake images away from the boundary, making this method applicable to domain adaptation problems. The method involves using critic and generator networks to move target samples away from the decision boundary in domain adaptation. The critic classifies samples into classes and is trained to maximize entropy, while the generator minimizes entropy. The key difference is replacing the sensitivity term with entropy in the adversarial training loss. The hyper-parameter for updating the generator is set to n = 4, which worked well in experiments. The protocol used for adaptation from SVHN to MNIST is followed. In domain adaptation, the protocol for adaptation from SVHN to MNIST is followed. Standard training splits of datasets are used for training data, and test splits of MNIST are used for evaluation. Different adaptations between MNIST and USPS involve sampling images and composing mini-batches with half from source and half from target samples. The batch size is set at 128 for both source and target, with the score reported after multiple repetitions. The baseline method ENT uses the same network architecture and hyper-parameters as the proposed method, with SGD used for optimization. ResNet101 finetuning involves a batch size of 32 due to GPU memory limitations. In domain adaptation, ResNet101 is finetuned with a batch size of 32. For the ResNext model, the batch size is set to 24 due to GPU memory constraints. MMD model training uses 5 RBF kernels with standard deviation parameters. Experimentation with different kernel numbers and parameters did not show significant performance differences. Training a model BID4 with two-layered domain classification networks did not result in improvements. The learning rate was fixed at 1.0 \u00d7 10 \u22123 as decreasing it every iteration did not improve results. The accuracy dropped significantly after the first epoch, possibly due to large domain differences. In domain adaptation, ResNet101 and ResNext models were trained with different batch sizes due to GPU memory constraints. The accuracy dropped significantly after the first epoch, possibly due to large domain differences. For the new baseline ENT, accuracy drops after 5 epochs, and the method is applied in training a Generative Adversarial Network for semi-supervised learning. The input images were resized to 512x1024, and batch size was set to one for GPU memory limitations. The proposed method cleanly segmented images by DRN-105. In semi-supervised learning, a K-class classification network is used as a critic to train a GAN. The goal is for the generator to produce images that deceive the critic, with labeled and unlabeled real images provided. The critic is trained to classify labeled images accurately and push unlabeled images away from the decision boundary. The method is evaluated on benchmark datasets SVHN and CIFAR, showing promising results compared to state-of-the-art methods. In ImpGAN, the critic is trained to minimize loss on labeled samples and ensure that unlabeled images are far from the decision boundary. The objective of the generator is to create fake images that are similar to real ones but placed far from the boundary. The training process updates the critic and generator an equal number of times. In the proposed GAN training method, the critic and generator are updated an equal number of times. Experiments were conducted using SVHN and CIFAR10 datasets with a batch size of 100 and Adam optimizer. A classifier was added after the conv6 layer of the critic, not involved in adversarial learning. Different configurations were tested, such as replacing Weight Normalization with Batch Normalization for C in SVHN experiment. Results show that ADR generates realistic SVHN images, with some being blurred but most clear. The proposed GAN training method generates realistic SVHN images, with some being blurred but most clear. The accuracy of the critic trained by the method outperforms other models for SVHN but slightly lags behind for CIFAR10. The method shows promise for SSL tasks but requires further exploration to improve accuracy. BID1's late-breaking results suggest that generating fake images far from decision boundaries does not enhance GAN training accuracy in SSL settings. Future work will focus on improving SSL based on these findings."
}