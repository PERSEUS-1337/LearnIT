{
    "title": "SyePUgBtPr",
    "content": "Automatic Essay Scoring (AES) research focuses on using deep neural network (DNN) models to differentiate essays and infer scores. The proposed Referee Network (RefNet) compares essay quality by capturing relative features, reducing the need for expert-rated training data. The proposed framework extends regression models to capture additional features and improve performance, especially in handling data sparsity. Automatic Essay Scoring (AES) aims to automate essay grading, reducing repetitive labor and improving consistency and fairness in scoring. AES research has evolved from early methods like Project Essay Grade (PEG) to using deep neural networks for scoring essays. Recent advances in neural networks have brought new possibilities to Automatic Essay Scoring (AES). Several works have leveraged neural networks and achieved decent results by following a 'representation + regression' scheme. However, the model requires a large amount of expert-rated essays for training, which is expensive to collect. To address data sparsity, the proposal suggests leveraging pairwise comparisons for scoring essays. The proposal suggests using pairwise comparisons for scoring essays instead of regression, shifting the model's goal to comparing essays. A Siamese network called Referee Network (RefNet) is designed for this purpose, utilizing various representation encoders and benefiting from transfer learning. This approach helps in dealing with data sparsity issues by pairing essays for training data, leading to acceptable performance even with limited training data. Our model, Referee Network (RefNet), compares essays using pairwise comparisons instead of regression, addressing data sparsity issues and achieving acceptable performance with limited training data. It provides transparency during the scoring process by comparing essays with labeled anchors and offers better insight into essay quality through internal and mutual perspectives. RefNet addresses data sparsity issues by comparing essays using pairwise comparisons instead of regression. It leverages internal features captured by regression and can be applied as an extension to various regression models, consistently improving performance. Existing AES solutions fall into two categories: feature-engineered models and end-to-end models. Recent models based on neural networks have shown promise in developing expressive representations of essays. Taghipour & Ng (2016) utilized a self-trained look-up table for embedding and found that LSTM yielded the best performance. Other variations such as CNN with attention pooling and LSTM with attention pooling have also been explored. These methods have proven the effectiveness of neural networks in this problem. The effectiveness of neural networks in developing expressive representations of essays has been proven. However, challenges remain, such as the lack of significant improvement over basic models and the scarcity of labeled data. While regression methods are commonly used for prediction, pairwise difference between essays has shown to outperform regression in experiments. The curr_chunk discusses the use of ranking preference methods in Automated Essay Scoring (AES) and introduces a novel approach using a Referee Network for comparing essays with known samples. The approach aims to exhaust information in representations to improve scoring accuracy. The curr_chunk explains the use of BERT model for obtaining word embeddings in Automated Essay Scoring. The model utilizes Transformers and achieves state-of-the-art results in reading comprehension tasks. The BERT model uses special tags for word embeddings, with the penultimate layer chosen for flexibility and semantic meaning. The network architecture compares essays to output rank preference instead of inferring scores directly. RefNet, inspired by Siamese Network Koch et al. (2015), encodes essays into representations using different backbones like Average Embeddings, Simple RNN, and LSTM. The network architecture compares essays to determine rank preference. The RefNet network architecture, inspired by Siamese Network Koch et al. (2015), encodes essays into representations using RNN and LSTM backbones. The final output is a scalar indicating the probability that one essay is better written than the other. RefNet is trained by pairing essays with different scores within the same prompt to form essay pairs, as essays from different prompts are not comparable. Identically scored essays can still be distinguished, and the inconsistent scoring schemes make equal quality vague. RefNet categorizing identically rated essays may frustrate the model. RefNet is trained by pairing essays with different scores within the same prompt to form essay pairs. This approach avoids categorizing identically rated essays, which can frustrate the model during training. Transfer learning enables RefNet to use internal information, with parameters transferred from a backbone network trained in a regression task. A probability majority voting algorithm is used to infer the final score of test essays compared against known samples. The RefNet model uses a probability majority voting algorithm to determine the final score of test essays by comparing them to known samples. This voting process considers the likelihood that the test essay falls within a certain score range based on comparisons with anchor essays. The RefNet model uses a probability majority voting algorithm to determine the final score of test essays by comparing them to known samples. The voting process penalizes the distance from 0.5 and selects the score notch with the highest votes as the final prediction. If multiple scores have the highest votes, the average is taken and rounded to the nearest integer. In the study, the model's performance is evaluated on two tasks using the ASAP dataset. The dataset consists of 12976 essays in 8 prompts, with a 5-fold split for training, validation, and testing. Quadratic Weighted Kappa (QWK) is used as the evaluation metric, following the standard for the ASAP dataset. RefNet tends to overfit when trained on the whole dataset due to the large number of training data pairs, causing the model to see each essay multiple times within each epoch. To address this issue, training samples are randomly dropped before training, with different dropping rates for each essay pair. Despite this, RefNet can accurately compare essays with contrasting scores, as shown in Figure 4. After data adjustment, only 15% of the training set is kept. RefNet consistently outperforms conventional regression methods, especially with RNN backbone. The model is not very sensitive to representation quality, as long as it makes sense. Comparison with ensembled neural networks in Taghipour & Ng (2016) is also conducted. In comparison to ensembled neural networks in Taghipour & Ng (2016) and SkipFlow LSTM networks by Tay et al. (2018), our model achieved state-of-the-art QWK scores, particularly excelling in prompt 8. We created balanced mini-ASAP datasets by extracting essays from the original dataset. RefNet outperforms regression methods, especially with RNN backbone, even with reduced training data. RefNet is robust to scarce data, maintaining high quality predictions even with 90% of data dropped. Ablation tests were conducted to study individual components, including transfer learning and data adjustment. Pairwise ranking approach achieved higher QWK scores compared to regression methods, showcasing the effectiveness of RefNet. RefNet utilizes mutual information and transfer learning to improve essay quality insight. Training without transfer learning results in a 2.48% performance decrease. RefNet is immune to cross-prompt noise and can handle hybrid datasets effectively. RefNet, unlike traditional regression methods, avoids aligning scores from different ranges by focusing on relative relations between essays within the same prompt. This approach reduces noise and shows superiority in few-shot learning scenarios. RefNet's pairing operation amplifies training data without introducing noise, making it well-suited for such problems. Additionally, the 'representation + regression' mechanism in RefNet is data-intensive but effective in improving essay quality insight. Referee Network (RefNet) is a framework for automatic essay scoring using pairwise comparisons. It excels in solving data sparsity issues and maintains high performance even with reduced training data. RefNet outperforms regression models significantly and can enhance conventional regression models. RefNet can boost scoring accuracy even with fixed and mediocre quality essay representations. It is an extendable framework that can be used with any representation encoders, allowing for the use of more complex models to push AES systems to new performance records."
}