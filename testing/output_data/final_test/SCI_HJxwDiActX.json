{
    "title": "HJxwDiActX",
    "content": "In this paper, the authors introduce StrokeNet, a novel model that uses a neural approximation of a painting environment to train an agent. This approach allows the agent to learn to write characters like MNIST digits faster than traditional reinforcement learning methods in an unsupervised manner. The primary contribution is the neural simulation of a real-world environment, enabling more efficient learning. The authors introduce StrokeNet, a model using neural approximation of a painting environment to train an agent. This allows the agent to learn to write characters like MNIST digits faster than traditional methods in an unsupervised manner. The approach involves learning to manipulate the painting program rather than generating the image directly. The authors introduce StrokeNet, a model using neural approximation of a painting environment to train an agent. This involves learning a mapping from stroke data to images with a neural network, allowing for continuous transformation. The stroke consists of color, brush radius, and coordinate points. A differentiable approximator called a \"generator\" is trained to mimic the painting software. The authors introduced StrokeNet, a model using neural approximation to train an agent for painting. The architecture includes a generator and an agent, with the agent trained to create images from popular datasets. The quality of the agent was evaluated using a classifier on MNIST digits, and comparisons with other methods were made to show efficiency. The latent space of the agent was also explored. Generative models like VAEs and GANs have been successful in image generation. Recent deep learning approaches in the field of painting generation fall into two main categories: RNN-based methods like SketchRNN and reinforcement learning techniques such as \"artist agent\" and SPIRAL. These methods aim to train agents to interact with the painting environment effectively. In the field of painting generation, methods train an agent to interact with the environment. To address computational costs in reinforcement learning tasks with large action spaces, the environment is simulated in a differentiable manner. This approach is similar to World Models and character reconstruction techniques. Differentiable rendering, extensively researched in computer graphics, is used to solve inverse rendering problems. In digital painting software, a generator neural network is used to simulate the 2D rendering process. A single stroke is defined with RGB color, brush radius, anchor point coordinates, and pressure. The strokes consist of fewer points compared to other datasets, with absolute coordinates used for each point. The StrokeNet architecture uses spline curves with fewer anchor points to represent stroke lines, allowing for the generation of complex drawings with minimal data input. A single stroke with 16 anchors can fit most MNIST digits, and longer lines can be decomposed into simple segments. The generator in StrokeNet takes stroke data as input and projects it using two MLPs. The StrokeNet generator in FIG0 uses two MLPs to project stroke data, with one MLP encoding position (x, y, p) into 64x64 feature maps and the other encoding brush color and radius. Color c is a grayscale scalar, strokes are approximated by channel mixing, and sequential information is preserved using a 2D Gaussian function. The StrokeNet generator uses two MLPs to project stroke data, encoding position and brush color/radius. Position features are generated by mapping (x, y) to 64x64 feature maps, with neighboring maps combined to represent stroke segments. These features are then fed into (de)convolutional layers for reconstruction. The StrokeNet generator utilizes (de)convolutional layers with batch-normalization and LeakyReLU activation to process features, followed by a tanh activation in the final layer. A VGG-like CNN encodes the target image into stroke representation, decoded using parallel FC-decoders for position (tanh), pressure (sigmoid), and brush data (sigmoid). Average-pooling is used for gradient flow improvement. In the recurrent version, separate CNNs are trained for the target image and drawing frame. A painting software was developed using JavaScript and WebGL, later adapted for the experiment. Catmull-Rom spline is used for anchor point fitting due to its property of passing through all control points. The Catmull-Rom spline feature ensures the curve passes through all control points. The generator blends colors using input RGB values and alpha maps. The blending process involves normalization and alpha-blending to simulate real software algorithms. The generator synthesizes samples incorporating chaos to capture randomness and smoothness in human writing. Three-body motion is simulated in space with random initial conditions, leading to unpredictable results for stroke dataset generation. In the simulation, three objects are positioned in space with gravitational forces exerted on them. The mass and gravitational constant are set, and images are generated with the camera at the center of the triangle. Over 600K images are collected with virtually no cost. An agent is trained to draw characters on various datasets, starting with simple characters and progressing to more complex ones like QuickDraw and KanjiVG BID20. The input images are resized to 256 \u00d7 256 with anti-aliasing. The agent is trained to draw characters on datasets like QuickDraw and KanjiVG BID20 by resizing input images to 256 \u00d7 256 with anti-aliasing. The position encoder is trained first, followed by the generator with smaller batch sizes resulting in more accurate images. The generator is trained with a batch size of 64 until the loss plateaus, then batch size is reduced to 32 to sharpen the neural network. The agent loss is defined based on the generated and ground-truth images. The summation term with penalty strength \u03bb enforces average distance between neighboring points, crucial for learning correct stroke order. Experiments conducted on NVIDIA Tesla P40 GPU include single step StrokeNet on MNIST and Omniglot, recurrent StrokeNet on QuickDraw and Kanji. Gaussian prior enforced on MNIST dataset for exploring latent space through linear interpolation. Classifier trained on MNIST shows close accuracies with images generated by the agent. The generator shows good generalization to different shapes and stroke patterns, but struggles with capturing details and tends to smear inside boundaries. Experimentation with a VAE version of the agent involves projecting features into two vectors representing means and standard deviations. The agent trained on MNIST uses vectors for means and standard deviations of 1024 dimensions. Latent space interpolation results in smooth transitions between digits generated by strokes. A 5-layer CNN classifier trained on pre-processed MNIST dataset evaluates the quality of the generated images. The classifier shows some performance drop due to the larger image size of 256 \u00d7 256 compared to standard 28 \u00d7 28 images. The agent trained on MNIST uses vectors for means and standard deviations of 1024 dimensions. Latent space interpolation results in smooth transitions between digits generated by strokes. A 5-layer CNN classifier evaluates the quality of the generated images, showing a performance drop due to the larger image size. Comparisons with SPIRAL on MNIST demonstrate faster convergence with our method over reinforcement learning approaches. Future improvements include enhancing the network structure and algorithm, considering more advanced recurrent structures like LSTM or GRU for better performance. Various attention mechanisms could be incorporated to help the agent focus on undrawn regions, preventing smear and blurry scribbles. Training the generator and agent as a whole by storing intermediate stroke data during agent training and using it to train the generator with real environment images can lead to more reliable reconstructions. Adding randomness to the learning rate and utilizing BID10 or GRU BID3 may also improve performance. Adding randomness to the learning rate can improve the agent's performance by encouraging bolder moves and preventing dull writing. Random sampling techniques could be used to make the agent's output more appealing and diverse. Additionally, incorporating attention mechanisms to focus on undrawn regions and allowing intersecting strokes can lead to better results. Combining naive l2 loss with adversarial evaluation metrics may also be beneficial. In this paper, a proof-of-concept is presented where an agent learns from a neural simulation of an environment. The proposed model-based method approximates non-differentiable environments with neural networks, allowing the agent to quickly converge on various datasets and adapt its skills to the real world. This approach could be beneficial for challenging reinforcement learning problems. The spline is produced by interpolating points linearly, with pressure values also interpolated. Agent loss is calculated based on distance and penalty terms. Learning rate and batch size are specified. StrokeNet generates images resembling painting software output, with the ability to produce strokes with color and texture, and draw MNIST digits. The spline is used to draw MNIST digits on its generative model and real-world painting software."
}