{
    "title": "BJlisySYPS",
    "content": "The lack of mathematical models hindering deep neural network understanding is addressed by comparing networks trained on structured vs unstructured data sets. Two phenomena related to network dynamics and generalization are revealed with structured data. A generative model called the hidden manifold model is introduced for high-dimensional inputs on a lower-dimensional manifold with position-dependent labels. Training networks on data sets from the hidden manifold model reproduces observed phenomena. The lack of mathematical models for data sets used in training neural networks hinders our understanding of their effectiveness. This prevents analysis of how data sets impact training and generalization, posing a challenge in statistical learning theory. Most theoretical results on neural networks do not consider the structure of training data, limiting insights into their behavior. In training neural networks, the lack of mathematical models for data sets hinders understanding of their effectiveness. Approaches blind to key structural properties of real-world data sets are limited in insights into behavior. The MNIST database problem illustrates the challenge of classifying handwritten digits using a neural network in high-dimensional space. The intrinsic dimension of the data set is estimated to be around 14, lower than the input space dimension. The intrinsic dimension of real data sets used in machine learning is often lower than the input space dimension. Inputs concentrated on a lower-dimensional manifold have a lower-dimensional latent representation. Two models are considered: the teacher task and the latent task, where the label is obtained as a function of the high-dimensional input or the lower-dimensional latent representation, respectively. The text discusses inputs concentrated on a lower-dimensional manifold in input space, with a focus on latent representations for structured inputs. It introduces the teacher task and latent task models, along with a generative model for data sets with structured inputs and latent labels. Key concepts are summarized in Table 1. The paper compares neural networks trained on different problems: discriminating odd from even digits in the MNIST dataset and a teacher-student setup with inputs drawn from a Gaussian distribution. The teacher task model is an example of unstructured inputs and has been studied in theoretical generalization ability of neural networks. The study compares neural networks trained on discriminating odd from even digits in the MNIST dataset with networks trained in a teacher-student setup using Gaussian inputs. The MNIST dataset is chosen for its structured nature, highlighting differences in network behavior. Two key differences are identified between networks trained in the two setups, showing that networks trained on MNIST learn globally different functions despite achieving the same test error. The study compares neural networks trained on discriminating odd from even digits in the MNIST dataset with networks trained in a teacher-student setup using Gaussian inputs. Two key differences are identified between networks trained in the two setups, showing that networks trained on MNIST learn globally different functions despite achieving the same test error. The hidden manifold model (HMF) is introduced as a probabilistic model that generates data sets with high-dimensional inputs on a lower-dimensional manifold. In the study, neural networks trained on discriminating odd from even digits in the MNIST dataset are compared with networks trained using Gaussian inputs in a teacher-student setup. The hidden manifold model (HMF) is introduced as a probabilistic model generating data sets with high-dimensional inputs on a lower-dimensional manifold. The importance of the structure of input space and the task in neural network dynamics and performance is highlighted. The text discusses recent papers on neural networks' ability to store inputs with lower-dimensional structure and random labels. It also provides accessibility to the full code of experiments and necessary parameter values. The focus is on determining a suitable model for structured data using a feedforward approach. In exploring suitable models for structured data, a feedforward neural network with one hidden layer and a few hidden units is considered. The network's dynamics and performance are focused on, using sigmoidal or ReLU activation functions. Training is done on datasets with input-output pairs. The study focuses on training neural networks with sigmoidal or ReLU activation functions on datasets with input-output pairs. Initial weights are randomly chosen, and the test error is compared to the true labels in a separate test set. The study compares two-layer neural networks trained on real data sets like MNIST images with networks trained on unstructured tasks using Gaussian i.i.d. inputs. Training independent networks on i.i.d. inputs does not yield the same results as training on real data sets. The study focuses on the generalization ability of neural networks trained on data from a probabilistic generative model, specifically using a vanilla teacher-student setup with two layers and M hidden nodes. The inputs are drawn from a standard normal distribution for regression tasks. The study demonstrates significant differences in the dynamics and performance of neural networks trained on realistic data sets compared to networks trained in a vanilla teacher-student setup. Two sigmoidal networks with K hidden units were trained to discriminate odd from even digits in the MNIST database using SGD with a constant learning rate until the generalization error converged. The study compared neural networks trained on Gaussian i.i.d. inputs with teacher labels to networks trained on structured inputs with latent labels. The experiment showed differences in performance and dynamics between the two setups. Increasing the number of hidden units in the network decreases test error. Comparing networks by measuring the fraction of inputs they classify differently shows that independent networks disagree at a rate corresponding to their test error. Bigger networks with more parameters are helpful in discrimination tasks but learn increasingly different functions as network size increases. The network learned the right function on the lower-dimensional manifold where MNIST inputs concentrate, but not outside of it. As the network's expressive power increases to match the teacher's, the test error decreases, leading to a small generalization error. Networks with fewer parameters find different approximations to the function, yielding finite values of disagreement. The network learned the right function on the lower-dimensional manifold where MNIST inputs concentrate. Networks with fewer parameters find different approximations to the function, yielding finite values of disagreement. The vanilla teacher-student setup is unable to reproduce the behavior observed when training on MNIST. Plateaus in test error are observed during training before a sudden drop. The generalization dynamics of neural networks during training show different stages of learning, with a plateau in test error followed by a sudden drop. This behavior is related to the network's understanding of linear separability and specialization with the teacher's structure. Plateaus are rarely seen in neural network training, especially in tasks like MNIST where the generalization error decreases exponentially without plateaus. During training, the dynamics of neural networks in the teacher-student setup can be affected by plateaus. Second-order gradient descent methods can help shorten plateaus, but the focus is on first-order SGD. A new generative probabilistic model for structured data sets aims to eliminate plateaus independently of output dimension, replicating training behavior on MNIST with synthetic data. The model is motivated by the expectation of a closed-form solution for learning dynamics. The model aims to generate a dataset with inputs in N dimensions by choosing feature vectors and collecting them in a matrix. The latent representation of each input is obtained through a non-linear function acting component-wise. The data \"world\" is a D-dimensional manifold obtained from the linear subspace generated by the feature vectors, with the exact form of the non-linear function being less important. The latent labels are obtained by applying a two-layer neural network with weights within the unfolded hidden manifold. The dependency of labels on the lower-dimensional manifold C is emphasized, rather than on the high-dimensional data X. The exact form of this dependence is deemed not crucial, with various choices expected to yield similar results. In an experiment with structured inputs and teacher labels, the behavior observed on MNIST was not reproduced. The entries of both C and F were drawn from a normal distribution with mean zero and unit variance. Data sets were generated from a hidden manifold model with 10 latent dimensions. The network's asymptotic performance on structured inputs was plotted. The asymptotic performance of a network trained on structured inputs with a teacher task is shown in Fig. 3. The network recovers the teacher function if it has enough parameters, achieving zero test error. The network performance differs when trained on inputs with a latent task where labels are based on the latent representation. The labels are determined by the latent representation of the inputs. Networks trained on structured inputs with teacher tasks show plateaus in performance, while those trained on latent tasks do not exhibit plateaus. The hidden manifold model mimics the behavior of independent networks trained on MNIST. In Appendix B, it is shown that the lack of plateaus for latent tasks is not due to higher generalization error. A teacher network with 4 hidden units pre-trained on MNIST reaches 5% error. Different setups for supervised learning include teacher-student setup and teacher/latent tasks on structured inputs. The behavior of networks trained on MNIST is being replicated through various setups. The setup involves training a network on the MNIST task and using it as a teacher to generate labels for inputs drawn from a standard normal distribution. Independent students trained on data with Gaussian inputs and true labels from the teacher network behave similarly to students in the vanilla teacher-student setup. The learning dynamics display plateaus similar to the vanilla setup. The hidden manifold model for structured data sets in supervised learning problems suggests that a model for realistic data sets should have both structured inputs and a latent task. This model includes high-dimensional inputs lying on a lower-dimensional manifold and latent labels depending on the inputs' position within the manifold. It aims to provide a better understanding of the structure found in real-world inputs. The model aims to understand how structured data impacts neural network training dynamics and generalization. Future work includes generalizing to multi-layer networks and analyzing learning dynamics in a closed-form. Questions arise about the necessity and importance of non-linearities in input generation. The experiment investigates the impact of non-linearity on neural network training. Without non-linearity, networks learn different functions and struggle to generalize. The weights in the network are unconstrained in certain directions, leading to convergence to different values. The experiment explores the effect of non-linearity on neural network training, showing that networks trained on the hidden manifold model converge to different values. The qualitative behavior is independent of the data-generating non-linearity. The input-generating function must be non-linear, and even networks trained within the vanilla teacher-student setup will disagree on Gaussian inputs. Neural networks trained on the hidden manifold model do not exhibit the plateau phenomenon seen in the vanilla teacher-student setup. The generalization error in the sigmoidal network does not plateau, unlike in the vanilla setup where it can be higher than the asymptotic error in a latent task on structured inputs. Neural networks trained on structured inputs with latent labels show similar generalization errors as networks trained in the vanilla teacher-student setup. The performance of independent neural networks trained on different tasks is compared, with a focus on early-stopping generalization error. The qualitative result remains consistent, indicating that independent students using structured inputs do not exhibit the plateau phenomenon observed in the vanilla setup. Neural networks trained on structured inputs with latent labels show similar generalization errors as networks trained in the vanilla teacher-student setup. The behavior of networks trained on data from the hidden manifold model in the extensive D regime is investigated, where the number of feature vectors D is on the same order as the input dimension N. Experimental studies show that inputs in the MNIST task lie on a low-dimensional manifold of dimension D ~ 14, much smaller than the input dimension N = 784. In the study, neural networks trained on structured inputs with latent labels exhibit similar generalization errors as networks trained in the vanilla teacher-student setup. Increasing the number of hidden units for the latent task leads to severe overfitting, which is only partially alleviated by early stopping. The generalization error on this task is significantly higher than in the low-dimensional regime, suggesting that increasing the network width is not an effective approach for learning a latent task. The study explores neural networks trained on structured inputs with latent labels, showing similar generalization errors as networks in the teacher-student setup. Increasing hidden units for the latent task leads to overfitting, partially mitigated by early stopping. Generalization error is higher in the high-dimensional regime, indicating widening the network is not effective for learning a latent task. The performance of deeper networks on this task is intriguing for future research, with results of numerical experiments on ReLU networks presented in Fig. 10. The study shows that increasing hidden units for a latent task can lead to overfitting, with generalization errors comparable between networks in the teacher-student setup. The performance of deeper networks on this task is of interest for future research, as shown in numerical experiments on ReLU networks in Fig. 10. The study found that the generalization error of ReLU networks increases beyond the error on structured inputs, similar to what was observed on MNIST. ReLU activation was trained independently on a binary classification task with structured inputs and latent labels."
}