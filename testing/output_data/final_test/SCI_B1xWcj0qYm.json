{
    "title": "B1xWcj0qYm",
    "content": "Empirical risk minimization (ERM) is a common practice in supervised classification, involving the use of proper loss functions and regularization. This paper explores training binary classifiers from unlabeled data using ERM. It is shown that estimating the risk of a binary classifier from a single set of unlabeled data is impossible in an unbiased manner, but becomes possible with two sets of data with different class priors. A new ERM-based learning method is proposed using two sets of unlabeled data, which is proven to be consistent and outperforms existing methods. In supervised classification, empirical risk minimization (ERM) is commonly used with proper loss functions and regularization. ERM is also applied in weakly-supervised learning, such as semi-supervised learning, where limited labeled data is available. Unlabeled data is crucial for regularization, especially in cases like positive-unlabeled learning. The lack of L data from the negative class makes it impossible to estimate risk. A two-step approach to ERM involves rewriting the risk into an equivalent expression and estimating it from both L and U data. This approach requires U data in ERM and enables learning from only U data without any L data, which is more challenging. The lack of labeled data (L data) makes training arbitrary binary classifiers significantly harder. Clustering is suboptimal for this purpose due to the reliance on critical assumptions. The right panel of the figure shows test distribution and data with four learned classifiers. The proposed method \"UU\" is compared to supervised learning (\"Oracle\") using the same amount of labeled data (L data). UU performs almost identically to Oracle and outperforms other methods. Clustering may not lead to good classification due to assumptions, so the preference is for Empirical Risk Minimization (ERM) without additional assumptions. The challenge is estimating risk with only unlabeled data (U data), which is addressed by an ERM-enabling risk rewrite in a two-step approach. The first step provides an unbiased risk estimator, used in the second step to evaluate training/validation risk with only U data. The two-step ERM method eliminates the need for L validation data in training deep models. It leverages weakly-supervised learning with class priors assumption. Risk rewrite is impossible with one set of U data but becomes possible with two sets, requiring three class priors for training deep models. The proposed method leverages class priors to train deep models from two sets of unlabeled data. An unbiased risk estimator allows for ERM-based learning, resulting in improved performance compared to existing methods. Experiments show success in training various neural networks from two sets of unlabeled data. Our findings support the possibility of empirical balanced risk minimization when learning from two sets of unlabeled data. Previous studies have shown similar results in learning from label proportions, with different approaches such as linear models and discriminative clustering. The proposed method is based on discriminative clustering with expectation regularization. It utilizes mutually contaminated distributions, which are more general than class-conditional noise. The method is the first of its kind to be based on ERM for MCD. The proposed method is based on discriminative clustering with expectation regularization, utilizing mutually contaminated distributions. It is the first of its kind for MCD. Knowing \u03c0 p and \u03b8 is insufficient for rewriting R(g). ERM BID54 involves minimizing R pn (g) with appropriate regularization to converge to the Bayes optimal classifier g * * as n \u2192 \u221e. The approximation error is R(g * ) \u2212 R(g * * ), and the estimation error is R( g pn ) \u2212 R(g * ). Learning is achieved by choosing a model G where g * = arg min g\u2208G R(g) is the target. The error in learning is defined as the difference between R(g*) and R(g**), with the estimation error being R(gpn) - R(g*). Learning is consistent when the estimation error converges to zero as n approaches infinity. Rewriting R(g) to be approximated with different data sets is known as backward correction in learning with noisy/corrupted labels. Theorem 2 states conditions for a bounded surrogate loss to converge to the Bayes optimal classifier. Theorem 2 provides conditions for a bounded surrogate loss to converge to the Bayes optimal classifier. Under the assumption of separability, R(g) is not rewritable, leading to a lack of learning objectives and the inability to access empirical validation risk. Knowing \u03c0 p, \u03b8, and \u03b8 is sufficient for rewriting R(g), which can be estimated from X tr and X tr. This motivates further investigation into the possibility of rewriting R(g). Theorem 2 provides conditions for a bounded surrogate loss to converge to the Bayes optimal classifier. Under the assumption of separability, R(g) is not rewritable, leading to a lack of learning objectives and the inability to access empirical validation risk. Knowing \u03c0 p, \u03b8, and \u03b8 is sufficient for rewriting R(g), which can be estimated from X tr and X tr. These facts motivate further investigation into the possibility of rewriting R(g), where g and are both arbitrary. R(g) is rewritable given p tr and p tr if there exist constants a, b, c, and d for any g. Theorem 4 states that fixing \u03b8 and \u03b8 and ensuring \u03b8 > \u03b8 allows for R(g) to be rewritable, leading to an unbiased risk estimator useful for training and hyperparameter tuning. The proposed unlabeled-unlabeled (UU) learning process aims to obtain the empirical risk minimizer using powerful stochastic optimization algorithms. Equation (10) can be simplified by employing a symmetric condition, leading to a simplified form that is easy to implement. Special cases of Equation (10) can be considered for different loss functions. The proposed UU learning process aims to minimize empirical risk using stochastic optimization. Equation (10) simplifies for supervised learning and positive-unlabeled learning. UU learning is a general framework in weakly-supervised learning with guaranteed consistency. The estimation error is analyzed in terms of Lipschitz continuity. The proposed UU learning process aims to minimize empirical risk using stochastic optimization. Theorem 5 guarantees consistency for all parametric models with bounded norms, including deep networks trained with weight decay. Experimental analysis is conducted on training deep networks and comparing with state-of-the-art methods. The implementation of the proposed UU learning process is based on Keras and available on GitHub. It is compared with three supervised baseline methods using binary classification datasets. The experiments aim to prove the concept of the proposed method. After implementing the UU learning process in Keras and comparing it with supervised baseline methods, experiments were conducted using binary classification datasets. Test data was drawn from p(x, y) and models like FC, AllConvNet, and ResNet were described in TAB0. The choice of optimizer and loss function (sigmoid or logistic) were discussed, with experimental results reported in FIG2. Results in FIG2 show that UU is comparable to PN oracle when \u03b8 = 0.9 and \u03b8 = 0.1, but slightly worse when \u03b8 = 0.8 and \u03b8 = 0.2. As \u03b8 and \u03b8 become closer, the task becomes harder. Testing on MNIST with varying \u03b8 values, UU and CCN BID31 perform worse as \u03b8 approaches \u03b8, with CCN being more severely affected. The phenomenon of UU is explained by Theorem 5, with an upper bound linear in \u03b1 and inversely proportional to \u03b8 \u2212 \u03b8. CCN is affected by stronger covariate shift as \u03b8 moves closer to \u03b8. CCN methods do not fit the problem setting, calling for a new learning method like UU. Strong covariate shift occurs not only by changing \u03b8 and \u03b8 but also by changing n and n. Robustness against inaccurate training class priors is a feature of UU, which is a robust learning method. The experimental results show that UU is robust to inaccurate training class priors and can be applied in real-world scenarios. UU is compared with two state-of-the-art methods, pSVM and BER, with a new baseline called BER-FC implemented for fair comparison. The first five datasets include original codes of BER and USPS from https://cs.nyu.edu/roweis/data.html, arranged by \u03c0p. Information on subsampled training data, generated training data, and \u03b8 values is provided. The task difficulty increases with closer \u03c0p to 0.5, smaller # Train or \u2206\u03b8. Small datasets are used due to limitations of pSVM and BER with larger datasets. Subsampling is done to match desired \u03c0p, with sample sizes n and n calculated based on P and N data. In the experimental results reported in TAB2, the UU method outperforms others in 7 out of 10 cases or is comparable in 3 cases. The performance of BER and BER-FC improves as \u03c0p approaches 0.5 but worsens as it approaches 0 or 1. pSVM falls behind due to its focus on balanced error instead of classification error. The study focuses on training binary classifiers using ERM on U data, showing that risk can be rewritten. The appendix proves theorems using a contradiction method for learning from two sets of U data. It introduces UU learning, an ERM-based method, showing successful training of various networks. The experiments demonstrate UU learning's effectiveness compared to state-of-the-art methods. The appendix presents a method for learning from two sets of data, proving theorems using a contradiction approach. It introduces UU learning, an ERM-based method, showcasing successful training of different networks. The experiments highlight the effectiveness of UU learning compared to other methods. The current chunk discusses various cases and equations to derive conclusions about binary classification problems. The current chunk presents equations and proofs related to minimizing the learning objective in non-binary classification problems. It includes a uniform deviation bound lemma for estimation error. The current chunk provides proofs and equations for minimizing the learning objective in non-binary classification problems, including a uniform deviation bound lemma for estimation error. It also includes an illustrative example using a Gaussian mixture of two components. In an illustrative example, two-dimensional Gaussian distributions are used to create training distributions with different class priors and sample sizes. A test distribution is formed by combining the two distributions with specific weights. A linear model with a sigmoid loss function is used for training with SGD optimization. The key difference between this approach and others lies in the changing distribution of p(x) between training and test sets. The model used SGD optimization with a learning rate of 0.01 and batch size of 128. No regularization was added due to the small number of parameters. Training was done for 500 epochs. The model architecture was a fully connected network with ReLU activation: d-300-300-300-300-1. Batch normalization was applied before hidden layers. L2 regularization with a parameter of 1e-4 was used. The dataset used was MNIST, consisting of grayscale images of handwritten digits. The even digits were labeled as P class and odd digits as N class. The learning rate schedule in Keras for Fashion-MNIST involved a decay factor chosen from a set of values. Fashion-MNIST is a grayscale image dataset with 10 fashion item classes. It was converted into a binary classification dataset with 'P' and 'N' classes. The SVHN dataset consists of color images of street view house numbers from 0 to 9. 100,000 data points were sampled for training from the training and extra training data. The model and optimizer used were the same as for MNIST, with an initial learning rate of 1e-4. The model used for the SVHN dataset was AllConvNet BID45 with specific layers and parameters. The dataset consists of 60,000 color images in 10 classes with 5,000 training images and 1,000 test images per class. The CIFAR-10 dataset also had specific classes like 'bird'. The CIFAR-10 dataset consists of 60,000 color images in 10 classes with 5,000 training images and 1,000 test images per class. The P class includes 'bird', 'cat', 'deer', 'dog', 'frog', and 'horse', while the N class includes 'airplane', 'automobile', 'ship', and 'truck'. Optimization setup was similar to SVHN, with a regularization parameter of 5e-3 and initial learning rate of 1e-5. Experimental results comparing sigmoid loss and logistic loss on MNIST showed similar classification errors, with sigmoid loss slightly better. When varying n and n, the impact of covariate shift was investigated. Testing UU and CCN on MNIST with n fixed at 20,000 and gradually decreasing n from 20,000 to 4,000 showed that as n moved farther from n, UU was slightly affected while CCN was severely affected. This indicates that CCN methods do not align well with the problem setting."
}