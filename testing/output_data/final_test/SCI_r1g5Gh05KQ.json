{
    "title": "r1g5Gh05KQ",
    "content": "The paper introduces Advanced Neuroevolution, an optimization algorithm designed to train deep neural networks as an alternative to SGD. It was tested on the MNIST dataset and global optimization problems like the Ackley function, outperforming algorithms like PSO and ES. The paper introduces Advanced Neuroevolution as an alternative to SGD for training deep neural networks. It outperformed algorithms like PSO and ES on the MNIST dataset and global optimization problems. The paper introduces Advanced Neuroevolution as an ensemble of low-level algorithms for training deep neural networks efficiently without gradients. It addresses different levels of abstraction in the search process and can be used for other optimization tasks beyond neural networks. The paper introduces Advanced Neuroevolution as an evolutionary optimization algorithm focused on training deep neural networks efficiently without gradients. It aims to complement existing global optimization algorithms like Evolution Strategies and Particle Swarm Optimization, offering another option with its own merits and limitations. Performance evaluation can be done using benchmark functions like Rastrigin or Ackley. Other approaches using evolutionary optimization techniques for training DNNs have been explored in recent research, reflecting the need for alternatives to SGD. The algorithm aims to complement existing optimization methods like Evolution Strategies and Particle Swarm Optimization, offering another option for training deep neural networks efficiently without gradients. It addresses limitations in learning potential caused by the use of SGD, which can lead to fluctuations in model performance during training iterations. The algorithm proposed aims to address limitations in learning potential caused by SGD, which can lead to fluctuations in model performance during training iterations. It seeks to train neural networks by evolving a pool of agents, maintaining the best performing agent throughout the process. This approach is different from SGD and offers a gradient-free alternative for efficient training of deep neural networks. The paper introduces a new approach to training neural networks by evolving a pool of agents, which allows for exploration and exploitation. It aims to improve upon existing algorithms by addressing issues such as sparse-rewards, high-dimensionality, and computational efficiency. The field of evolutionary computation offers promising implementations, such as neuro-evolution. The paper introduces Advanced Neuroevolution (AdvN), an evolutionary optimization algorithm for training neural networks. Unlike other approaches, AdvN evolves the weights of networks rather than architectures. The authors test AdvN on a large-scale model for the MNIST classification task to evaluate its performance. The paper introduces Advanced Neuroevolution (AdvN), an evolutionary optimization algorithm for training neural networks. AdvN is benchmarked against other optimization algorithms on global optimization functions and tested on the Easom function to evaluate its behavior in scenarios with near-zero gradients. Additionally, AdvN and SGD are tested on the MNIST dataset under special conditions to assess adaptability to training challenges. The algorithm consists of smaller, locally-aware algorithms and functions working together synergistically towards a global objective. The algorithm introduced, Advanced Neuroevolution (AdvN), utilizes its own notation to avoid traditional evolutionary optimization terminology. It employs a fixed-size pool and network structure, unlike other algorithms. The initial pool consists of random samples chosen based on a weight initialization scheme, with subsequent iterations following suit. The Advanced Neuroevolution (AdvN) algorithm utilizes a fixed-size pool with components like Elite, Anchors, Probes, and Blends. Elite is the best-performing sample, Anchors are top N samples, Probes are clones of Anchors with random perturbations, and Blends can occur between samples. The Perturbation step introduces noise into the system, serving as the primary searching mechanism. The algorithm utilizes uniformly-distributed noise as the primary searching mechanism, with the search radius determining the explorative vs. exploitative properties. The search radius is calculated based on the integrity value and two constants, using a shifted, scaled hyperbolic tangent function for control. The number of selections in the algorithm is determined by a function that starts at the origin and increases until it saturates near the top, limiting the modifications in the network. This prevents excessive adjustments in one step and controls exploration in high-energy regions. The experimenter chooses constants before starting the algorithm. Blending mechanism randomly selects weights from 2 components to create a blend. The blend allows exploration of unreachable regions in the search space, potentially transporting samples farther away from the current region. In our algorithm, elites are defined as the best-performing samples in the current pool and across all generations. The integrity concept determines the extent of perturbations, with lower integrity leading to greater changes. Neural networks are updated incrementally rather than in bulk. In the algorithm, perturbations and blends are controlled by thresholds set as parameters. Integrity decreases if the current samples do not improve the score by the defined Minimum Entropy percentage. Backtracking helps regulate behavior. Backtracking is a mechanism that resets integrity and inserts the historical elite to explore high-energy configurations more safely in the search space. This process helps prevent the model from becoming \"hot\" and weights from exploding, similar to simulated annealing. Anchors are the main search mechanism used in this process. Anchors are the main search mechanism in a process similar to simulated annealing. They represent the best performing agents and are updated each generation. Probes are spawned as clones of anchors to search local neighborhoods. Multiple anchors and probes are used to search multiple regions and local neighborhoods efficiently. Distance between anchors is calculated based on differences in weights. The Canberra distance is used to define a minimal distance between anchors to avoid searching the same region. Radial expansion adjusts perturbations to keep samples far apart, maintaining a full roster of anchors. If anchors are too close, some may be lost, but the remaining slots are used by the blending algorithm. The blending algorithm utilizes radial expansion to increase search space and diversity by casting probes farther from anchors. This mechanism plays a significant role in training networks for the MNIST task. The algorithm operates in two steps: a conditioning step that selects anchors and elites based on current and previous states, and an execution step. The algorithm for forming a pool through perturbation and blending steps is implemented in PyTorch framework BID16. A pool size of 50 samples is used across the experiment set. Common network architectures are employed, but there is potential for tailored architectures. Performance is influenced by architectural choice, but optimizing it is not within the scope of this work. 4 Nvidia Titan V GPUs are used for data processing. We use 4 Nvidia Titan V GPUs for data parallelization, dividing the dataset into 4 chunks. Our experiments showcase the algorithm on various tasks, benchmarking against global optimization algorithms using Inspyre and PyBrain libraries. Tuning parameters is not covered in this paper. Testing on 7 functions, convergence is defined as reaching a certain criteria. The study presents the convergence criteria for global optimization, using a regression approach with a neural network architecture. The network has a single hidden layer of size 128 and accepts 2-dimensional inputs. Input coordinates are randomly selected from specific uniform distributions for each function. The study uses benchmark functions like Rosenbrock, Schwefel, Bukin, Easom, and Eggholder, all within specific ranges. Algorithms are run for a maximum of 5000 generations, noting non-convergence with a \"+\". Special functions with unique properties, like the Easom function, are also tested to challenge gradient-following algorithms. These special functions are not used for benchmarking. In experiments, the algorithm was tested on a simple CNN model with 4 convolutional layers and a fully-connected layer using Parametric ReLu activation in PyTorch. The model had 4.7M parameters and was trained on a subset of 2000 images from the MNIST dataset. Validation was done on the entire set of 10,000 images to test generalization and learning capacity. The algorithm was tested on a simple CNN model with 4 convolutional layers and a fully-connected layer using Parametric ReLu activation in PyTorch. It was trained on a subset of 2000 images from the MNIST dataset and validated on 10,000 images to assess generalization and learning capacity. The test is terminated once the algorithm achieves a loss of 0.15 or lower, or if the number of generations exceeded 5000, to prevent diminishing returns. The goal is not to exceed the state of the art in MNIST classification, but to showcase performance in a high-dimensional search space. The algorithm is also tested on common global optimization functions and compared with other optimization algorithms like Evolution Strategies. The algorithm showcased strong performance in solving benchmarking functions efficiently, including the challenging Eggholder function with a small pool size of 50 samples. It demonstrated effective exploration in functions like Easom and Bukin, outperforming gradient-following algorithms. The Bukin function has a narrow ridge where the global minimum lies, but if exploration steps are too large, the algorithm may skip over it. Results were achieved with the same parameters for all functions, showing the algorithm's agility to handle varying conditions. A sample run showed convergence to a training loss of 0.15 after 2333 generations, with a validation accuracy of 90%. The algorithm achieved a validation accuracy of 90% after 2333 generations. It required significantly more inferences compared to SGD, which converged in around 16,000 inferences. The model achieved acceptable accuracy with only 2000 images, without shuffling them. The Advanced Neuroevolution algorithm successfully trained a 4.7M parameter network, showing potential for training deeper, wider networks on complex tasks. Half-precision did not hinder the algorithm, indicating promise for future iterations on Volta architecture GPUs. The algorithm was presented as an alternative to SGD, addressing limitations of gradient-based methods. The Advanced Neuroevolution algorithm outperformed other optimization algorithms on typical problems and achieved 90% accuracy on the MNIST digit classification task using only 2000 images. It utilized half-precision floats and 4 Titan V GPUs, making it more tractable in terms of resource requirements. Preliminary tests on RL tasks have shown promising results. The algorithm showed promising results in preliminary tests on RL tasks, solving assigned problems but taking longer than other approaches. Efforts are being made to enhance the algorithm and strategies for better performance in RL and Robotics tasks."
}