{
    "title": "rJMK4bD6vE",
    "content": "Automated planning on general semantic services is becoming increasingly important due to the variety of available services with different parameters and effects. Existing planners often only consider PDDL, and those claiming to use OWL-S usually translate it to PDDL, losing semantic information in the process. In this paper, a new domain-independent heuristic based on semantic distance is proposed for automated planning of semantic services described with OWL-S. The heuristic is calculated at runtime to provide more relevant information, resulting in better results in less time compared to established techniques. The need for a heuristic in AI planning is motivated by the computationally intractable search space of domain-independent planners for large problems. Domain-specific planners can easily provide heuristics for specific purposes, but for agents creating general plans, a heuristic like the proposed semantic distance is essential. The creation of heuristics during runtime is essential for agents creating general plans, as domain-specific heuristics are not sufficient. Reusing old heuristics or applying meta-heuristics have limitations, requiring a learning phase to gather information about the problem. The calculation of heuristics during runtime is motivated by additional information available, such as grounding information, leading to the encounter of new concepts in AI. During runtime, heuristics are created dynamically to adapt to changing goals and services, enhancing their usefulness in determining the distance from a state to a goal. This dynamic approach allows heuristics to incorporate additional information, such as service descriptions, to prevent loss of relevant data. For a formal description of heuristics and their properties, refer to (Pearl 1985). During runtime, heuristics are dynamically created to adapt to changing goals and services, improving their effectiveness in measuring the distance to a goal state. Understanding the functionality of a service can be challenging as interpretations may vary in different contexts. A goal-oriented heuristic approach is utilized for problem-solving, focusing on the semantics of the goal and capability descriptions. This approach aims to find a plan that solves the problem efficiently. The heuristic is designed for a one-shop planning problem, aiming to minimize the learning phase by quickly identifying useful capabilities based on goal and capability descriptions. It evaluates the usefulness of capabilities and estimates the fulfillment of preconditions to determine which ones are more likely to be executed. This dynamic approach adapts to changing goals and services during runtime. The heuristic created for a one-shop planning problem aims to quickly identify useful capabilities based on goal and capability descriptions. It evaluates capability usefulness and estimates precondition fulfillment to determine likely executions, adapting dynamically to changing goals and services during runtime. The state of the art in general heuristics for planning is discussed, with a focus on different approaches identified in the AI planning community over the last 28 years. Specializations of the general planning domain often involve translating the semantic domain to classical STRIPS planning in formats like PDDL. Service composition approaches in planning focus on Quality of Service and model checking. Classical planners are optimized for specific problems like the 15-puzzle or towers of Hanoi, while semantic general-purpose planning requires more general heuristics such as minimal step count to the goal. Different planning approaches address the search for a plan in various ways. The curr_chunk discusses the use of greedy heuristics in planning, specifically focusing on a heuristic derived from STRIPS planning problems. This heuristic is admissible and is based on executing services with the highest overlap of their add-list and the goal first. It is noted as being simple yet effective, and has been used in successful planners according to the International Planning Competition. The approach of BID6 has been extended by an optimization with an abstraction of the effects called Patterns BID7. Patterns are subtracted from each effect and the start and goal states to create abstract states, which are then mapped to the state space. However, Pattern Database Heuristics (PDB) do not scale up to real-world problems. BID11 optimizes the result of BID7 by adding a Causal Graph structure and Domain transition graph to the PDB heuristics. The text discusses the use of causal graph structural patterns in planning problems, specifically in the context of the SAS+ formalization. It mentions restrictions such as \"Post-uniqueness\" and \"Binariness\" which may not be applicable in an open world assumption and distributed service development. Learning domain structure through observing plans is still an area of research, with models like action cost proposed by Gregory and Lindsay. The text discusses the use of action cost models in planning problems, focusing on understanding services in plans. It mentions the limitations of learning domain structure through plan observation and emphasizes the study of services' understanding in intellectual problems. The approach of trial and error mechanisms for learning service usefulness is discussed, with a focus on deterministic actions. Other research on heuristic creation in uncertainty is mentioned but not explored further in this work. The text discusses using landmarks to guide search through the state space in planning problems. Landmarks are facts that must be true on the way to a goal, and they can be used to create a heuristic for decomposing the search problem. The LAMA planner combines greedy heuristic search with landmarks and preferred operators to improve search efficiency. In service planning, preferred operators are kept in a queue and tried first as part of a heuristic. The problem is formalized as a SAS + problem, allowing for the identification of landmarks to guide the search. Existing heuristics are based on problem abstraction, but lack the use of planning problem semantics. A new heuristic for service planning is proposed in this work. The proposed heuristic for service planning involves using Semantic Distance between states to solve a constraint satisfaction problem. A variation of the A* algorithm is used, where the cost function is minimized by selecting g as the cost of the path so far. Semantic Decomposition is performed to determine the semantic distance between states using a Marker Passing algorithm. The semantic decomposition algorithm looks up definitions and relations of a word in sources like Wikipedia or WordNet. It recursively decomposes related words to create a graph representing the connectionist interpretation of meaning. Functions like AddRelation and AddConcept are used to add relations and concepts to the semantic graph. This decomposition process helps in creating a semantic graph. The semantic decomposition algorithm creates a graph representing the connectionist interpretation of meaning by recursively decomposing related words. The algorithm builds a hierarchical structure of concepts called lexical units, using semantic primes as the termination criterion for recursion. The algorithm creates a hierarchical structure of concepts known as lexical units. It checks for decomposition depth and prevents redundant decompositions by stopping if a synonym has already been decomposed. Concepts are normalized by removing inflections to reveal the stem. The algorithm creates a hierarchical structure of concepts called lexical units. It normalizes concepts by removing inflections to reveal the stem, including all lexical paradigms and sub-categorization frames. Lemmatization is used for this reduction, integrating syntactic information into the graph. The algorithm creates a hierarchical structure of concepts called lexical units by looking up semantic relations and definitions in dictionaries. It checks if the concept is a semantic prime and simplifies stop word removal. Relations of the concept being decomposed are handled in the process. The Marker Passing algorithm, a generalization of Crestani's algorithm, decomposes concepts by adding relations between them and recursively decomposing connected concepts. Definitions are decomposed by connecting them to the definiendum via \"definition\" relations. Crestani's algorithm involves Pre-adjustment, spreading, post-adjustment, and termination condition evaluation steps, which can lead to inaccurate interpretations. To address this, a more precise description breaks down the activation into multiple steps without losing generality. The algorithm described is an extension of Crestani's spreading activation algorithm, which involves building up activation levels in nodes until a threshold is reached, selecting activated nodes to spread to neighbors. This process continues until a termination condition is met. The algorithm extends Crestani's spreading activation method by passing concepts and markers through different functions in four blocks, activating edge-functions and in-functions to propagate activation levels in nodes. The algorithm extends Crestani's spreading activation method by passing concepts and markers through different functions in four blocks, activating edge-functions and in-functions to propagate activation levels in nodes. The after-send-function is activated to fix markers on source concepts if needed, allowing for the analysis of marker passing to services based on goal-oriented heuristic composed of closeness to start and goal states. Marker information and parameters can be found in BID4. Two measurements were selected for the heuristic to avoid goal overcommitment. The algorithm extends Crestani's spreading activation method by passing concepts and markers through different functions in four blocks, activating edge-functions and in-functions to propagate activation levels in nodes. The after-send-function is activated to fix markers on source concepts if needed, allowing for the analysis of marker passing to services based on goal-oriented heuristic composed of closeness to start and goal states. Goal overcommitment and low hanging fruits are two effects that occur when focusing on usefulness and executability of services in the planning process. The algorithm enhances Crestani's spreading activation method by passing concepts and markers through different functions in four blocks to propagate activation levels in nodes. It introduces two weights that adapt based on the search progress towards the goal, prioritizing executability in the beginning and usefulness as the search progresses. Predicates from service preconditions and start axioms are compared using a sentence similarity measure to check fulfillment. The algorithm enhances Crestani's spreading activation method by comparing predicates using a sentence similarity measure to check fulfillment. The sentence similarity measure compares predicates with a semantic similarity measure and aggregates the results. The main difference is that the sentence similarity measure carries information about the sentence they started from, which is used in the interpretation of markers. The algorithm improves Crestani's spreading activation method by using a sentence similarity measure to compare predicates. The AvgActivation calculates the average activation of concepts activated by markers in both sentences, resulting in a normalized similarity value between 0 and 1. This method considers the ratio of equivalent words in both sentences and the activation of concepts, capturing semantic closeness. The algorithm enhances Crestani's spreading activation method by using a sentence similarity measure to compare predicates. It calculates the Distance between two states using measures d sen and d sem, which are then used to determine usefulness UF and executability E. The service's usefulness is determined by the maximal weighted name and arguments match over the set of subgoals, with argument matching based on the structure of goal and effect predicates. Semantic closeness is calculated based on predicate name and arguments, weighted to define similarity. The algorithm improves Crestani's spreading activation method by using sentence similarity to compare predicates. It weighs predicate name and arguments to maximize argument matches and effects fulfillment for a given goal. Predicate comparison is based on semantic similarity, while argument comparison is based on semantic similarity measure proposed in BID4. The argument comparison in the algorithm is independent of order, normalized w.r.t. number of predicates in the goal. H(S, Z) becomes 1.0 for a service fulfilling all goal predicates, and 0.0 when none fulfill the goal. Executability (E) is calculated similarly to usefulness. Services are evaluated based on fulfilled preconditions, avoiding those with unsatisfied preconditions. The search algorithm prioritizes services based on weight on usefulness and executability. The Secure Agent-Based Pervasive Computing (Scallop) domain contains 21 services in health, air travel, and medical transport. The problem involves transporting a patient to a hospital, including finding the nearest airport and organizing ground transport. The services and domain have been translated to OWL-S 1.2 for technical compatibility. The Scallop domain involves organizing flights and ground transport for medical purposes. A flight account must be created, a suitable flight booked, and transport to the hospital arranged. The goal is to transport a victim to a medical destination, with 64 axiomatic facts needing fulfillment. The domain is modeled in an ontology, detailing individuals and their relations. The Scallop project involves organizing flights and ground transport for medical purposes. The domain is modeled in an ontology, describing individuals and their relations. The initial state declares facts about available transports, such as Vehicle Transports and Flights. The goal state consists of the information needed to fulfill the desired outcome, including declaring individuals required for treatment at a specific hospital. The goal of the Scallop project is to organize flights and ground transport for medical purposes. The plan involves booking a flight for \"Patient 0\" using their credit card, ensuring arrival at the target destination on time. \"Patient 0\" needs a personal account to book flights and transports. The plan includes identifying individuals needed for the journey and the departure/arrival airports. The optimal plan consists of 4 steps, including two flight requests. The planning problem in the Scallop project involves 4 steps: requesting flight information, creating a flight account, and booking flights. The goal state is specified as a set of OWL axioms, leading to an infinite search space. Evaluation of the planner's performance is based on the number of extended nodes during the search for the goal state. The Greedy heuristic is still considered the 'gold standard' for general purpose heuristics. The evaluation of different heuristics in the Scallop project involves comparing results with the Uniform Cost distribution and the Random heuristic. The average results of ten runs are shown in TAB3, with columns describing the mean and standard deviation of steps and time. A step is an extended state during the search for the goal state. The heuristics are tested on the same start and goal state to ensure consistency. The evaluation of different heuristics in the Scallop project involves comparing results with the Uniform Cost distribution and the Random heuristic. The heuristics are tested on the same start and goal state to ensure consistency. The performance variation is due to random selection of services with the same usefulness. The greedy heuristic, considered the 'gold standard' for general purpose planning, prioritizes services with the most overlap with the goal. This can result in repeated testing of the same services in each state. The evaluation of goal overlap takes a similar amount of time as the semantic heuristic. The average step calculation time for greedy is 6.0 seconds, close to the 5.2 seconds for the marker passing heuristic. The standard derivation of steps for the greedy heuristic is 2.6, which is close to the 5.2 seconds spent by the marker passing heuristic on each state. The Random cost heuristic serves as a baseline, and if a heuristic performs worse than this, it creates more confusion than guidance in the search process. The creation of a random number consumes minimal resources and provides no information to the search. The random heuristic does not speed up the search process and looks at the most state in the search space. The use of semantics in the marker passing heuristic reduces the standard derivation, gathering more useful information than just comparing the overlap with the goal. The random selection of services with the same heuristic value leads to imprecise results. The heuristic used in academia for planning problems lacks precision, especially when analyzing grounded actions. Problems are formalized in PDDL with limited semantics, often scaled up to increase difficulty. In toy domains, specific services are essential for problem-solving, focusing on arranging them in the correct order. In general planning, selecting the right services is crucial to establish a domain and achieve the goal. The heuristic always returns a value between zero and one, indicating room for improvement. The heuristic used in academia for planning problems lacks precision, especially when analyzing grounded actions. Problems are formalized in PDDL with limited semantics, often scaled up to increase difficulty. In toy domains, specific services are essential for problem-solving, focusing on arranging them in the correct order. The heuristic always returns a value between zero and one, indicating room for improvement. The optimal selection of weights w1 and w2 needs further analysis. The heuristic benefits from using semantic information, but it remains to be seen if the effort of describing services with additional semantic information is worth it. Future work includes using executability as cost and adjusting the goal by removing fulfilled subgoals for the heuristic calculation. Additionally, a fastforward planner is being implemented by removing reasoning for consistent states during the search."
}