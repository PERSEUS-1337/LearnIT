{
    "title": "HyyP33gAZ",
    "content": "In this paper, the properties of GANs using class label information are studied. The proposed AM-GAN outperforms other baselines and achieves a state-of-the-art Inception Score on CIFAR-10. The Inception Score mainly tracks the diversity of the generator, and a new metric called AM is proposed to reflect true sample quality. The proposed AM Score metric aims to provide a more accurate estimation of sample quality in GAN models. Despite the success of GANs in various tasks, including image generation and manipulation, current models struggle with producing convincing samples on datasets with high variability. Utilizing class labels has been found to significantly improve sample quality in GAN models. GAN models like CatGAN BID20, LabelGAN BID19, and AC-GAN BID18 utilize class labels to improve generation quality and stability. The mechanisms behind these models have not been fully explored BID6. This paper mathematically studies GAN models with class labels, deriving the class-aware gradient for LabelGAN BID19. It also shows that AC-GAN BID18 can be seen as a GAN model with a hierarchical class discriminator. The paper discusses potential issues in previous GAN models and proposes a new method with explicit target class for clearer gradient guidance to the generator. It compares the effectiveness of introducing specific real class logits in the discriminator versus training an auxiliary classifier. The importance of adversarial training in the auxiliary classifier is highlighted to prevent mode collapse and low quality samples. Additionally, the paper suggests dynamic labeling to avoid intra-class mode collapse and introduces a new model named Activation Maximization Generative Adversarial. The paper introduces a new model called Activation Maximization Generative Adversarial Networks (AM-GAN) to address issues in previous GAN models. It achieves state-of-the-art Inception Score on CIFAR-10 and proposes a new metric, AM Score, to measure sample quality accurately. The paper also discusses the limitations of the commonly used Inception Score and presents controlled experiments to support their findings. The paper introduces AM-GAN as a new solution to the overlaid-gradient problem of LabelGAN. It also discusses important extensions like dynamic labeling and activation maximization view. Additionally, it proposes a new metric, AM Score, and empirically compares AM-GAN to baseline models in Section 7. In the original GAN formulation, the loss functions of the generator and discriminator are defined for binary classification between real and generated samples. The framework has been extended to a multi-class case with associated class labels, and the loss functions are defined in terms of cross-entropy. This model is referred to as LabelGAN. The LabelGAN model extends the original GAN framework to incorporate class label information. AC-GAN introduces an auxiliary classifier for real classes, with a variant defined as AC-GAN*. Each sample in AC-GAN has a target class y, and a loss on the auxiliary classifier is added to the generator. The modified AC-GAN formulation adds a loss on the auxiliary classifier w.r.t. the target class y to the generator. This version omits the loss that encourages the classifier to classify fake samples to their target class. Additionally, the generator also adopts the -log(D_r(x)) loss. The class-aware gradient in the discriminator helps refine samples towards specific classes, improving generation quality. The curr_chunk sheds light on how class label information improves generation quality in LabelGAN. It introduces Lemma 1 on gradient properties of cross-entropy loss. The gradient of L lab G (x) w.r.t. the logits vector l(x) is discussed, along with addressing the overlaid-gradient problem in Figure 1. The curr_chunk discusses how assigning specific target classes to generated samples in LabelGAN improves generation quality by considering label information in the gradient calculation. The gradient for each sample is optimized towards being one of the real classes, leading to refined generation in a probabilistic sense. LabelGAN aims to improve sample quality by refining generated samples towards specific classes. While inspired by previous works like BID4 and AC-GAN, LabelGAN suffers from the overlaid-gradient problem where all real class logits are encouraged simultaneously, leading to a weighted averaging of gradients from multiple label predictors. The revised LabelGAN, named Activation Maximization Generative Adversarial Networks (AM-GAN), assigns each generated sample a specific target class to resolve the overlaid-gradient problem. This approach ensures that each sample is classified with high confidence to a single class by the discriminator. The only difference between AM-GAN and LabelGAN lies in the generator's loss function. AM-GAN and AC-GAN are different in their approach to assigning specific target classes to samples. AM-GAN conducts adversarial training among all classes, while AC-GAN only does so at the real-fake level. The generator's loss function in AM-GAN can be decomposed using a cross-entropy lemma. The loss function of the generator in AM-GAN can be decomposed into a combination of LabelGAN and auxiliary classifier. AC-GAN, on the other hand, combines vanilla GAN with the auxiliary classifier. The generator in CatGAN optimizes entropy to ensure high confidence in class assignment, while AM-GAN achieves this through cross-entropy with a target distribution. The AM-GAN combines CatGAN and LabelGAN, extending the discussion in Appendix B. AC-GAN is reformulated as a K+1 classes model, introducing an auxiliary classifier for leveraging class label information. In contrast, AM-GAN is a non-hierarchical model where all classes stay at the same level in the discriminator. AC-GAN * is a hierarchical model with adversarial training at the real-fake two-class level, missing in the auxiliary classifier. Adversarial training is crucial for global convergence in GANs. When samples collapse to a certain point, they are more likely to receive a lower score from the network. Without adversarial training, a mode-collapsed generator would not improve. In experiments, AC-GAN is prone to mode collapse, but reducing the weight of auxiliary classifier losses can help. Introducing extra adversarial training in the auxiliary classifier improves AC-GAN's training stability and sample quality. AM-GAN, a non-hierarchical model, naturally conducts adversarial training among all class logits. Predefining each sample with a class label can result in a conditional GAN, and assigning each sample a target class based on discriminator probability is a possible solution. Dynamic labeling, based on the current probability estimated by the discriminator, is a beneficial approach for GAN models like AM-GAN and AC-GAN. It helps prevent intra-class mode collapse and allows for smooth interpolation across classes in the latent space. This technique enables GAN models to generate from pure random noises, improving sample quality and training stability. The Activation Maximization Generative Adversarial Network (AM-GAN) utilizes an Adversarial Activation Maximization Process during training to ensure high-quality samples that confuse the discriminator. This approach helps prevent mode collapse and improves sample quality and training stability. In AC-GAN, mode collapse is attributed to the lack of adversarial training in the auxiliary classifier. An extra loss is introduced to enforce adversarial training, improving performance consistently. This additional loss ensures high activation on a certain class, enhancing sample quality and avoiding mode collapse. According to experiments, adding an extra loss in AC-GAN improves stability and reduces mode collapse but results in a lower Inception Score. This is because encouraging the auxiliary classifier to classify fake samples to their target classes reduces its ability to provide gradient guidance for real classes. Inception Score mainly measures diversity, and a new metric called AM Score is proposed as a compensation. The AM Score is proposed as a compensation for Inception Score in evaluating generative models. Inception Score measures sample quality using class probability distribution, while AM Score considers entropy for diversity measurement. Inception Score evaluates generated samples based on diversity and quality, but it may be problematic for datasets with uneven class distribution. The value of H(C G ) measures diversity, while \u2212E x [H(C(x))] assesses sample quality. The Inception Score measures diversity and sample quality, with H(C G ) expected to increase but often decreases in practice. H(C(x)) values on CIFAR-10 data are variable, indicating a preference for certain samples. Experimental findings show H(C G ) values decrease during training, while H(C(x)) scores vary, preferring some samples over others. The Inception Score measures diversity and sample quality, with a preference for certain samples observed. Inception Score works as a diversity measurement, requiring each sample's distribution to be highly different from the overall distribution of the generator. A low Inception Score is typically associated with a mode-collapsed generator. The Inception Score is typically low for a mode-collapsed generator, with a minimal score of 1.0 if all samples collapse to a single point. To simulate mode collapse, synthetic experiments drop points and evaluate KL divergence, showing an increase as N - m increases, capturing mode dropping and diversity in generated distributions. The quality of generated samples is not necessarily correlated with mode coverage and sample diversity. Inception Score may not accurately measure sample quality, and an extra assessment using a pretrained classifier is proposed to compensate for this. The optimal classifier for measuring sample quality remains a challenge for future work. An extra assessment using a pretrained classifier is proposed to measure sample quality. The classifier's H(C(x)) can indicate sample quality, with most samples having scores below 0.05. To address uneven class distribution, a KL divergence between C train and C G is used. The AM Score, with a minimal value of zero, measures sample quality, with lower values indicating better quality. Inception Score and AM Score assess diversity and quality of generated samples, while FID BID10 measures distribution distance. To empirically validate the proposed method, experiments were conducted on CIFAR-10 and Tiny-ImageNet 2 datasets. Various metrics were used for evaluation, including Inception Score, AM Score, and FID BID10 to measure sample quality and distribution distance. The study conducted experiments on CIFAR-10 and Tiny-ImageNet 2 datasets, using metrics like Inception Score and AM Score to evaluate sample quality. A modified DCGAN structure was utilized, and visual results of various models were provided in the Appendix. The experiment code is available for further research, and the question of whether training an auxiliary classifier without correlated losses would improve sample quality was explored. In the AC-GAN setting, correlated loss plays a crucial role in improving GAN training. Dynamic labeling was used for fair comparison among different discriminator models. AC-GAN achieves better sample quality than vanilla GAN but still experiences mode collapse. Improved sample quality over vanilla GAN, but sustains mode collapse indicated by the value 0.61 in MS-SSIM. AM-GAN outperforms other models in Inception Score comparison on CIFAR-10. LabelGAN suffers from the overlaid-gradient problem, while AM-GAN achieves the best scores against baselines. AM-GAN achieves high scores in Inception Score, AM Score, and MS-SSIM, outperforming baseline models and reaching a state-of-the-art Inception Score of 8.91 on CIFAR-10. GAN models with class condition tend to face intra-class mode collapse, but AM-GAN shows no obvious mode collapse. During GAN training, balancing the generator and discriminator is crucial to avoid intra-class mode collapse. Switching from dynamic labeling to class condition can make it challenging to maintain this balance. A powerful discriminator may prevent mode collapse but hinder the generator's performance. By finding a suitable discriminator, AM-GAN outperforms other models in various metrics. In the class conditional version, AM-GAN outperforms AC-GAN, with the latter not experiencing mode collapse. However, Inception Score remains low due to decreased sample diversity. Despite some intra-class mode collapse, per-sample quality improves, leading to a lower AM Score. Evidence of partial mode collapse is seen in the difference in | \u2202z | values between dynamic labeling and conditional settings. LabelGAN does not require explicit labels and shows worsened Inception Score and AM Score in the conditional version. The balance between generator and discriminator is crucial in the conditional version of AC-GAN. Using dynamic labeling makes this balance easier, but reverting to the original AC-GAN results in worse Inception Score and AM Score on CIFAR-10. In dynamic labeling setting, Inception Score decreases from 7.41 to 6.48, and the AM Score increases from 0.17 to 0.43. The performance drop in the AC-GAN model on CIFAR-10 is attributed to using different network architectures and hyper-parameters compared to AC-GAN BID18. Despite efforts, the reported Inception Score of 8.25 was not achieved, possibly due to unreported details affecting performance. Further studies are needed to address this gap. Inception Score and AM Score curves are plotted in FIG6, with AM Score showing more stability overall. Increasing sample size can improve Inception Score stability, but it is costly to evaluate. A better Inception Model could offer a solution to this issue. The AC-GAN's curves demonstrate strength in performance. The Inception Model could help solve the performance issues observed in the AC-GAN model. The AM-GAN shows comparable Inception Score with LabelGAN and AC-GAN initially, but they are distinguishable in terms of AM Score. Results from CIFAR-10 experiments support the proposed method's superiority over strong baselines. Generalization of conclusions is demonstrated through experiments on Tiny-ImageNet, a more challenging dataset with fewer samples per class. Downsizing Tiny-ImageNet samples and using the same network structure as CIFAR-10 yields positive results, as shown in TAB0. In this paper, the analysis of current GAN models incorporating class label information shows that AM-GAN outperforms other methods. AC-GAN * + shows better performance than AC-GAN * by solving the overlaid gradient problem. Introducing class logits in a non-hierarchical way in the discriminator usually works better than simply adding an auxiliary classifier. Predefined labeling can lead to intra-class mode collapse, and dynamic labeling is proposed to address this issue. In this paper, the focus is on the proposed AM-GAN model, which demonstrates superior performance compared to strong baselines. The analysis delves into the Inception Score as a diversity measurement and introduces the AM Score for more accurate sample quality estimation. Future work will explore discriminator learning and semi-supervised learning. Additionally, AM-GAN is extended to unlabeled data for unsupervised and semi-supervised learning. The classifier-based evaluation metric in AM-GAN may face issues with adversarial samples, requiring further study. Integrating AM-GAN with models like Wasserstein GAN could be a promising direction. One-side label smoothing, applied only to real samples, is proposed as a regularization technique to avoid extreme logits values. Applying label smoothing to fake samples can lead to a fake mode in the data distribution, which is undesirable. The log(1\u2212D r (x)) generator loss, along with class-aware gradient, is discussed. The issue of gradient vanishing in GAN training is highlighted. The \u2212 log(D r (x)) generator loss with label smoothing is compared, emphasizing the importance of non-zero gradient efficiency. The both-side label smoothed version in GAN training has a strong connection to Least-Square GAN. AM-GAN's auxiliary classifier loss can be seen as a cross-entropy version of CatGAN, combining LabelGAN by introducing an additional fake class. In AM-GAN, the prediction entropy of fake samples is maximized by minimizing the probability on real logits. When using negative label smoothing, a uniform distribution can be defined for the label smoothing part probability, similar to CatGAN. The extension of AM-GAN to unlabeled data is analogous to CatGAN. In a semi-supervised setting, an additional loss can be added to integrate unlabeled data. In an unsupervised setting, an extra loss similar to categorical GAN is introduced. The InceptionScore is a metric for evaluating generative models, correlated with human evaluation. It involves using a pre-trained Inception model to calculate the score based on class probability distributions of generated samples. The Mode Score in BID3 considers the prior distribution of labels, incorporating the overall class distribution from training data. It is shown to be equivalent to the Inception Score, with a lemma demonstrating their equality."
}