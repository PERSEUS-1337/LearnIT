{
    "title": "rkgj0tNfom",
    "content": "Modern Hawaiian orthography includes characters for long vowels and glottal stops, which are crucial for reading comprehension and pronunciation. Two methods are introduced to automate transliteration between older and newer texts: one using finite state transducers (FSTs) and the other a hybrid deep learning approach combining FSTs with a recurrent neural network (RNN). The hybrid approach outperforms the FST method by dividing the problem into parts suitable for each technique. The Hawaiian language faced decline but has since seen a remarkable recovery. However, the missionary orthography used in old newspapers made it difficult for modern Hawaiians to read due to missing phonemes. The modern Hawaiian orthography includes characters for long vowels and glottal stops, crucial for comprehension and pronunciation. Two methods are introduced to automate transliteration between old and new texts: one using FSTs and the other a hybrid approach combining FSTs with an RNN. The modern Hawaiian orthography, developed by Pukui and Elbert, provides a more accurate mapping between graphemes and phonemes compared to the missionary orthography. Manual transliteration of old Hawaiian texts is labor-intensive but crucial for revitalizing the endangered language. Automating this process would make more material accessible to modern Hawaiian audiences. In Section 4, two methods for recovering missing graphemes and phonemes from the missionary orthography are presented. The first method involves weighted FSTs, while the second method uses an FST with a recurrent neural network language model. Both approaches only require modern Hawaiian texts for training. Results from transliteration experiments using a simulated parallel corpus and 19th-century newspaper articles show promising results, with the hybrid FST-RNNLM approach yielding the best results. The hybrid FST-RNNLM approach yielded the best results by combining hand-engineering methods with deep learning in a smaller data regime for an endangered language. The decision to avoid neural machine translation due to limited data availability was influenced by existing literature on machine translation for closely related languages. In prior work, combining FSTs and RNNs has been explored, but a new approximate FST-to-RNN composition algorithm is introduced here. A mapping between Hawaiian orthography and phonemic inventory is discussed, detailing the consonants and vowels. The Hawaiian orthography includes upper- and lower-case variants for consonants and vowels, with vowel length denoted by a macron. Capitalization, numbering, and punctuation follow English conventions. The missionary orthography differs from modern Hawaiian in encoding long vowels and the glottal stop. Foreign words may contain additional consonants. The 19th-century German traveler recorded Hawaiian phrases in the missionary orthography, which were later converted to modern orthography. Mapping modern Hawaiian orthography to missionary orthography involves replacing glottal stops and long vowels. This process results in some information loss due to many-to-one mappings. The transliteration problem addressed in the text seeks to use context to recover information not present in the missionary orthography that modern Hawaiian orthography retains. The study draws on modern Hawaiian texts for evaluation, including Hi'iakaikapoliopele BID6, short texts from Ulukau, and the full Hawaiian Wikipedia. The models were evaluated on simulated missionary-era versions of modern texts and 19th-century newspaper samples with parallel missionary-era and modern text. The text discusses the task of transliterating from missionary to modern Hawaiian orthographies using a combination of hand-designed FSTs and trained language models like RNNLMs. The approach involves constructing a finite state acceptor from the input text, with each symbol represented by a state emitting the symbol. The text describes constructing an FST to model orthography changes when transliterating from missionary to modern Hawaiian orthography. It includes transitions for long-vowel mapping and glottal stops. Additionally, character-level n-gram language models are built and evaluated using modern Hawaiian text. The text discusses using Kneser-Ney smoothing in n-gram language models for predicting modern orthography from missionary orthography in Hawaiian text. The FST language model is denoted as G, and the search graph FST is formed by composing FSTs. The Kneser-Ney-based models were found to perform the best in this approach. The text discusses training a language model on modern Hawaiian orthography to predict modern equivalents of 19th-century newspaper samples. A variant model, C wb, is used to model changes in Hawaiian word-boundary conventions. The text discusses using C wb to predict modern equivalents of 19th-century newspaper samples. An example prediction is provided in Section 6, with more in Appendix A. The FSTs C and C wb transduce between different orthographies and introduce optional spaces after vowels. Additionally, the possibility of combining FST C with an RNNLM is explored for better generalization. The text discusses using RNNs, specifically LSTMs, for language modeling in a hybrid approach with FSTs. The goal is to replace n-gram language models with RNNLMs in the end-to-end FST. While computing the minimum cost path through an FST is straightforward, composing it with an RNNLM is more complex. Nonetheless, a minimum cost path through the composition of the FST and the RNNLM can be defined. The text discusses finding a minimum cost path through the composition of FST and RNNLM using a breadth-first search with beam search. Duplicate beam elements are handled by selecting the lower cost edge. Pseudocode is provided in FIG0. The algorithm discussed in the text combines FST and RNNLM models, referred to as FST-RNNLM. The implementation involves searching over an FST graph using RNN outputs and FST weights. Different variations of the hybrid models are named accordingly, such as FST-RNNLM-C and FST-RNNLM-C wb. End-to-end FST models are denoted as FST-C and FST-C wb, with suffixes indicating the type of n-gram and smoothing used. The text discusses the performance of different n-gram language models and character-level RNNLMs. The best models were highlighted, with the hybrid approach producing the best results. The study focused on the performance of n-gram and RNN language models, with the hybrid approach using RNNLMs yielding the best results. Training was done on a corpus of modern Hawaiian texts due to the lack of parallel texts in the missionary and modern Hawaiian orthographies. Synthetic and real parallel corpora were used to evaluate the accuracy of the approaches. The study evaluated n-gram and RNN language models, with the hybrid approach using RNNLMs showing the best results. A simulated parallel corpus was created by reducing orthography in modern texts and applying end-to-end FST and hybrid FST-RNNLM models to learn a forward mapping between orthographies. Evaluation was done by computing DISPLAYFORM0, a modified character error rate. The strongest models from both approaches are detailed in Table 2. The study compared n-gram and RNN language models, with hybrid FST-RNNLM models outperforming all end-to-end FSTs. The best performing Kneser-Ney n-gram models were FST-C-9GRAM-KN and FST-C wb -9GRAM-KN. Evaluation included %CERR performance metrics and testing on synthetic and newspaper texts from 1867 and 1894. The study evaluated n-gram and RNN language models, with hybrid FST-RNNLM models performing the best. Replacing C with C wb on newspaper texts significantly improved output, especially on the FST-RNNLM model. A new transliteration problem was introduced, mapping between old and new Hawaiian orthographies. The study introduced a new transliteration problem in Hawaiian orthographies, proposing two models to solve it: an end-to-end model using weighted FSTs and a hybrid approach combining FST and RNNLM. The hybrid model outperformed, leveraging a powerful recurrent neural network-based language model despite limited data availability. This research direction shows promise for data-efficient modeling. This paper introduces a procedure to compose an FST with an RNN using beam search. The FST component is crucial as it allows for easy replacement without re-training the RNNLM. Two FSTs, C and C wb, were constructed to demonstrate modularity. Future work could extend the FST to model orthographic changes. An example of input and prediction is provided, showing correct and omitted characters by the model compared to the ground-truth. The paper introduces a method to combine an FST with an RNN using beam search, allowing for easy replacement without re-training the RNNLM. Two FSTs, C and C wb, were created to show modularity. The model's predictions include correct word boundaries, glottal stops, and long vowels, but struggle with uppercase/lowercase transitions. New mappings for consonant substitutions and handling contractions are suggested based on error analysis. The error analysis suggests mappings to delete spaces and handle contractions in the FST. Linguistic knowledge of Hawaiian can be incorporated to improve the hybrid model. Increasing the amount of modern Hawaiian text used to train the RNNLM could further enhance the model. The models aim to semi-automate the modernization of old Hawaiian texts within the community. The error analysis in the current chunk identifies incorrect characters in predictions compared to ground-truth, with specific formatting for errors. The first 10 sentences from Newspaper 1 are provided with examples of input, prediction, and ground-truth text. The error analysis in the current chunk highlights discrepancies between predictions and ground-truth in character recognition. It includes examples from Newspaper 1 showing input, prediction, and ground-truth text for the first 10 sentences. The chunk also mentions the start of planting activities and a local event. Puali Puhiohe Lahui and Kamalii Kawananakoa planted lehua trees together, surrounded by Hawaiian plants, after singing a song. The area was then open for others to plant, with some native helpers present. It is suggested that the planting of flowers may have been a mistake. One specific area was planted first with a sign indicating its beauty. Prediction 4: Puali Puhi 'ohe has arrived there. Prediction 4: Puali Puhi 'ohe Lahui arrived at the beautiful area where lehua trees were planted by Kamalii Kawananakoa. They sang a song and opened the space for others to plant, with native helpers present. It is suggested that planting flowers may have been a mistake."
}