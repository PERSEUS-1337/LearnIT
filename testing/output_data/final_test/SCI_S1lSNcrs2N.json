{
    "title": "S1lSNcrs2N",
    "content": "We present a theoretical framework for practical meta-learning methods that integrates task-similarity formalizations with online convex optimization and sequential prediction algorithms. This approach improves parameter-transfer analyses by adaptively learning task-similarity and enhancing transfer-risk bounds in statistical learning-to-learn settings. It also allows for deriving regret bounds for efficient algorithms in dynamic task-environments or tasks with shared geometric structures. Meta-learning, known as learning-to-learn (LTL), is crucial for multitask learning, changing environments, and federated settings. Meta-learning algorithms aim to perform well on new tasks by using data from multiple training tasks without requiring many samples. Modern approaches leverage deep neural networks for multi-task data representations or neural control of optimization algorithms. Parameter-transfer is a common approach where tasks share a global model to train task-specific parameters efficiently. Gradient-based meta-learning involves metainitialization for quick adaptation to new tasks with minimal samples. The International Conference on Machine Learning (ICML) reviewed the effectiveness of Gradient-Based Meta-Learning (GBML) in various domains such as vision, federated learning, and robotics. There are practical and theoretical questions surrounding the task-relationships GBML can exploit and its success in different settings. Recent efforts have focused on understanding GBML, including its connection to online convex optimization (OCO) and statistical learning theory. These efforts aim to learn a shared initialization for descent methods and provide performance guarantees at meta-test time. ARUBA introduces a new theoretical framework for meta-learning algorithms that can leverage more sophisticated task structures. It treats meta-learning as online learning of losses that bound regret on individual tasks, incorporating task-data and meta-initialization. This approach leads to new or significantly improved meta-learning algorithms. ARUBA introduces new or improved meta-learning algorithms in adaptive meta-learning and statistical LTL settings. It eliminates the need to guess task-similarity beforehand and provides fast rates in the number of tasks with high probability guarantees for a class of losses. ARUBA introduces new or improved meta-learning algorithms in adaptive meta-learning and statistical LTL settings, providing fast rates in the number of tasks with high probability guarantees for a class of losses. It improves upon existing guarantees for GBML algorithms and addresses the issue of learning a fixed initialization in changing environments. Using ARUBA helps in meta-learning the task geometry efficiently. In this paper, ARUBA introduces new meta-learning algorithms for adaptive meta-learning and statistical LTL settings. The algorithm can adaptively determine which directions in parameter-space need to be updated, providing efficient learning over a task-distribution with guarantees for a class of losses. The paper also discusses the theoretical aspects of learning-to-learn and defers the theory for meta-learning in dynamic environments and different task-geometries to the full version of the paper. The statistical analysis of LTL as learning over a task-distribution was formalized by BID4 and expanded upon by BID19. Recent works have built upon this theory to understand modern LTL from different perspectives, such as PAC-Bayesian and ridge regression with a learned kernel. Efforts have been focused on the online setting and lifelong learning framework, with some works exploring shared data representations and efficient online approaches to learning linear embeddings. This work is related to popular shared-representation methods like ProtoNets, while also considering the parameter-transfer setting of GBML. The parameter-transfer setting of GBML, a development from MAML, has been widely used in practice. An expressivity result for MAML shows that the metalearner can approximate any permutation-invariant learning algorithm with enough data and a specific neural network architecture. BID12 demonstrates that the MAML meta-initialization is learnable under strong-convexity and smoothness assumptions using a fixed learning rate. BID16 and BID9 focus on providing finite-sample meta-test-time performance guarantees in the convex setting. The work improves upon previous analyses by considering the case when the learning rate is not known beforehand but must be learned online. ARUBA can handle more sophisticated notions of task-similarity and provide better statistical guarantees than previous approaches. The goal is to design algorithms that result in small task-averaged regret. The current paper focuses on the regret (TAR) BID16, which measures within-task performance by comparing to the best action on individual tasks. The meta-learning problem involves determining the learning rate and initialization for each task. Existing regret guarantees of online algorithms in few-shot learning and meta-learning depend on parameters and data. The regret of OGD for G-Lipschitz convex losses is influenced by the optimal parameter in hindsight. Adaptive methods aim to reduce dependence on initialization, but in our setting with limited data per task, this is not feasible. If the upper bound on task regret is low on average, the TAR of actions due to running OGD will also be low. This approach, explicitly outlined in this work, leverages a joint convex bound in learning rate and initialization for OGD. In this work, a framework called Averaged-Regret Upper-Bound Analysis (ARUBA) is introduced for online learning optimization. It reduces Long-Term Learning (LTL) to online learning of regret upper-bounds, allowing the algorithm to compete with the best parameterization x as T approaches infinity. The meta-learning algorithm studied involves online mirror descent (OMD) or follow-the-regularized-leader (FTRL) with specific parameters and initialization. The text introduces a framework called Averaged-Regret Upper-Bound Analysis (ARUBA) for online learning optimization, focusing on the meta-learning algorithm involving online mirror descent (OMD) or follow-the-regularized-leader (FTRL) with specific parameters and initialization. The algorithm aims to demonstrate task-similarity and adaptability, considering tasks with optimal actions close to an unknown global parameter. The text introduces a framework called Averaged-Regret Upper-Bound Analysis (ARUBA) for online learning optimization, focusing on the meta-learning algorithm involving online mirror descent (OMD) or follow-the-regularized-leader (FTRL) with specific parameters and initialization. The algorithm aims to demonstrate task-similarity and adaptability, considering tasks with optimal actions close to an unknown global parameter. In Setting 2.1, Algorithm 1 achieves TAR DISPLAYFORM0 where D 2 = max t B R (\u03b8 * t ||\u03c6 t ) and R T is the regret of META (2) on a sequence f 1 , . . . , f T of functions of form DISPLAYFORM1. The proof follows from the well-known re- x + x, utilizing strongly-convex coupling for non-Lipschitz functions. Using strongly-convex coupling, the Exponentially-Weighted Online Optimization (EWOO) algorithm is applied to modified loss functions to improve upon the regret of the FTL algorithm. This results in an asymptotic per-task regret of V G \u221a m, which outperforms the minimax-optimal single-task guarantee DG \u221a m when tasks are close in parameter space. The study extends to cases where \u03b8 * t is unknown, utilizing either the last or average within-task iterate for meta-updates. ARUBA provides strong bounds on expected transfer risk in convexR cases and fast rates in strongly-convex scenarios. The algorithm also offers high probability bounds for linear regression. Theorem 2.2 states that if losses are sampled i.i.d. from a distribution Q over task distributions, an algorithm with regret upper-bound RT can be used on each task with regret upper-bound Rt(s t). The algorithm in ARUBA provides strong bounds on expected transfer risk in convex cases and fast rates in strongly-convex scenarios. It also offers high probability bounds for linear regression. If losses satisfy a self-bounding property, there is a high probability bound on transfer risk. In cases of known task-similarity, with expected task-parameter deviation V, the algorithm yields improved results compared to previous methods. Adaptive Gradient-Based Meta-Learning Methods by Zinkevich, M. in Proceedings of the 20th International Conference on Machine Learning, 2003."
}