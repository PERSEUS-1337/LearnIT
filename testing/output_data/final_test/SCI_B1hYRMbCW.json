{
    "title": "B1hYRMbCW",
    "content": "Generative adversarial networks (GANs) have become popular for modeling real data distributions. Wasserstein GANs address convergence issues by minimizing distance using a different metric, introducing a Lipschitz constraint. Weight clipping enforces this constraint, but a regularization term penalizing gradient norm deviation from one improves training. Theoretical arguments and experimental results support using a weaker regularization term for better performance. Generative adversarial networks (GANs) have gained attention for modeling data distributions. Recent advancements focus on stabilizing training with ensemble methods, improved network structures, and theoretical enhancements. Wasserstein-1 distance is proposed for training GANs, offering superior properties for modeling complex distributions. The Wasserstein GAN (WGAN) introduced a new minimization problem by using the Wasserstein-1 distance instead of the Jensen-Shannon distance. To ensure the discriminator function meets the 1-Lipschitz constraint, weight clipping was initially used. An improved training strategy proposed by BID9 involves augmenting the loss with a regularization term penalizing deviations in the norm of the gradient of the critic function. The text discusses the proposal of a less restrictive regularization term for WGANs, highlighting the limitations of the current regularization technique and presenting empirical results supporting the new approach. The new regularization term aims to address issues related to the joint distribution of training and generated samples, as well as the differentiability of the discriminator function. The text introduces the Kantorovich duality theorem in the context of optimal transport theory, defining couplings of probability distributions on R n and presenting a adapted version of Theorem 5.10 from BID19. The theorem involves the set of 1-Lipschitz functions and establishes conditions for two probability distributions on R n. The Kantorovich duality theorem in optimal transport theory states that for two probability distributions on R n, there exists an optimal coupling that minimizes the distance between them. Regularized optimal transport introduces an entropic term to speed up computation, with various approaches available for finding optimal couplings. Regularized optimal transport was extended by BID6 to a broader class of regularization terms \u2126(\u03c0), with connections to a learning algorithm discussed in Section 5. The dual problem introduced by BID3 involves Wasserstein GANs, where the optimization problem is solved through updating generator and discriminator parameters alternately using stochastic gradient descent. The discriminator aims to differentiate between real and generated data, while the generator aims to produce data that fools the discriminator. The WGAN objective is to minimize the Wasserstein-1 distance instead of the Jensen-Shannon divergence. This can be achieved by alternating gradient descent updates for the generating network. The WGAN objective involves minimizing the Wasserstein-1 distance by updating the generating network and 1-Lipschitz function alternately. The generator aims to create realistic data guided by the function values of the critic, which evaluates confidence levels for each data point based on similarity. The critic's role aids in convergence but loses the interpretation of classifying real and fake data. Refer to Appendix A for more details. The WGAN critic function can be modeled by a NN, but enforcing the 1-Lipschitz constraint raises questions. Weight clipping is a simple way to restrict the class of functions that can be modeled by the NN to \u03b1-Lipschitz continuous functions. However, weight clipping may not contain the optimal function within the class of functions modeled by the network. An alternative to weight clipping involves augmenting the WGAN loss with a regularization term to penalize the deviation of the gradient norm of the critic. The WGAN critic function can be modeled by a NN, but enforcing the 1-Lipschitz constraint raises questions. Weight clipping is a simple way to restrict the class of functions that can be modeled by the NN to \u03b1-Lipschitz continuous functions. An alternative to weight clipping involves augmenting the WGAN loss with a regularization term that penalizes the deviation of the gradient norm of the critic with respect to its input from one. This leads to a variant known as WGAN-GP, where GP stands for gradient penalty. The WGAN critic function can be modeled by a NN, but enforcing the 1-Lipschitz constraint raises questions. Weight clipping or adding a regularization term to penalize gradient norm deviation can restrict the class of functions. Norms of the gradients are one \u03c0 * -almost surely on specific points x t. Proposition 1 holds when f * is differentiable and x, y are sampled from optimal coupling \u03c0 * . Sampling independently from marginal distributions \u00b5 and \u03bd may result in points outside the support of \u03c0 * . The optimal cost function f * does not need to be differentiable everywhere. In the examples in FIG0, X represents samples from the generator, O represents real data samples. Optimal couplings \u03c0 * are shown in red, and values of an optimal critic function are shown in blue. The derivation of the condition that the norm of the gradient equals one between generated and real points only holds for points sampled from the optimal coupling. This may not hold in higher dimensions, as not all points lie on a line between some pair of points sampled from \u03c0 * . The optimal critic function values at specific points are crucial. Assuming a value at (1, 2) is zero, the Lipschitz constraint implies a \u2208 [1 \u2212 \u221a2, \u221a2 \u2212 1]. The optimal critic may not be differentiable at these points. An example with discrete probability distributions shows a Lipschitz optimal critic function f*(x) = 1 \u2212 |x|. The optimal critic function values at specific points are crucial, with the Lipschitz constraint implying a \u2208 [1 \u2212 \u221a2, \u221a2 \u2212 1]. The optimal critic may not be differentiable at these points. A proposition shows that the critic indicated in blue is optimal for real data and generated data. If \u00b5 describes real data and \u03bd describes the generative model, then an optimal critic function is given by \u03c6 * (x) = \u2212|x|. The issue of non-differentiability in optimal couplings can be extended to higher-dimensional spaces where deterministic couplings are not always possible. A deterministic coupling assigns each point from one distribution to a point in the other distribution without splitting masses, but in many cases, no deterministic coupling exists. The concept of deterministic coupling is defined, and it is observed that non-deterministic optimal couplings exist between probability distributions over R^n. In optimal couplings between probability distributions over R^n, if there is no \u03bb > 0 with (y \u2212 x) = \u03bb \u00b7 (y \u2212 x), then any optimal critic function f* is not differentiable at x. When the optimal critic is approximated by a neural network (NN), the function modeled by the NN is almost everywhere differentiable. However, having a gradient of norm one in the neighborhood of a non-differentiability is a strong constraint on the approximating function. The regularization of WGANs can be improved by penalizing the violation of the Lipschitz constraint. This involves sampling two points from empirical and generated distributions and adding a regularization term to the cost function. The regularization term is similar to the squared Hinge loss, used to turn a hard constraint into a penalty. Regularization in WGANs can be enhanced by penalizing the violation of the Lipschitz constraint. This involves adding a regularization term to the cost function, similar to the squared Hinge loss, to turn a hard constraint into a soft one. The regularization term enforces the gradient to be smaller than one in norm, implicitly bounding all partial derivatives in norm by one. It is suggested to add the regularization term max {0, ||\u2207f (x)|| \u2212 1} 2 to the cost function. The proposed method WGAN-LP adds a regularization term to the cost function to enforce the gradient to be smaller than one in norm. This method alternates between updating the discriminator and the generator network. The connection to regularized optimal transport is discussed, where a single function is used to approximate the supremum. This leads to an objective of minimizing a specific equation. The regularization parameter \u03bb plays a crucial role in the optimization process of WGAN-GP and WGAN-LP. The infimums of the regularized losses over a class of critic functions are denoted by L_GP \u03bb and L_LP \u03bb respectively. For small \u03bb, the optimal scores are similar, but increasing \u03bb strengthens the soft constraints, making theoretical observations more relevant. The regularization parameter \u03bb is crucial for WGAN-GP and WGAN-LP optimization. WGAN-LP performs better for larger \u03bb values and is less dependent on hyperparameter choice. The Kantorovich duality theorem applies in a general setting, allowing for different metrics like the Wasserstein-p distance. The regularization parameter \u03bb is important for WGAN-GP and WGAN-LP optimization. Experimental results for the Wasserstein-2 distance are provided. The authors suggest using the LP-penalty term instead of the GP-penalty term for Cramer GANs and compare the performance of WGAN-GP and WGAN-LP on different datasets. The generator and critic networks in the study are simple feed-forward NNs with three hidden Leaky ReLU layers. The latent variables dimensionality of the generator network is set to two. During training, 10 critic updates are performed for every generator update, except for the first 25 generator updates where the critic is updated 100 times. The networks were trained using RMSprop with a learning rate of 5 \u00b7 10 \u22125 and a batch size of 256. The study also trained bigger WGAN-GPs and WGAN-LPs on CIFAR-10 to test findings on real-world settings. The study trained WGAN-GPs and WGAN-LPs on CIFAR-10 to test findings on real-world settings. Code for reproducing results is available at the provided link. Level sets of the critic function were evaluated for two-dimensional data sets, showing results after different training iterations. With a penalty weight of \u03bb = 10, WGAN-GP did not learn well, but with a smaller \u03bb = 1, learning was stabilized. The LP-penalty resulted in a good critic even with a high penalty weight. The LP-penalty in WGAN-LP led to a good critic even with a high penalty weight, showing higher regularity in level sets. Training with lower penalty weight yielded similar results. The choice of \u03bb had minimal impact on results, with \u03bb = 10 giving almost the same results as higher values. Comparing critic loss functions without regularization terms, WGAN-LP showed smoother reduction to zero compared to WGAN-GP with \u03bb = 5, which exhibited unstable oscillations. The LP-penalty in WGAN-LP resulted in a good critic even with a high penalty weight, showing higher regularity in level sets. Training with lower penalty weight yielded similar results. The choice of \u03bb had minimal impact on results, with \u03bb = 10 giving almost the same results as higher values. When using the LP-penalty with a very high penalty weight like \u03bb = 100, the same results were obtained, indicating the constraint is always fulfilled for \u03bb = 10 already. Using \u03bb = 1 with the GP-penalty stabilized training but still resulted in fluctuations in the beginning. During training, the cost of minimum assignment is computed based on Euclidean distance between real and generated distributions using the Kuhn-Munkres algorithm. The LP-penalty in WGAN-LP leads to smaller estimated Wasserstein distance and less fluctuations compared to WGAN-GP with \u03bb = 5. Training WGAN-GPs with \u03bb = 1 stabilizes training, showing the importance of choosing the right regularization parameter. Sample quality on CIFAR-10 was evaluated using the same ResNet generator and discriminator as previous experiments. The Inception score was computed using the same ResNet generator and discriminator as previous experiments. WGAN-LP achieved similar or slightly better scores compared to WGAN-GP with small penalty weights, showing stability across different hyperparameter choices. Monitoring the regularization term during training revealed interesting observations, such as the impact of the penalty on sample quality. The regularization of WGAN-GP is highly dependent on the choice of the parameter \u03bb, with penalty contributions from gradient norms smaller than one almost disappearing for \u03bb = 5. Using different regularization terms led to good performance on toy data but worse results on CIFAR-10. Comparison of gradient penalty magnitude during training on CIFAR for WGAN-LP and WGAN-GP with different regularization parameters. The penalty for WGAN-GP penalizing gradients \u2264 1 decreases with a small \u03bb, approaching WGAN-LP. However, with larger \u03bb values, WGAN-GP incurs a higher penalty but suffers in performance. It is suggested to use specific regularization for stable training of Wasserstein GANs. The proposed penalty term for stable training of Wasserstein GANs enforces the Lipschitz constraint and outperforms previous methods. It leads to more stable learning behavior and lower sensitivity to penalty weight values, ensuring smooth convergence and well-behaved critic scores. The regularization term addresses issues with the original GAN discriminator, improving performance. The WGAN's optimal critic function measures the distance between generated and real data, but the interpretation of values as real or fake is lost. This could lead the generator to learn wrong things based on critic function values. The WGAN's optimal critic function measures the distance between generated and real data, but values alone cannot distinguish between real and fake points. An optimal coupling example shows how to connect real and generated data points to achieve equality in Kantorovich duality. The optimal critic function in WGAN measures the distance between generated and real data, aiming to distinguish between real and fake points. An optimal coupling example demonstrates how to connect real and generated data points to achieve equality in Kantorovich duality. The critic function flattens peaks to assign lower values to incorrect positions, as shown in one-dimensional and two-dimensional examples. The optimal critic function in WGAN enforces the Lipschitz constraint, ensuring optimality in the maximization problem. The critic function, represented by a neural network, aims to distinguish between real and fake data points. The coupling example illustrates achieving equality in Kantorovich duality. Weight clipping is not effective for enforcing the Lipschitz constraint in the critic function of WGAN. The common Lipschitz constant\u1fb1 is defined as the minimal \u03b1 such that f(x)\u2212f(y) \u2264 \u03b1||x \u2212 y|| 2 for all x, y and functions generated by the network under weight clipping. The actual value of\u1fb1 can be computed from the network structure. Deep NN with ReLU activation functions have a limited number of optimal functions that exhaust the Lipschitz constraint. The common Lipschitz constraint\u1fb1 is defined as the minimal \u03b1 such that f(x)\u2212f(y) \u2264 \u03b1||x \u2212 y|| 2 for all x, y and functions generated by the neural network. However, weight clipping is not effective in enforcing this constraint in WGAN's critic function. Deep neural networks with ReLU activation functions have a limited number of optimal functions that satisfy the Lipschitz constraint. The Lipschitz constraint for neural networks involves linear functions and ReLU activation functions. The Lipschitz constant \u03b1(f) is determined by the individual functions within the composition of f. To find the optimal function f*, we need to maximize \u03b1(f i ) for linear layers with weight constraint c max and find a sequence of points that satisfy certain conditions. The existence of this sequence shows that \u03b1(f) can be determined. The sequence of points proves the if-direction of the proposition by maximizing the Lipschitz constraint of each layer individually. To find the matrix A (i) maximizing \u03b1(f i ), each vector entry must be maximized in absolute value. The proposition is proven by maximizing the Lipschitz constraint of each layer individually. To find the matrix A (i) maximizing \u03b1(f i ), each vector entry must be maximized in absolute value. For the first linear layer, a matrix A (1) needs to be chosen satisfying certain conditions. A pair (x (1) , y (1) ) is found to ensure specific conditions, leading to unique determination of (x (2) , y (2) ). To maximize the Lipschitz constant of each layer, the matrix A (i) must contain only c max entries. This ensures the Lipschitz constraint for functions generated by the neural net. The derivation from Theorem 5.10 of BID19 leads to the formulation in (i) and the existence of an optimal solution. The formulation in (i) and the existence of an optimal coupling \u03c0 * and an optimal critic function f * are derived from Theorem 5.10. The set \u0393 in part 5.10 (iii) is given by \u0393 = f * \u2208Lip1 optimal \u0393 f * , where f * being optimal leads to a maximum on the RHS of equation FORMULA0. The proof shows that (a) implies (b) and vice versa, with \u03c0 * being optimal if \u03c0 * (\u0393 f * ) = 1 for all optimal f *. The 1-Lipschitz constraint implies that the values of f* must follow a linear function. The partial derivative has a norm of one in the direction from x to y. The direction of maximal descent equals the gradient. Proposition 2 is proven by showing that \u03c6*(x) = -|x| is the optimal critic function for certain distributions. Proposition 5 states that for symmetric continuous functions f and g with certain conditions, the maximum of their difference can be found by transporting parts of g to f. This involves multiplying both functions by a constant to define probability density functions, and finding a coupling to determine the maximum difference. The proof involves finding a coupling \u03c0 between probability distributions defined by f and g, maximizing the difference using Kantorovich duality theorem, and defining \u03c0 1 as a coupling between distributions g 1 and f. The proof involves establishing a coupling \u03c0 between distributions g and f, computing transport costs, and showing optimality using Kantorovich duality. The coupling \u03c0 1 between g 1 and f is defined, leading to the proof of Proposition 2. Proposition 2 states that f and g satisfy certain conditions, leading to the maximum being obtained for a specific function. The proof involves regularized losses of the critic function and the coupling of distributions g and f. The norm of the gradient of a function must be larger than one if there are two directions with an absolute value of one, contradicting the 1-Lipschitz constraint. The effect of GP and LP penalty on regularization was analyzed using different sampling procedures, including local perturbation. The evolution of the critics loss with local perturbation is similar to results with other sampling procedures. Training with the GP-penalty stabilizes at a later stage when noise is only added to training examples, leading to less fluctuation in the critic's loss compared to WGAN-LP. Fluctuations in the approximated Wasserstein-1 distance are larger with the GP-penalty than the LP-penalty, but less severe than when combined with a specific sampling procedure. The critic loss and EM distance decrease smoothly during training on the Swiss Roll dataset, making the Wasserstein-2 distance an interesting metric to explore further. The Inception score evaluates the quality of images generated by a model based on the Inception model, with a higher score indicating better performance. The Inception score is used to evaluate the performance of generative models, with a higher score indicating better quality images. WGAN-GP performs similarly to WGAN-LP for small regularization parameter values but worse for larger values. WGAN-LP shows more stable behavior in terms of critics loss compared to WGAN-GP. Training with a conditional model yielded similar performance for both models. The regularization terms in WGANs with penalty weight 10 showed similar performance for WGAN-GP and WGAN-LP on CIFAR-10. However, these penalties did not lead to good results on CIFAR-10, with regularization initially improving Inception scores but then diverging. Using different regularization terms led to instability in the training process. Inception scores compared for regularization terms with penalty weights 100 and 5, as shown in Figure 18."
}