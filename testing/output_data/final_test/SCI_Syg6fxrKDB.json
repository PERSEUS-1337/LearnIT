{
    "title": "Syg6fxrKDB",
    "content": "We present a graph neural network assisted Monte Carlo Tree Search approach for the classical traveling salesman problem (TSP). A greedy algorithm framework is used to construct the optimal solution by adding nodes successively. The graph neural network captures the graph structure to provide prior probabilities for selecting each vertex. Experimental results show that this method achieves shorter tours compared to other learning-based approaches for TSP. Recent advances in deep learning have provided a powerful way of learning effective representations from data, leading to breakthroughs in various fields. Efforts have been made to apply the deep learning approach to tackle the Traveling Salesman Problem (TSP), which is a well-known NP-hard problem in the literature. Heuristic algorithms have traditionally been used to find competitive tours efficiently, but they rely on handcrafted heuristics and substantial expertise in problem design. The deep learning approach offers a promising alternative for solving TSP by learning effective representations from data. Efforts have been made to apply deep learning to tackle the Traveling Salesman Problem (TSP). Various approaches such as pointer networks, Deep Q-Network, and Transformer-Pointer Network have been introduced to efficiently solve TSP without the need for expert skills or complicated feature design. Our approach combines deep neural network with Monte Carlo Tree Search (MCTS) for solving TSP efficiently. A graph neural network (GNN) is trained to predict the prior probability for each vertex in the partial tour, incorporating edge information for efficient feature extraction. The algorithm may fall into local optimum due to greedy selection, but we aim to overcome this limitation. The paper introduces a Graph Neural Network assisted Monte Carlo Tree Search (GNN-MCTS) to improve decision reliability in solving the Traveling Salesman Problem (TSP). Experimental results show that the proposed method outperforms other learning-based approaches in finding shorter tours. The paper is organized into sections discussing related work, TSP introduction, approach formulation, experimental results, and conclusion. In 1985, Hopfield et al. proposed a neural network to solve the TSP, marking the first attempt to use neural networks for combinatorial optimization problems. Since then, many researchers have worked on improving performance, including the development of shallow network architectures. In recent years, deep neural networks have been utilized to solve the TSP with remarkable results. Vinyals et al. introduced Pointer Net (Ptr-Net) to learn the conditional probability of a tour. Pointer Net (Ptr-Net) is an architecture that uses neural attention as pointers to input vertices to learn the conditional probability of a tour. It can only solve small-scale problems and may generate invalid routes during the beam search procedure. Bello et al. proposed a framework using neural networks and reinforcement learning to tackle TSP, employing Ptr-Net as a policy model to learn a stochastic policy over tours. They masked visited vertices to prevent deriving invalid routes. The Actor-Critic algorithm was introduced to improve TSP performance by masking visited vertices and aggregating input sequences. It outperformed supervised learning approaches, showing better generalization with up to 100 vertices. Kool et al. presented an efficient model for TSP, replacing recurrence with attention layers to remove input order influence. Multi-head attention mechanisms were used to incorporate valuable vertex information. The multi-head attention mechanism is crucial for decisions related to graph vertices. A reinforcement learning method was applied, introducing a greedy rollout policy to improve quality and convergence speed. State-of-the-art performance was enhanced for graphs with 20, 50, and 100 vertices. Deudon et al. also proposed a framework using attention layers and Actor-Critic algorithm to learn a stochastic policy. The framework combines machine learning methods with a heuristic algorithm to improve performance in solving combinatorial optimization problems like the Traveling Salesman Problem (TSP). Dai et al. introduced a framework that combines reinforcement learning with a graph embedding neural network to incrementally construct solutions for TSP and other optimization problems. They utilized a graph embedding network based on structure2vec to capture the current state of the solution and the graph structure. In this paper, a new Monte Carlo Tree Search-based algorithm is introduced to improve the performance of solving combinatorial optimization problems like the Traveling Salesman Problem. This algorithm aims to overcome the limitations of previous methods that relied on greedy policies for vertex selection. The paper introduces a new algorithm based on Monte Carlo Tree Search to solve combinatorial optimization problems like the Traveling Salesman Problem. It aims to find a tour sequence with the lowest cost by training a neural network to select vertices for addition to the tour. The paper introduces a new algorithm based on Monte Carlo Tree Search to solve combinatorial optimization problems like the Traveling Salesman Problem. It aims to find a tour sequence with the lowest cost by training a neural network to select vertices for addition to the tour. The algorithm uses prior probabilities to select vertices greedily, but to avoid local optima, it enhances policy decisions with MCTS and a deep neural network. The approach transforms TSP into a Markov Decision Process and utilizes a GNN architecture for parameterizing f(G|S). The GNN-MCTS method is described for solving TSP in Section 4. The state in the Traveling Salesman Problem (TSP) is an ordered sequence of visited vertices on a graph, with the terminal state being when all vertices have been visited. Transition in TSP involves adding one vertex to the sequence. Actions are selecting vertices from a candidate set, and rewards are based on the change in cost. A deterministic greedy policy is used based on probabilities generated by GNN-MCTS, considering the global graph structure and the current tour sequence. Nodes that have been visited are tagged, and the algorithm aims to summarize the state of the graph based on this tagging. The proposed deep learning architecture based on graph neural networks (GNN) aims to capture local and global graph structure by parameterizing the prior probability of each vertex belonging to a set S in a \"tagged\" graph. This architecture consists of a stack of neural network layers that aggregate local neighborhood information and pass it on to the next layer. The basic GNN model computes new features in each layer using parameter matrices and non-linear functions. It has shown success in combinatorial optimization problems like MIS and MVC. For TSP, edge information is crucial as it is based on edge cost. Edge information is integrated to compute the prior probability map for each vertex. The GNN model uses edge information to compute the prior probability map for each vertex in the tour sequence. New feature expressions are generated for each vertex in the \"tagged\" graph, which are then concentrated into a vector representing the graph context. This vector is input into a multilayer perceptron to output the prior probability. The GNN model integrates the latest node features directly in each update procedure, with parameters of each layer being independent. Edge weights are aggregated using an \"average\" operation to balance node and edge features, enhancing neural network performance. Node features are initialized based on a 3-dimensional vector representing vertex presence in a partial tour sequence. The GNN model integrates node features in each update procedure, with independent layer parameters. Vertex presence in a partial tour sequence is represented by a 3-dimensional vector. The feature tag elements include binary values for vertex presence, coordinates, and first/last vertex in the partial tour sequence. The prior probability of each vertex belonging to the sequence is computed using the new vertex features after T iterations. The GNN model integrates node features in each update procedure, with independent layer parameters. The architecture of the deep neural networks is illustrated in Figure 2. GNN-MCTS uses deep neural networks as a guide in the search tree, storing statistics for each edge. Notable differences between GNN-MCTS and AlphaGo include the evaluation of winning rates in Go games. In the game of Go, the branch with a high average rate of winning indicates strength. Instead of recording average action value, tracking the best action value found under each node's subtree is proposed. In Go, {0, 0.5, 1} is used to denote loss, draw, and win. Adjusting the parameter c puct of UCT can address tour length issues in TSP. Instead of trial-and-error adjustments to c puct, a normalization method is proposed for action values in a node's subtree. A value function combining GNN and beam search is used to evaluate tour length in a game scenario. The GNN-MCTS algorithm uses a value function to guide beam search from the leaf node to the end state, balancing exploration and exploitation. The algorithm iterates over four phases and selects a move to play based on the state with the highest value in the search tree. The GNN-MCTS algorithm uses a value function to guide beam search from the leaf node to the end state, balancing exploration and exploitation. It iterates over four phases: Expansion, Simulation, Back-Propagation, and Play, selecting a move based on the highest value in the search tree. The GNN-MCTS algorithm utilizes a value function to guide beam search through different phases. It compares against various baseline algorithms and deep learning-based methods for solving TSP instances. 50,000 instances are generated for training GNN, with optimal tour sequences obtained using state-of-the-art solvers. The study utilizes Gurobi and Concorde to find optimal tour sequences for TSP instances. N samples are generated based on the optimal tour sequence, and the dataset is split into training, validation, and test sets. Training is done using Adam with 128 mini-batches and learning rate 10^-3 for 30 epochs. GNN-MCTS is guided by pre-trained GNN during testing on 1000 instances for TSP20, TSP50, and TSP100. Parameter settings for GNN-MCTS include c_puct = 1.3, beam width = 1, and varying rollouts for different TSP instances. The method is compared with deep learning-based works focusing on the greedy mechanism. Our Pointer network implementation with supervised learning did not perform as well as reported by Vinyals et al. (2015). Results on random instances show optimality gaps on 20 and 50 vertex graphs. Comparisons with other deep learning-based methods were conducted using suggested experimental settings to achieve similar performance. Running times varied significantly based on implementation (Python or C++) and hardware (CPU or GPU). Despite being slower due to look-ahead search, our method can be optimized by rewriting code to C++. Testing was done on a machine with 32 virtual CPUs and 8 * 2080ti GPUs. Our method, tested on a machine with 32 virtual CPUs and 8 * 2080ti GPUs, showed good generalization to larger TSP instances compared to other learning-based algorithms. The GNN-MCTS procedure's different strategies were analyzed, with the best action value tracked under each node's subtree. Our method, tested on a machine with 32 virtual CPUs and 8 * 2080ti GPUs, showed good generalization to larger TSP instances compared to other learning-based algorithms. Different from AlphaGo, we track the best action value found under each node's subtree for determining its exploitation value. At the end of several rollouts, we select the node with the best action value as the next move in the root position. We also analyze the average action value strategy used in AlphaGo, where we track the average action value found under each node's subtree. Table 1 shows the gap between solutions of our approach with two strategies and the best-known solution for TSP20, TSP50, and TSP100. The empirical results demonstrate that using the \"best\" strategy is significantly better than using the \"average\" strategy for TSP. In a controlled experiment on the TSP test set, different components of the approach were analyzed. Variants included GNN-MCTS-t, GNN-MCTS-v, GNN-MCTS-p, and MCTS for comparison. Results showed the gap between each approach's solution and the best-known solution. The results from GNN-MCTS variants show that GNN prior helps MCTS reduce search space and allocate resources effectively. Using a suitable value function improves MCTS performance compared to random rollout. The developed MCTS efficiently avoids local optima, enhancing overall performance. Experiments explore the impact of different widths on value function accuracy. The value function accuracy is affected by the beam width setting, with performance improving as the beam width increases. However, this improvement comes at the cost of increased time. A trade-off between accuracy and time cost needs to be considered. The GNN integrates edge information to compute new node features, outperforming the basic GNN in extracting information. Performance comparison between the basic GNN and the GNN on random instances supports this claim. The study compares the performance of two GNN models in generating tour sequences for the traveling salesman problem. Results show that the GNN outperforms the GEN model in guiding Monte Carlo Tree Search, leading to shorter tours. The core idea is to convert the TSP into a tree search problem, improving solution quality. The approach converts the TSP into a tree search problem using a GNN that integrates node features and edge weights. A GNN-MCTS is designed to provide scouting simulation, avoiding local optima. Experimental results show shorter tours compared to other learning-based methods, aiming to combine deep learning and classic heuristics for NP-hard problems. The study utilizes the DIMACS TSP Challenge to create Euclidean instances for benchmark tasks. The GNN model has 3 node-update layers and input vectors of size 9. Increasing the number of layers allows nodes to aggregate more information. The GNN is trained with varying layer depths. The GNN model is trained with different numbers of layers on random instances from TSP20. Using prior probability to select vertices, the model shows improved performance with an increase in network layers."
}