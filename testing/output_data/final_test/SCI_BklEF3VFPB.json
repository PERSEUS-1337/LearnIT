{
    "title": "BklEF3VFPB",
    "content": "Domain adaptation involves transferring knowledge from a label-rich source domain to a label-scarce target domain. Domain-adversarial training (DAT) aims to create a domain-invariant feature space but faces challenges like training instability and lack of interpretability. A new approach called Max-margin Domain-Adversarial Training (MDAT) is proposed in this paper, utilizing an Adversarial Reconstruction Network (ARN) to address these issues. MDAT replaces the domain classifier with a reconstruction network to stabilize gradient reversing and achieve feature-level and pixel-level domain alignment. Deep neural networks have achieved success in various tasks but struggle with generalization to new environments due to data distribution discrepancies. ARN conducts feature-level and pixel-level domain alignment effectively without extra network structures, showing robustness to hyper-parameter settings. Empirical results confirm its superiority over other domain alignment methods, with visualized target samples supporting the domain-invariant feature space interpretation. Domain adaptation addresses the discrepancy between training and testing data distributions, known as domain shift. It aims to train a model in a label-rich source domain to generalize well in an unlabeled target domain. Prevailing methods for unsupervised domain adaptation focus on domain alignment to learn domain-invariant features by reducing distribution discrepancy using metrics like maximum mean discrepancy. Ganin & Lempitsky (2015) proposed achieving domain alignment through domain-adversarial techniques. Recently, Ganin & Lempitsky (2015) introduced domain-adversarial training (DAT) for domain alignment, which has been widely adopted in subsequent Unsupervised Domain Adaptation (UDA) methods. However, three critical issues hinder DAT's performance: unbalanced adversarial training, inability to handle pixel-level domain shift, and difficulty in interpreting domain-invariant features. The Max-margin Domain-Adversarial Training (MDAT) approach is proposed to address difficulties in adversarial domain adaptation. It includes an Adversarial Reconstruction Network (ARN) for Unsupervised Domain Adaptation (UDA), utilizing a shared feature extractor, label predictor, and reconstruction network. MDAT focuses on learning domain-invariant features through supervised learning on the source domain and pushing the target domain away from a margin. This approach aims to solve critical issues such as unbalanced adversarial training and difficulty in interpreting domain-invariant features. The Max-margin Domain-Adversarial Training (MDAT) approach addresses critical issues in adversarial domain adaptation by reducing the discriminative capacity of domain classifier, achieving domain alignment without new network structures, and visualizing aligned domains. MDAT with ARN shows significant improvement in UDA benchmarks, is insensitive to hyperparameters, and can enhance any UDA methods leveraging domain alignment. Domain adaptation transfers knowledge between domains. Ben-David et al. (2010) provide an upper bound of the test error on the target domain in terms of the source error and the H-distance. UDA methods aim to minimize the H-distance by reducing metrics like MMD and CORAL. Ganin & Lempitsky (2015) proposed learning domain-invariant features through adversarial training, inspiring many UDA methods. ADDA, CyCADA, and PixelDA leverage GAN for domain adaptation, yielding significant improvement in network complexity. In unsupervised domain adaptation, various approaches like using a decoder network for pixel-level adaptation have been successful. Our approach proposes utilizing the decoder network as a domain classifier in MDAT for feature-level and pixel-level domain alignment. In unsupervised domain adaptation, the model works with labeled dataset X S and unlabeled dataset X T. X S contains N s samples with certain labels from the source domain, while X T has N t samples from the target domain without labels. The architecture includes a shared feature extractor G e, a label predictor G y, and a reconstruction network G r. Adversarial reconstruction training helps G e learn domain-invariant features by reconstructing source samples x s and impeding the reconstruction of target samples x t. In unsupervised domain adaptation, the model utilizes labeled dataset X S and unlabeled dataset X T. The architecture consists of a shared feature extractor G e, a label predictor G y, and a reconstruction network G r. Adversarial reconstruction training aids G e in learning domain-invariant features by reconstructing source samples x s and hindering the reconstruction of target samples x t. The training of Domain Adversarial Training (DAT) is unstable due to an imbalanced minimax game, where the domain classifier D converges quickly with high accuracy, while the feature extractor F struggles to deceive the domain classifier. In unsupervised domain adaptation, the model uses labeled dataset X S and unlabeled dataset X T with a shared feature extractor G e, label predictor G y, and reconstruction network G r. The training of Domain Adversarial Training (DAT) is challenging due to the dominance of the domain classifier D, requiring tuning of hyper-parameters. To address this, a minimax game approach is proposed in MDAT scheme, inspired by max-margin loss in SVM, to make fooling the domain classifier easier for the feature extractor F. The MDAT scheme addresses training instability and feature-level alignment issues in Domain Adversarial Training (DAT) by introducing an Adversarial Reconstruction Network (ARN) and a model with three parts: a shared feature extractor, a label predictor, and a reconstruction network. The learning objectives for the feature extractor and label predictor are to perform well in the source domain by minimizing negative log-likelihood and to make feature learning domain-invariant to achieve high accuracy in the target domain. This is done by designing a decoder network as a domain classifier in the MDAT scheme. The MDAT scheme involves a decoder network G r that reconstructs features in the source domain and pushes features in the target domain away from a margin m. The feature extractor G e learns to make target features indistinguishable from source features. The learning procedure of ARN with MDAT is formulated as a minimax game. The MDAT scheme utilizes a decoder network to reconstruct features in the source domain and push features in the target domain away from a margin. It aims to make target features indistinguishable from source features through a minimax game. Theoretical justifications are provided on how MDAT reduces distribution discrepancy in unsupervised domain adaptation. The upper bound of the expected error for the target domain is reduced by maximizing the domain discrepancy with a margin in the reconstruction network. The feature extractor learns to minimize this discrepancy, leading to improved unsupervised domain adaptation compared to conventional methods. The proposed ARN with MDAT offers stable training and rich domain alignment information, showing strong robustness to hyperparameters and reducing the need for parameter tuning. The method incorporates new merits conceptually and theoretically, utilizing the reconstruction network as the domain classifier to capture more domain-specific features during unsupervised adaptation. The MDAT method enhances domain alignment by capturing domain-specific features and addressing pixel-level domain shift. It also allows for feature visualization to understand the alignment extent and mechanism of adversarial domain adaptation. The proposed ARN with MDAT is evaluated on various UDA tasks to validate its effectiveness through an ablation study. The effectiveness of MDAT and unsupervised reconstruction for UDA is investigated, along with the sensitivity of hyperparameters. The method is evaluated on classic visual UDA datasets and a WiFi-based Gesture Recognition dataset. The CNN architecture used is similar to DANN, with adjustments for the penalty term and margin. The same hyperparameter settings are used for all tasks to demonstrate robustness. For optimization, Adam Optimizer is used with specific parameters, and experiments are trained for 50 epochs with batch size 128 using PyTorch. The approach is compared with existing UDA methods like MMD regularization and Correlation Alignment. Results are compared with state-of-the-art approaches in terms of accuracy and standard deviation. Our method achieves state-of-the-art accuracy of 98.6% on MNIST\u2192USPS and 98.4% on USPS\u2192MNIST, demonstrating that ARN can handle low-level domain shift using only ART. The proposed method achieves state-of-the-art performance of 97.4% for SVHN\u2192MNIST and improves classic DANN by 22.7%. It also achieves a noticeable improvement of 5.3% for ARN with MDAT compared to the source-only model. Additionally, the method is applied to WiFi gesture recognition dataset for non-visual UDA tasks. The WiFi gesture recognition dataset was used to apply the method for UDA tasks, showing significant improvements in classification accuracy compared to Source-Only and DANN. An ablation study was conducted to verify the contribution of MDAT and unsupervised reconstruction in ARN, with results indicating the importance of unsupervised reconstruction for tasks with low-level domain shift. The MDAT in ARN significantly improves performance in domain adaptation tasks, with around 30% improvement for USPS\u2192MNIST and SVHN\u2192MNIST. Parameter sensitivity analysis shows that ARN is robust to changes in \u03b1 and m values, outperforming DANN in convergence. The training of ARN is not sensitive to parameters, with accuracy exceeding 96.0% for m \u2265 1. The training of ARN is robust to parameters, achieving convergence even in worst cases. ARN has smoother gradients compared to DAT domain classifier, leading to more stable training. Visualizing source, target, and reconstructed images validates MDAT features. The ARN method visualizes reconstructed MDAT features to show domain invariance. It conducts implicit feature-to-feature translation, making features domain-invariant. Performance analysis is done by plotting T-SNE embeddings on the SVHN\u2192MNIST task. The proposed ARN method effectively aligns two domains for all categories, providing clear classifier boundaries. A new domain alignment approach, MDAT, offers stable gradients for feature learning through an adversarial game. Theoretical analysis justifies how it minimizes distribution discrepancy, with extensive experiments demonstrating its effectiveness. Features are further interpreted through visualization, showcasing domain invariance. The ARN method aligns two domains effectively for all categories, with clear classifier boundaries. Features are interpreted through visualization, and hyperparameters are chosen based on sensitivity analysis. Network architectures are based on previous models for fair comparison. Detailed training procedures are shown in Figure 4. The ARN method aligns two domains effectively for all categories, with clear classifier boundaries. Features are interpreted through visualization, and hyperparameters are chosen based on sensitivity analysis. Accuracy increases when \u03b1 decreases or margin m increases due to the impact on supervised training and domain divergence measurement. Reconstructed target samples show source-like images with preserved shapes and skeletons for low-level domain shifts, while larger shifts result in source-like digits with some noise removal. After reconstruction, target samples with multiple noisy digits show only the correct digits. Some samples with poor illumination have clear reconstructed digits, showcasing impressive results."
}