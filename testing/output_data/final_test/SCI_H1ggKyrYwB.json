{
    "title": "H1ggKyrYwB",
    "content": "The method presented supplements supervised training with prior knowledge expressed as relations between training instances, such as causal relations or domain-specific invariances. This technique is illustrated on the task of visual question answering, utilizing various auxiliary annotations like relations of equivalence and logical entailment between questions. Unlike existing methods, which struggle to include these relations into the model, this approach shapes the embedding space of the model using these relations. The method shapes the model's embedding space using relations between training instances as strict constraints, leading to better generalization. This approach significantly improves accuracy and robustness in visual question answering compared to soft regularization. Incorporating prior knowledge consistently enhances performance, showing the value of additional training signals beyond end-to-end annotations. Generalizing beyond training data is a key challenge in deep learning, especially for complex tasks. End-to-end training in visual question answering tends to capture superficial correlations rather than underlying reasoning steps. Incorporating prior knowledge as relations between training examples can improve model training effectively. Incorporating prior knowledge as relations between training examples can improve model training effectively by providing high-level guidance beyond end-to-end supervision. This knowledge, such as constraints of equivalence, offers more powerful insights than just sharing labels. Existing approaches often task-specific and operate in parameter space. Our method for visual question answering (VQA) utilizes task-specific knowledge expressed as relations between training questions, providing complementary training signals beyond ground truth answers. Unlike existing approaches operating in parameter space, our approach leverages knowledge in embedding space, allowing for more intuitive expression of higher-level knowledge. This additional knowledge includes annotations of relations between specific training instances. The method proposed for visual question answering (VQA) utilizes task-specific knowledge expressed as relations between training questions. It operates in two phases, using constraints as soft regularizers in the first phase and enforcing hard constraints on learned embeddings in the second phase. Experimental results show that hard constraints are more effective than soft regularizers. Extensive experiments were conducted on synthetic and large-scale datasets. In VQA, the method leverages annotations on question relations from the GQA dataset to improve robustness and accuracy. Imposing hard constraints on linguistic embeddings is shown to be superior to soft regularizers, leading to consistent improvements regardless of the amount of supervised data. The paper proposes a method to utilize prior knowledge in training deep learning models by enforcing hard constraints on internal representations. It is applicable to various tasks and types of relations, without requiring domain-specific expert knowledge. The method is shown to be more intuitive than designing regularizers in parameter space. The method proposed in the paper utilizes prior knowledge by enforcing hard constraints on internal representations, which is more intuitive than designing regularizers in parameter space. It demonstrates benefits on the task of VQA by exploiting three types of auxiliary annotations, leading to clear improvements in robustness and accuracy. This approach leverages rules and prior knowledge in neural networks to improve model predictions. The method proposed enforces hard constraints on learned embeddings, contrasting with Hu et al. (2016) which balances rules with predictions. Techniques like differentiable theorem proving and neural reasoning learn symbol representations with constraints. Order embeddings and non-Euclidean representations impose hierarchical structure on embedding space. In this paper, the authors propose a novel training procedure to enforce hard constraints on learned embeddings for a complex multimodal task (VQA), contrasting with previous works that use soft objectives and regularizers. They turn annotations of set membership into linear constraints on the embeddings, similar to Pathak et al. (2015). The authors propose a new training method to enforce strict constraints on learned embeddings for the VQA task, contrasting with soft objectives used in previous works. They derive an objective for SGD that is robust to competing constraints and show the superiority of strict enforcement over soft regularization. VQA is posed as a classification task with supervised training, exposing flaws in purely end-to-end approaches. The method proposed in this paper allows using additional annotations during training, leveraging the CLEVR synthetic dataset for supervision. It offers more flexibility by exploiting partial annotations on a subset of the data. The method proposed in this paper leverages partial annotations on a subset of the data for data augmentation in VQA. Shah et al. (2019) introduced a generative model for questions conditioned on answers, while Mao et al. (2019) combined symbolic AI with neural networks for VQA using a domain-specific language. These approaches are different from ours, which focuses on question representations. In this paper, distillation is used to retrain network layers for desired embeddings by transferring knowledge from a teacher model to a student. The method enforces hard constraints through a teacher/student distillation procedure during training. The proposed approach involves translating task-specific knowledge into constraints for representations learned by the model. Three types of constraints are demonstrated in experiments on VQA: vector equality, norm inequality, and linear programs. A network is trained to strictly respect these constraints through a two-phase procedure. The approach involves training a network to respect constraints through a two-phase procedure. The first phase uses a regularizer to loosely fit the constraints, while the second phase improves the fit without overfitting the task objective. The approach involves a two-phase training procedure to combine task supervision with hard constraints on learned embeddings. In the first phase, the model is trained with end-to-end supervision, regularizers representing soft constraints, and internal projection of embeddings. The second phase retrains the embedding layers with a distillation objective using projected embeddings as targets. The model in Fig. 2 consists of layers representing functions f \u03b8 (\u00b7), g \u03c6 (\u00b7), and h(\u00b7). It uses supervised task loss and soft regularizers to optimize performance. The task loss for VQA is binary cross-entropy, and regularizers enforce constraints. The model is optimized with a combination of task loss and regularizers, with non-negative scalar hyperparameters. The model uses supervised task loss and regularizers to optimize performance. The objective encourages embeddings to follow desired constraints in a soft manner, balanced with the task objective. Constraints are known to be exact, such as learning identical representations for synonymous questions. Projected embeddings are used by the network, ensuring the remaining layers are optimized to use embeddings that perfectly respect the constraints. The training procedure involves replacing embeddings with their mean, normalizing entailed questions, and performing gradient descent on program operations to respect constraints. The second step focuses on improving layers to better adhere to constraints, often requiring early stopping to prevent overfitting. Our solution involves retraining layers using distillation with projected embeddings as targets to prevent overfitting and maintain performance. The objective minimizes L2 loss between the embeddings, ensuring no further overfitting on the target task. The proposed method involves retraining layers using distillation with projected embeddings as targets to prevent overfitting and maintain performance. It is applicable to various tasks and architectures, including VQA. A VQA model is abstracted with input question and image passed through embedding functions, producing vector representations passed to a fusion and output stage. The proposed method involves retraining layers using distillation with projected embeddings as targets to prevent overfitting and maintain performance, applicable to various tasks and architectures, including VQA. It encompasses attention mechanisms within h(\u00b7) for producing scores over candidate answers, with x and y unimodal. Constraints for VQA include relations of equivalence between questions, translated to constraints on question embeddings x i learned within the model. The proposed method involves retraining layers using distillation with projected embeddings as targets to prevent overfitting and maintain performance. Constraints for VQA include relations of equivalence between questions and annotations of functional programs. The proposed method involves retraining layers using distillation with projected embeddings as targets to prevent overfitting and maintain performance. A question can be translated to a set of operations with a large vocabulary of possible operations. The embedding of a question is determined by the intersection of subspaces associated with its operations, allowing for the use of partial annotations. The method involves retraining layers using distillation with projected embeddings as targets to prevent overfitting and maintain performance. A simple arithmetic task is designed where the model receives an integer digit as input along with a sequence of addition or multiplication operations. A baseline model is built to learn this task from a supervised dataset by mapping input tokens to vector embeddings and passing operation vectors through a GRU. The model is optimized by SGD for a regression loss. Additional annotations of equivalent sequences are used for training. Annotations are translated into constraints of equivalence of operation embeddings. The proposed method for optimizing the model proves more effective than using a standard soft regularizer. Data augmentation baseline is strong but limited to relations of equivalence, while the proposed method has wider applicability. Additional annotations show significant benefits over end-to-end supervision in training the model. The proposed method for optimizing the model proves more effective than using a standard soft regularizer. It leverages complementary training signals in addition to supervised, end-to-end training. Extensive experiments were conducted using the GQA dataset to evaluate the method on a popular VQA model. Ablative evaluation was performed to determine optimal loss weights for best performance. The proposed method for optimizing the model outperforms using a standard soft regularizer. It incorporates additional training signals and was evaluated on a popular VQA model using the GQA dataset. Ablative evaluation determined optimal loss weights for improved performance. Training with the proposed soft regularizer significantly enhances accuracy, with the addition of projection for embedding constraints leading to further performance boosts through distillation. In practice, re-optimization from scratch may exploit distillation loss gradients better than training the teacher model. Comparing soft regularizers, L1 norms show superior performance over L2 distance for entailment relations due to their asymmetry. Swapping premise and consequence in the formulation yields similar results, emphasizing the importance of modeling relation asymmetry. Alternative options like order embeddings and L2 norms did not match the performance of L1 norms. Order embeddings and L2 norms did not perform as well as L1 norms for entailment relations. Adding projection and distillation had a positive effect, with consistent improvement regardless of training data amount. Ablative evaluation on GQA showed the mean accuracy of different model combinations. The use of annotations with a method shows a positive improvement over the baseline. The soft regularizer is effective on its own, and combining it with projection and distillation brings additional improvement. The method can use partial annotations and easily extend to other datasets. Combining the best versions of constraints shows they are complementary to each other. The results show that the best performance is achieved with the full combination of methods. However, there is room for improvement in handling program annotations. Comparison to existing models demonstrates that our method outperforms the MAC model, particularly in consistency metrics. Training the model on varying amounts of data shows promising accuracy levels. The study demonstrates consistent improvement over the baseline model regardless of the amount of training data used, indicating the effectiveness of incorporating additional annotations. This approach reinforces the importance of integrating prior knowledge into deep learning models, particularly in tasks like VQA where multiple types of relations between training questions are leveraged. The proposed approach in VQA leverages various relations between training questions to improve model accuracy and robustness. It treats additional knowledge as hard constraints on internal representations, showing clear benefits over existing methods regardless of the amount of training data used. The proposed method in VQA utilizes hard constraints to improve model accuracy and robustness, surpassing existing methods. It can be applied to various tasks and domains, offering the potential for trustworthy machine learning models. The model used for a toy task had manually set hyperparameters and implementation details for baseline performance, not optimized for proposed contributions. Embedding size and all layers were fixed at 64, trained with AdaDelta and mini-batch size of 64. The MLP had a single layer of gated tanh units followed by a linear layer for regression output. Task loss was square L2 distance, with evaluation metric as accuracy of predicted output rounded to nearest integer. Dataset was generated for every possible instance of the task with sequences of one to three. The dataset for the toy task was generated with sequences of one to three operations. 20k instances were reserved for validation and another 20k for testing, with the rest used for training. The VQA model in the method used hyperparameters selected for baseline performance on the GQA dataset. The model utilized non-linear operations with gated hyperbolic tangent units and \"bottom-up attention\" features of size 36\u00d72048. The code for generating the dataset and replicating the experiments will be shared once anonymization issues are resolved. The model utilizes non-linear operations with gated hyperbolic tangent units and \"bottom-up attention\" features of size 36\u00d72048. Word embeddings are initialized as random vectors and normalized before being passed to a GRU. The network output is passed through a logistic function for scores in [0, 1]. Adadelta is used as the optimization algorithm, and the final classifier is trained from random initialization. Time complexity remains the same with this method compared to standard training, with a fixed overhead for each mini-batch. During training, mini-batches are sampled normally. Equivalent questions are retrieved for regularizer computation. The second training phase involves distillation by retraining a few layers. Experiments were repeated four times with different random seeds, and results were averaged. Other metrics from Hudson & Manning (2019) were also considered. During training, mini-batches are sampled normally. The second training phase involves distillation by retraining a few layers. The number of steps and step size for gradient descent are specified. The switch between training phases is based on validation set accuracy. The GQA dataset is used for all experiments, providing various annotations for each training question. The dataset provides a set of equivalent and entailed questions with reasoning operations. Relations of entailment involving questions with the same answer are kept. A vocabulary of possible operations is pre-built, with only operations appearing at least 1,000 times in the training set selected. This covers 78% of all annotated operations. Other operations are not used. The dataset includes equivalent and entailed questions with reasoning operations. Entailment relations are occasionally dependent on the answer to the premise. Constraints are enforced on the embedding of the question alone. Our method enforces constraints on question embeddings, allowing for answer-dependent relations in the network. A limited set of operations is used as functional programs, with a vocabulary of 354 operations selected based on frequency in the training set. The threshold of 1,000 was chosen among different values for best performance, covering 78% of all annotated operations. A larger vocabulary did not improve results, while a smaller vocabulary decreased the benefit of the method."
}