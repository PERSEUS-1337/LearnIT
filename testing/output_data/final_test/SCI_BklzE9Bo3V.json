{
    "title": "BklzE9Bo3V",
    "content": "Recent language models trained with deep neural networks struggle to adapt linguistic conventions on the fly like humans do. A repeated reference task is introduced as a benchmark for models of adaptation in communication. A regularized continual learning framework is proposed to help artificial agents understand their partners more accurately over time. The framework is evaluated through simulations on COCO and real-time reference game experiments with human partners. Linguistic communication relies on shared knowledge about word meanings, but real-world communication often requires understanding beyond dictionary definitions. The social world presents new communicative challenges, requiring agents to coordinate on new meanings. Flexible language use, like a nurse adapting to a patient's language over time, poses a challenge for machine learning models. Deep neural networks struggle to adapt linguistic conventions on the fly like humans do. To improve communication between robots and humans, a continual learning mechanism is needed. This mechanism offers advantages in adapting to new settings and building common ground efficiently. A benchmark communication task and continual learning framework are introduced to transform neural language models into adaptive models for real-time interactions. Through continual interactions in a shared context, adaptive listeners can enhance communication with partners. Our approach integrates a loss function combining speaker and listener information, along with a regularization scheme for fine-tuning model weights without overfitting. Communication is recast as a multi-task problem for meta-learning, where each context and partner is a distinct task. A communicative agent needs a good prior representation and a mechanism to rapidly update it from interactions. The repeated reference game task is introduced as a benchmark for studying this problem. The repeated reference game task FIG0 is used as a benchmark to study partner-specific adaptation in communication. It involves a speaker and listener collaborating to refer to images, with the speaker providing an utterance for the listener to select the target object. The sequence of trials allows for evaluating how communication about each image changes over time. The algorithm is formalized as a generic update rule for neural networks, based on theoretical Bayesian foundations. Communication models involve semantics of language and uncertainty is structured in a hierarchical Bayesian model. The highest level parameterizes task-specific prior expectations, allowing agents to update their models using Bayes rule. The Bayesian formulation decomposes task-specific adaptation into a prior term capturing task-general structure and a likelihood term accounting for deviations from general knowledge based on current evidence. For a benchmark communication task, paired observations of utterances and objects of reference are used. The speaker model uses task-specific semantics. The speaker model uses task-specific semantics to sample utterances proportional to their relevance to objects in a context. A listener evaluates how well an utterance describes each object relative to others by normalizing statistical information. The hierarchical Bayesian framework connects to deep learning for multi-task learning, proposing an online continual learning scheme. The online continual learning scheme proposed for a neural listener model adapts to a human speaker in a referential communication task. It combines a visual encoder with an LSTM decoder, utilizing a Bayesian prior and a softmax distribution over the vocabulary size. The model includes a fully connected adapter layer and is pre-trained on the COCO training set. The online continual learning scheme for a neural listener model adapts to a human speaker in a referential communication task by fine-tuning decoder weights based on observed utterance-object data points. Loss terms and techniques are considered, including speaker and listener likelihoods to make the observed utterance more likely for the target and relative to other objects in context. The speaker and listener likelihoods are computed directly from the neural captioning model, with regularization terms introduced to approximate the Bayesian prior on task-specific learning. A global KL regularization term minimizes the divergence between the captioning model's output probabilities before and after fine-tuning. The loss is averaged across random images from the full domain, not just those in context. The text discusses regularization techniques in neural captioning models, including global KL regularization and local rehearsal to prevent overfitting. It also mentions data augmentation for new utterances to improve learning in adaptive agents. The text discusses data augmentation for new utterances in adaptive agents, creating a small training dataset from the utterance. It evaluates the model using a repeated reference game with images from COCO BID10. Challenging contexts are constructed using a pre-trained visual encoder to find similar images. The baseline performance of human speakers and listeners is investigated with 113 participants from Amazon Mechanical Turk. In a study with 113 participants from Amazon Mechanical Turk, pairs of humans showed high accuracy in a repeated reference game with images. They became more efficient in communication, with utterance length decreasing from 7 words to 3 words per image across repetitions. In a study with 113 participants, pairs of humans showed high accuracy in a repeated reference game with images, with utterance length decreasing significantly across repetitions. Additionally, an adaptive listener was evaluated in real-time interaction with human speakers, showing a response latency of 6-8s and specific model parameters used for generating responses. The study evaluated an adaptive listener based on a pre-trained neural captioning model, which initially performed less accurately than humans but improved over time by coordinating with human speakers. Lesion analyses were conducted to understand the role of each component in the approach, highlighting the risk of catastrophic forgetting when fine-tuning on a small number of data points. The KL regularization term served as a Bayesian prior to prevent forgetting. The KL regularization term acts as a Bayesian prior to prevent catastrophic forgetting in an adaptive listener model. The effectiveness of this term was tested by comparing the likelihood of captions before and after adaptation to human baseline utterances. Likelihood curves were generated with and without speaker KL regularization to show the impact on the final caption generation. The final caption generation is improved with speaker KL regularization in FIG2, preventing catastrophic loss of initial captions. Simulation of adaptive agent's performance understanding human utterances showed rehearsal had the largest benefit, with data augmentation and listener terms providing smaller boosts. Even a simple loss with speaker likelihood and KL regularization outperformed a non-adapting baseline, successfully adapting to human language use in a repeated reference game benchmark. Our continual learning approach enables human speakers to adapt general-purpose knowledge for better performance in a challenging repeated reference game benchmark for artificial agents."
}