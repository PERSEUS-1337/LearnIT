{
    "title": "rJQDjk-0b",
    "content": "The novel UORO algorithm allows for online learning of general recurrent computational graphs like recurrent network models. It is computationally costly like truncated BPTT but provides unbiased gradient estimates, unlike truncated BPTT which can lead to divergence. Truncated BPTT can lead to divergence on synthetic tasks, while UORO converges due to unbiased gradients. Truncated BPTT struggles with parameters having conflicting short-term and long-term effects, requiring longer truncation spans, whereas UORO performs well. Unbiased Online Recurrent Optimization (UORO) is introduced as a memoryless learning algorithm for recurrent architectures, processing data samples sequentially without maintaining a history of previous inputs. Unlike BPTT, UORO is scalable and does not require storing all past inputs in memory, making it suitable for online learning through a single pass of long sequences of temporal data. Unbiased Online Recurrent Optimization (UORO) is a scalable algorithm that provides provably unbiased gradient estimates for neural network training. It can be easily implemented on top of existing recurrent models without needing to understand their structure or code. The final algorithm is simple, but its derivation is more complex. UORO is shown to provide convergence on a set of data samples. In Section 6, Unbiased Online Recurrent Optimization (UORO) is demonstrated to achieve convergence in synthetic experiments where Truncated Backpropagation Through Time (truncated BPTT) fails. UORO implementation is available as supplementary material. Truncated BPTT, a common online learning approach for recurrent neural networks, lacks convergence guarantees due to biased gradient estimates. Other methods like Real Time Recurrent Learning (RTRL) and NoBackTrack (NBT) offer unbiased gradient estimates but are computationally expensive for larger networks. NoBackTrack (NBT) BID11 provides unbiased gradient estimates for recurrent neural networks, but it is tedious to implement for complex architectures. Previous attempts at generic online learning algorithms with reasonable computational cost result in biased gradient estimates. Various methods like Echo State Networks (ESNs) and Long Short Term Memory (LSTM) algorithm cut gradient flows or bootstrap truncated gradient estimates to make computation tractable. Decoupled Neural Interfaces bootstrap truncated gradient estimates using synthetic gradients. The algorithm BID10 provides zeroth-order estimates of recurrent gradients via diffusion networks, lacking strong theoretical backing. UORO is a learning algorithm for optimizing parameters in recurrent computational graphs to minimize total loss. Optimization by gradient descent is standard for neural networks, updating one term at a time in the spirit of stochastic gradient descent. UORO is a learning algorithm for optimizing parameters in recurrent computational graphs to minimize total loss. It updates parameters online at each time step using a scalar learning rate. BPTT requires maintaining the full unfolded network, while Truncated BPTT reduces computational cost by unfolding the network for a fixed number of timesteps. Unbiased Online Recurrent Optimization is based on forward computation of gradients, rather than backpropagation. The derivation of UORO is closely related to BID11 but removes the sparsity hypothesis, reducing implementation complexity without model restrictions. UORO's convergence to a local optimum is proven in BID9. Forward gradient computation for recurrent models (RTRL) involves applying the chain rule to the loss function and state equation. The update equation for computing the derivative of the instantaneous loss without storing past history is derived using the chain rule. RTRL has a disadvantage of large memory requirements, which UORO addresses by modifying the approach. UORO modifies RTRL by maintaining a scalable, rank-one approximation of \u2202s t /\u2202\u03b8 to reduce memory and computational costs. The memory cost scales with the dimensions of the state and parameters, making it as memory costly as running the network itself. Unbiased estimates of derivatives can be derived using a stochastic matrixG t. The UORO update in RTRL maintains a rank-one unbiased approximation of derivatives to reduce memory and computational costs. By using a rank-one trick, an unbiased rank-one approximation can be obtained, with the choice of parameters influencing the variance of the approximation. DISPLAYFORM4 minimizes the variance of the approximation, E A \u2212\u00c3 The UORO update is obtained by applying the rank-one trick twice to reduce memory and computational costs. The unbiased estimation is rank-one and can be rewritten as G t+1 = s t+1 \u2297 \u03b8 t+1 with the updates. The UORO update minimizes variance by applying the rank-one trick twice. It provides unbiased estimation using G t+1 = s t+1 \u2297 \u03b8 t+1 with updates. The update rules for online estimation of \u2202 t /\u2202\u03b8 are scalable and implementable by maintaining the rank-one approximation and gradient loss estimate. The UORO update minimizes variance by applying the rank-one trick twice, providing unbiased estimation using G t+1 = s t+1 \u2297 \u03b8 t+1 with updates. The cost of UORO implementation involves several applications of F state and F out, backpropagation, and elementwise operations. The proposed update rule for stochastic gradient descent can be adapted to other optimizers like Adam. SGD and Adam are commonly used. Unbiased gradient estimates of UORO inject noise via \u03bd, requiring smaller learning rates. UORO can be used with truncated BPTT to reduce noise. The proposed update rule for stochastic gradient descent, known as memory-T UORO, involves applying Algorithm 1 to a new transition function F T, which is T consecutive steps of the original model F. This results in an unbiased gradient estimate with no noise from the last T steps, similar to T-truncated BPTT. The proposed update rule for stochastic gradient descent, memory-T UORO, involves reducing variance early on but not significantly impacting later performance. Higher-rank gradient estimates can further reduce noise by maintaining distinct values of parameters and averaging resulting gradients. UORO is designed to provide an unbiased estimate with bounded variance over time. Experimental validation of its variance is shown in FIG2 using a GRU recurrent network trained on Shakespeare's works. The network is rerun multiple times on the text, computing gradient estimates without applying them. The relative variance of these estimates is stationary over time, but increases as the number of hidden units in the network increases. This increase is experimentally verified, showing that the variance becomes coarser with more hidden units. The relative variance of gradient estimates increases with the number of hidden units in the network, necessitating smaller learning rates for larger networks when using UORO compared to truncated backpropagation. This can result in slower learning for certain dependencies. Training GRU networks on a copy task with decreasing learning rates shows that error decreases steadily for all network sizes except the largest, where the variance is too large, causing a sharp increase in error. The experiments demonstrate cases where biases from truncated BPTT hinder learning convergence. UORO's unbiasedness ensures steady convergence, emphasizing the importance of unbiased estimates in recurrent learning. One test case shows a parameter \u03b8 with short-term positive influence but long-term negative impact. Truncated algorithms' short-sightedness leads to abrupt failure, even with longer truncation lengths. Another case involves linear dynamics with a scalar parameter \u03b8, showcasing the challenges of balancing influences in learning. The effect of parameter \u03b8 on units diffuses over time, with UORO solving the problem while truncated BPTT fails due to ill balancing of time dependencies. Truncated BPTT requires a large truncation T to converge, even with n = 23 units and 13 minus signs. The experiment involves character-level synthetic text prediction using a recurrent model with either GRU or LSTM. The model outputs a probability vector for the next character, and the cross entropy criterion is used to compute the loss. The cumulated loss per character on the first t characters is plotted at each time t. Additionally, a \"recent\" loss on the last 100,000 characters is reported in TAB1. The experiment involves character-level synthetic text prediction using a recurrent model with either GRU or LSTM. Optimization was performed using Adam with default settings. UORO is favored over truncated BPTT due to its need for smaller learning rates. The distant brackets dataset is used for comparison. The experiment involves character-level synthetic text prediction using a recurrent model with either GRU or LSTM. UORO outperforms truncated BPTT in the long run, showing near optimal behavior with both GRUs and LSTMs. The dataset used tests memory and counting abilities. Plots and numerical results are provided for reference. UORO reliably converges and reaches near optimal performance in character-level synthetic text prediction using recurrent models. Increasing UORO's range does not significantly improve results, while truncated BPTT performs inconsistently. With GRUs, truncated BPTT either converges to a poor local optimum or exhibits gradient reascent, but with LSTMs, it reliably reaches optimal behavior even with biased gradient estimates. UORO is introduced as an algorithm for training recurrent neural networks in a streaming, memoryless fashion, and is easy to implement. UORO is an algorithm for training recurrent neural networks in a streaming, memoryless fashion. It provides unbiased gradient estimates, which is crucial for stochastic gradient descent theory. UORO converges reliably and outperforms truncated BPTT in experimental results."
}