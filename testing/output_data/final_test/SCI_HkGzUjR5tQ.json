{
    "title": "HkGzUjR5tQ",
    "content": "The Dual Adversarial Transfer Network (DATNet) is proposed for low-resource Named Entity Recognition (NER), with variants DATNet-F and DATNet-P for feature fusion. A Generalized Resource-Adversarial Discriminator (GRAD) is introduced to handle noisy data, and adversarial training improves model generalization. DATNet shows significant performance improvement on CoNLL and Twitter NER datasets without additional hand-crafted features, achieving state-of-the-art results for Spanish, WNUT-2016, and WNUT-2017 datasets. Named entity recognition (NER) is crucial in natural language processing (NLP) applications. Named entity recognition (NER) is vital in natural language processing (NLP) applications. Current methods focus on developing learning-based algorithms, particularly neural network-based approaches, to advance the state-of-the-art in NER. However, performance may degrade significantly in low-resource scenarios due to limited annotated data. Recent approaches aim to address this challenge. Recent approaches in low-resource NER focus on cross-resource word embedding to bridge the gap between high and low resources. However, two key issues need further investigation: representation difference and resource data imbalance. Existing methods do not account for the differences in feature representation across resources and the imbalance in training data sizes between high and low-resource languages. In this work, a Dual Adversarial Transfer Network (DATNet) is introduced to address representation differences and data imbalances in low-resource NER. Two architectures of hidden layers are explored, with one having common units shared across languages/domains and the other including private units for independent information. Extensive experiments demonstrate the advantages of each approach in various scenarios, with the addition of an adversarial discriminator (AD) loss to promote resource-agnostic representations. In this work, a Dual Adversarial Transfer Network (DATNet) is introduced to address representation differences and data imbalances in low-resource NER. The Generalized Resource-Adversarial Discriminator (GRAD) is proposed to handle resource data imbalance, while Adversarial Training (AT) is used to improve generalization and alleviate overfitting. The DATNet model combines GRAD and AT for end-to-end training, achieving state-of-the-art performance on NER tasks without the use of additional hand-crafted features. NER is typically a sequence labeling task for automatic detection of named entities from free text. Early works used CRF, SVM, and perception models with handcrafted features, but research has shifted towards deep neural networks like bidirectional LSTM-CNNs for better feature detection. Transfer learning methods for Named Entity Recognition (NER) can bridge high and low resource tasks using parallel corpora or shared representation. Early works focused on parallel corpora to align bilingual named entities, while shared representation methods do not require parallel correspondence. Shared representation methods for Named Entity Recognition (NER) do not require parallel correspondence, unlike methods using parallel corpora. Various approaches have been proposed, such as cross-lingual word embeddings, transfer learning with deep hierarchical RNNs, utilizing Wikipedia entity type mappings, creating multilingual annotators with minimal human expertise, and developing cross-language NER systems. Additionally, character-level neural CRFs and large-scale cross-lingual named entity datasets have been introduced. Multi-task learning is also being explored in this context. Multi-task learning and adversarial learning have shown promising results in improving performance across multiple languages and tasks in NLP. Adversarial learning, originating from GANs, has been applied to text classification, POS tagging, and cross-language POS tagging. Adversarial training is another concept aimed at improving model robustness. Our method integrates adversarial discriminator and training in a unified framework for end-to-end training. We introduce DATNet, a model for Named Entity Recognition (NER) that follows state-of-the-art models using LSTM-CNNs-CRF structure. It includes character-level embedding, word-level embedding, BiLSTM for feature representation, and CRF. The curr_chunk discusses the use of character-level embedding, word-level embedding, BiLSTM, and CRF in a model for sequence labeling. It explains how character features are encoded and combined with word-level embedding to form word vectors. The network incorporates contextual information using BiLSTM and CRF for label sequence prediction. The architecture of the base model is shown in FIG0. Previous research has demonstrated that character features can enhance sequence labeling. The curr_chunk discusses the use of character-level CNN for sequence labeling tasks, emphasizing its efficiency and parameter reduction compared to BiLSTM. It also mentions the sharing of character features between high- and low-resource tasks to enhance representations. Additionally, character-level features are concatenated with word embeddings to improve word-level representations. The curr_chunk discusses utilizing bidirectional LSTM architecture to extract contextualized word-level features for Named Entity Recognition (NER). Two transferable word-level encoders, DATNet-F and DATNet-P, are introduced to consider resource representation differences. The DATNet-P model decomposes BiLSTM units into shared and resource-specific components to improve feature compatibility between different domains. A resource-adversarial discriminator is used to make the shared BiLSTM outputs domain-agnostic. Previous works did not address the imbalance in training data size between the source and target domains. The training data in the source domain is much richer with 10k sentences. Imposing a weight \u03b1 on two resources helps balance their influences, but easily classified samples from high resource dominate the gradient. The Generalized Resource-Adversarial Discriminator (GRAD) assigns adaptive weights to focus on hard samples during model training. The loss of GRAD is computed by encoding the output sequence of the shared BiLSTM into a single vector using a self-attention module. The resource classifier's loss function is formulated with weighting factors to balance high and low resource contributions. Parameters control the loss from individual samples, with a scaling factor for hard and easy samples. The weighting factors reduce loss from high resource and easy samples. The resource classifier aims to minimize resource classification error. The resource classifier is optimized to minimize classification error by negating gradients for parameter updates in other model parts. The label decoder uses a linear chain model based on a chain conditional random field (CRF) BID22, with local and transition cliques defining the sequence evolution. The linear-chain CRF model is defined with transition distribution \u03b8 and optimized to maximize conditional log likelihood. Loss functions for source and target resources are defined as S = \u2212 log p(y|h 1:T ) and T = \u2212 log p(y|h 1:T ). Adversarial examples in deep learning models have been shown to be fragile, especially in computer vision where small pixel changes are imperceptible to humans. These examples are now used in training to enhance generalization. Adversarial training (AT) is a powerful regularization tool that incorporates adversarial samples into training to improve model generalization and robustness. In the context of NER, adversarial samples are prepared by adding small perturbations to the inputs to maximize the loss function. The value of the perturbation is approximated by linearizing it, as exact optimization is intractable in neural networks. This approach generates adversarial examples by adding perturbations in the direction that maximizes the loss. Adversarial training involves generating examples with small perturbations to inputs to increase model loss. These adversarial examples are created at each training step using \u03b7 against the current model parameters. The classifier is then trained on a mix of original and adversarial examples to enhance generalization. The loss function for adversarial training is defined to incorporate both original and adversarial examples. DATNet performance evaluation conducted on widely used NER datasets: CoNLL-2003 English NER, CoNLL-2002 Spanish & Dutch NER, WNUT-2016 English Twitter NER. Official split of training/validation/test sets used to study knowledge transfer effects. Previous works appended one-hot gazetteer features to CRF layer input, introduced orthographic feature as additional input. The study focused on using words and characters embeddings as inputs for social media NER in tweets, without hand-crafted features. Training was done only on the train set, except for the WNUT-2016 NER dataset where training and validation sets were merged. Additionally, experiments were conducted on a cross-language named entity dataset for 9 languages to evaluate methods and transferability across linguistic families. Target languages included Galician, West Frisian, Ukrainian, and Marathi. The study focused on using word and character embeddings for social media NER in tweets, without hand-crafted features. Training was conducted on the train set, except for the WNUT-2016 NER dataset where training and validation sets were merged. Experiments were also carried out on a cross-language named entity dataset for 9 languages, including Galician, West Frisian, Ukrainian, and Marathi. Target languages for the experiments were Spanish, Dutch, Russian, and Hindi, with Arabic as an additional source language from a different linguistic family. Low- and high-resource scenarios were simulated by creating different numbers of sentences for training, validation, and testing datasets. The selected datasets and embeddings used are described in detail. In experiments, character embeddings and filter numbers were set for char-level CNN, while hidden states dimensions were specified for word-level LSTM. Parameters optimization was done using Adam optimizer with gradient clipping and learning rate decay strategy. Dropout was applied to reduce overfitting. The approach was compared with state-of-the-art methods on CoNLL and WNUT benchmark datasets, utilizing all source and target data for performance improvement. The study focused on utilizing additional resources to improve performance in target tasks, showing better results with DATNets compared to BID8 in cross-language transfer scenarios. Transfer learning was particularly effective in low-resource situations. Transfer learning is significantly helpful for improving performance in low-resource scenarios within both same and different linguistic families or branches. The improvements are more prominent under in-family in-branch cases. However, in high-resource scenarios, the benefits of transfer learning are not as distinct. Transferring knowledge from Arabic to Galician and Ukrainian shows no effect, likely due to significant linguistic differences between the languages. In low-resource settings, transfer learning with partial target data ratios ranging from 0.05 to 1.0 was simulated. Results from cross-language and cross-domain transfer comparisons using DATNet showed consistent performance improvements, especially with lower target data ratios. Adversarial training and discriminator in DATNet contributed to performance gains, with the transfer learning component consistently outperforming the base model, particularly at lower data ratios like 0.05. In low-resource settings, DATNet-P model outperforms the base model by more than 4% in F1-score on Spanish NER at a data ratio of 0.05. DATNet-F model improves around 13% in F1-score on WNUT-2016 NER compared to the base model. In further experiments with extremely low resource cases, DATNet-F outperforms DATNet-P on cross-language transfer, but this is reversed with larger target dataset sizes. DATNet-F is consistently superior to DATNet-P on cross-domain transfer. In low-resource settings, DATNet-P model outperforms the base model by more than 4% in F1-score on Spanish NER at a data ratio of 0.05. DATNet-F model improves around 13% in F1-score on WNUT-2016 NER compared to the base model. For cross-language transfer with an extremely low resource and cross-domain transfer, DATNet-F model is suggested for better performance. DATNet-P model is preferred for cross-language transfer with relatively more training data. In the proposed DATNet, both GRAD and AT play important roles in low resource NER. In the first experiment, t-SNE BID34 was used to visualize the feature distribution of BiLSTM outputs with different AD methods. The proposed GRAD in DATNet makes the distribution of extracted features more similar by considering data imbalance. GRAD shows stable superiority over normal AD in quantitative performance comparison. In the experiment, DATNet-P and DATNet-F show no clear winner, with each being more suitable for different types of transfers. Adversarial Training (AT) enhances overall performance by adding perturbations to inputs. Target perturbation in AT affects knowledge transfer, showing the need for AT with low resource data. Analysis of discriminator weight \u03b1 in GRAD shows a direct relationship with data ratio \u03c1. The paper introduces DATNet, a transfer learning model for low-resource NER addressing representation difference and data imbalance. Two variants, DATNet-F and DATNet-P, are proposed for cross-language/domain use. Dual adversarial learning strategies, AT and GRAD, improve model generalization. Extensive experiments demonstrate DATNet's superiority over existing models, achieving state-of-the-art performance on CoNLL NER and WNUT NER benchmark datasets."
}