{
    "title": "H1gsGaq9US",
    "content": "Our novel BERTgrid, based on Chargrid, represents documents as a grid of contextualized word piece embedding vectors, making spatial structure and semantics accessible to neural networks. Used for semantic instance segmentation tasks like extracting fields from invoices, it shows good performance on tabulated line items and document headers. In classical NLP, layout information in documents is often discarded, making tasks like tabulated data extraction challenging. Recent approaches combine NLP and CV methods for document intelligence, such as Chargrid. BERTgrid is a new approach that combines NLP and CV methods for document intelligence by incorporating contextualized embedding into the grid document representation using a BERT language model pre-trained on unlabeled documents. This method preserves the spatial arrangement of the document and provides significant benefits for understanding tabulated or spatially arranged text. BERTgrid utilizes contextualized feature vectors from a BERT language model to improve invoice information extraction from document tables and headers. Results show a significant increase in accuracy compared to Chargrid, from 61.76% to 65.48%. Instead of character-level grids, BERTgrid uses word-piece level grids for embedding, enhancing document representation. The BERTgrid representation of a document is defined using a pre-trained BERT language model to create contextualized vectors for each word. These vectors, along with positional information, are used to construct a BERTgrid tensor W for downstream information extraction tasks. The model pipeline involves passing a raw document image through an OCR engine to retrieve words and positions, serializing this data to create S, and then feeding S into the BERT model to obtain contextualized vectors. The BERTgrid representation of a document involves using a pre-trained BERT language model to create contextualized vectors for each word. This is used to construct a BERTgrid tensor W for downstream information extraction tasks. A second model, [C+BERTgrid], combines Chargrid and BERTgrid input representations by replicating the first convolutional block of the neural network to have a Chargrid and a BERTgrid branch, which are then merged. All models are trained for 800k iterations on a single Nvidia V100 GPU each. The BERT model is trained for 2M steps without fine-tuning on downstream tasks. Key-value information is extracted from invoices, distinguishing between header fields and line item fields. The dataset used for training and testing consists of 12k samples split into 10k/1k/1k. The dataset used for training and testing consists of 12k samples split into 10k/1k/1k. In addition, a larger dataset of 700k unlabeled invoices is used for pre-training BERT and learning embedding vectors with word2vec. The evaluation metric used is similar to the edit distance, measuring dissimilarity between predicted and ground truth instances. The evaluation measure for different input representations is computed based on the dissimilarity between predicted and ground truth instances. Grid-based approaches like Chargrid outperform conventional sequential models and image-based methods. BERTgrid's performance is attributed to word-piece level embedding and contextualization. The BERT model, through contextualization and word-piece level embedding, distills knowledge about invoice language into its parameters. This enables faster convergence compared to Chargrid. The BERTgrid representation captures complex dependencies and facilitates downstream tasks, although it lacks access to document structure. Future work could explore using 2D positional encodings to preserve layout information. Future work could explore using 2D positional encodings to preserve layout information in BERTgrid representation, which currently lacks access to document structure."
}