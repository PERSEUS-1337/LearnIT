{
    "title": "B13EC5u6W",
    "content": "Interpretability and small labelled datasets are challenges in applying deep learning, especially in fields like medicine. A semi-supervised technique is proposed in this paper to address these issues. Dense representations are learned from unlabelled image datasets, used to train classifiers on small labelled sets, and generate visual rationales for predictions. The method shows good generalization in diagnosing chest radiography, identifying heart failure and other thoracic diseases. Visual rationales are generated for positive classifications by optimizing a latent representation to minimize disease probability while considering image similarity. The method proposed in the paper addresses challenges in applying deep learning to medicine by using a similarity measure in image space to generate visual rationales for disease predictions. This approach aims to improve interpretability and trust in machine learning algorithms, which is crucial for their adoption in medical fields. The paper proposes a novel method for creating visual rationales to explain individual predictions, specifically in classifying chest radiographs. Gradient-based techniques are commonly used to generate visual heatmaps, but they can be unintelligible due to the sensitivity of convolutional neural networks to small changes in pixel intensities. This method aims to improve interpretability in machine learning algorithms, particularly in medical applications. The saliency map is crucial for generating adversarial examples. Recent methods like Integrated Gradients and occlusion sensitivity highlight important features in visual heatmaps. Global average pooling and class activation maps provide low-resolution heatmaps for relevant activations. A novel analysis method known as locally is also introduced. A novel analysis method called locally interpretable model-agnostic explanations (LIME) aims to explain individual predictions by simulating model predictions in the local neighborhood. LIME uses superpixel-based algorithms to oversegment images and perturb them by replacing each superpixel with its average value. This approach addresses the challenge of sampling the neighborhood surrounding an example in raw feature space, especially for complex and high-dimensional image data. Our research introduces a novel method using generative adversarial networks (GANs) to generate high resolution visual rationales. This method is applied to a dataset of frontal chest radiographs to train a classifier for recognizing heart failure. The process involves training a generator on an unlabelled dataset using GANs. Our method involves training a generator on an unlabelled dataset using generative adversarial networks (GANs) to produce high resolution images. The generator is then used as the decoder in an autoencoder to encode and decode data in the latent space. Simple supervised classifiers are trained on encoded representations of a labelled dataset. The Wasserstein GAN formulation is used, with a gradient penalty term for stability. The dataset consists of 98,900 chest radiograph images scaled to 128 by 128 pixels. The dataset includes 98,900 chest radiograph images scaled to 128 by 128 pixels. A 100 dimensional latent space is used with a DCGAN architecture for the discriminator and generator. The training process involves 200k generator iterations with ADAM optimizer. The trained generator is used as the decoder in an autoencoder to reproduce images. The autoencoder was trained to reproduce images from an unlabelled dataset split by patient. Laplacian loss was minimized to prevent overfitting. A classifier was then trained on a smaller labelled dataset paired with B-type natriuretic peptide (BNP) blood test readings correlated with heart failure. This real-world medical task is important due to delayed availability of BNP test results and varying accuracy in interpreting chest radiograph images. In this study, chest radiograph image analysis is challenging due to varying accuracy levels among doctors. The network is trained to predict BNP values and evaluate AUC at a threshold of 100ng/L. Images are augmented and encoded using an autoencoder, with a 4 to 1 ratio for training and testing sets. The study involves training a network to predict BNP values and evaluate AUC at a threshold of 100ng/L using chest radiograph image analysis. Images are augmented and encoded with a 4 to 1 ratio for training and testing sets. A latent representation is generated with different predictions through optimization over the latent space. The study involves training a network to predict BNP values and evaluate AUC at a threshold of 100ng/L using chest radiograph image analysis. Images are augmented and encoded with a 4 to 1 ratio for training and testing sets. A latent representation is generated with different predictions through optimization over the latent space. The difference between the decoded generated representation and the decoded original representation is scaled and overlaid over the original image to create the visual rationale for that image. Optimization is performed in the latent space using gradient descent to optimize the objective. The study involves training a network to predict BNP values and evaluate AUC at a threshold of 100ng/L using chest radiograph image analysis. Images are augmented and encoded with a 4 to 1 ratio for training and testing sets. A latent representation is generated with different predictions through optimization over the latent space. The generated visual rationales are evaluated using external datasets, such as the NIH ChestX-ray8 dataset, downsized for use with an autoencoder and split into training, validation, and testing sets. A 6 layer fully connected neural network with 100 hidden units in each layer is utilized for training with a batch size of 2048. The study involves training a network to predict BNP values and evaluate AUC at a threshold of 100ng/L using chest radiograph image analysis. To evaluate the usefulness of visual rationales, an experiment is conducted comparing generated visual rationales by a classifier to a contaminated one. The method is also applied to the MNIST dataset using a linear classifier with a 10-way softmax. The optimization objective is altered by adding a negatively weighted term for the predicted probability of the target class. Algorithm 2 demonstrates visual rationale generation for multiclass predictors using an autoencoder to reconstruct images and visualize differences in chest radiographs. The process includes subtracting visualizations to create heatmaps showing the rationale behind the predictions. The text discusses generating visual rationales for predictions using various methods like saliency maps, integrated gradients, and LIME. Results from applying these methods to a chest radiograph dataset are compared, showing that the proposed method yields more relevant features. In FIG5, AUC results are compared, showing comparable or better accuracy than a baseline network without retraining. The method is applied to the MNIST dataset, demonstrating class switching between digits. Visual rationales for misclassifications are shown in FIG6, with some digits transformed into other similar digits. The method is applied to the MNIST dataset, demonstrating class switching between digits. Visual rationales for misclassifications show some digits transformed into other similar digits, with the time taken to generate a visual rationale depending on the confidence of the classifier in its prediction. This behavior is not observed in the chest radiograph dataset due to smaller differences between images with and without heart failure. In the study, visual rationales were generated for a heart failure classifier, with contaminated results showing unique aspects not related to heart failure. Images were classified based on BNP levels and reviewed by experts using both contaminated and normally trained classifiers. The study generated visual rationales for a heart failure classifier, comparing results from a contaminated and normally trained classifier. Experts reviewed images and selected corresponding features. Results showed the contaminated classifier produced less interpretable visual rationales. Using a GAN generator as an autoencoder decoder was found to be effective in producing high-quality autoencoders. Training the generator to produce realistic radiographs in a 100-dimensional latent space with a standard deviation of 1. This method is similar to previous work on inverting GANs by BID2, focusing on image recreation rather than exact latent representation recovery. By training on the loss between real input and generated output images, the encoder can predict outcomes on unseen datasets without retraining, showing its utility. Our primary contribution in this paper is the ability to generate visual rationales without retraining the encoder on unseen datasets. We provide examples of these generated rationales and discuss the importance of autoencoding inputs for rationale generation. The impact of different autoencoding algorithms on the quality of generated rationales is not extensively explored in this paper. Experiments with autoencoders struggled to reconstruct detailed information. Common signs of heart failure in chest radiographs include enlarged heart or congested lung fields. Rationales generated by a normally trained classifier align with medical literature, while a contaminated classifier fails to do so. MNIST dataset shows transformation of digit 9 into 4, but some digits resist conversion despite different weight permutations. In Algorithm 2, some digits resist conversion due to the difficulty of the chest radiograph dataset compared to MNIST. Various methods like integrated gradients and saliency maps perturb the image to identify salient elements for prediction. LIME method perturbs image squares by changing superpixels to average value, but fails on coarse classifications. Model agnostic gradient methods lead to noisy pixel-wise attribution, not aligning with human intuition of continuous object perception. Our approach perturbs the image's latent representation, ensuring realistic perturbed images that align with the GAN's constraints. The learned latent space acts as a coordinate system for natural images, allowing for optimization that constrains solutions to lie on the manifold of natural images, resulting in realistic output images. Our method generates high-resolution rationales by switching the predicted class of an input image while observing the constraints of the input structure. This allows us to answer questions about why an image represents a specific class. Limitations include a lack of a rigorous definition of interpretability, as highlighted by BID12. Future work could focus on measuring interpretability by assessing how much data a second model needs when learning from predictions and interpretations provided by a pretrained model. Maximizing interpretability may enhance information transfer between models, aiding learning without relying on large datasets. Technical challenges include training GANs for generating realistic images larger than 128x128 pixels, limiting classifier performance in detecting small features like nodules. The method of semi-supervised learning is applied to chest radiographs, showing improved performance in detecting nodules compared to the baseline NIH dataset. This approach can generate visual rationales and has been demonstrated on chest radiographs and the MNIST set."
}