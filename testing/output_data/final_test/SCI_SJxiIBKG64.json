{
    "title": "SJxiIBKG64",
    "content": "Knowledge Graph Embedding (KGE) models have gained attention recently. LiTSE is a temporal KGE model that incorporates time information using linear time series decomposition. It maps temporal KG representations into multi-dimensional Gaussian distributions to account for temporal uncertainty. The mean of entity/relation embeddings shows current expected position, while covariance represents stability over time. LiTSE is a temporal Knowledge Graph Embedding (KGE) model that incorporates time information using linear time series decomposition. It achieves state-of-the-art results in link prediction in temporal KGs and can predict the occurrence time of facts with missing annotations and future events. No other model can perform all these tasks. Various existing KGs like YAGO, NELL, DBpedia, and Freebase are successfully used in applications like question answering and information retrieval, where knowledge is represented as RDF triples. Recently, KGE has become a popular research topic for learning representations of entities and relations in high-dimensional latent feature spaces in graphs. Different KGE models have been proposed to efficiently learn KG representations and perform completion and inferencing tasks. However, most existing models do not utilize temporal information in KGs, which contain time-aware facts. Temporal KGs store temporal information explicitly or implicitly, which traditional KGE models like TransE do not consider. Temporal KGE models incorporate time information in embeddings to improve performance on link prediction over temporal KGs. Some models represent time as a vector but struggle to capture properties like time interval length and order of time points. Existing temporal graph embedding models consider entity representation changes over time but overlook uncertainty. The evolution of entity representations in temporal knowledge graph embeddings has randomness due to uncertainty. A new temporal KGE model based on linear time series decomposition (LiTSE) captures this evolution process by incorporating random components like Gaussian noise to handle sudden changes in semantic characteristics. LiTSE is a KGE model that represents entities and relations in temporal knowledge graphs as multi-dimensional Gaussian distributions, incorporating time information to capture evolution processes. It introduces random components like Gaussian noise to handle uncertainty and sudden changes in semantic characteristics. LiTSE is a KGE model that incorporates time information into KG representations by fitting the evolution process as a linear function of time. It predicts future occurrences based on past trends and considers temporal uncertainty by modeling entities as Gaussian distributions at each time step. The model can perform link prediction in temporal KGs and estimate the occurrence time of facts with missing time information. Our models can estimate the occurrence time of a fact with missing time annotation and predict future events. The paper is organized into sections reviewing related works, introducing our model, evaluating it against state-of-the-art models, and concluding. Research in KGE includes semantic matching models like RESCAL, DistMult, ComplEx, ConvE, and translational distance models like TransE, TransH, TransD. These models measure plausibility by matching latent semantics or translational distances of entities and relations. KG2E, TransE BID2, TransH BID22, and TransD are models that measure the plausibility of facts in knowledge graphs by calculating distances between entities and relations. KG2E incorporates uncertainties in KG representations by using random vectors from multivariate Gaussian distributions. These models have shown good results in link prediction. Recent research suggests that incorporating time information in temporal KGs can further improve KGE model performance. TAE BID17 enforces temporal order constraints on relation pairs, enhancing the model's accuracy. Know-Evolve BID18 models the temporal evolution of entity representations as individual temporal point processes, unlike TAE, TTransE, and HyTE which use time information differently in knowledge graph embedding models. In this paper, the temporal evolution of entity/relation representations is fitted using linear time series decomposition to observe and predict time information. Future events can be predicted based on the evolution trends of entity/relation representations. The uncertainty of temporal KGs is modeled by mapping entity and relation representations in a space of multi-dimensional Gaussian distributions to capture randomness during temporal evolution. In temporal KGs, LiTSE method incorporates temporal meta-data using linear time series decomposition, decomposing a time series into trend, cyclical, seasonal, and irregular components. The evolution of entity/relation representation is viewed as a linear time series with two components. The LiTSE method decomposes temporal KGs into trend and noise components, simplifying the model architecture and enabling time prediction. This approach avoids introducing too many parameters and improves model training efficiency compared to using a moving-average model. The LiTSE method uses Gaussian noise for time series decomposition and incorporates temporal information into traditional KGs by adding a new temporal dimension to fact triples. Time-specific representations of entities and relations are updated at each time step to ensure accuracy. The LiTSEE model incorporates time information into entity representations using a linear function to fit the evolution processes of entity representations. The model avoids redundancy by only incorporating time information into either entity representations or relation representations, not both. The LiTSEE model incorporates time information into entity representations using a linear function to fit the evolution processes of entity representations. In LiTSEE G, a translation-based scoring function is used to measure the plausibility of a fact, considering temporal uncertainty with Gaussian probability distributions. The advanced LiTSEE G model represents entities and predicates as Gaussian distributions, with embedding representations denoted by mean vectors and covariance matrices. The transformation result from subject to object in LiTSEE G is akin to the predicate in a positive fact. The LiTSEE G model incorporates time information into entity representations using Gaussian distributions. It uses a scoring function based on KL divergence to measure the similarity between entity-transformed distribution and relation distribution. The model represents entities and predicates with mean vectors and covariance matrices. The LiTSEE G model incorporates time information into entity representations using Gaussian distributions. It computes gradients of Equation 3 with respect to latent feature vectors, evolutionary direction vectors, and covariance matrix. LiTSER G extends LiTSER by adding a Gaussian noise component into the linear evolution function. The architectures of LiTSER and LiTSER G are similar to LiTSEE and LiTSEE G. The models are trained by minimizing the margin-based ranking loss. Incorporating time information into entity representations using Gaussian distributions, the model minimizes margin-based ranking loss. Negative samples are generated by corrupting positives and adding extra negatives for time prediction. Regularizations are added to avoid overfitting while learning Gaussian embeddings. Uniform negative sampling is used for link prediction and future event prediction to compare with baseline models. The model incorporates time information into entity representations using Gaussian distributions and minimizes margin-based ranking loss. Regularizations are added to avoid overfitting while learning Gaussian embeddings. Constraints for mean and covariance are considered during initialization and training. LiTSE is compared with state-of-the-art baselines on link prediction, time prediction, and future event prediction tasks using datasets like ICEWS14, ICEWS05-15, and YAGO11K. The curr_chunk discusses datasets ICEWS14, ICEWS05-15, and YAGO11K used for link prediction, time prediction, and future event prediction tasks. The datasets are split into training, validation, and test sets for model evaluation. The model is trained on the training set and evaluates quadruples in the test set for positivity. Decision-making is based on relation-specific thresholds determined on the validation set. Comparison is made with various KGE models for link prediction, including TransE, DistMult, KG2E, ComplEx, ConvE, TTransE, TA-TransE, TA-DistMult, and HyTE. The proposed models are compared for time prediction, as existing models are unable to represent future time steps. We compared our models with existing KGE models for future event prediction, implementing them in PyTorch. Adagrad optimizer was used for training with hyperparameters selected based on MRR on the validation set. Iterations were limited to 5000, batch size was set at 512, and parameters like embedding dimensionalities, learning rates, and ratios were tuned. Translation-based models varied margins, while semantic matching models chose regularizer weights. For ConvE and Gaussian embedding models, various parameters were selected such as dropout rates, covariance restrictions, and default configurations. The optimal configuration for LiTSEE on YAGO11k D included specific learning rates and gamma values. Link prediction results were presented for different models, with the best results highlighted. The optimal configurations for LiTSEE, LiTSER, and LiTSER G were determined for different datasets. LiTSEE G outperformed other models in link prediction tasks on ICEWS14 and ICEWS05-15. TransE by BID6 achieved the best MR in these datasets. BID6 had the best MR in ICEWS14 and ICEWS05-15 datasets. BID20 found that increasing the ratio of negatives to positives (\u03b7) improved KGE models. ConvE and ComplEx outperformed KG2E on static KGs. Modeling temporal uncertainty with multi-dimensional Gaussian distribution improved KGE model performance on temporal KGs. Time information was corrupted to generate negative samples for time prediction. Our proposed models' results are shown in TAB5. Our proposed LiTSE model incorporates time information into KG representations for time prediction. Despite high MAEs, 57.5% of prediction errors on ICEWS14 were under 10 days, demonstrating the method's effectiveness. LiTSE fits the temporal evolution of KG representations as linear time series, enabling it to estimate missing time annotations and predict future events. LiTSE incorporates time information into KG representations by mapping them into multi-dimensional Gaussian distributions. Experimental results show significant improvement in link prediction and future event prediction. The method can also predict the occurrence time of a fact and encode temporal rules. This work establishes a connection between relational processes and time series analysis, opening new research directions. Future work will explore using other time series analysis techniques to model temporal evolution in KG representations. The text discusses incorporating temporal rules into embedding models for knowledge graphs. It includes details on regularizing covariances, dataset statistics for future event prediction, and time spans for training, validation, and test sets. The goal is to encode temporal rules into the proposed models. The text discusses the time spans for training and validation sets of ICEWS14 and ICEWS05-15 datasets. It compares the space complexities of baseline models and their proposed models, highlighting similarities in space complexities with traditional KGE models. It also mentions that TTransE and HyTE have higher space complexities compared to their models if the number of entities and relations is larger. The text compares the space complexities of baseline models and their proposed models, noting similarities with traditional KGE models. It mentions that TTransE and HyTE have higher space complexities with larger numbers of entities and relations."
}