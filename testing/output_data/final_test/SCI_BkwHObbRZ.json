{
    "title": "BkwHObbRZ",
    "content": "We analyze learning a one-hidden-layer neural network with Gaussian input x and label y. The population risk formula for squared loss decomposes low-rank tensors. A non-convex objective function G is designed with guaranteed properties. The non-convex objective function $G$ has global minima that correspond to ground truth parameters, and all local minima are also global minima. The value and gradient of $G$ can be estimated using samples. Stochastic gradient descent on $G$ converges to the global minimum and learns ground-truth parameters. Finite sample complexity results are proven and validated through simulations. Scalable optimization is crucial for deep learning success in artificial intelligence. Designing new models like over-parameterization, batch-normalization, and residual networks improve optimization landscape. This paper focuses on learning neural networks with one hidden layer. This paper studies learning neural networks with one hidden layer using a non-convex objective function. The objective function is designed such that all local minima are global minima, and the global minima are the desired solutions. The input is assumed to come from a Gaussian distribution, and the label is modeled accordingly. The paper discusses learning neural networks with one hidden layer using a non-convex objective function. The input is assumed to come from a Gaussian distribution, and the label is modeled accordingly. The learning objective involves optimizing a 2 loss function with training parameters a and B. The ReLU function is considered for activation, and rows of B are assumed to have a norm of 1 for scaling purposes. When training neural networks with ReLU activation and an orthogonal matrix B, stochastic gradient descent struggles to converge to the ground-truth parameters even with infinite samples. This phenomenon extends to sigmoid activation as well. Empirical evidence suggests that over-parameterization is crucial for successful training, as spurious local minima with higher error than the global minimum exist in the population risk function. The population risk function exhibits inferior error compared to the global minimum, even with known parameters. Over-parameterization alleviates this issue empirically. Our method, detailed in the next section, does not require over-parameterization and is suitable for recovering true parameters. The landscape of the population risk function is studied to achieve learning with the same number of training parameters as the ground-truth model. The formula for the population risk function shows it attempts to solve multiple low-rank tensor decomposition problems simultaneously. This inspires the design of a new training model. The new training model is designed based on a formula for solving low-rank tensor decomposition problems. The associated loss function is named f and is used for decomposing matrices and 4th order tensors. Stochastic gradient descent on f is used to learn the network. A more sophisticated objective G(\u00b7) is designed with a provably nice landscape where all local minima are global and correspond to true parameter permutations. The value and gradient of G can be estimated using samples, allowing for straightforward optimization with no constraints using SGD. The authors introduce a new training model based on low-rank tensor decomposition. They design a sophisticated objective function G(\u00b7) with a nice landscape where all local minima are global. The empirical version of G shares similar properties as G itself, allowing for optimization with stochastic gradient descent. Previous works have focused on provable algorithms for learning deep neural networks and special cases of neural networks using kernel methods. The approach uses score function to estimate high order tensors for true components and applies tensor decompositions to recover parameters, particularly for Gaussian input distribution. Recent papers analyze theoretical properties of non-convex optimization algorithms for one-hidden-layer neural networks, focusing on population risk and stochastic gradient descent recovery of ground-truth parameters. Zhang et al. (2017a) study optimization landscape of learning one-hidden-layer neural networks with specific activation function. Our algorithm provides global convergence for gradient-based methods in learning one-hidden-layer neural networks with various activation functions and full-rank weight matrices. Previous studies have shown that deep neural networks do not have bad local minima but contain degenerate saddle points. Re-parametrization techniques, such as using identity connections in residual networks, can help eliminate these degenerate saddle points in the optimization landscape. The optimization landscape of deep linear residual networks has been analyzed, showing that over-parameterized neural networks do not have bad differentiable local minimums. Various machine learning problems have also been studied, including SVD/PCA, phase retrieval, and matrix completion. Additional regularization terms have been introduced to address spurious local minimums caused by weights and constraints. The text discusses notations for matrices and tensors, as well as the interpretation of a natural 2 loss for a one-hidden-layer neural network. It also mentions parameterizing the prediction model and using 2 as the empirical loss. The text introduces notations for matrices and tensors, and discusses the population risk for tensor decomposition using unit vectors. It provides an analytic formula for the population risk and connects it to tensor decomposition, highlighting the k-th summand in the equation. The objective is to decompose a k-order rank-m tensor into rank-1 components. Optimizing the population risk using stochastic gradient descent is challenging, as shown in experiments with zero noise. The landscape of the population risk may have spurious local minima. When \u03c3 = ReLU, \u03c30 = 0, and for n \u2265 2, \u03c3n = 0 for odd n and \u03c3n = 1 for even n. The objective is to decompose a k-order rank-m tensor into rank-1 components. A new objective function is designed based on tensor decomposition, using normalized probabilists' Hermite polynomials. Stochastic gradient descent on this objective converges to the ground truth or its equivalent permutations. The landscape of the objective function f for tensor decomposition is technically challenging to analyze and may provide insights into loss function with permutation invariance. The population risk lacks theoretical guarantees and may not converge to true parameters when adversarially chosen. Another objective is designed to address this issue. To address the convergence issue of SGD, a new objective function G(\u00b7) is designed with a provably nice landscape where all local minima are global minima. The objective function G(B) is defined with smooth functions \u03c6 and \u03d5, with easily computable derivatives. Sampling G(\u00b7) is straightforward as it is an average of functions of examples and parameters. The objective function G(B) is defined as an average of functions of examples and parameters. The method works when a i > 0 for every i. The landscape of G(\u00b7) is characterized by Theorem 2.3, with specific conditions on activation function \u03c3, parameters \u00b5, \u03bb, and matrix B. The function G(\u00b7) defined in equation (2.7) has local minima that are also global minima. Saddle points have strictly negative curvature. Approximate local minima can be written as B = PDB + EB, where B is close to a global minimum in Euclidean distance. Theorem implies learning B is possible with large \u03bb. By optimizing G(\u00b7) with stochastic gradient descent and setting \u03bb sufficiently large, we can learn B (up to permutation of rows and sign-flip). The diagonal matrix D is close to identity, leading to a local minimum B that is close to the global minimum. Using SGD, we converge to a local minimum BID7, which is also a global minimum for G(\u00b7). The theorem will be proven in Section B as a corollary of Theorem B.1, ensuring convergence to a local minimum. After optimizing G(\u00b7) with stochastic gradient descent and setting \u03bb sufficiently large, we can learn matrix B. The algorithm converges to an approximate global minimum B that is \u03b5-close to a global minimum in polynomial time. By fixing B, we can easily recover the coefficient a using linear regression. The key step in analyzing objective G(B) is a theorem that provides an analytic formula for G(\u00b7). In the most general setting, converging to a local minimum of a non-convex function is NP-hard. The function G(\u00b7) satisfies DISPLAYFORM1 Theorem 2.6 is proved in Section A. Section 3 provides a brief overview of design choices, while Section B formally analyzes the landscape of G. The empirical risk G's landscape is characterized, showing that stochastic gradient descent converges to ground-truth parameters with a polynomial number of samples. With N empirical samples, if N \u2265 poly(d, 1/\u03b5), the landscape of G has properties similar to Theorem 2.3. In Section C, the design of objective function G(\u00b7) is discussed, focusing on unbiased estimators via samples. A specific function is chosen with no spurious local minimums and a global minimum corresponding to ground-truth parameters. Analytic formulas for population risk f are provided, guiding the development of better objective functions. The lesson learned helps in designing better objective functions. The proof of Theorem 2.1 relies on the fact that for any continuous and bounded function \u03b3, we have \u03c3 k = h k , \u03c3. By choosing \u03b3 = h k, we can access functions involving weighted sums of powers of b i. Using Fourier analysis tools, symmetric polynomials over variables b i, b j can be estimated by samples. Claim 3.1 states the existence of corresponding functions for polynomials. The focus is on special cases in Theorem A.5 and Theorem A.6. Objective functions are chosen to avoid spurious local minimums. Permutation invariance poses technical challenges in designing objective functions for neural networks. The objective function used in BID7 guarantees permutation invariance and avoids spurious local minima. The function lacks weighting a i's, which will be addressed later. Assuming B is an orthonormal matrix, any permutation or sign-flip of its rows leads to a global minimum of the function P(B). Permutation and sign-flip of rows of B result in a global minimum of P(\u00b7). P(B) = 0 when B = SQB with a permutation matrix Q and a sign matrix S. These permutations of B are the only local minima of function P(\u00b7). Eigenvector problems have no spurious local minimums. The function P(B) does not involve coefficients a i's. The function P(B) does not involve coefficients a i's and aims to remove spurious local minima by adding a regularization term. This term pushes each row of B to be close to one of the rows of B. The objective function for decomposing tensor i a i b i \u22974 involves pushing each b i towards one of the b i 's. Adding a regularization term helps remove spurious local minima and enforces constraints without the need for specialized procedures. The regularization term enforces constraints for the orthogonal case, extendable to non-orthogonal cases without prior statistics estimation. The objective function minimizes a degree-4 polynomial G(B) with SGD, recovering a after B value retrieval. In this section, simple simulation results show that minimizing G(B) with SGD recovers a permutation of B, while minimizing Equation (2.2) with SGD leads to spurious local minima. Empirical verification of the population risk formula in Equation (2.3) supports the conjecture that SGD can successfully recover B using specific activation functions, even when data is generated from a different model. Experiments with B = Id d\u00d7d and a = 1, data from one-hidden-layer networks, and stochastic gradient descent are conducted to test convergence to a matrix B equivalent up to permutation. Without over-parameterization, using ReLU as an activation function, SGD does not converge to zero test error and ground-truth parameters. The step-size was decreased by a factor of 4 every 5000 iterations after the error plateaus at 10000 iterations. SGD with projection to the set of matrices B with row norm 1 converges to the ground-truth parameters using the activation function \u03c3 2 h 2 +\u03c3 4 h 4. The algorithm first gets close to a saddle point before breaking. The algorithm converges to a global minimum after approaching a saddle point. Using the loss function G(\u00b7) requires larger batch sizes for gradient variance reduction. Different batch sizes were used for different functions in the experiment. A novel population loss function is designed to avoid spurious local minima. The paper provides an analytic formula for the population risk of the standard 2 loss. The objective is to create well-behaved landscape for optimization. The techniques developed may be useful for other optimization settings. The paper conjectures that the objective function has no spurious local minimum under certain conditions and provides empirical evidence. The results assume a Gaussian input distribution, with potential for extension to other distributions. The Hermite polynomials are used in the proofs due to their nice properties. The Hermite polynomials are utilized in the proofs due to their properties. A claim connects them to the coefficients of a certain exponential function's Taylor expansion. Expectations involving correlated Gaussian random variables can be easily computed. The paper also discusses computing functions in the Hermite basis. In this section, Theorem 2.1 and Theorem 2.2 are proven using spherical standard normal random variables. The population risk is defined using Hermite coefficients of functions \u03c3 and \u03b3, showing that each Hermite polynomial influences the risk independently. The population risk G(\u00b7) is analyzed using orthogonal polynomials with respect to the Gaussian measure. The analytical formula for G(\u00b7) is crucial for the landscape analysis in Section B, derived from Theorems A.5 and A.6. The proof involves expanding equation (A.1) using Lemma A.7 with fixed vectors u, v, and random variable x \u223c N(0, Id d\u00d7d). The proof involves extending results to different scaling, verifying special cases, and using Lemmas A.8 and A.7 to prove Theorems A.6 and A.5. The function \u03c6(v, w, x) is designed for this purpose. The function \u03c6(v, w, x) is designed to estimate u, v, and w. Lemma A.9 is used to prove Theorem A.5 by applying it to every summand. The landscape property is assumed to be invariant with respect to rotations of parameters. In this section, the identity matrix B is denoted as Id. The population risk G(\u00b7) is equal to a specific formula when B = Id. A more general version of the function G, denoted as G \u03b1,\u03b2,\u00b5, is studied for future reference. Theorem B.1 extends Theorem 2.3, showing that B can be expressed as DP + E, where P is a permutation matrix, D is a diagonal matrix, and E is an error matrix satisfying certain conditions. Theorem 2.3 follows from Theorem B.1 by setting specific parameters. The proof of Theorem B.1 involves analyzing the properties of a local minimum matrix B. The first step is to focus on a single row of B as variables. Local optimality implies that each row corresponds to a different basis vector, making B a permutation matrix. The lemma in the curr_chunk discusses the properties of a local minimum of the objective function h(\u00b7), showing that it must be a scaling of a basis vector. It introduces parameters \u03b5 and \u03c4 and provides conditions for a point x to satisfy the minimum criteria. The lemma in the curr_chunk proves that a local minimum of function h(\u00b7) must be a scaling of a basis vector. It introduces parameters \u03b5 and \u03c4, and conditions for a point x to meet the minimum criteria. The proof involves analyzing the gradient and Hessian of h(\u00b7) and the indices of coordinates significantly away from zero. It concludes by showing that the assumption of \u03bb min (\u2207 2 h(x)) \u2265 contradicts the derived results. The lemma in the curr_chunk establishes conditions for a local minimum of function h(\u00b7) to be a scaling of a basis vector. It introduces parameters \u03b5 and \u03c4, and criteria for a point x to meet the minimum conditions. The proof involves analyzing the gradient and Hessian of h(\u00b7) and the indices of coordinates significantly away from zero. It concludes by showing that the assumption of \u03bb min (\u2207 2 h(x)) \u2265 contradicts the derived results. The lemma establishes conditions for a local minimum of function h(\u00b7) to be a scaling of a basis vector based on parameters \u03b5 and \u03c4. It involves analyzing the gradient and Hessian of h(\u00b7) and the indices of coordinates significantly away from zero. The proof shows that x 2 \u2264 2 and x 2 \u2265 1 2 under different conditions, concluding with a contradiction to the assumption of \u03bb min (\u2207 2 h(x)) \u2265 0. The lemma strengthens the result by showing that not all basis vectors can be local minima, requiring the coefficient \u03b1 to be reasonably small. If \u03b1 is large compared to other entries, moving the mass of a basis vector to another index will likely decrease the objective function. The lemma establishes conditions for a local minimum of function h(\u00b7) to be a scaling of a basis vector based on parameters \u03b5 and \u03c4. If \u03c4 \u2264 0.1\u03b2 min /d and \u03b5 \u2264 \u03c4 3 /\u03b2 min , then the proof involves algebraic manipulation to show that the local minimum x can be written as x = x i e i, where i is likely the argmin of \u03b1. This strengthens the result by establishing conditions for a local minimum of function h(\u00b7) to be a scaling of a basis vector based on parameters \u03b5 and \u03c4. Lemma B.5 strengthens the bound in Lemma B.2 by introducing conditions for a local minimum of function h(\u00b7) to be a scaling of a basis vector. The error bound in Theorem B.1 is dependent only on \u03b5, ensuring it approaches zero as \u03b5 approaches zero. The matrix B can be written as DISPLAYFORM14 DISPLAYFORM15 where D is diagonal with |D ii | \u2208 [1/4, 2], and P is a permutation matrix, and |E| \u221e \u2264 \u03b4. The proof shows that in a local minimum of B, each row has a unique large entry, and the largest entries of each row sit on different columns to avoid violating certain conditions. The proof contradicts the assumption that B is a local minimum by showing that each row of B has only one large entry and the largest entries of each row are on distinct columns. The proof shows that each row of B has only one large entry and the largest entries of each row are on distinct columns. It is demonstrated that if two rows have the same largest entry on a column, then certain inequalities hold, leading to a contradiction. The proof demonstrates that each row of matrix B has only one large entry, with the largest entries on distinct columns. By applying certain inequalities, it is shown that the largest entry of each row falls between 1/4 and 2. This leads to the conclusion that the matrix E, obtained by subtracting P D from B, satisfies certain conditions, completing the proof. The proof strengthens Proposition B.6 with better error bounds and control of column entries. If \u03c4 \u2264 c\u00b5\u03b2 2 min /\u03b2 max, matrix B can be written as DISPLAYFORM12 with P permutation matrix, D diagonal such that DISPLAYFORM13 and DISPLAYFORM14. By Lemma B.5, error bounds are improved, fixing an arbitrary s \u2208 [d] and viewing G \u03b1,\u03b2,\u00b5 as a function of DISPLAYFORM16 2. The condition of Lemma B.5 is verified for the largest entry in absolute value. The proof strengthens Proposition B.6 with better error bounds and control of column entries. By verifying the condition of Lemma B.5 for the largest entry in absolute value, we obtain improved error bounds. For any row s, the bound for the entries in D is given as |E| \u221e \u2264 3\u03b5 \u03b2min. The proof of Theorem B.1 strengthens Proposition B.6 with improved error bounds and control of column entries. By setting \u03b5 = 0, \u03c4 = 0 in Proposition B.6, it is shown that any local minimum B satisfies B = DP, where P is a permutation matrix and D is a diagonal matrix with precise diagonal entries. All these points have the same function value, making them all global minimizers. The proof shows that all points with the same function value are global minimizers. A saddle point B satisfies \u2207G(B) = 0, and it is proven that \u03bb min (\u2207 2 G(B)) \u2264 \u2212\u03c4 0. The 3rd bullet rephrases Proposition B.7, demonstrating that local minima are preserved by linear transformations. An objective function F(B) equivalent to G(B) allows for the characterization of local minima using Theorem 2.3. Theorem 2.3 can be used to characterize all local minima of a function F through linear transformations. The relationship between local minima of functions f and g, connected by gradients and Hessians, shows a 1-1 mapping with differences in norms and eigenvalues. The mapping between functions f and g, with norms/eigenvalues differing multiplicatively by quantities related to the matrix spectrum of W. Theorem C.1 states that for full rank matrix W, functions g and f related by g(x) = f(Wx) satisfy optimality conditions. The proof involves gradients and second-order derivatives, simplifying notation with A = \u2207^2f(Wx). The unit vector y minimizing yAy is in the column span. The unit vector y minimizing yAy is in the column span of W. A new objective function is designed to be linearly transformed to the orthonormal case by viewing the rows of B as the new basis. The objective function is optimized to ensure the \"norm\" of bj in the basis defined by the row of B to be 1. The objective function is optimized by choosing \u03b1 i = a i, computed as expectations where (x, y) is an independent sample. Finding a linear transformation to make {b i}'s orthonormal reduces the problem to the orthonormal case. The whitening matrix is the key to this transformation. The Theorem shows that the objective function can be rotated properly to match the ground-truth vector o i's. The text discusses a linear transformation using vector format and coefficients 1/a i instead of a i. It presents a corollary with conditions for a matrix B to be a local minimum of a function G. The text discusses conditions for a matrix B to be a local minimum of a function F, involving permutation matrices, diagonal matrices, and specific constraints on curvature and gradients. The text discusses conditions for a matrix B to be a local minimum of a function F, involving permutation matrices, diagonal matrices, and specific constraints on curvature and gradients. The properties of local minima of F are derived from those of G using transformation matrices. The SVD of matrix M is M = U DU, and the singular values follow from the SVD of M and W. Local minima of function F are of the form BW, where B is a local minimum of G. The gradient and Hessian of F(B) and G(B) are related. All local minima of F must be of the form B = BW = P D\u0393B W W = P D\u0393B M \u22121. The rows of matrix B\u2212 are permutations of ai bi. Property 2 in Theorem C.1 implies that B can be expressed as P DO + E where D is a diagonal matrix, P is a permutation matrix, and E is bounded by a certain value. When E is small enough, B can be defined as BW. In this section, we show how to handle the case when the number of components is smaller than the dimension (m < d). The objective function F only depends on the inner-products b j , b i. The previous objective function only depends on the projection of B in the space S. The local optimum of F (B) can have different conditions without modifying the objective. In this section, the objective function F is modified to prevent arbitrary components in the orthogonal subspace. By adding an additional regularizer, the algorithm aims to recover a matrix B that is close to the original matrix. The key observation is that the correlation between the components of B and the output y is proportional to a. Different methods, such as linear regression, can also be used to recover a, but the chosen algorithm is for ease of analysis. In this section, the algorithm aims to recover a matrix B that is close to the original matrix by adding a regularizer to prevent arbitrary components in the orthogonal subspace. The algorithm uses a simple method to estimate a and B, ensuring that a permutation exists where a and B are close to the original matrix. The proof relies on the property of Hermite polynomials and the correlation between the components of B and the output y. The algorithm aims to recover a matrix B close to the original by adding a regularizer. It uses a method to estimate a and B, ensuring a permutation exists where they are close to the original. The proof relies on Hermite polynomials and the correlation between B components and the output y. The algorithm aims to recover a matrix B close to the original by adding a regularizer. It uses a method to estimate a and B, ensuring a permutation exists where they are close to the original. The proof relies on Hermite polynomials and the correlation between B components and the output y. In this section, it is shown that the algorithm only requires polynomially many samples to find the desired solution. The proof of uniform convergence shows that with polynomially many samples, the gradient and Hessian of G are point-wise close to the gradient and Hessian of G, ensuring approximate local minimums. Technical issues arise with large norms of B affecting concentration and the non-subGaussian nature of the objective function, addressed through specific arguments. The function does not change significantly when Gaussian variables have bounded norm. A lemma states conditions for a polynomial function, with bounded coefficients, and its gradient and Hessian. Concentration bounds are used to show the probability of certain events. The curr_chunk discusses the boundedness of gradients and Hessians in relation to a function, along with a theorem proving universal convergence. This is in line with the previous discussion on conditions for polynomial functions with bounded coefficients. Theorem 2.7 states that for matrices B with rows having norm at most 2, the gradients and Hessians of a function G are close to a truncated version of G. If a row in B has a large norm, the gradient must also be large, indicating B cannot be an approximate local minimum. Lemma E.5 provides conditions for this scenario, showing that with high probability, the gradient of B is large. Theorem 2.7 discusses matrices B with rows having norm at most 2, stating that gradients and Hessians of a function G are close to a truncated version of G. Lemma E.5 provides conditions for scenarios where a row in B has a large norm, indicating B cannot be an approximate local minimum. In the current chunk, it is shown that for a local perturbation with \u03b5 1 , \u03b5 2 \u2264 \u03b5, and certain conditions on b 3 (2), b 4 (3), and b 4 (4), the objective function P (B) \u2265 1 when \u03b5 is small enough, making B a local minima of P."
}