{
    "title": "S1EfylZ0Z",
    "content": "Anomaly detection methods are lacking for high-dimensional spaces like images. A novel approach using generative adversarial networks shows state-of-the-art performance on image datasets. Automatic anomaly detection is crucial in various fields such as astronomy and medicine. Deep learning has become the preferred method for high-dimensional machine learning tasks due to its ability to automatically engineer features. It has shown impressive results in image classification, natural language processing, and speech recognition. A new approach using generative adversarial networks (GANs) has achieved state-of-the-art performance in anomaly detection for high-dimensional data like images. Generative adversarial networks (GANs) have excelled in high-dimensional generative modeling by pitting a discriminator against a generator. The generator learns to map low-dimensional samples to high-dimensional space, mimicking the target dataset. Anomaly detection with GANs (ADGAN) leverages this correspondence. Previous work on anomaly detection is discussed, followed by a description of the proposed algorithm. Experiments are detailed in Section 4. In Section 3, the proposed algorithm is described, showcasing ADGAN's ability to detect anomalies in high-dimensional data. Previous work on anomaly detection, generative models, and GAN methodology are briefly reviewed. Anomaly detection involves finding unusual samples in data, with traditional methods and challenges discussed in literature. Generative models estimate data distribution to identify anomalies, following a guideline of declaring unlikely samples as anomalous. Recent research has explored various methods for anomaly detection, including traditional non-parametric methods like kernel density estimation and generative models such as variational autoencoders and deep convolutional neural networks. These approaches aim to identify anomalies by estimating data distribution and generating samples resembling the data. Our approach uses a deep generative model for anomaly detection, overcoming the limitations of non-parametric methods. Deep neural networks have shown promise in addressing high-dimensional data analysis challenges. Hybrid techniques like deep belief networks combined with support vector machines have been explored for anomaly detection. Pretraining networks on tasks like ImageNet classification can also be effective for extracting relevant information from images. Our approach utilizes deep generative models for anomaly detection, leveraging GANs to extract relevant information from images. GANs have set a new state-of-the-art in generative image modeling by learning the parametrization of a neural network to generate samples approximating the distribution of training data. The approach utilizes GANs for anomaly detection by generating samples in the image space using a neural network. A discriminator learns to classify data from the generated distribution, improving through alternating training. The process involves generating consecutive images to assess similarity to training data for anomaly detection. The GAN framework involves generating samples to approximate a distribution, with the objective function equating to an empirical lower bound of an f-divergence. GAN training difficulties stem from vanishing gradients in high-dimensional spaces, which can be addressed by using integral probability metrics like the 1-Wasserstein distance. This distance measures the work needed to pull one density onto another and forms the basis of Wasserstein GANs. The WGANs function, DISPLAYFORM2, restricts the discriminator to 1-Lipschitz functions. WGAN training is stable and used in experiments. The proposed ADGAN method sets in after GAN training convergence. It checks if a new sample x is distributed according to p by comparing it to a point z in the latent space. If no z exists such that g \u03b8 (z) \u2248 x, then x is not from p. The ADGAN algorithm for anomaly detection uses Generative Adversarial Networks. It involves finding a latent space point z that closely resembles a given sample x by adjusting the generator parameters. This process helps determine if x is anomalous or not. ADGAN improves algorithm performance by adjusting generator parameters \u03b8, not part of training. Search initialized from n seed points to address optimization problem. ADGAN aims to find latent vectors close to inverse generator for anomaly detection. The generator inversion task was previously studied and shown to be successful. It is possible to train the generator without a discriminator, still achieving desirable properties of GANs. However, the discriminator may exploit artifacts induced by the generator once converged. The discriminator exploits artifacts induced by the generator architecture, separating real from forged data but struggles with samples unlike the training data. An alternative approach evaluated the likelihood of final latent vectors under a noise prior, but was outperformed by ADGAN. AnoGAN, a technique for anomaly detection, uses GANs similarly to the proposed algorithm by training a GAN and searching for a point in the latent space to minimize reconstruction loss. ADGAN utilizes a latent space for generating data and computes anomaly scores using a combination of reconstruction loss and discriminator layer. The discriminator is discarded after training, allowing ADGAN to be easily combined with various GAN-based approaches. It addresses non-convex optimization by seeding from multiple areas in the latent space and updates both latent vectors and generator parameters during inference. Experimental evidence demonstrates the effectiveness of ADGAN in comparison to other methods for anomaly detection. ADGAN outperforms non-parametric and deep learning approaches in anomaly detection tasks on popular image datasets. It shows promising results on large, unsupervised data like LSUN bedrooms. Experiments on benchmark datasets like MNIST demonstrate its superior performance compared to traditional methods like KDE and OC-SVM. The anomaly detection methods evaluated include OC-SVM with a Gaussian kernel, Isolation Forest, and Gaussian Mixture Model. Feature dimensionality was reduced using PCA, and a nonlinear transformation using Alexnet pretrained on Imagenet was also explored. Anomaly detection is performed on the final convolutional layer representation of Alexnet, projected down via PCA to address runtime issues. Performance of VAEs and DCAEs is evaluated based on reconstruction losses and ELBO, with convolutional architectures similar to DCGAN. ADGAN, utilizing batch norm regularizations and ReLU activations, requires a trained generator trained on the WGAN objective for stability. The latent space dimensionality is set to d = 256, with searches initialized from a normal distribution. Optimization is done using the Adam optimizer, with n seed = 8 points to account for non-convexity. More optimization steps in the latent space improve performance when matching test points. In experiments, more optimization steps improved performance. Using k = 5 steps balanced execution time and accuracy. Reconstruction quality was measured with squared L2 loss. The first task evaluated competing methods by training on MNIST data and testing on a subset. Anomaly detection was assessed by assigning higher scores to unseen classes. Receiver operating characteristic (ROC) was analyzed in FIG1 and results were presented in Table 1 and 2. ADGAN performed on-par with traditional methods in inferring anomalies in low-dimensional samples like MNIST. However, performance dropped for all methods on CIFAR-10. ADGAN outperformed others, needing eight seeds to achieve the best result. Non-linear transformation with a pretrained Alexnet did not improve performance for either dataset. Scoring using the GAN discriminator resulted in weak performance, with an average AUC of 0.625 for MNIST and 0.513 for CIFAR-10. In a practical setting with no ground truth information available, ADGAN was used to identify anomalous images within validation sets. The method showed the ability to distinguish usual from unusual samples in LSUN scenes visually. The training set sizes in the experiment limited the use of non-parametric methods like KDE and OC-SVMs. ADGAN can incorporate various properties of an image beyond just colors, such as canonical geometries and the presence of foreign objects. Low anomaly score samples align with an Ideal Form, showing plain colors and no foreign objects. For bedrooms, the least anomalous samples are simply a bed in a room. The method demonstrated state-of-the-art performance on image benchmark datasets and can scan unlabeled images for anomalies. The ADGAN method shows state-of-the-art performance on image benchmark datasets and can scan unlabeled images for anomalies. Additional experiments involve determining anomalous samples of different classes in CIFAR-10, such as birds, cats, and dogs. Further improvements can be made by tuning the neural network architecture or optimizing latent vectors and generator parameterization. Anomalous samples from various classes in CIFAR-10 were analyzed using ADGAN with a search conducted for 100 steps. The highest and lowest reconstruction losses of randomly selected images from the test set were reported in FIG6."
}