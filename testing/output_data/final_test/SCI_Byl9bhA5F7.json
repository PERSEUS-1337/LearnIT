{
    "title": "Byl9bhA5F7",
    "content": "NEMO is an unsupervised object detection approach that uses motion as a cue to learn object detection without the need for image labels. By collecting positive and negative examples through short videos, NEMO can learn object detectors that generalize well to new scenes and camera angles, outperforming template matching and tracking approaches. Object-based representations are a powerful abstraction of our world, enabling efficient generalization, simulation, planning, and communication. Grounding objects in sensory input currently relies on supervised learning, requiring a high number of labeled images. This paper takes a step towards accurate object representations for learning from demonstration in robotics. This paper aims to learn object detection from videos with minimal supervision by utilizing the physical properties of objects. Motion is used as a cue to optimize object-based representations, but visual distractions like camera motion can hinder this process. The paper improves on previous approaches by learning to ignore these distractions. This paper improves object detection from videos by learning to ignore visual distractions through negative examples, addressing challenges like changes between training and test videos. This paper introduces a spatial encoder architecture called NEMO for unsupervised object detection using negative examples and motion-based learning objectives. The method can learn new objects from just two short videos without pretrained models or additional supervision. NEMO is a spatial encoder architecture for unsupervised object detection using short videos without pretrained models or supervision. It can learn object detection in challenging conditions and generalize to new scenes and camera angles. The learned object representations can be applied to tasks like writing or pick-and-place, making robot learning more data-efficient. This work is related to physics-based representation learning, where latent representations are learned by optimizing consistency with physics. This paper introduces a novel approach to object detection in images by learning object embeddings in image coordinates. The approach is robust and efficient, contrasting with other methods that focus on image embeddings. It is also connected to the concept of active perception, where actions aid in perception. The paper discusses the use of motion in object detection and segmentation, combining it with learning to generalize beyond observed motion. It introduces variation, slowness, and presence losses to enforce object detections in consecutive frames. This paper introduces the NEMO approach for weakly supervised object detection, leveraging negative examples and motion cues to compensate for reduced supervision from per-video labels. The NEMO approach for weakly supervised object detection involves learning to detect objects from two videos, a positive one showing the object in motion and a negative one without the object. It optimizes objectives to detect moving objects and presence in the positive video. The spatial encoder network is trained using a combination of random search and gradient descent. The NEMO network architecture, based on deep spatial autoencoders, utilizes a spatial encoder with convolutional layers, residual connections, batch normalization, and ReLU nonlinearities. The spatial encoder consists of multiple residual blocks with specified channels and kernel sizes. The experiments adjust parameters like channels and kernel sizes to control the receptive field of the object detector. The output layer includes a spatial softmax for object location probability distribution. The spatial encoder in the NEMO network architecture produces a probability distribution over the object's location in the image. The mean and mode of this distribution estimate the object's location, with the mode being more robust to distractions during inference. The spatial encoder is trained by minimizing three losses - variation, slowness, and presence. The output of the spatial encoder before the spatial softmax is denoted as DISPLAYFORM0, and after applying the spatial softmax, we get a probability image P(t) and its mean z(t) normalized to [-1, 1]. The variation and slowness losses operate on the mean z in positive frames to measure the detected object's characteristics. The variation loss in the NEMO network architecture measures the proximity of object locations by comparing pairs of z (t) for different t. It enforces that the object does not stay still by ensuring z t+d is different from z t for a range of time differences. The hyperparameters \u03b2, d min, and d max control the distance and time differences for enforcing variation. The slowness loss in the NEMO network architecture measures the squared distance between object locations in consecutive time steps, favoring smooth trajectories. The presence loss computes the probability of the object being present in a positive frame but not in a negative one. These losses are combined in a weighted sum in the network architecture. The losses in the NEMO network architecture, including variation, slowness, and presence, are combined in a weighted sum. The weights are chosen to ensure consistent gradients. Experiments use specific weight values and minibatches for optimization. Additionally, Gaussian noise is added for gradient stability. NEMO addresses the issue of convergence in optimization by combining random search and gradient descent. It initializes the spatial encoder multiple times, optimizes each with a small number of gradient descent steps, and then finetunes the best model. This approach results in fast training times and improved generalization. The experiments evaluate object detection without using pretrained networks or labeled images. The study demonstrates object detection using NEMO, which does not rely on pretrained networks or labeled images. It achieves accurate detections in various settings, including static and moving cameras, single and multiple objects, and new scenes. The results show significant advantages over template matching and tracking methods. The approach involves training on positive and negative videos for a few minutes, without tracking or filtering, and enables learning from demonstration. The algorithm learned to detect a pen in a hand from positive and negative videos, showing precise object detection from only 2.5 minutes of video. The method is invariant to distractions like arm position and camera motion, making it challenging to learn object detection based on motion. The experiment evaluates NEMO on videos recorded with moving cameras to keep the object in view without constantly centering on it. The object detector uses the current frame and a difference image from the previous frame as input, producing consistent results despite camera motion and difficult lighting conditions. The training data for detecting multiple objects in a table top setting includes five videos of about 2 minutes each, with one video per object. The object detector trained on five videos shows mostly correct detections, even under occlusions and different camera angles. However, it occasionally detects the hand as the target object and misplaces objects when occluded. This is due to the spatial encoder always returning the most likely object location. The object detector trained on five videos shows mostly correct detections, even under occlusions and different camera angles. However, it occasionally detects the hand as the target object and misplaces objects when occluded. To improve this, estimating detection uncertainty and setting a certainty threshold could be explored in future work. NEMO's object-based representations enable subsequent learning from demonstrations, as demonstrated in pick-and-place tasks using object detectors. Comparing object locations in demonstrations reveals object movements, and statistics on final object locations describe the task goal for planning. NEMO's performance in object detection and tracking is compared to established template matching and tracking approaches. These baselines require supervision and bounding boxes around initial object locations. NEMO's performance in object detection and tracking is compared to established template matching and tracking approaches. The baselines required supervision and bounding boxes around initial object locations. NEMO, MIL, and KCF showed low error rates in detecting or tracking the pen in one video, but struggled with substantial occlusions and difficult lighting conditions in other videos. Template matching performed poorly in these scenarios, while NEMO was able to solve the videos almost perfectly. NEMO, a novel unsupervised object detection approach, utilizes additional videos for robustness to variations in appearance. This method shows data-efficient and robust object detection without image labels, opening new research directions. Extensions like ensemble methods for uncertainty estimation and integration with tracking or filtering for temporal consistency could further improve the approach. The presented approach aims to improve object detection performance by merging different detectors into a single network. Creating a large-scale dataset for this purpose would be valuable. This method could lead to unsupervised learning of object-based representations, enabling efficient learning, communication, prediction, and planning."
}