{
    "title": "HJgSwyBKvr",
    "content": "Learning disentangled representations is crucial for interpretable machine learning. Weak supervision is being explored as a way to achieve this, but there is no formal framework to guarantee disentanglement. A theoretical framework is proposed to analyze the guarantees of weak supervision coupled with learning algorithms. Empirical verification of weak supervision methods shows the predictive power of the framework. Theoretical framework for disentangled representation learning in machine learning, focusing on unsupervised learning of interpretable factors of variation in datasets. This aligns with the goal of developing explainable and human-controllable machine learning models. Recent research has shifted towards weakly supervised learning methods for building robust disentangled representation learning models, aiming to create interpretable representations without the need for large amounts of supervised data. This approach allows for the development of models with understandable features, even in cases where human labeling is challenging. In this paper, a theoretical framework for weakly supervised disentanglement is presented and evaluated on various datasets. The framework includes definitions for disentanglement inspired by existing literature, a rigorous calculus of disentanglement, and an analysis of weak supervision methods' theoretical guarantees. In disentangled representation learning, weak supervision methods like restricted labeling, match pairing, and rank pairing are experimentally verified for guarantees. The goal is to identify a latent-variable generative model corresponding to data's ground truth factors of variation. The model families, forms of weak supervision, and metrics for evaluating disentanglement are formalized. Data-generating processes involve factors of variation S and observed data X as a function of S. Existing algorithms aim to learn a latent-variable model with prior p(z) and generator g, where g(Z) = g*(S). In disentangled representation learning, weak supervision methods like restricted labeling, match pairing, and rank pairing are used to address entanglement between latent variables Z and generating factors S. By performing distribution matching on an augmented space, guarantees on learned representations can be provided. These forms of weak supervision involve observing a subset of latent variables or sharing information about the data-generating process. In disentangled representation learning, weak supervision methods like restricted labeling and match pairing involve observing subsets of latent variables or sharing information about the data-generating process. Restricted labeling allows for distribution matching on joint data and observed factors, while match pairing uses paired data sharing values for known factors. Match pairing is a weaker form of supervision than restricted labeling in disentangled representation learning. It involves collecting pairs of samples that share the same underlying factor, such as pairs of images with different people wearing the same glasses. Rank Pairing is another form of paired data generation where pairs are generated in an i.i.d. fashion with an additional indicator variable to determine the corresponding latent values. In disentangled representation learning, match pairing involves collecting pairs of samples with the same underlying factor, while rank pairing generates pairs in an i.i.d. fashion with an indicator variable. Weak supervision via ranking is prominent in metric learning literature, focusing on rank pairing for disentanglement guarantees. Generative models can be trained using data sampled from the ground truth model and a distribution matching objective. In disentangled representation learning, weak supervision plays a role in providing guarantees on disentanglement by introducing definitions of consistency and restrictiveness. Different forms of weak supervision enable these concepts on subsets of factors, leading to a calculus of disentanglement. The relationship to prior definitions is discussed, and an illustration of disentanglement, consistency, and restrictiveness is provided. The generative model decodes g(z 1:3) with fixed choices of z 1 and (z 2, z 3). An example of consistency versus restrictiveness in disentanglement models is shown. An oracle generates shapes based on size (S 1), shape (S 2), and color (S 3). The focus is on whether Z 1 disentangles size (S 1) in the generative model by visually inspecting changes in Z 1, Z 2, and Z 3. The inspection checks for consistency in object size (S 1) when Z 1 is fixed and restricted changes in size (S 1) when Z 1 is varied. The text discusses the properties of disentanglement in generative models, focusing on generator consistency and generator restrictiveness. It formalizes these properties within a hypothesis class of generative models, where factors of variation can be recovered from observations. The text also mentions assumptions made on the hypothesis class, including the recoverability of every factor of variation from observations. The text discusses disentanglement in generative models, focusing on generator consistency. It formalizes properties within a hypothesis class where factors of variation can be recovered from observations. Generator consistency is defined by aligning latent variables Z and S, ensuring they are equal in distribution. The goal is to determine if Z disentangles S. The text discusses how latent variables Z and factors S are related in generative models, focusing on generator restrictiveness. It states that resampling Z \\I will not affect the measurement of factors S I, showing that changing Z I only modifies S I. This property is contrasted with previous definitions of disentanglement. In generative models, Z I is restricted to modifying only S I, illustrating generator disentanglement where Z I is consistent with and restricted to S I. This implies the existence of invertible functions aligning S = e * \u2022 g(Z). The alignment between two invertible functions f I and f \\I decomposes the expression S = e * \u2022 g(Z) into disentanglement and invariance. Our proposed definitions focus on consistency and restrictiveness, measuring the behavior of a generative model against an encoder. These definitions are asymmetric and can also be applied to encoder-based consistency, restrictiveness, and disentanglement within our framework. The text discusses encoder-based consistency, restrictiveness, and disentanglement within a framework using an oracle generator. It highlights the ability to check for encoder consistency without needing access to ground truth factors, unlike existing disentanglement definitions and metrics. The text discusses the development of a theoretical framework using encoder-based definitions for consistency and restrictiveness. It emphasizes the ability to measure encoder-based disentanglement on synthetic data and highlights the relationships between restrictiveness and consistency. The text introduces a calculus for discovering relationships between learned latent variables and ground truth factors of variation. It provides a rigorous procedure for reasoning about disentanglement, eliminating the need to prove consistency and restrictiveness for every factor individually. In this section, a calculus is introduced to guarantee full disentanglement by combining multiple supervision methods. It also addresses distinguishing between disentanglement from supervision methods and model inductive bias. In transitioning to supervised approaches, it is essential to formalize disentanglement guarantees with weak supervision. A weak supervision method is considered sufficient for learning a generator that disentangles factors if there exists a learning algorithm that can handle all possible scenarios drawn from a given hypothesis class. This approach prevents the exploitation of model inductive bias. Algorithm A aims to reduce the hypothesis class \u0124 \u2282 H but may fail to handle oracles in the complementary class H \\\u0124. Distribution matching with g(Z) d = g * (S) ensures informative latent codes, preventing trivial solutions. Theoretical framework applied to weak supervision methods like restricted labeling, match pairing, and rank pairing shows that these methods can provide consistency or restrictiveness guarantees on factors. Theoretical guarantees on disentanglement performance are enforced by consistency across all factors. Experimental results in Figure 3 and Figure 5 demonstrate the predictive power of these guarantees. Theorem 1 shows that matching the generated distribution to data distribution under restricted labeling guarantees consistency between Z I and S I. Distribution-matching under various methods ensures consistency for both generator and encoder. In the experiments, theoretical guarantees on disentanglement performance are verified by enforcing consistency across factors. Empirical results confirm the predictive power of these guarantees, demonstrating that matching the generated distribution to data distribution under restricted labeling ensures consistency between Z I and S I. Additionally, distribution-matching methods ensure consistency for both generator and encoder. Our theoretical framework can handle nuisance variables in datasets like SmallNORB and Scream-dSprites. We use GANs for learning, but other distribution matching algorithms could be used. Results are collected over various hyperparameter configurations. Quantitative metrics of disentanglement are measured post-hoc on an encoder. The theory assumes the learned generator must be invertible, which is not true for conventional GANs. Our theoretical framework can handle nuisance variables in datasets like SmallNORB and Scream-dSprites using GANs for learning. The learned generator must be invertible, which is not true for conventional GANs. Empirical results show that invertibility is not an issue in practice. Three sets of experimental results are presented: single-factor experiments, consistency versus restrictiveness experiments, and full disentanglement experiments. Single-factor consistency or restrictiveness can be achieved with the supervision methods of interest. Theoretical framework can handle nuisance variables in datasets using GANs for learning. Special cases of match pairing are share pairing and change pairing. Heatmap visualization shows different supervision methods on Shapes3D. Share pairing, change pairing, and rank pairing are sufficient for consistency. Change pairing guarantees restrictiveness. The heatmap results for different supervision methods on Shapes3D show normalized consistency and restrictiveness scores. The normalization procedure is similar to Interventional Robustness Score. The final heatmap illustrates the calculus of intersection, suggesting acquiring paired data where multiple factors change simultaneously. Our calculus predicts that training on datasets where S I and S J are changed guarantees restrictiveness on S I\u2229J. The final heatmap shows intersection settings and measures the normalized restrictiveness score. Inconsistencies are attributed to GAN failure in distribution-matching due to hyperparameter sensitivity. Consistency and restrictiveness correlation is determined practically with collected Shapes3D models. The correlation between consistency and restrictiveness in training models on real-world data has been a source of confusion in disentanglement literature. Many have believed that restricted labeling or shared pairing guarantees disentanglement, but our results show a strong correlation between the two. This correlation is not guaranteed by weak supervision but is a consequence of model inductive bias. It remains unclear why consistency and restrictiveness are so strongly correlated in existing models. Our results show a strong correlation between consistency and restrictiveness in training models on real-world data. Training on complete share/change/rank-pairing data can guarantee full disentanglement, as seen in Figure 5. The performance of various GAN models on disentanglement metrics is evaluated, showing the potential for full disentanglement with the right data. In this work, a theoretical framework is constructed to analyze the disentanglement guarantees of weak supervision algorithms. The paper clarifies important concepts and distinguishes when disentanglement arises from supervision versus model inductive bias. Through theory and experiments, the conditions under which various supervision strategies guarantee disentanglement are demonstrated, inspiring future research directions. The authors hope their work inspires further scrutiny of inductive biases in models and the search for new learning algorithms with theoretical guarantees. They also aim to facilitate the analysis of weak supervision methods. The appendix elaborates on connections between disentanglement definitions and introduces new metrics for evaluation. The appendix expands on disentanglement definitions, introduces new evaluation metrics, and presents additional experiments on consistency and restrictiveness. In the appendix, various metrics of disentanglement are discussed, including modularity, compactness, and explicitness. Different definitions from literature are referenced, with a focus on the terminology proposed by Ridgeway & Mozer (2018). In this paper, the authors suggest decomposing explicitness into latent code informativeness and focus on comparing consistency and restrictiveness to modularity and compactness. Restrictiveness is not the same as modularity or compactness, as shown in Figure 2c where individual Z i is not predictable from factor S i. Therefore, Z 1 is not a modular or compact representation. The authors compare consistency and restrictiveness to modularity and compactness in decomposing explicitness. Z 1 is not a modular or compact representation, as it is not predictable from factor S i. Existing definitions of disentanglement measure mutual information between Z and S, but consistency and restrictiveness are invariant to statistically dependent factors. Consistency and restrictiveness rely on conditional resampling to ensure invariance to resampling of Z \\I when conditioned on Z I. These concepts serve as core primitive concepts for weak supervision guarantees and are amenable to theoretical analysis. We calculated normalized consistency and restrictiveness scores on 12800 models to analyze the relationship between consistency and restrictiveness. Using these scores as probes, we identified models with high consistency but low restrictiveness, and vice versa. Two models were highlighted for object color representation on the Shapes3D dataset, showing either consistent representation or restrictive to object color. The theoretical framework can handle nuisance variables that we cannot measure or supervise weakly. These variables may include factors of variation that are impossible to label or control. By introducing an additional variable \u03b7 as a nuisance variable, we can capture all sources of variation/stochasticity. This allows us to maintain consistency and restrictiveness in the representation of object color. The theoretical framework introduces a new variable \u03b7 as a nuisance variable to handle unmeasurable nuisance variables. This ensures consistency and restrictiveness in representing object color.\u03b7-disentanglement is defined as D\u03b7(I) = C\u03b7(I) \u2227 R\u03b7(I), where C\u03b7(I) captures changes to Z \\I \u222a {\u03b7} not modifying SI, and R\u03b7(I) ensures changes to Z I \u222a {\u03b7} only modify SI \u222a {\u03b7}. The framework guarantees full disentanglement even with nuisance variables, as shown in Proposition 1. Figure 7 shows hyperparameter sweep results with extra dense always set to False. Figure 12 compares models trained via different techniques, with changesharing achieving higher restrictiveness, share-sharing achieving higher consistency, and both techniques achieving a balance of restrictiveness and consistency. Fully-labeled GAN also performs well in terms of normalized consistency score across multiple datasets. In weakly supervised settings, using consistency and restrictiveness metrics for hyperparameter selection proves to be a viable surrogate for fully-supervised disentanglement metrics. Performance comparison of different GAN models across multiple datasets shows that restrictiveness and consistency are complementary factors. Figure 16 shows a scatterplot comparing existing disentanglement metrics with average normalized consistency and restrictiveness. Weakly supervised data can measure consistency and restrictiveness, allowing for hyperparameter tuning under weakly supervised conditions. The best-performing match-pairing generative models are visualized, demonstrating the importance of consistency and restrictiveness in weakly-supervised generative models. The text discusses training a probabilistic Gaussian encoder separately from the generative model, using a specific architecture with spectral norm convolutions and dense layers. The encoder is only exposed to data generated by the generative model during training. Additionally, a special variant of the projection discriminator is used for rank-pairing in the model. The text describes the architecture of the projection discriminator, which computes the conditional logit by comparing pairs and multiplying by y \u2208 {\u22121, +1}. The discriminator acts as an adversarially trained encoder to enforce the ranking rule in the embedding space. Parts in red indicate hyperparameter search. The discriminator body is applied separately to x and x, using spectral norm convolutions and dense layers. The unconditional and conditional heads are also applied separately to x and x, allowing for transitions between different modifications. The text discusses the importance of zig-zag connectedness for restrictiveness union and consistency intersection. It also outlines assumptions for continuous and discrete variables in mapping functions. Assuming that every factor of variation is recoverable from the observation X, the text discusses the calculus of disentanglement and the expected-norm reduction lemma for random variables with distribution p. The text discusses the calculus of disentanglement and the expected-norm reduction lemma for random variables with distribution p. It proves the forward direction by assuming a contradiction and showing that for all points in B(Z), the function f is equal. The text discusses the calculus of disentanglement and the expected-norm reduction lemma for random variables with distribution p. It proves the forward direction by assuming a contradiction and showing that for all points in B(Z), the function f is equal. The zig-zag path between R(I) and R(J) gives us the proof that R(I) \u2227 R(J) =\u21d2 R(I \u2229 J). If (p * , g * , e * ) \u2208 H, and (p, g, e) \u2208 H, and g * (S), then there exists a continuous function r such that E p(s1:n) r \u2022 e \u2022 g * (s) \u2212 s = 0."
}