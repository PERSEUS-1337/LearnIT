{
    "title": "rylxpA4YwH",
    "content": "Conditional Generative Adversarial Networks (cGANs) are widely used in various applications. Evaluating these models typically requires multiple metrics to assess image quality, conditional consistency, and diversity. The Frechet Joint Distance (FJD) is proposed as a single metric to capture these properties. Experiments on a synthetic dataset show the benefits of FJD over existing metrics when comparing cGAN-based models. The FJD metric is proposed as a single benchmark for comparing cGAN-based models with various conditioning modalities. Generative models like VAEs, auto-regressive models, and GANs have shown significant progress in various applications. Significant research has emerged on conditional generation, with cGANs being competitive. Quantitative evaluation of GANs remains a challenge, with various evaluation metrics introduced in the literature. Inception Score and Fr\u00e9chet Inception are commonly used metrics for benchmarking GAN-based models. Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) are commonly used to benchmark GAN-based models for unconditional image generation. However, these metrics do not fully capture all aspects of conditional image generation, such as conditional consistency and intra-conditioning diversity. Researchers have sought to address these limitations by focusing on reporting conditional consistency. Researchers have turned to reporting conditional consistency and diversity metrics alongside FID to address limitations in evaluating conditional image generation. Different metrics may hinder model selection as there is a trade-off between image quality and sample diversity. In this paper, a new metric called Fr\u00e9chet Joint Distance (FJD) is introduced to assess image quality, conditional consistency, and intra-conditioning diversity. FJD computes the Fr\u00e9chet distance on an embedding of the joint image-conditioning distribution with minimal computational overhead compared to alternative methods. The properties of FJD are evaluated on a synthetic dataset and compared to FID under different types of conditioning. The experiments show that FJD successfully captures the desired properties for evaluating conditional image generation. Conditional GANs have seen significant advancements in recent years, with techniques like progressive growing, spectral normalization, and the two time-scale update rule improving training stability. Architectural enhancements, such as auxiliary classifiers, have also been introduced. A new metric called Fr\u00e9chet Joint Distance (FJD) has been proposed to evaluate image quality, conditional consistency, and intra-conditioning diversity. FJD shows promise as a unified metric for hyper-parameter selection and cGAN benchmarking, capturing key properties of conditional generation that existing metrics do not. Recent advancements in conditional GANs include the use of auxiliary classifiers and projection-based conditioning for the discriminator. Image quality has improved with the incorporation of self-attention, increased model capacity, and batch size. Various forms of conditional image generation have been explored, such as class-based, image-based, mask-and bounding box-based, and text-based approaches. The intensified research in conditional image generation has led to the development of metrics to assess visual quality, conditional consistency, and intra-conditioning diversity. Various GAN evaluation metrics have emerged to evaluate visual quality, focusing on separability, distribution distance, and sample quality from conditional or marginal distributions. Automated visual quality metrics like Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) are used to assess sample quality and diversity in conditional image generation. Researchers evaluate the consistency of generated images with model conditioning using pre-trained feed-forward models specific to the modality of conditioning. The evaluation of forward models in conditional image generation depends on the type of conditioning, such as class, bounding box, mask, text, or image. Metrics like accuracy, Intersection over Union, BLEU, METEOR, CIDEr, SSIM, PSNR, LPIPS, and Intra-FID are used to assess sample diversity and quality. The evaluation of forward models in conditional image generation depends on various types of conditioning, such as class, bounding box, mask, text, or image. Metrics like accuracy, Intersection over Union, BLEU, METEOR, CIDEr, SSIM, PSNR, LPIPS, and Intra-FID are utilized to assess sample diversity and quality. However, Intra-FID may not be applicable beyond class-conditioning due to scalability issues and intractability with certain types of conditioning. In conditional image generation, Gaussian distributions are fitted to samples from a reference dataset and a generative model. Real images and model samples are embedded in a learned feature space using a pre-trained Inception v3 model. The goal is to produce diverse, realistic images consistent with various forms of conditioning, such as image-level classes, segmentation masks, or text. The Fr\u00e9chet distance (FD) compares Gaussians over joint image-conditioning embedding space. By estimating Gaussian parameters, it evaluates image quality, conditional consistency, and intra-conditioning diversity in conditional image generation models. Reproducibility in reporting FJD scores is crucial. When reporting FJD scores, include details like the conditioning embedding function, dataset for reference distribution, and \u03b1 value. The choice of embedding function varies based on conditioning modality. Use pretrained embeddings or learn new ones if needed. Refer to Table 1 for suggested assignments of modalities to functions. When reporting FJD scores, include details like the conditioning embedding function, dataset for reference distribution, and \u03b1 value. The \u03b1 value controls the contribution of the conditioning component to the final FJD value. Setting \u03b1 to the ratio between image and conditioning embedding norms ensures consistent behavior across different embeddings. In the project, the \u03b1 hyperparameter should be calculated on data from the reference distribution and then applied to all conditioning embeddings. Autoencoders are considered better suited than Inceptionv3 embeddings for capturing object positions. The merging function g combines image and conditioning embeddings into a joint embedding. In the project, the merging function g combines image and conditioning embeddings into a single joint embedding. Concatenation of the image and conditioning embedding vectors is found to be the most effective merging function for conditional image generation. The FJD method is shown to capture image quality, conditional consistency, and intra-conditioning diversity using the dSprite-textures dataset. The dataset contains 2,211,840 unique images with class labels, bounding boxes, and mask labels. One-hot encoding is used for class labels and autoencoder representations for bounding box and mask labels. The code to generate dSprite-textures is being released. The sensitivity of FJD to image quality perturbations is being tested by drawing 10k random samples and adding Gaussian noise to the images. The addition of noise to images in the dSprite-textures dataset mimics a generative model producing low-quality images. Results show that FJD closely follows FID, indicating its ability to capture image quality. The sensitivity of FJD to conditional consistency, such as scale or orientation inconsistencies, is highlighted. Additional image quality experiments on the COCO-Stuff dataset are also mentioned. In an experiment using the dSprite-textures dataset, 10k samples were drawn and duplicated to create reference and generated datasets with identical image and conditioning distributions. Swapping conditionings for 30% of the generated samples allowed for control over specific attributes' conditional consistency while keeping overall distributions unchanged. This manipulation helped isolate the impact of conditional inconsistencies on the Frechet Joint Distance (FJD) metric. The experiment on the dSprite-textures dataset involved manipulating conditionings to study the impact on the Frechet Joint Distance (FJD) metric. Results show that FJD remains constant for image distributions despite increasing conditional inconsistencies. Different conditionings like class, bounding box, and mask produce varying FJD values proportional to the offset, with mask conditioning showing fluctuating behavior due to partial realignment with ground truth. This highlights the sensitivity of FJD to conditional consistency. In this subsection, the sensitivity of FJD to intra-conditioning diversity is tested by varying image texture based on different attributes like shape, scale, orientation, and position. Attribute-texture assignments are created by stratifying attributes based on their values. A diversity score is introduced to quantify dataset intra-conditioning diversity, where a score of 1 indicates uniform texture distribution across stratas, and a score of 0 indicates each strata is assigned to a single texture. The diversity score is used to quantify dataset intra-conditioning diversity, with a score of 1 indicating uniform texture distribution across stratas. A reference dataset is created by randomly drawing 10k samples, and the distribution is adjusted to achieve the desired diversity score. Results show that FJD is sensitive to changes in intra-conditioning diversity, while FID increases with reduced diversity, indicating a change in image marginal distribution. In contrast to FID, FJD is sensitive to changes in intra-conditioning diversity when the image conditional distribution is affected. FJD is applied to evaluate models with different conditioning modalities such as class-conditioned, image-conditioned, and text-conditioned tasks. Rankings based on FJD and FID are similar due to similar conditioning mechanisms used in models. Rankings based on FJD and FID are dominated by image quality rather than conditional consistency. FJD is used to evaluate class-conditioned cGANs, with accuracy computed using Inception v3. FJD follows the same trend as FID for class-conditioned models, highlighting its ability to capture image quality. The difference between FJD and FID correlates with each model's characteristics. The difference between FJD and FID correlates with each model's classification accuracy, indicating better conditional consistency with smaller gaps. Diversity scores rank models differently, highlighting the trade-off between realism and diversity. FJD is a suitable metric for finding a model that matches the target conditional data generating distribution. BicycleGAN appears to have the best image quality among the models evaluated. Table 4 compares FJD and FID scores for text-conditioned models HDGan, StackGAN++, and AttnGAN trained on the CUB-200 dataset. Conditional consistency is assessed using visual-semantic similarity, with test set captions used for image generation. AttnGAN outperforms HDGan and StackGAN++ in conditional consistency according to FJD, while all models show similar diversity. FJD is introduced as a metric capturing image quality, conditional consistency, and intra-conditioning diversity. It is compared to FID on a synthetic dataset, validating its ability to assess these properties effectively. The FJD metric is validated on a synthetic dataset, showing its effectiveness in capturing image quality, conditional consistency, and intra-conditioning diversity. It can potentially serve as a unified cGAN benchmarking metric and aid in model selection by addressing the trade-off between image quality and sample diversity. The FJD metric is effective in capturing image quality, conditional consistency, and intra-conditioning diversity. It can be used as a unified cGAN benchmarking metric and help in model selection by balancing image quality and sample diversity. The computation details for FID and FJD metrics in different experiments are provided in Table 5. The FID and FJD metrics for various experiments are detailed in Table 5, including the conditioning modality, embedding function, dataset splits, image resolution, and sample generation per conditioning. The \u03b1 values are calculated based on the balancing mechanism recommended in Section 4.2. An experiment on the COCO-Stuff dataset is repeated to assess how well FJD tracks image quality, following the same procedure outlined in Section 5.2. The experimental procedure involves adding Gaussian noise to images within a specified range, using clean images as a reference distribution. FID and FJD metrics track image quality by increasing as more noise is added. The effectiveness of FJD in detecting conditional inconsistencies is tested using the Caltech-UCSD Birds 200 dataset. The dataset for text conditioned image generation models includes 200 bird categories with detailed annotations. The goal is to swap captions between images to introduce inconsistencies while comparing attribute vectors using Hamming distance. This helps determine how well captions describe images, with small distances indicating a good match and larger distances indicating discrepancies. The captions in Figure 7 describe a red bird with black wings, a short bill, and brown feet. The body is ivory with a bright red crown and black speckled wings. Hamming distance is used to compare how well captions match images by swapping them to introduce inconsistencies. The study uses Char-CNN-RNN embeddings to calculate FJD, showing that as captions become worse at describing images, FJD increases while FID remains constant. Table 6 lists sources of pre-trained models for conditional generation. The \u03b1 parameter in the FJD equation determines the importance of the image versus the conditional component. In experiments, a neutral value for \u03b1 is sought to balance the contribution of the conditional and image components in FJD calculation. By plotting \u03b1 versus FJD, changes in model ranking with increased weighting on the conditional component can be observed. The truncation trick is used to evaluate BigGAN at different \u03c3 values. The truncation trick involves scaling the noise vector in a GAN by \u03c3 to balance sample diversity and image quality without retraining the model. Increasing \u03c3 leads to higher diversity but lower classification accuracy. Models with higher \u03c3 values are favored at higher \u03b1 values in FJD evaluation. In this paper, the authors utilize a variant of the Regularized AutoEncoder with Spectral Normalization (RAE-SN) for creating embeddings. They enhance it with residual connections for better reconstruction quality. Spectral normalization is applied to all linear and convolution layers in the decoder, along with an L2 penalty on the latent representation during training. Hyperparameters are selected based on the best combination for optimal results. The architecture of an autoencoder with variable input resolution is described, with details on channel multiplier and latent dimensions. The utility of FJD for model selection and hyperparameter tuning is demonstrated using the loss function of an ACGAN generator. In this experiment, the generator loss in an ACGAN model is maximized during training, consisting of adversarial and classification components. A weighting parameter \u03bb is introduced to adjust the importance of the conditional component. Models are trained on the MNIST dataset with a sweep over \u03bb values from 0 to 5, evaluating each model using FID, FJD, and classification accuracy for conditional consistency. In an ACGAN model experiment, a weighting parameter \u03bb is adjusted to balance conditional consistency and image quality. Results show that \u03bb = 1.0 optimizes FJD, achieving a balance between image quality and conditional consistency. To demonstrate FJD applied to multi-label, bounding box, and mask conditioning on the COCO-Stuff dataset, three generative models were trained with different conditioning types and image resolutions. The BigGAN-style model was modified to accommodate all three conditioning types, and each model was trained 5 times with different random seeds to report mean and standard deviation. In Table 13, models were trained 5 times with different conditioning types and random seeds. N-hot encoding is used for multi-label conditioning, while autoencoder representations are used for bounding box and mask conditioning. FID values are similar between conditioning types, except at 64 \u00d7 64 resolution where mask conditioning achieves the lowest FJD score. Modifications were made to BigGAN to support multiple conditioning types in the generator. In the generator, conditional batch normalization layers are replaced with SPADE for spatial conditioning like bounding boxes or masks. Additional projection layers are added to the discriminator for class-conditional information, with downsampled conditioning resized to match each layer's spatial resolution. Neighbour interpolation is used to match spatial resolution in the generator, providing conditioning information at different resolutions for the discriminator to utilize. Models are trained with the same hyperparameters as specified in a previous study. Random 128 \u00d7 128 samples of conditional generation are presented, showcasing class, bounding box, and mask conditioning samples. Conditioning on classes results in variable samples in terms of object positions, scales, and textures. Conditioning strength affects the freedom of generation. Increasing conditioning strength reduces generation freedom, leading to subtle variability in textures. Different samples per conditioning only affect textures. Higher conditioning strength results in sharper, better-looking images."
}