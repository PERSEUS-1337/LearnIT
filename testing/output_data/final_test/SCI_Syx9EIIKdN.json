{
    "title": "Syx9EIIKdN",
    "content": "In this paper, new approaches to combining information in autoencoder representations are explored. Models are developed to combine attributes of multiple inputs to fool an adversarial discriminator. The architecture is also applied to semi-supervised learning, learning a mixing function to produce consistent interpolations of hidden states. The study provides evidence that this approach is promising for research in unsupervised learning. The autoencoder consists of an encoder that encodes input data into a high-level representation and a decoder that reconstructs the input. Its goal is to learn useful representations for downstream tasks like classification or reinforcement learning. Techniques such as restricting bottleneck size, adding input noise, or introducing a prior can enhance the information content of the representations. Another objective is to learn interpretable representations, often focusing on disentanglement of latent variables or maximizing mutual information. Mixup and manifold mixup are also explored in this context. Regularisation techniques like Mixup and manifold mixup encourage deep neural networks to behave linearly between data samples by creating random convex combinations between pairs of examples and labels. This results in smoother decision boundaries, improving generalisation performance. In manifold mixup, the combinations are computed in the hidden space of the network, producing novel training examples and enhancing supervised learning. Additionally, a method for semi-supervised classification based on random convex combinations between unlabeled samples and predicted labels has been proposed. In this paper, a wider class of mixing functions for unsupervised learning is explored, involving continuous interpolations between latent vectors, binary masking operations, and deep neural networks in the bottleneck layer of an autoencoder. Adversarial learning is leveraged to ensure the output of the decoder resembles the data distribution at the pixel level. The approach is also applied to semi-supervised learning, where a mixing function is learned to simulate novel data points. Our method extends autoencoders by learning a mixing function for semi-supervised learning, allowing for interpolations and masking operations. In contrast to VAEs, we sample mixup operations between encoder inputs. The ACAI method is another approach involving adversarially constrained autoencoder interpolation. Our method extends autoencoders by learning a mixing function for semi-supervised learning, allowing for interpolations and masking operations. It explores different mixing functions, including a semi-supervised variant using an MLP to produce mixes consistent with a class label. The method extends autoencoders by training an adversarial reconstruction autoencoder (ARAE) where the discriminator distinguishes between real and reconstructed images, while the autoencoder generates 'realistic' reconstructions to fool the discriminator. This approach allows for generating novel samples by encoding inputs into their latent representation, combining them, and decoding the result. The adversarial mixup resynthesiser (AMR) proposes a strategy to combine latent representations in an autoencoder by randomly retaining components from one representation and using the rest from another. This approach aims to produce mixes that, when decoded, are realistic. The adversarial mixup resynthesiser (AMR) uses an autoencoder to create realistic image mixes. The generator and discriminator are trained with various loss components to ensure the mixes are indistinguishable from real images. Mixing consistency loss helps maintain semantic consistency in the decoded images. The generator and discriminator are trained using the decoded image of the mix to label it as fake. The adversarial mixup resynthesiser (AMR) utilizes an autoencoder to generate realistic image mixes. The discriminator is trained to identify fake images, while the generator aims to deceive the discriminator. The coefficients \u03bb and \u03b2 control reconstruction and mixing consistency. A supervised mixing formulation is explored, involving a mixing function that aligns with specific class labels. This is achieved by backpropagating through a classifier network branching off the discriminator. The adversarial mixup resynthesiser (AMR) uses a mixing function to create combinations of hidden states consistent with class labels. The conditioning label is a convex combination to ensure semantic relevance. The unsupervised version of AMR includes a mixing function that generates image mixes in addition to autoencoder loss functions. The adversarial mixup resynthesiser (AMR) utilizes a mixing function to combine latent variables h1 and h2, which are then decoded into a realistic and semantically consistent image. This process involves consistency loss, a discriminator, and ResNets BID6 for the generator and discriminator. The model is evaluated on datasets like UT Zappos50K BID24, consisting of images of shoes and boots. The adversarial mixup resynthesiser (AMR) uses a mixing function to combine latent variables h1 and h2 for generating realistic images. It is evaluated on datasets like CelebA BID13, which consists of diverse face images. The supervised version of AMR involves a mixer function that produces an output combination using a Bernoulli mask. The adversarial mixup resynthesiser (AMR) uses a mixing function to combine latent variables h1 and h2 for generating realistic images. It involves a mixer function that produces an output combination using a Bernoulli mask, which is then used to generate x mix. The generator must fool the discriminator using x mix and ensure the class prediction by the auxiliary classifier is consistent with the mixed class y mix. Different mixup variants produce more realistic-looking interpolations than in pixel space, especially in datasets like CelebA BID13. The Frechet Inception Distance (FID) metric is used to compute the distance between samples from the dataset and ones from autoencoders. FID scores are calculated between validation samples and their reconstructions, as well as between validation samples and randomly sampled interpolations. Lower FID scores are generally preferred, and results are shown in the table for mixup and Bernoulli mixup formulations. The Frechet Inception Distance (FID) metric is used to measure the distance between samples from the dataset and autoencoder reconstructions. Lower FID scores are typically preferred, but in cases of mixing, a lower FID may not always be ideal. To prevent mixed features from being decoded back into original examples, a consistency loss with a tuned coefficient \u03b2 is leveraged. This coefficient determines how likely decoded mixes are projected back onto the data manifold, balancing between creating novel data points and maintaining fidelity to the original data. The FID metric is used to compare against baselines like ARAE for mixup and Bernoulli mixup. Bernoulli mixup produces higher FID scores due to mixing on an extra axis, leading to greater variability. Qualitative results are presented with the supervised AMR variant using a subset of CelebA attributes. The supervised AMR variant trains using a subset of CelebA attributes, producing random convex attribute mixes. Interpolations by the class mixer function show decent attribute mixes between faces, consistent with desired attributes. The model achieved decent attribute mixes between faces, but struggles with disentangling lipstick and makeup attributes. Hyperparameter tuning is needed for improvement, and using a mask instead of binary values showed better results. Further details can be found in Section 5.3 of the appendix. In this paper, the adversarial mixup resynthesiser was introduced to create realistic combinations of examples by mixing in the bottleneck of an autoencoder. Various mixing functions were proposed, including sampling from uniform and Bernoulli distributions. A semisupervised Bernoulli variant was also presented, allowing for leveraging class labels to determine mixing for generating images consistent with desired labels. The technique can be used for generative modeling and potentially improving latent representations for downstream tasks, with future work focusing on comparisons to existing literature and experimental validation. Future work will involve more comparisons to existing literature and experiments to determine the effects of mixing on the latent space itself and downstream tasks. The experimental setup includes using a residual network for both the generator and discriminator, spectral normalisation for the discriminator, and ADAM optimizer with specific parameters. The effect of consistency loss is examined on a two-dimensional spiral dataset with mixup loss enabled. After 100 epochs of training with mixup loss and \u03bb = 10, different values of \u03b2 (0, 0.1, 10, 100) were tested. Decoded random mixes were plotted over the data distribution, shown as orange points on top of real samples in blue. Lower \u03b2 values result in interpolated points lying within the data manifold (spiral) due to the competition between consistency and discriminator loss. The goal is to balance high consistency for semantically meaningful interpolations while maintaining realistic decoded results. Interpolations are defined as DISPLAYFORM0. Our formulation compares to ACAI BID2, which lacks a consistency loss term. ACAI tries to predict the mixing coefficient \u03b1, while our model sets \u03b2 = 0. Both ACAI and our model gradually increase consistency losses during training, moving interpolated points closer to the data manifold. In Figure 9, comparisons of model interpolations between faces with \u03b2 = 50 and \u03b2 = 0 show smoother results with \u03b2 = 50. The slight discontinuity in interpolation without consistency loss may be due to points being pushed closer to the data manifold. AMR and ACAI models with different training epochs are also shown. The supervised class mixer internally maps label mix to Bernoulli parameters, resulting in binary combinations of feature maps for different attributes. Visualization of Bernoulli parameters shows how feature maps contribute to attributes. Additional samples of the AMR model using mixup and Bernoulli mixup variants are demonstrated on Zappos and CelebA datasets. The AMR model is compared against other interpolation methods on Zappos and CelebA datasets. Results show that AMR and ACAI produce more realistic results with smoother transitions, while pixel and ARAE interpolations are less realistic and have more artifacts."
}