{
    "title": "SklOypVKvS",
    "content": "Measuring Mutual Information (MI) between high-dimensional, continuous, random variables from observed samples has wide theoretical and practical applications. A Data-Efficient MINE Estimator (DEMINE) is proposed to improve data efficiency and provide a tight lower confident interval of MI under limited data. This estimator incorporates cross-validation to the MINE lower bound and utilizes hyperparameter search and meta-learning with task augmentation to increase robustness and accuracy. DEMINE allows for statistical testing of dependency at practical dataset sizes. Our DEMINE estimator enables statistical testing of dependency at practical dataset sizes by estimating Mutual Information (MI) between random variables. MI is a non-linear measure of similarity capturing dependencies, widely used in various fields including physics, neuroscience, and machine learning. Existing studies focus on deriving lower bounds and bias reduction techniques for MI estimation. The challenges in Mutual Information (MI) estimation include the need for confidence intervals to quantify uncertainty and statistical significance. Existing MI estimators do not provide confidence intervals, leading to variability in estimates with additional observations. Existing MI estimators lack confidence intervals, causing variability in estimates with more observations. Belghazi et al. (2018) studied lower bounds of the MINE estimator under limited data, but it does not provide useful confidence intervals for realistic datasets. Practical MI estimators should be insensitive to hyperparameter choices, returning a single MI estimate with its confidence interval regardless of data type or number of observations. Model design and optimization hyperparameters should be automatically determined for learning-based approaches to compute the confidence interval. Our estimator, DEMINE, introduces a predictive MI lower bound for limited samples to enable statistical dependency testing under practical dataset sizes. It builds on the MINE estimator family, using cross-validation to remove the need for bounding generalization error. Hyperparameters are automatically selected through hyperparameter search, and a new cross-validation meta-learning approach is developed to automatically initialize model parameters. Task augmentation controls meta-overfitting, allowing for practical statistical testing of dependency on both synthetic and real datasets. The text introduces DEMINE, a data-efficient Mutual Information Neural Estimator for statistical dependency testing, including a new meta-learning formulation called Meta-DEMINE. It also discusses the application of these methods to real-world fMRI data analysis. The approach involves using k-NN estimates and other methods for Mutual Information estimation. Recent works on Mutual Information (MI) estimation have focused on developing tight asymptotic variational lower bounds using neural networks for signal modeling. The IM algorithm introduces a variational MI lower bound by learning a neural network as a variational approximation to the conditional distribution. This method applies to latent codes of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). Our work introduces cross-validation to the MINE-f estimator, deriving its lower bound under a limited number of samples. We also incorporate meta-learning and hyperparameter search to enable practical statistical dependency testing. This builds upon existing works in general statistical dependency testing by introducing new methods for improving generative models. The approach for independent testing involves utilizing neural networks to enhance test performance on complex signals. The p-values from this test are not based on approximated distributions and are valid for small sample sizes and any number of signal dimensions. Comparisons with the Hilbert-Schmidt independence criterion (HSIC) are provided, focusing on the presentation of the dependency test rather than a comprehensive comparison across different approaches. Meta-learning aims to improve neural networks' generalization capability by optimizing hyperparameters, network architectures, initialization, and distance metrics. It has shown performance enhancements in tasks like neural architecture search, few-shot image recognition, and imitation learning. The estimator benefits from the Model-Agnostic Meta-Learning (MAML) framework, which focuses on improving few-shot learning performance through network initialization. Meta-learning utilizes the Model-Agnostic Meta-Learning (MAML) framework to enhance few-shot learning performance. By leveraging MAML's model-agnostic nature, Mutual Information (MI) estimation is maximized between random variables. A task-augmentation protocol is proposed to construct diverse tasks for MAML learning, reducing overfitting and improving generalization. The goal is to estimate MI, I(X; Z), from independent and identically distributed sample pairs (x i , z i ). The MINE estimator I(X, Z) is defined based on a class of scalar functions and lower bounds of MI. The sample complexity of MINE requires a substantial number of samples to prevent overfitting and overestimation of MI. The sample complexity of MINE is defined as the minimum number of samples needed to achieve a certain confidence interval. For example, a neural network with specific parameters would require a large number of samples for accurate estimation. Real data acquisition for MI estimation can be costly, so an approach using MI lower bounds for prediction, like DEMINE, can improve sample complexity. DEMINE enables high-confidence MI estimation on small datasets by interpreting the estimation of MINE-f lower bound as a learning problem. The goal is to infer the optimal network T \u03b8 * (X, Z) with parameters \u03b8 * given a limited number of samples. The training set is used to learn a network \u03b8 as an approximation to \u03b8 *, while the validation set is used to compute the DEMINE estimation I(X, Z) n,\u03b8. DEMINE learns \u03b8 by maximizing the MI lower bound on the training set. The DEMINE algorithm, presented in Algorithm 2 in the appendix, estimates I(X, Z) \u221e,\u03b8 with a reduced sample complexity compared to MINE-f. The sample complexity of DEMINE does not depend on the model class F, and the number of samples required for a good approximation is derived in Theorem 1. The MINE lower bound has a higher sample complexity than MINE-f, but we choose MINE-f for its lower sample complexity. The DEMINE algorithm estimates I(X, Z) \u221e,\u03b8 with reduced sample complexity compared to MINE-f. The sample complexity of DEMINE is derived in Theorem 1, making MI-based dependency analysis feasible for expensive data domains like fMRI scans. The estimator requires fewer samples than MINE, optimizing hyperparameters U and L further reduces sample complexity. Theorem 1 bounds the closeness of the DEMINE estimate towards the MI. DEMINE estimates I(X, Z) \u221e,\u03b8 with reduced sample complexity compared to MINE-f, making fair comparison with MINE's sample complexity. DEMINE avoids the need to bound generalization error and allows for further improvements through meta-learning. Meta-DEMINE learns \u03b8 for generalization within the same model class and training samples. Meta-DEMINE generates MI estimation tasks through task augmentation and learns parameter initialization \u03b8 init to maximize MI estimation performance. The meta-training process involves starting from an initialization \u03b8 (0) and applying Stochastic Gradient Descent (SGD) to learn \u03b8. Task Augmentation adapts MAML for MI lower bound maximization, improving generalization performance. Meta-DEMINE improves MI estimation performance by generating tasks through task augmentation. Training samples are split into meta-training and meta-validation splits, then transformed using random invertible transformations to increase task diversity. This approach ensures that the model does not overfit by memorizing all meta-validation splits. MetaTrain(\u00b7, \u00b7) aims to achieve consistent MI lower bound estimation regardless of variable transformations, suppressing memorization. More sophisticated invertible transformations can be included. Task augmentation differs from data augmentation by not assuming variations of images are valid examples of the class. It requires \u03b8 init to recognize classes in translated/rotated worlds. Optimization involves solving for \u03b8 init using meta-learning formulation Eq.9. The optimization problem of solving for \u03b8 init using meta-learning formulation Eq.9 is challenging. Back propagation through time (BPTT) is commonly used but can be vulnerable to exploding gradients and memory intensive. Stochastic finite difference algorithms like Evolution Strategies (ES) and Parameter-Exploring Policy Gradients (PEPG) can improve optimization robustness. The Meta-DEMINE algorithm is specified in Algorithm 1 and evaluated against baselines on synthetic datasets. Meta-DEMINE is evaluated against baselines and state-of-the-art approaches on 3 synthetic datasets: 1D Gaussian, 20D Gaussian, and sine wave. The mutual information for the Gaussian datasets has a closed form solution, while for the sine wave dataset, accurate estimation requires extrapolation. Ground truth mutual information for the sine wave dataset is approximated using the KSG Estimator. Comparisons are made with the KSG estimator MI-KSG. Meta-DEMINE is compared to KSG estimator MI-KSG and MINE-f. Variance reduction and statistical significance modes are studied. Samples are split into train and validation sets. A separable network architecture is used for embedding signals x and z. The text discusses the use of hyperparameters and learnable parameters in vector embeddings for signals x and z. Bayesian hyperparameter optimization is used for MLP design and optimization. Hyperparameter search is conducted on DEMINE-vr and DEMINE-sig using the hyperopt pack. Meta-DEMINE-vr and Meta-DEMINEsig reuse these hyperparameters. Task augmentation was performed with 1 iteration, r = 0.8, and \u03b7 meta = \u03b7 3. NO was limited to 30 iterations for 1D and 20D Gaussian datasets due to memory constraints. For sine wave datasets with large NO, PEPG was used instead of BPTT. MI-KSG utilized an off-the-shelf implementation with k = 3 nearest neighbors. MINE-f employed the same network architecture as DEMINE-vr. Two implementations were used: the original formulation optimizing T \u03b8 on (x, z) till convergence and MINE-f-ES with early stopping. Results showed MI estimation performance on 20D Gaussian datasets with varying \u03c1 using N = 300 samples. Results show that Meta-DEMINE-sig outperforms DEMINE-sig in detecting the highest confidence MI, with both detecting statistically significant dependency at \u03c1 = 0.3. MINE-f and MINE-f-ES exhibit overfitting issues, while DEMINE variants show high empirical bias but low variance in MI estimation. Figure 1(b,c,d) illustrates MI estimation performance on various datasets. The study compares MI estimation performance on different datasets with varying sample sizes. Higher-dimensional Gaussian and complex sine wave datasets are more challenging to solve. DEMINE-sig and Meta-DEMINE-sig detect significant dependencies in various datasets, including nonlinear relationships. Cross-validation meta-learning and task augmentation are studied on 20D datasets. The study explores the impact of cross-validation meta-learning and task augmentation on 20D Gaussian datasets. Task augmentation modes involving axis flipping and permutation show the most success in preventing overfitting and improving performance. Meta-learning without task augmentation or with limited augmentation leads to overfitting, while specific augmentation strategies help prevent it. Task augmentation with m(\u00b7) or m(P (O(G(\u00b7)))) prevents overfitting but does not improve performance significantly. Data augmentation with O(\u00b7) outperforms no augmentation but still suffers from overfitting. Task augmentation provides orthogonal improvements to data augmentation. Humans use language to transmit brain representations effectively among individuals, with speaker-listener neural synchrony predicting comprehension. Speaker-listener neural synchrony predicts listener comprehension in transmission. Brain-to-brain synchrony is measured through inter-subject correlation (ISC) using fMRI responses. DEMINE and Meta-DEMINE allow for capturing nonlinear interactions in fMRI data. Mutual information analysis extends ISC to capture higher-order interactions between brain regions. The study uses mutual information (MI) for pair-wise ISC analysis on fMRI data from a story comprehension dataset. The dataset includes 40 participants listening to four stories, with an average duration of 11 minutes. The analysis focuses on functionally-defined masks of high ISC voxels and dorsal Default-Mode Network voxels, as well as 180 HCP-MMP1 multimodal cortex parcels. Simony et al. (2016) and Glasser et al. (2016) defined 180 HCP-MMP1 multimodal cortex parcels in MNI space. MI-based ISC using DEMINE and Meta-DEMINE was compared with correlation-based ISC using Pearson's correlation. fMRI data was split into train and validation sets. Residual 1D CNN was used for temporal dependency analysis. Results showed more regions with statistically significant correlation than dependency. Meta-DEMINE found 6 brain regions with significant dependency but not correlation, indicating the complementarity of MI analysis with correlation-based ISC. Using DEMINE and Meta-DEMINE with sliding windows, fMRI signals were modeled for improved accuracy. BSC was used for evaluation, dividing fMRI scans into time segments for classification tasks. Meta-DEMINE and DEMINE model fMRI signals with CNN as encoder, achieving higher accuracy and extracting mutual information. Task augmentation reduces overfitting and improves generalization in meta-learning, enabling statistical tests of dependency on data-scarce fMRI datasets. Our results suggest using neural networks and meta-learning to enhance MI analysis in fMRI datasets. Model-agnostic MI lower bound estimation approaches are limited in estimating small MI lower bounds. The dataset used had 40 participants with a mean age of 23.3 years. Participants with an average age of 23.3 years were recruited to listen to four spoken stories by different authors. The stories varied in duration from 7 to 14 minutes. After scanning, participants completed a questionnaire to measure narrative comprehension. Functional and structural images were acquired using a 3T Siemens Prisma scanner. The fMRI data were preprocessed with a multiband acceleration factor of 3, corrected for various factors, and normalized to MNI space. Nuisance variables were regressed out using AFNI software. The fMRI data comprised X \u2208 R Vi\u00d7T for each subject. Functional and structural images were acquired using a 3T Siemens Magnetom Prisma with a 64-channel head coil. Functional, blood-oxygenation-level-dependent (BOLD) images were acquired in an interleaved fashion with specific imaging parameters. The study utilized a high-resolution single-shot MPRAGE sequence for T1-weighted imaging with specific parameters. A T2-weighted structural scan was also acquired with the same parameters. Dataset preprocessing involved acquiring a field map at the beginning of each scanning session, but it was not used in subsequent analyses. Preprocessing was done using the fMRIPrep and Nipype libraries, including intensity correction, skull-stripping, spatial normalization, and brain tissue segmentation. Functional images were also corrected for slice timing and head motion. AFNI software's 3dTshift and FSL library's MCFLIRT tool were used for motion correction. \"Fieldmap-less\" distortion correction was performed by co-registering functional images to intensity-inverted T1-weighted images. Co-registration to T1-weighted images was done using FreeSurfer software's boundary-based registration. Physiological noise regressors were extracted using aCompCor method. Functional images were preprocessed by calculating six principal component time series within the subcortical mask intersecting with CSF and WM masks in T1w space. Framewise displacement was assessed, and nuisance variables were regressed out using various parameters. Functional response time series were z-scored for each voxel. The Hilbert-Schmidt independence criterion (HSIC) was reviewed in connection with correlation-based independence criteria. The HSIC approach is based on a necessary and sufficient condition of independence between two random variables X and Z. Existing approaches use Reproducing Kernel Hilbert Spaces (RKHS) for functions f and g to construct an independence test. Confidence intervals are derived through McDiarmid's inequality. The COCO(X, Z) used by HSIC estimators is related to the MINE family of mutual information estimators. It serves as an upperbound to the MINE estimates within a family of decomposable functions. The equivalence of COCO(X, Z) = 0 and I(X, Z) = 0 suggests a form of mutual independence. The necessity of non-decomposable T \u03b8 (X, Z) designs and mutual information lower bounds under decomposable designs of T \u03b8 (X, Z) may be subjects of further research. Comparison between DEMINE and HSIC on synthetic benchmarks is expected to provide insights into their performance. In this study, Canonical Correlation Analysis (CCA), DEMINE, DEMINE-meta, and HSIC were compared for independent testing on synthetic benchmarks. Results were reported for a single random seed, with experiments using multiple seeds to validate the findings. P-values were computed using different tests for CCA and HSIC, with statistically significant results highlighted. The study found that spectral HSIC required less data to test dependency effectively. Overall, DEMINE-sig and DEMINEmeta-sig outperformed spectral HSIC on the challenging sine wave dataset. Gaussian kernels were used for spectral HSIC, but more complex kernels could potentially improve results. A sanity check was performed along with comparisons to other statistical dependency testing implementations on a 1D Gaussian dataset with independent variables X and Z. Multiple runs with different random seeds were conducted to assess the false positive rate."
}