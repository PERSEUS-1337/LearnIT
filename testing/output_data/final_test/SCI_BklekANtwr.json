{
    "title": "BklekANtwr",
    "content": "Long short-term memory (LSTM) networks are used to learn sequences of 3D meshes for numerical simulations of car crashes. The approach involves transforming surface mesh sequences into spectral descriptors to efficiently encode shape. A two-branch LSTM network architecture is employed for unsupervised video prediction, with an encoder LSTM mapping input sequences to a fixed-length vector representation and two decoder LSTMs reconstructing the input sequence and predicting future behavior. The spatio-temporal error behavior of the LSTM model is analyzed to study its ability to extrapolate learned spectral descriptors into the future for numerical simulations in the automotive industry. Data-driven virtual product design is crucial for saving time and resources during development processes. Running a large number of simulation runs is not feasible due to the time it takes on a compute cluster. The rise of deep neural networks (DNNs) has led to increased research and industrial applications, particularly in autonomous driving and product design in the automotive industry. One example is using DNNs to predict car crash behavior based on numerical simulations, aiming to create a system that can imitate crash dynamics efficiently. The architecture learns crash behavior and imitates crash dynamics using car crash simulations based on a mathematical model. Data transformation allows for a compressed representation suitable for neural networks, avoiding direct handling of geometries in machine learning methods. The network designed for video prediction and embedding is adapted for mesh data using LSTM, a recurrent neural network for learning 3D sequences. The paper focuses on using DNNs to analyze car crash data, categorizing related works into publications on DNNs for 3D graphics and ML techniques for car crash simulations. The majority of research on 3D deep neural networks focuses on extending CNNs for 3D space, geometric deep learning, and developing CNN filters for unorganized point clouds. There is a lack of ConvLSTM extension for 3D space, but recent works introduce new feature sets and architectures for mesh embedding using autoencoders and LSTM. Recent works introduce new feature sets and architectures for mesh embedding using autoencoders and LSTM. The bidirectional LSTM architecture outperforms autoencoders, and an LSTM-based learning network has been proposed where the feature representation is fed into a CNN for lower dimensional latent space representation. Data collection diversity is crucial for deep learning applications. The study focuses on surface mesh data from car crash simulations, specifically a Chevrolet C2500 pick-up truck model with variations in plate thickness of structural components. The data is from a frontal crash simulation, showing different deformation behaviors. The geometries of the car model and parts are available in a regular mesh format. The study focuses on surface mesh data from car crash simulations, specifically a Chevrolet C2500 pick-up truck model with variations in plate thickness of structural components. Instead of working directly with 3D surface meshes, features are extracted for training the network to represent crash dynamics efficiently. A compact representation for deforming shapes based on the Laplace Beltrami Operator (LBO) is used for the car crash case. The Laplace Beltrami Operator (LBO) is utilized for car crash simulations to represent mesh deformations without stretching or tearing. Eigenvectors remain unchanged under isometric transformations, allowing for the projection of mesh functions onto an orthogonal basis to compute spectral coefficients. The Laplace Beltrami Operator (LBO) is used for car crash simulations to represent mesh deformations efficiently. Spectral coefficients are computed using an orthonormal basis derived from the Laplace operator, providing an optimal approximation for functions controlled in the H 1 -Sobolev norm. This spectral representation is analogous to Fourier decomposition of signals and is introduced for training LSTMs, allowing for bypassing the complexity of dealing with large meshes directly. The spectral coefficients C are obtained from the first m unit eigenvectors of the Laplace Beltrami Operator (LBO) for a 3D shape with n points. Using orthonormal matrices B, the 3D shapes can be reconstructed with smaller approximation errors by increasing the number of eigenvectors used. Averaging errors over samples for four distinct geometries shows the effectiveness of the spectral representation in preserving details. The reconstruction error for a 3D shape is analyzed over a simulation time, with errors localized towards the front of the parts undergoing large deformations during a crash. Different DNN architectures have been extensively investigated for frame prediction in videos and obtaining latent representations, with Srivastava et al. (2015) proposing an unsupervised LSTM-based method for video representation learning. Car crash simulation data can be viewed as a sequence of 3D geometries, similar to video frames. A two-branch LSTM architecture with reconstruction and prediction decoders is used for representation learning, following previous work on video prediction. The two-branch LSTM architecture with reconstruction and prediction decoders from Srivastava et al. (2015) is used for representation learning. The encoder LSTM maps an input sequence of k time steps into a fixed length vector representation, which is decoded using a decoder LSTM for reconstruction. The prediction decoder LSTM predicts future sequences of length k \u2212 l, where l < k, with a design shown to have better performance for predicting future frames compared to other approaches. The prediction encoder-decoder LSTM is similar to the autoencoder LSTM but functions as a supervised method for predicting future behavior after the input sequence. The prediction encoder-decoder LSTM in a two-branch architecture is designed to predict future sequences based on the initial input, addressing biases in autoencoder and encoder-decoder LSTMs. The model uses the input sequence as seed points to generate the rest of the sequence, improving performance in predicting future frames. The compositional architecture of the LSTM autoencoder network is designed to predict future sequences by learning the entire degrees of freedom of crash dynamics. The network uses the input sequence as seed points for reconstruction and future prediction, focusing on the left and right structural beams of a 3D truck model. The study focuses on evaluating an approach using left and right structural beams of a car. 205 simulations were performed, with each sample consisting of four parts over ten time steps. The dataset is divided into training and test sets. Each data point is normalized by the l2 norm of the features at t=0. The study evaluates using left and right structural beams of a car in 205 simulations. Each sample consists of four parts over ten time steps. The dataset is divided into training and test sets, with data points normalized by the l2 norm of features at t=0. The two branch LSTM network is employed with specific unit sizes and ReLU activation function. The entire network is trained together using ADAM over 100 iterations. The training phase involves the encoder, reconstruction, and prediction parts of the network over 100 iterations until reaching a stable mean squared error of 10^-7. The prediction part generates the next five time steps of the crash. Least squares error is computed for each grid point and accumulated over time. Figure 4 displays histograms of reconstruction and prediction errors during training. The reconstruction error is larger than the prediction error in the training and test datasets for all four parts, specifically for the spectral coefficients. A bifurcation in the car crash dataset has been reported, leading to two different bending behaviors for the beams due to changes in plate thicknesses. The simulations can be clustered into two groups, allowing for an analysis of the proposed system's performance for each branch of the bifurcation individually. This provides insight into how well the network can recognize the bifurcation and the spectral coefficients. The network's ability to recognize a bifurcation and preserve spectral coefficients is tested using simulations. Results show small reconstruction and prediction errors, indicating the network can learn complex structural mechanics. The errors accumulation for reconstruction in the two branches is visualized, showing the network's performance for each branch individually. The errors accumulation for the reconstruction in the two branches is similar, with higher error values in the red part and mid-range errors in the blue part. The prediction branch shows different error localization over time, with increasing errors and a change in behavior at the eighth time step. The encoder LSTM weights visualize the dataset's underlying space, using t-SNE to show bifurcation as two distinct clusters in Figure 6. Some points in each branch are misaligned, possibly due to high-dimensional mapping. The encoder LSTM weights visualize the dataset's underlying space, showing bifurcation as two distinct clusters. Some points in each branch are misaligned, possibly due to using spectral coefficients as an approximation. Increasing m might rectify the issue. The 2D visualization demonstrates the network's ability to learn the crash dynamics. The problem of video frames prediction in 3D is addressed by introducing spectral coefficients and a two branch LSTM architecture without convolutional layers. The employed LBO basis and spectral coefficients encode 3D shapes for video embedding and future frames prediction. A dataset from car crash simulations with plate thickness variations is used for evaluation. The network performs well in the presence of a bifurcation, showing different error localizations for reconstruction and prediction. The 2D visualization displays the bifurcation as two clusters, demonstrating the network's effectiveness with spectral coefficients. The proposed network using spectral coefficients can learn complex dynamical structural mechanical behaviors from a small amount of data. Future work may focus on scaling the pipeline for learning crash dynamics of entire cars and larger mesh sizes. Using spectral coefficients can simplify the re-meshing process by encoding shapes with different vertices numbers into fixed-size feature vectors. The question remains on how a trained network can be evaluated for changed geometries or different crash scenarios. The current system aims to improve accuracy by incorporating design parameters into the network architecture. It seeks to learn from minimal training data to predict simulation results for new design parameters, reducing computational resources. The ultimate goal is a data-driven system that can generate crash sequences with minimal error. Additionally, the system could be used as a feasibility detector during simulations on a compute cluster. The system aims to predict simulation results using minimal training data and design parameters, reducing computational resources. It can be used as a feasibility detector during simulations on a compute cluster. The approach involves extrapolating spectral coefficients and using LSTM autoencoders for car crash data. The system aims to predict simulation results using minimal training data and design parameters, reducing computational resources. It involves extrapolating spectral coefficients and using LSTM autoencoders for car crash data. Resulting features are long vectors, requiring 8 hours for learning on a CPU/GPU system for a data set similar in size to ours, where we aim for 30 minutes. Comparing these two approaches will be future work."
}