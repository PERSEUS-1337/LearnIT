{
    "title": "Bkl2SjCcKQ",
    "content": "In this paper, strategies are presented to identify fake samples generated with the Generative Adversarial Network framework. One strategy involves statistical analysis and comparison of raw pixel values and features, while the other learns formal specifications from real data to detect fake samples. Results on various datasets show that fake samples have a universal signature that can be used for identification. The study focuses on evaluating fake samples using formal methods. This paper evaluates fake samples generated by Generative Adversarial Networks using statistical summaries and formal specifications computed on real data. While most evaluations of GAN output focus on qualitative measures like sample quality, little is mentioned about the numerical properties of fake samples compared to real ones. In the context of Verified Artificial Intelligence, verifying that a model's output meets data specifications is challenging. This paper focuses on verifying fake samples generated by Generative Adversarial Networks by comparing numerical properties of fake and real samples. It highlights that fake samples have subtle properties that can distinguish them from real ones and discusses how these properties can be used to identify the source of the data. The paper discusses how fake samples generated by Generative Adversarial Networks can be identified by their subtle properties. It criticizes existing evaluation methods like fitting a Gaussian Parzen window and the inception score for their drawbacks in assessing GAN models. In GANs, authors rely on visual inspection of generated images to assess image quality and avoid mode collapse. Alternative objective functions and algorithms have been proposed to address issues like instability of learning and meaningful loss curves. Visual inspection remains necessary during training, despite these advancements. The experiments in this paper focus on the properties of fake samples generated by GANs, including numerical differences in statistical moments and violations of formal specifications. Datasets used include MNIST, CIFAR10, a MIDI dataset of Bach Chorales, and a subsample of the NIST 2004 speech dataset. Features extracted include the spectral centroid commonly used in the audio domain. The spectral centroid (centroid BID11) is a key feature used in various domains, computed by transforming pixel values into row probabilities and obtaining the expected row value. The spectral slope, adapted from BID11, is calculated using linear regression with an overlapping sliding window. These features are demonstrated on MNIST and Mel-Spectrograms in FIG1. Additionally, samples generated by DCGAN architecture using LSGAN and IWGAN/WGAN-GP are compared, along with adversarial MNIST samples produced with fast gradient sign 1 Kernel Density. We compare adversarial MNIST samples generated using the fast gradient sign method (FGSM) with GAN-generated samples. Different non-linearities are evaluated on the generator's output, focusing on identifying numerical properties that distinguish GAN-produced samples. The distribution of features over the MNIST training set is compared to other datasets, including the MNIST test set and samples generated by GANs. Training data is scaled and a random baseline is set. The study compares GAN-generated MNIST samples with those generated using the fast gradient sign method. IWGAN produces better samples than LSGAN, as shown in visual inspection. Statistical comparison using Kolgomorov-Smirnov and Jensen-Shannon Divergence tests reveals differences in pixel intensity distribution. The empirical CDFs in FIG1 help understand these numerical phenomena. The distribution of pixel values in GAN-generated samples is bi-modal, approaching values 0 and 1. The FGSM method causes a noticeable shift in the distribution modes. Fake images show more noise compared to real images, as seen in the distribution of statistical moments of the spectral centroid. Images with pixel values of 0 or 1 equally distributed have a mean spectral centroid with a mode at the center row. The fake images generated by GANs have noise that is equally spatially distributed, as shown by the distribution of mean spectral centroids. The GAN-generated samples smoothly approximate the modes of the distribution, which is different from the training and test sets. Different GAN architectures and activation functions were tested to evaluate this smooth approximation. The study tested various GAN architectures and activation functions to analyze the smooth approximation of fake images to the distribution of pixel intensities in the training data. The models with linear or scaled tanh activations were able to produce images similar to the MNIST training data, indicating a smooth curve in pixel intensities. Binarizing the real data did not affect the smooth behavior, suggesting that the smoothness in pixel intensities was inherent in the training data itself. The study analyzed the smoothness of pixel distribution in generated data using neural networks. Backpropagation and stochastic gradient descent update weights based on loss gradient. The inductive bias of smoothness is crucial for differentiation, leading to smooth pixel value distributions during training. The U shape of pixel distribution is a byproduct of this smoothness. The distribution of pixel values in fake samples generated with the IWGAN framework and DCGAN architecture differs from real data, especially for values close to -1. JSD between training data and IWGAN samples is significantly larger than with test data. The IWGAN samples differ from real data in pixel value distribution, particularly around 1. This difference can help identify GAN samples. The study explores Bach chorales generated using GAN and compares them to real data in piano roll format. The study compares features distribution in training, test, GAN generated samples, and a random baseline. Intensities in training and test data are strictly bi-modal. Violations of Bach chorales specifications are investigated using piano rolls. IWGAN samples show over 5000 violations compared to real data. The IWGAN samples have over 5000 violations compared to real data, indicating they do not come from the same distribution. The fake samples also violate the style of Bach. Distribution of note durations is analyzed, showing that the improved WGAN approximates the dominating modes. In the speech domain, real and fake samples from Mel-Spectrograms are compared. The NIST 2004 dataset is divided into training and test sets for generating samples using the GAN framework. Mel-Spectrograms are obtained by projecting spectrograms onto a mel scale with specific parameters. The GAN models are trained using DCGAN with the improved Wasserstein GAN algorithm, and the generated samples can be seen in FIG1. Dynamic range compression is applied to the Mel-Spectrograms. In this experiment, the Wasserstein GAN algorithm is used with continuous intensity values compressed using the log function. The KS-Statistic shows a significant difference between test and fake samples compared to training data. However, manipulation of fake samples can decrease this difference while maintaining similarity in harder to simulate features. Statistical moments computed on spectral centroids and slope show considerable overlap in distributions from different sources. In this study, the properties of fake samples generated by Generative Adversarial Networks were analyzed. It was found that fake samples closely approximate the dominant modes of the distribution due to the optimization process. Statistical measures showed a large divergence between real and fake data, especially in the distribution of pixel intensities. Additionally, fake data significantly violates the specifications of real data. The fake data generated by Generative Adversarial Networks significantly violates the specifications of real data, showing large differences in distribution. These differences can be used to identify fake samples, even if some features are weakly correlated with the image content. Training Generators to replicate the support of real data or mining easy-to-learn but hard-to-differentiate specifications are potential strategies to address these issues in the domain of Verified Artificial Intelligence. The paper acknowledges the feedback from Ryan Prenger and Kevin Shih and thanks NVIDIA for providing the Titan X GPU for the experiments."
}