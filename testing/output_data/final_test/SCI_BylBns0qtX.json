{
    "title": "BylBns0qtX",
    "content": "In robotic applications, maintaining a belief about the system's state is crucial for planning and decision-making. Recursive Bayesian Filtering algorithms address this problem by requiring models of process dynamics, sensory observations, and noise estimates. Recent works show that these models can be learned through end-to-end training. However, finding suitable noise models remains a challenge, leading to reliance on simplistic models in practical applications. The hypothesis is that end-to-end training can improve Bayesian filtering methods. Our hypothesis is that end-to-end training through differentiable Bayesian Filters enables learning complex heteroscedastic noise models for system dynamics. Experiments show that learning such models, especially for Particle Filters, can significantly improve tracking performance in robotic tasks. Recursive Bayesian Filtering is a probabilistic approach to estimating the current system state using an observer that provides state feedback from sensor measurements. The method relies on process and observation models to predict system behavior and generate expected observations. The challenge lies in formulating these models and estimating the noise within them to determine the certainty of predictions and observations. Deep neural networks are effective for extracting patterns from high-dimensional input signals. However, for robotics tasks like modeling dynamics, combining prior knowledge with trainable network components leads to better performance. Differentiable Bayesian Filtering algorithms focus on learning observation and dynamics models end-to-end, demonstrating improved results. The recursive filtering structure improves prediction results over using recurrent neural networks in robotic applications. Identifying appropriate values for process and observation noise is challenging despite research on identification methods. Heteroscedastic noise models, where uncertainty levels depend on the system state, have shown to enhance filtering performance in robotics tasks. In this work, a method to learn heteroscedastic noise models from data is proposed by optimizing prediction likelihood through differentiable Bayesian Filters. Different versions of the Unscented Kalman Filter are also introduced. The performance of these filters and noise models is evaluated on two real-world robotic problems: Visual Odometry for a driving car with simple dynamics and Visual tracking of an object pushed by a robot with challenging dynamics. Planar pushing involves challenging dynamics with heteroscedastic noise distribution. Using heteroscedastic process noise models significantly improves tracking performance of Particle Filter and Unscented Filter variants. Learning noise models benefits all filters, with EKF being the least sensitive. Learning observation noise does not show significant improvement in results. Filtering aims to estimate the state of a stochastic system given initial beliefs, observations, and control inputs. The aim is to compute p(x t |x 0...t\u22121 , u 0...t , z 0...t ) using a state space representation with process model f and observation model h. The model assumes Markov property and allows for computing p(x t |x 0. Common filtering algorithms like the Kalman Filter provide solutions for systems with linear models and Gaussian noise. The Extended Kalman Filter (EKF) extends the Kalman Filter to systems with non-linear process and observation models. It linearizes the models around the current mean of the state using Jacobians for prediction and update. The EKF uses the Kalman Gain to trade-off process noise and observation noise for updating the belief represented by mean \u00b5 and covariance matrix \u03a3. The Unscented Kalman Filter (UKF) addresses the limitations of the Extended Kalman Filter (EKF) by representing a Gaussian random variable with sigma points in state space. The Unscented Transform allows for the calculation of new statistics after a nonlinear transformation. In the prediction step of the UKF, the process model is used to compute the new mean and covariance. The UKF conveys non-linear transformations of covariance more faithfully than the EKF by using sigma points in state space and fitting a new Gaussian to transformed points. The parameter \u03bb controls the spread of sigma points and weighting of the original mean X0. Difficulty in tuning \u03bb can lead to prediction uncertainty and filter destabilization. Choosing \u03bb such that \u03bb + n = 3 may result in negative values for n > 3, affecting the estimated covariance matrix positivity. Negative weighting of X0 can cause divergence of the estimated mean in the UKF. The UKF uses sigma points to represent the state belief, but finding the correct scaling parameter \u03bb can be challenging, especially in high-dimensional states. An alternative approach is to use Monte Carlo methods, where samples from the current state distribution replace sigma points with uniform weights. This modification requires more samples to accurately represent the distribution. In contrast to Kalman Filter variants, the Particle Filter BID5 does not assume a parametric state distribution. The Particle Filter BID5 represents the state with particles, allowing it to track multiple hypotheses simultaneously. Initial particles are drawn from a prior belief with uniform weights. New particles are generated at each step by sampling process noise. The likelihood of each particle generating an observation is evaluated, and weights are updated accordingly. Particle deprivation is a common issue where particles receive low likelihoods over time. The Particle Filter algorithm uses resampling to prevent low likelihood states, drawing new particles with uniform weights from the old set. BackpropKF is a differentiable implementation of the Kalman Filter that enables training a neural network to preprocess input images and predict observation noise. The BackpropKF algorithm utilizes a heteroscedastic observation noise model for situations where information cannot be extracted from images, such as occlusions. It outperformed an LSTM model due to prior knowledge encoded in the Filtering algorithm. Jonschkowski & Brock (2016) introduced a differentiable Histogram Filter for discrete localization tasks, showing improved results when optimizing models end-to-end through the filter. BID9 ; BID12 proposed differentiable Particle Filters. In BID9 and BID12, differentiable Particle Filters were proposed for localization and tracking of a mobile robot using neural networks to predict particle likelihood. BID9 learned the process model and noise distribution, while BID12 used a given process model and introduced soft resampling for backpropagation through multiple time steps. It was shown that integrating algorithmic structure with learning leads to better results and training filter components end-to-end is beneficial. In this work, the focus is on learning heteroscedastic noise models and analyzing their benefits within different filtering algorithms for various applications. The evaluation includes a planar pushing task with challenging non-linear dynamics and a 10-dimensional state space. Variational methods offer an alternative approach for learning probabilistic generative model parameters and inferring latent states. Variational inference approximates the posterior distribution by an easier-to-compute distribution. BID3 combines a LGSSM with a variational autoencoder to encode sensory data into a low-dimensional latent representation. LSTM network predicts process model parameters from latent encodings. In contrast to previous works, BID13 train a variational autoencoder to predict process model parameters and noise from observations, ensuring the latent state contains all necessary information for prediction without relying on future observations. These methods focus on unsupervised learning in systems with unknown state representation, while our work leverages prior knowledge of the process model and state representation. The curr_chunk discusses the use of variational methods and learning in differentiable filters for supervised and unsupervised training in state space models. Variational methods optimize an approximate posterior distribution, while Bayesian filters provide fixed algorithms for approximating the posterior. Variational methods offer more flexibility in fitting training data, while Bayesian filters are more restricted in the models they can learn. The curr_chunk discusses implementing filtering methods as recurrent neural networks in tensorflow BID0, focusing on parametrizing and using learnable noise models in state space models. The observation model in state space models predicts observations from the state, but it can be challenging to find a model that directly predicts high-dimensional raw sensory signals. In experiments, a discriminative neural network is trained to preprocess raw sensory data and create a compact representation of observations. The perception network extracts components of the state directly from the data, simplifying the observation model. Additionally, the perception networks can predict the diagonal entries of the observation noise covariance matrix. The networks are pretrained to predict components of the state, and in experiments where the noise covariance matrix is learned, it is initialized with reasonable values. In the process noise modeling, a trainable bias is used with a fixed diagonal matrix R. Two conditions are considered: constant and heteroscedastic noise. The constant noise model has a trainable variable representing the diagonal entries of the covariance matrix Q. In the heteroscedastic case, the diagonal elements are predicted from the current state and control input using a 3-layer MLP. Different variants of the Kalman Filter use process noise in the prediction and update steps. In the training phase, noise models are trained end-to-end through filters using the Adam optimizer and backpropagation through time. The loss includes the negative log likelihood of the true state given the belief, Euclidean error between the ground truth state and predicted mean, and a regularization term on the weights of the trainable noise models. The ground truth state sequence, prediction mean, covariance, and weights of the trainable noise models are involved in the loss calculation. During training, noise models are optimized using scaling factors \u03bb i to minimize overall predicted covariance and penalize high confidence predictions with large errors. The MCUKF and Particle Filter approximate the state by sampling, with a limit of 100 samples during training to manage memory and computation time. Testing can use a higher number of particles/sigma points. End-to-end learning of heteroscedastic noise models is evaluated to see how it impacts filtering algorithm performance. Testing includes conditions without learning, learning observation noise R, learning heteroscedastic process noise Qh, and learning both with constant or heteroscedastic process noise (R + Q, R + Qh). Experiments are conducted on two different applications, including the Kitti Visual Odometry task. The Kitti Visual Odometry task involves estimating the position and orientation of a car using RGB images and true initial state. The dynamics model is simple, but the challenge lies in unknown driver actions and unobservable absolute position and orientation. Filters rely on estimating velocity from image pairs to update the state, leading to inevitable uncertainty growth. The uncertainty in updating the state of the car's position and heading grows due to missing feedback. A neural network is pretrained to extract information from current and difference images. The network architecture is similar to previous work, with batch normalization replacing response normalization layers. The Particle Filter is tested with 1000 particles and sigma points for the MCUKF. Process and observation noise are initialized consistently. Process noise is set using ground truth velocity standard deviation. The Kitti Visual Odometry dataset includes 11 trajectories with ground truth annotations for position and heading. Data augmentation is done by adding mirrored sequences. Training involves extracting non-overlapping sequences of length 50 with random starting points. Validation and testing sequences consist of 100 timesteps. In the Kitti Visual Odometry dataset, training involves extracting sequences of length 50 with random starting points, while validation and testing sequences consist of 100 timesteps. The perception network is pretrained offline and finetuned through filters in different noise learning conditions. The EKF outperforms other filters on the task, even without learning noise models, while the Particle Filter and MCUKF perform poorly without learning or when training observation noise alone. Learning a constant process noise improves their results. Learning a heteroscedastic process noise model significantly improves the performance of the MCUKF and PF in predicting the car's heading. This model facilitates training by quickly converging towards zero for position and orientation, unlike the constant noise setting where convergence is slower. The observation model implementation may also play a role in these differences. The MCUKF is not suitable for predicting car movement due to high uncertainty in car orientation caused by bad initialization of process noise. The standard UKF performs better by enforcing movement in the correct direction. The EKF performs best on the task of predicting car movement as it provides a good approximation of the posterior due to the smooth process model. Unlike PF and UKF, EKF does not generate additional uncertainty about the car's position and heading, making it more suitable for visual odometry where there are no observations to resolve uncertainty. The second experiment deals with quasi-static planar pushing, which involves non-linear and discontinuous dynamics. The state to estimate has 10 dimensions, including object position, orientation, friction parameters, contact point, and pusher status. An analytical model is used to predict the object's velocity based on pusher velocity and current state. The experiment involves using coordinate images to train a neural network to extract object position, contact point, and orientation changes between images. The network does not assume the initial state is correct and is evaluated on various initial conditions with different errors. The experiment uses coordinate images to train a neural network for object position extraction, contact point, and orientation changes. Evaluation is done on five initial conditions with varying errors, reporting average error and standard deviation. The MIT Push dataset includes real robot push sequences with object and pusher positions, force recordings. Additional annotations are obtained for state components and depth images using tools from BID17. Images show the robot arm from a realistic angle, with data from pushes at 50 mm/s velocity. The experiment uses data from pushes at 50 mm/s velocity to render short sequences of images. Sequences are extended to 100 steps by chaining pushes and adding movement. Training is done on subsequences of ten steps, testing on the full 100 steps. Tracking performance of different filters is compared without learning noise models. Filters are evaluated with unrealistic and realistic confidence values. EKF shows average performance of 11.8 \u00b1 0.54. Table 2 shows the evaluation of four non-linear filters under different noise learning conditions for the Planar Pushing task. The filters are compared based on their performance with realistic noise values. EKF, UKF, MCUKF, and PF are evaluated in terms of their tracking performance under various noise learning scenarios. The Particle Filter is most affected by unrealistic noise settings, sampling particles far from the true state. Learning noise models improves performance in tracking errors for the Planar Pushing task. In the Extended Kalman Filter, UKF, and MCUKF, performance remains mostly constant across conditions. Improved tracking of object orientation is seen with a constant process noise model and heteroscedastic Q. Traditional UKF with trained R and heteroscedastic Q performs best, while MCUKF could potentially perform better with more sigma points. Particle Filter benefits the most from learning in different conditions. The Particle Filter benefits greatly from learning in different conditions, especially with heteroscedastic process noise. Learning a separate Q for each particle helps steer the particle set towards more likely regions of the state space, improving tracking performance. Training observation noise R had minimal effect in this experiment. In contrast to previous findings, the study did not find evidence that heterostochasticity of observation noise was beneficial. This could be due to the lack of complete occlusions in the dataset. The study suggests that a constant observation noise model may have been sufficient. The researchers proposed optimizing process and observation noise for Bayesian Filters through end-to-end training and evaluated the method on two robotic applications. Our experiments showed that learning the process noise is crucial for filters like the Particle Filter and Unscented Kalman Filters, while the Extended Kalman Filter is more robust to suboptimal noise models. Optimized Unscented Filters outperformed in tasks with complex dynamics. Training a state-dependent process noise model improved prediction accuracy and facilitated faster model convergence. Developing better methods for communicating uncertainty about neural network predictions is crucial for improving the performance of differentiable Bayesian Filters. The Extended Kalman Filter steps can be implemented in Tensorflow without modifications, with a focus on computing the Jacobians of the process and observation model. Tensorflow supports auto differentiation but lacks native support for computing. Tensorflow lacks native support for computing Jacobians, so manual derivation is recommended. Implementing the UKF steps in Tensorflow is straightforward, but Cholesky decomposition often fails, so singular value decomposition is used instead. For the MCUKF, sigma points are sampled from a Gaussian distribution using Tensorflow's distribution tools. Our Particle Filter implementation, similar to BID9's variant, incorporates differentiable resampling from BID12 for backpropagation through weights. Unlike directly predicting observation likelihood, we use a preprocessing network for outputting observations and estimated covariance. Probability of observations under a Gaussian distribution is computed for each particle and R. This training approach may be more challenging due to small likelihoods with observation noise. Training differentiable filters in tensorflow can be challenging, especially ensuring positive semidefinite covariance matrices. The process model for visual odometry involves updating positions, velocities, and angles. The preprocessing network architecture is based on BID6. Process noise is initialized with specific values. The process model for visual odometry involves updating positions, velocities, and angles. The preprocessing network architecture infers object position, contact point, contact normal, and contact indicator from raw input images. Process noise is initialized with specific values for the analytical model output. The process model predicts the next contact point and normal by updating positions and angles based on the output of the analytical model. The prediction accuracy is limited by the pusher's radius, and the normal orientation is adjusted to the object's rotation using a rotation matrix."
}