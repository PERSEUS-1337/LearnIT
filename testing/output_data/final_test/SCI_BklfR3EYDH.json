{
    "title": "BklfR3EYDH",
    "content": "To reason about temporal sequences efficiently, abstract representations that compactly capture key events are essential. A hierarchical Keyframe-Inpainter (KeyIn) model is proposed in this paper to discover keyframes and represent sequences based on them. The model shows superior performance in learning hierarchical representations compared to other recent proposals. Humans focus on important future events without worrying about minor details. Temporal abstraction can make reasoning and planning more efficient. An example is a lead animator sketching keyframes to outline a story before filling in the sequence. Learning to discover keyframes from raw sequences is a powerful approach. Our goal is to learn an abstraction for future image prediction by selecting keyframes that are most informative about the full sequence, allowing holistic reasoning while using a small number of frames. The model selects keyframes that are informative about the full sequence, enabling visual predictive planning for long-horizon tasks. Our proposed model selects keyframes representing interesting moments in a sequence, allowing for easy inpainting of remaining frames. This hierarchical probabilistic model uses a keyframing module to identify keyframes and an inpainting module to fill in the gaps. By optimizing a variational lower bound, the model can predict future sequences accurately. The KEYIN model is a hierarchical approach for discovering informative keyframes using joint keyframing and inpainting. It can recover keyframe structures on visual data and identify hierarchical temporal structures in complex datasets. The hierarchy discovered by KEYIN improves planning performance, outperforming other planning schemes on tasks like robotic pushing. The KEYIN model discovers keyframes for robotic pushing tasks, enabling hierarchical control. Previous hierarchical neural models have been proposed for sequence modeling, but applying them to videos may be impractical. Keyframe representations have been used in video processing since 1991, with recent adaptations for neural compression. Our approach proposes a hierarchical video representation by discovering keyframes that best describe a sequence, different from other neural methods that leverage temporal structure. This method enables efficient hierarchical planning with a small set of keyframes, contrasting with models that use constant offsets between keyframes. Additionally, Kipf et al. (2019) focus on video segmentation for training hierarchical RL agents, while our model aims to represent sequences effectively. Video modeling involves probabilistic approaches such as autoregressive models and latent variable methods based on variational inference. Various models have been proposed, including those using normalizing flows for exact inference. The approach proposed uses exact inference based on normalizing flows for video modeling and learning temporal abstractions with a keyframe-based generative model. It builds on existing work in visual planning and model predictive control, showing improved planning performance with a hierarchical representation of sequences in terms of keyframes. A probabilistic model is developed for joint keyframing and inpainting in a hierarchical planning setting. The model generates keyframes and temporal indices, inpainting frames between keyframes to predict sequences. The goal is to predict key observations and time steps, filling in remaining observations. The model consists of a keyframe predictor and sequence inpainter, with a maximum likelihood objective for discovering keyframe structure. The model consists of two parts: the keyframe predictor and the sequence inpainter. The keyframe predictor generates keyframes and corresponding time indices, while the sequence inpainter fills in frames between keyframes to complete the sequence generation. The model handles different temporal spacing based on motion characteristics by predicting keyframe indices and inpainting frames between them. The model uses a latent variable z to create a multimodal distribution over keyframes. A variational lower bound is constructed for both images and keyframes, with a weight \u03b2 on the KL-divergence term. The keyframe predictor must be powerful to allow for a simpler inpainting process. Our model utilizes a latent variable z to generate a multimodal distribution over keyframes, with a focus on maximizing the likelihood. By combining a flexible keyframe predictor with a simpler inpainter, the model can identify semantically meaningful keyframes in video data. The process involves computing target images for predicted keyframes and evaluating reconstruction loss. To address the challenge of learning a distribution over keyframe placement efficiently, a continuous relaxation of the objective is proposed. The placement distribution \u03c4 n defines a probability for each predicted frame to match to a certain frame in the ground truth sequence. Instead of sampling from this distribution to pick a target frame, a soft target is produced for each predicted frame by computing the expected target frame. Keyframe targets are produced by linearly interpolating between ground truth images according to the predicted distribution over the keyframe's temporal placement. Temporal placement prediction is parametrized in terms of offsets \u03b4 with a maximum offset of J. Temporal placement prediction is parametrized in terms of offsets \u03b4 with a maximum offset of J, allowing for sequences of length N J. KEYIN accurately reconstructs motion by selecting informative keyframes, while a method with constant temporal keyframe offset fails to capture direction changes. Generating sequences longer than N J > T requires discarding irrelevant information. To compute the relaxed objective, predicted frames at times > T are discarded and placement probability is normalized. The inpainting network produces J frames between keyframes, with targets for ground truth images interpolated based on probability of predicted frames matching. The model uses a keyframe predictor parametrized with an LSTM network and a common encoder-recurrent-decoder architecture for training on high-dimensional observations like images. The full loss is computed by normalizing the probability distribution over produced frames. The keyframe predictor is parametrized with an LSTM network and conditioned on past frames. The sequence inpainter is also parametrized with an LSTM and conditioned on keyframe embeddings and temporal offsets. The network predicts keyframes at the timestep of events or one timestep apart, even for randomized agent positions. The model uses Gaussian and multinomial distributions for prediction in Gridworld. Inference is parametrized with an LSTM with attention, and training is done in two stages: first for inpainting and then for keyframe prediction. The model uses Gaussian and multinomial distributions for prediction in Gridworld, with training done in two stages: first for inpainting and then for keyframe prediction. The keyframe predictor is trained using L1 reconstruction losses and a reconstruction loss on the predicted embeddings of the keyframes. Target embeddings are computed using soft relaxation, and the quality of the representation is evaluated for future sequences. The model is evaluated on three datasets: Structured Brownian motion (SBM), Gridworld, and Pushing. SBM dataset contains binary image sequences of a ball changing directions. Gridworld dataset involves an agent navigating a maze with objects. Pushing dataset includes sequences of a robot arm pushing a puck towards a goal. The demonstrations were generated with the MuJoCo simulator at a resolution of 64 \u00d7 64 pixels. Keyframe discovery was evaluated by training KEYIN on three datasets, showing meaningful keyframes marking direction changes, transitions, and interactions. The inpainter network adapts keyframe prediction patterns to produce high-quality frames. Misplaced keyframes result in blurry interpolations. KEYIN discovers informative keyframes by describing overall sequences better than alternative approaches. The KL-divergence D KL between prior and posterior of a stochastic predictor is used to measure surprise. Keyframes are defined as points of direction change in datasets. KEYIN outperforms alternative methods in discovering keyframes, especially on complex datasets like Pushing and Gridworld. KEYIN outperforms alternative methods in discovering keyframes on complex datasets like Pushing and Gridworld. It can represent complex data distributions and achieve high diversity and visual quality in video sequences. Sample generations from the model show its ability to faithfully model complex distributions. KEYIN demonstrates superior performance in discovering keyframes on complex datasets like Pushing and Gridworld. It can accurately represent diverse video sequences and outperforms previous methods in terms of keyframe modeling and sequence prediction metrics. Additionally, KEYIN's robustness is evaluated by varying the number of selected keyframes, showing high recall with extra keyframes and high precision with fewer keyframes. KEYIN is able to find informative keyframes even when N does not exactly match the data structure. The method can select a superset or subset of original keyframes, showing robustness to the number of predicted keyframes. KEYIN remains effective even when trained and tested on sequences with additive Gaussian noise, commonly found in real-world camera sensors. KEYIN can find keyframes that capture an abstraction of a sequence, demonstrating effectiveness in hierarchical planning in the pushing environment. The keyframe predictor generates trajectories by sampling latent variables and optimizing for a sequence that reaches the target. KEYIN optimizes for latent variables to create keyframe trajectories that lead to the goal using the Cross-Entropy Method. These keyframes are used as subgoals for a low-level planner that employs model predictive control. The planning procedure is illustrated in Fig. 7. The effectiveness of the keyframes is evaluated by comparing to alternative subgoal selection schemes. The method optimizes for latent variables to create keyframe trajectories leading to the goal. It compares to other subgoal selection schemes and outperforms prior approaches, showing a significant improvement in performance. Our method, KEYIN, generates informative keyframes for sequences by keyframing and inpainting. It outperforms planners using Jumpy and Surprise subgoals, showing improved trajectory following. KEYIN discovers keyframes on datasets with stochastic dynamics, enhancing hierarchical planning schemes. Future work includes improving end-to-end training and exploring more powerful techniques. An improved training procedure allows end-to-end training. Powerful hierarchical planning approaches can be designed using keyframe representation for long-term tasks. The keyframing method can be applied to various applications like video summarization, understanding, and hierarchical video prediction. Simple attention over LSTM outputs is effective for inference. Posterior distribution over z t is computed using a key-value attention mechanism. The architecture for keyframe inference includes a key-value attention mechanism. The prediction horizon is set to 30 frames, predicting 6 segments for the SBM dataset and 6 frames for the Pushing dataset. The interpolator is pre-trained on segments of varying lengths, with specific hyperparameters hand-tuned. Generated images are activated with a sigmoid function, using BCE losses on each color channel to prevent saturation. The convolutional encoder and decoder have three layers for the Structured Brownian motion dataset and four layers for the Pushing dataset. A two-layer LSTM with a 256-dimensional state is used for all recurrent modules, with linear projection layers before and after. The Adam optimizer with specific parameters is used, and training is done on a high-end NVIDIA GPU. The interpolator is trained for 100K iterations, and the keyframe predictor for 200K iterations, taking about a day in total. The Pushing environment has a test set of 120 sequences, while the Structured Brownian Motion dataset is potentially infinite with 1000 testing samples used. The pushing dataset was collected in a simulated environment using MuJoCo. Demonstrations followed a rule-based algorithm to push an object to a goal position. Keyframes were defined at subgoal completion frames. Demonstration videos were subsampled by a factor of two. The pushing dataset was generated in a simulated environment using a rule-based algorithm to push objects to goal positions. Keyframes were defined at subgoal completion frames, and the continuous relaxation loss computation details were described. The computational complexity scales linearly with the number of keyframes, allowed frames per segment, and ground truth frames. Standard stochastic video prediction methods do not estimate keyframes and cannot be used as baselines for this approach. The variance of the learned prior in a stochastic video prediction model spikes before uncertain events, which is used to identify points of high uncertainty for keyframes. The KL divergence between the prior and approximate posterior is used to measure surprise, indicating the level of stochasticity in the next state. A stochastic video prediction network with a fixed prior is trained, and selecting peaks of surprise helps in finding true keyframes. The procedure for selecting keyframes involves running the inference network on a generated sequence to find keyframes. Keyframes are determined by converting offset distributions to timesteps and computing probabilities. Soft keyframe targets are calculated, and a keyframe loss is computed. The surprise measure is used to identify peak surprise points for keyframes. The surprise measure is used to find peak surprise points for keyframes. Training KEYIN with different numbers of keyframes results in the model predicting subsets or supersets of true keyframes based on the structure of the model. The KEYIN model uses a subset of keyframes for good inpainting. Latent variables are sampled for planning, with successful trajectory snapshots shown. The cross-entropy method is used to select subgoals, and keyframe detections are illustrated on noisy sequences. The KEYIN model reliably detects keyframes and reconstructs sequences, even in the presence of additive Gaussian noise. It shows good alignment with annotated keyframes, indicating robust performance under noisy conditions. In the CEM algorithm update step, trajectories are ranked based on cost and a Gaussian distribution is fit to the latents z of the top sequences. The cost between frames is defined as the Euclidean distance between object center pixels, recovered through color-based segmentation. The algorithm can be extended to use alternative cost formulations. Subgoals are selected and a CEM planner generates rollout trajectories. In the subgoal generation procedure, action sequences are sampled and image trajectories are generated based on ground truth dynamics. Trajectories are ranked by cost, and a Gaussian distribution is fitted to the best sequences. New actions are sampled from the distribution for multiple iterations. The algorithm terminates after a specified number of iterations, with the first action of the best rollout executed. The algorithm generates action sequences, ranks trajectories by cost, fits a Gaussian distribution, samples new actions, and terminates after a specified number of iterations or reaching the goal threshold."
}