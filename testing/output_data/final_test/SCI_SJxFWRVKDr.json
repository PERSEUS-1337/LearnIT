{
    "title": "SJxFWRVKDr",
    "content": "Deep networks face challenges in ensuring robustness against inputs not effectively represented by training data. A gradient-based representation is proposed to complement activation-based representation, focusing on missing information. A directional constraint on gradients during training improves missing information characterization. The gradient-based representation outperforms activation-based by 0.093 in CIFAR-10 and 0.361 in CURE-TSR datasets for anomaly detection. An anomaly detection algorithm utilizing this approach is also proposed. The proposed anomaly detection algorithm, GradCon, utilizes a gradient-based representation to outperform state-of-the-art algorithms in CIFAR-10, MNIST, and fMNIST datasets with average AUROC values of 0.664, 0.973, and 0.934, respectively. Deep networks face robustness issues when input not properly represented by learned knowledge is given. Deep networks are vulnerable due to limitations in activation-based representation. Complementing input data with unlearned information can enhance algorithm robustness. Gradients are crucial for learning new information in deep networks through backpropagation. During training, gradients guide deep networks to learn new information not present in the training data, complementing activation-based representations. Gradients help characterize missing information, as shown in an example where a network trained on curved edges learns to recognize straight edges in a new input. The activation-based representation in deep networks helps characterize information already learned, while gradients guide updates to learn new information. Gradients can effectively represent missing information, complementing activation-based representations. This approach has been used in various applications like adversarial attacks and visualization. The paper demonstrates the effectiveness of using gradient representation to characterize unlearned information in deep networks and detecting potentially invalid data. It proposes utilizing gradients as a representation to identify information not learned from training data but present in input data, compares gradient and activation representation capabilities, and introduces a gradient-based anomaly detection algorithm that outperforms activation-based methods. This approach complements activation-based representations and has applications in adversarial attacks and visualization. Several techniques have been developed to enhance the representation capability of activation in deep networks, including finetuning models with adversarial, blurred, and distorted images. Pre-processing methods like discrete cosine transform (DCT) have also been used to improve algorithm robustness. Additionally, methods for detecting and filtering out problematic samples have focused on improving data representation to achieve better performance. Methods have been developed to improve data representation in deep networks, including gradient-based pre-processing techniques to distinguish adversarial and out-of-distribution images from training images. Constrained activation representations are used for abnormal data detection. A new approach proposes backpropagated gradients-based representation to focus on unlearned information. The backpropagated gradients are used to visualize what has not been learned in the trained network, as well as for adversarial attacks and image classification. Various studies have shown how backpropagated gradients can map learned information back to the pixel space and weight activations for prediction reasoning. Adversarial attacks can be generated by adding a small vector based on input gradients. In Kwon et al. (2019), backpropagated gradients are used to classify and estimate image quality. Gradients with respect to input have been incorporated for regularization in deep network training to improve robustness. The role of weight gradients in data representation is explored using an autoencoder framework. The autoencoder consists of an encoder and a decoder, generating a latent variable from an input image and reconstructing the image. Training involves minimizing a loss function with a reconstruction error and a regularization term. Gradients are visualized to show the structure of the manifold formed by reconstructed training images. During test time, input to the autoencoder is projected onto the reconstructed image manifold. Test images outside the manifold are poorly reconstructed, showing missing knowledge the autoencoder cannot learn. During test time, the autoencoder projects input onto the reconstructed image manifold. The gradient of weights is calculated through backpropagation to incorporate test images accurately. These gradients represent orthogonal variations of the test distribution with respect to the reconstructed image manifold, characterizing missing information in the trained networks. The reconstruction error provides distance information between test and reconstructed images, serving as a primal loss to generate gradients. The gradients focus on directional information to represent missing knowledge in trained networks, complementing distance information from activation-based representations. They require discriminant capability in high dimensional space to be effective in practical scenarios of deep networks. The representation of information not learned in deep networks is expected to differentiate from learned information. Gradients from images with learned information should have a different direction compared to those with new information. This separation is crucial to characterize missing knowledge in deep networks. In Fig. 2, the reconstructed image manifold is a two dimensional plane in three dimensional space. Gradients from test images with learned information are tangential to the manifold, allowing for a distinction between learned and missing information in the network. Two experiments were conducted using a convolutional autoencoder (CAE) to analyze this separation. In the first experiment, backpropagated gradients from test images are analyzed for alignment using cosine similarity. The distribution of cosine similarity between Airplane class images with learned information and images from other classes is visualized. The average cosine similarity is calculated over all layers in the decoder to assess the effectiveness of gradients as a representation. The cosine similarity between images with learned and missing information is analyzed for separability. The proposed method reduces the number of overlapped samples, making gradients more distinguishable. Gradients become more aligned for learned information and orthogonal for missing information, improving separability. In the second experiment, the alignment of gradients in a CAE is analyzed by measuring cosine similarity. The focus is on the distinction between gradients from learned and missing information, visualized over 1000 training epochs. The study focuses on aligning gradients in a CAE to distinguish between learned and missing information. The proposed method effectively constrains gradients, achieving a cosine similarity of 0.55 to 0.85. This constraint leads to clear separability in the results. The directional constraint enables gradients to characterize missing information in deep networks. The study proposes using cosine similarity to align gradients in a CAE, with a regularization term in the loss function. The gradient constraint is applied at the kth iteration of training, ensuring optimal weights exploration until the primal loss is minimized. This constraint is applied to a subset of layers, with a small \u03b1 value to maintain active gradient exploration. The forward propagation calculates the primal loss, while backpropagation obtains \u2202L \u2202Wi k without weight updates. The entire loss J is then calculated, and weights are updated using backpropagated gradients. This gradient constraint is applied to autoencoders for evaluation. The study introduces a gradient constraint in autoencoders to evaluate its performance in characterizing unlearned information. Anomaly detection is used to assess activation-based and gradient-based representations. Abnormal data is defined as data not learned during training, with images from one class considered inliers for training. The study introduces a gradient constraint in autoencoders for anomaly detection, evaluating activation-based and gradient-based representations. Inliers from one class are used for training, while outliers are given during testing to distinguish learned and unlearned knowledge. Existing anomaly detection methods rely on activation-based representations, utilizing reconstruction error or latent loss for anomaly characterization. Two sets of experiments validate the effectiveness of gradient-based representation in characterizing missing information. The study evaluates the anomaly detection performance of gradient-based representations in autoencoders. An autoencoder with 4-layer encoder and decoder is used, training CAEs with mean squared error and VAEs with binary cross entropy and KL divergence. The gradient loss is defined by the gradient constraint and utilized as abnormality scores for anomaly detection. In the second experiment, an anomaly detection algorithm called GradCon is developed using reconstruction error and gradient loss as abnormality scores. GradCon outperforms other algorithms on benchmarking datasets like CIFAR-10, CURE-TSR, MNIST, and fashion MNIST. These datasets contain color images, traffic sign images, handwritten digit images, and fashion classes respectively. The curr_chunk discusses the dataset protocols for CIFAR-10, CURE-TSR, MNIST, and fMNIST, including training and testing splits, validation, and anomaly detection experiments. It mentions using specific classes for training and testing, as well as the utilization of challenge-free images for CURE-TSR. During testing, challenge-free images are used as inliers and their challenging versions as outliers. Results are evaluated using AUROC and F1 score on the fMNIST dataset for comparison with a previous method. Anomaly detection performance is compared based on gradient loss, reconstruction error, and latent loss using CIFAR-10. The effect of gradient constraint on characterizing missing information is analyzed, showing comparable performance with the addition of the constraint. The gradient constraint in VAE + Grad achieves the second best performance by marginally sacrificing the average AUROC of reconstruction error and latent loss. Imposing constraints on activation can degrade the performance of other activation-based representations in characterizing missing information. The gradient constraint in VAE + Grad achieves good performance in anomaly characterization by complementing activation-based representations. Anomaly detection in CURE-TSR highlights the discriminant capability of gradient representation for diverse challenging conditions. CAE + Grad outperforms CAE in detecting challenging conditions like decolorization, lens blur, exposure, rain, snow, and haze. CAE + Grad achieves superior performance in anomaly detection, with the gradient loss outperforming the reconstruction error in most cases. The gradient representation effectively captures challenging information and surpasses activation-based methods. Comparison with GradCon, a combination of reconstruction error and gradient loss, shows promising results. The proposed method is compared with other algorithms including OCSVM. GradCon achieves the best average AUROC performance in CIFAR-10 and comparable performance in MNIST compared to other state-of-the-art methods. It is solely based on gradient loss, making it computationally efficient without the need for additional networks. Visualizations are provided in Fig. 5. The proposed method, GradCon, demonstrates state-of-the-art performance in separating inliers and outliers in MNIST and CIFAR-10 datasets. It relies on gradient loss, which outperforms activation-based losses, especially in CIFAR-10. Comparisons with another algorithm, GPND, show GradCon's superior performance in fMNIST experiments. In fMNIST experiments, the proposed method GradCon outperforms GPND in terms of AUROC and F1 scores across different outlier ratios. The method introduces a gradient-based representation for characterizing information not learned by deep networks, showing effectiveness in anomaly detection and achieving state-of-the-art performance. The proposed method based on gradient representation achieves state-of-the-art performance in benchmarking datasets by effectively characterizing missing information through gradients. This approach complements distance information from activations and provides a comprehensive perspective for handling data not represented in training data, ensuring robustness in deep networks."
}