{
    "title": "HylWY1n4Yr",
    "content": "Recent findings suggest that deep generative models, like variational autoencoders (VAEs), can struggle with misaligned likelihood estimates on image data. To address this issue, a novel likelihood function is developed that incorporates both VAE parameters and self-supervised learned data features to capture semantic information. Experiments on FashionMNIST and MNIST datasets demonstrate improved reliability of estimates. Deep Generative Models (DGMs) have become popular for modeling training data density and generating new samples, but challenges in inference remain, as highlighted by Nalisnick et al. (2018). In response to the challenges highlighted by Nalisnick et al. (2018) regarding the reliability of likelihood-based models like VAEs and flow-based models, a novel likelihood estimation method is proposed to address misaligned likelihood estimates on image data. This method leverages findings from previous work and aims to improve the accuracy of likelihood estimates during test time. The main contribution of this paper is the introduction of a feature-based likelihood trained in a self-supervised fashion, which evaluates the model based on the semantics of an image. The aim is to improve the reliability of likelihood estimation produced by VAEs, focusing on image data specifically. The curr_chunk discusses the evaluation of Variational Autoencoders (VAEs) and their use of amortized inference with encoder and decoder neural networks. It also mentions omitting experiments on non-image data and refers to previous work for specifics on VAEs. The curr_chunk discusses the evaluation of Variational Autoencoders (VAEs) using different evaluation schemes and likelihood functions. B\u00fctepage et al. (2019) argue that the choice of evaluation scheme and likelihood parametrisation influence the likelihood estimates produced by a trained VAE. The effect is demonstrated in Figure 1 with VAE V1 using a Bernoulli likelihood and VAE V2 using a Gaussian likelihood. The evaluation of Variational Autoencoders (VAEs) is discussed, comparing different evaluation schemes and likelihood functions. The choice of evaluation scheme and likelihood parametrisation impacts the variance of estimates and the diversity of latent representations. B\u00fctepage et al. (2019) demonstrate this with VAE V1 using a Bernoulli likelihood and VAE V2 using a Gaussian likelihood on FashionMNIST and MNIST datasets. The likelihood parametrisation choice influences estimate values, with the top-left combination reproducing results from Nalisnick et al. (2018). The self-supervised feature-based likelihood function is the main contribution of this work, hypothesising that likelihood estimates are affected by the assumption of independent and identically distributed image pixels. The likelihood function in image representation is based on iid pixels, capturing pixel-wise errors locally. To address the lack of global evaluation, a weighted likelihood term is proposed during test time, incorporating semantic information from a self-supervised classifier. The feature representation of an image is trained on the same dataset as a VAE. A Bayesian Gaussian Mixture model is fitted to the feature representations, and during evaluation, each mixture component is assigned a weight. The global likelihood of an image is defined based on the contribution of each mixture component. The likelihood of a test image under decoded parameters is evaluated using a combined likelihood function that captures local pixel-wise errors and global semantic likelihood. Experiments on FashionMNIST and MNIST datasets were conducted, and low-dimensional features were extracted using a self-supervised Jigsaw classifier. After training a self-supervised Jigsaw classifier on FashionMNIST and MNIST datasets, low-dimensional features were extracted from the first layer of the classifier. A BGM model with 15 components was fitted to the representations of 10000 training images. The parameters were determined through hyperparameter grid search, and VAEs V1 and V2 were trained for further experiments. In the experiment, two VAEs (V1 and V2) and two Jigsaw classifiers (\u03931 and \u03932) were trained on FashionMNIST dataset with different specifications. The models were trained on binarised images and images with pixel values scaled to [0, 1]. V1 assumes a Bernoulli likelihood and V2 a Gaussian likelihood. Low dimensional features were extracted from the first layer of the Jigsaw classifier and used to calculate likelihoods. The experiment involved training two VAEs (V1 and V2) and two Jigsaw classifiers (\u03931 and \u03932) on FashionMNIST dataset with different specifications. The likelihood p F EV AE was proposed under the fitted BGM following Equation (3), and the log likelihood estimates were compared using PR and APO evaluation schemes on FashionMNIST and MNIST datasets. The results showed significant improvement in estimates with Gaussian likelihood parametrisation, separating OOD samples from ID samples. The VAE parameters \u03c6 x (z) in the PR evaluation reflect the distribution of the entire training data, averaging over all classes during training time. Our method increases the variance of the likelihood of OOD samples but fails to achieve the same separation as in the Gaussian case due to loss of semantic information during binarisation of FashionMNIST dataset. OOD samples become too similar to ID samples when background is corrupted with salt and pepper noise, suggesting that the Bernoulli likelihood is not effective in this case. The Bernoulli likelihood is not suitable for modeling OOD samples in VAEs, as it makes them too similar to ID samples. Loaiza-Ganem and Cunningham (2019) recommend using a continuous Bernoulli distribution instead. The assumption that image pixels are iid around decoded parameters limits the VAE likelihood function to a local area of data density, ignoring global data density and semantic information. Our proposed likelihood function addresses this issue by utilizing self-supervised feature learning. Future work includes evaluating the method on CIFAR-10 and SVHN datasets and developing an end-to-end training procedure for VAEs using the new likelihood."
}