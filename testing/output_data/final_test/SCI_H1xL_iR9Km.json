{
    "title": "H1xL_iR9Km",
    "content": "The machine learning and computer vision community is experiencing a surge in new tasks addressed by deep convolutional networks. Each new task comes with a human-labeled dataset for supervised training, but labeling data is costly and time-consuming. To tackle this, algorithms like GradMix are developed for multi-source transfer learning across domains and tasks in a semi-supervised setting. GradMix transfers knowledge by mixing gradients from various sources during gradient descent. The proposed method, GradMix, transfers knowledge by weighting and combining gradients from different sources during training. It follows a meta-learning objective by assigning layer-wise weights to the gradients, adjusting learning rates adaptively, and using pseudo-labeling for unlabeled samples. Experimental results on digit and action recognition tasks show superior performance compared to baseline methods. The need for algorithms to reduce manual labeling efforts in supervised training is highlighted, with a focus on adapting deep models across domains, transferring knowledge across tasks, and learning efficiently in a few-shot manner. While most works concentrate on single-source and single-target scenarios, recent efforts have emerged for multi-source domain adaptation, assuming shared label space between source and target domains. In this work, the problem of multi-source domain and task transfer (MS-DTT) is formalized, aiming to transfer knowledge from multiple labeled source datasets to a sparsely labeled target dataset in a semi-supervised setting. The focus is on aligning feature distributions between source and target domains for domain transfer. In this work, a method called GradMix is proposed for semi-supervised multi-source domain and task transfer (MS-DTT). Unlike traditional methods, GradMix does not require feature alignment through additional layers or loss functions. Instead, it transfers knowledge by weighting and mixing gradients from all source datasets during training, following a meta-learning paradigm. GradMix is a method proposed for semi-supervised multi-source domain and task transfer. It weights and mixes gradients from all source datasets during training to minimize loss for unbiased samples from the target dataset. The method adapts the learning rate for each mini-batch based on its importance to the target task and utilizes a pseudo-labeling method based on model ensemble to learn from unlabeled data in the target domain. Extensive experiments on digit recognition and action recognition tasks show superior performance compared to multiple baselines. The code is available at https://www.url.com. Domain adaptation aims to create a model that performs well on a target domain by addressing the domain shift issue. Various methods focus on aligning feature distributions or learning domain-invariant features. Transfer learning extends this concept. Transfer learning extends domain adaptation to cases where source and target domains may differ in input and label spaces. In computer vision, ConvNets trained on large datasets like ImageNet have shown state-of-the-art performance when transferred to other tasks through fine-tuning. This work focuses on scenarios where source and target domains share the same input space but have different label spaces. Meta-learning aims to quickly learn on target tasks using knowledge from past experiences and only a few annotated samples. Meta-learning aims to quickly learn on target tasks using knowledge from past experiences and only a few annotated samples. It seeks to perform learning at a higher level than conventional learning, such as learning update rules or finding good initialization points for easy fine-tuning. A recent method proposes training models with good generalization ability to novel domains. The method uses validation loss as the meta-objective and reweights source domain gradients layer-wise for transfer learning. The semi-supervised MS-DTT problem is formally introduced, assuming a set of source domains and a target domain with shared input space but different label spaces. The target domain has sparsely labeled images, with the goal of learning a strong classifier for predicting labels. Unlike standard domain adaptation, this approach considers joint transfer across domains and tasks, with some source domains having overlapping label spaces with the target domain. The network parameters are denoted as \u0398, and a loss function L(x, y; \u0398) = f(\u0398) is minimized during training using SGD or its variants for deep networks. In semi-supervised MS-DTT, a small validation set V with labeled samples from the target domain is used to optimize the weights for the source gradients. The goal is to minimize the loss on the validation set by adjusting the parameters according to the sum of the source gradients. Calculating the optimal weights requires nested loops of optimization, which can be computationally expensive. In semi-supervised MS-DTT, a small validation set V is used to optimize weights for source gradients. A first-order approximation is proposed to adjust parameters based on the validation gradient, maximizing cosine similarity. Layer-wise gradient weighting is suggested for finer gradient combination in the network. This method provides a cheap estimation for the meta-objective and prevents over-fitting to V. In semi-supervised MS-DTT, a small validation set V is used to optimize weights for source gradients. A first-order approximation is proposed to adjust parameters based on the validation gradient, maximizing cosine similarity. Layer-wise gradient weighting is suggested for finer gradient combination in the network. This enables a finer level of gradient combination. Specifically, in our MS-DTT setting, the source domains and the target domain share the same parameters up to the last fully-connected (fc) layer, which is task-specific. To efficiently solve the constrained non-linear optimization problem, we utilize a sequential quadratic programming method, SLSQP, implemented in NLopt. In practice, we normalize the weights for each layer across all source domains so that they sum up to one. In semi-supervised MS-DTT, a method is proposed to adaptively adjust training by measuring the importance of mini-batches using cosine similarity. A scaling term is calculated based on this importance score, and used to update parameters in SGD. Additionally, a pseudo-label with ensembles approach is introduced to learn target-discriminative knowledge from a large set of unlabeled images in the target domain. In semi-supervised MS-DTT, a method is proposed to adaptively adjust training by measuring the importance of mini-batches using cosine similarity. A scaling term is calculated based on this importance score and used to update parameters in SGD. The proposed method calculates pseudo-labels for unlabeled images and constructs a pseudo-labeled dataset. The model is trained using the source domain datasets and a gradient mixing method to acquire pseudo-labels, with the ensemble of models helping to produce more reliable labels. In semi-supervised MS-DTT, a method is proposed to adaptively adjust training by measuring the importance of mini-batches using cosine similarity. The ensemble of models helps to produce more reliable pseudo-labels by training multiple models with different combinations of parameters. The top models with the best accuracies are selected to create pseudo-labels using hard label and soft label approaches. During training, pseudo-labels are generated for unlabeled images by averaging probabilities from multiple pre-trained models. The soft pseudo-labels are used to minimize KL-divergence with the model output probabilities. Both hard and soft label approaches are employed before training a new model from scratch. After generating pseudo-labels, a model is trained from scratch using all available datasets. The gradient mixing method relies on an enlarged validation set to estimate the model's performance on the target domain. The experiment involves transfer learning across different digit domains using MNIST and Street View House Numbers datasets. SVHN dataset has 73,257 training examples and 26,032 testing examples with colored background and blurred digits. Another setup involves MS-DTT from MPII dataset BID0 and BU101 dataset BID18 for video action recognition using UCF101 dataset. MPII dataset has 28,821 images covering 410 human activities, while UCF101 dataset consists of 13,320 videos from 101 action categories. BU101 dataset contains 23,800 images with the same action categories as UCF101. The experimental setting involves using different ConvNet architectures for training and fine-tuning with specific learning rates. Training data includes labeled images from SVHN and MNIST datasets for different sources. The experimental setting involves training ConvNet architectures with labeled images from SVHN and MNIST datasets. The second source includes labeled images of digits 0-4 as S2, while validation set V consists of labeled images of digits 5-9. Unlabeled images from the rest of the training split of MNIST 5-9 are used as U. Baselines are compared with the proposed method, which includes training with different subsets of labeled examples and hyper-validation set for tuning hyper-parameters. The model is trained using different methods including Source only, Fine-tune, MDDA BID19, DCTN BID33, GradMix w/o AdaLR, GradMix, GradMix w/ hard label, and GradMix w/ soft label. These methods involve training with various subsets of labeled examples and using different approaches for creating pseudo-labels. GradMix method outperforms other methods in classification accuracy. Results show that adaptive learning rate improves accuracy. Increasing k leads to better performance. Using different \u03b2 and \u03b3 values with k=3 also improves accuracy. Ensemble of top three models used for creating pseudo-labels. V helps in combining gradients during training. Some methods in the lower part of the table utilize all available datasets. The proposed GradMix method achieves comparable performance with state-of-the-art baselines that use all available datasets. Using pseudo-label with model ensemble significantly improves performance. Hard label approach outperforms soft label. Ablation study demonstrates the effectiveness of the method and the impact of different hyper-parameters. Results of hyper-validation loss for Source only method and GradMix are shown. GradMix achieves quicker and steadier decrease in hyper-validation loss compared to other methods. Grid search results show highest accuracy with \u03b2 = 10 and \u03b3 = 0.6. Top three models are selected for ensemble to create reliable pseudo-labels. Using top three models for ensemble yields better performance. Action recognition experiment involves four sets of training data, including labeled images. The experiment involves training data from various sources, including labeled images and video clips. Different numbers of video clips are sampled for each class. The experiment is run twice with different video clip samples. Baselines are compared, including Target only, Source only, and Fine-tune methods. Per-frame and per-video classification accuracies are reported. The experiment involves training data from various sources, including labeled images and video clips. Different numbers of video clips are sampled for each class. Baselines are compared, including Target only, Source only, and Fine-tune methods. Per-frame and per-video classification accuracies are reported. Results show that Target only outperforms Source only, indicating a distribution shift between source and target data. GradMix performs better than baseline methods using S1, S2, and V for training, and achieves comparable performance with MDDA using the unlabeled dataset U. The proposed pseudo-label method improves accuracy by assigning hard labels to U and learning target-discriminative knowledge. GradMix is a method for semi-supervised MS-DTT that assigns layer-wise weights to gradients from each source objective to optimize the target objective. It adapts learning rates for each mini-batch and uses pseudo-labels from model ensembles for unlabeled samples. The method is validated through experiments on digit and action recognition tasks, showing its effectiveness in multi-source domain and task transfer. For future work, GradMix aims to extend its application to tasks with limited labeled data, such as image captioning."
}