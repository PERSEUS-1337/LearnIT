{
    "title": "BJeZw4B334",
    "content": "Interpolation of data in deep neural networks is a subject of research interest. Over-parameterized single layer fully connected autoencoders memorize training data rather than just interpolate. Depth is necessary for memorization in convolutional autoencoders. Adding nonlinearity to deep convolutional autoencoders results in stronger memorization by outputting individual training images. These findings shed light on the inductive bias in over-parameterized deep networks. Recent research has focused on the role of interpolation in deep convolutional neural networks, showing that overparametrized networks can interpolate training data even with random labels. Autoencoders, trained to minimize a specific function, have multiple interpolating solutions. Autoencoders in the overparametrized setting exhibit interpolating solutions, with inductive bias characterized as memorization. This is relevant for CNNs and image tasks, where autoencoder architectures are commonly used. In the overparametrized setting, autoencoders exhibit memorization by mapping input images to the training set. This phenomenon extends to nonlinear and deep convolutional autoencoders. The paper discusses the phenomenon of memorization in autoencoders, specifically focusing on the difference between fully connected and shallow convolutional architectures. It highlights that fully connected autoencoders map input images to the training set, while shallow convolutional autoencoders do not memorize training data, even with added filters. The study also explores the connection to linear regression and the nonlinear span of training data. In Section 4, the study shows that memorization in linear CNNs extends to nonlinear CNNs, which exhibit strong memorization by outputting individual training images. Section 5 concludes the discussion. Appendices E, F, G, and H provide details on downsampling, early stopping, and initialization effects on memorization in linear and nonlinear convolutional autoencoders. This section focuses on the memorization properties of nonlinear single layer fully connected autoencoders initialized at zero, providing a closed form solution for the matrix A using gradient descent on mean squared error loss. When initialized at A (0) = 0 and computed using gradient descent on mean squared error loss, a closed form formula for A can be derived in the nonlinear overparameterized setting under three mild assumptions often satisfied in practice. These assumptions involve properties of the function \u03c6, such as concavity, convexity, and monotonicity, which are typically observed in nonlinearities like sigmoid and tanh used in practice. Theorem 1 shows that in an overparametrized setting, solving a nonlinear autoencoder problem can be reduced to a linear regression problem using gradient descent. The proof suggests that the adaptive learning rate may not be necessary for the result to hold. The autoencoding problem can be reduced to a linear regression problem, defining a memorization property for nonlinear systems with \u03c6-eigenvectors and \u03c6-span. Memorization in nonlinear single layer fully connected autoencoders is characterized in the corollary. In the context of autoencoding, shallow linear convolutional autoencoders do not memorize training data, achieving 0 training error by satisfying \u03c6-eigenvectors with eigenvalue 1. The rank of the solution A (\u221e) is equal to the rank of the covariance matrix of training examples, indicating a relationship between the two in the overparameterized setting. Shallow linear convolutional autoencoders do not memorize training data even in the overparametrized setting, requiring depth for memorization. A single filter convolutional autoencoder trained on images in R s\u00d7s using gradient descent learns a rank s 2 solution. The proof involves constructing a matrix A to represent the autoencoder. Material D. Theorem 2 states that a single layer single filter convolutional autoencoder in the overparameterized setting does not memorize training data due to forced zeros in the matrix A. This prevents memorization in such autoencoders. Theorem 2 states that a single layer single filter convolutional autoencoder in the overparameterized setting does not memorize training data due to forced zeros in the matrix A. Lemma 1 shows that a single layer linear autoencoder with a single forced zero entry cannot memorize arbitrary inputs. Shallow convolutional autoencoders still contain forced zeros regardless of the number of filters used in the intermediate layers. Theorem 3 states that at least s - 1 layers are required for memorization in a linear convolutional autoencoder with filters of kernel size 3. Theorem 3 emphasizes the necessity of depth over filters in linear convolutional autoencoders for memorization. A 2-layer autoencoder with kernel size 3 and stride 1 cannot memorize images of size 4x4 or larger, regardless of filter count. Depth is crucial for memorization in convolutional autoencoders. In linear convolutional autoencoders, depth is crucial for memorization. Downsampling through strided convolution allows for memorization with fewer layers. Nonlinear convolutional autoencoders with leaky ReLU activations strongly memorize examples from CIFAR10. This paper explores the mechanism behind memorization in autoencoders, showing that deep nonlinear convolutional autoencoders have training examples as strongly attractive fixed points. Unlike linear models, convolutional autoencoders require overparameterization through depth or downsampling for memorization. Overparameterization through depth or downsampling is necessary for memorization in convolutional settings, while increasing the number of filters in a layer does not lead to memorization. Memorization is more pronounced in the non-linear setting, where input images are mapped to visually identifiable output images. The exact mechanism behind this phenomenon is still not fully understood, but it is reminiscent of FastICA in Independent Component Analysis or non-linear eigenproblems. Our work explores the relationship between overparameterization, memorization, and generalization in deep convolutional networks. We suggest that increasing depth may enhance memorization, particularly in non-linear settings. This could have implications for tasks like image classification using deep networks with near zero initialization. Our findings could provide insights into the connection between overparameterization, memorization, and generalization properties in neural networks. When using gradient descent to solve the autoencoding problem for the system, the gradient with respect to the parameters A is calculated. The gradient descent with learning rate \u03b3 > 0 will proceed according to a specific equation. If A(0) = 0, the recurrence relation for t > 0 can be solved directly. The matrix S is real symmetric and has an eigendecomposition. The proof of Theorem 2 from the main text is presented, focusing on the convergence of the first row of matrix A during gradient descent. The proof involves using gradient descent on matrix A with an adaptive learning rate per example. The learning rate is determined by the reciprocal of a function \u03c6. The strategy for the proof is outlined before continuing. The strategy for the proof involves using assumption (c) and induction to upper bound the sequence (\u03c6(A DISPLAYFORM5 j) with a sequence along a line segment. The iterative form of gradient descent along the line segment will provide a coordinate-wise upper bound on the sequence A (t)1. This upper bound is shown to be a coordinate-wise least upper bound, and A (t)1 is proven to be a coordinate-wise monotonically increasing function converging to the least upper bound. The text discusses the use of gradient descent to establish an upper bound for a sequence of parameters B in solving a linear regression problem. It also shows that B is a coordinate-wise upper bound for A, with a detailed induction proof provided. The text provides a detailed induction proof to establish an upper bound for a sequence of parameters B in solving a linear regression problem. It shows that B is a coordinate-wise upper bound for A, with key details preserved. The induction proof establishes an upper bound for the parameters B in solving a linear regression problem. B is shown to be a coordinate-wise upper bound for A, with entries of A monotonically increasing. The entries of A (t) converge to the entries of B (\u221e) as the least upper bounds. The proof shows that A (t) converges to the solution obtained by autoencoding the linear system Ax (i) = \u03c6 \u22121 x (i) using gradient descent with constant learning rate. The convolutional layer can be represented as a matrix operating on a vectorized zero padded image. Training this layer to autoencode examples using gradient descent is equivalent to fitting examples using gradient descent. The rank of the resulting solution will be s^2. This section explains how to extract a matrix form for convolutional and nearest neighbor upsampling layers. The matrix form for convolutional and nearest neighbor upsampling layers is constructed by applying Algorithm 1 to create separate matrix blocks for each filter and then concatenating them. An example is provided for converting a single layer convolutional network with a single filter of kernel size 3 into a matrix for 3 \u00d7 3 images. The matrix form A for the convolutional filter is presented to show how it can be applied to the image x. The matrix form for convolutional and nearest neighbor upsampling layers is constructed using Algorithm 1. A fixed zero pattern in the matrix of a convolutional layer is utilized to demonstrate the need for depth in convolutional autoencoders. Linearizing the nearest neighbor upsampling operation is necessary in downsampling autoencoders, with Algorithm 2 providing a general algorithm for this. Linear convolutional autoencoders with varying layers and filters were trained on 3x3 images, showing no memorization. The study trained linear convolutional autoencoders with varying layers and filters on 3x3 images to investigate memorization. Results showed that even with 8 layers, memorizing two images of size 3x3 was not achieved, indicating the need for further depth in convolutional autoencoders. The study found that even with 8 layers, linear convolutional autoencoders could not memorize two 3x3 images. The number of filters per layer did not affect the rank of the learned solution. The depth needed for memorization was determined by a heuristic lower bound. Autoencoders initialized at 0 memorize training examples. Linear convolutional autoencoders with one filter per layer need s^4/9 layers to achieve the same parameters as a fully connected network. This leads to a heuristic lower bound for memorization in linear convolutional autoencoders operating on images of size s x s. The experimental setup involved training networks with gradient descent using a learning rate of 10. The networks satisfying the heuristic lower bound were found to memorize single and multiple training examples based on their eigenvalue spectra. The experimental setup involved training networks with gradient descent using a learning rate of 10. The networks with over 100 layers utilized skip connections every 10 layers to aid gradient propagation. Eigenvalues were sorted by magnitude in the resulting spectrum, with a heuristic lower bound showing effectiveness for deep networks with skip connections. Memorization of 7x7 required over 200 layers according to experiments in TAB4. The experiments in TAB4 show that over 200 layers are needed for memorization of 7 \u00d7 7 images. Downsampling can be used to create smaller convolutional autoencoders that memorize training examples by trading off depth. Extreme downsampling can make a convolutional autoencoder equivalent to a fully connected network, as illustrated in FIG13. Training the network on two CIFAR10 images resulted in a rank of 2 for the learned solution. Using default PyTorch initialization, eigenvalues are 1 and eigenvectors are linear combinations of training images. Memorization with convolutional autoencoders involves downsampling to smaller representations. Depth provided by heuristic bounds leads to memorization, as seen in a network operating on CIFAR10 images downsampling to a 4x4 representation. The network downsamples a 32 \u00d7 32 CIFAR10 image to a 4 \u00d7 4 representation after layer 1, using 29 layers as suggested by a heuristic lower bound. The network memorizes the image by producing a solution of rank 1 with eigenvalue 1, with the eigenvector being the dog image. Investigating if the depth needed for memorization in linear convolutional autoencoders applies to nonlinear ones, a deep nonlinear convolutional autoencoder with specific parameters is considered. The nonlinear network with 29 layers can memorize 4 \u00d7 4 images, showing that depth required for memorization in deep linear convolutional autoencoders carries over to the nonlinear setting. Memorization is stronger in the nonlinear case, as seen in examples where the network outputs individual training examples instead of combinations. The nonlinear network with 29 layers can memorize 4 \u00d7 4 images, showing that depth required for memorization in deep linear convolutional autoencoders carries over to the nonlinear setting. Memorization is stronger in the nonlinear case, appearing early in training before full convergence. Both linear and nonlinear convolutional networks show memorization throughout the training process, mapping new inputs to current representations of training examples. The nonlinear autoencoder FIG16 trained on CIFAR10 images outputs learned representations for test examples, showing memorization throughout training. Initialization at zero is necessary for memorization in linear autoencoders. Memorization is stronger in the nonlinear setting, with depth playing a role in memorization. A 5 layer nonlinear network strongly memorizes 2 \u00d7 2 images with Xavier Uniform initialization and skip connections between every 2 layers. Training images have white squares in different corners and test examples have pixels from a standard normal distribution. The popular initialization techniques such as Kaiming and Xavier uniform/normal, along with PyTorch initialization, are compared to zero initialization. Kaiming initialization leads to larger 2 norm outputs compared to Xavier and PyTorch, suggesting less memorization. Experimental results show noisy outputs for Kaiming initialized networks in nonlinear autoencoders. In experiments with modified Leaky ReLU activations, the Kaiming initialization strategies result in larger norms compared to Xavier, indicating noisy memorization in the output for arbitrary inputs."
}