{
    "title": "H18WqugAb",
    "content": "In this paper, the authors introduce the SCAN domain, a set of navigation commands paired with action sequences, to test the generalization capabilities of recurrent neural networks (RNNs). RNNs can generalize well with small differences between training and test commands but fail when systematic compositional skills are required. The study concludes with a proof-of-concept experiment in neural machine translation. Neural networks struggle with systematic compositionality, which is crucial for making strong generalizations from limited data in human language and thought. Jerry Fodor and others argue that neural networks cannot capture this compositionality, making them implausible models of the mind. Neural networks excel in practical domains like machine translation but struggle with systematic compositionality, leading to sample inefficiency and reliance on broad patterns over accumulated statistics. This paper introduces a grounded navigation environment to explore these limitations. The paper introduces a grounded navigation environment to test the systematic generalization capabilities of modern recurrent network architectures. Results show that while standard architectures like LSTMs with attention can generalize with mixed constructions, they struggle with systematic differences between training and test sentences. The data set SCAN is a simplified version of the CommAI Navigation tasks, where learners translate commands into action sequences. It can be treated as a supervised sequence-to-sequence semantic parsing task. SCAN consists of commands generated by a grammar and corresponding action sequences. The SCAN grammar allows for primitive actions like JUMP, WALK, and LTURN, along with modifiers and conjunctions to build action sequences. Modifiers like \"left\" and \"right\" change the direction of actions, while \"opposite\" and \"around\" modify the agent's movement. Repetition can be triggered with \"twice/thrice\" and actions can be combined with \"and/after\". The SCAN grammar allows for primitive actions like JUMP, WALK, and LTURN, along with modifiers and conjunctions to build action sequences. The grammar lacks recursion but can generate a large set of commands. Commands can be decoded compositionally by applying the function in Appendix Fig. 7. Learners can understand commands they have not seen during training by learning the meaning of different verbs. For example, a learner can decode the complex command \"jump around left after jump twice\" zero-shot. The seq2seq approach is used to decode commands in the SCAN grammar by utilizing a recurrent network encoder and decoder. The encoder forms a low-dimensional representation of the command, which is then used by the decoder to generate the output action sequence. The encoder and decoder have the same network structure but do not share weights/parameters. Various recurrent neural network models were tested using this framework. Recurrent networks like SRNs, LSTMs, and GRUs were tested with and without attention mechanisms. A hyperparameter search varied layers, hidden units, and dropout for 180 network architectures. Results were analyzed for successes and failures. The winning architecture was a 2-layer LSTM with 200 hidden units per layer, no attention, and dropout at 0.5 level. Training involved 100,000 trials using the ADAM optimization algorithm with a learning rate of 0.001. Gradients larger than 5.0 were clipped, and the decoder used the previous output as the next input in two different ways during training. The network's self-produced outputs were used for half the training time, while ground-truth outputs were used for the other half. The networks, based on a standard seq2seq implementation in PyTorch, were trained on a large set of commands from the SCAN tasks. Training accuracy was above 99.5% for the best network in each experiment, with successful zero-shot generalization after training on a random subset of tasks. The experiment involved training networks on a large set of commands from the SCAN tasks, with training accuracy above 99.5%. The networks were then evaluated on new commands to test generalization, making zero-shot generalizations based solely on extrapolation from the training data. The tasks were split into a training set and a test set to examine how networks can decompose and recombine commands. The experiment involved training networks on a large set of commands from the SCAN tasks, with training accuracy above 99.5%. The networks were then evaluated on new commands to test generalization, making zero-shot generalizations based solely on extrapolation from the training data. The tasks were split into a training set and a test set to examine how networks can decompose and recombine commands. The network needs to make compositional generalizations by recombining pieces of existing commands to perform new ones. The top-performing network achieved 99.8% accuracy on the test set, using a LSTM architecture with 2 layers of 200 hidden units and no dropout. The best-overall network achieved 99.7% correct using a LSTM with no attention, 2 layers of 200 hidden units, and no dropout. Classic SRNs performed poorly, with the best SRN achieving less than 1.5% correct. Attention-augmented SRNs performed better, achieving 59.7% correct on average. LSTMs and GRUs did not require attention for high performance. The main split provided 80% of commands for training, totaling over 16,700 examples with strong combinatorial coverage. The best-overall network achieved high accuracy without attention, while classic SRNs performed poorly. Attention-augmented SRNs improved performance. The main split provided a large number of examples with strong combinatorial coverage. The results show that networks can generalize to random subsets of tasks with sparse coverage. The experiment confirmed that sequence-to-sequence RNNs can generalize to new commands, which is crucial for achieving impressive results in machine translation. The random split used implies that generalization required for understanding test commands is minor and can be achieved by recombining pieces of seen commands within familiar templates. The experiment showed that sequence-to-sequence RNNs can generalize to new commands, crucial for machine translation success. Models must now bootstrap to longer action sequences than seen in training, requiring productive generalization of familiar elements. The experiment demonstrated that models struggle to generalize to longer action sequences, with the best model achieving 13.8% accuracy. The model only performs well on the longest commands in the test set, which are similar to training instances. The experiment showed that models struggle with generalizing to longer action sequences. Providing the proper length at evaluation time improved network performance, but mastering long sequences remained a challenge. The top-performing model saw a significant improvement in accuracy. The focus was on action sequence length rather than command length due to more variance. The experiment revealed that models faced challenges with long action sequences, even with improvements in network performance. The top model showed a strong correlation between action sequence length and accuracy, ranging from 95.76% for 24 actions to 22.8% for 48 actions. The next experiment aimed to test Fodor's view of systematicity by training the model on primitive commands for basic actions like \"jump.\" The model is trained on basic actions like \"jump\" and exposed to various primitive and composed commands. At test time, it has to execute composed commands for actions it only saw in the primitive context. Two variants of the experiment generalize from \"turn left\" and \"jump\". It is redundant to test all commands as some are distributionally identical. The networks were over-represented with the target primitive command to ensure familiarity. During training, models were familiarized with the primitive commands \"jump\" and \"turn left\", with \"turn left\" being over-represented. Results showed that models performed well on composed commands for \"turn left\" but struggled with \"jump\". The best accuracy achieved for \"turn left\" was 90.3%, while for \"jump\" it was only 1.2%. The exposure to the primitive command during training helped models generalize to composed commands for \"turn left\". The model trained on primitive commands \"jump\" and \"turn left\" struggled with generalizing to new composed commands. Errors were mainly seen in conjunctions involving \"turn left\" commands, even though the model performed well on them. The network struggled with generalizing to new composed commands, particularly in conjunctions involving \"turn left\" commands, despite performing well on them during training. The network struggled with generalizing to new composed commands, especially those involving \"turn left\", despite performing well on them during training. In the \"jump\" experiment, the network could only correctly decode two composite cases, both starting with the execution of primitive \"jump\" conjoined with a different action. Command similarity was measured by the cosine between the final decoder hidden state vectors, showing that \"run\" is close to other primitive commands like \"look\" and \"walk\", as well as short conjoined commands containing \"run\". The model struggled to generalize the compositional paradigm of the primitive command \"jump\" compared to other basic commands like \"walk\", \"look\", and \"run\". Despite similarities in commands composed with \"twice\", \"jump twice\" remained isolated in representational space with arbitrary nearest neighbors. The model was only exposed to \"jump\" in isolation, failing to establish a link to other basic commands for modifier application. The network struggled to generalize the compositional paradigm of the primitive command \"jump\" compared to other basic commands like \"walk\", \"look\", and \"run\". Despite efforts to show composed \"jump\" commands during training, weak generalization was observed until the network was presented with 8 composed tasks, showing significant but still imperfect generalization. The network struggled to generalize the compositional paradigm of the primitive command \"jump\" compared to other basic commands like \"walk\", \"look\", and \"run\". Weak generalization was observed until the network was presented with 8 composed tasks, showing significant but still imperfect generalization. Further experiments confirmed the network's powerful generalization abilities, which do not conform to traditional rule-based behavior and require more positive examples to emerge. These findings extend beyond SCAN to other sequence-to-sequence problems like machine translation. The study extended beyond SCAN to explore machine translation using a seq2seq model with specific hyperparameters. The network achieved a BLEU test score of 28.6 after 100,000 steps. Additionally, the network was tested for compositionality by adding a new word to the training data, showing minimal impact on the original test set's BLEU score. The study explored machine translation using a seq2seq model with specific hyperparameters. The network achieved a BLEU test score of 28.6 after 100,000 steps. Testing the network for compositionality by adding a new word to the training data showed minimal impact on the original test set's BLEU score. The model struggled with translating the word \"daxy\" accurately, achieving only one correct translation out of eight. Our study tested systematicity in modern seq2seq models for machine translation. Results show that while standard recurrent models can achieve high accuracy with representative training data, they struggle with systematic compositionality when adding new words to their vocabulary. This highlights a challenge that neural networks face in tasks requiring compositional generalization. The study tested systematicity in modern seq2seq models for machine translation. Results show that while standard recurrent models can achieve high accuracy with representative training data, they struggle with systematic compositionality when adding new words to their vocabulary. Generalization only occurs when networks are exposed to the target command in a fair number of composed contexts during training. The study tested systematicity in modern seq2seq models for machine translation, showing that while they excel with representative training data, they struggle with systematic compositionality when adding new words. Generalization only happens when networks are exposed to the target command in various contexts during training. This suggests that a model capable of systematic compositionality could greatly benefit machine translation and other applications. Neural networks with external memories show promise for extracting algorithm-like representations, outperforming standard RNNs on longer sequences. Future work will explore these approaches on tests of zero-shot compositional generalization like SCAN. Systematic compositionality is crucial for developing powerful algorithms and understanding the human mind. The encoder-decoder framework transforms natural language commands into learned embeddings for machine translation. The encoder-decoder framework uses learned embeddings to process words in a sequence. The final hidden state is passed to the decoder, which generates a sequence of output actions. The attention decoder can access all encoder hidden states to select the next action. The encoder-decoder framework uses learned embeddings to process words in a sequence. The attention decoder can access all encoder hidden states to select the next action by computing a context vector as a weighted sum of the encoder hidden states."
}