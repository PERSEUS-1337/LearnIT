{
    "title": "ryljV2A5KX",
    "content": "The novel architecture of GAN, IB-GAN, is inspired by Information Bottleneck theory and aims for disentangled representation learning. It introduces capacity regularization for mutual information, leading to better quality samples compared to \u03b2-VAEs. IB-GAN also achieves higher disentanglement metrics on the dSprites dataset. The consensus on the importance of good representations in the learning community has been discussed in various studies. Disentanglement, a key property of representations, involves statistical independence or factorization, aligning with human intuition on data generative factors. Learning representations that distill important factors into independent directions is challenging but valuable for downstream tasks. Various models have been proposed for disentangled representation learning. In contrast to supervised approaches, unsupervised methods like \u03b2-VAE and InfoGAN focus on independent factor learning without requiring ground-truth generative factors or weak supervision. \u03b2-VAE demonstrates high-quality disentanglement by encouraging the KL-divergence term of VAE objective. InfoGAN proposes a fully unsupervised approach based on GAN for disentangled representation learning. The fully unsupervised approach based on Generative Adversarial Network (GAN) BID18 aims to learn disentangled representations by increasing mutual information (MI) between generated samples and latent representations. InfoGAN struggles with complex datasets like CelebA and its disentangling performance is not as good as \u03b2-VAE models. Inspired by the success of \u03b2-VAE models in disentangled representations learning, the weakness of InfoGAN may stem from its focus on maximizing mutual information without additional constraints. IB-GAN is a new GAN-based model for unsupervised learning of disentangled representations, incorporating an information capacity constraint lacking in InfoGAN. The generator can use latent representations in a more interpretable and disentangled manner. IB-GAN is the first unsupervised GAN-based model to incorporate the Information Bottleneck theory, surpassing state-of-the-art disentanglement scores on various datasets. It outperforms existing models like InfoGAN and \u03b2-VAE variants in generating realistic samples. The IB BID25 BID5 aims to obtain a compressive representation Z from input variable X while preserving predictive information about target variable Y. The objective balances maximizing and minimizing mutual information terms to enforce the representation to ignore irrelevant information from X and be predictive about Y. Studies support that representations learned with the IB objective tend to be effective. The IB objective in representation learning aims to create efficient and robust representations that are generalizable, disentangled, and invariant to nuances. The \u03b2-VAE model is a state-of-the-art approach that multiplies a constant \u03b2 to the KL-divergence term in the VAE objective to achieve unsupervised disentangled representation learning. In the context of representation learning, the connection between \u03b2-VAE and the Information Bottleneck theory has been established. By leveraging variational bounds, the MI can be approximated using a prior for the latent representation and a decoder model. This allows for the reconstruction of data from the representation Z in an auto-encoding task. The \u03b2-VAE, based on Information Bottleneck theory, promotes disentanglement by constraining Mutual Information (MI) to focus on relevant data features. Generative Adversarial Networks (GAN) establish an adversarial game between a generator and discriminator to distinguish real samples. The discriminator D distinguishes between real and synthetic samples created by G, while G aims to produce realistic samples. The adversarial game involves the Jensen-Shannon divergence between synthetic and true sample distributions. InfoGAN introduces an additional latent code to learn disentangled representations. The training objective of InfoGAN involves maximizing mutual information between latent code c and generated sample x. Variational lower bound of mutual information is optimized using a weight coefficient \u03bb. Variational inference relies on the positivity of KL divergence. IB-GAN is introduced for disentangled representation learning, with a practical variational approximation proposed. Characteristics of IB-GAN are discussed in-depth. The weakness of InfoGAN in independent factor learning may stem from the lack of information constraint or compression mechanism for the representation. To address this, Information Bottleneck GAN (IB-GAN) is introduced, which maximizes mutual information while simultaneously constraining it. Parameters \u03bb and \u03b2 control the weight coefficients for the GAN loss and the upper-bound of mutual information. More details on these parameters are discussed in section 3.3. The optimization of IB-GAN involves regularizing the upper bound of mutual information with \u03b2, using a reconstructor model to approximate the generator marginal, and maximizing the lower-bound of mutual information between the generator and the code z. The upper-bound of generative mutual information in IB-GAN training involves choosing a proper approximation model for the generator marginal, which can impact the quality of synthesized samples. The algorithm requires specific hyperparameters and learning rates for optimization. The variational upper-bound on the mutual information term in IB-GAN training involves developing a new formulation based on deep-learning architecture and IB theory. It introduces a stochastic model that generates an intermediate representation, leading to a practical upper-bound on the generative mutual information. The IB-GAN architecture introduces a practical upper-bound on generative mutual information by leveraging an intermediate representation and KL divergence. The training involves maximizing the generator, representation encoder, variational reconstructor, and discriminator. The IB-GAN architecture, presented in FIG0 (a), connects to rate-distortion theory. Information Bottleneck theory is a generalization of rate-distortion theory, aiming to minimize distortion D without exceeding a certain rate R. In IB-GAN, z and r are treated as input and encoding, respectively, with D minimized by optimizing the variational reconstructor q \u03c6 (z|x(r)). The IB-GAN architecture connects to rate-distortion theory, aiming to minimize distortion D without exceeding a certain rate R. The disentanglement-promoting behavior of \u03b2-VAE is encouraged by the variational upper-bound of MI term. IB-GAN uses a noise input z fed into the representation encoder instead of the image x, leading to a different disentangling mechanism compared to \u03b2-VAEs. The disentangling mechanism of IB-GAN differs from \u03b2-VAEs, with the GAN loss acting as a secondary capacity regularizer. The GAN loss in IB-GAN controls the information compression level of z in its encoding x. This loss serves as a second rate constraint in addition to the first rate constraint in the rate-distortion theorem, promoting disentanglement behavior. The goal is to deliver the input source z through the noisy channel using compact encoding schemes for r and x. The efficient encoding schemes for r and x in IB-GAN aim to promote statistical independence and realistic image generation, respectively. Maximizing mutual information indirectly enhances the dependency between r and G(r). Hyperparameters are set with \u03b2 \u2208 [0, 1] and fixed \u03bb = 1. In IB-GAN, setting positive values for \u03bb and \u03b2 is possible. The focus is on the effect of \u03b2 \u2208 [0, 1.2] on IU(r, R(z)) while fixing \u03bb = 1. Model scores are obtained from 32 random seeds, with a peak score of (0.91, 0.78). The baseline scores, except InfoGAN, are referred to as BID17. The DCGAN with batch normalization is used as the base model for the generator and discriminator. The reconstructor shares the same frontend feature with the discriminator. More discussion on hyperparameter settings will be in the Appendix. The model is trained using RMSProp optimizer with a minibatch size of 64 and images are normalized to [-1, 1]. Architectural configurations for the generator, discriminator, reconstructor, and representation encoder are similar across experiments. Evaluation of representation disentanglement is challenging, with some proposed quantitative metrics based on synthetic datasets. More details on models and experimental settings are provided in the Appendix. In experiments, the approach was verified using different metrics on the dSprites dataset. Instance noises technique was adopted to improve the training stability of GAN models due to the simplicity of dSprites images. The intensity distribution of synthetic images was narrow, making it difficult for the generator to learn without added noises. The training stability of GAN models was improved using instance noises on the dSprites dataset. The KL variations for different factors of variations were observed, and the IB-GAN successfully learned all ground truth factors. Visual inspection of latent traversal with the IB-GAN model showed accurate learning of factors like positions, scales, and rotations. IB-GAN successfully learned all 5 ground truth factors from dSprites dataset - Y and X positions, scales, rotations, and shapes. Results show IB-GAN outperforms other baselines in disentanglement metrics. Qualitative evaluation reveals IB-GAN discovers human attributes like azimuth and hair color. Generated images are sharp. IB-GAN is a novel unsupervised GAN-based model that successfully disentangles attributes like scales, leg types, and azimuth of chairs. It incorporates an information capacity constraining term inspired by the IB theory and \u03b2-VAE, achieving state-of-the-art performance in disentangled representation learning. IB-GAN outperformed \u03b2-VAE and InfoGAN in disentangled representation learning, with higher quality samples on CelebA and 3D Chairs. Future work includes exploring extensions to discrete latent representation and incorporating ideas from \u03b2-VAE extensions. The architecture of IB-GAN is similar to \u03b2-VAE but avoids generating blurry images due to large \u03b2 values. \u03b2-VAE often produces blurry images with large \u03b2 values, while IB-GAN minimizes distortion by learning to generate images with a smaller rate. IB-GAN does not rely on probabilistic modeling assumptions like VAEs and inherits InfoGAN's benefits. One drawback is the introduction of an additional capacity control parameter \u03bb, which could impact convergence. Further investigation on the impact of fixing \u03bb = 1 in IB-GAN experiments is suggested for future work. The behavior of IB-GAN is discussed in relation to the parameter \u03b2, where a large \u03b2 value can lead to a loss of information in the generated samples. Maximizing the variational lower-bound has been utilized in various algorithms, such as BID2 and InfoGAN, to measure the complexity of learned representations. In this work, GILBO is introduced as a data independent measure for the complexity of learned representations in generative models. An upper-bound for generative MI is discovered based on the causal relationship of deep learning architecture, showing effectiveness in measuring disentanglement. The implementation of IB-GAN involves a stochastic representation encoder requiring the reparametrization trick for training. The representation can be embedded with an extra discrete code before entering the generator, affecting the reconstructor network. The IB-GAN model introduces a discrete representation by using a reconstructor network to predict the code c. The representation encoder learns a disentangled representation of r from the real data x by sampling z and inputting it to the encoder. Various extensions of \u03b2-VAE have been proposed in related work. The IB-GAN model introduces a discrete representation using a reconstructor network to predict the code c. Kim & Mnih (2018) and BID11 show that minimizing KL-divergence enforces factorization of the marginal encoder, promoting independence of learned representation. A high \u03b2 value can decrease the MI term too much, leading to worse reconstruction fidelity. Total correlation BID26 based regularization overcomes the reconstruction and disentanglement trade-off. These approaches could complement IB-GAN, as both involve the KL term. The hyperparameter \u03b2 in the IB-GAN objective controls the ratio of lower-bound I L (z, R(z)) and upper-bound I U (z, R(z)), affecting the balance between the two terms. The optimal balance point between the lower and upper bound term in IB-GAN is influenced by the hyperparameter \u03b2. When \u03b2 is properly set, both lower and upper-bound of mutual information increase smoothly, allowing the representation encoder to capture distinctive factors of the dataset. The encoder e \u03c8 (r|z) is slowly adapted to capture dataset factors, with KL-divergence increasing one by one for each attribute. Different values cap all variations, a key element in disentangled representation learning. The upper MI bound decreases exponentially as \u03b2 increases, affecting the representation encoding r without restrictions. The upper MI bound decreases exponentially as \u03b2 increases, affecting the representation encoding r without restrictions. The optimal disentanglement score is achieved when \u03b2 is in the range of [0.1, 0.35], with a score of 0.91 obtained at \u03b2 = 0.212. IB-GAN controls disentanglement with generative MI and varying \u03b2, discovering human attributes like azimuth, background color, hair color, skin color, smile, and gender. The upper MI bound decreases exponentially as \u03b2 increases, affecting the representation encoding r without restrictions. The optimal disentanglement score is achieved when \u03b2 is in the range of [0.1, 0.35], with a score of 0.91 obtained at \u03b2 = 0.212. IB-GAN controls disentanglement with generative MI and varying \u03b2, discovering human attributes like azimuth, background color, hair color, skin color, smile, and gender. Attributes captured by the best model with parameters \u03b2 = 0.2838, \u03bb = 1 are not seen in InfoGAN, demonstrating the usefulness of generative MI in IB-GAN. Generated images from IB-GAN are sharper and more realistic than those from \u03b2-VAE and its variants. Various datasets with different attributes and factors are used in the experiments. The hyperparameter settings used in experiments on datasets like dSprites, 3D Chairs, and CelebA are detailed in TAB2. It includes parameters for LR, iterations, RMSProp, noise levels, and model architectures for IB-GAN and InfoGAN."
}