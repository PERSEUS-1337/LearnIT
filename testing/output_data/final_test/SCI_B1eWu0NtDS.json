{
    "title": "B1eWu0NtDS",
    "content": "Convolutional neural networks (CNNs) have had a significant impact in various fields, but the theoretical understanding of CNN architecture design is still unclear. This work aims to quantify and rank the importance of neurons in CNNs, proposing two methods to incorporate neuron importance in the objective function. Neural networks have proven effective in various cognition tasks, such as image and speech recognition, machine translation, and reinforcement learning. CNNs excel in vision tasks due to their ability to capture visual information through convolution filters. While the effectiveness of CNNs is clear, the details of their architecture design and what makes them work remain uncertain. Experimental results suggest that network accuracy and representational capacity are linked to network depth. The depth of neural networks is correlated with accuracy and representational capacity. There is a debate on the relationship between network width and expressivity. The focus on network architecture often centers on filters, layers, and size, with concerns about overparametrization leading to heavy computational load and overfitting. Research aims to create smaller yet accurate networks by removing redundant units and designing lighter architectures. In research on network architecture, the focus is on creating smaller, accurate networks by removing redundant units and designing lighter architectures. This approach involves discerning between significant and insignificant features, with larger weights considered more important for learning tasks. The study aims to scrutinize individual filters and propose that not all units in the network are equally important for performing inference tasks. This suggests that CNNs learn features in a discriminative way, with some carrying more significance than others. The study aims to quantify the importance of features in CNNs by proposing a ranking method based on the Shapley value concept. This approach aims to differentiate between significant and insignificant features in the network, highlighting that not all units are equally important for inference tasks. The study introduces a ranking method based on the Shapley value concept to quantify the importance of features in CNNs. This method differentiates between significant and insignificant features, allowing for a more informed way of building effective models by focusing on the relevant features and discarding the less relevant ones. The study introduces a ranking method based on the Shapley value concept to quantify the importance of features in CNNs. This method differentiates between significant and insignificant features, allowing for a more informed way of building effective models by focusing on relevant features and discarding less relevant ones. The feature ranking of convolutional features provides interpretable information about the network, shedding light on black box models. The emergence of GPU implementability and regularization algorithms has enabled the use of larger architectures that train and generalize well. The trend towards larger neural networks contradicts research on interpretability and knowledge extraction. The method will be compared to existing ones in terms of compression ability and interpretability, focusing on neuron ranking. Early compression work focused on non-Bayesian approaches and non-structured pruning methods. Hardware-oriented structured pruning techniques have led to practical speed-ups. Bayesian methods using network weights' uncertainties have achieved impressive compression rates. The network weights' uncertainties have achieved impressive compression rates using various methods, but none directly optimize for extracting the importance of each neuron. Three lines of work have been done for interpretability of CNNs: visualization of neurons, probing trained CNNs for local explanations, and mapping semantic information. In the context of interpretability for CNNs, previous work has focused on visualizing neurons, probing for local explanations, and mapping semantic concepts. A new method is introduced to rank neurons based on their predictive utility using the game theoretical concept of Shapley value. This approach aims to provide a global view of a trained model by determining the importance of learned features. In the context of interpretability for CNNs, a new method ranks neurons based on their predictive utility using the game theoretical concept of Shapley value. This approach aims to provide a global view of a trained model by determining the importance of learned features through coalitional games. In the context of interpretability for CNNs, a new method ranks neurons based on their predictive utility using the game theoretical concept of Shapley value. This approach aims to provide a global view of a trained model by determining the importance of learned features through coalitional games. The value of a coalition in a coalitional game is given by a characteristic function that assigns payoffs to every subset of nodes, with the choice of characteristic function being crucial. For CNNs, the characteristic function chosen is accuracy on a validation set, allowing for the assessment of the importance of individual features based on the payoffs for each subset of nodes. The Shapley value concept evaluates each player's marginal contribution to coalitions in a fair way. It calculates the difference in value when a player joins a coalition compared to when they are not in it. This method helps determine the importance of features in CNNs by assigning payoffs to subsets of nodes based on accuracy. The Shapley value concept evaluates each player's marginal contribution to coalitions in a fair way by comparing the accuracy of the architecture before and after each node joins the coalition in a specific order represented by permutations. The Shapley value of a node is computed by comparing the accuracy of the architecture before and after adding the node, considering its marginal contributions for all permutations. The Shapley value is the averaged marginal contribution of the node, calculated based on permutations or sets. This method is a mathematically rigorous division scheme that satisfies normative criteria. The Shapley value is a fair payoff distribution measure that satisfies efficiency, symmetry, null player payoff, and linearity criteria. However, choosing a characteristic function that meets these criteria may not be feasible in practice. Despite this, the Shapley value provides a valid cost division that works well in practice. The Shapley value is a valid cost division method that works well in practice, but computing it for large networks is computationally infeasible due to its exponential time complexity. To address this, two solutions are proposed: computing the Shapley value for subsets no larger than a certain size, and using sampling to obtain an unbiased estimate of the optimal result. Our proposal aims to improve the speed of computing neuron rankings in neural networks by introducing importance switches in each layer. These switches are probability vectors that modify the forward pass in the network, allowing for efficient computation of neuron importance. Introducing importance switches in each layer of a neural network model can improve the speed of computing neuron rankings. These switches are probability vectors that modify the forward pass, allowing for efficient computation of neuron importance. The output probability under such networks with hidden layers for classification problems can be written as a softmax operation. The Dirichlet distribution is a natural choice to model the distribution over the switch, defining a probability distribution over a probability vector. Each switch is modeled as a vector of independent Dirichlet distributed random variables. The symmetric Dirichlet distribution is a special case where the same parameter is applied to each dimension. Setting \u03b1 0 < 1 concentrates the probability mass towards a few components, inducing a sparse probability vector. On the other hand, setting \u03b1 0 > 1 makes all components similar. The posterior over the switch is modeled as a Dirichlet distribution with asymmetric form, using variational parameters \u03c6 l to learn different probabilities for each element. The posterior distribution over the switch is defined by optimizing the variational parameters \u03c6 l to maximize the variational. The variational parameters \u03c6 l are optimized sequentially for each layer's importance switch, freezing weights to pre-trained values. Computing gradients involves the integral and KL divergence terms dependent on \u03c6 l . While KL divergence can be computed in closed form, the reparameterization trick is ineffective for the first term. In an attempt to find a reparameterization for a k-dimensional Dirichlet random variable, a weighted sum of Gamma random variables is used. However, this method does not detach the randomness from the parameters, leading to the need to sample from the posterior every time the variational parameters are updated. Existing methods suggest computing the gradients of the inverse CDF of the Gamma distribution during training to reduce gradient variance. The importance switch considered is typically less than 100s in length, where gradient variance does not significantly impact convergence speed. When training for the importance switch in each layer, the analytic mean of the Dirichlet random variable is used to estimate the integral. This approximation works well with low dimensional switches. The relationship between game-theoretic and probabilistic neuron ranking methods is discussed, where a vector of random variables describes neuron rankings for predictive distribution on test data. The predictive distribution over neuron rankings is used to obtain test data likelihood. The Shapley value is computed using an approximate predictive likelihood, selecting the label with the highest probability to measure accuracy. Both methods aim to maximize the likelihood by finding the best ranking. In this section, experimental results are presented for CNN features ranking using the Shapley value and importance switch methods. Tests were conducted on LeNet-5 with MNIST and FashionMNIST, and VGG-16 with CIFAR-10. The Shapley value is computed by removing subsets of features and testing the network on a validation set to determine accuracy. The computation of payoffs for a group of features involves computing the power set for layers up to 25 nodes. The number of nodes in the pretrained LeNet-5 architecture is limited to 10-20-100-25 to illustrate the proposed method. Different methods are used to compute marginal contributions for layers with a larger number of features. The importance switches are learned by loading the same trained model used to compute the Shapley value. The importance switches are trained per layer using the same model as the one used for computing the Shapley value. Training for 300 epochs is sufficient to identify important nodes. Comparison of ranks shows similarity in identifying important nodes between methods, especially in smaller layers. Top nodes are consistent in several cases, indicating the effectiveness of the approach. The comparison between importance switches and Shapley values in identifying important nodes shows agreement in smaller layers, with discrepancies in larger layers. Both methods highlight similar unimportant nodes in fc2, with common nodes found in fc1. The inexact computation of Shapley values may contribute to the differences observed. The text discusses rankings of filters using Shapley value and importance switches methods in a four-layer network. The aim is to better understand the learning process of convolutional neural networks by interpreting visual features through filter rankings. The comparison between the two methods shows agreement in smaller layers but discrepancies in larger layers, with common nodes found in fc1. The inexact computation of Shapley values may contribute to the differences observed. The text discusses the visualization of feature maps produced by the first convolution layer of filters, highlighting the importance of certain features in identifying specific parts of images. The ranking of features reveals that some nodes within each layer are less significant, leading to the possibility of network compression. The text discusses network compression experiments where neurons are pruned based on rankings, resulting in smaller architectures with good performance on LeNet-5 and VGG-16 models trained on MNIST and CIFAR-10 datasets. The compressed architecture has fewer parameters compared to other methods, showing promising results in reducing model size. The study demonstrates the effectiveness of neuron ranking in compressing LeNet-5 and VGG-16 models without compromising performance. The proposed method outperforms traditional magnitude pruning techniques, showcasing its potential for reducing model size while maintaining predictive accuracy. The proposed method focuses on the importance of neuron ranking in compressing CNN models without compromising performance. It suggests a new paradigm where channels are treated as whole units contributing directly to task generalization. The study introduces two methods for feature ranking in CNN networks, showing that different methods lead to similar results in identifying important nodes with confidence. The study introduces methods for ranking important nodes in CNN networks to build a slim architecture. Future research aims to quantify neuron importance for better understanding feature importance in CNNs."
}