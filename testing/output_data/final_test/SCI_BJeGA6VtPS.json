{
    "title": "BJeGA6VtPS",
    "content": "The opaqueness of large-scale neural networks allows for Trojan horse attacks, where adversaries embed malicious networks within benign ones. This attack is difficult to detect and computationally infeasible to uncover. It reveals a new direction in machine learning security by exploiting a previously unknown loophole. Trojan horse attacks can be activated by triggers to perform malicious activities in software and hardware circuits. These attacks take advantage of the complexity in the transport medium, making detection difficult. The complex architecture of modern neural networks allows for embedding unintended functionalities by adversaries, similar to software and hardware Trojan horses. An intruder could embed a person identification classifier in the object recognition network of autonomous vehicles, turning them into a secret mass surveillance force. This Trojan horse attack utilizes excess model capacity to learn a public and secret task simultaneously, with the secret task remaining undetectable without a hidden key. The model uses a secret permutation to hide a hidden task, making it undetectable without knowledge of the permutation. The decision problem to detect the secret functionality is NP-complete. Experimental validation on a ResNet50 network shows that the model can achieve the same performance on both intended and secret tasks without any increase in parameters. The attack on machine learning models involves using a Trojan trigger to manipulate model predictions covertly. This attack is difficult to prevent and can have serious consequences if undetected. The behavior of neural networks makes them susceptible to being used as a transport medium for such attacks. Trojan horse attacks on neural networks involve training a model to perform a benign task while secretly being able to switch to a malicious task when triggered. This can be achieved by shuffling model parameters using a secret permutation. The attack can also be executed by hard-wiring the permutation into hardware or packaging a separate model for the secret task inside a Trojan horse program. The concealment of a Trojan network in the parameters of a transport model is crucial to avoid suspicion. Embedding the Trojan network inside a transport model and obfuscating the loading process can make the attack appear benign. The framework allows Trojan networks to act as sleeper agents, triggering retroactively when a secret permutation is supplied. Using a pseudo-random number generator to generate a permutation from a fixed-length key reduces the detectability of the attack. This technique simplifies the problem of Trojan horse attacks on neural networks. The technique discussed in the current text chunk focuses on concealing a Trojan network inside another model by shuffling layer parameters. This approach simplifies the problem of Trojan horse attacks on neural networks. The text discusses concealing a TrojanNet within a transport network by shuffling parameters. The TrojanNet is trained for a secret task while the transport network is trained for a public task. Parameters are permuted using a secret key to switch between tasks. The text discusses training a network for person identification using permuted parameters. Different tasks can be trained with the same number of permutations, and task losses can be re-weighted. Selecting maximally de-correlated permutations is important when training against multiple tasks. To ensure distinctness between permuted models, a pseudo-random permutation generator is used to map keys to permutations. This reduces the footprint of the Trojan trigger and hides the secret model embedded in the network. The Trojan trigger's footprint is reduced by storing a small permutation or a human-memorizable password. A method of Trojan horse attack involves training a model on a secret task using multi-task learning, but it can be easily detected by evaluating the model's performance on suspected tasks. TrojanNet can bypass detection methods by using a permutation that the user is unaware of, making it difficult to evaluate the model's performance. The decision problem of finding a permuted model with a test loss below a threshold is shown to be NP-complete for regression and classification tasks. This complexity makes it computationally challenging to detect the presence of a hidden TrojanNet. The presence of a TrojanNet hidden within a network is computationally infeasible to detect. The decision problem for finding a permuted model with a test loss below a threshold is NP-complete for regression and classification tasks. The proof involves reductions from 3SAT variants. Theorem 2 introduces a different construction for detecting TrojanNets by reducing from the CYCLIC-ORDERING problem. The threshold L must be carefully chosen to avoid false positives. The value of L also impacts the difficulty of the EXISTS-PERM problem. It is crucial for L to be close to the optimal secret task loss to prevent false positives. To address the issue of ensuring independent random samples from similar keys in pseudo-random permutation generators, a cryptographic hash function like SHA-256 can be applied to the key before use. This helps create different permutations across layers, preventing high correlation or identical weight sharing schemes between layers. To prevent high correlation or identical weight sharing schemes between layers, a deterministic function F is applied to the input key at each layer transition. This ensures that subsequent layers share weights differently. Batch normalization in TrojanNet models requires storing batch normalization parameters for each valid key to handle different permutations. The design of TrojanNet models involves applying a deterministic function to input keys at each layer transition to prevent weight sharing schemes. Batch normalization parameters are stored for each valid key to handle permutations, allowing for easy discovery of hidden tasks. Non-parametric normalizers like layer normalization and group normalization can be used at test time without storing global statistics. Despite their similar performance, batch normalization is chosen for uniform comparison in experiments. TrojanNet stores parameters per valid key and can handle different output sizes for secret and public tasks. It uses pseudo-random permutations for training on multiple tasks and ensures the model is de-correlated from the public transport model. Experiments are conducted on CIFAR10 and CIFAR100 datasets to verify TrojanNet's capabilities. In experiments, various image classification datasets are used, including CIFAR10, CIFAR100, Street View House Numbers (SVHN), and German Traffic Sign Recognition Benchmark (GTSRB). Different combinations of pairwise tasks are tested, with a TrojanNet trained against all four tasks simultaneously. The method is implemented in PyTorch using ResNet50 as the base model architecture, referred to as TrojanResNet50 (TRN50). Additionally, a TrojanNet for face identification on the Labeled Faces in the Wild (LFW) dataset is trained within a transport network trained on the GTSRB dataset. TrojanNet variant TRN50 is trained on multiple tasks using torch.randperm() for pseudo-random permutation and Adam optimization with a learning rate of 0.001. Learning rate drops by 0.1 after 50% and 75% of training epochs. Results show that training on two tasks simultaneously yields similar test accuracy as training on each task individually. Tasks from CIFAR10, CIFAR100, SVHN, and GTSRB datasets are paired as public and private, with interchangeable results. Test accuracy of models trained on these datasets is shown in Table 1. The test accuracy of models trained on multiple tasks from CIFAR10, CIFAR100, SVHN, and GTSRB datasets is shown in Table 1. Results indicate that simultaneous training of tasks does not significantly affect classification accuracy, even when trained on all four tasks together. Experiments on group normalization and training classification and regression tasks simultaneously are discussed. Results show negligible impact on test accuracy when training a public network and TrojanNet for SVHN regression. TRN50 achieves low false positive rates on LFW and GTSRB tasks, with comparable accuracy to RN50 on GTSRB. A potential scenario of a Trojan horse attack involves embedding a person identification classifier in a traffic sign recognition network, turning a vehicle into a mobile spying camera. This attack was simulated by training a traffic sign recognition network on GTSRB and embedding a TrojanNet trained on LFW to classify inputs as a specific person. The target person was chosen based on the highest number of samples in the dataset. The RN50 and TRN50 networks were trained on LFW to achieve high test accuracy and low false positive rates. Both networks performed similarly on GTSRB with test accuracies of 97.8% and 97.0% respectively. The goal is to train the transport network to perform well on GTSRB while minimizing false positives and false negatives on LFW for a binary classification task. The min-cost matching algorithm can permute a network trained on a public task to a network for a secret task, achieving high test accuracy. Detecting a TrojanNet by evaluating test loss is NP-hard, but choosing a threshold L can control the false positive rate. Empirically determining an upper bound on L helps in detecting TrojanNets effectively. To achieve a low test error on secret tasks, a model can be trained using min-cost matching between public and secret task parameters. Quantizing weights for computation and then recovering full-precision weights during testing can lead to high accuracy on tasks like CIFAR10 and SVHN. Regardless of the public task dataset, the permuted model shows remarkably high accuracy. The permuted model achieves high accuracy on the dataset. Threshold-based detectors for TrojanNet on CIFAR10 may result in false positives. Selecting a tight threshold L is crucial. Training a network with multiple keys on the same task can result in TrojanNets behaving similarly to independent networks. Test performance of ensembling permuted networks can measure their degree of independence. Ensemble methods benefit from diversity of component models, measured by boost in performance. TRN50 trained on CIFAR10 and CIFAR100 with n keys for different K values. Compare ensemble with independently trained RN50 models and HashedNet for space efficiency. HashedNet compresses neural networks for space efficiency by applying a hash function to model parameters. When training TRN50 with K distinct keys, each permuted model has effective capacity of 1/K compared to the vanilla RN50 model. Ensemble of K hashed RN50 networks with compression rate 1/K results in HashedResNet50 (HRN50). Test accuracy of TRN50 ensemble, RN50, and HRN50 ensembles compared in Figure 2. Ensemble models like TRN50 and HRN50 show similar accuracy on datasets. Ensembling TRN50 networks provides a significant boost in accuracy compared to individual models. Parameter sharing via pseudo-random permutations is efficient in TRN50 models. TrojanNets show comparable test accuracy to independent models when de-correlated. TRN50 ensemble performs well with small K values but lags behind RN50 ensemble with higher K values due to lower model capacity. TrojanNets rely on excess model capacity for training on multiple tasks. TrojanNets rely on excess model capacity for training on multiple tasks, with larger models able to accommodate weight sharing with more tasks. A TrojanResNet18 (TRN18) ensemble was trained on CIFAR10 and CIFAR100, showing that larger models like TRN50 have more excess capacity to share among different permutations. TRN50 with up to 10 different keys had a relatively insignificant effect on individual models' accuracy, suggesting that TrojanNets may be effective for larger models. TrojanNets utilize excess model capacity for training on multiple tasks, with larger models like TRN50 able to share weight among different permutations efficiently. This approach may have applications beyond machine learning security. Adversarial examples are a widely studied security threat where attackers aim to change a model's prediction on a modified input with imperceptible changes. Privacy and security concerns in machine learning models have been highlighted in recent studies (al., 2017; Brendel et al., 2017; Ilyas et al., 2018). Attacks like model inversion have been successful against systems like Google Voice and Google Cloud Vision, compromising sensitive data. Differential privacy frameworks offer protection against privacy leakage by providing plausible deniability for all participants in the training set. The private model ensures plausible deniability for participants in the training set by adding noise to the training process. The Trojan horse attack scenario is introduced, highlighting the challenge of detection and prevention due to computational infeasibility. Strategies like Markov Chain Monte Carlo may not be efficient in reducing the search space for this attack. The number of permutations for a single convolutional layer of ResNet50 can be extremely large, making it computationally infeasible. The TrojanNet framework can be used for malicious purposes but also has potential for improving neural network security. The framework resembles symmetric key encryption and steganography, allowing for secure sharing of neural networks. The EXISTS-PERM decision problem is proven to be NP-complete in the appendix. The EXISTS-PERM decision problem with regression losses abs (z, y) = |z \u2212 y| and square (z, y) = (z \u2212 y) 2 is NP-complete, proven by reducing from the 1-IN-3SAT problem. Linear regression models are used to show NP-hardness, with the framework resembling symmetric key encryption and steganography for secure sharing of neural networks. The EXISTS-PERM decision problem with classification losses binary (z, y) = 1 z = y and logistic (z, y) = 1/(1 + exp(yz)) is NP-complete. The proof involves showing NP-hardness for a linear network h used in binary classification. The reduction utilizes a collection C of ordered triples to determine if a permutation exists satisfying certain conditions. Logistic loss properties are also discussed. TrojanNet is evaluated using group normalization as an alternative to batch normalization. Training accuracy for pairwise tasks in the RN50 model is shown in Table 5, with minimal impact on performance observed when network weights are shared between tasks. Accuracy is slightly affected when training all four tasks simultaneously."
}