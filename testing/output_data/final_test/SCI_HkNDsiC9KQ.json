{
    "title": "HkNDsiC9KQ",
    "content": "A major goal of unsupervised learning is to discover data representations useful for subsequent tasks without supervised labels. This work proposes meta-learning an unsupervised weight update rule for semi-supervised classification performance. The update rule is constrained to be a biologically-motivated, neuron-local function for generalization across different neural network architectures and datasets. The meta-learned unsupervised update rule generalizes to train networks with different widths, depths, and nonlinearities, as well as on data with randomly permuted input dimensions. It also extends from image datasets to text tasks, showing potential for unsupervised learning in situations where labeled data is scarce or unknown. Unsupervised representation learning algorithms often do not align well with the target task, focusing on objectives like generative model likelihood or reconstruction error. This limits their ability to linearly expose high-level data attributes and perform effectively in semi-supervised settings. However, these algorithms show promise for meta-learning applications, as they can produce useful representations for candidate tasks. In this work, a meta-learning approach is proposed to develop an unsupervised update rule that optimizes the utility of representations generated from unlabeled data for later supervised tasks. This method treats unsupervised representation learning as a transfer learning problem, focusing on creating a transferable learning rule that generalizes across data domains and neural network architectures. The goal is to optimize the learning rule for generating representations for various tasks, with a current focus on semi-supervised classification. Unsupervised learning techniques like autoencoders and generative adversarial networks are used to create useful latent representations of datasets. These methods differ from manual approaches by learning algorithms that generate representations based on a meta-objective, rather than predefined training algorithms or loss functions. Autoencoders compress data and optimize reconstruction loss, while generative adversarial networks use a min-max optimization approach for feature learning. Recent work has shown that unsupervised feature learning can be achieved through min-max optimization, leading to useful features for few-shot learning. Various techniques like self-supervision, domain knowledge, and feature space design are used to define 'supervised' losses for unsupervised learning. Techniques include unscrambling jigsaw-like crops, using temporal ordering from videos, and clustering methods. Bojanowski and Joulin (2017) introduce a scalable clustering technique based on predicting noise. Other methods by Schmidhuber (1992), Hochreiter and Schmidhuber (1999), and Olshausen and Field (1997) focus on properties of latent representations like predictability, complexity, independence, and sparsity. Meta-learning involves two levels of learning: an inner loop for learning and an outer loop for optimizing meta-parameters. Meta-training adjusts meta-parameters to improve performance on a meta-objective in the inner loop. Meta-learning approaches involve adjusting meta-parameters for optimal performance on a meta-objective in the inner loop. Early work by Schmidhuber (1987) and Bengio et al. (1990; 1992) explores various meta-learning algorithms. Runarsson and Jonsson (2000) meta-learn supervised learning rules, while others focus on few-shot learning without utilizing unlabeled data. Ren et al. (2018) make use of both labeled and unlabeled data in their meta-learning approach. Meta-learning approaches involve adjusting meta-parameters for optimal performance on a meta-objective in the inner loop. Some approaches utilize both labeled and unlabeled data, while others focus on few-shot learning without unlabeled data. Hsu et al. (2018) use a task created with no supervision to train few-shot detectors, and Garg (2018) applies meta-learning for unsupervised learning, primarily in clustering with a small number of meta-parameters. The process involves iteratively applying the UnsupervisedUpdate to a base model during metatraining, where the UnsupervisedUpdate is updated by gradient descent on the MetaObjective. The goal is to modify the base model to achieve a top layer representation that performs well at few-shot learning. The UnsupervisedUpdate method is used to train the base model for few-shot learning. Unlike backprop, backward weights are decoupled from forward weights, and there is no explicit error signal. A meta-learned MLP injects a learning signal at each layer and for each neuron. Weight updates depend on the hidden state of pre-and postsynaptic neurons. A survey of previous work in meta-learning is presented for comparison. This approach is the first to tackle the problem of meta-learning. The UnsupervisedUpdate method trains the base model for few-shot learning using a meta-learned MLP. It is the first approach to tackle unsupervised representation learning in meta-learning, generalizing across input data modalities, datasets, permutation of input dimensions, and neural network architectures. The base model, a multilayer perceptron (MLP) with parameters \u03c6 t, is trained in the inner loop of the meta-learning process through iterative application of a learned update rule. In standard supervised learning, the 'learned' optimizer is stochastic gradient descent (SGD) with a supervised loss function associated with the model. The parameters of the base model are updated iteratively using SGD. The update rule can be written as \u03c6 t+1 = SupervisedUpdate(\u03c6 t , x t , y t ; \u03b8), where \u03b8 are the meta-parameters of the optimizer. In this work, the learned update is a parametric function that does not depend on label information, \u03c6 t+1 = UnsupervisedUpdate(\u03c6 t , x t ; \u03b8), encompassing many unsupervised learning algorithms. The update rule in unsupervised learning algorithms involves training meta-parameters, including neural network weights, through SGD on the MetaObjective. The model consists of the base model, UnsupervisedUpdate, and MetaObjective components. The meta-learned UnsupervisedUpdate parameters can be found in the Appendix. The base model for UnsupervisedUpdate includes a fully connected MLP with batch normalization and ReLU nonlinearities. The model aims to generalize across different network architectures by designing a neuron-local update rule. The parameters include weights and biases for each layer, with corresponding weights for the backward pass. The UnsupervisedUpdate model incorporates a neuron-local update rule, where each neuron has an associated MLP called an update network. These networks share meta-parameters and use feedforward activations, feedback weights, and error signals as inputs to calculate weight updates. The UnsupervisedUpdate model utilizes neuron-specific update networks with shared meta-parameters to calculate weight updates based on feedforward activations, feedback weights, and error signals. During unsupervised training, statistics of unit activation are accumulated across examples in each training minibatch, and error signals are generated by the corresponding update network for each unit. These error signals are then propagated backward using learned 'backward weights' instead of the transpose of the forward weights. The UnsupervisedUpdate model uses neuron-specific update networks with shared meta-parameters to calculate weight updates based on feedforward activations, feedback weights, and error signals. Weight updates are determined by pre-and post-synaptic signals generated using per-neuron update networks. The meta-objective in this work is based on fitting a linear regression to labeled examples with a small number of data points to encourage generalization of features. The meta-objective involves fitting a linear regression on one minibatch of data points and evaluating classification performance on another minibatch. Features are extracted from the base model on the data, and cosine distance is used for stability. The inner loop computation is done without labels, and SGD is chosen for meta-optimization due to its superior convergence properties in high dimensions. This meta-objective is only used during meta-training and not during the application of the learned update rule. To improve stability and reduce computational cost, gradients are approximated via truncated backprop through time. Design choices like batch norm and restricting the norm of the UnsupervisedUpdate update step were crucial for stability and convergence in meta-learning. Generalization in the learned optimizer comes from the form of the UnsupervisedUpdate and the meta-training distribution, which includes datasets and base model architectures like CIFAR10 and subsets of classes from Imagenet. Increased training dataset variation improves meta-optimization process. Input data restricted to 16x16 pixels during meta-training. Evaluation includes MNIST, Fashion MNIST, IMDB, and Imagenet classes. Base model architecture sampled with 2-5 layers and 64 to 512 units per layer. Inputs permuted along feature dimension for UnsupervisedUpdate to learn permutation invariant learning rule. Focus on learning a learning algorithm rather than fixed feature extractors. The learning task is made harder by using fixed feature extractors that generalize across tasks. Dataset variation is increased with shifts, rotations, and noise. Augmentation coefficients are added as regression targets for the meta-objective. Models are implemented in distributed TensorFlow BID16 with training taking approximately 8 days. Training involves 512 workers performing partial unrolls of the inner loop UnsupervisedUpdate asynchronously. The text discusses limitations of existing unsupervised and meta learning methods, the meta-training and generalization properties of a learned optimizer, and visualizing how the learned update rule works. It also demonstrates the negative consequences of objective function mismatch in unsupervised learning algorithms by training a variational autoencoder on CIFAR10. Despite improving the VAE objective, classification accuracy decreases sharply later in training, highlighting the reduced generalization from learning transferable features rather than an update algorithm. Training a prototypical network primarily learns transferrable features, and input shuffling significantly hampers performance. Results show that optimizing a variational auto-encoder hurts few-shot accuracy over time. Prototypical networks transfer features rather than a learning algorithm, performing poorly without consistent data structure. Performance on a MiniImagenet task is greatly reduced when permuting inputs, while our performance remains invariant to pixel permutation. The training loss continues to decrease after 200 hours, indicating effective learning techniques. Evaluation loss decreases on image datasets like MNIST and Fashion Mnist, but meta-overfitting occurs on different domain datasets like IMDB sentiment prediction. Meta-parameters for UnsupervisedUpdate are based on 200 hours of meta-training. The goal is to learn a transferrable learning algorithm. The UnsupervisedUpdate algorithm, developed after 200 hours of meta-training, aims to create a general-purpose unsupervised representation learning algorithm that can generalize across various scenarios. Performance comparisons show that the learned UnsupervisedUpdate outperforms variational autoencoders, supervised learning, and random initialization with a trained readout layer on few-shot classification tasks. The algorithm also demonstrates generalization to unseen datasets. The UnsupervisedUpdate algorithm, developed after 200 hours of meta-training, aims to create a general-purpose unsupervised representation learning algorithm that can generalize across various scenarios. The learned update rule produces representations suitable for few-shot classification and outperforms fully supervised learning. Performance drops due to domain mismatch later in meta-training. The algorithm is tested on a binary text classification dataset, IMDB movie reviews BID15. The IMDB movie reviews BID15 dataset is used for binary text classification, encoded with a bag of words using 1K words. A model trained for 30 hours shows improvement over random initialization, but longer training leads to poor performance due to \"meta-overfitting\" to the image domain. Despite low absolute performance, the transfer of learned rules from images to text is considered exciting. The learned optimizer generalizes well to deeper and larger networks, with results compared at different training stages. The learned UnsupervisedUpdate generalizes well to deeper and larger networks with different activation functions. Despite training only on ReLU activations, it can improve on random initializations for various activation functions like leaky ReLU and Swish. Our learned UnsupervisedUpdate optimizer shows improved performance on various activation functions, including leaky ReLU and Swish, with little decrease in performance. It optimizes without using base model gradients, achieving double the performance of random initialization. Analysis of first layer filters during meta-training reveals evolving features, from coarse to more local and interesting ones. During meta-training, our algorithm learns to manipulate and separate data in an unsupervised manner. The variance in the embedding space is mostly influenced by a few dimensions. Comparing with MNIST, where variance is spread out over more principal components due to the generative process having more latent dimensions. The UnsupervisedUpdate rule manipulates data during meta-training without labels. It transforms low frequency features into higher frequency, spatially localized features on CIFAR10. The learned representations can separate data classes without labels, as shown in the visualization. In this work, the authors meta-learn an unsupervised representation learning update rule using principal components analysis (PCA) on learned representations. The update rule can train models of varying widths, depths, and activation functions, showing performance that matches or exceeds existing unsupervised learning on held out tasks. This demonstrates an application of meta-learning for learning complex optimization tasks where no objective is explicitly defined. The authors meta-learn an unsupervised learning algorithm using a synaptic learning rule. The meta-training procedure involves updating meta-parameters via a meta-optimizer (SGD) and computing gradients of the MetaObjective through backpropagation. UnsupervisedUpdate updates base model parameters using unlabeled data, involving forward and backward passes through the model. The base model is a fully connected network generating hidden states for each layer, with the backward pass using an error signal from the layer above. The weight updates are computed using a convolutional network with an error signal from the layer above. Training recurrent systems can be challenging due to chaos, requiring techniques like gradient clipping and small learning rates. Additional techniques are needed for stable convergence when training with truncated backpropagation. The policy in meta-optimization constantly changes the distribution of states reached by the optimizer, leading to non-i.i.d training. To address this, a large number of workers are trained in parallel to maintain a diverse set of states for gradient computation. Truncation steps and unsupervised training steps are sampled to reduce bias, with a focus on stabilizing the inner loop step size. The learning rate's impact on optimization stability was studied in BID22 and Maclaurin et al. (2015) showed that increasing learning rates lead to chaotic gradients. Unconstrained learning rates can cause rapid growth into a chaotic regime. Batch norm is useful for addressing these issues, especially in multi-layer perceptron training where precise weight initialization is crucial. Applying a learned optimizer early in meta-training can lead to high variance weights in the base model, which batch norm helps to resolve. In distributed Tensorflow BID16, a cluster of 512 workers computes gradients asynchronously for meta-objective training. Each worker trains on a task by sampling datasets, architectures, and training steps. Gradients are computed and sent to a parameter server for updating \u03b8 with asynchronous SGD. Staleness of gradients is reduced by batching them as workers complete unrolls, improving compute efficiency. The training process in distributed Tensorflow BID16 involves 512 workers computing gradients asynchronously for meta-objective training. Gradients are sent to a parameter server for updating \u03b8 with asynchronous SGD, reducing gradient staleness by batching them as workers complete unrolls. The training occurs over \u223c8 days with \u223c200 thousand updates to \u03b8 using multi-core CPUs instead of GPUs. The base model and learned optimizer details are described, with a focus on the inner loop and meta-training procedure. The system's design goals and future work are also discussed. The space of possible architectures is vast, with future work focusing on simplifying and enhancing abstractions around algorithmic components. An open-source implementation of UnsupervisedUpdate can be found on GitHub. The inner loop computation involves iterative application of UnsupervisedUpdate on a Base Model parameterized by \u03c6, consisting of forward weights, biases, and backward weights. This computation includes a forward pass on unlabeled data, pre-and post-activations on each layer, and weight updates. The next set of forward weights, biases, and backward weights are then computed using an SGD-like update. In our work, weights, biases, and backward weights are computed using an SGD-like update with a decay term. The weights and biases are set to an exponential moving average of the computed terms. We use \u03bb \u03c6lr = 3e \u2212 4. \u2206W l , \u2206V l , \u2206b l are computed via meta-learned functions. The base model is an L layer multi-layer perception with batch norm, and \u03c6 represents its parameters. N 1 .. N L are the sizes of the layers, and N 0 is the size of the input data. The MetaObjective is defined as a few shot linear regression, with the computation involving the base model converting inputs to embeddings, centering, and normalizing prediction targets before solving for the linear regression. The MetaObjective involves few-shot linear regression with the base model converting inputs to embeddings, centering, and normalizing prediction targets before solving for the linear regression weights in closed form. The learned update rule is parameterized by \u03b8, shared across all instantiations of the unsupervised learning rule to generalize across different network architectures. The computation in different network architectures involves forward and backward passes to update weights and signals. Unlike traditional backpropagation, a learned top-down signal is used instead of a scalar error signal for optimization. In this work, a neural network architecture called TopD is used with a learned top-down signal for error propagation. The error is structured similarly to backpropagation, with contributions at every layer and separate weight matrices for error propagation. The signal is moved down the network using a backward weight matrix, with separate weights that are updated along with the forward weights. The architecture called TopD uses a learned top-down signal for error propagation, with separate weight matrices for error propagation. The backward weight matrix moves the signal down the network, with weights updated along with the forward weights. The internal vectors are computed via a neural network, and weight updates are a mixture of low rank readouts from different layers. The final update in the TopD architecture involves normalizing mixed weights from previous updates. Both forward and backward weights are updated using the same rule parameters. A low rank readout function, LowRR, is defined to output a single lower rank tensor based on the state of pre-and post-synaptic neurons. This allows for adjustment of weights based on neuron activity. Each contribution to the weight update is represented as a sequence of planes, denoted as \u2206W. The TopD architecture involves normalizing mixed weights from previous updates. Weight update planes are linearly summed with coefficients generated to prevent pathologies during training. Additional weight update planes aid in decorrelating units and receptive fields. Post-processing steps prevent cheating by the optimizer and instability. The TopD architecture involves normalizing mixed weights from previous updates to prevent pathologies during training. Biases are updated with constraints to avoid pushing units into the linear regime. The update is normalized via the second moment and ComputeDeltaWeight function handles forward and backward weight updates and bias updates. The TopD architecture involves 1D convolution operators ConvBatch and ConvUnit, with S as hidden units size and K as kernel size. Reshaping adds a dimension to x L, followed by batch dimension convolution with batch norm and ReLU. Unit convolutions are then performed to rewrite the batch dimension and pull information from nearby elements.\u03bb topdeltasize is set to 64. The TopD architecture involves 1D convolution operators ConvBatch and ConvUnit, with S as hidden units size and K as kernel size. Reshaping adds a dimension to x L, followed by batch dimension convolution with batch norm and ReLU. Unit convolutions are then performed to rewrite the batch dimension and pull information from nearby elements.\u03bb topdeltasize is set to 64. Next, a series of 1D convolutions are performed over the batch dimension for more compute capacity. Finally, the representations are converted to the desired dimensions and output. ComputeH (\u00b7; \u03b8 computeH ) = m 11. Training was done on a data distribution consisting of tasks sampled uniformly over various datasets, including a glyph dataset of 14x14 black and white images of alphabet characters. The dataset used for training consists of alphabet characters and various classification problems sampled randomly, as well as specific types of images like letters, math symbols, and currency symbols. Additional augmentation techniques such as random rotations and shifts were applied to half of the random sampling and all specialized selections. The dataset also includes Cifar10 and imagenet images resized to 16x16 for computational reasons, with additional augmentation applied with some probability. We apply additional augmentation techniques to the dataset, including per task and per example dropout masks, permutations, and random shifts. Adam is used as the meta-optimizer with a specific learning rate schedule. Gradient clipping is applied, and the meta-objective is computed by averaging 5 evaluations of linear regression with a ridge penalty of 0.1. Truncated gradients are computed by sampling the number of unrolled applications of the UnsupervisedUpdate uniformly. During meta-training, the number of unrolled applications of UnsupervisedUpdate is initially sampled uniformly from [2, 4] and gradually increased to [8, 15] over 50k steps for improved speed and stability. The number of truncated steps is sampled from a shifted normal distribution to mimic the expected distribution of training steps across workers. The standard deviation is slowly increased from 20 to 20k steps over 5000 steps to enhance stability and training speed. Each experimental figure documents the details of the VAE with 3 layers used in the study. The VAE used in the study consists of 3 layers, size 128, with ReLU activations and batch norm. A projection to mean and log std of size 32 is learned, followed by sampling and decoding back to images. A quantized normal distribution is used as a posterior. Training is done with Adam at a learning rate of 1e-4. Performance is evaluated on the labeled training set instead of a validation set. The architecture includes 4 layers, size 128 units, and a 32 layer embedding for all models. Training steps are selected at 100k for the VAE and 3k for the learned optimizer. The supervised learning baseline has an additional layer for outputting log probabilities and is trained with cross entropy loss. For the IMDB experiments, the top 1K words were tokenized and selected, with encoding as 1 for presence and 0 for absence. A 4-layer, 128 hidden unit MLP with an additional layer outputting log probabilities was used. Training was done with Adam at a learning rate of 3e-3, and the test set performance plateaued over 10k steps. Having a true validation set would reduce labeled data availability, so the test set was used to aid in performance. The study utilized a 4-layer, 128 hidden unit MLP with an additional layer outputting a 32-dimensional embedding. Prototypical networks were trained on intact or shuffled mini-Imagenet images to demonstrate the inductive bias of meta-learning. The base network used the same fully connected architecture as the paper, with 3 layers, size 128, ReLU activations, and batch normalization. The study swapped the convolutional architecture with a fully connected one due to tied weights not making sense with shuffled pixels."
}