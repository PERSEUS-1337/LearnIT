{
    "title": "SJVmjjR9FX",
    "content": "In this paper, a variational framework for Bayesian phylogenetic analysis is proposed as an alternative to Markov chain Monte Carlo methods. The approach uses a subsplit Bayesian network to approximate the true posterior and train the variational approximation via stochastic gradient ascent. This structured variational approximation provides comparable posterior estimation to MCMC but with less computation due to a more efficient tree exploration mechanism enabled by variational inference. Bayesian phylogenetic inference is essential in evolutionary biology, providing ways to assess phylogenetic uncertainty and estimate parameters of interest. Variational inference offers a more efficient tree exploration mechanism for posterior approximation, enabling further statistical analysis like marginal likelihood estimation. Experiments show the effectiveness of these methods on synthetic and real data problems. Bayesian phylogenetic inference involves complex substitution models and random-walk Markov chain Monte Carlo approaches for tree exploration. However, the random-walk algorithm faces obstacles due to the vast number of possible trees, leading to the need for major modifications in tree proposals. Bayesian phylogenetic inference involves random-walk Markov chain Monte Carlo approaches for tree exploration, but faces challenges due to the vast number of possible trees. Major modifications in tree proposals are needed, restricting movement to local modifications. Variational inference is gaining popularity as an alternative method for Bayesian analysis, selecting the best candidate from tractable distributions to minimize statistical distance to the target posterior. Variational inference (VI) is a faster and scalable method for Bayesian analysis, using optimization to minimize statistical distance to the target posterior, often the KL divergence. VI can introduce bias if the variational distribution is not flexible enough, requiring appropriate tractable distributions and efficient training. Recent advancements in subsplit Bayesian networks (SBNs) have provided flexible distributions on tree topologies, enabling variational formulations for Bayesian phylogenetic inference. In this paper, a general variational inference framework for Bayesian phylogenetics is developed using subsplit Bayesian networks (SBNs) on tree topologies. SBNs offer flexible variational approximations for phylogenetic trees with branch lengths, utilizing unbiased gradient estimators for efficient stochastic gradient ascent. The complexity of variational parameterization for branch length distributions is reduced by leveraging local structure similarities among trees, with an extension to capture between-tree variation effectively demonstrated. In this paper, a variational inference framework for Bayesian phylogenetics is developed using subsplit Bayesian networks (SBNs) on tree topologies. SBNs provide flexible approximations for phylogenetic trees with branch lengths, reducing complexity by leveraging local structure similarities among trees and effectively capturing between-tree variation. The methods are demonstrated on synthetic and real data Bayesian phylogenetic inference problems. The phylogenetic likelihood for each site can be efficiently evaluated using the pruning algorithm, also known as the sum-product algorithm in probabilistic graphical models. This method assumes identical distribution and independent evolution of different sites, with a proper prior distribution imposed on tree topologies and branch lengths. The phylogenetic posterior p(\u03c4, q|Y ) is proportional to the joint density DISPLAYFORM3 with density p(\u03c4, q) imposed on tree topologies and branch lengths. Subsplit Bayesian networks provide flexible distributions on tree topologies, with nodes representing subsplit or singleton clade values. A subsplit (W, Z) of a clade X is an ordered pair of disjoint subclades of X such that W \u222a Z = X and W Z. Subsplit Bayesian networks represent tree topologies with nodes as subsplit or singleton clade values. The SBN tree probability is determined by the subsplit decomposition of a rooted tree. The Bayesian network formulation of SBNs offers flexibility and normalization in distributions. The SBN framework generalizes to unrooted trees in phylogenetics, viewing them as rooted trees with unobserved roots. Model complexity is reduced by sharing CPTs for parent-child subsplit pairs across the SBN network, similar to weight sharing in convolutional networks for identifying conditional splitting patterns of phylogenetic trees. The SBN framework provides flexible tree topology distributions for variational inference in phylogenetics. It involves using approximate distributions over tree topologies and branch lengths, combining them to minimize KL divergence and maximize the evidence lower bound (ELBO). The ELBO is maximized by averaging over multiple samples, leading to tighter lower bounds as the number of samples increases. In SBNs, CPTs are associated with all possible parent-child subsplit pairs, requiring a large number of parameters in theory but manageable in practice with a sufficient subsplit support. In this paper, the focus is on the variational approach for finding the support of CPTs, with a mention of a bootstrap-based approach for estimating CPT support. The set of root subsplits is denoted as Sr and the set of parent-child subsplit pairs as Sch|pa. CPTs are defined using specific equations, and the Log-normal distribution is used as a variational approximation for branch lengths. The paper focuses on using a Log-normal distribution as a variational approximation for branch lengths in phylogenetic models. Instead of parameterizing each edge individually, an amortized set of parameters is used for shared local structures among trees, such as splits. Each edge corresponds to a split, and parameters \u00b5(\u00b7, \u00b7), \u03c3(\u00b7, \u00b7) are assigned for each split in Sr. A simple independent approximation is used for branch lengths in phylogenetic trees. The paper proposes a Log-normal distribution as a variational approximation for branch lengths in phylogenetic models. It uses a simple independent model for branch lengths in trees, but suggests a more sophisticated parameterization to capture between-tree variation. This involves additional local structure associated with each edge, allowing for tree-dependent terms in the variational parameters. The paper introduces a Log-normal distribution as a variational approximation for branch lengths in phylogenetic models, incorporating additional parameters for primary subsplit pairs to capture between-tree variation. This structured parameterization enables joint learning across tree topologies and is optimized using stochastic gradient ascent. In practice, the lower bound is maximized via stochastic gradient ascent (SGA). Variance reduction techniques like control variate and reparameterization trick are applied to improve gradient estimators for latent variables. A stable gradient estimator based on an alternative variational objective is also considered. BID29 propose a localized learning signal strategy to reduce variance in gradient estimation. The VIMCO estimator utilizes independence between samples and regularity of learning signal to estimate gradients. The reparameterization trick is used for continuous latent variables like branch lengths. The gradient of the lower bound with respect to parameters is normalized. The RWS estimator is a multi-sample generalization of the wake-sleep algorithm, providing gradients for optimizing the variational approximation by minimizing the reversed KL divergence. It uses an importance sampling estimator with normalized importance weights to compute the gradient of the objective. The RWS estimator, similar to the VIMCO estimator, provides gradients for branch lengths. Equation 8 with the reparameterization trick is more effective for faster convergence. Stochastic gradient estimators can be used with optimization methods like SGA or Adam BID19. Algorithm 1 in Appendix B outlines a variational Bayesian phylogenetic inference approach. The variational framework is evaluated for phylogenetic tree inference using a simple SBN structure. The VIMCO and RWS estimators are compared for phylogenetic tree topology variational distribution. CPT supports are estimated from maximum likelihood phylogenetic bootstrap trees. Different variational parameterizations for branch length distributions are tested, with Adam and AMSGrad used for stochastic gradient ascent. KL divergences are reported over the collection of phylogenetic tree structures. The study compares VIMCO and RWS estimators for phylogenetic tree topology variational distribution. KL divergences are calculated over a collection of phylogenetic tree structures to assess the quality of approximation. In experiments on simulated data, a target distribution is generated using symmetric Dirichlet distributions. The target distribution becomes more diffuse as the concentration parameter increases. In a study comparing VIMCO and RWS estimators for phylogenetic tree topology variational distribution, lower bounds are optimized based on 20 and 50 samples. The empirical performance of different methods is shown in FIG1, with SBNs demonstrating expressive power in phylogenetic tree probability estimations. VIMCO performs better with more samples, while RWS learns slightly faster initially. The regularization term in the lower bounds benefits the overall performance. The regularization term in the lower bounds benefits the overall performance of variational approximation methods like VIMCO and RWS in estimating phylogenetic tree posteriors. VIMCO slightly underestimates trees in high-probability areas due to regularization, while RWS provides better approximations in high-probability areas but underestimates trees in low-probability areas. More samples are expected to alleviate biases in both approaches. The study focuses on variational Bayesian phylogenetic inference algorithms' performance in estimating unrooted phylogenetic tree posteriors on real datasets. Different parameterizations for branch length distributions are considered, including split-based and primary subsplit pairs (PSP). Ground truth posterior is derived from a long MCMC run for comparison. The study evaluates variational Bayesian phylogenetic inference algorithms' performance in estimating unrooted phylogenetic tree posteriors using different branch length distributions. A modified lower bound with an inverse temperature schedule is utilized, and Adam with learning rate 0.001 is employed for training variational approximations. Results on KL divergence to ground truth on DS1 are shown, indicating the effectiveness of the methods. The performance of variational Bayesian phylogenetic inference algorithms improves significantly with an increase in the number of samples. Using PSP for variational parameterization enables more flexible branch length distributions across trees, making the learning task easier. Comparison to MrBayes 3.2.5 BID34 shows that VBPI has efficient learning capabilities. VBPI methods, especially those with PSP, outperform MCMC by quickly arriving at good tree topology approximations with fewer computations. The variational approximations from VBPI can be used for phylogenetic inference through importance sampling. Comparison with the GSS algorithm shows VBPI using VIMCO with 20 samples and PSP is effective in estimating the marginal likelihood of trees. The VBPI method with PSP outperforms MCMC by quickly obtaining accurate tree topology approximations with fewer computations. VBPI using VIMCO with 20 samples and PSP is effective in estimating the marginal likelihood of trees. Power posteriors are used with 1,000,000 MCMC iterations, sampling every 1000 iterations, with better approximations leading to lower variance. VBPI with 1000 samples is competitive with SS using 100000 samples, providing more reproducible and reliable estimates with less variance. The extra flexibility of PSP reduces the need for a larger number of samples in the training objective, achieving high-quality variational approximations. VBPI is a variational framework for Bayesian phylogenetic inference that combines subsplit Bayesian networks and efficient parameterizations for branch length distributions. It offers guided exploration in tree space, competitive performance to MCMC methods with less computation, and can be used for marginal likelihood estimation for model comparison. Promising numerical results demonstrate its effectiveness and efficiency on real data problems. VBPI in Bayesian phylogenetic inference addresses challenges in support estimation of CPTs with diffuse posteriors. The SBN parameterization factorizes uncertainty in tree topologies, offering advantages over classical MCMC approaches. Future work includes constructing flexible branch length distributions, investigating support estimation in different data regimes, and developing efficient training algorithms for variational inference on structured latent variables. In this section, the gradient for multi-sample objectives is derived for variational inference on discrete/structured latent variables. An importance sampling procedure is detailed for marginal likelihood estimation in phylogenetic inference using VBPI approximations. Accurate approximations to posterior branch lengths are provided, allowing for estimation of marginal likelihood for each tree \u03c4 covered by subsplit support. In phylogenetic inference, importance sampling is used to estimate the marginal likelihood of \u03c4 and the data. A Monte Carlo estimate is obtained using K = 1000 samples, which can serve as a lower bound for Bayesian model selection with increasing tightness as K increases."
}