{
    "title": "Syl3_2JCZ",
    "content": "Working memory relies on neural activities to maintain stable representations of external stimuli. Prior research suggests that if neural dynamics are in the 'null space' of representation, information can be retained for longer periods. However, the mechanisms through which biological networks self-organize to learn memory function remain unclear. Biologically plausible synaptic plasticity rules enable networks to learn memory function by modifying connectivity matrix. Networks can form memory representations with only 10% plastic synapses, are robust to noise, and can represent multiple stimuli. Working memory relies on retaining external stimuli representations. Elevated firing rates in prefrontal cortex during delay period are neural correlates of working memory. Perturbations to delay period activities affect subsequent report of remembered stimuli. The prefrontal cortex shows elevated firing rates during the delay period, representing working memory. Neural activities have time-varying dynamics, retaining information for seconds. A synaptic plasticity mechanism overcomes fine-tuning issues in neural networks, enabling stable representations. The FEVER model matches monkey prefrontal cortex dynamics during working memory tasks but requires fine-tuned connectivity for stable representations. Previous work suggests Hebbian learning for connectivity, but it is unclear how synaptic plasticity can maintain functional working memory networks. This study identifies biologically plausible synaptic plasticity rules that can solve the fine-tuning problem without assuming 'tight frame' representations. Our plasticity rules dynamically adjust connectivity to maintain persistent representations of stimuli in parametric working memory tasks, allowing for the retention of information over time. This addresses the challenge of remembering continuous values across different variables or dimensions. In the oculomotor delayed response task, subjects remember target location during a delay period. Experiments show networks using plasticity rules can store information about multiple stimuli, work with only a fraction of tuned synapses, and are robust to synaptic noise. The networks improve over time with multiple stimuli and work within densely or sparsely connected networks. The network model uses positive rectifying activation functions and standard linear dynamics. The network's firing rates are determined by internal states and a rectifying function. After receiving an external stimulus, the network's representation of the stimulus is calculated using weighted firing rates. The synaptic weights are updated to minimize changes in the stimulus representation, with a focus on the biological plausibility of this plasticity rule. The network model utilizes positive rectifying activation functions and standard linear dynamics. The performance of working memory networks was evaluated by assessing how well they could store information about a scalar stimulus value. The networks, with 100 neurons and all-to-all connectivity, were compared to random networks without plastic synapses. The study focused on quantifying the fraction of stimulus retained over 3 seconds, simulating the dynamical evolution of the representation. The source code and scripts for reproducing the experiments are available for evaluation. The plasticity rule enabled random networks to quickly become effective working memory systems by reorganizing connectivity, maintaining a constant representation after initial decay. This success was not limited to fortuitous random initialization, as shown by the retention of stimulus over time. The study quantified stimulus retention in networks with different initializations. FEVER networks showed perfect retention, while models with plastic synapses performed almost as well but required self-organization. Random constant synapse networks quickly lost information. Adding noise showed FEVER networks with plastic synapses were robust, while constant synapse networks forgot the stimulus representation. To test network robustness to noise, simulations were conducted with varying levels of Gaussian noise added to synaptic updates. The noise did not significantly impact network performance, indicating that learning was not hindered by random synaptic weight multiplication. It remains unknown if all synapses change during learning, prompting simulations to assess network performance when only some synapses are updated. In simulations, networks were tested with different fractions of synapses updated, showing that even with just 10% of synapses tuned, networks could store information. Real neural circuits are not fully connected, with connection probabilities ranging from 50% to 80% in visual cortex. This suggests that not all synapses need to be updated to satisfy constraints for storing stimulus values. In simulations, networks with varying connection probabilities can store stimulus information, even with just 10% connectivity. Working memory performance declines with age due to a reduction in synapse number. The network continuously learns and retains stimulus information, allowing it to remember subsequent stimuli. The network can store new stimuli without re-training after initial training on 1, 5, or 10 stimuli, showing improved performance with each subsequent stimulus. The network can retain information about new stimuli after initial training on 1, 5, or 10 prior stimuli, without needing further synaptic updates. Storing novel stimuli becomes stable once the connectivity weight matrix has eigenvalues near unity. Training improves performance, as shown in Figure 5. Incorporating working memory capacity into models, plasticity rules were derived for multiple read-out vectors representing stimulus values. The experiments focused on remembering four stimuli, with networks capable of storing up to 100 stimuli. Each neuron contributed to representing the stimuli. In experiments, neurons in the network represent multiple stimulus aspects. Plasticity rules involve local synaptic information and a global error signal. Unclear aspects include the source and precision of the error signal and the symmetry of feedback signals to synapses. The feedback signals convey error information to synapses, allowing networks to form memory representations with minimal constraints. Two sources for the global error signal are proposed: feedback to neurons' dendrites and neuromodulatory chemicals. Continuous training is not necessary for functioning working memory, as downstream systems estimate and send back information. The global error signal can be calculated locally by each neuron using segregated dendrites, addressing the challenge of accessing the same value at distantly-located brain regions. Feedback and neuromodulatory mechanisms can implement memory circuits with random feedback weights. The error signal can be calculated locally by neurons using feedback from apical dendrites to basal dendrites. A readout layer provides feedback specifying the stimulus value, with synaptic updates computed locally. Alternatively, global error signal can be signaled with neuromodulators. Neuromodulators like dopamine, acetylcholine, serotonin, and norepinephrine can communicate the global error signal throughout the network. These neuromodulators play a crucial role in synaptic plasticity and working memory. Experimental work shows that synapses have activity-dependent \"eligibility traces\" that are converted into changes in synaptic strength by reward-linked neuromodulators. The concentration of different modulators tracks the error signals, and the densities of receptors to the modulators at each synapse bring information that yields updates in synaptic strength. The read-out neuron calculates the remembered stimulus value via Eq. 5, where q i is the weight of the synapses from cell i in the memory circuit. The error signal is calculated by the apical dendrite, weighted by d i, and transmitted to the basal dendrites for synaptic updates. Neurons in the modulatory system communicate error signals using neuromodulators like dopamine, acetylcholine, serotonin, and norepinephrine. The read-out neuron calculates the remembered stimulus value using synaptic weights (q i) from cell i in the memory circuit. Neuromodulators track changes in stimulus value and affect synaptic plasticity based on receptor density (d i). Feedback weights to the readout neuron may not match the feedback signals received by cell i. The fraction of stimulus retained varies in networks with plastic random synapses and feedback weights, with or without binary error signals, and constant synapses. The discussion emphasizes the importance of implementing memory networks with asymmetric feedback weights. By letting top-down feedback impact neurons at synapses with weights d i, the network can learn to store stimulus information effectively. Results show that even with asymmetric feedback, networks can retain stimulus information due to the positive elements in q and d, aligning with the update signal calculated from gradient descent. The synaptic updates with asymmetric feedback align with gradient descent updates, indicating effective learning. Binarizing error signals to {\u00b11} still allows for Hebbian or anti-Hebbian learning rules, showing that coarser feedback suffices for memory representation formation. The results show that networks can learn to form memory representations with asymmetric and binary feedback, although not as effectively as with precise feedback signals. Biologically plausible synaptic plasticity rules allow networks to store information in working memory, even in the presence of synaptic noise and partial connectivity. These networks can store multiple stimuli and show improved performance after training. The global error signal for the plasticity rule can be sourced from two candidates, and the networks can learn to store stimulus information while meeting biological requirements. This flexibility suggests that other synaptic plasticity updates may also be effective. The results suggest that synaptic plasticity updates can organize working memory circuits. Tests on networks of different sizes show that the update rule is effective. The optimal learning rate decreases as the network size increases. Future work may involve creating a spike-based model to account for spike timing in information sharing between cells. This research may also have implications for training recurrent neural networks. Recurrent neural networks (RNNs) can learn to store information using biologically plausible synaptic plasticity rules, requiring local information and a global error signal. This setup could make RNNs more biologically realistic, leading to better understanding of brain learning and potential biomimetic technologies. This approach has already resulted in hardware devices with on-chip learning capabilities, enabling simpler and more efficient implementations."
}