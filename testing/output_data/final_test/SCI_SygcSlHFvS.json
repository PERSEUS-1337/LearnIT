{
    "title": "SygcSlHFvS",
    "content": "Many methods have been developed to represent knowledge graph data, exploiting low-rank latent structure to encode information and infer unknown facts. Embeddings of entities are compared in a latent space for relationship prediction. The latent structure of models capturing semantic information remains unexplained. Recent theoretical interpretations of word embeddings are used to consider an explicit structure for relations between entities, predicting properties and justifying the performance of knowledge graph representation methods. Knowledge graphs consist of binary relations between entities in the form of facts. Recent link prediction models in knowledge graphs learn entity embeddings of lower dimensionality to recall known facts and infer unknown ones. Despite the steady improvement in performance, little is understood about the low-rank latent structure underlying these models, which is the focus of this work. In this work, the focus is on the latent structure underlying entity embeddings in knowledge graphs, drawing parallels with word embeddings like Word2Vec and GloVe. The latent features of words, such as meaning and grammatical type, give rise to patterns in data, aiding in tasks like word co-occurrence statistics and relatedness. Understanding this latent structure in one embedding task can be beneficial for another, like knowledge graph entity embedding. The text discusses how semantic properties are encoded in word embeddings through matrix factorization of word cooccurrence PMI. It explains that semantic relationships between words are reflected as linear relationships in the PMI matrix, leading to similar words having similar embeddings. This insight helps identify geometric relationships between word embeddings, crucial for semantic relations in knowledge graphs. The text discusses how semantic properties are encoded in word embeddings through matrix factorization of word cooccurrence PMI. It explains that semantic relationships between words are reflected as linear relationships in the PMI matrix, leading to similar words having similar embeddings. This insight helps identify geometric relationships between word embeddings, crucial for semantic relations in knowledge graphs. The key contributions of this work include deriving relation representations based on PMI-based word embeddings and categorizing relations based on relation conditions. The text discusses how semantic properties are encoded in word embeddings through matrix factorization of word cooccurrence PMI. It explains that semantic relationships between words are reflected as linear relationships in the PMI matrix, leading to similar words having similar embeddings. This insight helps identify geometric relationships between word embeddings, crucial for semantic relations in knowledge graphs. The key contributions of this work include deriving relation representations based on PMI-based word embeddings and categorizing relations based on relation conditions. The related object word embeddings categorize relations into three types and show how the performance of link prediction models aligns with relation conditions. Ranking metrics can be flawed, providing novel insight into prediction accuracy per relation of knowledge graph models. Recent knowledge graph models represent entities as low-dimensional vectors and relations as transformations in a latent space. These models are distinguished by their score functions, which define the form of relation transformation and how closeness between embeddings is evaluated. Score functions can be linear or non-linear, with various methods such as matrix multiplication or vector addition. Linear models for knowledge graph representation focus on simplicity and strong performance in link prediction. Competitive linear models include TransE, DistMult, TuckER, and MuRE, each with specific score functions. Additive models use Euclidean distance with relation-specific translations, while multiplicative models use a bilinear product of entity embeddings and relation-specific matrices. DistMult is a simple example with a diagonal matrix R. In TuckER, relation-specific matrices are a linear combination of prototype matrices in a core tensor, enabling multi-task learning. Word2Vec and GloVe generate low-rank word embeddings for downstream tasks. These models predict context words around target words using shallow neural networks. While recent language models focus on context-specific embeddings, we concentrate on interpretable embeddings for knowledge graph entities. Word embeddings in knowledge graph entities are interpretable and factorize a word co-occurrence PMI matrix, encoding semantic relationships like similarity and analogy. Similar words have similar embeddings, preserving linear geometric relationships under a linear projection. The embeddings of word pairs reflect similarities and analogies, with a common vector offset. The PMI vectors of analogies show a common difference between word associations, impacting the strength of the analogy. The common difference in word co-occurrence distributions signifies a semantic context-shift. The common difference in word co-occurrence distributions signifies a semantic context-shift, where context can be added or subtracted to transform words. The interpretation of word embeddings preserves relative relationships but obscures direct dimensions. The aim is to enhance understanding of PMI-based word embeddings. The aim is to build on the understanding of PMI-based word embeddings to identify what a knowledge graph relation representation needs to achieve. Relation conditions define a mapping by which subject embeddings are mapped to related object embeddings, allowing entities to be identified by proximity measures. Knowledge graph representation models' performance can be evaluated based on their ability to express mappings that satisfy required relation conditions. The text discusses how relation conditions define a mapping between subject and object embeddings in knowledge graph representation models. It mentions that relation conditions may not guarantee a relation holds, leading to false positives. Additionally, it highlights the difference between data used for knowledge graph embeddings and word embeddings, suggesting that word embeddings can provide a solution for knowledge graph models. Relation conditions in knowledge graph representation models define the proximity between mapped entities based on similarity and relatedness. Similar words have similar PMI vectors and embeddings, while related words co-occur similarly with other words. The strength of relatedness is reflected in the components of the PMI vectors. Relatedness is a weaker and more variable relation compared to similarity. In word embeddings, analogy refers to relational similarity, with relations requiring common vector offsets between word embeddings. Context-shift relations involve common differences in distributions of co-occurring words, leading to 1-to-1 relations with an aspect of relatedness. Specialisation relations add context, while generalised context-shift relations extend to 1-to-many, many-to-1, and many-to-many relations by specifying added or subtracted context from a context set. The context discusses how relations in word embeddings can vary in scope and size, with small context sets leading to explicit context-shift relations and large context sets focusing on relatedness. The relations can be viewed as set operations, with similarity as set equality, relatedness as equality of a subset, and context-shift as the set difference representing a relation-specific set. This highlights the relatedness aspect of relations in word embeddings. Relations in word embeddings can be categorized into three types: highly related (R), (generalized) specialization (S), and (generalized) context-shift (C). These relations reflect common themes and specific word associations between entities. Type R relations can be seen as a special case of type S relations. Relations in word embeddings can be categorized into three types: highly related (R), (generalized) specialization (S), and (generalized) context-shift (C). Type R relations can be seen as a special case of S, which is a special case of C. Table 2 categorizes relations in the WN18RR dataset, containing 11 relations between 40,943 entities. The FB15k-237 dataset mostly consists of type C relations, making it difficult to draw contrasts between relation types. The text discusses the identification of relations between word embeddings using loss functions and contrasts them with knowledge graph models. It also mentions the projection of entity embeddings onto a subspace for evidence of relatedness. The text discusses identifying relations between word embeddings using loss functions and contrasts them with knowledge graph models. It mentions projecting entity embeddings onto a subspace for evidence of relatedness, with a focus on relation-specific symmetric matrices and vectors. The text discusses comparing entity embeddings using dot product and Euclidean distance, predicting the complexity of relation representation, symmetry of relation matrices, and eigenvalues reflecting relation strength. The text discusses the performance of different knowledge graph models (TransE, DistMult, TuckER, and MuRE) on various types of relations, highlighting the strengths and weaknesses of each model based on relation representation. The evaluation process involves generating evaluation triples for each test triple by varying entities and relations. Scores are ranked to calculate hits@10, measuring the fraction of times a true triple appears in the top 10 ranked evaluation triples. Results for each relation type are reported in Tables 3 and 4, including known confounding influences. The evaluation process includes generating evaluation triples for each test triple by varying entities and relations to calculate hits@10. Results for each relation type show a performance gap with additive-only models performing poorly on average. Additive-only models perform poorly on average, especially on type R relations. DistMult performs well on type R relations as it can fully represent them. MuRE performs best overall, particularly on S and C type relations. TuckER's performance on NELL-995 is explained by its multi-task learning ability. All models struggle with the hypernym relation despite its type S. The performance of models on hierarchical structures like hypernym relations and type R relations is not ideal. The percentage of training instances of a relation does not necessarily correlate with its performance. TuckER compensates for its lack of an additive component by having high symmetry scores for type R relations. TuckER compensates for the lack of an additive component by having lower scores for type R relations. Relation vectors for type R relations have a noticeably lower norm compared to types S and C. Eigenvalue magnitudes of the relation-specific matrices reflect the strength of relatedness, with type R relations showing the highest values. Results support predictions that knowledge graph models benefit from the same latent semantic structure as word embeddings. The analysis identifies the best performing models for different relation types, aiding dataset-dependent model selection. Independent predictions of triple truth are not commonly reported, despite recent models being capable of it. Ranking-based metrics are typically used for evaluation, which can be computationally costly and flawed if entities have multiple relations. The evaluation of models for predicting triple truth is often based on ranking-based metrics, which can be computationally costly and flawed if entities have multiple relations. To address this, actual model predictions are considered by sub-sampling and splitting positive predictions between training and test/validation instances. The accuracy of predictions for different relation types is shown in Table 6 for MuRE I, DistMult, TuckER, and MuRE models. The evaluation of relation prediction accuracy for MuRE I, DistMult, TuckER, and MuRE (WN18RR) models shows that MuRE performs best on the test set, followed closely by MuRE I. DistMult and TuckER perform poorly on most relations. Analysis of positive predictions reveals TuckER is accurate but pessimistic, MuRE I is optimistic but inaccurate, and MuRE is both optimistic and accurate. Histograms of MuRE prediction probabilities show a clear distinction between relation types, with type R being classified correctly with high confidence. The analysis shows that most train and test triples are classified correctly with high confidence, but for types S and C, incorrect predictions are confidently far below the decision boundary. Models struggle with representing type S/C relations, with fewer positive predictions for less accurate relation types. The study recommends including predictive performance in future link prediction work and highlights the need to understand the latent structure learned by models for knowledge graph link prediction. The curr_chunk discusses the mapping of word embeddings to related knowledge graph relations, partitioning relations into three types and assessing loss functions of knowledge graph models. It highlights that models satisfying relation conditions can represent them using PMI-based word embeddings. The study extends understanding of how semantic relations are encoded in relationships between word embeddings, showing commonality with latent structures learned by PMI-based word embeddings like W2V. The curr_chunk discusses the categorization of WN18RR relations and the Krackhardt hierarchy score in directed graphs. It evaluates the predictive performance of knowledge graph models and the binary reachability matrix in representing directed paths. The Krackhardt hierarchy score in directed graphs is defined based on the symmetry score of a relation matrix. Tables show unknown triples for various relations at different probabilities, as predicted by models. True triples are highlighted, and self-related entities are marked in blue."
}