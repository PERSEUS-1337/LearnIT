{
    "title": "B1xY-hRctX",
    "content": "The Neural Logic Machine (NLM) is a neural-symbolic architecture combining neural networks and logic programming for inductive learning and logic reasoning. NLMs excel in tasks like sorting arrays and relational reasoning on family trees, achieving perfect generalization where traditional methods struggle. The debate over systematicity in connectionist models has been ongoing since Fodor & Pylyshyn (1988). Logic systems can process symbolic rules for language understanding and reasoning. Inductive logic programming (ILP) has been developed to learn logic rules from examples, combining symbols and probabilities. Inductive logic programming (ILP) struggles to scale due to the large search space of compositional rules. The classic blocks world problem involves moving blocks to achieve a target configuration. Neural Logic Machines (NLMs) offer a neural-symbolic architecture to solve the challenges of the blocks world problem by realizing Horn clauses in first-order logic. Neural Logic Machines (NLMs) implement logic operations using neural networks to approximate logical ANDs and ORs efficiently. The paper outlines the organization, definitions in symbolic logic, neural rule induction system, evaluation of NLM effectiveness, related works, and conclusions. NLMs apply first-order rules to draw conclusions based on base predicates and objects in the Closed-World Assumption. Neural Logic Machines (NLMs) use tensors to represent logic predicates and apply neural operators to draw conclusions based on premises about objects. The probabilistic tensor representation allows for handling relational data with various orders. Grounding predicates on a set of objects results in tensors that can be operated on to generate conclusion tensors. Neural Logic Machines (NLM) utilize tensors to represent logic predicates and apply neural operators for drawing conclusions based on object premises. Grounding predicates on objects result in tensors that can be operated on to generate conclusion tensors. The tensor p U represents whether a value is True under specific grounding conditions, with mutually exclusive grounded objects. This restriction does not limit representation generality, as missing entries can be represented by grounding other predicates with smaller arity. Neural Logic Machines (NLM) use tensors to represent logic predicates and apply neural operators for drawing conclusions based on object premises. The grounded values of predicates can be represented by tensors, with each entry taking a value from [0, 1] indicating the probability of being True. The tensors describe properties of objects and pairwise relations between objects, with a maximum arity B set for the predicates. Our goal is to build a neural architecture to learn rules that handle relational data with multiple arities. We discuss our neural implementation of boolean logic rules and quantifications, combining these neural units to compose Neural Logic Machines (NLMs). Neural Logic Machines (NLMs) combine neural units to create a multi-layer, multi-group architecture. NLMs operate on tensor representations of predicates with varying arities, taking input tensors as premises and outputting conclusions. The layers of NLMs allow for the formation of higher levels of abstraction, with forward propagation representing a sequence of rule applications. NLMs efficiently realize a partial set of Horn clauses by utilizing neural boolean logic rules and quantifiers. Neural Logic Machines (NLMs) utilize neural boolean logic rules and quantifiers to operate on tensor representations of predicates with varying arities. The symbolic meta-rule for boolean logic is used to instantiate boolean expressions, with predicates stacked as tensors. Grounding values for conclusive predicates are conditioned on subsets of objects, allowing for rule applications with arbitrary permutations. Our neural implementation of boolean logic rules utilizes a lifted neural module that applies uniformly to any grounding entries in the output tensor. It includes a Permute operation and a multi-layer perceptron (MLP) for processing tensor representations. The MLP applies uniformly to all object indices using sigmoid nonlinearity and trainable network parameters. The neural implementation of boolean logic rules utilizes a lifted neural module that applies uniformly to any grounding entries in the output tensor. It includes a Permute operation and a multi-layer perceptron (MLP) for processing tensor representations. The MLP applies uniformly to all object indices using sigmoid nonlinearity and trainable network parameters. For exclusive indexes i 1 , . . . , i r \u2208 {1, 2, . . . , m}, the same MLP is applied, making the size of \u03b8 independent of the number of objects m. Meta-rules for quantification, such as expansion and reduction, are introduced, with expansion creating new predicates by introducing a new variable x r+1. The expansion meta-rule for a set of C r-ary predicates introduces a new and distinct variable x r+1. The neural implementation introduces meta-rules for quantification, including expansion and reduction. Expansion creates new predicates by introducing a new variable x r+1, while reduction operation reduces a variable in a predicate via quantifiers. The reduction meta-rule eliminates the variable x r+1 via quantifiers, with the neural implementation taking the maximum or minimum element along the dimension of x r+1. Neural Logic Machines (NLMs) implement symbolic logic rules in a multi-layer, multi-group architecture. Each layer has B + 1 computation units as groups, with intra-group and inter-group computations between layers. Predicates are grouped by their arities, and tensors from the previous layer are connected and aligned to form an intermediate tensor. Nonexistent terms are ignored in the process. Neural Logic Machines (NLMs) implement symbolic logic rules in a multi-layer, multi-group architecture. Intra-group computation is performed using neural boolean logic, with tensors concatenated and processed using sigmoid nonlinearity. The output tensor of predicates for each object pair is computed through shared MLP, enabling forward chaining of a partial set of Horn clauses. Neural Logic Machines (NLMs) implement symbolic logic rules in a multi-layer, multi-group architecture. Intra-group computation is performed using neural boolean logic, with tensors concatenated and processed using sigmoid nonlinearity. The extension to support cyclic references is left for future work. NLMs can induce lifted rules from training data pairs and generalize during testing. The expressive power of NLM depends on factors like depth, breadth, and the number of output predicates used at each layer. In experiments, Neural Logic Machines (NLMs) use a small number of output predicates and prefer shallow networks with few hidden layers and neurons to simplify the learned rules. The computational complexity of NLM's forward or backward propagation is quadratic in the number of objects, with O(DC^2) parameters. NLM can solve various tasks, including relational reasoning and decision making. Neural Logic Machines (NLMs) can handle a broad range of tasks, from relational reasoning to decision making. They can generalize from small to large instances and use different loss functions for supervised and reinforcement learning. Baselines like Memory Networks (MemNN) and Differentiable Inductive Logic Programming (\u2202ILP) are compared, along with models like Differentiable Neural Computer (DNC) and graph neural networks. For more details on training and implementation, refer to the appendices. Neural Logic Machines (NLMs) can handle various tasks, including relational reasoning and decision making. They can generalize from small to large instances and use different loss functions for supervised and reinforcement learning. MemNN utilizes unique identifiers for objects and stores pre-conditions in memory slots. Unary predicates are stored as tuples with properties, while binary predicates are stored with relations for each pair. Key and value extraction for MemNN's lookup is done using 2-layer MLPs. Neural Logic Machines (NLMs) and MemNN utilize unique identifiers for objects and perform relational reasoning. MemNN uses 2-layer MLPs for key and value extraction in memory slots. \u2202ILP and NLM excel in family tree and graph reasoning tasks, achieving 100% accuracy on the test set. The goal is to reason about family members and their relationships. The task involves reasoning about family members and their relationships. MemNN treats relation prediction as a question answering task, using unique identifiers for objects. The finishing hidden state is used to classify whether a specific relation exists. \u2202ILP and NLM excel in family tree and graph reasoning tasks, achieving 100% accuracy on the test set. MemNN models use binary predicates to classify relations in family trees. Trained on instances of size 20, tested on sizes 20 and 100. Fully supervised learning with accuracy evaluated on objects or pairs. MGUncle defined as maternal great uncle. Performance reported in Micro/Macro accuracy format. DNC reaches 81.8% accuracy in finding MGUncle. Family tree extended to general graphs with reasoning performance reported. The Family tree is extended to general graphs, where nodes are treated as objects. The graph is represented by a \"HasEdge\" relation and a color property for each node. Nodes can have properties like AdjacentToRed and k-OutDegree. The N/A result in the 2-OutDegree task is due to memory restrictions. Models are trained and tested on instances of size 10 and 50. The proposed NLM is compared to MemNN in tasks like sorting integers and finding shortest paths, both trained and tested on instances of size 10 and 50. Performance is evaluated based on task completion probability and average moves used. MemNN fails to complete the blocks world task within the maximum moves allowed. NLM's decision-making capability is tested in the blocks world domain by extending the model to fit the Markov Decision Process formulation. The blocks world environment in reinforcement learning involves two worlds with ground and blocks. The task is to match the operating world configuration to the target world. Objects are represented by properties like world_id and coordinate. The input involves numeral comparisons between objects. The only operation allowed is Move(i, j) to move objects in the operating world. In the blocks world environment, the only operation allowed is Move(i, j) to move objects in the operating world. Objects can be movable or placeable based on certain conditions. The action space is determined by the number of blocks in the world. A shared MLP is applied on the output relational predicates of each pair of objects to compute an action score for Move(x, y). In the blocks world environment, the algorithm demonstrates its ability to excel at algorithmic tasks like Sorting and Path. For sorting integers, the algorithm iteratively swaps elements to arrange them in ascending order. Each slot in the array is treated as an object, and their index and numeral relations are inputted to the model. The action space indicates the pair of integers to be swapped, and the learning performance is summarized in TAB3. Sorting the array within the maximum number of swaps is considered an easy task due to the comparisons between all pairs of elements given to the agent. The algorithm excels at algorithmic tasks like Sorting and Path in the blocks world environment. For sorting integers, it iteratively swaps elements to arrange them in ascending order. The learned algorithms can be interpreted as Selection-Sort, Bubble-Sort, etc. Videos demonstrating some learned algorithms are available on the website. Additionally, the algorithm's performance in finding a path in a given graph as a sequential decision-making problem is tested. The algorithm excels at algorithmic tasks like Sorting and Path in the blocks world environment. For sorting integers, it iteratively swaps elements to arrange them in ascending order. The learned algorithms can be interpreted as Selection-Sort, Bubble-Sort, etc. Videos demonstrating some learned algorithms are available on the website. Additionally, the algorithm's performance in finding a path in a given graph as a sequential decision-making problem is tested. In the steps, the maximum distance between s and t is set to be 5 during training and 4 during testing, replicating the setting of BID6. The shortest path task is formulated as a challenging reinforcement learning task where the agent iteratively chooses the next node along the path. Inductive logic programming (ILP) is a powerful way of reasoning over discrete symbols, successfully applied to various language-related problems. Differentiable implementations of ILP have been introduced, allowing integration into modern learning frameworks. Scaling up to a large number of complex rules remains a major challenge for these approaches. Our method can handle more complex tasks like the blocks world by learning lifted rules from input-output pairs using neural networks, without the need for human-designed rules. It differs from existing approaches by not relying on symbolic rule induction and is related to symbolic relational reasoning. Our work focuses on symbolic relational reasoning for processing discrete data structures like knowledge graphs and social graphs. Existing approaches for KB reasoning rely on known predicates, leading to exponential complexity in the blocks world. Our method learns subsymbolic embeddings for efficient KB completion, distinct from approaches focusing on complex rules. The scalability of Neural Language Models (NLMs) to large entity sets is left for future works. Modular networks like BID0 BID4 are proposed for reasoning over subsymbolic data such as images and natural language question answering. BID16 implements a visual reasoning system based on \"virtual\" objects brought by receptive fields in CNNs. Graph neural networks and relational inductive bias are also discussed, including Graph Convolution Networks (GCNs) as a family of neural architectures. The proposed neural architecture removes restrictions on graph neural networks, allowing for lifted rules on any set of objects. It shows effectiveness in relational reasoning and general algorithm modeling tasks. The model is fully differentiable and can be integrated into existing neural architectures for logic reasoning. The neural architecture introduced in the paper allows for lifted rules on any set of objects, enabling relational reasoning and handling relational data with multiple orders. It can be integrated into existing convolutional or recurrent neural architectures for logic reasoning. The paper introduces a novel neural-symbolic architecture for relational reasoning and program induction, aiming to optimize complex programs without requiring strong supervision like ground-truth programs. The paper proposes Neural Logic Machines (NLMs), a differentiable neural-symbolic architecture for first-order logic deduction. NLMs can learn logical rules from small-scale tasks and generalize to large-scale tasks. Future research directions include exploring adaptive depth selection, handling vector inputs with real values, and addressing the nontrivial training process of NLMs. The supplementary material provides more details on the training method, implementation details, hyper-parameters, and NLM extensions. It also discusses the need to extract human-readable rules from NLMs and includes a proof of how NLMs can realize the forward chaining of logic rules. In the supplementary material, details are provided on the training method, hyper-parameters, and NLM extensions. It includes a proof of how NLMs can implement logic rules and a list of sample rules for the blocks world problem. Additionally, a minimal implementation of NLM in TensorFlow is provided for reference. The training method involves using Adam optimization with a learning rate of \u03b1 = 0.005 and Softmax-CrossEntropy as the loss function for supervised learning tasks. For reinforcement learning tasks, a curriculum learning approach is used. For reinforcement learning tasks, the REINFORCE algorithm is used for optimization. Each training batch consists of a single episode of play. A policy entropy term is added to the objective function to aid exploration. The update function for policy parameters includes an entropy function and rewards based on state, action, and discounted rewards. The agent receives a reward of 1.0 for completing tasks within a limited number of steps and a penalty of -0.01 for each move. The reward discount factor is set at 0.99 for all tasks. The hyper-parameters for reinforcement learning tasks are detailed in Table 3, with a reward discount factor of 0.99 and a penalty of -0.01 for each move. Training instances are grouped by complexity and presented to the model in increasing difficulty. Models are tested periodically on novel instances, advancing to harder lessons based on performance. The curriculum learning approach in reinforcement learning involves passing exams to advance to harder lessons with more complex training instances. Models graduate based on performance on final exams, with each lesson containing training instances of increasing complexity. Recording models' failure cases is crucial for efficient training of NLMs. The curriculum learning approach in reinforcement learning involves passing exams to advance to harder lessons with more complex training instances. Training samples are balanced between positive and negative sets to prevent sub-optimal solutions. The evaluation process involves randomly sampling examples from recent lessons, with the agent's success rate determining if it passes the exam. The threshold for passing the final exam is 100%, with a linear decrease in threshold for earlier lessons. The curriculum learning approach in reinforcement learning involves passing exams to advance to harder lessons with more complex training instances. The threshold for passing the final exam is 100%, with a linear decrease in threshold for earlier lessons. During training, balanced sampling is used to choose instances from positive and negative pools. Hyper-parameters and implementation details for the model and experiments are provided, including the addition of residual connections to the model. The model includes residual connections, with base predicates concatenated to conclusive predicates in each layer. Hyper-parameters for different tasks are shown in Table 4, with a hidden dimension of 8 for all layers. In supervised learning, a model is \"graduated\" if training loss is below a threshold, while in reinforcement learning, an agent is \"graduated\" if it achieves 100% success rate on the final exam evaluation. In family tree tasks, the difficulty of learning the maternal great uncle relation results in a low graduation ratio of 20%. Increasing the number of people in training examples to 30 raises the graduation ratio to 50%. Hyper-parameters for Neural Logic Machines are shown in Table 4, with definitions of depth and breadth. Residual links and successful graduation ratios are also discussed. The process involves randomly creating individuals in a family tree, selecting their gender and parents, and arranging marriages. In graph tasks, nodes are sampled on a unit square and connected to nearest nodes. In Sorting, permutations are generated and sorted in ascending order. In Blocks World, blocks are placed on randomly selected objects. In the Blocks World environment, the agent is trained on an auxiliary task to predict the validity or effect of actions using supervised learning. The agent's actions are chosen based on the Softmax score of the relational representation of objects in the current and target configurations. The accuracy of the Neural Logic Machine (NLM) is estimated empirically through sampling testing examples. In experiments, accuracy statistics are reported on randomly generated data, with a specific model tested on 100,000 samples showing no failures. The confidence level in the accuracy being at least 99.98% is 99.7% based on the Chernoff Bound. NLM can reason over noisy input by integrating with neural perception, allowing input properties or relations to be derived from other neural architectures. In a preliminary example, CNNs are used to process input images from the MNIST dataset for reasoning. The model is optimized jointly with NLM to reason over noisy input. The task is modified to AdjacentToNumber0, where nodes are labeled with numbers from MNIST. LeNet is used to extract visual features for number recognition, achieving 99.4% accuracy on testing examples. The NLM can realize a partial set of Horn clauses in first-order logic, up to its depth and breadth limits. Cyclic references of predicates among rules are not allowed in NLMs. The realization of a definite clause in FOL is proven, with one positive literal and multiple negative literals. The extension to support cyclic references is left for future work. The depth, breadth, and number of predicates in NLM are assumed to be flexible and large enough to realize demanding rules. The NLM can realize a partial set of Horn clauses in first-order logic, up to its depth and breadth limits. Cyclic references of predicates among rules are not allowed in NLMs. The realization of a definite clause in FOL is proven, with one positive literal and multiple negative literals. The extension to support cyclic references is left for future work. The depth, breadth, and number of predicates in NLM are assumed to be flexible and large enough to realize demanding rules. In the current chunk, variables in a rule are classified into subsets based on their appearance in head and body predicates. The composition of computation units in NLMs to realize rules is demonstrated in four steps. In this example, helper predicates are created to modify the right-hand side of the rule. Neural boolean logic is used to handle boolean formulas within quantification symbols. The tensor representation is transposed using the Permute operation. The Reduce operation adds quantifiers to the right-hand side. Finally, the Expand operation adds variables that only appear in the head predicate to the derived predicate. In NLMs, symbolic rules written as Horn clauses are realized through a computation flow involving expansions, neural boolean rules, reductions, and conclusions. Forward propagation in NLMs corresponds to forward chaining of Horn clauses, starting from initial facts and applying rules to derive new facts. Facts in NLMs are represented as the U-grounding of predicates. If rules do not have recursive references, they can all be sequentially applied in the forward chaining process. In NLMs, symbolic rules are realized through a computation flow involving expansions, neural boolean rules, reductions, and conclusions. Rules can be sequentially applied in the forward chaining process if they do not have recursive references. Topologically resolved set of rules R allows for building NLMs to realize specific rules, leading to complex reasoning in the Blocks World domain. The Blocks World challenge involves manual rules created by human experts to determine if a block should be moved to reach the target configuration. Input relations include SameWorldID, SmallerWorldID, LargerWorldID, SameID, SmallerID, LargerID, Left, SameX, Right, Below, SameY, Above. Helper predicates are defined to create the desired predicate \"ShouldMove(x)\". This is part of the logic rules needed to solve the Blocks World challenge, along with figuring out where the block should be moved. The proposed NLM can learn policies to solve the Blocks World with sparse reward signals. The Blocks World challenge involves manual rules to determine block movements. NLM can learn policies from sparse rewards and generalize to larger instances. The python code shows a minimal implementation of a Neural Logic Machines layer with breadth 3 in TensorFlow."
}