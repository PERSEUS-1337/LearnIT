{
    "title": "Syx9rnRcYm",
    "content": "Unmanned Autonomous Vehicles (UAVs), particularly flying drones, have gained significant attention in Artificial Intelligence due to advancements in electronic technology. Their applications range from monitoring floods to detecting forest trails. This study focuses on the efficiency, robustness, and accuracy of autonomous flying drones, presenting results supported by experiments and comparing three state-of-the-art algorithms: TrailNet, InceptionResnet, and MobileNet. MobileNet outperformed TrailNet and InceptionResnet in accuracy, robustness, power consumption, and inference time. It showed superior results with minimal computational requirements and power consumption. Challenges faced during the study were discussed, along with plans for future work to enhance safety features. In the modern era, UAVs are popular for their autonomous flying capabilities, unlike ground vehicles limited by physical paths. Autonomous flying objects like drones are widely used in various applications such as traffic monitoring, agriculture, surveillance, data mining, and disaster response. Finding suitable algorithms for these vehicles is crucial as their applications expand. Some applications prioritize accuracy while others focus on longer durations of operation. Significant changes in autonomous motion planning of UAVs have been observed in the last decade. The complexities of aerial vehicles, such as differential constraints and uncertainty in vehicle state, make precise pre-computed plans impossible. Various approaches and techniques have been developed to plan the motion of unmanned autonomous vehicles, with a need for benchmarking studies to enhance accuracy, robustness, power consumption, safety, and inference time. The basic design of UAVs includes acceleration and velocity constraints, as well as higher-order differential constraints related to drone motion. The main goal of UAVs is to guide the vehicle towards a specific objective. This paper presents a comparative study of three algorithms for motion control of drones in trail detection. The study evaluates precision, robustness, power consumption, and inference time of the algorithms, considering their application areas. This analysis aims to determine the most suitable algorithm based on specific application requirements. Our study covers recent developments and algorithms used in trail detection by UAVs, reviewing applications and challenges. Inspired by BID13's research on a MAV system, we enhanced accuracy and reduced training time using InceptionResnet and MobileNet. InceptionResnet BID14 and MobileNet Howard et al. (2017) have shown good performance at low computational cost. Residual connections in Inception architecture have led to state-of-art performance in the 2015 ILSVRC challenge. MobileNets, introduced in BID7, are efficient models for embedded vision applications using depth-wise separable convolutions for lightweight deep neural networks. In this study, a comparative analysis was conducted to find an algorithm suitable for UAVs, focusing on Trailnet, InceptionResnet, and MobileNet. Inception-ResNet and MobileNet were chosen for their strong performance in classification tasks. The goal is to train these algorithms offline, implement them on drones for navigation through trails, and assess their robustness using the Udacity simulator. The aim is to showcase the effectiveness of low-cost systems for drone navigation. The architecture used for research in achieving autonomous drone flight includes Jetson TX2 for computing, ROS with Ubuntu L4T, and a ZED stereo camera for object detection. Additionally, a Windows 10 system with Intel Xeon CPU and Nvidia Titan Xp GPU was used for training purposes, along with a Venom lithium polymer battery. The drone utilized a Venom 35C, 14.8V, 5000 mAh lithium polymer battery and a Holybro Ublox Neo-M8N GPS module for high sensitivity and minimal acquisition time. The Jetson Developer Kit (TX2) was flashed with Ubuntu 16.04 and JetPack installer was used to install developer tools. ROS Kinetic Kame was employed as robotics middleware for hardware integration. The drone's ROS system consists of MAVROS, Control Node, DNN, Camera, and Joystick nodes for communication. MAVROS enables communication with the PX4 on-board using MAVLink protocol. The Jetson TX2 on-board had wifi access for remote connection with the host PC. The host PC connected wirelessly to the Jetson TX2 to control the drone via SSH. A simulator from Udacity's Flying Car nanodegree program was used to mitigate risks and expenses associated with testing UAVs. The simulator utilizes UART communications for controls. For experiments, IDSIA trail dataset BID6 from Swiss Alps forest trails was used, consisting of 15GB image data divided into folders. Folders 001, 002, 004, 005, 006, 007, and 009 were used for training, folders 003, 008, and 010 for validation, and folder 012 for testing. Folders 000, 013, and 014 were discarded as they contained preliminary test data. Model selections were made based on performances in ImageNet Challenge BID12, an ongoing visual object recognition database project. ImageNet is a database used for visual object recognition research, hosting an annual competition with 1.2 Million images across 1000 classes. Deep learning models are selected based on performance metrics like accuracy and computation, crucial for building effective models. Convolutional neural networks have high memory and computational requirements, posing challenges for embedded AI devices like drones. Size of the final trained model is also a key consideration. Transfer learning is a Machine Learning technique used in embedded AI devices like drones. The size of the final trained model is crucial for deployment, with a trade-off between accuracy and computational cost. Factors like training time, generalization ability, and inference time are important in selecting models. MobileNet BID7 has been chosen for its efficiency. Fine-tuning is a transfer learning strategy used to adapt ConvNets for specific tasks by adjusting the final layers and retraining the classifier on a new dataset. Earlier layers capture generic features while later layers extract detailed class-specific features. In this case, InceptionResnet and MobileNet were fine-tuned with weights pretrained on ImageNet BID5. In this section, the results of experiments comparing TrailNet, InceptionResnet, and MobileNet on size, accuracy, inference time, and power consumption are discussed. InceptionResnet and MobileNet show better accuracy than TrailNet, with MobileNet having lower training time and computational cost due to its simplicity. Testing was done on a dataset of 2000 images for a trail path using Udacity simulator. The drone autonomously followed the ground truth path using Inception-Resnet and MobileNet models. MobileNet had a lower inference time, making it more energy-efficient for high frame rate cameras. Power draw values were calculated on Nvidia Titan Xp. MobileNet draws less power compared to other models, resulting in longer battery life for the drone. Inference time is low, allowing high frame rate cameras to operate for longer with less energy consumption. Challenges were faced in running DNN models on the drone in real time due to hardware issues. Due to hardware issues, we faced challenges running DNN models on the drone in real time. We addressed data imbalance by upsampling and downsampling the dataset, reduced overfitting with data augmentation techniques and regularization, and optimized power consumption for mobile embedded devices. In this paper, a comparison between TrailNet, InceptionResnet, and MobileNet algorithms for UAVs was presented. MobileNet outperformed others with less computational requirement and power consumption, making it more suitable for drones and embedded devices. MobileNet is deemed more suitable for drones and embedded devices due to its lower computational requirement and power consumption compared to TrailNet and InceptionResnet. Safety concerns for drones include collision risks, external disturbances, battery issues, and theft, which will be addressed in future work."
}