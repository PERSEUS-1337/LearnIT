{
    "title": "HkxWXkStDB",
    "content": "Deploying machine learning systems in the real world requires high accuracy on clean data and robustness to natural corruptions. Despite architectural advances improving accuracy, building robust models remains challenging. Previous research has shown a trade-off between robustness and accuracy, with standard data augmentation techniques like Cutout and additive Gaussian noise affecting one but not the other. A new augmentation method called Patch Gaussian, which adds noise to randomly selected patches in an input image, has been introduced. Models trained with Patch Gaussian achieve state-of-the-art performance on CIFAR-10 and ImageNet Common Corruptions benchmarks while maintaining accuracy on clean data. This augmentation reduces sensitivity to high-frequency noise. Patch Gaussian augmentation reduces sensitivity to high frequency noise while maintaining the ability to utilize relevant high frequency information in images. It can be combined with other regularization methods like AutoAugment and helps in adversarial learning without sacrificing accuracy. Larger \u03c3 of Patch Gaussian improves mean corruption error and clean accuracy, leading to more robust and accurate models. Modern deep neural networks can achieve impressive performance at classifying images but lack robustness to various forms of distribution shift in real-world settings. They are sensitive to small translations, changes in scale, blurring, additive noise, and small objects in images. For models to be useful, they need to be accurate on a high-quality set of images and robust on corrupted images. Most literature in machine learning focuses on architectural changes to improve model performance. Recent research has shifted focus from architectural changes to improve clean accuracy in neural networks towards improving robustness. Studies have quantified the problem by establishing benchmarks and comparing human and neural network performance. Systemic failure modes include excessive invariance to visual features, texture bias, sensitivity to adversarial perturbations, and reliance on non-robust but highly predictive features for classification. Recent research has focused on improving model robustness performance through various methods such as projecting out superficial statistics, architectural improvements, pretraining schemes, and data augmentations. Data augmentation increases training set size and diversity, allowing for the learning of invariances that are difficult to encode architecturally. Recent work includes learning better transformations, inferring combinations of transformations, unsupervised methods, and the theory of data. Recent research has focused on improving model robustness through various methods such as data augmentation, unsupervised methods, and theory of data. However, individual data augmentation methods that enhance robustness often come at the cost of reduced clean accuracy. The current state of the art in robustness benchmarks involves creating custom datasets with styled-transferred images before training, leading to a significant drop in clean accuracy. Many recent works aim to improve either robustness or accuracy, as trade-offs between the two are considered inevitable. In this work, a new data augmentation method called Patch Gaussian is proposed to balance robustness and accuracy in machine learning models. This method achieves state-of-the-art results in the Common Corruptions benchmark while maintaining clean accuracy. Patch Gaussian can be combined with other regularization strategies and data augmentation policies for further improvements. In this study, a new data augmentation method called Patch Gaussian is introduced to enhance machine learning model performance. The method is shown to effectively leverage high-frequency information in lower layers and is not overly sensitive in later layers. Additionally, the study explores the use of Patch Gaussian in adversarial training, raising questions about the impact of training distributions on out-of-distribution robustness. The comparison between Cutout and Gaussian data augmentation techniques for accuracy and robustness is also discussed. The study introduces Patch Gaussian data augmentation to improve model performance, comparing its effectiveness with Cutout and Gaussian methods. Cutout enhances accuracy on clean data but does not improve robustness. Conversely, training with higher levels of Gaussian noise can increase robustness but decreases accuracy on clean data, leading to a trade-off between accuracy and robustness. The study introduces Patch Gaussian data augmentation to improve model performance by exploring augmentation strategies that do not compromise clean accuracy for robustness. Previous methods showed a trade-off between accuracy and robustness, but Patch Gaussian aims to achieve both goals simultaneously. Patch Gaussian is a technique that combines the noise robustness of Gaussian with the improved clean accuracy of Cutout. By adding a patch of Gaussian noise to the image, it overcomes limitations and outperforms complex training schemes. This method allows for interpolation between Gaussian and Cutout by varying patch size and noise standard deviation. The goal is to learn models that balance clean accuracy and robustness to corruptions by selecting hyper-parameters that prioritize robustness while maintaining a minimum clean accuracy threshold. Patch sizes around 25 on CIFAR and \u2264250 on ImageNet are found to be effective. The study focuses on selecting hyperparameters for augmentations to achieve out-of-distribution robustness. Models are chosen based on robustness to Gaussian noise to avoid overfitting to Common Corruptions benchmark. Patch Gaussian training enhances robustness to Gaussian noise while maintaining clean accuracy. The study establishes a new state of the art in the Common Corruptions benchmark by improving robustness to Gaussian noise. Patch Gaussian training complements other regularization strategies and data augmentation policies to enhance robustness to various corruptions beyond Gaussian noise. Patch Gaussian training achieves state of the art performance on the Common Corruptions benchmark, which includes CIFAR-C and ImageNet-C, by improving robustness to various real-world corruptions beyond Gaussian noise. The benchmark consists of images transformed with 15 corruptions at 5 severities each, modeling common real-world transformations like brightness, weather conditions, and noise. The model's average error over 5 severities of a given corruption, normalized by a baseline model, is used to measure performance. ImageNet-C was released in compressed JPEG format, altering the corruptions applied. Patch Gaussian training achieves state of the art performance on the Common Corruptions benchmark, which includes CIFAR-C and ImageNet-C. Results are reported on the benchmark with and without extra compression, as well as on noise-based corruptions. Baselines trained with flip and crop data augmentation are used to normalize Corruption Errors, except for ImageNet where the AlexNet baseline is used for comparison with previous work. Patch Gaussian training outperforms adversarially-trained models on CIFAR and models trained with Random Erasing on ImageNet. Previous work has shown that augmentation diversity is crucial for robustness gains. Patch Gaussian achieves state-of-the-art performance on CIFAR-C and ImageNet-C benchmarks, even outperforming models on corruptions like fog where Gaussian augmentation hurts performance. Patch Gaussian training achieves state of the art in CIFAR-C and ImageNet-C robustness benchmarks while maintaining clean test accuracy. The results are surprising as achieving this level of robustness was thought to require major changes in training procedures and datasets. Training shape-biased models involves creating a custom dataset of style-transferred images, which is computationally expensive. The Patch Gaussian model achieves a substantial decrease in error compared to other models, indicating that complex training schemes are not necessary for robustness. Comparisons with other regularization methods show that label smoothing improves clean accuracy but weakens robustness. Label smoothing improves clean accuracy but weakens robustness in all corruption metrics considered. Increasing weight decay does not enhance clean accuracy or robustness. Dropblock does not improve clean accuracy but does make the model more robust, even after training for 90 epochs. Combining Dropblock with Patch Gaussian improves model robustness according to various corruption metrics. Using label smoothing alongside Patch Gaussian enhances clean accuracy but has mixed effects on robustness metrics. Dropblock as a strong regularizer for 90 epochs reduces clean accuracy when combined with Patch Gaussian, but together they achieve the best robustness performance. Patch Gaussian can be effectively used with other regularization strategies, raising the question of its compatibility with different data augmentation policies. In this section, the study explores the impact of adding Patch Gaussian to augmentation policies for improved model robustness. Models are trained for 180 epochs to achieve optimal results, combining AutoAugment with Patch Gaussian. A frequency-based analysis is conducted on models trained with various augmentations, measuring changes in network activations and test error using Fourier-noise-corrupted images. The study analyzes model sensitivity to frequency and orientation perturbations in the Fourier domain by measuring changes in network activations and test error using Fourier-noise-corrupted images. Heatmaps show sensitivity in the first layer of CIFAR-10 models and ImageNet, focusing on lower frequencies for the latter. Different augmentations like Cutout and Gaussian are explored with larger patch sizes to highlight their effects on sensitivity. Additional model heatmaps can be found in the Appendix. The study examines the impact of different augmentations on model sensitivity to frequency. Gaussian encourages low-pass filtering, leading to low test error sensitivity at high frequencies but may discard valuable high-frequency information. Cutout promotes the use of high-frequency information, improving generalization performance but not robustness. Patch Gaussian allows high-frequency information at lower layers but still maintains relatively lower test error sensitivity at high frequencies. Patch Gaussian models maintain accuracy with high-pass filtered images, allowing high frequencies in lower layers while remaining robust to them. This contrasts with Gaussian models that learn low-pass filtering, making lower layers too invariant to high-frequency information. Cutout promotes high-frequency use but remains sensitive to test errors. Patch Gaussian matches Cutout and Baseline performance with high-frequency information. The impact of data distributions and noise on representations in neural networks has been studied extensively. Data augmentations alter the input distribution seen by the network, affecting the learned representations. Previous research on efficient coding and autoencoders has shown how filter properties change with noise. The performance of Cutout and Baseline is compared to Gaussian models in utilizing high-frequency information in images. In the unsupervised setting, filter properties change with noise, resulting in lower-frequency filters with Gaussian. Networks are least sensitive to low frequency noise where spectral density is largest. Performance drops at higher frequencies with increased noise. Training with more naturalistic noise may improve corruption robustness. Patching a transformation can prevent overfitting and maintain clean accuracy. To confirm robustness gains, a model is trained with adversarial training on a patch of the input. Adversarial training aims to achieve robustness to worst-case perturbations, leading to decreased clean accuracy. The models are trained with PGD, selecting hyper-parameters based on validation set performance while maintaining accuracy above 90%. The focus is on evaluating robustness to Common Corruptions rather than improving adversarial robustness. Training with Patch PGD improves robustness to unseen Common Corruptions without sacrificing clean accuracy, suggesting patching is a powerful tool for out-of-distribution generalization. Patch Gaussian, a simple data augmentation operation, also enhances robustness to common corruptions without affecting clean accuracy. Patch Gaussian improves clean accuracy and robustness by combining Cutout and Gaussian data augmentation operations. It is a simpler method compared to previous state-of-the-art techniques and can be used with other regularization strategies. Applying perturbations in patches can vary training distributions in the adversarial setting, indicating a need for further research on the robustness/accuracy trade-off. The study explores the trade-off between accuracy and robustness in out-of-distribution (o.o.d.) scenarios. Various hyper-parameters of Cutout and Gaussian data augmentation are tested, showing how Patch Gaussian can enhance robustness without compromising accuracy. Experiments are conducted on CIFAR-10 and ImageNet datasets using different models and training settings. The study uses a batch size of 128 and trains models with standard data augmentation. ResNet-50 and ResNet-200 models are used on ImageNet for 90 epochs with specific hyperparameters. Gaussian and Cutout augmentation techniques are applied with specific parameters. The study explores the use of Patch Gaussian augmentation on a RetinaNet detector with a ResNet-50 backbone trained on the COCO dataset. Patch sizes and \u03c3 max are selected based on specific hyperparameters, and the augmentation is tested beyond classification tasks. The study investigates the impact of Patch Gaussian augmentation on a RetinaNet detector with a ResNet-50 backbone trained on the COCO dataset. The models are trained for 150 epochs with specific parameters and evaluated on clean and corrupted data sets, showing improved detection performance with Patch Gaussian augmentation. The study explores the effects of Patch Gaussian augmentation on a RetinaNet detector with a ResNet-50 backbone trained on the COCO dataset. Results show better performance on small object detection and stricter IoU thresholds with Patch Gaussian, while Gaussian performs better on large object detection and less strict IoU thresholds. Training with Patch Gaussian leads to more robust models without compromising accuracy. Fourier analysis reveals high-frequency filters in models trained with Cutout* and Patch Gaussian, and high variance filters in Gaussian*. The study investigates the impact of Patch Gaussian augmentation on a RetinaNet detector with a ResNet-50 backbone trained on the COCO dataset. Results show improved performance on small object detection and stricter IoU thresholds with Patch Gaussian. Fourier analysis reveals high-frequency filters in models trained with Cutout and Patch Gaussian, and high variance filters in Gaussian. Future work will explore the importance of filters on sensitivity, and PGD training is found to enhance corruption robustness. The study explores the impact of Patch Gaussian augmentation on a RetinaNet detector with a ResNet-50 backbone trained on the COCO dataset. Results show improved performance on small object detection and stricter IoU thresholds with Patch Gaussian. When adjusting the patch size and scale, the model's sensitivity to high frequencies changes, moving it closer or further away from a Gaussian-trained model. This adjustment affects the model's invariance at the first layer and test error. The study examines the impact of Patch Gaussian augmentation on a RetinaNet detector with a ResNet-50 backbone trained on the COCO dataset. Results show improved performance on small object detection and stricter IoU thresholds with Patch Gaussian. Adjusting patch size and scale affects the model's sensitivity to high frequencies, influencing invariance at the first layer and test error. This sensitivity is reflected in the frequency-based analysis for models with different hyper-parameters of Patch Gaussian."
}