{
    "title": "BkxAh63phr",
    "content": "Humans can learn concepts and skills incrementally throughout their lives, exhibiting properties like non-forgetting, concept rehearsal, and transfer of knowledge. A unified framework for lifelong machine learning is proposed, utilizing weight consolidation parameters in deep neural networks. Parallels are drawn between this framework and human learning behaviors, serving as a conduit for understanding lifelong learning in both machines and humans. The text discusses lifelong learning in machines and humans, with a focus on continual or lifelong learning (LLL). The goal is to mimic human learning scenarios by presenting one concept-learning task at a time, with each classification task and labeled data presented sequentially. The example given is learning to classify hand-written characters like \"1\", \"2\", \"3\" in sequence. The text discusses lifelong learning in machines and humans, focusing on presenting one concept-learning task at a time, with each task and labeled data presented sequentially. The example given is learning to classify hand-written characters like \"1\", \"2\", \"3\" in sequence. The setting assumes mutually exclusive concepts and a set of background negative examples. This contrasts with standard multi-class machine learning where all training data is available at once. The example task sequence includes classes \"1\", \"2\", \"3\", and \"I\", with negative samples coming from a non-overlapping background set. In lifelong learning, the goal is to avoid catastrophic forgetting of old tasks when learning new tasks. The model should be able to learn new tasks without forgetting how to classify previously learned tasks. This requires a non-forgetting approach to prevent the need for retraining on old data. The ability to learn new tasks without forgetting old ones is crucial in lifelong learning. Models can expand neural networks or perform selective forgetting to make room for new tasks. Forward transfer allows for easier learning of new tasks after mastering earlier ones. Non-confusion arises when discriminating features for classification become insufficient with the emergence of new tasks. When learning new tasks, models may experience confusion between similar features, such as \"1\" and \"I\". To avoid this, samples of both features should be seen together during training to find discriminating features. This type of confusion is similar to humans learning to recognize animals, where distinguishing features may change as new tasks are introduced. Backward transfer involves knowledge transfer in the opposite direction as forward transfer. In the context of learning new tasks, backward transfer involves improving performance on old tasks by learning new ones. Previous works on Lifelong Learning (LLL) have focused on different aspects like non-forgetting and confusion reduction, but our framework encompasses all abilities including selective forgetting. Deep neural networks are popular for their ability to learn abstract features. In our study, we use fully-connected neural networks with two hidden layers to demonstrate a Lifelong Learning (LLL) approach. We modify weights using back propagation algorithms to minimize errors. Our unified framework utilizes \"stiffness\" parameters of weights to achieve LLL properties like non-forgetting and forward transfer. Different subsets of weights are frozen, free to change, or easily changed for each property. In a Lifelong Learning approach, weights in neural networks are categorized as frozen, free, or easily changed to facilitate different learning properties. Weight consolidation techniques like EWC aim to prevent important weights from changing to reduce catastrophic forgetting. The consolidation value for each weight can be adjusted during different stages of learning. This approach is expected to outperform existing methods like EWC and PNN in various metrics. In weight consolidation techniques like EWC, the consolidation target value \u03b8 target i is combined with the original loss L t using a balancing parameter \u03bb. Different values of b are used to control the flexibility of network weights, with b nf for non-forgetting, b tr for forward transfer, and b f ree for freely tunable weights. These consolidation hyperparameters are set by heuristic strategies to control the stiffness of weights in different parts of the network. Our approach utilizes hyperparameters to control the stiffness of weights in deep neural networks, achieving various lifelong learning abilities. These hyperparameters are determined heuristically but could potentially be learned. Comparing machine and human lifelong learning suggests that our model hyperparameters may be intrinsic to the brain's physiology. Future studies will explore the explicit learning or fine-tuning of these heuristics. Our approach is illustrated through learning hand-written numbers in a sequence. The training data includes positive examples for the class and background negative examples. A simple feed-forward network with two fully-connected hidden layers is used for training. This approach can be extended to more complex architectures like Convolutional Neural Networks, improving training and inference costs for computer vision tasks. Hyperparameters are set heuristically in the deep neural network. The hyperparameters in the deep neural network are set heuristically to exhibit various properties. The setting of these hyperparameters is described to demonstrate desired properties, with heuristics detailed in a follow-up technical paper. Key strategies include setting weight consolidation values for new tasks, adjusting values after learning to prevent forgetting, and setting transfer links based on task similarity. The b values of transfer links should be set to encourage forward transfer of representation and knowledge in few-shot learning. Weight consolidation values should be adjusted to resolve confusion between tasks. Unused task b values should be gradually reduced to allow controlled forgetting while learning new tasks. These hyperparameters mimic human learning phenomena like memory loss. In our model, we relate hyperparameters to human learning phenomena like memory loss and sleep deprivation. Starting with a small or medium network for task 1, we can expand it as more tasks are learned. Alternatively, starting with a large network and pruning it after each task is an option. For training class 1, all weights are adjustable. To prevent forgetting class 1 when training class 2, we increase network capacity by adding free neurons. In our model, we prevent forgetting class 1 when training class 2 by increasing network capacity with free neurons. The consolidation strength of weights for task 1 is set to be very large, while for task 2 it is small to achieve non-forgetting. Newly added nodes have small b values for weight updates via back-propagation. In the model, to prevent forgetting class 1 when training class 2, network capacity is increased with free neurons. The consolidation strength of weights for task 1 is set to be large, while for task 2 it is small to achieve non-forgetting. Newly added nodes have small b values for weight updates via back-propagation, encouraging forward transfer of skills from task 1 to task 2. Few-shot learning can occur to increasing extents, allowing new tasks to be learned with less data. Leveraging curriculum learning may further improve forward transfer and few-shot learning capacity. During training of class 2, only the loss from the class 2 output needs to be back-propagated. Mixing in a small amount of class 1 samples with background samples as negative examples of class 2 can reduce confusions between tasks 1 and 2. To prepare for class 3 training, apply a consolidation strength of b nf to all weights used by previous classes and extend each layer with new nodes. Forward transfer connections are added from class 1 and class 2 to the new class 3 nodes. During training of class 3, only the loss from the class 3 output needs to be back-propagated. The network may have learned to discriminate \"1\" and \"2\" by identifying straight strokes. Tasks 3 has also been individually learned well. Confusion may occur between visually similar classes like task 3 and class 1. When confusion occurs between visually similar classes like task 3 and class 1, the network can be trained using data from both classes to resolve the issue. Additional weights can be added if needed, and back-propagation of errors should only be applied to the confused classes. The consolidation of weights for class 2 should not be significantly affected during this process. In practice, confusion can occur between any pair of tasks when learning sequentially. Pair-wise confusion reduction can be applied to resolve all pair-wise confusions, starting with the highest confusion pairs. Important weights for class 2 are frozen, and additional capacity can be added if needed. Consolidation of weights during backward transfer for overall refinement is also done. In practice, confusion can occur between any pair of tasks when learning sequentially. Pair-wise confusion reduction can be applied to resolve all pair-wise confusions. Selective forgetting of task 1 is performed to learn an additional task 4 without adding many new weights. Skills learned for earlier classes have been utilized by later classes, but backward transfer of skills is needed for overall refinement of the model. Selective forgetting can be used to free up network capacity from previous tasks by determining the least important tasks based on usage frequency. This process allows for learning additional tasks without incurring significant computational costs. In the process of selective forgetting, less important tasks are identified based on frequency of use. Weight adjustments are made to free up network capacity for new tasks, sacrificing performance on the least important task in exchange for the ability to continue learning. This allows for learning new tasks without exceeding network capacity. When learning multiple tasks incrementally, the network gradually forgets less important tasks to make room for new ones. This process is similar to human memory, where old information is vaguely recalled. Training T tasks individually requires O(T) time complexity, with additional computation for confusion reduction and backward transfer. Proper forward and backward transfer of knowledge can reduce the overall training data needed, leading to less learning required. By encouraging forward and backward transfer of knowledge and minimizing sample storage, our approach aims to outperform related work in various metrics. The ability to transfer knowledge across tasks and control individual network weights allows for versatility in learning. This approach is detailed in a future manuscript. Our approach focuses on controlling individual network weights to mimic human learning behaviors. We discuss parallels between our model and human learning patterns, emphasizing adaptability and knowledge acquisition. The ability to make connections between experiences is similar to our approach's forward and backward transference, modulated by hyperparameters and rehearsal. In our approach, the b nf hyperparameter and rehearsal play a crucial role in memory retention and adaptation to new tasks. A large b nf value helps remember important information, while adding new nodes facilitates learning new tasks. Improper b nf values can lead to memory loss, similar to gradual memory loss in humans. Sleep deprivation is detrimental to cognitive performance related to memory. The proposed approach emphasizes the importance of rehearsal for memory retention and adaptation to new tasks. Without rehearsal, the model may struggle to distinguish between similar classes and lose the ability to transfer skills between tasks. Setting b tr to a large value and skipping forward and backward transfer steps hinders skill transfer, leading to rote learning without generalizing knowledge. This is akin to the memory abilities of Kim Peek. The proposed approach highlights the importance of rehearsal for memory retention and adaptation to new tasks. It contrasts with Kim Peek's memory abilities and early Alzheimer's disease stages. Existing LLL approaches focus on parameter-based, rehearsal-based, and dynamic network-based mechanisms, but none address all LLL abilities simultaneously. The LLL approaches aim to identify important weights in a neural network to prevent modification and avoid catastrophic forgetting. Various approaches like Elastic Weight Consolidation, biological complexity incorporation, unsupervised weight importance calculation, and Orthogonal Weights Modification have been proposed to address this issue. Orthogonal Weights Modification is a parameter-based approach that aims to restrict the movement of important weights to prevent forgetting. It uses regularization to combat catastrophic forgetting, reduce intransigence, and confusion. Unlike existing approaches, it leverages regularization for weight consolidation in a flexible manner, allowing for the modulation of consolidation strengths for maintaining task skills and benefiting from transference and refinement. It also incorporates the ability to selectively forget tasks in a controlled fashion. Rehearsal-based approaches combat catastrophic forgetting by storing past task data for further training, preventing information loss. Methods like Gradient Episodic Memory (GEM) and Meta-Experience Replay (MER) require samples from previous tasks to restrict new-task loss and align gradients. Our unified approach for lifelong learning minimizes the need for old task data during new task training, using it only to reduce class confusions and for backward transfer. Unlike other methods, our approach leverages the bias of the last fully-connected layer towards newer classes and corrects it with a two-parameter linear model per task. Dynamic network-based approaches aim to consolidate information from multiple tasks into the same set of weights. Progressive Neural Networks (PNNs) extend the network for new tasks by adding new columns while freezing previous column weights. Unlike PNNs, our approach adds lateral connections from new columns to older ones for backward transfer and addresses confusion in single-head evaluation. Our proposed approach addresses the criticism of quickly growing network size in Progressive Neural Networks (PNNs) by supporting selective forgetting and variable-size additional columns. Several approaches with more efficient resource allocation, such as Dynamically Expandable Networks (DENs), have been proposed to extend the network only as much as necessary. DENs work by identifying existing parameters that can be reused and retraining neurons when necessary for new tasks. The proposed approach addresses the issue of network size growth in Progressive Neural Networks (PNNs) by supporting selective forgetting and variable-size additional columns. Dynamically Expandable Networks (DENs) identify existing parameters for reuse and retrain neurons as needed for new tasks. DENs facilitate forward transfer but do not consider backward transfer or selective forgetting. Reinforced Continual Learning (RCL) optimizes layer expansion for new tasks using reinforcement learning, keeping learned parameters fixed for previous tasks. RCL aims to balance accuracy with network complexity. In this work, a unified approach for lifelong learning is presented, addressing key aspects such as non-forgetting, transfer learning, confusion reduction, few-shot learning, and selective forgetting. The approach aims to reduce the need for extensive training data while allowing a single model to learn multiple tasks. By utilizing weight consolidation, the approach covers all lifelong learning skills with a small number of hyperparameters dynamically applied to groups of weights. The parallels with human learning are also examined. The model's response to hyperparameter settings is compared to human learning effects on the brain."
}