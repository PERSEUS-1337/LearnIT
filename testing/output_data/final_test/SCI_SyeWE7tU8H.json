{
    "title": "SyeWE7tU8H",
    "content": "Biological neural networks face constraints on connection weights, which determine the solution spaces for computational tasks. The size of these constraint spaces influences neural circuit development. Analytical approximations and bounds are developed for maximum entropy degree distributions under these constraints. Evidence from a fly brain connectome suggests a developmental progression in neural circuitry. The capacity of neural networks for associative learning in the fly brain is influenced by their architecture, which is shaped by developmental programs and slow structural plasticity. High-throughput connectomics studies are revealing the architecture of neural circuits, allowing for the examination of biological circuit structures for signatures of developmentally inspired cost functions governing network architectures. Developmental programs and slow structural plasticity shape neural circuit architecture to stabilize learning and memory. Synaptic scaling in pyramidal neurons regulates total synaptic input strength. Simple models of resource limitations and homeostatic constraints on synaptic weights are considered to optimize flexibility in weight configurations. The solution space for these constraints depends on the number of connections, and the optimal degrees of flexibility are computed under different conditions. The study explores the optimal flexibility of neural connections under various constraints on connection strengths. Using maximum entropy degree distributions, the researchers analyze a Drosophila melanogaster connectome to determine which constraints best explain neuron degree distributions at different developmental stages. They find that a fixed net weight predicts Kenyon cell inputs and outputs, while mature cells are better explained by a random wiring model, indicating a developmental progression in mushroom body wiring cost functions. The study focuses on a simple model of synaptic interactions, where neurons have a degree K and total strength of projection J. The flexibility of constraints on synaptic weights is measured by the size of the solution space, approximating the size of the constraint space for any K. The size of the constraint space for synaptic weights approximates the number of allowed weight configurations for a neuron with degree K. The flexibility of constraints serves as a simple bound on the computational capacity of a neuron, with an upper bound on mutual information between inputs and outputs. The net synaptic weight is bounded, which can be interpreted as a limit on presynaptic vesicles or postsynaptic dendritic tree availability. The summed synaptic weight is scaled based on individual synaptic weights, with different strengths corresponding to different values of p. The solution space for this constraint is represented by a volume under a simplex, with the number of weight configurations proportional to this volume. This can also be seen as the count of available configurations when synaptic weights are measured relative to incremental changes. In the continuum limit, the volume under the simplex approximates the number of synaptic weight configurations. The optimal degree, K*, maximizes the volume under the simplex and is linearly related to total synaptic weight. For p=1, J=1/e, the volume is independent of K. The volume decreases for J<1/e and increases for J>1/e. A model of homeostatic synaptic scaling considers fixed net weight constraints, requiring synaptic weights to live on surfaces instead of volumes under them. The surface area of the simplex increases with the net excitatory weight, but has a maximum at positive K. The optimal degrees obey a linear relationship, similar to the constraint on the maximum possible synaptic weight. The area decreases for J < 1/e and increases for J > 1/e, with a model for resource limitations at individual connections. The volume of the hypercube, C = W K p\u22121 K, measures the size of the solution space. The volume exhibits a maximum at positive K when p < 1. The upper limit for each connection strength is independent of K. The maximum entropy distribution on the synaptic weight configurations J under the constraint is the uniform distribution over its solution space, S K. The text discusses the volume under a regular simplex with vertices at JK p, where a developmental process selects K without considering weight configurations. The maximum entropy distribution for synaptic weight configurations J is uniform over the union of S1 to SK. The degree distributions are proportional to the size of the solution space, with predictions for neural degree distributions tested using electron microscopic reconstruction of connectivity in the larval Drosophila melanogaster's mushroom bodies. The text discusses the anatomical measurements of Drosophila melanogaster's mushroom bodies, focusing on the number of synapses and their relation to physiological synaptic weights. It also mentions the morphological classification of Kenyon cells based on dendrite structure, with single-claw KCs considered more mature than multi-claw KCs. The text discusses the anatomical measurements of Drosophila melanogaster's mushroom bodies, focusing on the number of synapses and their relation to physiological synaptic weights. Single-claw KCs are more mature than multi-claw KCs. Models with bounded individual synaptic weights provided poor explanations for KC connectivity degrees. Binomial wiring model had the highest evidence for single-claw KCs, while fixed net weight had the highest evidence for young and multi-claw KCs. Less mature KCs have connectivity governed by a homeostatically regulated total input and output strength, while as KCs mature, other factors dominate their wiring. The probability of a neuron having a certain degree is proportional to the space of allowed circuit configurations with that number of partners. This concept traces back to Elizabeth Gardner's work on the storage capacity of the perceptron for random input patterns. In contrast to previous studies on neural circuit connectivity, this work examines the hypothesis that the size of the space of allowed configurations influences the distribution of the number of connections in neurons. The study also explores constraints on total connection strengths and individual connection strengths. In contrast to previous studies on neural circuit connectivity, this work examines the idea that the number of synaptic partners to a neuron may be structured to allow for flexible connectivity configurations. Experimental studies have shown evidence of homeostatic regulation of total synaptic weights in Drosophila melanogaster neurons. In machine learning, regularization of weights is common to reduce errors. L2 and L1 regularization constrain weights in different ways. Examining regularization alone, the solution spaces for weight constraints depend on the degree, leading to consideration of cost functions for connectivity degrees. These biologically inspired cost functions may aid in architecture search. The Rademacher complexity of a set is bounded. The Rademacher complexity of a set is bounded by its covering number, which is the number of spheres needed to cover the set. Haussdorff measures of solution spaces for different constraints are used to measure configuration flexibility. There is potential for a relation between this approach and Rademacher complexity."
}