{
    "title": "HJghQ7YU8H",
    "content": "In this paper, the authors investigate the existence of functional modularity in Deep Neural Networks (DNN) trained through back-propagation. They aim to dissect hidden layers into task-specific modules, called Functional Modules, by grouping hidden neurons that are functionally related for predicting similar data samples. They propose a method to identify these Functional Modules using bi-clustering attribution scores of hidden neurons. The study explores the presence of functional modularity in Deep Neural Networks (DNN) trained through back-propagation. It aims to identify task-specific modules, called Functional Modules, by grouping functionally related hidden neurons for predicting similar data samples. The research investigates whether DNNs exhibit functional modularity similar to real brain networks. Functional Modules are groups of hidden neurons in DNNs that are functionally related for predicting similar data samples. These modules serve as the basic functional unit and can be identified through biclustering attribution scores. They play a critical role in discriminating data samples, learn rich representations, and detect specific feature patterns. Researchers believe that artificial neural networks exhibit modularity, similar to real brain neuronal networks. This modularity is seen in hidden neurons co-adapting together as modules for prediction, inspiring techniques like Dropout for DNN regularization. However, identifying modularity in DNNs remains challenging as traditional community detection methods are not directly applicable. Biclustering is favored over standard clustering methods for identifying modularity in densely-connected acyclic graphs in DNNs. Neuron attribution methods are also utilized for help in this process. Spectral co-clustering is chosen for biclustering in DNNs to produce non-overlapping biclusters with strong connections. Neuron attribution is easier in artificial neural networks than real neurons, aiming to assign importance scores to hidden neurons based on their predictive significance for samples. This is done using internal weights and feedforward structure of DNNs to compute attribution scores. Neuron attribution methods like DeepLIFT and integrated gradients assign importance scores to hidden neurons based on their predictive significance. These methods can identify important hidden neurons relevant to specific predictions. Our approach aims to find Functional Modules in hidden neurons by constructing a neuron-sample matrix with attribution scores. Our approach involves constructing a neuron-sample matrix with attribution scores to identify functional modules in hidden neurons. This matrix is then used for spectral coclustering to group neurons and samples with consistent high attribution values. The approach involves constructing a neuron-sample matrix with attribution scores using DeepLIFT. Spectral co-clustering is then applied to find biclusters with high values, grouping neurons and samples with consistent high attribution values. In the approach, biclusters are formed where each neuron and sample belongs to one bicluster. A pre-trained DNN model is used for visual classification on MNIST, with a 4-layer feedforward rectified architecture. The second convolutional layer with 1600 hidden neurons is chosen for analysis. The biclustering algorithm successfully constructs a sparse neuron-sample matrix, with certain groups of hidden neurons highly correlated for predicting data samples. Visualization of the matrix reveals a checkerboard pattern, indicating strong correlations. The neuron-sample matrix shows bicluster labels with coherent feature patterns and high attribution scores for a subset of hidden neurons on specific samples. Samples within the same bicluster exhibit similar feature patterns, indicating the presence of Functional Modules. The biclusters show coherent feature patterns and similar sample distributions, indicating the presence of Functional Modules. Neurons within a bicluster do not exhibit spatial relationships, even in non-convolutional layers. Removing hidden neurons affects the DNN's performance, highlighting the importance of Functional Modules in discriminating samples. In an experiment to evaluate the performance of a DNN, hidden neurons are gradually removed by bicluster analysis. The accuracy drop is compared with different baseline methods for neuron ablation, showing that ablation by module results in the most significant accuracy decrease. This highlights the importance of Functional Modules in discriminating samples. The study demonstrates the importance of Functional Modules in discriminating data samples by using spectral coclustering on attribution scores of hidden neurons. The research suggests that these modules play a crucial role in identifying functionally-related neurons within a layer. However, the study acknowledges the need for further testing on different layers, activation functions, and models to gain more generalizable insights."
}