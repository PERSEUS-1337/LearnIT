{
    "title": "ryxDUs05KQ",
    "content": "The novel algorithm DSGAN is developed from traditional GAN and addresses the challenge of collecting training samples for the target distribution $p_{t}$. It utilizes the differences between two distributions $p_{\\bar{d}}$ and $p_{d}$ to learn $p_{t} using samples from $p_{d}$ and $p_{\\bar{d}$. DSGAN is a flexible algorithm that can generate samples from different target distributions, including out-of-distribution scenarios. It is validated through applications like semi-supervised learning and adversarial training. The convergence of DSGAN is theoretically analyzed in the context of unsupervised learning in machine learning. Generative approaches, like GAN, are used to learn data distribution and create new samples, such as images and speech synthesis. GAN, while effective, can be challenging to train due to multiple losses and consists of a generator and discriminator functions. The generator and discriminator functions in GAN are neural networks trained in a minimax two-player game. The generator maps latent space samples to a distribution to fool the discriminator. Recognizing unseen data as \"abnormal\" is crucial in one-class classification. Unsupervised algorithms for one-class classification focus on handling unseen data. Some approaches use supervised learning with unbalanced data to address the issue. Complementary data and adversarial attacks are related challenges. Generating unseen data with GANs can be beneficial for various applications, but traditional GANs require a large amount of training data for unseen classes, leading to a contradiction. This motivates the need for a new design approach. The proposed DSGAN aims to generate unseen data by considering the distribution of unseen data as the difference of two distributions, which are relatively easy to obtain. Unlike traditional GANs where the target distribution is equal to the training data distribution, DSGAN treats both distributions as different. The novel algorithm DS-GAN proposes to approximate the target distribution by minimizing the statistical distance between the mixture distribution of two distributions. DSGAN can learn the generator distribution under mild conditions and has the flexibility to learn different target distributions in semi-supervised learning applications. DSGAN aims to learn various target distributions in semi-supervised learning and adversarial training. In semi-supervised learning, samples must be a linear combination of labeled and unlabeled data, while in adversarial training, samples are considered out-of-distribution with bounded distortion. Experimental results confirm DSGAN's ability to learn these distributions effectively across different datasets. The paper outlines DSGAN in Sec. 2, presents theoretical results in Sec. 3, showcases applications in Sec. 4, and provides experimental results in Sec. 5, concluding with future research directions in Sec. 7.2. The proposed method DSGAN aims to learn the target distribution p_t by generating samples in high-density areas of pd and low-density areas of pd. The generator and discriminator in GANs are formulated with inputs drawn from p_z in an M-dimensional space, where the generator function G maps to data space with parameters \u03b8_g. The discriminator D in DSGAN outputs a scalar representing the probability that input x belongs to real data. Unlike traditional GANs, real data comes from pd and fake data from a mixture of pd and pg. Training involves alternating k steps of training D and one step of training G using minibatch stochastic gradient descent. Back propagation updates \u03b8 d and \u03b8 g in DSGAN. Gradients are computed using m samples in a minibatch. DSGAN faces issues like mode collapse and overfitting. Literature suggests ways to improve these problems. The goal is to learn the target distribution p t, not the training data distribution. Training involves minibatch stochastic gradient descent with k steps for the discriminator. \u03b1 represents the ratio between p g and p d in the mixture distribution. DSGAN uses \u03b1 as the ratio between p g and p d in the mixture distribution. The discriminator is updated using minibatches of noise samples, while the generator is updated using stochastic gradient descent. DSGAN is able to generate boundary samples around the training data by adjusting the density and support set of the distributions. DSGAN utilizes \u03b1 to adjust the ratio between p g and p d in the mixture distribution. By updating the discriminator with noise samples and the generator with stochastic gradient descent, DSGAN can generate boundary samples around the training data. The method is demonstrated on a 2D swissroll dataset, showing the ability to generate low-density samples and validate on high-dimensional datasets like MNIST. The generator in DSGAN tends to output digit \"7\" with high probability when x is digit \"1\". The distribution of the generator prefers to output samples from high-density areas of the data distribution. The objective function aims to minimize the JensenShannon divergence between the mixture distribution and the data distribution. The capacity of the generator and discriminator is assumed to be infinite in a nonparametric setting. The distribution of samples drawn from the generator is defined as pg. The optimal discriminator for G in DSGAN is shown, and minimizing V(G, D) with the optimal discriminator is equivalent to minimizing the Jensen-Shannon divergence. The optimal solution for D given G is discussed, followed by finding the optimal G with D fixed. The assumption in Theorem 1 may be impractical in real applications. In real applications, the assumption in Theorem 1 may be impractical. DSGAN still performs well despite this. The support set of pg is within the difference of support sets of pd and pd, achieving the global minimum to generate the desired pg. If the global minimum of the virtual training criterion is achieved, the generator tends to output samples in high-density areas of pd. The generator in DSGAN tends to output samples in high-density areas of pd and low-density areas of p d. The discriminator reaches its optimal value given G in Algorithm 1. DSGAN can be applied to semi-supervised learning and adversarial training, acting as a \"bad generator\" and generating adversarial examples in low-density areas of training data. Semi-supervised learning uses a small number of labeled data and a large amount of unlabeled data, with existing works based on generative models like VAE and GAN showing good results. The generator in DSGAN generates samples in high-density areas of pd and low-density areas of p d. In semi-supervised learning, a bad GAN is needed to obtain good results, where the generator should generate complement samples in low-density areas to help the discriminator learn correctly. DSGAN generates samples in high-density areas of pd and low-density areas of p d to help the discriminator learn correct decision boundaries. Complement samples are crucial for enhancing the robustness of neural networks against adversarial attacks. Adversarial training has been shown to be more effective in defending against white-box attacks compared to other strategies. Adversarial training involves a min-max game to find adversarial examples and train the model to minimize loss. DSGAN generates adversarial examples directly for fine-tuning the model. The training procedure of DSGAN can be enhanced with other GAN extensions like WGAN. DSGAN's training can benefit from GAN extensions like WGAN-GP to improve stability and reduce mode collapse. The method is applied in semi-supervised learning on benchmark datasets like MNIST. DSGAN generates complement samples in the feature space to ensure correct classification of unlabeled data. DSGAN generates samples in the feature space by combining labeled and unlabeled data, ensuring they do not fall into the real data distribution. The neural network parameters are optimized for semi-supervised learning tasks on MNIST, SVHN, and CIFAR-10 datasets. Our DSGAN model performs well on MNIST, SVHN, and CIFAR-10 datasets without relying on additional density estimation networks like PixelCNN++. Results show competitiveness with state-of-the-art methods, with hyperparameters detailed in TAB3 and results in TAB1. PixelCNN++ is a top density estimation network but has limitations in estimating density in dynamic feature spaces during training. This affects models in BID4, with our results slightly below badGAN BID4 but outperforming other methods. The complexity of image patterns challenges generators with insufficient capacity to learn the desired distribution. However, improvements in GANs are expected to address this issue, with badGAN relying on feature matching in their objective function to learn distributions. Our proposed DSGAN aims to improve classifier robustness against adversarial examples by generating adversarial examples via GAN instead of gradient descent. By assigning a convolution of distributions, samples from the generator will be in low-density areas. The distortion is linked to the range of the uniform distribution, which may pose challenges in training the generator. Our proposed semi-supervised adversarial learning approach involves training a baseline classifier on labeled training data, then training a generator to produce adversarial examples as additional unlabeled data. The classifier is fine-tuned with all training data and generated samples to minimize a combined loss function. The additional entropy loss in the model prevents attacks by adversarial examples. The weight parameter balances the importance of labeled and unlabeled data, making the classifier more robust. Evaluation against various adversaries is done using different distortion norms. The study evaluates the model's robustness against different adversaries using various attack methods and distortion norms. Adversarial examples are generated and the model's accuracy in resisting attacks is measured. Two baseline networks are proposed for comparison, one trained with all data and the other with noisy inputs for added protection. Our method demonstrates stronger robustness against adversaries compared to the second baseline model, which uses uniform noise. Increasing the weight parameter w from 1 to 10 improves the model's robustness. Introducing noise to inputs in both our method and the baseline models helps improve accuracy and robustness, with our method outperforming others across a wide range of w values. The training data distribution is smoothed after applying noise, with most samples still concentrated in high-density areas. Our method uses a generator to produce low-density data, helping the model resist adversarial attacks. Combining our method with the second baseline model may improve performance. Previous work includes BID25, which generates samples of unseen classes through adversarial learning but requires solving an optimization problem for each sample. DSGAN is a new GAN architecture that can generate diverse unseen samples without the need for unseen data. It is more flexible in generating different kinds of unseen data compared to other methods like BID4 and BID13. DSGAN is a new GAN architecture that can generate diverse unseen samples without the need for unseen data. It is more flexible in generating different kinds of unseen data compared to other methods. DSGAN is fully unsupervised and can produce samples from the target distribution by leveraging the difference between the densities of any two distributions. It is useful in scenarios where collecting samples from the target distribution is challenging. DSGAN is applicable to semi-supervised learning and adversarial training, with empirical and theoretical results validating its effectiveness. Additionally, DSGAN can easily incorporate improvements from traditional GANs. DSGAN aims to improve traditional GANs by minimizing C(G) with a constraint that increases on pg(x) and converges to 0. The Jensen-Shannon divergence returns a minimal value of 0 when both distributions are the same, specifically when \u03b1pd(x) \u2264 pg(x). This implies the existence of a solution that satisfies the constraint. The last inequality implies a solution exists for DISPLAYFORM4. The proof idea from Proposition 2 in BID6 shows that if f(x) is convex for every \u03b1, then DISPLAYFORM0 includes the derivative at the maximum point, leading to convergence with small updates of pg. A trick is provided to stabilize training by reformulating the objective function V(G, D) in (2) as DISPLAYFORM0. Sampling (1 \u2212 \u03b1)m and \u03b1m samples from p z and p d respectively reduces computation cost in training. Empirical validation shows training with (10) performs better than (2). In empirical validation, training with (10) outperforms (2) due to the linearity of expectation. Hyperparameters were adjusted to align generated samples with assumptions, aiming for 90% compliance. Tuning hyperparameters is crucial, as shown in TAB3, to ensure fair comparison with other methods. In order to compare with other methods, generators and classifiers for MNIST, SVHN, and CIFAR-10 are the same as in previous works. An additional discriminator in the feature space is designed, with architecture similar across datasets. MNIST is a simple dataset with fully connected layers. Batch normalization or weight normalization is used for stable training. Gaussian noise is added before each layer in the classifier, showing positive effects for semisupervised learning. The architecture for semisupervised learning is shown in TAB4 and TAB6 for SVHN and CIFAR-10 models. Differences include the number of convolutional filters and types of dropout. Training alternates between optimizing D and G, with k being crucial to prevent mode collapse. For semi-supervised learning, k is set to 1 for all datasets. DSGAN is trained for 50 epochs to generate adversarial examples, followed by finetuning the baseline classifier for 50 epochs. In the experiments for adversarial training on CIFAR-10, the generator and discriminator are the same as those in semi-supervised learning. The architecture is modified by removing dropouts and Gaussian noise, decreasing the number of layers, and increasing the number of layers following the feature space to 3. The sub-network after the feature space is made non-linear. k is set to 5 in all experiments, and additional results are shown in FIG12 with different values of w."
}