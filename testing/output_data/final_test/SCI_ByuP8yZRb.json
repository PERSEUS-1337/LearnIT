{
    "title": "ByuP8yZRb",
    "content": "Adversarial feature learning (AFL) involves training neural networks to deceive adversaries predicting sensitive information. The success of AFL depends on the adversary chosen. A novel adversary design called Multiple Adversaries over Random Subspaces (MARS) is proposed to address vulnerabilities in deceiving easily fooled adversaries. The proposed method utilizes an ensemble of independent classifiers to predict sensitive variables from different subsets of representations, making it less vulnerable. Empirical validations on three user-anonymization tasks demonstrate that the method achieves state-of-the-art performance without significantly impacting data utility. The significance of designing the adversary for improving AFL performance is highlighted by the implications of using deep neural networks (DNN) in various fields. Incorporating desired constraints into learned representations is a key challenge when applying DNN to real-world data, especially to ensure privacy and fairness in decision-making. Adversarial feature learning (AFL) aims to censor sensitive variables like gender, age, or race from DNN representations. AFL uses an adversarial training framework to deceive a classifier predicting sensitive variables, ensuring little to no information leakage. In this paper, a novel design of adversary for improving the performance of AFL, called multiple-adversaries over random subspace (MARS), is proposed. The success of AFL depends on the choice of the adversarial classifier, and the design of the adversary is crucial for its performance. Existing studies have failed to address how to design the adversary to improve the quality of AFL. The proposed MARS design considers the vulnerableness of the adversary and is motivated by recent reports. The proposed design, MARS, incorporates multiple adversaries to predict sensitive variables from different subsets of representations, making it less vulnerable to encoder updates. Empirical validation shows MARS outperforms baselines using single or multiple adversaries and is less vulnerable. The paper introduces MARS, a design with multiple adversaries to predict sensitive variables, making it less vulnerable to updates. It emphasizes the importance of adversary design in AFL and achieves state-of-the-art performance in censoring representations. The proposed method using three user-anonymization tasks allows for learning more anonymized representations with minimal performance degradation. It improves the probability of correctly predicting user IDs from learned representations compared to single or multiple adversaries. Censoring representation aims to obtain unbiased features less affected by certain variables for reasons like fairness or privacy. The primary goal of censoring representation is to obtain an encoder E that reduces information about S while maintaining information about Y. This involves a joint optimization problem with input variable X, encoder E, weighting parameter \u03bb, and loss functions V and L. S can be any form of variables like binary, categorical, or continuous. In this paper, the focus is on a variant of censoring representation tasks where the goal is to learn an encoder E with deep neural networks while considering S as the user ID. Adversarial feature learning (AFL) is a proposed approach for this task, where an external neural network D measures the information V (E(X), S). AFL updates the encoder E weights based on how accurately S can be predicted from the representations R, aiming to reduce the information about S in the updated representations. Adversarial feature learning (AFL) solves joint optimization problems by removing sensitive information from representations for fair classification tasks. AFL has shown superior performance compared to other methods like Learned Fair Representation and variational fair auto-encoder. This paper addresses the challenge of improving the performance of AFL by introducing a new design consideration of adversary vulnerability. Previous studies have shown that using high-capacity networks as adversaries may not always improve performance, and our work validates this by proposing a method to instantiate the concept. The concept of multiple adversaries has been proposed and verified in the context of image generation with adversarial training. The proposed method, multiple-adversaries over random subspaces (MARS), extends the concept of multiple adversaries by introducing diversity for censoring representations in adversarial feature learning. It considers different subsets of features for each adversary to prevent vulnerability. The paper also discusses the applicability of MARS in other adversarial training applications such as image/text generation and domain adaptation. The proposed method, MARS, uses an ensemble of diverse classifiers to make the adversary less vulnerable, resulting in improved performance of AFL. Empirical experiments show that MARS outperforms methods with single adversaries or simple ensemble of adversaries. The technique benefits from variance reduction and is widely used in various methods like random forest. The proposed method, MARS, utilizes an ensemble of diverse classifiers to enhance performance in AFL. It outperforms single adversary methods and simple ensembles. The technique benefits from variance reduction and is commonly used in methods like random forest. The comparison between AFL with an adversary and multiple adversaries over random subspaces is discussed, focusing on training adversaries and using adversary information. Each adversary in MARS is trained to predict over a randomly selected subset of features to maximize expected results. The proposed method, MARS, uses an ensemble of diverse classifiers to improve performance in AFL by training adversaries to predict over randomly selected subsets of features. The optimization problem for each adversary involves maximizing expected log-likelihood, with integration of predictions to train the encoder. The encoder is trained to minimize a probability distribution parameterized by an ensembled adversary. The proposed method, MARS, utilizes an ensemble of diverse classifiers to enhance performance in AFL by training adversaries on randomly selected feature subsets. The encoder is trained to minimize a probability distribution parameterized by an ensembled adversary. The algorithm optimizes the model by updating weights of E and M. Two datasets are used to demonstrate MARS' effectiveness in human activity recognition using wearable data, focusing on anonymized representations while maintaining classification performance. The USC-HAD dataset contains sensory readings from body-worn, object-based, and ambient sensors for gesture and locomotion recognition tasks. The dataset includes 113 real-value sensory readings per record, with 18 class activities for gesture recognition and 4 class locomotion activities for locomotion recognition. Sampling frequency of 30 Hz produced 57,790 samples using a sliding window procedure. Training/validation sets were from subjects 2-4, while subject 1 was used for testing. The dataset consists of 14 subjects (7 males and 7 females) with 12 activity classes. MotionNode, a 6-DOF inertial measurement unit, recorded sensory values from accelerometers for gesture and locomotion recognition tasks. The dataset included 172,169 samples with subjects 1-10 used for training/validation and subjects 11-14 for testing. The encoder E was parameterized using convolutional neural networks (CNN) and logistic regression for M, trained with the Adam algorithm over 150 epochs. The optimization process involved using annealing heuristics for weighting parameter \u03bb during training. An evaluator was trained to assess the level of anonymization achieved by the representations learned. The efficacy of the method was demonstrated by comparing different approaches, including standard CNN and variants with single or multiple adversaries. The study compared different approaches for anonymization, including MA, MARS, logistic regression (Adv-LR), DNNs, ensemble of DNNs (MA-DNN), and ensemble of DNNs over random subspaces (MARS-DNN). Adversaries were parametrized by MLP with 800 hidden units, and evaluators included LR, MLP with 50 hidden units, and MLP with 800 hidden units. The study compared different approaches for anonymization using various models like logistic regression, DNNs, and ensemble methods. Results showed that for small-capacity evaluators, a single adversary performed better, but for high-capacity evaluators, the proposed method outperformed baseline methods. Increasing training iterations for the adversary did not improve performance significantly. Increasing the iterations of training the adversary did not significantly improve performance, as demonstrated by weak performance improvements of Adv 2 or Adv 5 against Adv. Qualitative evaluation was also conducted by visualizing learned representations using t-SNE BID9. Random sampling of 1,000 examples from validation sets and reducing data dimension with principal component analysis was done. One method failed to achieve good final performance while the other succeeded, despite similar accuracy during training. For example, in the Opp-L dataset, MA-DNN and MARS showed similar performance curves during training, but MARS outperformed with a score difference of more than 0.10 at the end. The training iterations of the adversary did not significantly improve performance. MARS outperformed MA-DNN with a score difference of more than 0.10 at the end, indicating that accuracy alone is not the sole factor determining success in AFL. The update of E affects the \u2212 log q D k, with MARS showing more varied influences compared to MA. Figures compare performance between different K and \u03b1 values. The study proposed MARS, a method incorporating multiple adversaries with different roles for censoring representations, specifically user-anonymization for wearable data. Results show that using subspaces gives lower accuracy on predicting S, and the number of discriminator K affects accuracy on S. The proposed method outperformed several baselines, providing well-anonymized representations. Each adversary in MARS has a diverse role. The proposed method MARS incorporates multiple diverse adversaries for robust user-anonymization in wearable data. Results show superior performance in removing specific factors compared to previous methods. The design of diverse-views adversaries and stronger encoders contribute to its effectiveness. Capacity or accuracy of the adversary alone does not determine success, as shown by MARS outperforming MA with larger capacity. Final performance of adversarial feature learning can vary even with similar accuracy during training. The paper discusses the importance of diverse adversaries in adversarial feature learning for user-anonymization in wearable data. It suggests using more sophisticated methods for subset selection and exploring different ways to achieve diversity in adversaries, such as constraining weights or adding different noises. This approach can improve the effectiveness of the adversarial feature learning process. The MARS approach in adversarial training is applicable to various applications, including image generation. It does not rely on domain-specific settings, making it versatile for different applications. Using multiple adversaries in feature spaces can prevent mode collapse and improve image generation quality. Generative Multi Adversarial Networks also demonstrate the benefits of multiple adversaries in generating better images. Enhancing the diversity of discriminators with asymmetric adversaries can help generate better images and avoid mode collapse. Table 2 displays the selected \u03bb values for different datasets and baselines, but the relationship between the best \u03bb and task difficulty is not clear."
}