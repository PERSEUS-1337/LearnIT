{
    "title": "rylK-kBYwr",
    "content": "To address the challenge of developing an end-to-end multi-domain task-oriented dialogue system, a novel Multi-level Neural Belief Tracker is proposed. This tracker helps the dialogue agent obtain complete belief states from all relevant domains and process various types of information to shape context-aware and task-specific responses to humans. The Multi-level Neural Belief Tracker is a novel approach that tracks dialogue belief states at both slot and domain levels independently. It achieves state-of-the-art performance on the MultiWOZ2.1 benchmark and integrates with generation components for end-to-end dialogue tasks. The Dialogue State Tracking module updates dialogue states at each turn to steer the conversation towards task completion. Task-oriented dialogues can be single-domain or multi-domain. In single-domain dialogues, tasks are completed within one domain, while in multi-domain dialogues, tasks can come from different domains. Dialogue states in multi-domain dialogues should include inform and request slots from all corresponding domains up to the current turn. Limited contributions have been made towards developing multi-domain task-oriented dialogue systems compared to single-domain systems. Developing end-to-end systems for multi-domain task-oriented dialogues presents challenges due to the complexity of belief states and the need to incorporate information from multiple domains to shape relevant responses. Directly applying single-domain dialogue methods is not straightforward, as belief states extend across domains. A possible solution is to process a multi-domain dialogue for N D times for N D domains. The proposed end-to-end dialogue system approach tracks dialogue states in multiple domains by using a Multi-level Neural Belief Tracker and multi-head attention layers for processing various types of information. This allows for shared learning of common slots among domains and learning of unique slots in each domain. The end-to-end dialogue system utilizes multi-level neural belief tracking and multi-head attention layers to process information from dialogue states, request slots, and DB query results. It achieves state-of-the-art performance in DST, task-completion, and response generation in the MultiWOZ2.1 corpus. Our work focuses on achieving competitive measures in Inform and BLEU metric in the context of multi-domain DST. Previous research has mainly dealt with single-domain dialogues using specific corpora like WOZ and DSTC2. Recent efforts have been made towards multi-domain DST, with models categorized into fixed-vocabulary and open-vocabulary approaches. Our approach aligns more closely with the open-vocabulary models that derive candidate sets based on dialogue history. Our approach in multi-domain DST focuses on dynamically generating dialogue state based on input dialogue history. Unlike prior work, our Multi-level Neural Belief Tracker learns domain-level and slot-level signals independently and combines them in a Late Fusion manner. This differs from conventional end-to-end dialogue systems composed of separate modules for NLU, DST, Dialogue Policy, and NLG. Our approach aligns with open-vocabulary models for deriving candidate sets based on dialogue history. Our work focuses on integrating conventional components into a single network architecture for dialogue agents. We incorporate NLU and DST modules together, with additional supervision for tracking user goals. Some models omit the DST component by formulating entity attributes into memory form. These models perform well in small-scale corpora like In-Car Assistant. Incorporating NLU and DST modules in a single network architecture for dialogue agents improves performance in small-scale corpora like In-Car Assistant, but scaling to large knowledge bases in multi-domain settings is challenging. Task-oriented dialogue systems aim to generate responses that are contextually appropriate and task-related with correct entity results. In multi-domain settings, responses should also be domain-related with the correct domain-specific information for users. Incorporating NLU and DST modules in a single network architecture for dialogue agents improves performance in small-scale corpora like In-Car Assistant. We propose a Multi-level Neural Belief Tracker to track belief states at both domain and slot levels for multi-domain dialogues. Our model utilizes previous belief states as input and adopts the attention-based principle of Transformer network for comprehensive information processing. The proposed model consists of three main components: Encoders encode various dialogue elements into continuous representations, Multi-level Neural Belief Tracker tracks belief states at domain and slot levels using attention layers, and Response Generator incorporates contextual information for generating system responses. Attention mechanisms and residual connections are employed for effective information processing. The proposed model includes encoders for encoding dialogue elements, a Neural Belief Tracker for tracking belief states, and a Response Generator for generating system responses. Attention mechanisms and residual connections are used for effective information processing in the model. The encoder encodes text sequences into continuous representations using token-level trainable embedding layers and positional encoding functions. The proposed model includes encoders for encoding dialogue elements, a Neural Belief Tracker for tracking belief states, and a Response Generator for generating system responses. Each user utterance is tokenized and processed along with past dialogue history. Dialogue belief states are created from previous turns based on slot names and values. The proposed model includes encoders for encoding dialogue elements, a Neural Belief Tracker for tracking belief states, and a Response Generator for generating system responses. Belief sequences encode past dialogue states of multiple domains. Slot and domain tokens are used as input to the state tracker for slot-level and domain-level signals. Positional encoding is used except for slot and domain tokens. Embedding weights are shared among all encoders of source sequences. Target system response embedding weights are not shared to learn input and output semantics. The DST module processes slot-level and domain-level information independently and integrates them for multi-domain state tracking using a Late Fusion approach. Slot-level signals are learned by projecting the encoded slot token sequence through multiple identical layers with attention blocks and feed-forward layers. Residual connections are used for better learning. The DST module utilizes multiple attention blocks and transformations with ReLU activation for processing slot-level and domain-level information independently. Residual connections and layer normalization are employed in each attention block to integrate contextual information from dialogue context, previous belief state, and user utterance in each turn. The domain-level processing module utilizes attention blocks to extract important contextual information from dialogue history and user utterance. It allows reasoning among domains independently and enables learning domain signals from past and current dialogue turns. The domain-level processing module uses attention blocks to extract contextual information from dialogue history and user utterance. It enables learning domain signals from past and current dialogue turns, allowing models to detect changes in dialogue domains. In multi-domain dialogues, users can switch domains, and responses should address the latest domain. Decoded dialogue states query DBs of all domains to obtain result entities, creating one-hot pointer vectors for each domain. The generator in the system uses DB pointer vectors, domain-slot joint features, dialogue history, and user utterance as inputs to decode system responses. It consists of multiple layers with attention blocks to capture contextual cues and knowledge base signals. The output is transformed using softmax activation to generate responses based on belief state objectives and system response objectives. The system uses various inputs to decode system responses, including DB pointer vectors, domain-slot joint features, dialogue history, and user utterance. The objectives are conditioned on input features such as dialogue context, user utterance, belief states, and DB queries. The dataset used is MultiWOZ 2.1, which includes single-domain and multi-domain dialogues with improved DST labels. Preprocessing involved tokenizing, lower-casing, and delexicalizing system responses. The corpus includes 8,438 dialogues with 7 domains and 35 unique inform slots identified. The model parameters for the preprocessing scripts include dropout of 0.3 and label smoothing for target system responses. Teacher-forcing learning strategy is used during training, while inference involves decoding system responses sequentially using previously decoded belief states. The model parameters for the preprocessing scripts include dropout of 0.3 and label smoothing for target system responses. Teacher-forcing learning strategy is used during training, while inference involves decoding system responses sequentially using previously decoded belief states. Turn by turn, the belief state is used to query DBs for pointer vectors. The models are trained in an end-to-end manner with Adam optimizer and evaluated using DST metrics like Joint Accuracy and Slot Accuracy. The models are implemented using PyTorch and decoding is done using a greedy approach and beam search. In the evaluation process, various metrics are used including Joint Accuracy, Slot Accuracy, Inform, Success, and BLEU score. The experiments are conducted in two settings: end-to-end dialogues and DST. The end-to-end setting involves training a dialogue agent responsible for both DST and text generation without access to ground-truth labels. The model's performance is compared on the joint task of DST and context-to-text generation. Our model, based on TSCP, outperforms in all metrics for both multi-domain and single-domain dialogues, with higher performance gain in multi-domain dialogues. The performance gain in multi-domain dialogues can be explained by the separate network structure between domain and slot processing modules in our models. Increasing the L bspan from 8 to 20 tokens helps improve performance but also increases training time significantly. All inform and request slots are decoded independently, and training time is less affected by the size of the target dialogue states. Additional results by individual domains are described in Appendix A.3. DST. Our model outperforms existing baselines and achieves state-of-the-art performance in MultiWOZ2.1 corpus by leveraging dialogue context signals through independent attention modules at domain and slot levels. Compared to TRADE, our approach enables deeper interaction of context-related signals for better joint features of domains and slots. Training our models as an end-to-end system improves DST performance. Training models as an end-to-end system improves DST performance by providing additional supervision from system responses. Experiment results show the importance of self-attention in learning signals across joint features of domains and slots. Varying the number of attention layers in processing reduces model performance gradually. Our Late Fusion approach combines features at deeper network layers, resulting in better joint feature representation and increased model performance. The models efficiently detect contextual signals from previous dialogue states, benefiting from evolving dialogue history. The performance remains similar with or without using the full dialogue history, as the models only need to process the latest dialogue turn along with the predicted dialogue state from the previous turn. Our Late Fusion approach combines features at deeper network layers for better joint feature representation and increased model performance. In qualitative analysis, our predicted dialogue state and system response outperform the baseline TSCP. The dialogue state accurately detects the correct type slot in the attraction domain, leading to more accurate responses from the database. Important tokens in the user utterance are attended to with higher scores, improving the overall performance of the system. In this work, an end-to-end dialogue system with a Multi-level Neural Belief Tracker is proposed. The system combines a DST module to track complex belief states across multiple domains and an attention-based generation module for dialogue responses. Evaluated on the MultiWOZ2.1 benchmark, the models achieve state-of-the-art performance in DST and competitive results in task completion and response generation. The attention is more refined along neural network layers, with the 4th layer showing clustered attention around specific tokens in user utterances. The complete predicted output and qualitative analysis can be found in Appendix A.4. The proposed end-to-end dialogue system combines a DST module for tracking belief states and an attention-based generation module for responses. It achieves state-of-the-art performance in DST and competitive results in task completion and response generation on the MultiWOZ2.1 benchmark. Data pre-processing involves delexicalizing target system responses by replacing entity attributes with canonical tags. The text discusses the use of entity databases to match attributes in target system responses. It also mentions the splitting of dialogue history, user utterances, and belief states into tokens. The unique tokens in source and target sequences are detailed, along with their overlapping rates in the training embedding vocabulary. The text discusses the use of entity databases for matching attributes in target system responses. It details the unique tokens and overlapping rates in the training embedding vocabulary for source and target sequences. Dialogues in each domain are analyzed, and inform and request slots are built using belief state annotations. Baseline models in DST and context-to-text generation settings are described, including FJST and HJST, which follow a fixed-vocabulary approach for state tracking. The text discusses various models for dialogue state tracking (DST), including FJST and HJST which use fixed-vocabulary approach. TSCP is an end-to-end system for DST and NLG, while DST Reader treats DST as a reading comprehension task. The DST Reader model treats dialogue state tracking as a reading comprehension task, predicting slots as spans over tokens in the dialogue history. HyST combines fixed-vocabulary and open-vocabulary approaches for slot prediction. TRADE is the current state-of-the-art model on the MultiWOZ2.1 dataset, using pointer networks and slot gating components for slot generation. The TokenMoE model utilizes expert bots for different dialogue scenarios, while HDSA is the state-of-the-art for context-to-text generation in MultiWOZ2.0, leveraging dialogue act structures to improve dialogue responses. The Structured Fusion approach improves dialogue responses by biasing self-attention networks. LaRL model uses latent dialogue actions learned through unsupervised learning. Domain-specific results are presented in tables for state tracking metrics. Our approach outperforms TSCP in most metrics across different domains, except for Success and BLEU in the taxi domain. Significant improvements are seen in domains with large DB sizes like train and restaurant for task completion. In response generation, our model consistently outperforms baselines by returning more appropriate responses. For state tracking alone, our models perform consistently well in the attraction, restaurant, and train domains. Our model performs well in the attraction, restaurant, and train domains but experiences a significant drop in performance in the taxi domain, impacting overall performance. We aim to address challenges in the taxi domain in future work. Our model achieves state-of-the-art results in the Inform metric but falls short in the Success metric, possibly due to not utilizing dialogue act information. The current state-of-the-art HDSA leverages dialogue act information in dialogue models, achieving high performance in context-to-text generation. Our model, unlike others, does not rely on pretrained network modules and follows an end-to-end approach for dialogue systems. In Table 10, the dialogue agent can detect new domains introduced by the user, such as the attraction domain at the 5th turn and the taxi domain at the 8th turn. The model can also infer co-references among domains, for example, inferring the slot area for the attraction domain when the user mentions 'close the restaurant'. However, there are instances where the decoded dialogue state is incorrect, possibly due to errors in previous turns. The dialogue agent's state accuracy decreases over time, with the highest accuracy at the 1st turn and zero accuracy at later turns. The BLEU score for response generation fluctuates between the 2nd and 13th turn, with the highest score at the 3rd turn."
}