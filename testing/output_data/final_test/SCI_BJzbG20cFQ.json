{
    "title": "BJzbG20cFQ",
    "content": "The NeuroFovea metamer model proposed in this paper aims to address the problem of visual metamerism by using a foveated generative model based on a mixture of peripheral representations and style transfer algorithms. The model is parametrized by a foveated VGG19 encoder-decoder, allowing for encoding images in high dimensional space and interpolating between content and texture information. Key contributions include a framework for computing metamers resembling a noisy communication system and a perceptual optimization scheme to address the hyperparametric nature of the problem. A perceptual optimization scheme is proposed to address the hyperparametric nature of the metamer model, requiring tuning of image-texture tradeoff coefficients due to internal noise. An ABX psychophysical evaluation shows that the model matches V1 and V2 receptive field growth rates, with a rendering speed-up of \u00d71000 compared to previous work. The history of metamers began with color matching theory, creating color metamers where two light sources match a test light's wavelength. Visual metamerism occurs when different stimuli produce the same perceptual response. BID7 developed point-of-fixation driven metamers using local texture matching models across the visual field. Their algorithm uses gradient descent to match local texture and image. The algorithm uses gradient descent to create images that are perceptually indistinguishable by matching local texture and image statistics throughout the visual field. However, metamerism research faces limitations such as no unique solution and imperceptible perturbations across all pixels. The goal is to create point-of-fixation driven metamers that preserve information in the fovea. The current state of the art for full field of view rendering of metamers is computationally intensive, taking hours for grayscale images and days for color images. This poses challenges for data-driven experiments requiring thousands of metamers. Creating quick-to-compute metamers could enhance computational efficiency in rendering VR foveated displays. Quick-to-compute metamers can improve computational efficiency in rendering VR foveated displays and creating neuroscience experiments. By capitalizing on metamer understanding and advancements in style transfer, localized style transfer with proper texture statistics can potentially render metamers efficiently without the need for re-training. The recent work introduces adaptive instance normalization (AdaIN) for style transfer, enabling real-time applications without the need for re-training. By stacking a peripheral architecture on VGGNet, the model maps images into a perceptual space with added internal noise for improved results. The model uses AdaIN for style transfer and VGGNet for texture statistics to create metamer by transferring localized styles over a content image controlled by style-to-content ratios for each pooling region. The NeuroFovea model utilizes AdaIN for style transfer and VGGNet for texture statistics to generate metamer by transferring localized styles over a content image controlled by style-to-content ratios for each pooling region. The goal is to find a Metamer function that feeds an input image through a VGG-Net encoder to produce content features, allowing for spatial control to interpolate between stylized-noise and content in a new feature space. The metamer is the output of the pooled feature vector through the Meta VGG-Net Decoder, where noise is stylized via spatial control and Adaptive Instance Normalization to encode texture representation in the feature space. Target features are defined as an interpolation between stylized noise and content modulated by alpha for each pooling region. In the quest for metamerism, an intermediate representation is found between image vectors and stylized noise in each pooling region. This involves a tradeoff between content and style, with the final target feature vector being a masked sum with spatial control masks. The Meta VGG-Net Decoder produces the metamer output by decoding the target vector T, compensating for artifacts with a pix2pix U-Net refinement module. The model described involves stacking a pix2pix BID15 U-Net refinement module trained on Encoder-Decoder outputs to map to the original high-resolution image. The metamer transform is computed using a foveated encoder and perturbing the encoded representation in the direction of stylized noise to generate metamers. The model involves using a foveated encoder and perturbing the encoded representation with stylized noise to generate metamers. The metamerism framework considers distortions in the perceptual null space, maximizing information discard based on image texture properties and receptive field size. The model involves using a foveated encoder and perturbing the encoded representation with stylized noise to generate metamers. The metamerism framework considers distortions in the perceptual null space, maximizing information discard based on image texture properties and receptive field size. The value of components in the null space changes based on the location and geometry of the encoded space. The maximal average amount of distortion is computed to determine human sensitivity before differences can be perceived. This concept is illustrated in the perceptual space with a metameric boundary for distortion. The model resembles a noisy communication system in information theory. The model involves using a foveated encoder and perturbing the encoded representation with stylized noise to generate metamers. Metamerism can be explored within the context of image compression and rate-distortion theory. The BID7 model requires a scale parameter to control the growth of receptive fields. The scaling factor in the model aims to maximize perceptual discrimination by finding an upper bound. A high scaling factor makes distortions more apparent, while a low scaling factor may ensure metamerism. FS conducted a psychophysical experiment to determine the critical value for humans to detect differences. The model aims to estimate hyperparameters \u03b1 for every receptive field in the visual field, with the goal of solving intractability in joint estimation of scale and distortion parameters. The experiment aims to determine the critical value for humans to detect differences in distortions. The FS model does not require additional hyperparameters due to its gradient descent nature, matching local texture statistics while preserving global image structural information. This equilibrium point eliminates the need for further synthesis steps, as shown in experiments where discarding structural information leads to non-metameric images. The text discusses the challenge of finding an equilibrium point between structural and texture representation in a feed-forward model without gradient descent. It highlights the complexity of solving a multi-variable optimization problem that may be psychophysically intractable, requiring multiple rounds of experiments for different scales and values. In Experiment 1, the goal is to estimate \u03b3 as a function of s through computational simulation to simplify the optimization problem. Experiment 2 will involve an ABX experiment on human observers to vary the scale for visual metamers. The shape and existence of \u03b3 will be explored based on biological priors. In Experiment 1, the goal is to estimate \u03b3 as a function of s through computational simulation to simplify the optimization problem. The shape and existence of \u03b3 will be explored based on biological priors, where \u03b3 is continuous and monotonically non-decreasing with a unique zero at \u03b3(0) = 0. The function of \u03b3 is sigmoidal and parametrized by s to simulate perceptual loss in discriminating between metamers and original stimuli. The perceptual loss L aims to match distortions via SSIM between FS metamers, NeuroFovea metamers (NF), and their reference images. SSIM is chosen for its correlation with human judgements. The reference image I for NF metamer is limited by the model's autoencoder-like nature, where perfect reconstruction is constrained by the encoder-decoder pair. Loss function L cannot be directly defined between metamers, requiring alternative methods. The goal is to define a convex surrogate loss function L R to match the perceptual loss of metamers for each receptive field k compared to their reference images. Optimization is performed with reference to the original image I for the FS model and the decoded image I for the NF model. Despite limited reconstruction capacity, using only the original image in optimization leads to poor local minima. Results: A collection of 10 images were used in experiments to compute SSIM scores for FS and NF images paired with their reference image across receptive fields. The convex nature of the loss function is shown in FIG2. The procedure was repeated for different retinal eccentricities and scales, with a sigmoid used to estimate \u03b3 for each \u03b1 per receptive field. This resulted in a collection of d values controlling the slope rate of the sigmoid. The study conducted a permutation test to compare the variation in parameters of \u03b3 across different scales, showing non-significant differences. The results suggest that the \u03b1 = \u03b3(z) function remains fixed, with the scale parameter influencing the maximum noise distortion. The maximal noise distortion is dependent on the scale factor, with smaller scales resulting in smaller distortions in the far periphery. The study simplified the model by computing an average and fitting a sigmoid to estimate the maximal distortion for receptive fields in the perceptual space. Metamers can now be rendered as a function of a single scaling parameter, making the psychophysical optimization procedure tractable for human observers. In a study by Wallis et al., metamers were tested on a group of 3 observers performing ABX discrimination tasks. Observers matched images in a forced fixation task, with each image shown 30 times per scaling factor and discriminability type. Images were rendered at 512 \u00d7 512 px, viewed at 52cm distance on a calibrated monitor. The critical scaling factor and absorbing gain factors were estimated for a roving ABX task using a psychometric function. The results showed a critical scaling factor of 0.51 in the Synth vs Synth experiment, matching a critical region in the brain known to respond to texture. This suggests that the parameters used to capture and transfer texture statistics differ from a steerable pyramid decomposition. The critical scaling factor for the Synth vs Reference experiment is less than 0.5, aligning with recent findings. Different flavors of metamer models can be created with different statistics, as shown by recent research on developing and testing new models like the SideEye model. The Texture Tiling Model (TTM) by BID23 is deterministic, unlike the CNN synthesis model by BID29 which uses gradient descent. The question of optimizing parameters for metamerism remains open. The question of optimizing parameters for metamerism remains open, with recent studies suggesting that metamers are driven by image content rather than bouma's law. The hyperparametric nature of the model sheds light on reconciling these theories, showing that the average maximal distortion is fixed but can be increased for some images based on their location, geometry, and projection in perceptual space. Our model explains why synthesized samples are metameric at the scales of (V1;V2), but only generated samples at the scale of V1 (s = 0.25) are metameric to the reference image. It differs from other models by using noise as a proxy for texture distortion associated with crowding in the visual field, rather than as an initial seed for texture matching. Our approach uses noise as a proxy for texture distortion in the visual field, creating metamers through perturbations in a hierarchical system. The perturbed foveated representations finely tile the perceptual space, unlike the encoded images which are distant from each other in a 2D projection. The perturbed texture-like noise in the visual field acts as a biological regularizer for human observers, leading to robust representations in the foveated human visual system. A model is proposed to emulate metameric responses using a foveated feed-forward style transfer network. Our model uses a foveated feed-forward style transfer network to create metamers by calibrating perturbations in the perceptual space. Through a psychophysical experiment, we found that the critical scaling factor matches the receptive fields in V2 and V1. The accelerated metamer generation pipeline can be extended to other models for texture/style transfer. The model utilizes a foveated feed-forward network for creating metamers by adjusting perturbations in the perceptual space. Through experiments, it was found that the critical scaling factor aligns with receptive fields in V2 and V1, enabling rapid generation of various visual metamers with applications in neuroscience and computer vision. Algorithm 1 outlines Experiment 1, using spatial control windows and pooling regions for metamers at different scales. The decoder network architecture and training details can be found in BID14, utilizing code by Huang and Belongie trained on ImageNet and paintings for texture inversion. The decoder approximates the inverse of the encoder by combining the content image and style image. A re-trained decoder on scene images produced similar outputs. Foveated pooling is applied at 64x64 resolution. Peripheral representations are constructed based on specific equations. The foveated pooling operation is performed on the output of the Encoder using a cosine profiling function. The scale parameter defines the number of eccentricities and polar pooling regions. A pix2pix U-Net refinement module was trained on a Titan X GPU for 3 days with 64 crops per image. The U-Net architecture proposed by BID15 was used to train 12800 images over 200 epochs with adversarial and L2 loss. The NF model cannot directly generate a metamer and has limitations in achieving lossless compression. The distance between V1 and V2 metamers is the same, making them perceptually indistinguishable. The metamer generation process is decomposed into Image, Encoded, and Perceptual spaces. The metamer generation process involves the Image, Encoded, and Perceptual spaces. The original image patch is transformed into V1 and V2 metamers, with white noise stylized via AdaIN. Interpolation for distortion is done between points in the encoded space representing \u03b1 = 0.0 and \u03b1 = 1.0. In FIG1, the process is illustrated for two sample metamers with different noise perturbations. In a preliminary psychophysical study, observers discriminated between synthesized images in the ABX task, with only a sub-group scoring well above chance. The FS metamers were not metameric to their reference images at a scale of 0.5. The ABX task results showed good discrimination ability, consistent with previous evaluations. Estimating the lapse rate is crucial for accurate parameter estimation in psychometric functions. Lapse rates are computed by penalizing a psychometric function within a specified range. A new function is defined to estimate the lapse rate \u03bb. The new function defined by Equation 11, parametrized by absorbing factor \u03b2 0 and critical scaling factor s 0, computes the lapse rates for an AXB task. Lapse rates were found for three observers and averaged due to equal trial probabilities. The lapse rates for the pooled observer were estimated to be \u03bb ZQ = 0.0339, \u03bb AL = 0.0087, \u03bb AG = 0.0179. The critical scaling values were obtained by averaging estimates over the three observers. The perceptual optimization pipeline is robust to a selection of IQA metrics such as MS-SSIM and IW-SSIM. The sigmoidal nature of the \u03b3 function is scale independent, showing broad applicability. IW-SSIM is a weighted version of MS-SSIM based on mutual information between encoded representations. The IW-SSIM score asymptotes to the MS-SSIM score when evaluated over small pooling regions. About 90% of the maximum \u03b1 values were the same with the sampling grid used. Different hyperparameters and sampling schemes may show visible differences between the metrics. The sigmoidal slope is smaller for both IW-SSIM and MS-SSIM compared to SSIM, resulting in more conservative distortions. The model can create metamers at estimated scaling factors of 0.21 and 0.50, with different critical scaling factors for various experiments. Future work should focus on finding these critical scaling factors psychophysically. The \u03b3 function is invariant to scale, suggesting flexibility across IQA metrics. A permutation test showed each \u03b3 function is scale independent under the 99% confidence level. The test results showed that each \u03b3 function is scale independent under a 99% confidence interval. When using a 95% confidence interval, significant differences were observed for most curves except for MS-SSIM and IW-SSIM at a scaling factor of 0.3. These differences in the sigmoid function's d parameter were found to be statistically insignificant."
}