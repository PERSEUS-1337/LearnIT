{
    "title": "BJOFETxR-",
    "content": "Learning tasks on source code have been recently considered, with a focus on utilizing graphs to represent both syntactic and semantic structures. Graph-based deep learning methods are proposed to reason over program structures, capitalizing on code's unique syntax. In this work, the authors demonstrate how to build graphs from source code and scale training of Gated Graph Neural Networks on large graphs. They evaluate their method on VarNaming and VarMisuse tasks, showing the advantages of modeling known structure in program representations. The VarMisuse task successfully identifies bugs in open-source projects, highlighting the potential of \"big code\" methods for supporting software engineers. In this work, the authors introduce unsupervised methods for software engineers to generalize from existing source code by incorporating data flow and type hierarchies into program graphs. By encoding programs as graphs with syntactic and semantic relationships, they aim to reduce the need for extensive training data and model capacity. The machine learning model reduces training data requirements and allows solving tasks beyond the current state of the art. Two tasks illustrate exposing more semantic structure of programs: VARNAMING task and detecting bugs in source code. The model detected a bug in RavenDB, an open-source C# project, where the variable used was incorrect. The issue was fixed in PR 4138. A new task called VARMISUSE was introduced to predict variable misuse in program locations. This task requires learning representations of program semantics to achieve high accuracy. The VARMISUSE task involves learning the semantic role and usage of variables in source code. This task aims to improve machine learning modeling of program semantics and can be valuable for tasks like code completion and bug finding. Machine learning models for VARNAMING and VARMISUSE tasks are presented, achieving 32.9% accuracy on VARNAMING and 85.5% accuracy on VARMISUSE. Practical relevance of VARMISUSE is demonstrated by finding bugs in open-source projects. Implementation of graph neural networks for a simpler task can be found at https://github.com/Microsoft/gated-graph-neural-network-samples. Our work builds upon using machine learning for source code artifacts, focusing on predicting variable and method identifiers. Previous works have modeled code as a sequence of tokens or syntax tree structures, but our approach incorporates data flow information. While some models have used conditional random fields to predict variable names and types, they do not explicitly consider the flow of data. Our work is remotely related to these approaches. Our work focuses on predicting variable and method identifiers in source code using machine learning. Unlike previous approaches that model code as sequences of tokens or syntax trees, we incorporate data flow information. Our approach is complementary to other methods that require specifications to complete gaps, as we learn statistically from code without the need for specifications. Neural networks on graphs have been used in various applications, such as link prediction and semantic role labeling in NLP. Our work focuses on predicting variable and method identifiers in source code using machine learning. Unlike previous approaches that model code as sequences of tokens or syntax trees, we incorporate data flow information. The task involves detecting variable misuses in code by inferring the role and function of program elements. The goal is to automatically identify errors, such as using the wrong variable identifier, in a mostly complete program. Our work focuses on predicting variable and method identifiers in source code using machine learning. We incorporate data flow information to detect variable misuses in code. Program graphs are used to encode program text and semantic information. Gated Graph Neural Networks (GGNN) are utilized for learning representations over program graphs. A graph G = (V, E, X) consists of nodes V, node features X, and directed edge sets E = (E 1 , . . . , E K ). Each node v \u2208 V is annotated with a real-valued vector x (v) \u2208 R D representing its features. Nodes are associated with a state vector h (v) initialized from the node label x (v). Messages of type k are sent from each node v to its neighbors, computed from its current state vector. All states can be updated simultaneously by computing messages for all graph edges at once. The state of a node in a graph is updated by aggregating incoming messages using an aggregation function. The next state is computed using a recurrent cell function, such as a gated recurrent unit (GRU). Program source code is represented as graphs with different edge types to model relationships between tokens, based on the program's abstract syntax tree. The abstract syntax tree (AST) represents a program's structure with syntax nodes and tokens. Nodes are labeled with nonterminals, tokens with strings. Child edges connect nodes in the AST, NextToken edges link tokens. Additional edges capture control and data flow by connecting variable uses and updates. The flow of a program is tracked by sets of syntax tokens where variables were last used. The program's structure is represented by an abstract syntax tree (AST) with syntax nodes and tokens. Control and data flow are captured by connecting variable uses and updates. Sets of syntax tokens track where variables were last used, creating semantic edges in the program code. The text discusses connecting tokens to formal parameters, variables to guard expressions, and introducing backward edges to propagate information faster in a GGNN model for a statically typed language with known variable types. To use variables with known types in a GGNN model for a statically typed language, a learnable embedding function is defined for known types and an \"UNKTYPE\" for unknown types. The type hierarchy is leveraged by mapping a variable's type to its supertypes. The type representation of a variable is computed as the maximum of the embeddings of its supertypes. This allows for generalization to unseen types that implement common supertypes or interfaces. For example, different concrete types like List<int> and List<string> can share common characteristics through a common interface like IList. During training, a subset of known types in the lattice is randomly selected to ensure comprehensive training. The initial node state is computed by combining information from the token's textual representation and type. Subtokens are created from the node's name, and their embeddings are averaged to obtain a representation. This representation is concatenated with the learned type representation and passed through a linear layer to generate initial node representations in the graph. Program Graphs for VARNAMING involve building a program graph, replacing variable names with <SLOT> tokens, using GGNN propagation for 8 time steps, and predicting variable names as sequences of subtokens. The graph2seq architecture is trained using a maximum likelihood objective to predict exact names and subtokens. Program Graphs for VARMISUSE focus on modeling variable misuse. To model VARMISUSE with program graphs, a context representation is computed for a slot by inserting a new node and connecting it to the graph. Usage representation of candidate variables at the target slot is computed by inserting candidate nodes for all variables and connecting them with specific edges. Each candidate node represents the speculative placement of the variable within the scope. The context representation for a slot in VARMISUSE is computed by inserting a new node connected to the graph. Candidate variable usage at the slot is represented by candidate nodes connected with specific edges, each node representing the speculative variable placement. GGNN propagation is used for 8 time steps to compute final node states for context and usage representations. Training involves a max-margin objective with a linear layer concatenating context and usage representations. Efficient batching for diverse graph shapes is challenging, but sparse tensor representation can help reduce memory consumption. Our TensorFlow BID0 implementation efficiently handles large batch sizes by representing graphs as one large graph with unique node identities. Batch construction is CPU-intensive, so minibatches are prepared on a separate thread. The implementation scales to 55 graphs per second during training and 219 graphs per second during test-time on a single NVidia GeForce GTX Titan X. The GGNN model used has 8 unrolling iterations, 20 edge types, and a hidden layer size of 64. The number of edge types in the GGNN affects running time proportionally. The GGNN model's running time is influenced by the number of edge types. Using only two common edge types, the model achieves 105 graphs/second during training and 419 graphs/second at test time. A dataset for the VARMISUSE task was collected from top-starred C# projects on GitHub, resulting in 29 projects with 2.9 million lines of code. The GGNN implementation is available on GitHub for a simpler demonstration task. For the VARMISUSE task, a dataset was collected from 29 C# projects on GitHub with 2.9 million lines of code. The task involves detecting variable misuses by inferring the correct variable at usage locations. Two projects were selected for development, three for testing on unknown projects, and the remaining split into train/validation/test sets. For the VARMISUSE task, a dataset was collected from 29 C# projects on GitHub with 2.9 million lines of code. The remaining 23 projects were split into train/validation/test sets in a 60-10-30 proportion. The test set obtained was named SEENPROJTEST. Baselines for VARMISUSE included two bidirectional RNN-based models: LOC and AVGBIRNN. The LOC model evaluates the importance of usage context information, while the AVGBIRNN model extends LOC by computing the usage representation using another bidirectional RNN. The AVGBIRNN model is a stronger baseline for capturing structural information by averaging over all variable usages. VARNAMING replaces LOC with AVGLBL, which uses a log-bilinear model for context tokens. Evaluation results are shown in TAB1 for both tasks. AVGLBL and AVGBIRNN outperform LOC due to capturing more information. Generalizing across different source code projects is a challenge in machine learning. Evaluation on unseen projects shows slightly lower performance, mainly due to unknown type hierarchies. The challenge of applying a trained model to an unknown project lies in the unknown type hierarchy and differing vocabulary. Additional experiments show that restricting the model to syntactic information greatly impacts performance, while semantic edges mostly affect VARMISUSE. Certain edges like ComputedFrom and FormalArgName improve performance on specific tasks. Node label representation and token names have varying impacts on different tasks. The GGNN model has a significant impact on VARNAMING, accurately predicting variable usages in code snippets. Figure 3 displays predictions made by GGNN on a test snippet, showcasing its ability to recursively search for global directives files. Additionally, ROC and precision-recall curves for the GGNN model on the VARMISUSE task are presented in Sect. A. The VARMISUSE predictions on slots within a snippet of the SEENPROJTEST set for the ServiceStack project are shown in Figure 3. The predictions are based on variables such as baseDirectory, path, directivesDirectory, fullPath, and GlobalDirectivesFileName. The GGNN accurately predicts variable usages in most slots, providing valuable warnings to software engineers about potential variable misuses. Additional samples and code snippets can be found in Appendices B and C. The VARMISUSE model identified bugs in RavenDB and Roslyn by grouping variable usages with semantic similarities. Three bugs were found in each project, with Fig. 1 showing a bug possibly caused by copy-pasting. The bug in Fig. 1, possibly caused by copy-pasting, cannot be easily caught by traditional methods. Compiler warnings are not triggered for certain conditions, leading to non-informative error messages. Additionally, other bugs were privately reported and fixed by Roslyn developers. The model identified bugs in widely released code, showing its usefulness in software development. It can guide code reviews and focus testing efforts. Deep learning in source code analysis is a new domain with novel opportunities. The VARMISUSE task goes beyond code completion, requiring refinement of standard information in type systems. The GGNN model shows high precision with a 73% true positive rate for SEENPROJTEST and 69% for unseen tests at a 10% false positive rate. Samples from SEENPROJTEST projects demonstrate the model's performance in identifying bugs in code. The model predicts correctly most usages except for one in slot #3, requiring additional semantic information. It matches string parameters to formal parameter names, but struggles with conditionals and rare constants. Nearest neighbors are shown based on cosine similarity of learned representations. The data includes hand-picked examples with good and bad instances, along with a brief description for each pair. HasAddress is a local function only seen in the testset. A large portion of the data has been released, excluding projects with a GPL license. Results, averaged over three runs, on the published dataset show Accuracy (%) PR AUC for SEENPROJTEST at 84.0 0.976 and UNSEENPROJTEST at 74.1 0.934. The model struggles with conditionals and rare constants but performs well in matching string parameters to formal parameter names. Nearest neighbors are determined based on cosine similarity of learned representations."
}