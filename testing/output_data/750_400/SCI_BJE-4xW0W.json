{
    "title": "BJE-4xW0W",
    "content": "We introduce causal implicit generative models (CiGMs) for sampling from observational and interventional distributions using adversarial training. The generator architecture is based on a causal graph for conditional and interventional sampling of face images with binary feature labels. A two-stage procedure is devised for learning a CiGM over the labels and images using a Wasserstein GAN. We introduce CiGMs for sampling face images with binary labels using a causal graph. A two-stage procedure involves training a CiGM over binary labels with a Wasserstein GAN and combining it with a conditional GAN to generate images based on the labels. New architectures CausalGAN and CausalBEGAN are proposed for this purpose. The optimal generator of CausalGAN samples images conditioned on the labels. The generator neural network is consistent with the causal graph between the labels. Two new conditional GAN architectures, CausalGAN and CausalBEGAN, are proposed. The optimal generator of CausalGAN samples from image distributions conditioned on the labels, allowing for sampling from observational and interventional image distributions. The conditional GAN, combined with a trained CiGM for labels, forms a CiGM over labels and generated images. Proposed architectures enable sampling from observational and interventional image distributions, even for interventions not in the dataset. GANs are effective for training implicit generative models without explicit parameterization of likelihood. Generative adversarial networks (GANs) are neural models that can sample from high-dimensional distributions without explicit parameterization. The generator network produces samples from a noise vector, refined by a discriminator network that distinguishes between generated and real data. Using backpropagation, GANs sample from high-dimensional nonparametric distributions. A generator network produces samples from a noise vector, refined by a discriminator network that distinguishes between generated and real data. The objective is for the generator to maximize the loss of the discriminator, convincing it that the samples are from the real data distribution. GANs have been successful in generating samples such as images and videos. Generative Adversarial Networks (GANs) aim to distinguish between generated and real samples by maximizing the loss of the discriminator. GANs have been successful in generating samples like images and videos. Extensions include sampling from class conditional data distributions by feeding class labels to the generator. Various neural network architectures have been proposed for this task. Extensions of GANs involve sampling from class conditional data distributions by providing class labels to the generator. Different neural network architectures have been proposed for this purpose, allowing sampling from both joint and interventional distributions. In extending GANs, new architectures aim to sample from joint and interventional distributions based on class labels. These architectures need to capture label dependencies and causal effects for improved conditional image generation. In this paper, the focus is on extending previous work on conditional image generation by capturing label dependencies and causal effects. The generator maps labels to images in a non-deterministic way, following the causal graph \"Labels cause the Image\" denoted by L \u2192 I. Conditional image generation is viewed as a causal process where labels determine the image distribution. The generator maps labels to images non-deterministically, following causal graphs like \"Labels cause the Image\" (L \u2192 I). More detailed models can include causal relations between specific labels, such as Gender causing Mustache (G \u2192 M). Conditioning on Gender = male results in males with or without mustaches based on the male population's mustache prevalence. Using a finer model, causal graphs can be included between labels, such as Gender causing Mustache (G \u2192 M). Conditioning on Gender = male results in males with or without mustaches based on the population's prevalence. Causal models allow sampling from conditional and interventional distributions. Causal models allow sampling from conditional and interventional distributions. Intervening on Mustache = 1 does not change the distribution of Gender in the causal graph. Intervening in a causal graph fixes a variable's value, affecting its descendants' distributions but not its ancestors'. For example, intervening on Mustache = 1 would not change the distribution of Gender in the graph. Causal implicit generative models (CiGM) can sample from both conditional and interventional distributions. Causal implicit generative models (CiGM) can sample from correct joint, conditional, and interventional probability distributions based on the given causal graph. GANs can be utilized when the generator structure aligns with the causal graph's neural connections. Causal implicit generative models (CiGM) can utilize GANs to train models that sample from correct probability distributions based on a given causal graph. Two novel conditional GANs, CausalGAN and CausalBEGAN, are proposed for training CiGM for images and image labels. Using Wasserstein GAN, a CiGM is trained for binary image labels in the first step of a two-step procedure. Two new conditional GANs, CausalGAN and CausalBEGAN, are introduced for the second step. The optimal generator of CausalGAN can sample from true conditional distributions, and combining it with a CiGM on labels results in a CiGM on both labels and images. The optimal generator of CausalGAN can sample from true conditional distributions, and when combined with a CiGM on labels, it results in a CiGM on both labels and images. Adversarial training can be used to structure the generator architecture based on the causal graph to train a CiGM. Additionally, WGAN can be utilized to learn a CiGM for binary labels, enabling conditional and interventional sampling of images given a causal graph over binary labels. Adversarial training is used to structure the generator architecture based on the causal graph to train a CiGM for binary labels. A two-stage procedure is proposed to train a CiGM over binary labels and images, including a novel conditional GAN architecture and loss function. An extension of BEGAN to accept labels is also suggested. The proposed CiGM training framework includes a novel conditional GAN architecture and loss function. An extension of BEGAN to accept labels, called CausalBEGAN, is also introduced. The framework is evaluated on labeled CelebA data, showing that CausalGAN produces high-quality images capturing image labels. Extension of BEGAN to accept labels, resulting in CausalBEGAN, which produces high-quality images capturing image labels. CausalGAN and CausalBEGAN can generate label-consistent images even for interventions not seen during training. CausalGAN and CausalBEGAN can create label-consistent images for interventions not encountered during training. Previous works include conditional GAN (CGAN) and ACGAN, which involve using image labels in the generation process. In BID10, ACGAN is introduced where the discriminator estimates labels instead of receiving them as input. A comparison between CGAN and ACGAN is made in , with an extension to the semi-supervised setting proposed. BID15 presents InfoGAN, aiming to maximize mutual information between inputs and generated images. Existing conditional GANs do not allow sampling from unseen label combinations. In BID15, InfoGAN introduces a new architecture to maximize mutual information between inputs and generated images. BiGAN and ALI extend the GAN framework by learning a mapping from image space to latent space. CoGAN learns a joint distribution over images and binary labels by enforcing weight sharing between generators and discriminators. In BiGAN and ALI, the GAN framework is extended by learning a mapping from image space to latent space. CoGAN learns a joint distribution over images and binary labels by enforcing weight sharing between generators and discriminators. SD-GAN splits the latent space into \"Identity\" and \"Observation\" portions, allowing for the generation of faces of the same person by fixing the identity portion of the latent code. SD-GAN is an architecture that splits the latent space into \"Identity\" and \"Observation\" portions, allowing for the generation of faces of the same person by fixing the identity portion of the latent code. It can be seen as an extension of BEGAN to accept labels, making it the only extension before CausalBEGAN. Extending CoGAN and SD-GAN to more than two labels is not trivial. BID0 authors use CGAN with a one-hot encoded vector for age interval conditioning. CausalBEGAN is an extension of BEGAN that incorporates labels. It is the only extension of BEGAN to do so before CausalBEGAN. BID0 authors use CGAN with a one-hot encoded vector for age interval conditioning. Generative models can also be used in compressed sensing, as shown by Bora et al. (2017). Generative models, such as CGAN, are used for various applications like changing attributes in images and compressed sensing. Recent research has focused on the connection between GAN layers and causal inference, using techniques like neural networks to discover causal relationships in datasets. Recently, deep learning techniques for causal inference have gained attention. In various studies, authors have explored the connection between GAN layers and structural equation models to determine causal relationships between variables. Additionally, neural networks have been used to identify causal relations between image class labels based on static images. Authors have also introduced causal regularization in training neural networks to ensure predictive causality. Authors have proposed a causal regularization technique for training neural networks to discover causal relations between image class labels. Another study connects GANs to causal generative models, viewing images as causes of neural network weights. Additionally, neural networks have been utilized to learn causal graphs by mimicking structural equations. In a study connecting GANs to causal generative models, authors view images as causes of neural network weights without using labels. Another work proposes using neural networks to learn causal graphs by mimicking structural equations and utilizing directed acyclic graphs. Pearl's framework BID11 is used to represent causal models with structural equations and random variables X, Y. In this section, a brief introduction to causality is given using Pearl's framework BID11, which involves structural causal models (SCMs) represented by directed acyclic graphs. Within this framework, X causing Y implies the existence of a function f and an unobserved random variable E, where Y is determined by X and E through f. The causal graph for this relation is X \u2192 Y. The SCM framework under the causal sufficiency assumption states that X causes Y through a function f and an unobserved random variable E. The causal graph is represented as X \u2192 Y in a directed acyclic graph. The parents of a node in the causal graph represent the causes of that variable. The causal graph X \u2192 Y is a directed acyclic graph implied by structural equations, where the parents of a node represent the causes of that variable. A structural causal model consists of functions, random variables, and a probability distribution. A structural causal model (M) consists of functions (F), random variables (V), and exogenous variables (E), with a joint distribution implied by the distribution of E and the functional relations F. The causal graph (D) is a directed acyclic graph on the nodes V, where a node Xj is a parent of node Xi if Xj is in the domain of fi. An intervention in a structural causal model changes the underlying causal mechanism and corresponding causal graph. It is denoted as do(Xi = xi) and differs from conditioning on Xi by removing its connections to its parents. An intervention in a structural causal model changes the causal mechanism and graph. It is denoted as do(Xi = xi) and removes connections to parents, different from conditioning. Setting Xi to a value alters its determination through the function fi. Interventions in a structural causal model change the causal mechanism and graph. It removes connections to parents, unlike conditioning. The post-interventional distribution can be calculated for a set of nodes in a Bayesian network. After an intervention in a Bayesian network, the post-interventional distribution can be calculated by factorizing the observational distribution. Identifying the true causal graph for variables without experiments or additional assumptions is generally not possible. After intervention on nodes X S, the post-interventional distribution is determined by P(x i |P a S i). Identifying the true causal graph for variables without experiments is generally not possible, as multiple causal graphs can produce the same joint probability distribution. This paper focuses on learning a causal model given a known causal graph. This paper assumes a given causal graph and focuses on learning a causal model. Prior work on learning causal graphs is acknowledged, and using a Bayesian network helps sample from correct observational distributions when the true causal graph is unknown. In this paper, the focus is on learning a causal model using a Bayesian network to sample from correct observational distributions when the true causal graph is unknown. Causal implicit generative models are proposed to sample from both observational and interventional distributions. In this paper, causal implicit generative models are proposed to sample from both observational and interventional distributions. Generative adversarial networks can also be used for training these models, allowing for sampling from different distributions. Generative adversarial networks can be used to train causal implicit generative models, representing causal graph structures with neural networks. Noise terms can be chosen as independent, ensuring joint independence of variables. Neural network connections can reflect causal graph structure, with feedforward networks representing functions f X , f Y , f Z. Noise terms (N X , N Y , N Z) are chosen as independent, satisfying joint independence condition. Gaussian distributed variables can be used for exogenous variables. The feedforward neural network represents causal models with graph structure. The feedforward neural network can represent causal models with graph structure using Gaussian distributed variables. Two causal models with the same observational distribution will have the same interventional distributions for any intervention. Given the true causal graph, two causal models with the same observational distribution will have the same interventional distributions for any intervention. A feedforward neural network can be linked to a causal graph by defining a set of mutually independent random variables and outputting a vector based on the parents of each variable in the graph. A feedforward neural network can be linked to a causal graph by defining a set of mutually independent random variables. The network outputs a vector based on the parents of each variable in the graph, defining causal implicit generative models. Causal implicit generative models (CiGM) are defined as feedforward neural networks that output based on a causal graph. Adversarial training is proposed for training CiGMs to be consistent with the causal graph. Training CiGMs involves using samples from a joint distribution given the causal graph, but it can be challenging for image generation with binary labels. Causal implicit generative models (CiGM) are trained using a neural network consistent with a causal graph. For image generation with binary labels, a CausalGAN architecture is used, dividing the task among a causal controller, labeler, and anti-labeler. The CausalGAN architecture involves training a generative model for labels and images separately, with the image node as the sink node in the causal graph for image generation. The CausalGAN architecture involves training a generative model for labels and images separately, with the image node as the sink node in the causal graph for image generation. The new architecture and loss function (CausalGAN) ensures that the generator outputs label conditioned image distributions under the assumption of a strictly positive joint distribution between labels and images. The CausalGAN architecture involves training a generative model for labels and images separately. The new architecture and loss function (CausalGAN) ensure that the generator outputs label conditioned image distributions under the assumption of a strictly positive joint distribution between labels and images. The Causal Controller is used for controlling the distribution from which images are sampled. The Causal Controller, known as the Causal Controller, is trained to generate binary labels and control the distribution of sampled images based on the labels. The generator is structured to produce labels sequentially according to the causal graph, with a preference for discrete label distributions. The Causal Controller network generates binary labels and controls image sampling based on the labels. WGAN is used to sample from a discrete label distribution, as standard GAN training is not suitable for this task. The Causal Controller network uses WGAN to sample from a discrete label distribution, enabling the generation of images based on the labels. This approach overcomes limitations of standard GAN training for learning a CiGM over labels and image variables. In a two-step process for learning a CiGM over labels and image variables, a new conditional GAN architecture is designed to generate images based on the labels of the Causal Controller. The architecture and loss function ensure the generator outputs label-conditioned image distributions. Two separate labeler neural networks, Labeler and Anti-Labeler, are used to estimate labels of images in the dataset. Our new architecture and loss function ensure the generator produces label-conditioned image distributions. We use a pretrained Causal Controller and have separate Labeler and Anti-Labeler neural networks. The Labeler estimates labels of dataset images, while the Anti-Labeler estimates labels of generator-sampled images. The generator aims to create realistic images, consistent with labels, and avoid unrealistic images by competing with the discriminator. The CausalGAN architecture includes an Anti-Labeler network in addition to a Labeler network. The generator's objective is to produce realistic images, consistent with labels, and avoid easy-to-label unrealistic image distributions by maximizing the Anti-Labeler loss. The theoretical guarantee developed in Section 5.2.3 is dependent on the presence of the Anti-Labeler. The Anti-Labeler loss in CausalGAN prevents label-conditioned mode collapse by discouraging the generator from outputting only a few typical faces for a fixed label combination. This technique helps avoid unrealistic image distributions that are easy to label. The Anti-Labeler loss in CausalGAN prevents label-conditioned mode collapse by discouraging the generator from outputting only a few typical faces for a fixed label combination. Minibatch-features are commonly used to avoid mode-collapse, but may be ineffective against label-conditioned mode collapse due to diversity within a batch of images. Using Anti-Labeler can lead to faster convergence. The diversity within a batch of images can make the approach ineffective for combating label-conditioned mode collapse, especially for rare label combinations. Using Anti-Labeler helps with faster convergence. Results for a single binary label are presented, which can be extended to more labels. The analysis assumes a perfect Causal Controller. The analysis assumes a perfect Causal Controller and uses mappings due to generator, discriminator, Labeler, and Anti-Labeler. The generator loss function of CausalGAN contains label loss terms and an added loss term due to the discriminator, allowing for faster convergence and combating label-conditioned mode collapse. The Causal Controller 9, shorthand DISPLAYFORM0, D LG (.), and mappings for generator, discriminator, Labeler, and Anti-Labeler are key components in CausalGAN. The generator loss function includes label loss terms, GAN loss, and an additional term from the discriminator. This setup ensures the optimal generator outputs the class conditional image distribution, even with multiple binary labels. The Anti-Labeler and Labeler each have their own optimization problems to solve for a fixed generator. The optimal generator outputs the class conditional image distribution, even with multiple binary labels. The Anti-Labeler and Labeler have their own optimization problems to solve for a fixed generator. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true. The best CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution and the discriminator and labeler networks operate at their optimum. This result holds for a single binary label and can be extended to multiple binary variables. The CausalGAN generator samples from the class conditional image distribution when the Causal Controller samples from the true label distribution. The discriminator and labeler networks operate optimally, ensuring the best performance for a single binary label. This architecture is the only one with such a guarantee after CGAN. The proof can be extended to multiple binary variables. The optimal discriminator behavior is characterized by optimizing the GAN loss terms. The only conditional generative adversarial network architecture with a guarantee after CGAN 10 ensures optimal discriminator behavior by optimizing GAN loss terms. The generator minimizes its loss by sampling from class conditional distributions, leading to the global minimum of the virtual training criterion. The generator minimizes its loss by sampling from class conditional distributions, achieving the global minimum of the virtual training criterion. This two-stage procedure can train a causal implicit generative model for any causal graph where the Image variable is a sink node. The virtual training criterion C(G) is met when the generator output matches the class conditional image distribution. This two-stage procedure can train a causal implicit generative model for any causal graph with the Image variable as a sink node. The corollary discusses a causal implicit generative model for a causal graph with the Image variable as a sink node. It introduces a generator that can sample from the image distribution based on given label combinations. The objective is to extend the results to cases with multiple binary labels. The generator can sample from image distribution based on label combinations. The objective is to extend results to cases with multiple binary labels. The minimizer of C(G) samples from class conditional distributions given d labels. To extend results to cases with multiple binary labels, the generator can sample from class conditional distributions given d labels. An alternative architecture is proposed for experiments, using cross entropy loss terms for each label to simplify implementation with only d outputs. To simplify implementation with multiple binary labels, an alternative architecture using cross entropy loss terms for each label is proposed. This ensures the generator captures each label's posterior distribution, but does not guarantee true class conditional distributions for practical joint distributions. The generator captures each label's posterior distribution, but does not guarantee true class conditional distributions for practical joint distributions. However, for many joint distributions where labels are determined by the image, the joint label posterior will be true to the data distribution, implying the optimum generator samples from the class conditional distributions. Refer to Section 8.7 for formal results and details. The guarantee that the joint label posterior will be true to the data distribution implies that the optimum generator samples from the class conditional distributions. Trained causal implicit generative models can also sample from counterfactual distributions with known exogenous noise terms. Counterfactual sampling involves conditioning on an event and sampling from the push-forward of the posterior distributions of the exogenous noise terms under the interventional causal graph. In this section, a simple extension of BEGAN involves feeding image labels to the generator for counterfactual sampling. The interventional causal graph can be constructed by using rejection sampling and interventional sampling. An extension of BEGAN involves feeding image labels to the generator, utilizing a Labeler network for architecture modifications. The Causal Controller is used for interventional sampling in the context of architecture modifications, incorporating a Labeler network to label real images well and generated images poorly. Margin modifications are motivated by the need for better trained Labeler to provide meaningful gradients for label quality. In this section, CausalGAN and CausalBEGAN are trained on the CelebA Causal Graph. Margin modifications are inspired by the importance of a well-trained Labeler for meaningful gradients in label quality, with a necessary margin of margins term comparing different margins. In this section, CausalGAN and CausalBEGAN are trained on the CelebA Causal Graph, emphasizing the importance of label quality and informative label gradients. The dataset used satisfies the condition where changing the presence of a mustache does not affect the probability of being male. The Causal Controller was trained on the CelebA Causal Graph dataset, showing that changing the presence of a mustache does not affect the probability of being male. The top row displays both males and females with mustaches, while the bottom row only shows male images. The top row displays both males and females with mustaches, while the bottom row only shows male images. The generator never sees the label combination {Male = 0, Mustache = 1} during training. The conditional distribution P(.|Mustache = 1) shows only male images. The presence of a mustache does not affect the probability of being male in the CelebA Causal Graph dataset. The proposed generative model can create samples conditioned on labels and sample from interventional distributions. Theoretical analysis provides guarantees for correct sampling under interventions. Top row: Intervene Narrow Eyes=1, Bottom row: Condition Narrow. The proposed generative model can create samples conditioned on labels and sample from interventional distributions. Theoretical analysis provides guarantees for correct sampling under interventions. Intervening/Conditioning on Narrow Eyes label in CelebA Causal Graph with CausalBEGAN. Smiling \u2192 Narrow Eyes in CelebA Causal Graph, P(Smiling = 1|do(Narrow Eyes = 1)) = P(Smiling = 1) = 0.48. Intervening/Conditioning on Narrow Eyes label in CelebA Causal Graph with CausalBEGAN shows that conditioning on Narrow Eyes = 1 increases the proportion of smiling images. However, the generator in one image mistakenly rules out the possibility of Narrow Eyes = 0 instead of demonstrating Narrow Eyes = 1. Conditioning on Narrow Eyes = 1 increases the proportion of smiling images in the dataset, although the difference may not be statistically significant. The generator in one image mistakenly rules out the possibility of Narrow Eyes = 0 instead of demonstrating Narrow Eyes = 1. Causality leads to more creative generative models, as shown in CausalGAN and CausalBEGAN. The research demonstrates that causality leads to more creative generative models, illustrated with CausalGAN and CausalBEGAN. The structural causal model includes functions, random variables, and exogenous random variables. The research has been supported by various grants and corporations. The research, supported by various grants and corporations, focuses on a structural causal model (M) containing functions, random variables, and exogenous random variables. The model implies a joint distribution of observable variables (V) based on the distributions of E and functional relations F. The causal graph (D) is a directed acyclic graph on the nodes. The joint distribution of observable variables V is derived from the exogenous variables E and functional relations F. The causal graph D is a directed acyclic graph on nodes V, where a node Xj is a parent of node Xi if Xj is in the domain of fi. D forms a Bayesian network for the joint probability distribution over V, assuming causal sufficiency. The directed acyclic graph on nodes V represents a Bayesian network for the joint probability distribution over observable variables. Causal sufficiency is assumed, where every exogenous variable is a direct parent of at most one observable variable. Interventional distributions for causal Bayesian networks can be calculated from conditional probabilities and the causal graph. Under the assumption of causal sufficiency, interventional distributions for causal Bayesian networks can be calculated directly from conditional probabilities and the causal graph. This allows for the determination of the same interventional distributions for different variables. The joint data distribution and the joint distribution for the binary label and image are denoted as P r (l, x) and P g (l, x) respectively. Later, the binary label is generalized to be a vector. In this section, the joint data distribution and joint distribution for binary label and image are denoted as P r (l, x) and P g (l, x) respectively. Proposition 2 states the optimal discriminator D for fixed G. The optimum Labeler has D LR (x) = P r (l = 1|x) according to Lemma 1. The optimal discriminator D for fixed G is given by Proposition 2. The optimum Labeler has D LR (x) = P r (l = 1|x) as per Lemma 1. The optimal Anti-Labeler for a fixed generator with x \u223c P g (x) is discussed in Lemma 2. The optimal discriminator D for fixed G is given by Proposition 2. The optimum Labeler has D LR (x) = P r (l = 1|x) as per Lemma 1. The optimal Anti-Labeler for a fixed generator with x \u223c P g (x) is discussed in Lemma 2. The proof for the optimal discriminator and Anti-Labeler follows similar lines, considering the objective and assumptions of causal sufficiency. The optimum Anti-Labeler, with x \u223c P g (x), has D LG (x) = P g (l = 1|x). This assumes causal sufficiency, where exogenous variables do not affect more than one observable variable. Pearl's model assumes a product distribution over exogenous variables. The complete graph \"cG1\" is formed with added edges, and the graph rcG1 is obtained by reversing the direction of every edge in cG1. The generator loss C(G) is defined when discriminator, Labeler, and Anti-Labeler are at their optimum. The global minimum of the virtual training criterion C(G) is achieved when the generator output has the same distribution as the class conditional image distribution. The global minimum of the virtual training criterion C(G) is achieved when the generator output matches the class conditional image distribution. This is proven by the relations between the Labeler, Anti-Labeler, and discriminator. The optimum Labeler, Anti-Labeler, and discriminator relations prove that the generator objective is minimized when the class conditional image distribution is matched. This is achieved when the joint distribution over labels and images are equal. The joint distribution over labels and images is equal when P g = P d. A causal implicit generative model for the causal graph D is consistent with the causal graph D. The generator in a conditional GAN is given noise terms and labels. The generator G samples from the image distribution based on the label combination. In a conditional GAN, the concatenated generator neural network is consistent with the causal graph D. If C and G are perfect, they sample from the true label joint distribution and conditional image distribution. The concatenated generator neural network G(C(Z1), Z2) is consistent with the causal graph D, where D = (V \u222a {Image}, E \u222a {(V1, Image), (V2, Image), ... (Vn, Image)}). Assuming perfect C and G sample from true distributions, the concatenated model can sample from observational and interventional distributions, making it a causal implicit generative model for graph D. The concatenated model, consistent with causal graph D, can sample from true observational and interventional distributions, making it a causal implicit generative model. Extending the proof to multiple binary labels requires modifications due to the challenge of characterizing the correct joint distribution. Extending the proof to multiple binary labels poses challenges in characterizing the correct joint distribution. The difficulty lies in each labeler only learning about the posterior P(l j |x) for each label, which is insufficient for the generator to learn the correct joint distribution. Two solutions are proposed: (1) Estimating the probability of each of the 2^d label combinations, and (2) Assuming the label vector is a deterministic function of the image. From a theoretical perspective, two solutions are proposed to address the challenge of learning the correct joint distribution with multiple binary labels. The first solution involves estimating the probabilities of all label combinations, while the second solution assumes the label vector is a deterministic function of the image. This ensures that the generator can achieve the desired outcome at the minimizer of C(G). The extension presented in this section focuses on using Labelers to estimate label probabilities for a deterministic function of the image. The optimum Labeler with respect to loss is determined by the probability of a label given an image. The optimum Labeler with respect to loss is determined by the probability of a label given an image, as shown in the Lemma. The Labeler's function D LR is strictly positive on (label, image) combinations with positive probability, ensuring a finite loss. The Labeler's loss function can be written as a vector D LR (x) with coordinates. The loss is lower bounded by \u2212H(L x ) where H(L x ) is the Shannon entropy of L x. This minimum can be achieved. The Labeler loss function D LR (x) can be written as DISPLAYFORM3 where L x is a discrete random variable. The loss is lower bounded by \u2212H(L x ) and the optimum Labeler network gives the posterior probability of a label combination based on the observed image. The optimum Labeler network provides the posterior probability of a label combination based on the observed image, achieved by satisfying specific conditions. The Anti-Labeler network also has its own optimization problem to solve. The Anti-Labeler network solves an optimization problem where the coordinates sum to 1 using a softmax function. The optimum Anti-Labeler has D *LG (x)[j] = P g (l = j|x). The Anti-Labeler network optimizes the conditional entropy of labels given the image. The generator samples from class conditional image distributions given a specific label. The generator optimizes the conditional entropy of labels given the image. The optimal generator samples from class conditional image distributions based on a particular label combination. The global minimum of the virtual training criterion is determined when the Causal Controller samples from the true joint label distribution. The global minimum of the virtual training criterion is achieved when the generator samples from class conditional image distributions based on a particular label combination. This is determined by the Causal Controller sampling from the true joint label distribution. The virtual training criterion C(G) is optimized when the generator samples from class conditional image distributions based on specific label combinations. This is achieved by ensuring that P g (l, x) = P r (l, x) for the vector of labels. The Kullback-Leibler divergence is minimized when P g = P d jointly over labels and images. Relabeling combinations of binary labels as a 2 d label may be challenging in practice for a large number of labels. Theoretical guarantees for the implemented CausalGAN architecture with d labels are provided under the assumption of deterministic relationships between images and labels in the dataset. Theoretical guarantees are provided for the CausalGAN architecture with d labels, assuming deterministic relationships between images and labels in the dataset. This ensures the global optimal generator samples from class conditional distributions. The CausalGAN architecture with d labels assumes deterministic relationships between images and labels, ensuring the global optimal generator samples from class conditional distributions. The Anti-Labeler and Labeler optimize for fixed generators, while the generator optimizes for fixed discriminator, Labeler, and Anti-Labeler. The Anti-Labeler addresses an optimization problem in the CausalGAN architecture with d labels. The generator aims to achieve the global minimum of the virtual training criterion by matching conditional distributions and overall distributions between real and generated data. The global minimum of the virtual training criterion in the CausalGAN architecture is achieved when the conditional and overall distributions of real and generated data match. This ensures correct conditional sampling with all labels. The global minimum of the virtual training criterion in the CausalGAN architecture is achieved when the conditional and overall distributions of real and generated data match, ensuring correct conditional sampling with all labels. This is based on the assumption that the image determines all labels, which is relevant in practice. In the CausalGAN architecture, correct conditional sampling is ensured by assuming that the image determines all labels. This assumption is practical, as seen in the CelebA dataset, where label vectors are deterministic functions of the image. The lemma states that any discrete joint probability distribution can be expressed as a product of conditional probabilities. The lemma states that a discrete joint probability distribution can be represented as a product of conditional probabilities, where all marginal distributions are kronecker delta functions. The joint probability distribution is a product of kronecker delta functions for all marginal distributions. Proof by contradiction shows that the distribution is zero everywhere except at specific values. The joint probability distribution is proven to be zero everywhere except at specific values through a contradiction. This implies that the distribution is 1 at those specific values. Applying this lemma to the conditional distribution P g (l 1 , l 2 , . . . , l d |x) is straightforward. The joint probability distribution is proven to be zero everywhere except at specific values, where it is 1. Applying this lemma to the conditional distribution P g (l 1 , l 2 , . . . , l d |x) is straightforward, as shown in Proposition 3. The joint probability distribution is proven to be a product distribution by Lemma 5, where every marginal distribution is a kronecker delta function. This implies that P r (x|l 1 , l 2 , . . . , l n ) = P g (x|l 1 , l 2 , . . . , l n ) due to equal marginal distributions. In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from the class conditional image distributions, as proven by the joint probability distribution being a product distribution with kronecker delta functions as marginal distributions. This implies that P r (x|l 1 , l 2 , . . . , l n ) = P g (x|l 1 , l 2 , . . . , l n) due to equal marginal distributions. In this section, a simple extension of BEGAN is proposed where image labels are fed to the generator. The optimum generator samples from the class conditional image distributions, as proven by the joint probability distribution being a product distribution with kronecker delta functions as marginal distributions. This implies that the generator samples from the class conditional image distributions. The central contribution of BEGAN is a control theory-inspired boundary equilibrium approach that encourages generator training only when the discriminator is near optimum and its gradients are the most informative. The introduction of a new loss and a set of margins reflects the idea that label gradients are most informative when the image quality is high. The new approach introduces a loss and margins that prioritize label gradients when image quality is high. This is an extension of BEGAN, emphasizing generator training when the discriminator is near optimum. The new approach introduces a loss and margins that prioritize label gradients when image quality is high, extending BEGAN to emphasize generator training near discriminator optimality. The loss functions incorporate labels but require further refinement. The generator in the image sample is labeled with l g. Extending the BEGAN loss formulation to include labels introduces a margin-coefficient tuple (b 2 , c 2) for meaningful gradients in training. The BEGAN formulation introduces a margin-coefficient tuple (b 2 , c 2) to address the use of margins in training. The generator aims to minimize two loss terms, but image quality may suffer as images exploiting the Labeler network may not be realistic. Label loss may not provide useful gradients for training. The generator in the BEGAN formulation minimizes two loss terms, but image quality may suffer when images exploiting the Labeler network are not realistic. Label loss may not provide useful gradients unless the image quality remains good. To address this, a new margin of margins term, b3, is introduced to encourage the generator to incorporate label loss only when the image quality margin b1 is large compared to the label margin b2. The generator in the BEGAN formulation minimizes two loss terms, but image quality may suffer when label loss is not realistic. A new margin of margins term, b3, is introduced to encourage the generator to incorporate label loss only when the image quality margin b1 is large compared to the label margin b2. This extension preserves the property of a monotonically decreasing scalar to track convergence during optimization. Our extension of BEGAN introduces learning rates for coefficients and maintains a monotonically decreasing scalar to track optimization convergence. We explore training causal implicit generative models using GANs and investigate their behavior when the true data distribution comes from a different causal graph. In Section 4, a GAN was used to train a causal implicit generative model by incorporating the causal graph into the generator structure. The study investigates the convergence of causal implicit generative models on synthetic data with different causal graphs: \"line,\" \"collider,\" and \"complete.\" Each node's value is computed using a cubic polynomial in n + 1 variables. The study explores the convergence of causal implicit generative models on synthetic data with different causal graphs: \"line,\" \"collider,\" and \"complete.\" Each node's value is computed using a cubic polynomial in n + 1 variables, and the results of 20 runs for each model are averaged. The convergence of the joint distribution to the true joint is compared in terms of the total variation distance for each data generating graph. The study compares the convergence of causal implicit generative models on synthetic data with different causal graphs: \"line,\" \"collider,\" and \"complete.\" Data is generated from line causal graph X \u2192 Y, and results are averaged over 20 runs for each model. The joint distribution convergence is measured in terms of total variation distance. The generator is structured based on different causal graphs: line, collider, and complete. Generators with no knowledge of causal structure are also included. Results are shown in FIG9 for data generated from various causal graphs. Each curve represents the convergence behavior of the generator distribution based on the causal graph used. The generator is structured based on different causal graphs: line, collider, and complete. Results in FIG9 show convergence behavior of the generator distribution based on the causal graph used. The correct Bayesian network should be able to fit to the true joint distribution. The causal graph used to structure the generator can generate the joint distribution from the true causal graph. Complete graph can encode all joint distributions, making it suitable for all data generation models. Standard fully connected layers correspond to a causal graph with a latent variable causing observable variables. The convergence behavior of adversarial training across these models is being explored in FIG9 for the line graph data X \u2192 Y \u2192 Z. The convergence behavior of adversarial training across different causal generative models is being explored. The best performance is seen when using a line graph in the generator architecture, with complete graphs also showing good convergence. Fully connected networks with 3 layers perform well, but surprisingly those with 5 and 10 layers perform much worse. The best convergence behavior is observed when using a line graph in the generator architecture. Complete graphs also show good convergence, while fully connected networks with 3 layers perform well. However, fully connected networks with 5 and 10 layers perform much worse. The number of layers in fully connected networks needs to be tuned for optimal performance in adversarial training. Using the wrong Bayesian network, such as the collider, results in worse performance. In practice, the number of layers in a fully connected generator should be tuned for optimal performance in adversarial training. Using the wrong Bayesian network, like the collider, leads to worse performance. Surprisingly, a fully connected generator with 3 and 5 layers shows the best performance for the collider graph. The number of layers is crucial, with 10 layers resulting in the worst convergence behavior. Complete and collider graphs achieve decent performance, while the line graph performs worse. In contrast to the optimal performance of a fully connected generator with 3 and 5 layers, using 10 layers results in the worst convergence behavior. Complete and collider graphs perform decently, while the line graph, a wrong Bayesian network, shows the worst performance. The fully connected 3 performs the best, followed by fully connected 5 and 10. Line and collider graphs perform the worst due to incomplete encoding of distributions. Evaluation on a generated dataset using the wrong causal graph X1 \u2192 X2 \u2192 X3 is shown in FIG10. The scatter plot in FIG10 displays a three-dimensional distribution generated using the causal graph X1 \u2192 X2 \u2192 X3. The generator causal graph affects the distribution, with an improvement seen when adding the edge Young \u2192 Male. Both graphs include the edge Male \u2192 Mustache, indicating the learning that women do not have mustaches. The graph G1 treats Male and Young labels as independent but still approximates well. Adding the edge Young \u2192 Male improves the learned distribution. Using the correct graph gives a close scatter plot to the original data, while using the wrong Bayesian network results in a different distribution. The causal graphs used for experiments on the CelebA dataset are discussed. The CelebA Causal Graph (G1) is a completed version of a causal graph on a subset of image labels from the CelebA dataset. It includes labels like Young, Male, Eyeglasses, Bald, Mustache, Smiling, Wearing Lipstick, Mouth Slightly Open, and Narrow Eyes. The ordering in the graph shows causal relationships, such as Male causing Smiling. The CelebA Causal Graph (G1) is a completed version of a causal graph on image labels from the CelebA dataset. It shows causal relationships like Male causing Smiling. The graph rcG1 is formed by reversing every edge in cG1. Using the incorrect Bayesian network for the data generates Male and Young independently, which is incorrect. Comparing pairwise distributions in TAB0 shows that G1 still learns a reasonable approximation to the true distribution. The CelebA Causal Graph (G1) shows causal relationships like Male causing Smiling. The graph rcG1 is formed by reversing every edge in cG1. Using the incorrect Bayesian network for the data generates Male and Young independently. Comparison of pairwise distributions in TAB0 demonstrates that for G1 a reasonable approximation to the true distribution is still learned for {Male, Young} jointly. For cG1 a nearly perfect distributional approximation is learned. Despite this inaccuracy, both graphs G1 and cG1 lead to Causal Controllers that never output the label combination {Female, Mustache}. The CelebA Causal Graph (G1) and its reversed version rcG1 show causal relationships. Comparison of distributions reveals that G1 approximates the true distribution for {Male, Young} jointly, while cG1 is nearly perfect. Despite inaccuracies, both graphs lead to Causal Controllers avoiding {Female, Mustache} label combination. The Wasserstein GAN ensures convergence of output distribution to discrete labels. The original form with Lipshitz discriminator ensures convergence in distribution of the Causal Controller output to discrete labels. A modified version of Wasserstein GAN with penalized gradient is used. The outputs have \"approximately discrete\" support, as shown in FIG12. TVD may not always be intuitive, as demonstrated in the example with 9 labels and TVD of 0.14. In FIG12, the joint label distribution is sampled 1000 times, showing good convergence for both graphs. The CelebA Causal Graph and its completion allow training of reasonable marginal distributions for all labels, with the worst label being off by no more than 0.03. The CelebA Causal Graph and its completion (cG1) enable training of accurate marginal distributions for all labels, with the worst label being off by no more than 0.03. The Wasserstein Causal Controller's performance is tested on a subset of binary labels from the CelebA dataset using the causal graph from FIG6. The Wasserstein Causal Controller's performance is tested on a subset of binary labels from the CelebA dataset using the causal graph from FIG6. The generator learns a mapping from continuous noise to a discrete distribution, with 96% of samples appearing as an almost discrete distribution. The Wasserstein training allows the generator to learn a mapping from continuous noise to a discrete distribution. The Causal Controller outputs an almost discrete distribution with 96% of samples near 0 or 1. Total variational distance (TVD) shows convergence for CelebA Causal Graph, defined completion, and completion with reversed arrows. The Causal Controller outputs an almost discrete distribution with 96% of samples near 0 or 1. Total variational distance (TVD) shows convergence for CelebA Causal Graph, defined completion, and completion with reversed arrows, with TVD decreasing to 0 for cG1 and rcG1. G1's TVD asymptotes to around 0.14, indicating incorrect conditional independence assumptions. This suggests that any complete causal graph can lead to a nearly perfect implicit causal generator over labels, and partially incorrect causal graphs can still give reasonable convergence. In this section, additional CausalGAN results are presented, showing the effects of intervening vs conditioning on the \"Wearing Lipstick\" label in CelebA Causal Graph. The CelebA Causal Graph indicates a causal relationship where \"Male\" influences \"Wearing Lipstick\", leading to expectations regarding interventions and conditions. In this section, additional CausalGAN results are presented, focusing on intervening vs conditioning on the \"Wearing Lipstick\" label in CelebA Causal Graph. The top row shows both males and females wearing lipstick, while the bottom row only displays female images due to the conditional distribution. In CelebA Causal Graph, the top row displays both males and females wearing lipstick, while the bottom row only shows female images due to the dataset's distribution. Intervening vs Conditioning on Narrow Eyes is also discussed in the context of the CelebA Causal Graph. The CelebA Causal Graph displays images of females wearing lipstick, and the concept of Intervening vs Conditioning on Narrow Eyes is discussed. In the dataset, conditioning on Narrow Eyes = 1 increases the proportion of smiling images, although the difference may not be statistically significant with only 10 images. Training CausalBEGAN on CelebA dataset using CelebA Causal Graph. Causal Controller pretrained with Wasserstein loss used for training. Empirical justification for margin of margins introduced. Image quality affected when removing margin effect. The study trained CausalBEGAN on the CelebA dataset using a CelebA Causal Graph. The Causal Controller was pretrained with a Wasserstein loss. Empirical justification was provided for the margin of margins introduced, showing deteriorating image quality for rare labels when the margin effect was removed. The difference between interventional and conditional sampling for specific labels was illustrated in figures. The study demonstrated the impact of removing the margin effect on image quality for rare labels. Intervening vs conditioning on specific labels like Bald showed differences in sampling methods. The CelebA Causal Graph was used to show that intervening on Bald did not affect the probability of Male = 1. The top row displayed both bald males and females, while the bottom row only showed male images sampled from the conditional distribution. Intervening on Bald label in CelebA Causal Graph does not affect the probability of Male = 1. The top row displays both bald males and females, while the bottom row shows only male images sampled from the conditional distribution. Conditioning on Mouth Slightly Open = 1 increases the probability of Smiling = 1. The distribution P(.|Bald = 1) in the dataset shows only male images. Conditioning on Mouth Slightly Open = 1 increases the proportion of smiling images, although the difference may not be statistically significant. Additional simulations for CausalGAN are provided in this section. In this section, additional simulations for CausalGAN are presented. Figures 16a-16d demonstrate the conditional image generation properties of CausalGAN by varying a single label while keeping others fixed. Figure 17 shows 256 randomly sampled images to assess mode collapse and image diversity. Simulation results for CausalBEGAN are also provided, highlighting the importance of the third margin term b3. In this section, additional simulation results for CausalBEGAN are presented. The third margin term b3 is shown to be important, as omitting it affects the image quality of rare labels. A scalar \"M\" is defined, which decreases monotonically during training, with an extension M complete that maintains this property. See FIG9 for the visualization of M complete decreasing. The third margin term is crucial for image quality of rare labels in CausalBEGAN. A scalar \"M\" decreases monotonically during training, with an extension M complete that also maintains this property. Conditional image generation properties are demonstrated using \"label sweeps\" in FIG3. The generator in CausalBEGAN is not always a continuous function. The scalar \"M\" in CausalBEGAN decreases monotonically during training, showing image diversity with a random sampling of 256 images. The generator in this architecture learns a discrete function with respect to its label input parameters. The CausalBEGAN architecture's generator learns a discrete function with label input parameters. A random sampling of 256 images is used to show image diversity. The approach involves jointly training an implicit causal generative model for labels and images, treating the image as part of the causal graph. One way to feed both labels and images to the discriminator is by encoding the label as a constant image in an additional channel. The approach involves training an implicit causal generative model for labels and images, treating the image as part of the causal graph. One way to feed both labels and images to the discriminator is by encoding the label as a constant image in an additional channel. However, in the CelebA Causal Graph, image generation was not learned, possibly due to the discriminator focusing on labels without providing useful gradients to the image generation. The implementation details of the Wasserstein Causal Controller for generating face labels were explained, using the total variation distance (TVD) as a metric to evaluate model success. The gradient term as a penalty was estimated to address issues with image generation in the CelebA Causal Graph. The implementation details of the Wasserstein Causal Controller for generating face labels were explained, using the total variation distance (TVD) as a metric to evaluate model success. The gradient term as a penalty was estimated by evaluating the gradient at points interpolated between real and fake batches, allowing the Causal Controller to output discrete labels. The Wasserstein approach allows training the Causal Controller to output discrete labels. The generator architecture is based on a causal graph, using uniform noise as exogenous variables and neural networks for mapping parents to children. Training involved 25 Wasserstein discriminator updates per generator update with a learning rate of 0.0008. The generator architecture in the Causal GAN framework is structured based on a causal graph using uniform noise and neural networks. Training involves 25 Wasserstein discriminator updates per generator update with a learning rate of 0.0008. The model is trained using stochastic gradient descent and DCGAN Radford et al. (2015) implementation of generative adversarial networks is extended with Labeler networks and a Causal Controller network. In the Causal GAN framework, the model is trained using stochastic gradient descent with a learning rate of 0.0008. DCGAN is extended with Labeler networks and a Causal Controller network, making 6 generator updates for each discriminator update on average. Loss terms contain a single binary label, but in practice, a d-dimensional label vector is used. In the Causal GAN framework, the model is trained using stochastic gradient descent with a learning rate of 0.0008. Compared to DCGAN, 6 generator updates are made for each discriminator update on average. The discriminator and labeler networks are updated concurrently in a single iteration. The loss terms defined in Section 5.2.1 contain a single binary label, but in practice, a d-dimensional label vector is used. The Labeler and Anti-Labeler loss terms are extended by averaging the loss terms for every label. In the Causal GAN framework, the model is trained using stochastic gradient descent with a learning rate of 0.0008. The labeler and anti-labeler loss terms are extended by averaging the loss terms for every label in a d-dimensional label vector. The approach differs from the architecture in Section 8.6, where the discriminator estimates probabilities of all label combinations given the image. This approach may not sample from class conditional distributions if the data distribution is not restricted. In the Causal GAN framework, the model is trained with a learning rate of 0.0008. The discriminator outputs a length-2 d vector to estimate label probabilities given the image. The architecture is sufficient for labeled image datasets where labels are determined by the image. Swapping the order of terms in the cross entropy expressions for labeler losses has improved image sharpness. For more details, refer to Section 8.7 in the supplementary material. In the Causal GAN framework, the architecture is sufficient for labeled image datasets where labels are determined by the image. Swapping the order of terms in the cross entropy expressions for labeler losses has improved image sharpness. Labels input to CausalBEGAN are taken from the Causal Controller, with minimal parameter tuning. The learning rate for both the generator and discriminator is 0.00008, with simultaneous updates and \u03b3 values set to 0.5. The Causal GAN framework has improved image sharpness by swapping the order of terms in labeler losses. Labels for CausalBEGAN are from the Causal Controller with minimal parameter tuning. The learning rate for both generator and discriminator is 0.00008, with \u03b3 values set to 0.5. Customized margin learning rates are used to reflect the generator's response speed to each margin. In the Causal GAN framework, customized margin learning rates are utilized to reflect the generator's response speed to each margin, with \u03b3 values set to 0.5. The best performing models exhibit all three margins being \"active\" near 0 while frequently taking small positive values. In the Causal GAN framework, customized margin learning rates are used to reflect the generator's response speed to each margin. The best models have all three margins \"active\" near 0 while frequently taking small positive values. Comparing CausalGAN behavior with and without Anti-Labeler network shows that using Anti-Labeler leads to faster convergence and provides more diverse images for very rare labels."
}