{
    "title": "rkeNfp4tPr",
    "content": "Stochastic gradient descent with stochastic momentum is commonly used in nonconvex stochastic optimization, especially for training deep neural networks. The addition of a momentum term biases the parameter update in the direction of the previous change. Empirical evidence suggests that stochastic momentum is beneficial in training deep networks. In non-stochastic convex optimization, momentum adjustment reduces convergence time. However, its benefits in stochastic and non-convex settings have been unclear. Stochastic momentum, observed to improve convergence time in training deep networks, lacks theoretical justification. This paper proposes that stochastic momentum enhances deep network training by biasing parameter updates towards previous changes. Stochastic momentum improves deep network training by modifying SGD to escape saddle points faster and find a second order stationary point more quickly. The ideal momentum parameter should be large (close to 1) according to theoretical analysis, aligning with empirical findings. SGD with stochastic momentum accelerates deep network training by escaping saddle points faster and finding second order stationary points more quickly. The ideal momentum parameter should be large (close to 1) based on theoretical analysis, which is supported by empirical findings. SGD with stochastic momentum is a widely used algorithm in nonconvex optimization and deep learning, with empirical and experimental findings supporting its effectiveness. It is commonly utilized in various machine learning applications such as computer vision, speech recognition, natural language processing, and reinforcement learning. SGD with stochastic momentum is widely used in machine learning applications like computer vision, speech recognition, natural language processing, and reinforcement learning. It has been shown to lead to faster convergence compared to standard SGD, making it an essential tool for designing new optimization algorithms. SGD with stochastic momentum has been widely observed to lead to faster convergence compared to standard SGD. The success of momentum makes it a necessary tool for designing new optimization algorithms in deep learning. Popular variants of adaptive stochastic gradient methods like Adam or AMSGrad include the use of momentum. Despite its wide use, the justification for the empirical improvements remains elusive. In this paper, a theoretical analysis is provided for stochastic momentum in optimization algorithms like Adam and AMSGrad, which have been observed to lead to faster convergence in deep learning. The momentum parameter setting, such as \u03b2 = 0.9, has shown practical success despite lacking clear empirical justification. In this paper, a theoretical analysis is provided for stochastic momentum in optimization algorithms like Adam and AMSGrad. Large momentum values (e.g. \u03b2 = 0.9) have been observed to work well in practice. Algorithm 1 is the default momentum method in popular software packages. The analysis includes setting the momentum parameter and mild conditions for SGD with stochastic momentum. The theoretical analysis for SGD with stochastic momentum shows that it can escape saddle points faster than standard SGD. Stochastic heavy ball momentum maintains a weighted average of stochastic gradients for updates. In this paper, the focus is on finding second-order stationary points for smooth non-convex optimization using SGD with stochastic heavy ball momentum. The analysis demonstrates that this approach can amplify the escape direction of saddle points. The paper focuses on finding second-order stationary points for smooth non-convex optimization using SGD with stochastic heavy ball momentum. It aims to amplify the escape direction of saddle points in the optimization process. The paper addresses the challenge of finding approximate second-order stationary points in nonconvex optimization, emphasizing the importance of obtaining a second-order guarantee. In nonconvex optimization, the goal is to reach an approximate second-order stationary point with the use of momentum, following related works that emphasize the importance of a second-order guarantee. The text discusses reaching a second-order stationary point in nonconvex optimization with the use of momentum, following related works emphasizing the importance of a second-order guarantee. The text discusses the use of momentum in reaching a second-order stationary point in nonconvex optimization, emphasizing the importance of a second-order guarantee. It introduces the Correlated Negative Curvature (CNC) assumption and shows how the recursive dynamics of SGD with heavy ball momentum help in escaping saddle points faster. The text discusses the use of momentum in reaching a second-order stationary point in nonconvex optimization, emphasizing the importance of a second-order guarantee. It introduces the Correlated Negative Curvature (CNC) assumption and shows how the recursive dynamics of SGD with heavy ball momentum help in escaping saddle points faster. Let v t be the eigenvector corresponding to the smallest eigenvalue of \u2207 2 f (w t ). The stochastic momentum m t satisfies CNC at t with parameter \u03b3 > 0. If SGD with momentum has properties called Almost Positively Aligned with Gradient (APAG), Almost Positively Correlated with Gradient (APCG), and Gradient Alignment or Curvature Exploitation (GrACE), then it takes T = O((1 \u2212 \u03b2) log(1/(1 \u2212 \u03b2) ) \u221210 ) iterations to return an ( . The text discusses the use of momentum in nonconvex optimization to reach a second-order stationary point faster. It highlights the importance of properties like APAG, APCG, and GrACE in SGD with momentum, showing that a larger momentum parameter \u03b2 helps in escaping saddle points. The theoretical result states that T = O((1 \u2212 \u03b2) log(1/(1 \u2212 \u03b2) ) \u221210 ) iterations are needed for an ( , ) second order stationary point, or T = O((1 \u2212 \u03b2) log(1/(1 \u2212 \u03b2) ) \u22125 ) iterations for an ( , \u221a ) second order stationary point. Theoretical results show that a larger momentum parameter \u03b2 helps in escaping saddle points faster in nonconvex optimization. It is demonstrated that T = O((1 \u2212 \u03b2) log(1/(1 \u2212 \u03b2) ) \u221210 ) iterations are needed for an ( , ) second order stationary point, or T = O((1 \u2212 \u03b2) log(1/(1 \u2212 \u03b2) ) \u22125 ) iterations for an ( , \u221a ) second order stationary point. This sheds light on why SGD with momentum enables faster training in optimization and deep learning. The text discusses the benefits of stochastic momentum in optimization and deep learning, particularly in avoiding saddle points. The use of momentum parameter \u03b2 helps in escaping saddle points faster, leading to faster training. The notation E t [\u00b7] is used to represent conditional expectation. The text explains the advantage of stochastic momentum in avoiding saddle points during optimization. It highlights how the momentum parameter helps parameters escape saddle points faster for quicker training. When facing saddle points, gradient updates may drift slowly, hindering escape. Moving along the smallest eigenvector of the Hessian matrix guarantees a faster escape with proper step size constraints. Directly computing the negative eigenvector is costly, making 2nd-order methods impractical. Moving along the smallest eigenvector of the Hessian matrix guarantees a faster escape from saddle points, but direct computation is costly. Daneshmand et al. (2018) assume that stochastic gradients are strongly non-orthogonal to the direction of large negative curvature, which helps drive updates out of saddle points. In the study of stochastic momentum, the CNC property requires that the update direction is strongly non-orthogonal to the direction of large negative curvature. This ensures that updates escape the saddle point region. In stochastic momentum, the update direction must be non-orthogonal to the negative curvature direction to escape the saddle point region. The momentum update amplifies this effect in successive iterations when the momentum parameter is close to 1. If the update direction has significant correlation with the negative curvature direction, the updates in each round are close to multiples of the previous update. In stochastic momentum, the update direction must be non-orthogonal to the negative curvature direction to escape the saddle point region. The momentum update amplifies this effect in successive iterations when the momentum parameter is close to 1. The updates in each round are close to multiples of the previous update, accelerating the escape process. The momentum update in stochastic momentum accelerates the escape process from saddle points by a factor of 1 \u2212 \u03b2. The benefit of stochastic momentum is empirically established, showing a clear improvement in performance. The text discusses the benefits of stochastic momentum in accelerating the escape process from saddle points by a factor of 1 \u2212 \u03b2. It also highlights the empirical evidence of improved performance in stochastic optimization tasks with significant saddle points. The text discusses constructing two stochastic optimization tasks with significant saddle points. Problem (3) involves a non-convex optimization challenge with a saddle point represented by matrix H and stochastic gaussian perturbations. The convergence in function value f(\u00b7) is plotted for these tasks. In a non-convex optimization task with saddle points represented by matrix H and stochastic gaussian perturbations, the origin is near saddle points. Convergence in function value f(\u00b7) is plotted, with initialization at w0 = 0 and all algorithms using step size \u03b7 = 5 \u00d7 10 \u22125. Progress is measured in relative distance to the true model w*, capturing the global sign of the objective. In a non-convex optimization task with saddle points, convergence in function value f(\u00b7) is plotted with initialization at w0 = 0 and step size \u03b7 = 5 \u00d7 10 \u22125. Progress is measured in relative distance to the true model w*, capturing the global sign of the objective. SGD and SGD with momentum are initialized at the origin to escape saddle points before convergence. The second objective (4) relates to the phase retrieval problem with real applications. The algorithms are initialized at the same point with a step size of \u03b7 = 5 \u00d7 10 \u22124. The second objective involves the phase retrieval problem with real applications in physical sciences. Convergence is observed for both objectives in the experiment. In phase retrieval, the convergence of optimization trajectories is accelerated by larger choices of \u03b2. Large-momentum trajectories escape saddle points more quickly than those with smaller momentum, as shown in empirical findings. The heavy ball method accelerates convergence in phase retrieval with larger choices of \u03b2, as large-momentum trajectories escape saddle points more quickly than smaller momentum ones. This empirical finding establishes the speed-up of stochastic momentum for optimal solutions. The heavy ball method accelerates convergence in phase retrieval with larger choices of \u03b2, as large-momentum trajectories escape saddle points more quickly than smaller momentum ones. This empirical finding establishes the speed-up of stochastic momentum for optimal solutions. The heavy ball method, proposed by Polyak in 1964, shows no convergence speedup over standard gradient descent in the deterministic setting, except in cases like convex quadratic objectives where an \"accelerated\" rate is possible. The heavy ball method does not provide a convergence speedup over standard gradient descent, except in cases like convex quadratic objectives where an \"accelerated\" rate is possible. Specialized algorithms aim at reaching a second order stationary point by exploiting negative curvature explicitly. Our work belongs to the category of specialized algorithms designed to exploit negative curvature explicitly and escape saddle points faster. Jin et al. (2017) demonstrated that adding isotropic noise guarantees gradient descent escapes saddle points and reaches a second order stationary point. Our work, like Jin et al. (2017), focuses on exploiting negative curvature to escape saddle points efficiently. Phase retrieval is known to have strict saddle properties, making it nonconvex. Daneshmand et al. (2018) build on the idea that stochastic gradient inherently aids in this process. Phase retrieval is nonconvex with strict saddle properties, where every local minimizer is global up to phase and each saddle exhibits negative curvature. Daneshmand et al. (2018) assume the Correlated Negative Curvature (CNC) for stochastic gradient to avoid perturbing updates with isotropic noise. Our work assumes Correlated Negative Curvature (CNC) for stochastic momentum instead of gradient, comparing results with related works in Appendix A. We assume gradient \u2207f is L-Lipschitz and Hessian \u22072f is \u03c1-Lipschitz, ensuring convergence. Stochastic gradient is bounded. The analysis of stochastic momentum in our work relies on three key properties of the dynamic: assuming CNC for the stochastic momentum instead of the gradient, ensuring the gradient is L-Lipschitz and the Hessian is \u03c1-Lipschitz, and bounding the stochastic gradient and stochastic momentum. The analysis of stochastic momentum in our work relies on three key properties of the dynamic: assuming CNC for the stochastic momentum instead of the gradient, ensuring the gradient is L-Lipschitz and the Hessian is \u03c1-Lipschitz, and bounding the stochastic gradient and stochastic momentum. SGD with stochastic momentum satisfies Almost Positively Aligned with Gradient (APAG) if certain conditions are met. SGD with stochastic momentum satisfies Almost Positively Aligned with Gradient (APAG) and Almost Positively Correlated with Gradient (APCG) with parameter \u03c4. The SGD with momentum exhibits Gradient Alignment or Curvature Exploitation (GrACE) if certain conditions are met. SGD with stochastic momentum satisfies Almost Positively Correlated with Gradient (APCG) with parameter \u03c4 if there exists a positive constant c, where the PSD matrix M t is defined for any integer 1 \u2264 k \u2264 \u03c4 \u2212 1, and \u03b7 is a step size ensuring each G s,t is PSD. The momentum term must not be significantly misaligned with the gradient \u2207f (w t ) to exhibit Gradient Alignment or Curvature Exploitation (GrACE). The Almost Positively Correlated with Gradient (APCG) property requires that the momentum term is aligned with the gradient, ensuring progress in the algorithm. This alignment is crucial when the gradient is large, guaranteeing that the algorithm makes advancements. The APCG property ensures that the momentum term is aligned with the gradient for progress in the algorithm, especially when the gradient is large. The PSD matrix M_t measures the local curvature of the function with respect to the trajectory of the SGD with momentum dynamic. The PSD matrix M_t measures the local curvature of the function with respect to the trajectory of the SGD with momentum dynamic. Empirically, this property holds on natural problems for a reasonable constant c. APCG is only needed when the update is in a saddle region with significant iterations. The value is large when the gradient is \u2265 0.02, except during the transition. The value is almost always nonnegative. The experiments show that SGD with momentum exhibits APAG and APCG properties. The value of Gs,t is plotted and reported in saddle point regions, with Mt being almost always nonnegative. The experiments demonstrate that SGD with momentum displays APAG and APCG properties. The value of Gs,t is plotted in saddle point regions, with Mt being consistently nonnegative. Additionally, for the phase retrieval problem, expected values may be nonnegative even with negative curvature. In experiments, it was observed that for the phase retrieval problem, expected values may be nonnegative even with negative curvature. The analysis does not require APCG to hold when the gradient is large or at a second-order stationary point. GrACE measures alignment between stochastic momentum and gradient, with the first term being small when they are aligned and the second term being small when momentum can exploit. The alignment between stochastic momentum and the gradient is measured by the first term on the left-hand side of the equation, while the curvature exploitation is measured by the second term. A small sum of these terms allows for bounding the function value of the next iterate. When the stochastic momentum exploits negative curvature, a small sum of terms allows bounding the function value of the next iterate. Figures 3 and 4 show quantities related to APAG, APCG, and GrACE when solving problems using SGD with momentum. The analysis follows a similar template to previous works. The analysis in the current section reports quantities related to APAG, APCG, and the gradient norm when solving problems using SGD with momentum. The proof is structured into three cases, leading to a second-order stationary region. The algorithm analyzed is similar to Algorithm 1 but with a larger step size. The proof by Staib et al. (2019) is structured into three cases, leading to a second-order stationary region. Algorithm 2 is analyzed, with a larger step size compared to Algorithm 1. Key parameters include step size, momentum, and period. The analysis of Algorithm 2 involves increasing the step size to a larger value r. Key parameters include step size, momentum, and period. The algorithm shows progress in certain cases and weakly hurts progress in others. Ultimately, it proves the existence of a second-order stationary point. The algorithm involves setting stochastic momentum and learning rate parameters. Progress is shown in specific cases, and a second-order stationary point is reached with high probability. The analysis introduces novel momentum analysis and borrows tools from previous studies. Theorem 1 assumes certain conditions for stochastic momentum and gradient values for the algorithm to have the APAG property. The analysis introduces novel momentum analysis and borrows tools from previous studies to prove that stochastic momentum reaches a second-order stationary point with high probability under certain conditions. The analysis shows that stochastic momentum for SGD reaches a second-order stationary point with high probability under specific conditions. Higher \u03b2 values help escape saddle points faster, leading to faster convergence. The proof of this theorem is detailed in Subsection 3.2.1. Higher \u03b2 enables faster escape from saddle points, reaching second-order stationary points quicker. Constraints on \u03b2 prevent it from being too close to 1. Our result's T thred has a dependency on 1 \u2212 \u03b2, making it smaller than that of Daneshmand et al. (2018). In Appendix G, minor constraints on \u03b2 are needed to prevent it from being too close to 1. The T thred of our result has a dependency on 1 \u2212 \u03b2, showing faster escape from saddle points with momentum compared to Daneshmand et al. (2018). In the high momentum regime, Algorithm 2 is proven to be strictly better than CNC-SGD. In the high momentum regime, Algorithm 2 is shown to be superior to CNC-SGD, demonstrating faster escape from saddle points with momentum. Empirically, it is found that certain conditions are easily satisfied for a wide range of \u03b2 in the phase retrieval problem. In the phase retrieval problem, it is found empirically that certain conditions are easily satisfied for a wide range of \u03b2. The process of escaping saddle points by SGD with momentum is analyzed, showing that it takes at most T thred iterations to escape a region with small gradient and large negative eigenvalue of the Hessian. SGD with momentum takes at most T thred iterations to escape a region with small gradient and large negative eigenvalue of the Hessian. When it escapes, the function value decreases by at least F thred = O( 4 ) on expectation. The function value decreases by at least F thred = O(4) on expectation in T thred iterations, proven by contradiction using upper and lower bounds analysis. The analysis shows that the function value must decrease by at least F thred in T thred iterations on expectation, with a contradiction between upper and lower bounds. Larger momentum can help in escaping saddle points faster. Lemma 1 provides an upper bound on the expected distance. The analysis indicates that the function value must decrease by at least F thred in T thred iterations on expectation. Larger momentum can aid in escaping saddle points faster. Lemma 1 offers an upper bound on the expected distance, while Lemma 2 provides a lower bound based on the recursive dynamics of SGD with momentum. Lemma 2 provides a lower bound on the expected distance using the recursive dynamics of SGD with momentum. The proof of Lemma 2 is in Appendix D. Additionally, Lemma 3 shows the dominant term in the lower bound. Lemma 3 further analyzes the lower bound of the expected distance in the context of the recursive dynamics of SGD with momentum. It focuses on the critical component necessary to ensure the lower bound surpasses the upper bound of the expected distance. The proof involves the eigenvector of the Hessian matrix corresponding to the minimum eigenvalue. Lemma 3 analyzes the lower bound of the expected distance in SGD with momentum, focusing on ensuring it surpasses the upper bound. The proof involves the eigenvector of the Hessian matrix corresponding to the minimum eigenvalue. The lower bound grows exponentially with t and the momentum parameter \u03b2. Lemma 5 states that if SGD with momentum has the APCG property, certain conditions must be met. The lower bound in SGD with momentum grows exponentially with t and \u03b2, surpassing the upper bound. Lemma 5 states that for SGD with momentum to have the APCG property, specific conditions must be satisfied. This leads to a lower bound that grows exponentially with time and momentum, surpassing the upper bound. SGD with momentum has the APCG property, which allows it to reach a second-order stationary point faster with a higher momentum parameter. The practice of using a large momentum value is justified as it helps in escaping strict saddle points faster. However, ensuring that SGD with momentum possesses these properties is not clear, and further research is needed to identify conditions that guarantee these properties. SGD with momentum escapes strict saddle points faster by enlarging the projection to an escape direction. The conditions guaranteeing the properties of SGD with momentum are unclear, but understanding why they hold in phase retrieval could be a starting point. Results suggest insights into the success of SGD with momentum in non-convex optimization and deep learning. The heavy ball method, proposed by Polyak in 1964, does not provide a convergence speedup even in the deterministic setting. The heavy ball method, introduced by Polyak in 1964, does not accelerate convergence in the deterministic setting, except for specific cases like convex quadratic objectives. Recent research has explored its application to other optimization problems beyond quadratic functions. The heavy ball method does not speed up convergence in most cases, except for convex quadratic objectives. Recent research has analyzed its application to other optimization problems, showing that it does not outperform standard SGD. The heavy ball method does not speed up convergence in most cases, except for convex quadratic objectives. Recent research shows that stochastic heavy ball momentum and Nesterov's momentum for smooth non-convex functions converge at a rate of O(1/ \u221a t), but not better than standard SGD. Ghadimi & Lan proposed variants of stochastic accelerated algorithms with first-order stationary point guarantees, but these do not include the stochastic heavy ball momentum. Kidambi et al. demonstrated a negative result for heavy ball momentum in a specific strongly convex and strongly smooth problem. Specialized algorithms and simple GD/SGD variants aim at reaching a second-order stationary point. Kidambi et al. (2018) found that SGD with heavy ball momentum fails to achieve the best convergence rate for specific problems, while other algorithms can. Specialized algorithms are designed to exploit negative curvature and escape saddle points faster than simple GD/SGD variants. One approach involves multiplying the gradient by a preconditioning matrix and updating the weights accordingly. This method has been shown to help in escaping saddle points faster. Specialized algorithms exploit negative curvature to escape saddle points faster than simple GD/SGD variants. One method involves multiplying the gradient by a preconditioning matrix for updates. Fang et al. (2019) propose average-SGD with a suffix averaging scheme for updates, assuming stochastic gradients can help escape saddle points. The iteration complexity results of related works for simple SGD are summarized. The algorithm proposed by Fang et al. (2019) utilizes a suffix averaging scheme to escape saddle points faster than standard SGD. They assume stochastic gradients have a property that aids in this process. The iteration complexity results of various SGD variants are compared in Table 1, highlighting differences in performance. The algorithm by Fang et al. (2019) uses a suffix averaging scheme to escape saddle points faster than standard SGD. They compare iteration complexity results of different SGD variants in Table 1. Our analysis focuses on the effectiveness of stochastic heavy ball momentum and its advantages, building on previous work by Daneshmand et al. (2018). The study focuses on the advantage of using stochastic heavy ball momentum, building on previous work by Daneshmand et al. (2018). It suggests modifying assumptions and algorithms in Fang et al. (2019) or Jin et al. (2019) to show the benefits of stochastic momentum. Lemma 7 states that under the APAG property, SGD with momentum decreases when the gradient norm is large. Lemma 6, 7, and 8 discuss the advantages of stochastic momentum in optimization algorithms. Lemma 7 shows that SGD with momentum decreases the function value when the gradient norm is large. Lemma 8 bounds the increase of function value of the next iterate. If SGD with momentum has the APAG property, it leads to progress in optimization. Lemma 6, 7, and 8 discuss the benefits of stochastic momentum in optimization. Lemma 7 states that SGD with momentum decreases function value when gradient norm is large. Lemma 8 bounds the increase of function value of the next iterate. If SGD with momentum has the APAG property, it leads to progress in optimization. Lemma 7 discusses the update step in SGD with momentum, showing progress in optimization under certain conditions. Lemma 8 explores the benefits of stochastic momentum in optimization, bounding the increase of function value in the next iterate. Lemma 8 discusses the benefits of stochastic momentum in optimization, bounding the increase of function value in the next iterate. The conditional expectation is proven in Lemma 1, where the update equation is derived for t > 1. The gradient is rewritten with zero-mean noise, and an upper bound is needed for E t0 [4\u03b7]. The text discusses rewriting the gradient with zero-mean noise and the need to upper bound E t0 [4\u03b7]. Lemmas 2 and 3 are then introduced, with Lemma 2 defining t 0 and Lemma 3 involving conditional expectations. The text discusses the need to bound E t0 [4\u03b7] and introduces Lemmas 2 and 3. Lemma 2 defines t 0 and a quadratic approximation, while Lemma 3 involves conditional expectations. The text introduces Lemmas 2 and 3, defining t 0 and a quadratic approximation at w t0. It discusses the need to bound E t0 [4\u03b7] and involves conditional expectations. Lemma 3 builds upon the definitions and quadratic approximation introduced in Lemma 2 to provide a proof involving conditional expectations. Lemma 5 states that if SGD with momentum has the APCG property, then a certain inequality holds. Lemma 5 states that if SGD with momentum has the APCG property, then certain constraints on parameter \u03b2 must be met. These constraints ensure that \u03b2 is not too close to 1. The constraints on parameter \u03b2 ensure it is not too close to 1, as stated in Lemma 5. The constraints include \u03c3 2 (1 \u2212 \u03b2) 3 > 1 and c (1 \u2212 \u03b2) 2 > 1, bounding the value of \u03b2. These constraints are used in proofs but are mostly artifacts of the analysis. The value of \u03b2 cannot be too close to 1, with constraints on L, \u03c3, and c being artificial. These constraints are used in proofs but are mostly artifacts of the analysis. Lemma 9 upper bounds E t0 [ q q,t\u22121 ] following conditions in Lemma 1 and Lemma 2. The dependence on \u03c3 is not highly relevant as variance can be increased with gaussian perturbation. To prove Lemma 5, a series of lemmas with parameter choices from Table 3 is needed. Lemma 9 upper bounds E t0 [ q q,t\u22121 ] based on conditions from Lemma 1 and Lemma 2, using triangle inequality and Lipschitz gradient assumptions. The upper bound of \u2207f (w t0+k ) \u2212 \u2207f (w t0+s ) is derived using triangle inequality and the assumption of L-Lipschitz gradient. Additionally, an upper bound of E t0 [ \u2207f (w t0+s ) \u2212 \u2207Q(w t0+s ) ] is obtained by considering the Lipschitz Hessian of a function. The upper bound of \u2207f (w t0+k ) \u2212 \u2207f (w t0+s ) is derived using triangle inequality and the assumption of L-Lipschitz gradient. An upper bound of E t0 [ \u2207f (w t0+s ) \u2212 \u2207Q(w t0+s ) ] is obtained by considering the Lipschitz Hessian of a function. The analysis continues with an examination of \u03a0 t\u22121 j=s+1 G j 2 and the upper-bounding of terms on the right-hand side of the equation. The text discusses the upper bounding of terms on the right-hand side of the equation by considering various factors such as \u03a0 t\u22121 j=s+1 G j 2 and the choice of parameters like \u03b7 and \u03bb. The analysis involves deriving upper bounds using triangle inequality, Lipschitz Hessian, and specific step sizes to ensure certain inequalities are met. The text discusses upper bounding terms on the right-hand side of the equation by considering factors like \u03b7 and \u03bb. It involves deriving bounds using triangle inequality, Lipschitz Hessian, and specific step sizes to meet certain inequalities. The text discusses lower bounding terms on the right-hand side of the equation by considering factors like \u03b7 and \u03bb. It involves deriving bounds using specific step sizes and coefficients to meet certain inequalities. The text discusses lower bounding terms on the right-hand side of the equation by considering factors like \u03b7 and \u03bb. It involves deriving bounds using specific step sizes and coefficients to meet certain inequalities. Conditions in Lemma 1 and Lemma 2 are used to prove the lower bound, where the matrix B is shown to be symmetric positive semidefinite. The matrix B is shown to be symmetric positive semidefinite by defining it in a specific form. This property is crucial for deriving lower bounds on terms involving specific coefficients and step sizes. The APCG property is used to prove these bounds, demonstrating the importance of certain conditions in the process. Lemma 14 shows that if SGD with momentum has the APCG property, then the matrix is symmetric positive semidefinite. The proof involves defining specific conditions and using the APCG property to derive lower bounds on terms. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation by leveraging negative curvature and deriving upper and lower bounds on the expected distance. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation by leveraging negative curvature and deriving upper and lower bounds on the expected distance. By leveraging negative curvature, a lower bound is shown to be larger than the upper bound, leading to a contradiction and concluding that the function value must decrease. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation. By leveraging negative curvature, a contradiction is reached by showing that the lower bound is larger than the upper bound. The proof involves showing that the function value must decrease by at least F thred in T thred iterations on expectation. By leveraging negative curvature, a contradiction is reached by showing that the lower bound is larger than the upper bound. At ICLR 2020, a paper presented a constraint of \u03b7, using inequalities and conditions to guarantee certain outcomes in the results. Lemma 15 by Daneshmand et al. (2018) defines an event where a specific w value is chosen with a certain probability. Lemma 15 by Daneshmand et al. (2018) defines an event where a specific w value is chosen with a certain probability, ensuring the inequality holds with high probability. Lemma 15 by Daneshmand et al. (2018) defines an event where a specific w value is chosen with a certain probability, ensuring the inequality holds with high probability. The proof shows that if SGD with momentum has certain properties, it reaches a second order stationary point in a certain number of iterations with high probability. The proof in this subsection outlines how uniformly sampling a specific w value guarantees reaching a second order stationary point in a certain number of iterations with high probability. The complete proof is available in Appendix G. Lemma 15 guarantees that uniformly sampling a specific w value leads to a second order stationary point with high probability. The proof is replicated in Appendix F. With probability at least 1 \u2212 \u03b4, choosing a specific w value ensures \u03a5 k does not occur. Conditions in (86) must be satisfied for Lemma 15 to be used. The expected increase in function value when taking a large step size is limited by \u03b4. The proof is based on Lemma 15, where conditions must be satisfied for its use. The expected increase in function value with a large step size is limited by \u03b4. The proof of the theorem relies on Lemma 15, which requires certain conditions to be met. By satisfying these conditions, we can apply Lemma 15 and complete the proof. The choice of parameters allows us to find a second order stationary point, concluding the proof. The proof relies on Lemma 15 and the choice of parameters from Table 3 to find a second order stationary point, making Algorithm 2 better than previous methods. Algorithm 2 is proven to be better than previous methods in finding a second order stationary point, with a higher momentum leading to faster convergence."
}