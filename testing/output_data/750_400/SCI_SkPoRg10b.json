{
    "title": "SkPoRg10b",
    "content": "We present an approach to understand the generalization properties of deep neural networks by revisiting old ideas in the statistical mechanics of neural networks. A prototypical Very Simple Deep Learning (VSDL) model is introduced, controlled by two parameters - one representing the data load on the network and the other with an effective temperature interpretation. This model helps explain how the network behaves under different conditions. The Very Simple Deep Learning (VSDL) model introduced in this approach is controlled by two parameters - one representing data load and the other with an effective temperature interpretation. This model helps explain the behavior of deep neural networks, including issues like overfitting, discontinuous learning, and sharp transitions in generalization properties. The Very Simple Deep Learning (VSDL) model explains the behavior of deep neural networks, addressing issues like overfitting, discontinuous learning, and sharp transitions in generalization properties. It provides a qualitative description of empirical results on the limitations of deep neural networks. Neural networks, including deep neural networks used in deep learning, are of interest for their empirical performance and complex properties. Some research suggests DNNs are robust to noise, while others find them sensitive to even small amounts of noise. Some papers present conflicting views on the behavior of neural networks, with some claiming they are robust to noise while others find them sensitive. Additionally, there is debate on the applicability of popular theories like PAC and VC to understanding neural network learning. Many papers also highlight the non-convex nature of the associated optimization problems. Some papers express surprise that popular theories like PAC and VC do not describe neural network properties well, while others argue that these theories are not suitable for understanding NN learning. The optimization problems associated with NNs are noted to be extremely non-convex, leading to issues like local minima. There are conflicting views on whether convergence to flat or sharp minimizers is preferable, highlighting long-standing tensions in the field. Some papers discuss the non-convex nature of optimization problems in neural networks, leading to debates on convergence to flat or sharp minimizers. These tensions have been known in the field for a long time but have gained recent attention due to a study by Zhang et al. on DNNs overtraining with noisy data. Recent attention has been drawn to the tendency of state-of-the-art neural networks to overtrain with noisy data, as highlighted in a study by Zhang et al. These networks can easily fit to noise and noisy data, even when presented with inaccurate labels or feature vectors. Observation 1: State-of-the-art neural networks easily overtrain with noisy data, fitting to noise and inaccurate labels. Reproducing this result is challenging. Observation 2: Popular regularization methods may not prevent overtraining, even when implementing capacity control functions. Observation 2 highlights that popular regularization methods, such as adding noise or performing dropout, do not effectively prevent overtraining with noisy data. The only method that shows substantial regularization effect is early stopping, which may seem peculiar compared to SVM models. The only effective regularization method for preventing overtraining with noisy data is early stopping, unlike popular methods like adding noise or performing dropout. This contrasts with SVM models where overtraining is bounded by the training accuracy. Observation 1 and Observation 2 highlight that deep neural networks (DNNs) behave differently from SVM models in terms of overtraining. While SVM models are bounded by training accuracy, DNNs can overtrain even with regularization methods like tuning parameters. Observation 1 and Observation 2 show that DNNs behave differently from SVM models in terms of overtraining. DNNs can overtrain even with regularization methods, leading to a need for rethinking the properties of DNN-based learning. The text discusses how DNNs behave differently from SVM models in terms of overtraining, leading to a need for rethinking the properties of DNN-based learning. It suggests revisiting old ideas on generalization and capacity control from statistical mechanics of NNs to understand DNN-based learning better. DNN-based learning requires rethinking generalization beyond popular ML methods to revisit old ideas from statistical mechanics of NNs. The statistical mechanics theory of generalization applied to NNs and DNNs can explain empirical properties not easily understood by PAC/VC theory commonly used in ML. The SM approach can be formulated rigorously or non-rigorously. The statistical mechanics theory of generalization can explain empirical properties of NNs and DNNs that PAC/VC theory cannot. The SM approach can provide precise quantitative agreement with observed results for models like DNNs. The statistical mechanics approach can provide precise quantitative agreement with empirically-observed results for models like DNNs, offering a theory of generalization that explains complex learning behaviors and phenomena. The statistical mechanics approach explains complex learning behaviors in models like DNNs, with load-like and temperature-like parameters influencing phenomena such as phases and discontinuous learning. This approach complements the PAC/VC approach but offers more detailed insights. The statistical mechanics approach explains complex learning behaviors in models like DNNs, with load-like and temperature-like parameters influencing phenomena such as phases and discontinuous learning. The SM approach is not inconsistent with the PAC/VC approach but offers more detailed insights. The VSDL model of classification in DNN learning models involves error plots, phase diagrams, adding noise to input data, and adjusting algorithm knobs. Zhang et al. propose control parameters for the learning process in their model. The VSDL model of classification in DNN learning models involves error plots, phase diagrams, and adjusting algorithm knobs. Control parameters proposed by Zhang et al. are analogous to load-like and temperature-like parameters in traditional statistical mechanics. The VSDL model of classification in DNN learning involves control parameters analogous to load-like and temperature-like parameters in traditional statistical mechanics, leading to complex generalization properties. The VSDL model of classification in DNN learning involves control parameters analogous to load-like and temperature-like parameters in traditional statistical mechanics. General considerations from the SM theory of generalization suggest that complex generalization properties emerge naturally as a function of these parameters. The behavior of generalization error is illustrated in a one-dimensional phase diagram, showing a critical value where generalization changes. The one-dimensional phase diagram in FIG1 shows the generalization error behavior with increasing or decreasing load parameter \u03b1, highlighting a critical value \u03b1 c where properties change dramatically. The two-dimensional phase diagram in FIG1 depicts sharp transitions in generalization properties in the \u03b1 and \u03c4 parameter space. The two-dimensional phase diagram in FIG1 illustrates sharp transitions in generalization properties in the \u03b1 and \u03c4 parameter space. Noise is added to data and algorithm knobs are adjusted to compensate, causing changes in \u03b1 and generalization behavior. Adding noise and adjusting algorithm knobs can cause changes in the generalization properties of the system, as illustrated in FIG1. Starting from point A with good generalization behavior, adding noise decreases \u03b1, leading to poor generalization at point B. This can be offset by adjusting the number of iterations to modify the \u03c4 parameter, resulting in good generalization at point C. Adjusting the number of iterations can offset the decrease in \u03b1 caused by adding noise, improving generalization from point B to point C. The VSDL model and its consequences are discussed in more detail in Sections 3.1 and 3.2. Adjusting the number of iterations can offset poor generalization from point B to point C in the VSDL model. The SM approach to generalization can lead to quantitative results, but technical complexities are not the focus of this paper. The basic ideas and qualitative results are simple and will be explored in future work. In this paper, the focus is on the basic ideas and qualitative results of the SM approach to generalization, rather than the technical complexities. It is important to be cautious when interpreting the results and not make broad claims about realistic DNN systems. The focus is on the basic ideas and qualitative results of the SM approach to generalization, caution is advised when interpreting the results for realistic DNN systems due to the complexity of control parameters and their interactions. The SM approach to generalization emphasizes the complexity of control parameters in DNN systems, such as SGD block sizes, learning rate schedules, and layer normalization. Generalization can vary based on model details, learning algorithms, data properties, and noise levels. This insight highlights the intricate relationship between control parameters and generalization in machine learning processes. In the next sections, the paper will discuss the connection between practical DNN control parameters and generalization behavior in a VSDL model. Section A will provide a detailed explanation of the main result, while Section 4 will offer a brief overview. In Section 3, the paper presents its main contributions on connecting practical DNN control parameters with load-like parameters, temperature-like parameters, and non-trivial generalization behavior in a VSDL model. Section A provides a more detailed discussion of the main result, while Section 4 offers a brief conclusion. The historical background of the SM approach to NNs is also discussed. The historical background of the SM approach to NNs dates back to the earliest days of the field, with an equivalence between NNs with symmetric connections and the equilibrium SM behavior of magnetic systems. This allows for the design of NNs for associative memory and other computational tasks. In the Hopfield model, there is an equivalence between neural networks with symmetric connections and the equilibrium behavior of magnetic systems like spin glasses. This allows for designing NNs for associative memory and computational tasks. The ML community later shifted to methods like Support Vector Machines and PAC/VC-based analysis for controlling generalization properties of NNs. In the 80s/90s, PAC/VC theory was used to control generalization properties of NNs. Later, the ML community focused on methods like Support Vector Machines for optimization. Recent theoretical work in ML has favored PAC/VC approach over SM approach for generalization. Theoretical work in machine learning has shifted towards the PAC/VC approach for generalization, ignoring the SM approach. However, the SM approach to neural networks can provide a qualitative description of observed phenomena, although a quantitative description is not provided in the current paper. The SM approach to NNs offers a qualitative description of observed phenomena, highlighting various properties in simple and complex neural network systems. This contrasts with the PAC/VC approach favored in theoretical machine learning. The SM approach to learning in neural networks emphasizes the diverse qualitative properties observed in learning and generalization curves, which can be more complex than the gradual improvement predicted by PAC/VC theory. The SM approach to learning in neural networks explains the complex nature of generalization performance, including strong discontinuities and sensitivity to control parameters, model details, and algorithm properties. The generalization performance in neural networks can be complex, with strong discontinuities and sensitivity to control parameters, model details, algorithm properties, and data properties. Researchers have observed these properties in recent years. The properties of data and their noise in approximate computations have been historically well-known and are observed in complex deep learning systems. This separation allows for algorithmic optimization and statistical inference questions to be considered separately. See Section A.2 for more details. In recent years, complex deep learning systems have shown properties related to noise in data. This separation allows for separate consideration of algorithmic optimization and statistical inference questions. It can be limiting due to strong distribution assumptions and technical complexity in application. The Rademacher complexity, or related capacity control measures, can be limiting due to strong distribution assumptions and technical complexity in application. It involves taking different limits than those in theoretical computer science and mathematical statistics, and is described as \"non-rigorous\" in its usual method of application. PAC/VC theory provides smooth upper bounds on generalization accuracy quantities, but a smooth upper bound does not guarantee the accuracy being bounded. The Rademacher complexity and related capacity control measures can be limiting due to strong distribution assumptions and technical complexity. The PAC/VC theory provides smooth upper bounds on generalization accuracy quantities, but this does not guarantee the accuracy being bounded. The SM approach to generalization involves different phases depending on control parameters chosen. The SM approach to generalization involves different phases depending on control parameters chosen, where aggregate properties of the system change smoothly. These phases are not well described in publications, making it difficult to reproduce results accurately. The curr_chunk discusses how neural networks can have different phases in their phase diagrams, where properties of the system change smoothly. Phase transitions represent points of discontinuity in the system's properties. In neural networks, phase transitions represent discontinuities in system properties. Phase diagrams show regions of different system behavior based on control parameters like load and temperature. For example, the Hopfield model can exhibit high-temperature ergodic or spin glass phases. In the Hopfield model of associative memory, the system can exhibit different phases based on load and temperature parameters. These phases include high-temperature ergodic, spin glass, and low-memory phases. Changing control parameters can dramatically alter the system's retrieval properties. The system in the Hopfield model of associative memory can exhibit different phases based on load and temperature parameters, such as high-temperature ergodic, spin glass, and low-memory phases. Changing control parameters like \u03b1 and \u03c4 can dramatically alter the system's retrieval properties, affecting the generalization properties of neural networks. In the context of neural networks, the generalization properties can change based on control parameters of the learning process. A simplified model of deep learning computations can explain aspects of modern DNN performance, including Observations 1 and 2. The main results are presented in three claims. In a simplified model of deep learning computations, the VSDL model explains aspects of modern DNN performance, including Observations 1 and 2. The main results are presented in three claims, focusing on practical control parameters and the thermodynamic limit for analyzing the model. The VSDL model explains modern DNN performance and practical control parameters. It includes three claims, with Claim 1 detailing the modeling of DNN training using a function denoted by f. The VSDL model explains modern DNN performance and practical control parameters. Claim 1 details the modeling of DNN training using a function denoted by f, mapping input images to output labels. The VSDL model, denoted by f, maps input images to output labels. It depends on parameters \u03b1 and \u03c4, making it a Very Simple Deep Learning model. The VSDL model, denoted by f, depends on parameters \u03b1 and \u03c4, which can be controlled during DNN training. These parameters affect the function implemented by the system. The parameters \u03b1 and \u03c4 can be easily controlled during DNN training. Examples include water's state depending on temperature and pressure, and the Erd\u0151s-R\u00e9nyi random graph model showing transitions based on connection probability. In physical applications, transitions between regions of control parameter space with different macroscopic properties are important. In statistical learning applications, engineers often focus on avoiding sensitivity to parameters and prioritize improving prediction quality by 1%. The interest lies in rethinking generalization and understanding deep learning. In statistical learning applications, engineers prioritize improving prediction quality by 1% and avoid sensitivity to parameters. The focus is on rethinking generalization and understanding deep learning. The macroscopic properties of DNN learning systems are of primary interest, rather than microscopic improvements. Adding noise decreases an effective load \u03b1, suggesting that adding noise to training data can be beneficial. Adding noise to training data, such as randomizing labels or adding extra noisy data, decreases an effective load \u03b1 in DNN learning systems. This can be beneficial for improving generalization and understanding deep learning at a macroscopic level. Adding noise to training data, like randomizing labels or adding extra noisy data, decreases an effective load parameter in DNN learning systems. This can improve generalization and deepen understanding of deep learning. Adding noise to training data, such as randomizing labels, reduces the effective number of training examples but does not significantly affect the model capacity obtained through training. This can lead to improved generalization and a better understanding of deep learning systems. Adding noise to training data, like randomizing labels, decreases the effective number of training examples but does not impact the model capacity. This reduces the load on the network, leading to improved generalization in deep learning systems. The addition of noise to training data decreases the load on the network, as the model capacity of realistic DNNs scales with the number of data points. This leads to improved generalization in deep learning systems. The model capacity of realistic DNNs scales with the number of data points, leading to improved generalization. When training a new DNN model on a set of data points with noisy labels, the model essentially faces multiple new binary problems that may not be satisfiable. When training DNN models on data with noisy labels, the model faces new binary problems that may not be satisfiable. Overtraining occurs due to the model's excessive capacity, leading to early stopping increasing an effective temperature. The iteration complexity in stochastic training algorithms acts as a control parameter similar to temperature. The model f has excessive capacity for m \u2212 m rand labels, leading to overtraining. Early stopping increases an effective temperature-like control parameter in stochastic training algorithms. This is justified by the interpretation of DNN training as a stochastic learning algorithm with weights evolving through a relaxational Langevin equation. Early stopping in stochastic training algorithms increases an effective temperature-like control parameter, justified by interpreting DNN training as a stochastic learning algorithm with weights evolving through a relaxational Langevin equation. This is related to a temperature \u03c4 corresponding to the learning rate of the stochastic dynamics. The temperature \u03c4 in the stochastic dynamics corresponds to the learning rate and is related to the annealing rate schedule of the SGD algorithm. It decreases the variability of NN weights with t \u22121 * steps taken by the algorithm. This parameter depends on t * as \u03c4 = \u03c4 (t \u22121 * ). The VSDL model focuses on this parameter, ignoring other factors affecting the learning process. The VSDL model focuses on the temperature-like parameter \u03c4, which is related to the learning rate in stochastic dynamics. It depends on the number of steps taken by the algorithm. Other factors affecting the learning process are ignored in this model. The VSDL model focuses on the parameter \u03c4, related to the learning rate in stochastic dynamics. It can be used to control the learning process by adding noise to input data or early-stopping. Other factors like VC dimension or growth function are not practical for control. Claim 2 discusses appropriate limits for analysis in modern DNN computations, emphasizing the practical use of parameters like \u03b1 and \u03c4 to control the learning process. Other factors such as VC dimension or growth function are deemed impractical for this purpose. Claim 2 emphasizes the need for appropriate limits in the analysis of modern DNN computations, focusing on parameters like \u03b1 and \u03c4 to control the learning process effectively. The use of factors like VC dimension or growth function is considered impractical for this purpose. When analyzing modern DNN computations, it is important to consider a thermodynamic limit where the hypothesis space and data points both diverge. This approach contrasts with the PAC/VC approach and involves complexities related to generalization. In analyzing modern DNN computations, considering a thermodynamic limit where hypothesis space and data points diverge is crucial. This approach differs from the PAC/VC approach and involves complexities related to generalization, as described in detail in the references cited. The SM theory of generalization implies certain aspects for models like the VSDL model in the thermodynamic limit, such as a one-dimensional phase diagram. In the thermodynamic limit, the VSDL model exhibits one-dimensional and two-dimensional phase diagrams based on load-like and temperature-like parameters. The VSDL model exhibits one-dimensional and two-dimensional phase diagrams based on load-like and temperature-like parameters. The phase diagrams show generalization and training errors as functions of \u03b1 and \u03c4. The VSDL model's phase diagram in FIG1 (b) shows lines between different learning phases based on varying parameter \u03c4. As \u03b1 increases from a small value, generalization error decreases gradually until a critical value \u03b1 c, where it decreases dramatically. Alternatively, decreasing \u03b1 from a large value results in a similar trend. When \u03b1 transitions from being greater than \u03b1 c to less than \u03b1 c, there is a significant increase in generalization error, indicating a shift in the ability to fit training data well. When \u03b1 decreases from a large value, the generalization error increases gradually until it reaches a critical value \u03b1 c, where it increases dramatically. This transition results in a significant increase in generalization error, indicating a shift in the ability to fit training data well. The transition in learning as \u03b1 decreases is illustrated in FIG1 (b), where fitting training data well shifts dramatically at a critical value \u03b1 c. For certain \u03c4 values greater than \u03c4 c, the system may exhibit only one phase of learning. Adding noise and adjusting parameters is depicted in FIG1 (c). The transition in learning as \u03b1 decreases is illustrated in FIG1 (b), where fitting training data well shifts dramatically at a critical value \u03b1 c. For certain \u03c4 values greater than \u03c4 c, the system may exhibit only one phase of learning. Adding noise and adjusting parameters is depicted in FIG1 (c). In the (\u03b1, \u03c4 ) plane, the process of adding noise to data and adjusting algorithm knobs to compensate is shown. The process of adding noise to data and adjusting algorithm parameters is illustrated in FIG1 (c) in the (\u03b1, \u03c4 ) plane. A DNN trained to point A with parameter values (\u03b1 A , \u03c4 A ) can still fit new noisy data at point B with parameter values (\u03b1 B , \u03c4 B ), but if enough data labels are changed, the effective load parameter \u03b1 < \u03b1 c. This results in different generalization properties on new noisy data. At point B, some data labels are randomly changed, leading to a decrease in the effective load parameter \u03b1. This results in worse generalization properties on new noisy data. Adjusting the temperature parameter \u03c4 can help compensate for this issue. At point B, data labels are changed randomly, decreasing the load parameter \u03b1 and resulting in worse generalization properties on new noisy data. Adjusting the temperature parameter \u03c4 can help compensate for this issue. The VSDL model has consequences for NN/DNN learning, with focus on Observations 1 and 2. Many technical complexities are left for future work. Neural networks can easily overtrain without a global control parameter for generalization in realistic NNs and DNNs, as opposed to linear models. Conclusion 1 states that neural networks can easily overtrain without a global control parameter for generalization in realistic NNs and DNNs. Conclusion 2 discusses that popular ways of regularization may or may not help in this scenario. In contrast to linear learning, the system may enter a phase of overfitting for certain values of parameters \u03c4 and \u03b1. Regularization methods may not always prevent overfitting in realistic neural networks. The number of iterations t* serves as a control parameter to prevent overfitting in NNs and DNNs. The only parameter that can prevent overfitting for a given noise level is \u03c4. In realistic neural networks, the number of iterations t* acts as a regularization parameter to prevent overfitting. The only way to prevent overfitting for a given noise level is by adjusting the control parameter \u03c4. In an idealized model of realistic DNNs, the number of iterations t* acts as a regularization parameter to prevent overfitting, controlled by the parameter \u03c4. This approach revisits old ideas in the SM of NNs to understand the properties of modern DNNs, offering a different perspective from the PAC/VC approach popular in ML. Revisiting old ideas in the SM of NNs offers a powerful way to rethink generalization properties of modern DNNs, differing from the popular PAC/VC approach in ML. Despite technical complexity, there is value in exploring these old ideas further. Consider referring to fundamental material for more details. In revisiting old ideas in the study of neural networks, there is value in exploring the generalization properties of modern deep neural networks. The approach involves simplifying complex DNNs to understand key properties. The VSDL model idealizes these networks to uncover non-trivial characteristics. The VSDL model simplifies complex DNNs by using two control parameters to explain generalization properties. The VSDL model simplifies complex DNNs by using two control parameters to explain generalization properties. It provides a qualitative description of empirical results on overfitting, discontinuous learning, and sharp transitions in generalization properties. The paper discusses how applying ideas from the SM theory of generalization provides a qualitative description of empirical results on overfitting, discontinuous learning, and sharp transitions in generalization properties of DNNs. Recent work in related areas is also mentioned. Recent work in related areas, such as BID44 and BID45, explores scale-sensitive analysis and Information Bottleneck ideas in analyzing stochastic optimization algorithms. These lines of work complement the paper's approach and merit further examination due to their connections with the results presented. The curr_chunk discusses the compression of information in stochastic optimization algorithms early versus late in the process, and the impact on training error improvement. It emphasizes the historical significance of these questions and the potential benefits of revisiting old ideas. The curr_chunk also mentions the existence of a generalization phase diagram for every DNN and the influence of adjusting algorithm parameters. The curr_chunk discusses the generalization phase diagram for every DNN and the impact of adjusting algorithm parameters on training error improvement. It suggests that revisiting old ideas can be fruitful and mentions a \"low temperature\" spin glass like phase where learning and generalization break down. The curr_chunk discusses the effect of moving around parameter space in DNNs, highlighting a phase where generalization changes gradually and a \"low temperature\" spin glass like phase where learning breaks down. It emphasizes the need to separate optimization and regularization issues in theory due to empirical sensitivity and non-reproducibility of results. The curr_chunk discusses the VSDL model and SM approach providing explanations for various empirical phenomena, such as discontinuities in generalization performance and sensitivity to model details. The VSDL model and SM approach explain various empirical phenomena, including discontinuities in generalization performance and sensitivity to model details. Additionally, they address the dependence of generalization performance on control parameters, algorithm details, regularization properties, data properties, and decay patterns in the asymptotic regime. The generalization of models can be sensitive to various factors such as model details, algorithmic approximations, regularization properties, data characteristics, and noise levels. Generalization can decay in the asymptotic regime following a power law with different exponents. In this section, we delve into simple models studied with the SM approach to understand these concepts better. In this section, we will discuss simple models that capture aspects of realistic large DNNs, studied with the SM approach. These models help understand the generalization behavior of the VSDL model, consistent with Observations 1 and/or 2. The text discusses simple models that capture aspects of realistic large DNNs and their generalization behavior, consistent with Observations 1 and/or 2. It also provides an overview of the PAC/VC versus SM approach to generalization and explains the root of discontinuous generalization properties in simpler models. In Sections A.2 to A.5, the text discusses the PAC/VC versus SM approach to generalization, the root of discontinuous generalization properties in simpler models, evidence in larger DNNs, and popular mechanisms for regularization. In larger DNNs, evidence is presented for discontinuous generalization properties. Popular regularization mechanisms may not be applicable in these situations. Simple network architectures like the fully-connected committee machine are considered to understand generalization principles. The text discusses simple network architectures like the fully-connected committee machine, tree-based parity machine, and one-layer reversedwedge Ising perceptron to understand generalization principles in DNNs. Multilayer networks have stronger representational power than single layer networks. The fully-connected committee machine and tree-based parity machine are examples of networks with multilayer and non-trivial representation capabilities, essential for modern DNNs. Multilayer networks have stronger representational power than single layer networks. The one-layer reversed-wedge Ising perceptron serves as a prototype model for the representation ability of more realistic networks. The fully-connected committee machine is a multi-layer network with one hidden layer containing K elements, specified by K vectors connecting the N inputs with the hidden units. It has strong representation capabilities and is essential for modern DNNs. The fully-connected committee machine is a multi-layer network with one hidden layer containing K elements, specified by K vectors connecting the N inputs with the hidden units. The model operates by majority vote of the hidden layer, with the generalization error shown in the learning curve. The hidden unit vector H \u2208 R K determines the output through a majority vote of the hidden layer. The model exhibits discontinuous behavior in the generalization error \u03b5 based on the control parameter \u03b1\u03b2. The tree-based parity machine also utilizes K vectors to connect inputs to hidden units in a tree-like structure. The tree-based parity machine is a multi-layer network with hidden units arranged in a tree-like structure. The output is determined by the majority vote of the hidden layer, showing discontinuous behavior in generalization error \u03b5 based on the control parameter \u03b1\u03b2. FIG3 illustrates the generalization error \u03b5 as a function of \u03b1 for different values of K. The one-layer reversed-wedge Ising perceptron is a single layer network with a non-trivial activation function. It operates based on input vector S and weight vector J, defining \u03bb as a function of \u03b3. Refer to (54; 55; 47) and FIG3 (b) for more details on the tree-based parity machine model and its learning curve. The one-layer reversed-wedge Ising perceptron is a single layer network with a non-trivial activation function. It defines \u03bb as a function of \u03b3, showing the non-monotonicity of the activation function and classification based on \u03bb compared to \u03b3. Refer to (49; 50) for more details and FIG3 (c) for the learning curve. The activation function in the one-layer reversed-wedge Ising perceptron model is non-monotonic, with classification based on the parameter \u03bb in relation to \u03b3. The learning curve, shown in FIG3, demonstrates the abrupt change in generalization error \u03b5 with respect to the control parameter \u03b1. The generalization error \u03b5 is depicted as a function of the control parameter \u03b1 for various values of \u03b3, showing abrupt changes in the learning curve. Different parameters like the number K of intermediate groups or the value of \u03b3 can influence this behavior, but the basic discontinuous pattern remains consistent within a certain range of values. In addition, different parameters like the number K of intermediate groups or the value of \u03b3 can influence the generalization behavior, with a range of values where the basic discontinuous pattern is observed. Further discussion on simpler models and approaches to understanding this behavior will be provided in subsequent sections. In Section A.3, two simpler models will be discussed to explain the mechanism behind the discontinuous generalization behavior. This will be analyzed from two complementary approaches to the SM theory of generalization. In Section A.2, two different approaches to understanding generalization in ML will be reviewed. The classification of elements in input space X into classes {0, 1} will be considered, with a target rule T and hypothesis space F for approximating mappings. In ML, understanding generalization involves classifying elements in input space X into classes {0, 1} using a target rule T and hypothesis space F. The goal is to select an element from F that approximates T well based on training set examples from X. The problem in machine learning is to approximate the target rule T using mappings from set F, such as neural networks. The goal is for the student/hypothesis to approximate the teacher/target rule as closely as possible, with generalization error \u03b5 representing the disagreement between them on a subset of X. The student aims to approximate the target rule T using mappings from set F on input space X. The generalization error \u03b5 measures the disagreement between the student and teacher on a subset of X. The student iterates the process of updating mappings to minimize this error. The student iterates a process to approximate the target rule using mappings from set F on input space X. The version space at each time step is the subset of X compatible with the data/labels received so far. In the iterative learning algorithm, the version space is the subset of X compatible with the data received so far. The zero-temperature Gibbs learning rule is sometimes considered for generalization error evaluation. The version space V(S) is defined as the set of hypotheses that match the data seen so far. The zero-temperature Gibbs learning rule is used to evaluate generalization error. The training error \u03b5t measures disagreements between student and teacher outputs on the training set. The difference between training error and generalization error is of interest. The training error \u03b5t quantifies the student's performance on the training set by measuring disagreements with the teacher's output. The difference between training error and generalization error is of interest, characterized by the learning curve. The PAC/VC approach views training set size as a control parameter to understand Eqn. (1). The learning curve examines the behavior of the error as the training set size increases in the PAC/VC approach to generalization. This framework uses accuracy parameters \u03b4 and \u03b3 to analyze the control parameters of the learning process. In the PAC/VC approach to generalization, the learning curve analyzes the error behavior as the training set size increases. The framework uses accuracy parameters \u03b4 and \u03b3 to study the control parameters of the learning process, focusing on the convergence of frequencies to probabilities. The m \u2192 \u221e limit can be explored using a law of large numbers or a central limit theorem for learning in finite scenarios. The problem of deciding which hypothesis will perform well on the complete input based on a small training set is related to the convergence of frequencies to probabilities. Using a Hoeffding-type approach may not be suitable due to the rule f* being dependent on the training data. One way around this is to fix F and construct a uniform bound over the entire hypothesis space. One way to address the issue of dependency on training data is to fix F and create a uniform bound over the entire hypothesis space, focusing on the worst-case scenario. This can be derived from the Hoeffding inequality, even if the cardinality of F is infinite, as shown by Sauer and Vapnik and Chervonenkis. A uniform bound over the hypothesis space F can be derived from the Hoeffding inequality, even if |F| is infinite, as shown by Sauer and Vapnik and Chervonenkis. The PAC/VC approach uses the growth function and VC dimension to minimize empirical error on a random sample, leading to a generalization error bounded above by b. The PAC/VC approach uses the growth function and VC dimension to minimize empirical error on a random sample, leading to a generalization error bounded above by a power law decay dependent on m. The VC dimension measures the complexity of the function class F. The PAC/VC approach uses the VC dimension to minimize empirical error on a random sample, leading to a generalization error bounded above by a power law decay dependent on m. The bounds are universal and only depend on the VC dimension, not on specific details of the learning algorithm or target rule. The PAC/VC approach uses the VC dimension to minimize empirical error on a random sample, leading to generalization error bounds that are universal and independent of specific learning algorithm or target rule details. The function class F can vary with training set size, with the theory allowing for divergence in a well-defined manner known as the thermodynamic limit. The thermodynamic limit allows for divergence in function class F with training set size, providing a basis for the SM approach to generalization. The thermodynamic limit allows for divergence in function class F with training set size, providing a basis for the SM approach to generalization. The SM approach to generalization focuses on computing quantities related to generalization error easily. It was first proposed in specific references and offers different perspectives on mathematical statistics and statistical physics. The SM approach to generalization, proposed in specific references, offers different perspectives on mathematical statistics and statistical physics. It describes the learning curve of a parametric class of functions for classification tasks. The SM approach describes the learning curve of a parametric class of functions for classification tasks, such as NNs trained with larger data sets. It may not always lead to meaningful results in cases like mean field spin glass phases. The SM approach describes the learning curve of a parametric class of functions for classification tasks with larger data sets. It may not always lead to meaningful results in cases like mean field spin glass phases. If a fixed target function is chosen for each class, a sequence of target functions is obtained. The behavior of the number of functions in the class at a given error value may have an asymptotic behavior if a limit exists. This limit can be exploited by describing the learning curves as a \"competition\" between the error value and the logarithm. If the limit exists, the number of functions in a class at a given error value may show asymptotic behavior. This limit can be utilized to describe learning curves as a \"competition\" between error value and the logarithm of function numbers. When considering the case of m, N \u2192 \u221e with \u03b1 = m/N as a fixed constant, it allows for investigation of generalization error with varying sample sizes relative to the number of parameters. This \u03b1 serves as a control parameter analogous to network load in associative memory models. The sample size and function class sizes are fixed, with m, N \u2192 \u221e and \u03b1 = m/N as a control parameter for investigating generalization error. Two approaches to the SM theory of generalization will be described, focusing on the behavior observed in FIG3. The SM theory of generalization explores two approaches, focusing on the behavior observed in FIG3. The mechanism for this behavior is examined through simpler models, illustrating key issues. The text discusses the behavior of various models in the SM theory of generalization, including committee machine, parity machine, and reversed-wedge Ising perceptron. It compares continuous and discrete variants of a simple one-layer perceptron to illustrate key issues. The behavior is analyzed rigorously, through numerical simulations, and replica-based calculations from statistical physics. The behavior of various models in the SM theory of generalization is discussed, including committee machine, parity machine, and reversed-wedge Ising perceptron. The basic single-layer perceptron with input vector S \u2208 R N and weights vector J \u2208 R N is described, with the output classification rule determined by the angle between S and J. The basic single-layer perceptron model in the SM theory of generalization is described with input vector S \u2208 R N and weights vector J \u2208 R N. The output classification rule depends on the angle between S and J, with classification as +1 or -1 based on the angle being smaller or larger than \u03c0/2. The normalization choice ensures both vectors lie on the surface of an N-dimensional sphere with radius \u221a N. In the single-layer perceptron model, the classification rule is based on the angle between input vector S and weights vector J. The generalization error can be expressed in terms of the overlap parameter and the angle between T and J. The generalization error in the perceptron model depends on the overlap parameter and the angle between the input and weights vectors. The error is exponential in N and can be written in terms of the overlap parameter R. The perceptron model considers a continuous version where the output is either -1 or +1. The perceptron model has two versions: continuous perceptron with continuous weights on an N-dimensional sphere, and Ising perceptron with weights constrained to \u00b11. The generalization error depends on the overlap parameter R between input and weights vectors. The Ising perceptron model involves weights constrained to \u00b11, leading to a stronger discreteness condition compared to the continuous perceptron model. This version exhibits a phase transition common to all spin glass systems. The Ising perceptron model involves weights constrained to \u00b11, leading to a stronger discreteness condition. This version exhibits a phase transition common to all spin glass systems and has important consequences for generalization error. The Ising perceptron model exhibits a phase transition common to all spin glass systems, impacting generalization error. The generalization error decreases as the training set size increases, with vectors becoming incompatible with the data. Vectors are grouped based on their overlap with the teacher, quantifying the probability of remaining compatible when a new example is presented. When a new example is presented, vectors are grouped based on their overlap with the teacher, determining the generalization error. The volume of compatible students decreases with each example, reducing the chance of producing the same output as the teacher. The volume of vectors J with overlap R (or generalization error \u03b5) decreases with each example presented, reducing the average volume of compatible students with generalization error \u03b5 after m training examples. Generalization in this context is controlled by the balance between energy and entropy, where entropy density s(\u03b5) refers to the logarithm of the volume. The generalization error \u03b5 after m training examples is characterized by the balance between energy and entropy. The entropy density s(\u03b5) is the logarithm of the volume, while the energy e(\u03b5) is the penalty for incorrect predictions. This is described mathematically by the extremum condition for a combination of energy and entropy terms. The entropy and energy terms in the context of the volume DISPLAYFORM8 are mathematically described by an extremum condition. For the continuous perceptron, the entropy behaves as ln(\u03b5) for small \u03b5 or large \u03b1, while the energy behaves as \u03b1\u03b5. In the thermodynamic limit, the energy term is dominated by an exponential function. The entropy and energy terms in the context of the volume DISPLAYFORM8 are described by an extremum condition. The entropy behaves as ln(\u03b5) for small \u03b5 or large \u03b1, while the energy behaves as \u03b1\u03b5. In the thermodynamic limit, the energy term is dominated by an exponential function. The entropy slowly diverges to \u2212\u221e as \u03b5 \u2192 0 or as R \u2192 1. The energy is determined by optimizing the difference s(\u03b5) \u2212 e(\u03b5) to find the maximum value. In the context of the volume DISPLAYFORM8, the maximum value of the expression in the square brackets of Eqn. BID5 dominates the quantity. When a student vector is randomly chosen from the version space, it is likely to be one where the expression in the square bracket is a maximum. Optimizing the difference s(\u03b5) \u2212 e(\u03b5) helps determine the maximum, leading to a smooth decrease in generalization error with more examples, as shown in FIG5 (a). This aligns with PAC/VC theory. For the discrete Ising perceptron, the entropy approaches zero as \u03b5 \u2192 0 or as R \u2192 1, indicating exactly one state with R = 1. This behavior is different from the smooth decrease in generalization error with more examples seen in PAC/VC theory. The discrete Ising perceptron shows different behavior compared to the smooth decrease in generalization error in PAC/VC theory. The entropy approaches zero as \u03b5 \u2192 0 or as R \u2192 1, indicating a single state with R = 1. The energy behaves as e(\u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1. Minimizing s(\u03b5) \u2212 e(\u03b5) is discussed in Sec. V.D of FORMULA22 for small \u03b5 or large \u03b1. The discrete Ising perceptron exhibits different behavior compared to PAC/VC theory, with entropy approaching zero as \u03b5 \u2192 0 or R \u2192 1, indicating a single state with R = 1. The energy behaves as e(\u03b5) \u223c \u03b1\u03b5 for small \u03b5 or large \u03b1. Minimizing s(\u03b5) \u2212 e(\u03b5) is discussed in Sec. V.D of FORMULA22 for small \u03b5 or large \u03b1, with the optimal value at the boundary \u03b5 = 0 (or R = 1) for large \u03b1 values. For small-to-moderate values of \u03b1, the expression has a solution, but for large values of \u03b1, there is no solution, indicating the optimal value is at the boundary \u03b5 = 0 (or R = 1). There is a discontinuous change in \u03b5 as a function of \u03b1 at a critical value \u03b1 c, not described by PAC/VC theory. The behavior of the continuous perceptron shows a smooth decrease in generalization error with increasing data, while the discrete Ising perceptron exhibits more complex behavior with a discontinuous change in error at a critical value of \u03b1. The behavior of the continuous perceptron is simple, showing a smooth decrease in generalization error with more data. In contrast, the discrete Ising perceptron's generalization behavior is more complex, with a one-dimensional phase diagram and two phases depending on the value of \u03b1. There is a discontinuous change in generalization error between the phases. The discussion focuses on the complex behavior of the discrete Ising perceptron with a one-dimensional phase diagram and two phases based on the value of \u03b1. There is a discontinuous change in generalization error between the phases, highlighting the differences from the continuous perceptron's behavior. The discussion focuses on the discrete Ising perceptron with a two-dimensional phase diagram involving a temperature parameter \u03c4. The phase diagram shows non-trivial behavior as a function of both \u03b1 and \u03c4. The two-dimensional phase diagram of the discrete Ising perceptron includes a phase of perfect generalization, a phase of poor generalization, a spin glass phase, and metastable regimes, depending on the values of \u03b1 and \u03c4. The Ising perceptron in FIG5 shows different phases depending on \u03b1 and \u03c4 values, including perfect generalization, poor generalization, spin glass phase, and metastable regimes. The two-dimensional phase diagram of the continuous perceptron is also shown in FIG5 (b). The SM approach to learning theory characterizes generalization as a competition between entropy-like and energy-like terms. Results from the rigorous SM approach show that generalization in learning theory is characterized by a competition between entropy-like and energy-like terms. The version space V(S) \u2286 F represents all functions consistent with the target function T on the sample S. The approach also provides intuitive explanations for the observed results in various figures. The approach provides intuitive explanations for observed results in various figures, focusing on the version space V(S) and the -ball around the target function in learning theory. Lower bounds on \u03b4 are discussed in relation to generalization error. The -ball around the target function, defined as functions with generalization error \u03b5 not larger than , is a sample-independent subclass of f. Lower bounds on \u03b4 provide bounds on the generalization error \u03b5 of any consistent learning algorithm. Lower bounds on the probability \u03b4 provide bounds on the generalization error \u03b5 of any consistent learning algorithm outputting a function h. If a function h with generalization error \u03b5 remains in a certain subset of functions, then with probability at least 1 \u2212 \u03b4, a function consistent with random examples of a target function in F will also be in that subset. Lower bounds on the probability \u03b4 provide bounds on the generalization error \u03b5 of any consistent learning algorithm outputting a function h. If a function h with generalization error \u03b5 remains in a certain subset of functions, then with probability at least 1 \u2212 \u03b4, a function consistent with random examples of a target function in F will also be in that subset. The generalization error \u03b5(h) is given by a sum of quantities over functions in F with generalization error greater than \u03b5, and one wants to minimize this expression to obtain improved bounds. If |F| < \u221e, then any consistent h satisfies \u03b5(h) \u2264 1/m ln(|F|/\u03b4), with probability at least 1 - \u03b4. The generalization error \u03b5(h) is determined by a sum of quantities over functions in F, and one aims to minimize this expression for better bounds. If |F| < \u221e, any consistent h satisfies \u03b5(h) \u2264 1/m ln(|F|/\u03b4), with probability at least 1 - \u03b4. This bound is independent of the distribution D or target function T, and relies on F only through |F|. However, it can be weak, leading to potentially larger values of \u03b5(h). The PAC/VC-like bound for generalization error \u03b5(h) is \u03b5(h) \u2264 1/m ln(|F|/\u03b4), with probability at least 1 - \u03b4. This bound is independent of the distribution D or target function T, and relies on F only through |F|. However, it can be weak, leading to potentially larger values of \u03b5(h). More refined upper bounds can be obtained by tracking errors and the number of hypotheses achieving those errors. The PAC/VC-like bound for generalization error \u03b5(h) is \u03b5(h) \u2264 1/m ln(|F|/\u03b4), with probability at least 1 - \u03b4. More refined upper bounds on the left hand side of Eqn. FORMULA29 can be obtained by keeping track of errors j and the number of hypotheses achieving that error Q j. If we consider a parametric class of functions, we can rewrite the expression. In a parametric class of functions, the expression for generalization error can be rewritten. The trade-off between entropy and energy is explained in terms of bounding the error by a certain threshold. In Eqn. FORMULA20, log Q (11) states that summing terms in Eqn. BID17 where > * + \u03c4, with \u03c4 > 0, equals 0 in the thermodynamic limit. This allows bounding generalization error by * + \u03c4. The trade-off between entropy and energy is illustrated by the right-most crossing point of non-negative functions s( ) and \u2212\u03b1 log(1 \u2212 ). This point, denoted by *, signifies when the energy term dominates the entropy term. This concept is applied to the continuous perceptron. The trade-off between entropy and energy is illustrated by the right-most crossing point of non-negative functions s( ) and \u2212\u03b1 log(1 \u2212 ). This point, denoted by *, signifies when the energy term dominates the entropy term. Applied to the continuous perceptron, an entropy upper bound of s( ) = 1 can be used. For the continuous perceptron, an entropy upper bound of s( ) = 1 can be used, as shown in FIG5 (e). The learning curve corresponding to the energy-entropy competition gradually decreases with increasing \u03b1. For the Ising perceptron, an entropy upper bound of s( ) = H(sin 2 can be shown. The Ising perceptron shows a gradual decrease in \u03b5 with increasing \u03b1, consistent with PAC/VC theory. An entropy upper bound for the Ising perceptron is s( ) = H(sin 2 (\u03c0 /2)), which is consistent with Eqn. BID9 for small values of . The entropy upper bound for the Ising perceptron is s( ) = H(sin 2 (\u03c0 /2)), consistent with Eqn. BID9 for small values of . The entropy density s( ) is very small for energy values slightly greater than the minimum, showing a competition between energy and entropy. The entropy density is very small for energy values slightly greater than the minimum, showing a competition between energy and entropy. The rightmost intersection points plotted as a function of \u03b1 in FIG5 represent the learning curve corresponding to the energy-entropy competition. The rightmost crossover point decreases gradually as \u03b1 is increased, hitting a critical value where the plot suddenly decreases in FIG5 (h). The entropy density decreases gradually as \u03b1 is increased, hitting a critical value where the plot suddenly decreases to 0. This non-smooth decrease of \u03b5 with \u03b1 is consistent with results from Eqn. BID12, showing a solution only for small-to-moderate values of \u03b1. The plot in FIG5 (h) decreases suddenly to 0 for larger values of \u03b1, which is not described by PAC/VC theory but is consistent with results from Eqn. BID12. The reason to believe in idealized models for understanding large DNNs lies in the theoretical and empirical work on loss surfaces. Theoretical and empirical work on loss surfaces of NNs/DNNs suggests a connection to spin glasses, supported by FIG5 of FORMULA20 showing a histogram count as a function of model loss/energy. The authors present a histogram count or entropy as a function of the loss or energy of the model, suggesting a connection between NNs/DNNs and spin glasses. The results are consistent with the random energy model (REM) and its entropy transition at a non-zero temperature parameter. The random energy model (REM) is a weaker hypothesis compared to a spin glass. It shows a transition in entropy density at a non-zero temperature parameter, where entropy vanishes. Above a critical value, there are many configurations, while below it, there is only one configuration. This phenomenon is observed in the Ising perceptron, not the continuous perceptron. Above a critical value \u03c4 c, there is a relatively large number of configurations, and below that critical value, there is a single configuration. This small entropy for configurations with loss slightly above the minimum value is responsible for the complex learning behavior discussed. The phenomenon of having low entropy for configurations with loss slightly above the minimum value is responsible for complex learning behavior. This is illustrated analytically and pictorially, suggesting that every DNN exhibits this phenomenon. The connection between this discussion and the observation that early stopping is a mechanism for regularization in the VSDL model is questioned. The low entropy for configurations with loss slightly above the minimum value is a common phenomenon in DNNs. The connection between this and early stopping as a regularization mechanism in the VSDL model is questioned. The Tikhonov-Phillips method and TSVD method are discussed for solving ill-posed LS problems. The Tikhonov-Phillips method and TSVD method are used to solve ill-posed LS problems involving a matrix A and vector b in R n\u00d7p. The naive solution involves computing x = A^-1 b, but issues arise if n > p or if A is rank-deficient and poorly-conditioned. The solution to the related LS problem is x = A^T(A^-1)(A^T)b, which may overfit the training data. The Tikhonov-Phillips method and TSVD method are alternatives to solving ill-posed LS problems when the matrix A is rank-deficient or poorly-conditioned. The Tikhonov-Phillips method involves solving for x with a regularization parameter \u03bb, while the TSVD method replaces the original problem with a truncated singular value decomposition. The Tikhonov-Phillips method and TSVD method are used to solve ill-posed LS problems with rank-deficient or poorly-conditioned matrices. The TSVD method replaces the original problem with a truncated singular value decomposition, while the Tikhonov-Phillips method involves solving for x with a regularization parameter \u03bb. The solution to Problem (22) involves finding the best rank-k approximation to matrix A by replacing bottom singular values with 0. The control parameter \u03bb determines the convergence radius of the inverse of A, while parameter k restricts the domain and range of the linear operator used in the TSVD approach. The control parameter \u03bb determines the radius of convergence of the inverse of A, while parameter k restricts the domain and range of the linear operator in the TSVD approach. One can choose a value of \u03bb (or k) to prevent overfitting, potentially sacrificing underfitting by adjusting the control parameter. The TSVD approach involves choosing a value of \u03bb (or k) to prevent overfitting, even at the expense of underfitting. This is due to the linear structure of A T A + \u03bb 2 I. For non-linear systems like NNs or DNNs, this may not hold true. Both approaches generalize to a wide range of problems. The linear structure of A T A + \u03bb 2 I may not hold true for non-linear systems like NNs or DNNs. Both approaches generalize to a wide range of problems, including objectives such as SVMs. In the context of non-linear systems like NNs or DNNs, linear regularization approaches may not work well historically. Increasing control parameters can prevent overfitting, even if it leads to underfitting, as seen in statistical learning theory. In the context of non-linear systems like NNs or DNNs, linear regularization approaches may not work well historically. It is known that increasing control parameters can prevent overfitting, even if it results in underfitting, as emphasized in statistical learning theory. Additionally, early stopping of iterative algorithms has been a successful approach for training NNs, termed implicit regularization. The early stopping of iterative algorithms has been a successful approach for training NNs, termed implicit regularization. This approach is more natural and fundamental than the number of iterations as control parameters. Implicit regularization in training neural networks involves early stopping of iterative algorithms, where \u03bb and k are considered more fundamental control parameters than the number of iterations. Regularization can be viewed differently when learning algorithms are defined operationally without a specific optimization objective. In some cases, a connection with Tikhonov-Phillips/TSVD can be made for linear problems, but this is not generally expected. Implicit regularization in training neural networks involves early stopping of iterative algorithms, where \u03bb and k are considered more fundamental control parameters than the number of iterations. Regularization can be viewed differently when learning algorithms are defined operationally without a specific optimization objective. In certain cases, a connection with Tikhonov-Phillips/TSVD can be made for linear problems, but this is not generally expected. The dynamics leading to the SM approach to generalization do not optimize linear or convex objectives but follow a stochastic Langevin type dynamics, resulting in an underlying Gibbs probability distribution. The dynamics leading to the SM approach to generalization do not optimize linear or convex objectives but follow a stochastic Langevin type dynamics, which has strong connections with stochastic dynamics used to train modern DNNs. The dynamics leading to the SM approach to generalization are well-suited for connections with stochastic dynamics like SGD used in training modern DNNs. General dynamical systems exhibit phases, phase transitions, and phase diagrams, defining phases as inputs mapped to fixed points and phase transitions as points in parameter space where nearby points are mapped. General dynamical systems also have phases, phase transitions, and phase diagrams, where a phase is defined as the set of inputs mapped to a fixed point under iterated dynamics. However, there is no structure like the thermodynamic limit to obtain generalization bounds, and control parameters may not serve the same purpose. In dynamical systems, a point in parameter space can lead to different fixed points nearby. Adding noise to a system may not always prevent overfitting as hoped by many researchers. Adding noise to a dynamical system may not always prevent overfitting, as hoped by many researchers. Regularization parameters in the system can play a role in preventing overfitting. Regularization parameters can prevent overfitting in a system by adjusting the quality of generalization smoothly with changes in the parameter. The hope is that increasing the regularization parameter \u03bb can reduce the generalization problem to an optimization problem. Upper bounds from the PAC/VC approach are smooth, making it easier to reason about the prevention of overfitting. Our results in Section 3 show that increasing the regularization parameter \u03bb may not always reduce the generalization problem to a simple optimization problem. The intuition that one quantity diverging is easier to reason about than two quantities diverging simultaneously is often incorrect in machine learning and mathematical statistics. Our results in Section 3 challenge the common intuition in machine learning and mathematical statistics that one quantity diverging is easier to reason about than two quantities diverging simultaneously. The assumption of regularity conditions for linear systems may not hold for nonlinear systems like neural networks and deep neural networks, leading to unexplored consequences."
}