{
    "title": "R43248",
    "content": "The statutory framework for the communications sector largely was enacted prior to the commercial deployment of digital technology. The Telecommunications Act of 1996 (1996 Act), the most recent comprehensive revision of that framework, is virtually silent with respect to Internet Protocol (IP), broadband networks, and online voice, data, and video services. The expert agencies charged with implementing the relevant statutes\u2014the Federal Communications Commission (FCC) and the Copyright Office\u2014have had to determine if and how to apply the law to technologies and circumstances that were not considered by Congress. Frequently, their decisions have led to litigation, requiring the courts to rule with limited guidance from the statutes. This has led to long delays in the rule implementation and increased market uncertainty. These new technologies have driven changes in market structure throughout the communications sector that were not contemplated by the 1996 Act. Technological spillovers have allowed for the convergence of previously service-specific networks, creating new competitive entry opportunities. But they also have created certain incentives for market consolidation. Firms also have used new technologies to attempt to \"invent around\" statutory obligations or prohibitions, such as retransmission consent and copyright requirements. In addition, firms have developed new technologies that allow consumers to avoid paying for programming or to skip the commercials that accompany video programming, challenging traditional business models. The statutory framework imposes obligations and prohibitions on certain networks and service providers, but also provides privileges and rights. In some cases, entrants employing new technologies are not subject to the obligations and prohibitions imposed on the incumbents they compete against, but also are denied access to privileges and rights that accrue to those incumbents. Members on both sides of the aisle as well as industry stakeholders have suggested that many existing provisions in the Communications Act of 1934, as amended, and in the Copyright Act of 1976, as amended, need to be updated to address current technological and market circumstances. There is no consensus about the changes needed. There is agreement, however, that the statutory framework should foster innovation, investment, and competition both in physical broadband networks and in the applications that ride over those networks. One of the challenges is to determine the appropriate mix of market forces and regulation when the sector is characterized by a small number of vertically integrated network providers that also offer applications in direct competition with the independent applications providers that must use those networks. Any statutory provision intended to create incentives for one group of industry players to innovate and invest runs a risk of creating disincentives for other groups to do likewise. Three broad, interrelated policy issues are likely to be prominent in any policy debate over how to update the statutory framework: how to accommodate technological change that already has taken place and, more dynamically, how to make the framework flexible enough to accommodate future technological change; given that underlying scale economies allow for only a very small number of efficient facilities-based network competitors, how to give those few network providers the incentive to invest and innovate while also constraining their ability to impede downstream competition from independent service providers who must use their networks; and given that spectrum is an essential communications input, how to implement a framework that fosters efficient spectrum use and management. Congress will be addressing these three broad questions during a time of great market uncertainty. Technology-driven market forces are potentially undermining the established business models of many incumbent firms, even as the viability of most new entrants remains uncertain. But the communications sector as a whole is robust and growing, with overall usage and revenues increasing, many incumbents enjoying record revenues and profits, and many new entrants enjoying rapid revenue gains though they may not yet have attained profitability. It is difficult to predict which business models ultimately will succeed, and therefore it is difficult to predict the ultimate impact of proposed statutory changes. While this suggests the need for caution, it should not necessarily be justification for inaction if technology-driven market forces have rendered some existing statutory provisions ineffective or even counterproductive. The communications sector does not look at all as it did when the Telecommunications Act was passed in 1996. Most significantly, consumer behavior in 2013 bears little resemblance to that in 1996. The Centers for Disease Control's National Health Interview Survey found that 38.2% of U.S. households had only wireless telephones during the second half of 2012, and six in 10 adults aged 25-29 lived in households with only wireless telephones. According to eMarketer, which performs data collection and analysis on digital markets, \"the average adult will spend over 5 hours per day online, on nonvoice mobile activities or with other digital media this year ... compared to 4 hours and 31 minutes watching television.\" Thus it is not surprising that Verizon Communications chief financial officer Francis Shammo reportedly has stated that its recent deal with the National Football League for the rights to live-stream football games on 7.5-inch devices or smaller (including smartphones) was \"pretty significant for us.\" Similarly, James Dolan, chief executive officer of Cablevision Systems, a major cable company, has reportedly stated that \"Ultimately over the long term I think that the whole video product is eventually going to go over the Internet. I'm not willing to cede that position now, and I've got a lot of customers that buy my video product ... [but] the handwriting is on the wall, particularly when you look at young customers.\" Three interrelated elements of this digital transition have had substantial impact on U.S. markets and on the efficacy of the existing communications statutory framework.  First, digital technologies have led to the \"convergence\" of networks that previously had provided a particular type of communication, such as voice or video. This has fundamentally changed market structure. As explained in the 2005 Phoenix Center Paper, true convergence (i.e., one that actually affects the underlying market structure) is not the offering of a \"bundle\" of several products into a single service offering, but is, in fact, a technological spillover that reduces entry costs so that existing firms find it profitable to extend their network into related markets, a decision that would not be profitable without the spillover. As such, \"convergence\" does not generally mean that busloads of new firms can now enter the market\u2014it means only those firms with assets in a related market that have been affected by the spillover can afford to enter. [Emphasis in original.] Network providers that are able to exploit these technological spillovers can enter new service markets, as with cable operators that have upgraded their coaxial cable networks to offer high speed Internet access and voice services. But providers whose service-specific networks could not be readily modified to exploit spillovers, such as satellite operators unable to offer quality high speed Internet access or voice services, not only have failed to gain new business opportunities but now face competition from network providers that were able to exploit the spillovers.  Second, independent efforts by a wide variety of large and small entrepreneurs, using unlicensed as well as licensed spectrum, have yielded a mobile wireless alternative to local wireline broadband networks that is viable for most popular consumer and small business applications (though this new alternative still depends on wireline facilities for much of its backbone and backhaul). This new mobile wireless ecosystem includes (1) cellular broadband wireless networks (sometimes referred to as macro networks) that offer consumers mobile connectivity to the Internet and hence access to a vast array of voice, data, and video services, (2) femtocell and other small cell networks that extend the reach of macro networks, and (3) WiFi networks that sometimes compete with macro networks but more often provide essential offloading and backhaul capabilities that allow macro network providers to relieve traffic pressures and constrain the capital and spectrum requirements of their macro networks. Given the projected rate of growth in mobile data (including video) traffic that will be generated by users of mobile devices such as smartphones and tablets, and the consequent need of macro network providers to offload from their macro networks a substantial portion of that traffic (onto femtocell or WiFi networks that they or other network providers may own), all three technologies\u2014macro networks, small cell networks, and WiFi\u2014are needed for mobile wireless broadband to succeed. The initial research and development efforts relating to the non-macro technologies were not necessarily undertaken with the expectation that there would be synergies with the macro technologies. Today, however, the value of each of these wireless technologies (and of the licensed and unlicensed spectrum on which they ride) is tied to the other.  Third, digital technologies have significantly changed the underlying cost structure of a wide range of communications services\u2014voice, data, video, music\u2014that ride over the new wireline and wireless broadband networks, with potentially revolutionary market ramifications. Most digital services are applications that ride on existing wireline or wireless broadband networks; although they directly or indirectly compensate broadband network providers for use of their networks, digital service providers do not face the substantial fixed upfront costs associated with constructing a network. For certain types of content, digital technologies turn products that can be costly to produce and distribute (such as CDs, DVDs, and hard copy newspapers) into formats that can be distributed inexpensively. More generally, digital technologies potentially allow for cost-saving \"disintermediation\"\u2014the elimination of middle men between the content producer and the final consumer. But the ease associated with digital content distribution also can create costs for content providers, as the proliferation of distribution channels can make it more costly or more difficult for content producers to obtain compensation for use of their content, both because of increased piracy and because the elimination of middle men may be accompanied by the loss of scale economies needed for more efficient marketing and distribution. Technological change has lowered entry costs and thus boosted competition, but it also has created incentives for market consolidation. The technology-driven reduction in content distribution costs has fostered entry into the distribution of all types of content and, as a result, generally has increased the negotiating strength of content owners\u2014or, perhaps more accurately, of owners of \"must have\" content\u2014relative to distributors. This has created incentives for distributors to merge with content providers, for example, for Comcast to acquire NBC Universal. Where network providers have networks that cannot exploit spillover economies that would allow them to use their existing networks to enter new service markets, these network providers have had the incentive to seek marketing joint ventures with network providers that do offer those services. For example, the major cable operators, whose networks cannot accommodate wireless services, have entered into marketing agreements to sell Verizon Wireless service to their customers. In exchange, Verizon is marketing the cable companies' video services in those markets where it has not deployed its FiOS fiber-to-the-home network and thus cannot offer its own multichannel video service. Similarly, Dish Network, which cannot offer broadband services over its satellite network, in recent months has made (unsuccessful) offers to buy the wireless broadband providers Clearwire, Sprint, and LightSquared. There also are non-technology-driven incentives for consolidation. As broadcast television station groups purchase additional stations, they increase their leverage in retransmission consent and other negotiations. For example, recently proposed and/or consummated acquisitions will expand Sinclair Broadcast Group's reach to an estimated 37.1% of U.S. television households and Nexstar Broadcasting Group's reach to 14%. Similarly, Gannett's proposed acquisition of Belo Corporation's stations will allow it to reach 33% of U.S. television households and the combined Media General/Young Broadcasting will reach 14% of U.S. television households. Tribune Company's proposed purchase of Local TV LLS, which owns 19 stations in 16 markets, for $2.75 billion in cash, would leave Tribune with 42 stations, including 14 in the top 20 markets. Tribune chief executive officer Peter Liguori reportedly has stated he will seek higher retransmission consent fees for its growing number of network affiliated stations.  Video distributors, fearful of potentially higher programming costs, have sought to thwart broadcaster consolidation. The American Cable Association (which represents small cable companies), Time Warner Cable, and DirecTV have filed with the FCC a petition to deny the transfer of five stations from Belo to Gannett on the grounds that, through the use of sharing agreements, Gannett would be able to negotiate retransmission consent agreements on behalf of multiple stations within a local market, enabling it to increase retransmission rates and raising the risk of a negotiations impasse leading to a programming blackout.  Negotiating leverage is not the only motivation in today's brisk market for television stations, however. Purchasers also have been attracted by low interest rates and the rapid growth in political advertising revenues for stations in swing-states. Also, according to Michael Kupinski, an analyst with Noble Financial Group, \"the industry needs to consolidate because you ... need to have scale now to invest in digital media technologies and move into mobile applications ... and also to drive economies through developing your own programming.\"  Broadcaster consolidation may be triggering countervailing consolidation in the video distribution market. The trade press has reported that Liberty Media, which owns 27% of Charter Communications, seeks to have Charter purchase Time Warner Cable and then additional cable systems. SNLFinancial reports that \"Time Warner Cable, which reportedly showed little interest in a deal with Charter, is reportedly eyeing mergers with Cablevision Systems Corp., which Charter also is eyeing, and Cox Communications Inc.\" It also reports that Charter CEO Thomas Rutledge predicted that only \"two major players\" will eventually emerge in the U.S. cable industry. At the same time, Charlie Ergen of Dish Network has suggested that a merger of Dish and DirecTV, which was rejected by the antitrust authorities in the past, might be possible now.  If ownership consolidation by broadcasters triggers countervailing consolidation by video distributors, many programmer-distributor negotiations will feature large companies on both sides of the table, each with some leverage from their scale. This may make it more difficult for either party to impose its will on the other. But a battle between two companies, each with sufficiently deep pockets to be willing and able to withstand an extended blackout\u2014as was the case in the month-long blackout of CBS programming channels on Time Warner Cable systems in August 2013\u2014may injure consumers. There also will be situations in which a large broadcast station group is across the table from a small cable carrier or a large cable or satellite operator is across the table from an independent broadcast television station, with the smaller entity at a negotiating disadvantage.  In addition to the programmer-distributor market, there also is a local advertising market. If the broadcast television stations in a local market are part of a large television group, and especially if that group owns more than one station in that market (or has a joint marketing agreement or shared services agreement with another station in that market), local retailers and other local advertisers may find themselves at a disadvantage when attempting to negotiate local advertising rates. The new market opportunities and new market forces generated by technological change have, overall, been a boon to stakeholders in the communications sector, with incumbents as well as new entrants benefiting. At the same time, even for the most successful firms the landscape is potentially risky since underlying costs and consumer demands continue to change. The big picture for communications remains favorable. Segments under direct pressure from new technologies likely will face lower rates of growth, but appear to continue to plan significant capital expenditures. According to a March 2013 FCC document, there has been nearly $250 billion in private capital investment in U.S. wired and wireless broadband networks since 2009. Annual investment in U.S. wireless networks alone was $30 billion in 2012 and is projected to be $35 billion in 2013, and more fiber-optic cable has been laid in the U.S. in each of the past two years than in any year since 2000. But there are some indications that network capital expenditures will fall. AT&T has announced a $2 billion decrease in capital expenditures over the next two years; and SNLFinancial forecasts a long-term decline in cable companies' capital expenditures, from a peak of $13.1 billion in 2012 to $11.4 billion in 2016. This decline may, in part, be the result of consolidation as mergers and joint marketing agreements reduce the number of competitors that must build out national networks. Although the term \"apps economy\" is widely used, it is difficult to get a handle on aggregate capital spending in the United States by applications providers. The United States enjoys dominance in some markets\u2014according to the FCC, more than 90% of smartphones sold globally in 2012 use operating systems developed by U.S. companies. Also according to the FCC, there was more Internet venture capital investment in the U.S. in 2011 and 2012 than in any year since 2001. Looking only at those large venture capital investments for which there were public announcements, SNLFinancial estimated that such funding for digital-media firms in May 2013 alone was $601.8 million, with the largest investments coming in online advertising ($90.1 million), digital media ($85.2 million), online video ($72.2 million), mobile software/cloud ($55.7 million), and social networking ($53.5 million). Since these estimates only capture very large venture capital investments for which there are public announcements, they fall far short of aggregate investment levels. With respect to potential revenues, perhaps the most important group of applications involves over-the-top (OTT) video\u2014video provided online by means other than a website controlled by the content owner or a cable television or satellite television company. SNLFinancial has begun to construct a database on five types of OTT deployments: OTT aggregators (currently dominated by Netflix, but also including Hulu, Amazon, Apple's iTunes, Redbox, Automated Retail LLC, Verizon's Redbox Instant, Time Warner's Warner Archive, Sony Entertainment Network, and subscription channels on Google's YouTube); game consoles (Nintendo's Wii, Microsoft's Xbox, and Sony's PlayStation 3), which have integrated a lot of video content and offer major aggregator services such as Netflix and Hulu; stand-alone set-top boxes such as Roku units and Apple TV, which also offer aggregator services such as Netflix and Hulu; Internet-connectable television sets, which have become the industry standard, with the manufacturers offering apps and both free and premium programming capabilities; and TV Everywhere, which gives authenticated subscribers to traditional MVPD service access to content on a variety of screens in addition to their television sets. As the OTT segment matures, more data may be collected to help policy makers analyze the impact of alternative public policies on the health and viability of applications markets.  Various estimates indicate that the number of online video ads viewed is growing quickly and that media spending on OTT video is surging. SNLFinancial reports that 20.09 billion online video ads were viewed on desktops and laptops in June 2013, a 120.9% increase from January 2013, driven by more online sites monetizing their videos with an increasing number of ads and by the relatively stable pool of viewers watching more videos. BIA/Kelsey projects that local online video will increase fivefold to $5 billion by 2017; similarly, Standard Media Index found that digital media spending grew 27% during the first half of 2013 and Borrell Associates found digital video advertising increased 29% this year, to about $1 billion in revenues and will continue to grow. At the same time, advertising on traditional broadcast and cable channels continued to grow, though at lower rates; according to Standard Media Index, broadcast television advertising spending grew between 5 and 10% and cable television advertising spending grew 4% in the first half of 2013. (Although each of these data collection and analysis organizations uses its own unique data collection methodologies, so it is not appropriate to compare the numbers generated by one organization to those of another organization, they all are reporting similar trends.) There is no consensus on the extent to which households that had been subscribers to a pay cable, satellite, or telephone multi-channel video have \"cut the cord\" and now rely solely on over-the-air broadcasts and over-the-top video. But such cord-cutting is an identifiable trend. A recent study by GfK reportedly found that 19.3% of television homes (22.4 million) have broadcast-only reception (though they may also get programming online), compared with 17.8% in 2012. Of those 22.4 million households, 5.9% cut the cord in their current home at some point in the past; the remainder never subscribed to an MVPD service while living in their current house. The current statutory framework\u2014which was shaped by negotiations among the many stakeholders present at the time the statutes were being developed\u2014created obligations, prohibitions, privileges, and even rights for those various stakeholders. Industry players have constructed business models based on these. Now, new technologies have spawned entirely new networks, services, and industries that compete with the incumbent stakeholders but do not always easily fit the statutory definitions used to delineate who is subject to/eligible for those obligations, prohibitions, privileges, and rights. As a result, existing statutory provisions\u2014and the regulations constructed by the FCC and Copyright Office to implement the provisions\u2014in some cases may no longer be effectively fostering competition, public safety, and other long-standing policy goals for which they were created.  In a technologically dynamic sector, the statutory framework cannot be modified every time there is a significant technological change. The challenge therefore is to create statutory language that is flexible enough to continue to foster articulated public policy objectives in the face of technological change, without artificially favoring either legacy technology or new technology. In industries characterized by networks and services provided over those networks, this tends to raise three related types of policy questions. Given that statutory provisions generally must define the services, networks, or entities to which they apply, and technological change may result in some competing services, networks, or entities falling within those definitions while others do not, how can policy makers minimize artificial competitive advantages or disadvantages, especially those that would discourage innovation or efficiency or otherwise undermine public policy goals? As providers deploy new technologies to migrate from legacy networks that are subject to statutory requirements to new networks that are not explicitly subject to statutory requirements, which of those requirements should be applied to the new networks? As some network providers (typically the largest providers) migrate from legacy time-division multiplexing (TDM) networks to new (IP) networks, but other network providers or end users have not made the investments needed to be able to connect with or otherwise utilize the new networks, (1) what requirements, if any, should be placed on the migrating providers to continue to support their legacy networks, and (2) what time limits should be placed on the other network providers and end users to take the steps needed for them to connect to the new IP networks? An obvious\u2014but by no means simple, appropriate, or even feasible\u2014way to limit distortions created when statutory definitions do not cover newly available technology is to frequently modify definitions and other relevant provisions in existing statutes. But even if it were possible for Congress to constantly monitor technological change and instantly modify statutes, this likely would not be an effective strategy because it often takes some time to identify the market and public policy implications of new technologies. There does come a time, however, when technological change renders statutory provisions ineffective. Existing statutes are silent on digital technology, Internet protocol, broadband networks, and online services, forcing the FCC, Copyright Office, and courts to extrapolate to these new technologies provisions explicitly crafted for legacy technologies. In another report, CRS has explored in detail the policy issues that this has created in the video distribution market. Online video distributors do not meet the statutory definitions of a \"multichannel video programming distributor (MVPD),\" \"cable company,\" or \"satellite carrier,\" and thus are treated differently than their distribution competitors on a wide range of issues. These include retransmission consent, broadcast retransmission rights, access to a compulsory copyright license, program access rules, program carriage rules, network non-duplication and syndicated exclusivity rules, must-carry obligations, equal employment opportunity rules, closed captioning, and emergency video programming accessibility for persons with hearing and visual disabilities. These differences in rights and obligations are likely to distort, and may undermine, potential competition from over-the-top online video distributors. Table 1 provides a brief summary of the different statutory treatment of competing video programming distributors.  Similar analysis can be performed of other technology-specific definitions and provisions in current statute to determine whether they favor some competing services over others. For example, the statutory treatment of copyright for the public performance rights for sound recordings is different\u2014and more favorable\u2014for terrestrial broadcast radio (that is, AM and FM radio stations) than for satellite radio (XM-Sirius) or online radio (for example, Pandora), although all provide competing audio services. In June 2013, Broadcast Music Inc. (BMI), which represents 600,000 songwriters, composers, and music publishers, filed an action asking a federal court to set royalty rates for Internet radio service Pandora after negotiations did not result in an agreement. At about the same time, Pandora announced its purchase of KXMZ-FM, a small terrestrial radio station in Box Elder, SD, in order to qualify to pay lower royalty rates to music publishers. In response, the American Society of Composers, Authors and Publishers (ASCAP) has filed with the FCC a petition to deny the license transfer.  In a technologically dynamic environment, there may be opportunities for a firm that is constrained by regulatory restrictions or prohibitions, or by patent or copyright restrictions, to \"invent around\" the impediment. This might take the form of exploiting a loophole in the regulation. It may allow for greater competition but it also could result in the innovating firm avoiding a regulation intended to foster a public interest objective.  For example, the public performance of copyrighted works on broadcast television signals is subject to copyright licensing, but the private performance of such works is not. A cable or satellite operator must obtain a copyright license to retransmit the copyrighted material on broadcast signals to its subscribers, but a consuming household does not have to pay a license fee to capture the same broadcast programming directly over the air with use of a rooftop antenna. Video distributors therefore have the incentive to develop and deploy technologies that mimic the household's rooftop antenna or in some other fashion allow the consuming household to directly capture the broadcast signal. A start-up company, Aereo, now has deployed thousands of mini-antennas, which, though maintained at Aereo's own premises, are assigned to individual subscribers as their personal antennas; these antennas send the broadcast television signal to individual subscribers over the Internet. Aereo claims that it is not a video distributor but rather a technology rental company and that the programs received by its subscribers are private performances and not subject to copyright licensing requirements. The broadcasters claim otherwise and have sued Aereo for copyright infringement and sought a preliminary injunction. On July 11, 2012, a federal district court judge denied the injunction, concluding \"that plaintiffs have failed to demonstrate they are likely to succeed in establishing that Aereo's system results in a public performance.\" That decision was appealed, but first a three-court panel of the Second U.S. Circuit Court of Appeals and then the full court en banc refused to enjoin Aereo from continuing to operate while a lower court decides the case. Aereo therefore has been able to continue to offer its service to residents of New York, Connecticut, and Vermont (the three states within the Second Circuit's jurisdiction) as the copyright infringement case moves forward.  Separately and in two different federal district courts (in California and in Washington, DC), broadcasters have sought injunctions against a company using the same technology as Aereo, and in those cases the courts found that the online provider was infringing copyrights and enjoined it from offering service. The judge in the Washington, DC case made the scope of the injunction national, with the exception of the states in the northeastern part of the U.S. covered by the Aereo decision. These cases also are being appealed. It is widely expected that with these inconsistent court rulings appeals will continue, perhaps reaching the Supreme Court. Should the Court decide to resolve the disagreement among the lower courts on the legality of these issues, a potential Supreme Court ruling is unlikely before 2015. In the interim, however, the adverse rulings in the AereoKiller/FilmOnX cases are expected to threaten Aereo's expansion plans.  If the broadcasters are unsuccessful on this issue and lose copyright revenues, they are likely to pursue alternate compensation, most likely by seeking to make Aereo and similarly situated video distributors subject to retransmission consent requirements. Currently, however, online video distributors such as Aereo do not meet the definition of an MVPD and therefore are not subject to the statutory retransmission consent requirements, so the broadcasters would have to seek a statutory change. Since the current legal uncertainty is making it more difficult for both programmers and distributors to make business decisions, Congress may choose to address this issue through legislation.  In another copyright case involving new technology, the U.S. Court of Appeals for the Ninth Circuit has affirmed the denial of a request by Fox Broadcasting Company, Twentieth Century Fox Film Corp., and Fox Television Holdings, which own the copyrights to television shows that air on the Fox television network, for a preliminary injunction against a Dish Network product, Auto-Hop, that allows subscribers to skip over commercials in the programming they receive. The court found that the plaintiffs \"did not establish a likelihood of success on its claim of secondary infringement because, although is established a prima facie case of direct infringement by customers, the television provider showed that it was likely to succeed on its affirmative defense that the customers' copying was a 'fair use.'\" The case will proceed, but whatever its outcome Congress may want to review copyright law in light of new technologies being developed by video distributors that make their products more attractive to consumers by giving consumers the ability to skip commercials. The copyright cases mentioned above are symptomatic of a larger challenge: how, in this digital era, to keep the balance in our copyright laws between rewarding creators for their work and fostering the dissemination and innovative use of those works. Article I, Section 8 of the Constitution states that Congress shall have power: \"To promote the Progress of Science and useful Arts, by securing for limited Times to Authors and Inventors the exclusive Right to their respective Writings and Discoveries.\" It gives Congress the authority to grant copyright holders a limited monopoly over their works in order to foster the public policy goal of promoting innovation. This has two, sometimes complementary, sometimes conflicting, components\u2014protecting copyright holders' intellectual property rights while promoting the dissemination of the knowledge, information, and other value in the copyrighted content. In the digital age, it is very cheap and easy to copy and distribute works, so copyright laws must set up a framework for protecting the intellectual property rights of the copyright holders. At the same time, digital technology provides unique opportunities for unleashing the value in existing works that may be denied if the creator of the work is allowed to employ exclusive rights to curtail innovative uses. This argues, at the least, for laws that clearly spell out what is legal and what is illegal use of copyrighted materials so potential innovators are not unnecessarily discouraged by penalties for infringement that, in their view, does not cause substantial economic harm to copyright holders.  The Department of Commerce Internet Policy Task Force has released a report, Copyright Policy, Creativity, and Innovation in the Digital Economy, which lists a number of policy issues that the Obama Administration seeks to address. The report tends to focus more on protecting copyright holders' intellectual property than on removing disincentives for third party use of copyrighted materials, but it does demonstrate the strain between those two objectives. Some of the issues identified in the report, which Congress may want to investigate, include the following: A proposal supported by the Administration to extend the public performance right for sound recordings to cover broadcasting (as discussed earlier in this report). Assessing the appropriateness of different rate-setting standards for the public performance of sound recordings by different types of digital music services (as discussed earlier in this report). A proposal supported by the Administration to make willful violations of the public performance right\u2014such as streaming copyrighted materials without a license\u2014a felony, rather than a misdemeanor. Determining whether legislative adjustments can help modernize the existing mechanical license by converting it into a blanket license, permitting a single license for a complete repertoire. A proposal supported by the Administration to ensure that consumers have the ability to unlock their cell phones, subject to applicable service agreements. A review of the legal framework for the creation of remixes, which some observers claim is being unacceptably impeded by legal uncertainty. Reviewing the relevance and scope of the \"first-sale doctrine\" in the digital environment. A copyright owner has an exclusive distribut ion right and also an exclusive reproduction right, which involves making copies. The first-sale doctrine creates a basic exception to the distribution right; once the work is lawfully sold or transferred, the copyright owner's interest in the material object in which the copyrighted work is embodied (a book or a CD) is exhausted; the owner of that material object can thereafter dispose of the object as she sees fit (such as giving it away to a friend or reselling it to a used book or record store). But unlike a tangible transfer, a digital transfer between two end users results in a reproduction of the work through the electronic transmission of a new copy of the work to its recipient, and the reproduction right is not subject to the first-sale doctrine limitation, so such transfers are a copyright infringement. Reviewing the application of statutory damages in the context of individual file-sharers and secondary liability for large-scale online infringement. The particular concern is that while statutory damages are necessary for online copyright enforcement, in some cases they may be set at an unreasonably high level. The appropriate role for the government, if any, to help the private sector improve the online licensing environment. Derek Khanna raises several additional copyright issues that may affect innovation and therefore may be of interest to Congress. The original copyright term was 14 years, plus a 14 year renewal if the author were still alive. Over time it has been extended and now the term is the lifetime of the author plus 70 years, and for corporate authors 120 years after creation or 95 years after publication. Khanna suggests that these time periods may be inconsistent with the constitutional language restricting exclusive rights to \"limited times.\" He claims that these lengthy terms benefit content producers, but harm other, added-value services that have the potential to develop in an interactive Internet environment. For example, with shorter copyright terms, entrepreneurs seeking niche audiences would have greater access to books to which they could add pop-up text capability and to videos to which they could add pop-up trivia and commentary add-ons. He therefore proposes significantly shortening the term. Khanna also argues for an expansion of what is legally fair use. In addition, to protect against the abuse of false copyright infringement claims, he proposes more stringent requirements for requests that content be removed from websites (takedown requests) and penalties for fake takedown requests, which have a chilling effect on legitimate speech. The current federal statutory framework for communications contains many network interconnection, network reliability, emergency service, consumer protection, universal service, and competition provisions intended to foster specific public policy objectives. But most of those provisions only apply to a subset of communications networks that are \"telecommunications carriers,\" that is providers of telecommunications services.  To foster the development of advanced communications services, Congress created a category of services, called \"information services,\" that it distinguished from \"telecommunications services\" and freed from some of the regulations imposed on telecommunications services in Title II of the Communications Act. Telecommunications services involve \"the transmission of information of the user's choosing, without change in the form or content of the information as sent and received .\" In contrast, information services are defined as \"the offering of a capability for generating, acquiring, storing, transforming, processing, retrieving, utilizing, or making available information via telecommunications.\" In 2002, the FCC classified cable modem Internet access service as an information service with a telecommunications component, rather than a telecommunications service, and thus outside the purview of Title II. In 2005, the Supreme Court upheld this determination. Later that year, the FCC reached a similar determination with respect to the DSL Internet access service offered by telephone companies. As a result, wireline broadband Internet access service, whether provided by a cable company or by a telephone company, is not treated as a telecommunications service and services offered as broadband applications, such as Voice over Internet Protocol, are not telecommunications services. But this creates some statutory and regulatory asymmetry because IP networks offer voice services in direct competition with the voice services provided by telecommunications carriers; the latter may be subject to regulations that do not apply to the former. Moreover, among telecommunications carriers there is a statutory hierarchy, with some carriers subject to greater regulation than others. There are a number of statutory provisions that apply to all telecommunications carriers. Additional provisions apply to \"local exchange carriers\" (LECs), basically those telecommunications carriers that offer local telephone service. And still more provisions apply to \"incumbent local exchange carriers\" (ILECs), those local exchange carriers that offered service as government-sanctioned monopolies before the 1996 Act opened up the market to competitive entry. In addition, many state regulatory agencies require ILECs (and sometimes all LECs) to be \"carriers of last resort\" and to serve all requesting customers in their service areas upon demand. In the on-going broadband transition, many network providers are migrating from legacy circuit-switched, largely copper networks that use time division multiplexing technology\u2014the long-standing public switched telephone network (PSTN) that offers plain old telephone service (POTS)\u2014to packet-switched, fiber and wireless-based networks that offer multiple video and data as well as voice services. These new networks are not subject to many of the requirements imposed on telecommunications carriers, LECs, and ILECs. But in some cases the network providers, which have invested billions of dollars to deploy these new networks, are required by federal or state law to maintain their legacy networks and to continue to offer legacy voice services. AT&T has announced its intention to upgrade all of its wireline and wireless facilities to IP, which may result in it no longer serving about one percent of its legacy customers. It has asked the FCC to open a proceeding to address transition issues, including legacy regulations to which it is subject, but to which some of its competitors are not subject. The FCC has opened a proceeding and also has created an internal Technology Transitions Policy Task Force. But the FCC will deliberate in the absence of congressional guidance about which of the statutory requirements on legacy networks should apply to new networks, how they should be applied, and which legacy requirements should be retained during the transition. Some issues of potential interest to Congress include the following: VoIP Interconnection: Although the FCC in May 2013 reiterated that it \"expect[s] all carriers to negotiate in good faith in response to requests for IP-to-IP interconnection for the exchange of voice traffic\" and that \"[t]he duty to negotiate in good faith has been a longstanding element of interconnection requirements under the Communications Act and does not depend upon the interconnection, whether TDM, IP, or otherwise,\" IP network providers are not considered telecommunications carriers and therefore are not subject to the interconnection requirements in Section 201 of the 1996 Act. Rather, IP networks rely on negotiated \"peering agreements\" for the exchange of traffic. But there have been instances of \"peering disputes\" in which networks refuse to exchange traffic because they cannot agree on terms. Although such disputes\u2014and the resultant interruption of traffic\u2014are rare, Congress may well be concerned if peering disputes between IP network providers result in captive customers losing access to telephone service. Interconnection agreements cover a multitude of parameters, including the number and physical points of interconnection, pricing (intercarrier compensation), transit, numbering and number portability, service levels, quality of service, and other terms and conditions. Many of these parameters may be best left to negotiations among private parties, and others may be best left to the FCC's expertise, but Congress may want to provide guidance and a mechanism for protecting residential and business customers if disputes arise between network providers. Public Safety/NG911: Successful transition from the legacy enhanced 911 (E911) architecture to the IP-based NG911 model will require the industry to resolve challenging technical issues relating to conveying accurate caller location data to the 911 call center when calls are made using nomadic, mobile, and over-the-top VoIP applications. The FCC plans to have trials to determine, among other things, how VoIP and other IP-based networks can interconnect with emergency service IP networks (ESInets). Although the industry and the FCC will take the lead in this transition, Congress may want to review statutory requirements to make sure they are not impeding the E911 to NG911 transition. Copper Wireline to Fiber or Wireless: Some ILECs are replacing existing customer voice and broadband services delivered over legacy circuit switched wireline networks with similar product offerings delivered over fiber and/or wireless IP networks. The FCC intends to seek information on how this technology migration would affect capabilities such as access to 911 and emergency services, the ability to send and receive a fax, credit card transactions for small businesses, alarm/security systems, and the ability for individuals with disabilities to continue to use assistive devices. This is important because, despite the fact that both wireline and wireless IP networks have many capabilities that the legacy copper PSTN lacks, there also are some uniquely positive features of the PSTN that wireless or fiber networks lack. For example, the legacy copper PSTN network has its own power source and continues to operate even when the electric service to a premise is not working; by comparison, fiber networks depend on the electric service at the premise. The copper PSTN has been engineered and built to 99.999% reliability, which is significantly higher than the reliability of IP and wireless networks. Also, the copper PSTN has been adapted to be able to accommodate the special needs of hearing-impaired and vision-impaired customers. Wireless networks may be less able to accommodate these needs. Congress may want to review the many requirements it has imposed on telecommunications carriers to determine which of these, if any, should be retained for IP networks. Legacy M onopoly- Era R egulatory O bligations: There are a number of federal and state statutory requirements, first enacted during the long period of government-sanctioned monopoly provision of telephone service, that are intended to protect customers from discontinued service or unanticipated network changes. For example, Section 214(a) of the Communications Act prohibits common carriers from discontinuing, reducing, or impairing service to a community, or part of a community, until the FCC certifies that the public interest will not be adversely affected in the present or future. Many states impose \"carrier of last resort\" service obligations that require ILECs to serve customers in their service areas on demand, regardless of the cost of offering such service. The FCC's rules for \"eligible telecommunications carriers\" (ETCs)\u2014those providers eligible to receive funds from the high-cost universal service fund\u2014also require network providers to offer certain services upon demand. These requirements, singly or in combination, may have the effect of forcing incumbent carriers to maintain their legacy TDM-based networks and services even as they are attempting to migrate to IP-based networks and services. Any diversion of capital expenditures to the upkeep of legacy networks could slow migration to the innovative new architecture. At the same time, Congress may be concerned that even if the vast majority of customers benefits, some may lose service in the transition. To the extent these issues stem from state laws, Congress might want to delineate what role, if any, states should continue to have as technology renders all services interstate in character. Differing R ates of IP A doption in a Network E nvironment: Some network providers are migrating to IP networks more quickly than others, and some end-users are migrating to IP-based customer premises equipment more quickly than others. Though the transition to an IP world is inevitable, late adopters will prefer to control the timing of their change-over. In some cases, they may even have a market incentive to delay the changeover, for example if that would allow a carrier to continue to collect above cost intercarrier compensation payments that it would not be able to command if interconnection rates were set in peering negotiations. Similarly, consumers who seek only the most basic voice service might resist purchasing IP-capable customer premises equipment such as a smartphone. If legacy networks or legacy customer premise equipment are incompatible with new IP networks, and if network providers are required to retain legacy networks and services in order to serve the slow-adopters, the IP transition will be delayed. Congress may want to provide the FCC with guidance on how to weigh the tradeoff between rapid IP deployment and protection of end users who may not wish to adopt new technologies.  From its inception, the statutory framework for the U.S. communications sector has explicitly addressed issues of market structure for two reasons. First, communications networks are characterized by significant economies of scale that limit the number of efficient-sized providers in the market. Second, the capacity of the spectrum available for use at any point in time is constrained by existing technology and lack of spectrum can impede competition by inhibiting market entry or the offering of new services.  A comprehensive statutory framework for U.S. communications policy, covering telecommunications and broadcasting, was first created in the Communications Act of 1934. That act created the FCC to implement and administer the economic regulation of the interstate activities of government-sanctioned telephone monopolies and the licensing of spectrum used for broadcast and other purposes. It explicitly left most regulation of intrastate telephone services to the states. In the 1970s and 1980s, a combination of technological change, court decisions, and changes in U.S. policy permitted competitive entry into some telecommunications and broadcast markets. In 1996, Congress passed the Telecommunications Act (1996 Act), which sought to open up markets to competition by removing unnecessary regulatory barriers to entry. The 1996 Act attempted to foster competition among providers that used similar underlying network technologies (for example, circuit-switched telephone networks) to offer a single type of service (for example, voice). It created one regulatory regime for carriers providing voice telephone service and another regime for cable television providers, and removed barriers to competitive provision of voice or cable (video) services. Within each of these communications modes it attempted to foster \"intramodal competition.\" For example, the ILECs, which until passage of the 1996 Act enjoyed government-sanctioned monopolies and a regulated rate of return, were required to make the individual, unbundled elements of their networks available to new entrants at cost-based rates. It was assumed that the entrants would slowly build out their networks, and reduce their dependence on ILEC network elements, as they built up market share and could begin to exploit economies of scale. But intramodal competition has proved limited. Although a number of new entrants were able to take advantage of the unbundling requirements to serve large business customers across multiple urban locations\u2014and to build out their own telecommunications networks in geographic areas with large business concentrations\u2014these \"competitive local exchange carriers\" (CLECs) generally were not able to successfully enter the residential voice market. Technological advances not envisioned by, or addressed in, the 1996 Act, however, created spillovers that began to allow for inter modal competition. Cable operators upgraded their networks to offer voice and Internet access as well as video services. Responding to the cable operators, telephone companies have now upgraded their wireline networks to offer video and Internet access services. Increasingly, both the legacy telephone companies and the legacy cable networks are migrating their traffic onto IP networks whose offerings represent information services that to varying degree are not subject to the legacy voice or video statutory provisions.  Although both the cable and telephone companies have invested heavily in their new networks, it appears that the migration has been relatively easier and less expensive for the cable companies to accomplish. The relatively inexpensive upgrade available to the telephone company networks\u2014deploying digital subscriber line (DSL) technology on existing copper telephone lines\u2014could not provide bandwidth and speeds equivalent to those provided over cable companies' upgraded hybrid fiber-coaxial cable networks with data over cable service interface specification (DOCSIS) 3.0 technologies. Instead, landline telephone companies have had to deploy relatively expensive optical fiber that cannot be economically justified except in areas that exceed some threshold level of population density. AT&T has deployed optical fiber to neighborhood nodes and then used legacy copper lines into customer premises. Verizon has deployed optical fiber all the way into the customer premise, and although this has yielded a higher bandwidth service it has cost a lot more to deploy. Wall Street has penalized Verizon for the higher upfront costs. AT&T has been able to extend its U-verse service into a larger portion of its service area than Verizon has been able to deploy its FiOS service, but neither has been able to provide high bandwidth landline broadband service universally throughout its service area. Moreover, by choosing an all-Internet Protocol technology platform with a fiber to the node network architecture, AT&T has had challenges meeting long-standing regulatory requirements, such as making public, educational, and governmental (PEG) access cable television channels available to subscribers in the same fashion as it makes commercial programming available, including making its PEG platform fully accessible to hearing-impaired and visually impaired viewers.  Those same telephone companies, however, have been the leaders in developing wireless broadband networks. Although these wireless networks do not have the same bandwidth capability as optical fiber networks and upgraded coaxial cable networks, they do offer sufficient bandwidth for many applications, and especially for many consumer and small business users. They also provide complementary mobile services for enterprise customers and other heavy-bandwidth users whose bandwidth needs cannot be met by wireless alone. Although the telephone companies continue to invest in their wireline facilities, they have responded to an apparent shift in demand from fixed to mobile services by shifting their capital investments from wireline to wireless. For example, in September 2012 Verizon announced that it would not expand its FiOS fiber-optic network beyond its existing contractual franchise obligations, and would redirect investment toward its wireless network. Yet Tony Melone, Verizon's chief technical officer, explicitly included the FiOS network among the four platforms the company plans to use in the future, alongside its 4G LTE wireless network, a global IP backbone, and data centers using cloud infrastructure. On one hand, Verizon appears to be committed to taking full advantage of FiOS capabilities in the locations where it is deployed; on the other hand, the high cost of FiOS deployment appears to be constraining the footprint on which such deployment will take place.  In December 2011, Verizon announced it was purchasing from four major cable operators\u2014Comcast, Time Warner Cable, Bright House Networks, and Cox Communications\u2014the advanced wireless service (AWS) spectrum that those companies had first purchased in a federal auction in 2006. At the same time, Verizon announced joint marketing agreements with these four companies, under which Verizon would market the cable operators' video services in those markets in which Verizon did not offer its own FiOS video service and the cable companies would market Verizon Wireless service. These agreements confirmed that the cable companies had decided not to enter the wireless service market and that Verizon was not planning to expand the footprint of its FiOS offering. The spectrum transfers and joint marketing agreements were approved by the Antitrust Division of the Department of Justice and by the FCC in August 2012 subject to several modifications and conditions. In those markets in which the purchase would have resulted in Verizon Wireless holding more than certain threshold levels of spectrum, Verizon Wireless sold or swapped spectrum with T-Mobile. Similarly, the joint marketing agreement was modified to allow the cable companies to market Verizon Wireless services under their own brand names, such as Comcast Wireless, immediately (rather than having to postpone such marketing for five years, as required under the original agreement). The policy implications of these transactions, and thus the appropriate statutory framework for this new market structure, may depend on the extent to which consumers view wireline and wireless services as substitutes or complements.  The decision of the cable companies to forgo entry into the wireless market, Verizon's acquisition of an important block of wireless broadband spectrum, and the joint marketing agreements between Verizon and the cable companies may reduce the amount of spectrum available to independent wireless carriers and limit Verizon's participation in the video market to those geographic markets in which it already offers FiOS service. The Verizon/cable company transactions highlight the possibility that the enter/don't enter/exit decisions of incumbent network providers can markedly change market forces and incentives. Congress may want to consider whether structural constraints (such as spectrum caps) and/or behavioral constraints (such as interoperability and/or network neutrality requirements) are needed to limit the market power of the vertically integrated network providers.  The 2005 Phoenix Center Convergence Paper describes possible policy-maker concerns when there is convergence. In a section entitled \"What Entry Says About Collusion,\" it first states, \"When faced with a concentrated market, probably the first concern that comes to the mind of a policymaker is the threat of collusion.\" It then explains that \"the collusive outcome is to ignore convergence and not enter. The converse is also true\u2014 if we observe reciprocal entry, then that entry is solid evidence that collusion is not occurring. \" (Emphasis in original.) Noting cable operator entry into the voice market and telephone company entry into the video market, it concludes that \"this simple observation alone is strong evidence that collusion is not present ... and policymakers should not focus on the possibility of collusion, at least in those markets where reciprocal entry is observed.\" But in a footnote it adds the caveat, \"Once market shares stabilize, probably five to seven years out, then policymakers may wish to revisit the question of collusion.\" Although the Phoenix Center scenario focuses solely on wireline convergence, and thus does not take into account the development of wireless networks as partial complements to and substitutes for wireline networks, its analysis suggests that policy-makers should be mindful of the enter/don't enter/exit decisions of incumbent network providers. Given the simultaneous decisions of the cable operators not to enter the wireless broadband market and of Verizon to limit its geographic reach in the wireline broadband market, Congress may want to be sure that its statutory framework is able to address competition and other public policy issues in an environment in which the enter/don't enter/exit decisions of one or two providers can markedly change market forces and incentives.  There are four general approaches that a statutory framework could take (or some combination of these): structural regulation, such as caps on the amount of spectrum any network provider may own or control in a geographic market; ex ante non-discrimination rules, such as explicitly stated network neutrality requirements; ex post adjudication of abuses of market power, as they arise, on a case-by-case basis; and reliance on antitrust (and unfair methods of competition) law and self-regulation. Ex ante rules and ex post adjudication both typically focus on anti-competitive discrimination that harms consumers, but in distinct ways. Ex ante rules create affirmative legal duties that are intended to remedy either past discrimination or the likelihood of future discrimination, prohibiting certain activities before the fact. By contrast, ex post adjudication typically seeks to punish identified episodes of discrimination on a case-by-case basis, after the fact. Ex ante schemes impose more up-front costs, by restricting certain behaviors, some of which might have proven beneficial to consumers. But, depending on the cost to consumers (in terms of denied access to potentially highly valued applications) of allowing discrimination to occur and then adjudicating after the fact, the ultimate cost of ex ante rules might prove lower than that of ex post adjudication. The dominant cost characteristic of the communications sector is the substantial fixed costs, and associated scale and scope economies, of large networks. Both wireline and wireless broadband networks are subject to economies of scale that limit the number of efficient competitors that can participate in the market. Thus, historically the statutory framework for communications has focused on market structure.  As discussed earlier, in recent years the FCC has taken steps to reduce structural regulation by distinguishing between telecommunications services and information services and removing information services and networks from Title II regulation. But given recent enter/don't enter/exit decisions by major network providers, there has been increased interest in structural regulation.  There has been concern about potential choke points that could limit the number of viable competitors. This is a particular concern in the wireless broadband market, as only limited amounts of suitable spectrum are available in major metropolitan areas. As wireless carriers migrate from 2G to 3G and 4G networks, they cannot abandon their customers who still have older-technology phones, and thus they must allocate some of their spectrum to each generation of technology. As a result, the major wireless carriers have sought to amass large amounts of spectrum in major markets. Some observers have alleged, however, that the two dominant carriers\u2014AT&T and Verizon Wireless\u2014may have the incentive to strategically hoard spectrum, depriving smaller carriers of access to the low frequency spectrum that has superior propagation characteristics. These observers generally argue that spectrum caps or spectrum screens are needed both for the auctioning of newly available spectrum and for reviewing wireless spectrum license transactions. The FCC has employed such structural rules since 1994. (The policy debate on spectrum caps and screens is discussed later in this report, in the section on spectrum policy.)  The basic principle behind a network non-discrimination regime is to give users the right, by rule, to use non-harmful attachments or applications, and to give equipment and applications innovators the corresponding right, also by rule, to supply them. It therefore applies both to end users and to independent applications providers. Proponents claim that such a regime avoids some of the costs of structural regulation by allowing for efficient vertical integration so long as the rights granted to the users of the network are not compromised. In December 2010, the FCC adopted its Open Internet Order, establishing ex ante rules to govern the network management practices of broadband Internet access providers. There are three primary components: transparency: fixed and mobile broadband Internet service providers are required to publicly disclose accurate information regarding network management practices, performance, and commercial terms to consumers and to content, application, service, and device providers; no blocking: fixed and mobile broadband Internet service providers are both subject, to varying degrees, to no blocking requirements. Fixed providers are prohibited from blocking lawful content, applications, services, or non-harmful devices, subject to reasonable network management. Mobile providers are prohibited from blocking consumers from accessing lawful websites, subject to reasonable network management, nor can they block applications that compete with the provider's voice or video telephony services, subject to reasonable network management; and no unreasonable discrimination: fixed (but not mobile) broadband Internet service providers may not unreasonably discriminate in transmitting lawful network traffic over a consumer's broadband Internet access service. Reasonable network management shall not constitute unreasonable discrimination. Multiple appeals of the order, challenging the FCC's authority to impose these rules, have been filed and subsequently consolidated for review in the U.S. Court of Appeals, D.C. Circuit, with Verizon Communications the remaining challenger seeking review. Oral arguments were held in September 2013. Typically, proponents of non-discrimination rules are proponents of network neutrality\u2014not favoring one application (or applications provider) over another. They argue that network neutrality, as embodied in ex ante non-discrimination rules, fosters the goal of stimulating investment and innovation in broadband technology and services in two ways: (1) by eliminating the risk of future discrimination, thereby providing independent applications providers greater incentives to invest in broadband applications, and (2) by facilitating fair competition among applications, ensuring the survival of the fittest. Proponents claim that a network that is as neutral as possible, with such neutrality ensured by explicit non-discrimination rules, provides entrepreneurs predictability in that all applications are treated alike. This, they argue, will foster investment in broadband applications by eliminating the unpredictability created by potential future restrictions on network usage. Neutrality provides applications designers and consumers alike with a baseline on which they can rely. Usage restrictions, they claim, particularly harm those small and startup developers that are most likely to push the envelope of what is possible using the Internet's architecture. Proponents also claim that the most promising path of development will be difficult to predict in advance; neutral network development is likely to yield better results than planned innovation directed by a single prospect holder. Any single entity will suffer from cognitive biases (such as a predisposition to continue with current ways of doing business). These proponents conclude that restrictions on usage, however well-intended, tend to favor certain applications over others. A regulatory framework that requires network providers to justify deviations from neutrality would prevent both unthinking and ill-intentioned distortions of the market for new applications. The proponents of non-discrimination rules argue that the restrictions not only directly harm consumers and applications providers today, but also have a chilling effect on innovators and venture capitalists considering future applications development and deployment. They argue that the possibility of discrimination in the future dampens the incentives to invest today. Critics of e x ante non-discrimination rules claim that such rules would intrude too much into the business plans of broadband network providers. These critics argue that non-discrimination rules impinge on the ability of broadcast network providers to fully exploit efficiencies from vertical integration or to use price discrimination or other pricing strategies to maximize return on investment. Another criticism of ex ante non-discrimination rules is that they inherently lead to delays, litigation, and other regulatory costs, as parties fight over interpretation of the rules. The complexity of communications networks, it is argued, renders it difficult, if not impossible, to construct clear ex ante rules. These critics point to the industry experience implementing the 1996 Act. The other major criticism is that ex ante rules of any sort, and especially those relating to network access, will artificially aid an independent applications provider in its contractual negotiations with a broadband network provider by allowing the applications provider to threaten to bring a regulatory complaint and attendant costs if the network provider does not accept its terms. According to this argument, the network provider often might be forced to accept unfavorable or inefficient access terms to avoid the threat of litigation. An alternative approach would adjudicate alleged abuses of market power ex post , as they arise, on a case-by-case basis. For example, the Progress and Freedom Foundation has proposed an ex post approach modeled after the Federal Trade Commission Act which would give the FCC the authority to adjudicate allegations of \"unfair methods of competition ... and unfair or deceptive acts in or affecting electronic communications networks and electronic communications services.\" These unfair practices could include interconnection-related practices (such as the refusal to interconnect or unfair terms, conditions, and rates of interconnection): if such practices were shown to pose a substantial and non-transitory risk to consumer welfare; and if the Commission determined marketplace competition were not sufficient to protect consumer welfare; and if the Commission considered whether requiring interconnection would affect adversely investment in facilities and innovation in services. Under the proposal, the Commission could require the guilty party to pay damages to the harmed party if any violation were found.  Proponents of ex post adjudication claim that the potential harm to consumers from bad regulation far exceeds the potential harm from badly functioning markets and therefore the burden of proof must fall on the regulator for imposing any regulation. They claim that even inefficient market outcomes are likely to be less problematic than regulatory solution because (1) markets are effective at responding to and overcoming their own inefficiencies, (2) government may not have the incentive to improve matters, and (3) policy makers are likely to lack the information needed to make efficient decisions. Proponents of ex post adjudication argue that a new statute is needed in order to replace the current model of regulation based on vague standards such as the \"public interest\" and \"just and reasonable\" with the well-established \"unfair competition\" standard in the Federal Trade Commission Act.  E x post adjudication has been subject to several criticisms. First, it is based on the assumption that consumer welfare loss from bad regulation is always far greater than consumer welfare loss from badly performing markets, and that it is therefore best to err on the side of under-regulating. This may or may not be true in the case of markets characterized by networks where the platform provider and applications providers must cooperate to maximize consumer welfare. There is a large and growing academic law and economics literature on these unique markets; there is no consensus in the literature, or from empirical evidence, that in these markets there is less risk from erring on the side of under-regulation than on the side of over-regulation. Nor is there theoretical or empirical proof that the potential harm to consumers from distortions created by ex ante rules are greater than those created by ex post adjudication. It is possible that a narrowly crafted ex ante non-discrimination rule could create less distortion than ex post adjudications that will inherently result in some, and potentially many, innovative independent applications providers being driven from the market, thereby denying customers the benefit of their services.  More generally, critics claim that ex post regulation distorts the business plans, and undermines the negotiating positions, of independent applications providers by placing the burden of proof for network access on them if they seek to develop and introduce an application that may not fit into the business plan of the network provider. According to this argument, the independent applications provider might be forced to modify its planned application or accept unfavorable or inefficient access terms to avoid the threat of being denied access to the broadband network. Some critics also are concerned that replacing the public interest standard with what is basically an antitrust standard fails to take into account non-economic objectives of U.S. communications policy, such as public safety, consumer protection, access for hearing- and visually impaired individuals, localism, and diversity of voices. The broadband network providers have argued that they should not be subject to access regulation because they face strong market incentives not to restrict the access of independent applications providers to their networks. They cite the existence of indirect network efficiencies, which reward network providers for keeping their networks open, and the availability to most Americans of at least two broadband networks. They argue that any access regulation would cause harm, by curtailing their ability to vertically integrate to exploit efficiencies such as ensuring quality of service levels needed for video and voice services. They argue that where they have placed usage restrictions on customers those restrictions were needed to ensure quality of service and other bandwidth management objectives and to make it feasible to undertake their huge infrastructure investments. They also claim that they remain subject to the antitrust laws, which would constrain them from undertaking any anticompetitive activities that are harmful to consumers. Critics of reliance on antitrust enforcement argue that public policy objectives in the communications sector extend far beyond the market competition issues addressed by antitrust law, to include public safety, consumer protection, access for hearing- and visually impaired individuals, localism, diversity of voices, etc. There is a Supreme Court decision that could affect the efficacy of an antitrust approach to regulation. The 1996 Telecommunications Act includes an \"antitrust savings clause\" stating that neither the act nor any amendments made by it \"shall be construed to modify, impair, or supersede the applicability of any of the antitrust laws.\" An antitrust suit was brought against Verizon, an incumbent telephone company that had been disciplined by both the FCC and the New York Public Service Commission (PSC) for breaching its duty under the 1996 Act to adequately share its network with competitive providers. The plaintiff alleged that such breaches represented illegal exclusionary and anticompetitive behavior under Section 2 of the Sherman Act. In its 2004 Trinko decision, the Supreme Court ruled that the breached FCC and PSC rules affirmatively required Verizon to aid its competitors but that failing to meet those requirements was not a sufficient basis for finding a violation of antitrust law. The Court found that \"the act does not create new claims that go beyond the existing antitrust standards.\" Violations of the obligations under communications law cannot be enforced via the antitrust laws. In the case, three justices joined the concurring opinion that argued that Trinko, the plaintiff, did not have standing. The majority opinion decided the case on the merits, and did not address the question of whether the plaintiff had proper standing. The concurring opinion raises important questions as whether Trinko has the proper standing to bring the case. That opinion did not say that no one had standing to bring the case, but rather that AT&T, Trinko's service provider, would have been the proper plaintiff (since it was injured by Verizon's failure to provide it access), rather than Trinko, AT&T's customer. This means it is likely possible to bring a private antitrust suit against a regulated telecommunications company, but it may not be possible for consumers to bring suit.  Congressional reaction to the Trinko decision was mixed. Then-chairman of the House Judiciary Committee, Representative Sensenbrenner, stated concern that the decision not be \"perceived as giving a green light to all manner of anticompetitive behavior by the Bells.... The Committee on the Judiciary ... will not hesitate to develop legislative responses to competitive problems that may arise as a result of this decision.\" Then-ranking minority member of the House Judiciary Committee Conyers called for legislation to address the \"Supreme Court's horrible blunder.\" Representatives Sensenbrenner and Conyers introduced a bill in May 2004 that would have added a section to the Clayton Act to make unlawful actions such as those that had been taken by Verizon, but the bill did not move forward. At the same time, then-chairman of the House Energy and Commerce Committee Tauzin expressed his approval that the Supreme Court had \"decisively reiterated ... that the regulation of the telecommunications industry should be the purview of the FCC and the state [public utility commissions], rather than judges all across the country.\" It may be that, when Congress inserted the \"antitrust savings\" clause in the 1996 Act, many Members believed that the clause was preserving an unlimited private right of action on the part of other-than-directly affected parties to sue under the antitrust laws. But, as this case indicates, the clause may be of little effect in instances such as this in which it is found that traditional antitrust principles and standards are not implicated. These concerns might be moot, however. Under current FCC and court interpretations of law, IP network providers and providers of information services are not subject to the provisions in Title II of the Communications Act that were intended to jump-start competition, but rather to the much more limited requirements in Title I. Congress, however, may want to clarify that for those network and service providers that are not subject to the provisions in Title II that require local exchange carriers to affirmatively aid new entrants, the Trinko decision is not relevant.  Two elements of the current regulatory framework\u2014the retransmission consent/must carry requirements for retransmission of broadcast signals by multi-channel video programming distributors (MVPDs) and the broadcast media ownership rules\u2014were constructed to address specific market structure concerns. The Cable Television Consumer Protection and Competition Act of 1992 (1992 Cable Act, P.L. 102-385 ) established rules that govern the carriage (retransmission) of television signals by cable operators. At that time, before cable faced competition from satellite television or from the video services of telephone companies, Congress was concerned that cable companies might refuse to carry the signals of local broadcast stations or might refuse to compensate local stations for the carriage of their signals. Those outcomes would have harmed the long-standing public policy objective of localism\u2014fostering programming of particular interest and importance to the local area. Congress therefore created the retransmission consent/must-carry rules under which every three years each local commercial broadcast television station must choose between the following: retransmission consent\u2014 negotiating a retransmission consent agreement with each cable system operating in its area, such that either the broadcaster is compensated by the cable system for the right to retransmit the broadcast signal or the cable system may not retransmit the broadcast signal; and must-carry \u2014requiring each cable system operating in its service area to carry the signal, but receiving no compensation for such carriage.  With this mandatory election, broadcasters with popular programming that are confident the local cable systems will want to carry that programming can make the retransmission consent election and be assured compensation for such carriage, and broadcasters with less popular programming that the local cable systems might otherwise not choose to carry can make the must-carry election and be assured that their signals will be carried by all local cable systems. As satellite and telephone providers have entered the video distribution market and been classified as MVPDs, they too have become subject to the same or analogous retransmission consent/must-carry requirements.  The retransmission consent/must-carry rules were intended to help mitigate cable company negotiating leverage vis-\u00e0-vis local broadcast stations. The regulatory framework also includes broadcast media ownership rules (some explicitly in statute, some implemented by the FCC but later referred to in statute) intended to place limits on broadcasting consolidation that could impair the three long-standing policy objectives of competition, localism, and diversity of voices. There are separate rules addressing the number of television stations that a single entity may own or control in a local market, the number of radio stations that a single entity may own or control in a local market, ownership or control of radio and television stations (radio/television cross-ownership) in a local market, ownership or control of a newspaper and a broadcast station (newspaper/broadcast cross-ownership) in a local market, the total television reach that a single entity may have nationwide (in terms of the percentage of all U.S. television households served by the stations owned or controlled by that entity), and the number of national broadcast networks that a single entity may own or control. In addition, there are FCC rules relating to what kind of activities and decision making one station in a market may undertake on behalf of a second station in the same market without control of the second station being attributed to the first station. By statute, the FCC must review these ownership rules every four years to determine if they remain in the public interest.  There have been many structural and behavioral changes in the video market since the retransmission consent/must carry rules were enacted in 1992 that have affected the relative negotiating strength of the various parties. In 1992, there were only limited multichannel pay television alternatives to cable. Today, Dish Network operates in all 210 U.S. markets, DirecTV in about 195 markets, and AT&T and Verizon are expanding their video footprints. As a result, the cable companies have lost some of their leverage when negotiating retransmission consent agreements with broadcasters. If a broadcaster reaches an impasse with a cable company and the cable company faces the threat of not being allowed to carry the broadcaster's signal, then that cable company risks losing customers to a cable or telephone company competitor that continues to offer the broadcast programming, especially if the broadcaster offers \"must-have\" programming that some portion of cable subscribers would change providers to retain. In the 1990s and early 2000s, the compensation that local broadcast stations received for retransmission consent rarely took the form of cash payments from MVPDs. Rather, in most cases, the local broadcast affiliate gave its network the right to negotiate retransmission consent directly with the MVPDs; in exchange, the affiliate station made lower cash payments to its network for the network programming (or, in some cases, received cash payments from the network). The major broadcast networks, which are subsidiaries of major program producers and aggregators that also own multiple cable networks, sought non-cash compensation in the form of MVPD agreement to carry their full array of cable networks.  By the mid-2000s, there were two market developments that led to changes in these business relationships. The broadcast network parent companies had successfully gotten most of the major MVPDs to carry their full array of branded cable networks. And the cable networks had developed a very successful business model based on two revenue streams\u2014advertising revenues and also per subscriber license fees imposed on MVPDs. By 2005, some broadcasters\u2014in particular, those that had many stations across multiple markets, such as CBS with its owned-and-operated stations and large group station owners, such as Sinclair and Nexstar\u2014sought to emulate the cable network business model, especially as their advertising revenues were becoming increasingly sensitive to the underlying business cycle. This placed an emphasis on cash compensation for retransmission consent. Since in many cases compensation previously was in non-cash form, the move to cash payments was strongly resisted by MVPDs.  In this new strategy, the broadcast network or station group negotiated with each MVPD on behalf of all of its owned stations. That is, a single retransmission consent negotiation covered multiple local markets, rather than having separate negotiations for each broadcast station.  At the same time, online video distribution and mobile video distribution were beginning to develop. MVPDs developed their own websites and sought the rights to retransmit the broadcast signals over those websites. In some cases, the broadcasters and MVPDs jointly developed \"TV Everywhere,\" a strategy to retain the legacy business model by extending consumer access on new gateways such as applications for tablets and smartphones to those consumers who subscribed to an existing MVPD. But there also were new online video distributors not affiliated with the MVPDs and the broadcasters also wanted to make their programming available to these new outlets. As a result, the traditional retransmission consent negotiations between broadcasters and MVPDs began to take on additional elements\u2014for example, the terms and conditions, including timing windows and exclusive/non-exclusive access to the broadcaster programming for screens other than the television screen. The terms, conditions, and rates that had to be negotiated within retransmission consent agreements increased exponentially. This created many more elements that potentially could create a negotiating impasse. Thus, although formally retransmission consent is a right of a particular local broadcast television station, an impasse could be caused by a conflict that had nothing to do with that station or with its local market. In addition, in recent years, many television stations have entered into sharing arrangements with other stations in their local market to jointly sell advertising and/or produce local news programming, typically with one station managing the shared operation and perhaps providing most or all of the staffing and other resources. In many cases the FCC has not deemed a station to have control over another station in the same market even if such control is considered to exist, and must be reported, under generally accepted accounting practices. Such agreements have resulted in the proliferation of so-called \"virtual duopolies\" that would not be allowed under the local ownership rule if control had been attributed to the first station. Where a single entity is able to jointly negotiate retransmission consent on behalf of two or more stations in a local market, this provides that broadcaster with leverage, especially if both stations are affiliates of major broadcast networks. According to the American Cable Association, which represents small cable companies, \"48 pairs of Big 4 broadcasters in 43 DMAs coordinat[ed] their retransmission consent negotiations in 2011.\" The number of virtual duopolies is expected to increase if the many recently announced television group mergers are approved.  As explained above, in recent months there have been a large number of mergers that, if approved, would give the acquiring station groups greater leverage when negotiating retransmission consent agreements with MVPDs. In some cases, these larger station groups also will enjoy duopoly or virtual duopoly positions in some local markets, again increasing their negotiating leverage. In part to create a countervailing negotiating force, some large cable companies have discussed merging and Dish Network has raised the trial balloon of merging with DirecTV. According to a recent survey by Leichtman Research Group, 86% of households nationwide subscribe to a multichannel video service, down from 88% in 2010. Of the television households that do not subscribe to an MVPD service, 42% get one or more of the three major over-the-top services (Netflix, Amazon Prime, and Hulu Plus). Eight percent of all television households watch over-the-air broadcast television only. About 1.4% of all television households discontinued subscription to an MVPD service over the past year, which is about the same rate as in recent years, suggesting no great surge in \"cord cutting\" households. In recent years, a number of online video distributors have entered the market. They do not qualify as MVPDs and therefore are not subject to the retransmission consent requirements. As discussed earlier, Aereo and a number of copycat companies have a mini-antenna for each of their subscribers to retransmit broadcast signals to subscriber premises, and claim that such retransmission does not infringe copyright. Broadcasters have sued these companies for copyright infringement, but the cases are still progressing in court. In the interim, in those markets in which the courts have not issued an injunction, those services provide households with an alternative source of broadcast programming if an impasse between their MVPD and a local broadcaster has resulted in a blackout of that broadcaster's programming. This alternative access to broadcast programming could weaken the position of broadcasters in their retransmission consent disputes with MVPDs, though it is potentially a two-edged sword since households that subscribe to Aereo might have less reason to maintain their MVPD subscriptions.  These market developments, with the exception of the last one, have tended to make broadcaster-distributor negotiations more contentious, with greater risk of impasses. The highly publicized retransmission consent blackout of CBS networks on Time Warner Cable systems was just one of several impasses between programmers and distributors in the summer of 2013, some of which were resolved before blackouts occurred, some of which were not. For the period January 1 through August 22, 2013, SNLFinancial has identified 12 publicized instances of broadcast signal negotiation impasses, which resulted in the blackout of 94 full-power broadcast television stations for various periods of time, including the CBS-Time Warner Cable and Raycom-DISH blackouts that began in August.  In addition to these blackouts involving broadcast station signals, there have been a number of impasses involving MVPDs and cable networks. Congress is more likely to be concerned about broadcast-related blackouts than cable network-related blackouts because of its long-standing commitment to localism and diversity of voices, which are impacted more by the loss of local broadcast signals than by the loss of a national cable programming network. (Congress also has been concerned about blackouts of local sports programming when regional cable sports networks are unable to reach agreement with MVPDs, because such programming is of great interest to consumers, but local news and public affairs programming is more central to civic institutions.) Congress may want to review the current statutory framework to determine whether any changes are needed to make it more effective in the new market environment characterized by greater consolidation and increased risk of programming blackouts. From the perspective of consumer protection, blackouts result in households losing access to programming that they paid for. SNLFinancial has identified 35 retransmission consent blackouts between 2005 and 2013 that lasted 28 days or longer. In total, these blackouts involved 145 stations in 111 markets. Four of these blackouts, involving 30 stations in 19 markets, began in 2013. In these situations, MVPDs are in a difficult situation. On one hand, they risk alienating customers by not providing a credit for blacked out programming. On the other hand, giving anything beyond the most token credit lends support to the broadcaster negotiating claim that its programming is highly valued and thus merits substantial retransmission consent compensation.  One of the most effective broadcaster negotiating devices is to time the termination of retransmission consent agreements to coincide with major sports events, which represent the ultimate in \"must have\" programming. To the extent the programming is local, blackouts decrease the diversity of local voices. This can be especially significant if a blackout involves more than one local station because the broadcaster has a \"duopoly\" or \"virtual duopoly\" position in the local market.  Some observers have proposed that the best way to protect consumers is to require the broadcasters to continue to provide the programming to the MVPD while the impasse is addressed in some sort of mandatory arbitration process either within or outside the FCC. But mandating that the program continue to be provided would substantially reduce the leverage the broadcaster would have in its negotiations. One middle position might be to mandate that the programming continue to be made available only for 30 days, while an expedited arbitration process takes place. That would allow MVPDs to meet the typical language in their franchise agreements with local franchise authorities that they give subscribers 30-day notice of any change in programming. An alternative approach to direct intervention into the retransmission consent negotiating process would be to set structural regulations that would attempt to limit those situations most likely to give rise to undue negotiating leverage. Structural constraints could be set up that are market-specific or that cross markets.  For example, if a single entity owns multiple stations that reach a very large portion of total U.S. television households, that entity could be negotiating with MVPDs that have far less reach and thus would be at a greater disadvantage if an impasse led to a blackout. By statute, an entity may own and operate local broadcast stations that reach, in total, up to 39% of U.S. television households. But when calculating the total audience reach by an entity's stations, the so-called \"UHF discount\" is applied\u2014audiences of UHF stations are given only half-weight. Thus an entity could own stations that reach up to 78% of U.S. television households. This discount had been imposed because in the pre-digital analog world UHF stations had less reach than VHF stations and there was a policy goal of fostering use of the UHF spectrum. Now that the broadcast digital transition has been accomplished, stations broadcasting on the UHF spectrum actually enjoy superior transmission to stations on the VHF spectrum. There are differences of opinion as to whether the FCC has the authority to eliminate the UHF discount on its own. Nonetheless, the FCC has issued for public comment a Notice of Proposed Rulemaking that tentatively concludes that the UHF discount should be eliminated, but that would grandfather the discount for UHF stations already owned by station groups. If Congress is concerned that a single entity could attain undue negotiating leverage if it exceeded a 39% national reach, it might instruct the FCC to eliminate the discount or to clarify that the FCC has the authority to undertake a rulemaking proceeding that could result in elimination of the discount. There also have been differences of opinion about the public interest impact of allowing a single entity to own and control two major network-affiliated stations in a single local market or of allowing an entity to have a virtual duopoly in a single local market through use of a sharing arrangement. The National Association of Broadcasters and other supporters of duopolies argue that the economies gained and potential increase in revenues generated allow stations to invest more in local programming and might even be the only way to keep two stations on the air. While all video distributors tend to oppose such duopoly situations, small cable operators represented by the American Cable Association in particular claim that two concurrent trends\u2014the development of competitive alternatives to cable and the increase in virtual duopolies that allow a single broadcaster to negotiate retransmission consent agreements for the affiliates of two different network in a single local market\u2014place small cable companies at a distinct disadvantage in those negotiations. They cite a study by Professor William P. Rogerson that claims that smaller MVPDs\u2014and hence their primarily rural customers\u2014pay retransmission consent fees that on average are twice as high per subscriber as those paid by large MVPDs. The small cable operators propose, among other things, that the retransmission consent statute be modified to prohibit any entity from negotiating retransmission consent on behalf of more than one station in a local market. The Television Consumer Freedom Act ( S. 912 ), introduced by Senator McCain, would indirectly address some of the complexities that are affecting broadcaster/MVPD retransmission consent negotiations as well as cable network/MVPD negotiations by creating incentives for both programmers and distributors to offer programming on an a la carte basis, rather than in packages or tiers. It would deny an MVPD access to the low-cost compulsory copyright for the retransmission of the copyrighted works on a broadcast signal if the MVPD did not offer that signal and all other video programming channels to its subscribers on an a la carte basis. It also would not allow a broadcast station to receive compensation for the retransmission of its signal by an MVPD if it did not offer its broadcast signal, or any other video programming under its control, to MVPDs on an a la carte basis. Finally, a programmer could offer a channel of video programming to an MVPD as part of a package only if it also offered that channel on an a la carte basis. If an MVPD and a programmer (of broadcast or cable channels) failed to reach agreement regarding the terms, including prices, for the distribution rights, then both the MVPD and the programmer would have to disclose to the FCC the terms of the most recent offer they made. Proponents of this proposal suggest that these incentives for broadcasters and other large programmers to make their offerings available on a \"wholesale\" a la carte basis, and for MVPDs to make their consumer offerings available on a \"retail\" a la carte basis could foster channel-specific negotiations that would be less subject to impasses. But, at least at the wholesale level, programmers already make their offerings available on an a la carte basis; they simply choose to price their individual channels and packages in such a fashion that it rarely is beneficial for a distributor to acquire programming on an a la carte basis. There are market forces at play that could constrain the recent increase in programmer-distributor impasses and blackouts without any government intervention. Consumers who face actual blackouts, or even the threat of blackouts, become aware of alternatives\u2014the availability of Aereo for relatively inexpensive access to broadcast signals in some markets, the availability of rooftop or rabbit-ear antennas for free over the air reception of broadcast signals in all markets. Actual and threatened blackouts therefore may increase the rate of \"cord-cutting\"\u2014of households abandoning MVPDs altogether. Any significant migration of MVPD customers to over-the-top alternatives is likely to harm the financial position of broadcasters (and other major programmers) and MVPDs alike. This suggests that all these parties should have an incentive to avoid blackouts. But given the increasing complexity of the negotiations, that incentive may not be sufficient to protect consumers from blackouts. Wireless broadband is very spectrum-intensive. Steep projected growth in demand for both mobile and fixed wireless services and other spectrum-using services make efficient spectrum management an increasingly important policy goal. As never before, there will be costs to society if the statutory framework does not foster efficient spectrum use.  Spectrum, by itself, is not of any use. It has value when technology is applied to it to create services. But the direction that the applied technology takes will depend on the way spectrum is allocated for use and rules about such use. For example, since different parts of the spectrum have different signal-carrying characteristics, different equipment must be developed for different portions of the spectrum. But innovators have little incentive to develop the equipment needed for a previously unused portion of the spectrum until the policy makers have made that portion available to service providers. As another example, technological development will take a very different path if spectrum users are assigned exclusive licenses to specific spectrum than if spectrum users are required to share spectrum, since these two options create different potential problems of electromagnetic interference. As a third example, since transmitters are subject to rules about the interference they can create, but receivers are not subject to requirements about their ability to block extraneous transmissions, vendors have placed a lot of effort in developing transmitters that meet those requirements but little or no effort in developing receivers that can block out unwanted signals. More generally, product development tends to follow the path defined by statutory and regulatory rules. Just as different portions of the spectrum have different characteristics, different technologies that can be applied to spectrum to create services have different characteristics. For example, \"spread spectrum\" technology, which underlies Wi-Fi, spreads a radio signal out over a wide range of frequencies; this makes the signal both difficult to intercept and less susceptible to interference. It is an especially effective technology for shared spectrum use, but loses its advantages in an environment of exclusive channel assignments. In contrast, the technologies being deployed by the cellular wireless broadband network providers in their macro networks create more interference and lend themselves to exclusive channel assignments. As explained earlier, U.S. wireless broadband service relies heavily on both types of technology. This suggests that relying on a single way to allocate spectrum\u2014for example, only through auctions for exclusive channel rights or only through rules for shared, unlicensed use\u2014could favor one type of technology over another, thereby artificially cutting off potentially rich avenues for innovation. In fact, the FCC already employs multiple approaches. As discussed below, since 1993 it has been authorized by Congress to hold spectrum auctions and has held a number of auctions. But as far back as 1985, the FCC also has set aside blocks of spectrum for shared use. Recently it has moved toward a hybrid approach to spectrum allocation in the \"white spaces\" that exist between licensed television broadcasters by creating rules that allow different types of users to share that block of spectrum while protecting broadcasters from interference. Traditionally, spectrum management has included three tasks\u2014allocating blocks of spectrum to different uses, granting individual entities exclusive spectrum licenses for specific radio frequency channels within those spectrum blocks, and setting rules on how licensees may utilize the spectrum channels they are granted, for example, not allowing them to transmit in a fashion that creates electromagnetic interference with any other channel. To protect against interference, a lot of spectrum was set aside to provide buffers. These buffers have taken the form of \"guard bands\" (unused spectrum channels) between spectrum blocks and \"white spaces\" between licensees operating within a channel.  New technological developments, such as network-centric technologies that can turn some types of interference from an insurmountable obstacle into a manageable occurrence, are increasing the productive capacity of fixed amounts of spectrum by allowing shared use of spectrum and reducing the need to set aside buffer spectrum. With the new technologies, the transmitting and receiving radios of multiple users can be \"networked\" to jointly move transmissions from one communications node to the next in the same fashion that traffic moves on the Internet, reducing or eliminating interference choke points while better utilizing available spectrum. With the danger of interference reduced, more users can share a given amount of spectrum. These new technologies already allow for spectrum sharing and, more generally, the more intensive use of existing spectrum, since it potentially allows for the utilization of otherwise unused white spaces and perhaps even guard bands. But this technology does not work well in narrow spectrum channels. To bring significant efficiencies, it requires setting aside a large block of spectrum for shared use. Some in the wireless sector, and in particular the large wireless carriers, argue that it is more efficient to give individual licensees blocks of spectrum for their own exclusive use than to require spectrum sharing. They claim that they\u2014and the financial community\u2014require the certainty associated with exclusivity in order to invest in their networks and that this in turn will generate technological innovation. But given that there can be benefits from spectrum sharing as well as from license exclusivity, there may be reasons for Congress and the FCC to continue to allocate spectrum using both methodologies. Peter Rysavy, a longtime wireless industry observer, has identified the potential and the challenges of spectrum sharing: There is no question that spectrum sharing can and will eventually result in more efficient overall use of spectrum. There are already a number of spectrum sharing solutions in the market that can work under defined circumstances. But what must be understood is that the spectrum-sharing approaches range from simple to extremely complex, from readily achievable and in use today to extremely difficult with technologies yet to be developed. The ones being used today solve relatively simple problems, e.g., geographic sharing or sharing between two types of fixed systems. More complex problems, such as how a carrier class mobile technology could share with multiple government systems will take many years to develop, test, and implement in an economically rational manner. Making spectrum sharing a reality will mean identifying what types of systems can be shared, negotiating and stipulating access rights, determining the market for such shared systems, developing specifications and standards to allow sharing including spectrum-coordination systems, modifying existing networks to integrate with the new sharing architectures, developing infrastructure and devices to implement the sharing, certifying equipment using new test procedures and equipment for compliance, and finally enforcing compliance. This process could easily take ten years or possibly even much longer. The FCC and the various industry participants undoubtedly will have many policy discussions about the pace at which specific types of spectrum sharing can move forward. For example, the President's Council of Advisors on Science and Technology (PCAST) appears to be more bullish than Mr. Rysavy about the advantages of moving to spectrum sharing. In a recent report, PCAST found that clearing and reallocating Federal spectrum is not sustainable because of the high cost, lengthy time to implement, and disruption to the federal mission. Instead, PCAST concluded \"that the norm for spectrum use should be sharing, not exclusivity.\" Whatever the outcome of those policy debates, there is widespread recognition that spectrum sharing will become increasingly important over time and that Congress should make sure that the statutory framework does not create obstacles to such sharing. Historically, the United States employed a command-and-control approach to spectrum management in which the FCC (and the National Telecommunications and Information Administration within the Department of Commerce for that portion of the spectrum allocated to government use) allocated blocks of spectrum to specific uses and then assigned channels within those blocks to specific licensees based on public interest criteria. Once allocated and assigned, spectrum could not readily be reallocated to a different use or reassigned to a different user. As a result, much spectrum has been underutilized or available only for a relatively low-value use.  In recent years, Congress has taken a number of steps intended to foster more efficient spectrum use. In particular, it has given the FCC authority in limited situations to implement market mechanisms, such as auctions and secondary spectrum markets, which could be expected to move spectrum to higher-valued uses. (A secondary market is a market for a good or service that has previously been purchased. Examples of secondary markets are the markets for financial stocks and bonds, used cars, and used books. What is exceptional about secondary markets for spectrum is that the licensee does not own the spectrum, but rather owns the right to use the spectrum, subject to various non-interference and other requirements. It is that right that is sold or leased in a secondary market) Setting a price on spectrum and allowing its transfer to higher valued uses increases incentives for licensees to use their spectrum efficiently\u2014for example, by employing spectrum-saving transmitting and receiving equipment or by making unused or underutilized spectrum available to others. Congress already has taken the following actions: The Omnibus Budget Reconciliation Act of 1993 ( P.L. 103-66 ) first authorized the FCC to establish \"competitive bidding systems\" for awarding spectrum licenses. This authority was extended in the Balanced Budget Act of 1997 ( P.L. 105-33 ), the Deficit Reduction Act of 2005 ( P.L. 109-171 ), and the DTV Delay Act ( P.L. 111-4 ). Title VI of the Middle Class Tax Relief and Job Creation Act of 2012 ( P.L. 112-96 ), often referred to as the Spectrum Act, contains provisions that reallocate certain spectrum, assign new spectrum rights, and change the procedures for \"repurposing\" spectrum used by the federal government to commercial use. It allows the FCC to establish an \"incentive auction\" through which licensees of certain spectrum currently used for broadcast television could voluntarily relinquish their spectrum in exchange for a portion of the proceeds generated by auctioning that spectrum to wireless broadband providers.  The FCC has used its spectrum management authority both to hold spectrum auctions and to foster secondary spectrum markets. In an initial order, it implemented two different options for spectrum leasing. One option enables licensees and lessees to enter into leasing arrangements, without the need for FCC approval, so long as the licensee retains de facto control of the leased spectrum under the newly refined standard. The other option permits parties to enter into arrangements in which the licensee transfers de facto control pursuant to streamlined approval procedures. In a second order, the FCC adopted additional streamlining procedures for certain categories of spectrum leases; adopted policies to facilitate advanced technologies within existing regulatory frameworks, including dynamic spectrum leasing arrangements; created a third option for spectrum leasing called \"private commons\" that permits peer-to-peer communications between devices in a non-hierarchical network arrangement that does not utilize the network infrastructure of the licensee; and streamlined the process for licensee assignments and transfer of control. Market mechanisms such as auctions and secondary markets are efficient to the extent that the private valuation of spectrum coincides with the overall societal valuation of spectrum. The private value of a particular block of spectrum typically will be highest for those providers that have established products or services that generate substantial revenues from the use of that spectrum. In most cases, the total value of the spectrum\u2014public and private\u2014will also be highest when the spectrum has been assigned to the producer of the most highly valued services, who likely could make the highest bid. There are several situations in which the public and private valuation may diverge, however, and these may require non-market allocation mechanisms.  Federal, state, and local public safety organizations and first responders need a reliable communications network, but may not have the funds to compete with commercial interests in spectrum auctions, especially since most organizations are not national in scope. To make sure that spectrum is available for public safety needs, either certain spectrum must be set aside for that purpose or some system of shared use must be established that in effect gives public safety preferred access\u2014and perhaps even exclusive access\u2014to the spectrum in times of emergency. This issue, including the creation of a public safety trust fund from auction revenues, was addressed in the Spectrum Act. Spectrum is essential for the development of new network and application technologies and services. Some of that research is performed by established firms using their own available licensed spectrum. But some is performed by start-up firms working on the technology frontier that do not have spectrum licenses and may not have the wherewithal to successfully bid against established firms for needed spectrum. Even established firms may not have licenses for spectrum with the characteristics needed to perform their research. To foster innovation, it may be beneficial to set aside some spectrum for experimental, unlicensed, shared use constrained only by specified non-interference criteria.  Incumbent providers may have an incentive to oppose the allocation of blocks of spectrum for unlicensed experimental use if such experimentation potentially could result in the development of new technologies that undermine their existing business model. But just as making sufficient spectrum available for the major wireless carriers to transition from 2G to 3G and then 4G networks was essential for the rapid deployment of networks capable of meeting the demands of consumers with smartphones and tablets, so was making sufficient spectrum available for experimentation and unlicensed services. As noted earlier, the wireless broadband ecosystem is strong today in large part because Wi-Fi was able to develop in the unlicensed spectrum block set aside for spread spectrum and other experimentation. The underlying cost structure of wireless broadband is characterized by significant economies of scale, such that there are likely to be few efficient network providers, perhaps only a single efficient provider in some rural areas, and no profitable provider in very rural areas. There are universal service and rural utilities service funds available to provide subsidies needed to ensure the availability of service, and the FCC has followed Congressional mandates to encourage spectrum license ownership for small, rural, or entrepreneurial businesses. But many small companies that have received licenses through preferential programs have later transferred their licenses to larger companies, and a number of small wireless carriers and their associations have submitted filings in recent FCC proceedings on the increasing difficulties they face competing for wireless customers. It is possible that the policy goal of ensuring a competitive alternative in certain rural areas will not prove feasible even with subsidies and preferences. Over time, spectrum can be repurposed from federal to commercial use or from one type of commercial use to another, or new spectrum-saving technologies can be developed and deployed, but at a point in time, the amount of available spectrum is fixed. There is a long history of concern that competition could be constrained if a few wireless providers control so much of the bands with superior propagation characteristics that other providers were effectively foreclosed from the market. The FCC first introduced a spectrum cap on mobile spectrum holdings in 1994 to promote diversity and competition in mobile services. In 2003, the FCC replaced the spectrum cap with case-by-case review of mobile spectrum holdings when making public interest determinations of transactions involving the transfer, assignment, or lease of licenses. Since 2004, the FCC has used a two-part screen to help identify markets where the acquisition of spectrum would provide particular reason for further competitive analysis. The first part of the screen considers changes in market concentration as a result of the transaction. The second part examines the amount of spectrum in each market that is suitable for the provision of mobile telephony/broadband service. Those markets highlighted in the analysis are subject to detailed reviews to determine whether the transaction would result in an increased possibility of anticompetitive conduct. In 2008, it extended the case-by-case analysis to spectrum acquired by auction. In 2012, the FCC opened a proceeding to review its spectrum screening process in light of the expansion in the number of spectrum bands used for mobile wireless service, and the roll-out of new service offerings, consumer devices, and bandwidth-intensive applications. In a submission in that proceeding, which coincided with a proceeding to develop rules for the upcoming incentive auction, the Department of Justice raised a concern that incumbent carriers that controlled a substantial portion of preferred spectrum might \"have incentives to acquire spectrum for purposes other than efficiently expanding their own capacity or services\" and that the \"foreclosure value\" of that spectrum might be greater than its \"use value,\" thus allowing the incumbents to outbid others for the spectrum. It concluded \"that rules that ensure that smaller nationwide networks, which currently lack substantial low-frequency spectrum, have an opportunity to acquire such spectrum could improve the competitive dynamic among nationwide carriers and benefit consumers.\" It therefore proposed that the FCC build into its auction rules a bright-line test, in the form of rules, weights, or caps that would reduce the risk of foreclosure. This proposed intervention into a market-based auction has been criticized by Verizon and AT&T and others. For example, a Phoenix Center report characterized it as an ill-founded attempt to direct spectrum to rivals of the leading firms in order to equalize competition among competitors, thus reverting from market allocation to agency selection of winners. Pricing mechanisms such as auctions and secondary markets help create market signals that improve the efficient allocation of resources such as spectrum. But pricing mechanisms are only useful if the market participants know in advance what rights they are getting\u2014especially with respect to protection from interference and permissible levels of interference creation\u2014when they bid for a spectrum license in an auction or seek to acquire or lease a spectrum license in a secondary market or consider using shared, unlicensed spectrum. In a market such as the one for spectrum, in which the actions of one participant may impose costs on other participants\u2014notably, spectrum use will create some level of electromagnetic interference that limits the usefulness of the spectrum or raises costs for other spectrum users\u2014market mechanisms will foster efficient spectrum usage only if the rules help create market signals that appropriately take into account the interference-related \"externality\" created. The extent to which spectrum use by one entity precludes its use by another entity is a function of the amount of interference created by that use and the ability of others to withstand that interference. All participants have a variety of parameters at their disposal to modify the impact of the interference. It generally is possible to develop transmitters that lower or otherwise mitigate the amount of interference created and also to develop receivers that mitigate the impact of interference, but both of these cost money and parties will prefer rules that place those costs on the other guy. It sometimes is possible for the parties to come together to jointly develop standards and equipment that mutually reduce the impact of interference so that the spectrum can be more intensively used, as was the case for the development of Wi-Fi and appears to be the case for the current development of network-centric technologies. But before these collaborations can begin, there must be some basic ground rules on the rights and responsibilities of participating entities, and the choice of these ground rules can foster or impede the efficient use of spectrum. Historically, those ground rules have applied to transmitters, but not to receivers. By rule, a licensee operating a transmitter in a particular spectrum frequency band is prohibited from allowing its signal to stray into an adjacent band and create interference to a receiver operating in that adjacent band. If the licensee is allowing this to happen, it would be ordered to discontinue transmission. In contrast, if the licensee's signal is not straying into an adjacent band, but receivers in that adjacent band are not sufficiently well-tuned to pick up only the signals from their own frequency band\u2014rather, they experience interference because they are picking up both the signals of the licensee in the adjacent band and the signals in their own frequency band\u2014there is no rule that would require the licensee to discontinue its transmission. Nor is there a rule requiring that a receiver only be able to receive signals from the intended frequency band.  In the past, it was not important that a receiver be selective in the signals it receives because there were few services operating near one another in the spectrum. But as demand for spectrum increases to meet demand for new wireless services, fewer frequency bands are remaining vacant. As a result, adjacent frequency channels are being assigned and utilized, and existing spectrum users (service providers and/or end users) with non-selective receivers increasingly pick up adjacent channel signals that are being transmitted according to rules, but nonetheless resulting in interference known as \"receiver overload\" or \"desensitization.\"  This is most likely to happen with mass market devices, such as GPS receivers, which both service providers and customers have strong incentives to make as inexpensive as possible. Inexpensive GPS devices may well lack filters that keep them from picking up signals from adjacent channels. In such cases, although the transmitter in the adjacent channel that is \"creating\" the interference for the unsophisticated GPS devices may be fully meeting the interference rules, there could be strong pressure to protect the sunk investments consumers have made in GPS receivers by constraining legal transmissions in the adjacent channel. This occurred in 2011, when testing of LightSquared's plan to offer terrestrial broadband service using a satellite band that is located next to the band used for GPS devices indicated that some GPS receivers were subject to interference even though the LightSquared signals were properly transmitted within the LightSquared frequency band. Because of this impact on GPS owners, the FCC ultimately did not approve LightSquared's proposal and that spectrum band has remained largely unused. More generally, the lack of rules that set requirements or incentives for receivers to be selective in the signals they pick up leads to valuable portions of the electromagnetic spectrum being kept out of service or only sparsely utilized. It also raises the cost of competitive entry. The absence of rules requiring (or, at the least, providing incentives for) receivers to be sufficiently selective that they do not pick up signals from adjacent frequency bands may encourage \"moral hazard.\" Moral hazard occurs when a party will have a tendency to take risks because it has reason to believe it will not bear the costs that might be incurred as a result of that risky behavior. In the absence of any receiver ground rules, a provider of a mass-market wireless service might attempt to attract customers by offering inexpensive receivers that do not block out signals from adjacent channels, confident that if another spectrum user sought to use the adjacent spectrum in a way that would create interference to the non-selective receivers, the FCC would protect those customers from interference, even if the new spectrum user was operating its transmitter within the rules. Since the costs associated with the risk of interference would fall on the new spectrum user, not the mass market wireless service provider, that service provider would have the incentive to undertake the risky behavior.  There is wide recognition that ground rules are needed for receivers, but there will be vigorous debate about the form those rules should take. Incumbent service providers and customers that have invested in receivers will seek to minimize the impact any rules will have on the status quo. In light of that, in its recent spectrum report, the President's Council of Advisors on Science and Technology proposed \"a receiver management framework that does not mandate additional costs on receivers but provides a framework for defining harmful interference and provides clarity on the requirements that a new entrant must meet to co-exist with legacy systems in adjacent bands.\" Rules that \"grandfather\" inefficient legacy spectrum use, however, may impose costs on future spectrum users.  The PCAST report indicated that some have claimed the FCC's authority to implement receiver rules is limited, and suggested that Congress might want to clarify the FCC's authority.  Technological innovation and efficiency are important public policy objectives, but there are other policy goals that may not always be consistent with innovation and efficiency. Two of these are likely to be part of the policy debate in any attempt to update the communications statutory framework\u2014budgetary considerations and fairness considerations that typically are raised in the context of grandfather clauses intended to protect certain parties from regulatory changes. Since market mechanisms generally allocate resources to their highest-valued use, spectrum auctions often yield both efficient resource allocation and substantial government revenues. But as discussed in the earlier section on spectrum management, some public policy objectives are not fostered by market mechanisms and can be better achieved by non-market allocations or by placing partial constraints on the market. These include the direct allocation of spectrum for public safety uses; the allocation of spectrum for experimentation, research, and development, typically by creating opportunities for innovators to have access to unlicensed spectrum; and placing constraints on how much spectrum any bidder can obtain through auction to protect against market foreclosure or to subsidize rural service providers. Statutes intended to foster each of these goals could reduce the potential contribution to the Treasury from spectrum auctions. Congress may want to provide guidance to the FCC on how best to weigh the tradeoffs between maximizing auction revenues and meeting these other public policy objectives. When proposals are made to change statutory or regulatory rules to better meet public policy goals, one associated cost may be the harm that would be suffered by existing providers or consumers who have made business model, investment, or purchasing decisions based on the old regulations. A frequent way to avoid such harm is to \"grandfather\" the old regulation for those legacy providers or customers. But if the proposed change would further a policy goal, then to the extent providers or consumers are excluded from the change, the public benefits from the change will be reduced. These grandfather clauses, some explicit, some implied, are common in communications statutes and regulations or in how agencies choose to construct new rules. For example: Many of the media ownership rules, such as the newspaper-broadcast cross ownership rule, grandfathered pre-existing cross ownership combinations. Similarly, when making public interest determinations about whether a licensee with a pre-existing combination could transfer that combination to a new entity, the FCC typically has continued to grandfather such combinations and make them permanent. Broadcast satellite carriers are allowed to retransmit the signals of distant television stations affiliated with a particular network to that subset of subscribers who are deemed \"unserved\" by any local affiliate of that network. But due to grandfather clauses, there are many situations in which the signal of a local station affiliated to that network is available to subscribers but they nonetheless continue to be considered unserved and are allowed to receive the distant signal. When the President's Council of Advisors on Science and Technology prepared its report on spectrum sharing, and proposed the implementation of receiver management requirements, it explicitly \"propose[d] a receiver management framework that does not mandate additional costs on receivers\" and \"recommend[ed] starting with the smallest plausible incremental step.\" In each of these cases, Congress, the FCC, or the Obama Administration chose to limit the reach of policy change (as expressed in statutory or regulatory change) in order to minimize harm to legacy market participants. As Congress considers future statutory changes, however, it is possible that in some situations the overall public interest calculus will not allow for such grandfathering."
}