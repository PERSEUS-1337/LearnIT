{
    "title": "RL34363",
    "content": "There are about 9,000 local election jurisdictions in the United States. In most states, they are counties or major cities, but in some New England and Upper Midwest states, they are small townships\u2014for example, more than 1,800 townships in Wisconsin. The number of registered voters and polling places in a jurisdiction also varies greatly. The average reported was 40,000 voters, ranging from fewer than 100 to more than 1 million, and 32 polling places, ranging from 0 to almost 1,000, with 16% of jurisdictions having only one and 14% more than 50. The number of election personnel working in a jurisdiction, in addition to the local election official, also varied greatly, from none to more than 10,000. Given such diversity and other differences among states\u2014such as wealth, population, and the role of state election officials\u2014responsibilities and characteristics of LEOs are likely to vary greatly. Nevertheless, some patterns emerged from the survey. According to the survey results, the typical LEO is a white woman between 50 and 60 years old who is a high school graduate. She was elected to her current office, works full-time in election administration, has been in the profession for about 10 years, and earns under $50,000 per year. She belongs to a state-level professional organization but not a national one, and she believes that her training as an election official has been good to excellent. As with any such description, the one above does not capture the diversity within the community surveyed: About one-quarter of LEOs are men, about 5% belong to minority groups, 40% are college graduates, and 8% have graduate degrees (see Table 1 ). They range from 21 to more than 80 years of age, and have served from 1 to 45 years. About one-third were appointed rather than elected to their posts. Reported salaries range from under $10,000 to more than $120,000. About three-quarters belong to at least one professional organization. The demographic profile of LEOs is unusual, especially for a professional group. They differ from those of other local government employees. For example, according to U.S. Census figures, while women comprise a higher proportion of the local government workforce than men overall, men comprise a higher proportion of local government general and administrative managers. About 20% of those managers are members of minorities. The patterns do not appear to be a result of the fact that most LEOs are elected, as the demographic characteristics of legislators appear to be largely similar to those for local government managers. The average tenure in the current position declined by about one year from 2004 to 2006, with the proportion of LEOs who had served for two years or less in their current positions rising to 15% in 2006 from 11% in 2004 (see Figure 1 ). Thus, there appeared to be a small increase in job turnover between the two elections. However, there was no significant change in average age ( Figure 2 ). The survey was not designed to identify the causes of such changes, but they appear to be consistent with the impacts of federal and state election reform on local jurisdictions. That reform led to increased funding for election administration, changes in voting systems used by many jurisdictions, and an increased workload for election officials. For example, the survey found that those who reported that they worked full-time on election administration increased from 66% in 2004 to 76% in 2006, while those who reported that they spent more than twenty hours per week on election duties increased from 41% to 47%. The increasing complexity of elections and the increased federal role after the passage of HAVA have focused more attention on the role of professionalism in election administration. Given that change, it might be expected that election officials who began serving more recently would have more formal education than those who have served for longer periods. Such a pattern could yield a statistical association between the highest education level attained and the number of years in service as an election official. In fact, there was a small but significant relationship, with LEOs who did not have a college degree averaging 11-12 years of service and those with graduate degrees averaging 9 years. However, there was no significant change in the distribution of maximum education level between the 2004 and 2006 surveys ( Figure 3 ). The survey also examined other factors related to election administration as a profession. About three-quarters of LEOs belonged to at least one professional association. About 40% of those belonged to a national or international association, with 60% belonging only to a state or regional association (see Figure 4 ). Those results did not change significantly from 2004 to 2006. In 2006, the percentage of LEOs reporting that they had a written job description was 43% for those who had been elected and 70% for those who had been appointed. Most LEOs reported a broad range of election-administration responsibilities beyond solely running elections. Most are also responsible for budgeting, personnel, and purchasing, for example ( Table 2 ). Most LEOs received some initial training specifically designed to prepare them for their duties, but for most that training was less than 20 hours, and only one-fifth of LEOs were required to pass an examination ( Table 3 ). Most have also received additional training. More than two-thirds of LEOs assessed that their training was good to excellent and resulted in moderate to substantial improvement in their effectiveness and ability to solve problems. More than four-fifths believe that training and experience are equally important in ensuring a successful election. This result, shown in Figure 5 , might reflect the impact of HAVA requirements, most of which went into effect in 2006. For example, election officials might have felt less well prepared by their training to implement HAVA in 2006 than in 2004, but the survey did not address that possibility. Other possible factors include increasing public attention to problems in election administration, and recent controversies about the reliability and security of voting systems. Two-fifths of respondents to the 2006 survey commented on additional training needs. The most common suggestions were for more training in technical and legal aspects of elections, and more \"hands-on\" training. Given the increasing role of technology in elections, both surveys asked LEOs questions about their attitudes toward technology ( Figure 6 ). Respondents believed that technology can be useful for government services, but were cautious about implementation. They were only slightly positive on average about whether the benefits outweigh the risks. They held those views somewhat more strongly in 2006 than in 2004. Respondents reported that the percentage of jurisdictions using lever machines, punchcards, hand-counted paper ballots, and central-count optical scan (CCOS) as their primary voting system decreased substantially, while the percentage using PCOS and DREs increased (see Figure 7 ). These changes are consistent with results from other sources. The trends conform with expectations arising from HAVA requirements that emphasized improved usability and accessibility of voting systems for voters. The average length of time jurisdictions have been using a particular kind of voting system varies greatly with the kind of system ( Figure 8 ). The average length of use varies with the length of time a voting system has been available for use. At one extreme, jurisdictions with hand-counted paper ballots have used them for 80 years, on average. At the other, jurisdictions with DREs have had them under 10 years on average. The pattern of use shown in Figure 8 suggests that jurisdictions do not readily change the kinds of voting systems they use. On the one hand, such reluctance to change creates stability that may be beneficial to voters and administrators. On the other hand, it may mean that a particular kind of technology is used far longer than it should be, with increasing risks of negative consequences. For example, many of the problems associated with the 2000 presidential election were attributed to the continued use of outmoded or flawed technology, such as the punchcard systems in use at the time. The causes of such long-term use patterns are complex and may include factors such as legal and budgetary constraints and various forms of transaction costs that would be incurred with any change. Such factors, if they continue to be important, may impede jurisdictions from taking advantage of the kinds of improvements that are likely to occur in voting technology over the next decade. Most LEOs play a role in decisions on what voting systems to use in their jurisdictions (see Table 2 above). Many other stakeholders may also influence those decisions. To help provide an understanding of how LEOs assess the appropriateness of the roles other stakeholders play, the survey asked respondents to what extent they agreed or disagreed with statements about the influence of those stakeholders on the decision-making process. Two examples are \"The federal government has too great an influence,\" and \"Local level, elected officials should have greater influence.\" The results are presented in Figure 9 . On average, in fact, LEOs felt more strongly about the role of local elected officials than any other stakeholder. LEOs were largely neutral about the level of influence of state election officials and the public, and did not believe that nonelected officials, professional associations, and independent experts should have greater influence than they do now. Some of the differences between the 2004 and 2006 results are notable. In 2004, LEOs were largely neutral about the influence of the media, political parties, and various advocacy groups. In 2006, they thought those groups had too much influence. They also agreed more strongly than in 2004 that elected local officials should have more influence. Also, in 2006 more LEOs believed that vendors have too great an influence than in 2004, and fewer believed that the public and independent experts should have greater influence. Their views did not change on the roles of the federal government, elected state officials, professional associations, and nonelected state and local officials. Overall, the observed patterns of response are not surprising. LEOs generally either report to elected local officials or are elected themselves. The concerns of local officials about the influence of the federal government are well-known in many areas, not just election administration, and many may have resented the HAVA requirements that led to changes in long-used voting systems. Also, it is not surprising that LEOs have become more concerned about the roles of stakeholders such as the media, advocates, and political partisans, who are closely associated with the recent controversies about the reliability and security of voting systems. There has also been debate and uncertainty specifically about the role and influence of voting system manufacturers and vendors in the selection of voting systems by local jurisdictions. Some observers have argued that vendors have undue influence in what voting systems jurisdictions choose. Others believe that such concerns are unwarranted. But little has been known previously of how LEOs view vendors and their relationships with them. The results of the 2004 survey were mixed with respect to the importance of vendors. (These questions were not included in the 2006 survey.) LEOs in 2004 appeared to have high trust and confidence in vendors but did not rate them as being especially influential with respect to decisions about voting systems. Fewer than 10% believed that there was insufficient oversight of vendors by the federal government and states, but about one in six believed that local governments did not exercise enough oversight. Most jurisdictions using computer-assisted voting reported in 2004 that they had interacted with their voting-system vendors within the last four years. More than 90% of LEOs considered their voting system vendors responsive and the quality of their goods and services to be high. They felt equally strongly that the recommendations of those vendors could be trusted. However, about a fifth of respondents thought that vendors were willing to sacrifice security for greater profit, although 60% disagreed. Also, a quarter felt that vendors provide too many elements of election administration. When LEOs were asked in 2004 what sources of information they relied on with respect to voting systems, state election officials received the highest average rating, with about three-quarters of LEOs indicating that they rely on state officials a great deal. Next most important were other election officials, followed by the EAC and advocates for the disabled. About one-third of LEOs stated that they relied on vendors a great deal, a level similar to that for professional associations. Only 2% of LEOs rated vendors higher than any other source, whereas 20% rated state officials highest. Interest groups were rated lower than vendors, and political parties and media received the lowest ratings. When LEOs were asked in 2004 about the amount of influence different actors had on decisions about voting systems, the overall pattern of response was similar to that for information sources. Once again, state, local, and federal officials were judged the most influential, and political parties and the media the least, with vendors in between. An exception was that local nonelected officials were considered less influential on average than vendors. Both voters and advocates for the disabled were rated as more influential on average than vendors. No LEOs rated vendors as more influential than any other source. Those results contrast with the views of LEOs described above about whether the levels of influence of stakeholders are too little or too great ( Figure 9 ). Of the three actors considered most influential, LEOs believed that local elected officials should have more influence and the federal government has too much, and they were neutral about state officials. They did not believe on average that those considered least influential should have more. Congress may find it useful to take these attitudes into account in conducting oversight of HAVA implementation and in considering additional election-reform legislation. LEOs had strong opinions about the different kinds of voting systems used in the United States. Those whose jurisdiction used a particular kind of system, whatever it was, supported its use more strongly than any other system (see Figure 10 ). Thus, users of lever machines strongly supported their use, showed some support for the use of DREs, were neutral about optical scan systems, and were opposed to the use of punchcard and hand-counted paper ballot systems. In general, except for those using them, LEOs opposed the use of lever machines, punchcard systems, and paper ballots. Those views changed little across the two surveys. However, there was a slight but significant decrease in the level of support for DREs among users of optical scan and DRE systems. DREs were the only voting system for which support of users dropped between 2004 and 2006, although it still remained very high. It was not possible to determine if the change in support for users of DREs resulted from changes in the views of long-time users or from lower initial support among those who used DREs for the first time in the 2006 election. Overall, and consistent with the above results, LEOs reported a high level of satisfaction with their voting systems and assessed that they performed very well during the most recent election. On a scale of 1-10, average ratings were 8 or higher for each of those questions in both surveys ( Figure 11 ). However, ratings for satisfaction with and performance of optical scan and DRE systems were significantly lower in 2006. Ratings for performance were also lower for paper systems. There was no difference in ratings between years for lever machines in satisfaction or performance. LEOs who used DREs and precinct-count optical scan systems were more satisfied with them in 2004 than LEOs who used lever machines, paper ballots, or central-count optical scan, but in 2006, there were no significant differences in satisfaction among users of different voting systems. However, users of PCOS systems were slightly more satisfied overall than users of either CCOS or DRE systems. There were also no significant differences in rated performance of different voting systems in either 2004 or 2006, despite the striking difference between the two years. To assess more directly how LEOs rated their own voting systems in 2006, they were asked whether their current system is the best available, and what voting system they believed is best overall. Almost 80% agreed with the statement that their current voting system is the best available, although the level of agreement was somewhat higher among optical scan and DRE users ( Figure 12 ). The same percentage believed that their current voting system is the best overall, with a significantly higher percentage of PCOS users holding that view than users of other systems. To further assess voting system preferences, both surveys asked LEOs to assess their primary voting systems on fifteen specific characteristics ( Figure 13 ). The high ratings for accuracy, security, reliability, and usability changed little from 2004 to 2006. For other characteristics, there were substantial differences both among voting systems and between the two surveys. For most of those, LEOs were less happy with performance in 2006 than 2004, especially with respect to optical scan and DRE systems, which they rated lower for cost, size, storage requirements, and machine error in 2006 than 2004. Ratings for usability were also slightly lower, but those for multilingual capacity were higher. Optical scan systems, both central- and precinct-count, were rated higher for accessibility in 2006 than in 2004. The reasons for this change are not clear. All systems were rated lower for machine and voter error in 2006\u2014LEOs switched from positive to fairly neutral about these performance characteristics. It was not surprising that DREs received the highest ratings of any system for accessibility and ability for use in multiple languages, or that hand-counted paper ballots were rated lowest for counting speed. Some of the comparisons among voting systems, however, did yield surprising results. The ratings for reliability, security, accuracy, and ease of use by voters were very high and were similar for all voting systems. Given media reports about problems with the reliability and security of electronic voting, somewhat different outcomes might have been expected\u2014namely, that DREs would have been rated lower in reliability and security. Also, given that modern DREs are often described as more voter-friendly than other systems, and certainly have the capability of providing higher levels of usability than other types, the lack of difference in ratings for usability is somewhat surprising. With respect to accuracy, a lower rating might have been expected for punchcards, given the difficulties with recounts that were prominent during the 2000 presidential election. It is possible that such confidence exists because few jurisdictions use punch cards now, and those that do have them declined to replace them after 2000. Those jurisdictions kept the system despite intense negative media coverage of system limitations and opted not to take part in the punchcard buyout program offered through the Help America Vote Act. The relative lack of difference in ratings of optical scan and DRE systems for acquisition and maintenance costs, and size and storage requirements, appears to run counter to widely held views. Many observers regard DREs as the most expensive voting systems, given that several machines may be needed for each polling place, whereas optical scan systems usually require one machine per polling place (PCOS) or none (CCOS). These differences from expectation suggest that LEOs' perceptions of how their voting systems perform may differ substantially in some ways from public perceptions about those systems. If the perceptions of election officials are accurate, then several of the criticisms leveled at specific voting systems could lead, if acted upon, to unnecessary and even counterproductive regulation and expenditure. For example, if in fact there is little difference in security between an optical scan system and a DRE, then requirements for paper trails may be unnecessary. If, however, LEOs' perceptions are inaccurate, then understanding and addressing the causes of those inaccuracies may be beneficial. Much of the recent controversy about election reform has focused on electronic voting systems. Questions about the security and reliability of those systems were a relatively minor issue until 2003. Two factors led to a sharp increase in public concerns about them: (1) HAVA promoted the use of both PCOS and DREs through its provisions on preventing voter error and making voting systems accessible to persons with disabilities; and (2) the security vulnerabilities of electronic voting systems, especially DREs, were widely publicized as the result of several studies released in 2003. Both surveys asked several questions designed to elicit the views of LEOs about aspects of that controversy. When asked whether current federal and state guidelines and standards about electronic voting systems (both optical scan and DRE systems) are strict enough, most LEOs, about 60%, replied in the affirmative. Those who did not were fairly evenly split among officials who believed that the current standards are too strict and those who believed they are not strict enough. There was no significant difference in average assessment between users and nonusers of electronic voting systems, but nonusers were slightly more likely to believe that the standards are either too strict or not strict enough ( Figure 14 ). In both surveys, LEOs were asked to what extent they agreed with several statements about DRE and optical scan systems. In 2004 those questions were asked of all LEOs, but in 2006 they were asked only of those who used DREs and optical scan as their primary voting systems. Also, two questions asked in 2004 were not asked in 2006 (See Figures 15 and 16 ). Not surprisingly, the opinions of nonusers of either kind of system were generally less strong than those of users. Nonusers were neutral on average with respect to several statements about DREs, including their level of knowledge about the systems, vulnerabilities to tampering, and the need for more public trust. LEOs whose primary voting systems were precinct-count optical scan were more neutral about DREs than were users of other voting systems. Users of DREs, in contrast, generally agreed that they had sufficient knowledge about the voting system, that certification procedures were adequate, that DREs are not vulnerable to tampering and security concerns can be addressed with good procedures, that the public should have greater trust in DREs, and that the media report too many criticisms of that voting system. Those views were similar in both surveys. Nonusers were less neutral about optical scan (OS) systems, but users nevertheless held stronger views than nonusers about these systems, except for the statement about media criticism, about which both users and nonusers were neutral on average. LEOs whose primary voting systems were DREs were less neutral about OS systems than users of other voting systems. The controversy about the security and reliability of DREs has led to widespread calls for the adoption of a paper trail of the ballot choices that a voter can verify before casting the ballot. These paper trails, printed as separate ballot records that the voter can examine, are usually called voter-verified paper audit trails, or VVPAT. LEOs whose primary voting system is a DRE were asked several questions in both surveys about VVPAT. The percentage who used them doubled to 36% in 2006, from 18% in 2004 . About one-third of LEOs whose jurisdictions used DREs as their primary voting system stated that voters who did not wish to use a DRE had the option of using a paper ballot instead. However, it was not possible to determine which of those jurisdictions permitted that choice in the polling place rather than through the use of \"no excuse\" absentee balloting. In the 2006 survey, only DRE users were asked if VVPAT should be required. However, in the 2004 survey, both users and nonusers were asked. Among DRE users, only 14% supported such a requirement, whereas among nonusers 68% did ( Figure 17 ). In 2004, 47% of respondents strongly disagreed, and only 5% strongly agreed that DREs should produce a VVPAT, while in 2006 the numbers were 36% strongly disagreeing and 12% strongly agreeing ( Figure 18 ). In 2006, LEOs were also asked if they would be willing to use a VVPAT if reimbursed for the costs by the federal government, and 57% answered in the affirmative. However, even those respondents (DRE users and nonusers) who expressed support for VVPAT were generally willing (65%) to spend only $300 or less for the feature. LEOs were asked to choose one or more of several reasons for disagreeing or agreeing that DREs should produce a VVPAT ( Figure 19 ). The most frequent reasons chosen were the risk of printer failure, the complexity of implementation, and risks to voter privacy. Among the choices available in both surveys, LEOs were more concerned in 2006 about costs and the risk of printer failure, and less concerned about the risk of tampering with the VVPAT. About three-quarters of LEOs who used a VVPAT were somewhat to very satisfied with it. However, about one-fifth were dissatisfied. More than four-fifths of LEOs had confidence in their accuracy, with fewer than one-tenth expressing concerns. More than two-thirds thought that voters reacted positively to them, but about one-quarter thought that voters were neutral ( Figure 20 ). Most LEOs, about 90%, considered themselves familiar with and knowledgeable about HAVA's requirements in both surveys. The level of familiarity increased from 2004, when about 20% considered themselves \"very familiar\" with the law, to 2006, with almost 40% very familiar. Those who were \"not familiar at all\" with HAVA decreased from 4% in 2004 to 0.1% in 2006. About 90% of respondents believed that almost all jurisdictions in their state were in full compliance with HAVA provisions in 2006. However, more LEOs believed that the law resulted in no improvements than in major improvements, and the level of support was lower in 2006 than in 2004 ( Figure 21 ). Most LEOs regarded the major provisions of HAVA as advantageous, although the level of support varied both among the provisions and between the two surveys. LEOs were most supportive of federal funding and least supportive of the requirement for provisional voting and the creation of the Election Assistance Commission ( Figure 22 ). However, provisional voting received substantially higher negative ratings than any other provision in both surveys ( Table 4 ). While remaining positive overall, the level of support declined for all provisions except the voter registration and identification requirements, which were unchanged, and provisional voting, where support in 2006 was higher than in 2004. This was the only provision for which the percentage of negative ratings declined between the two surveys. The steepest decline in support was for the state matching-fund requirement. The decline in support for HAVA from 2004 did not result from a change in the perceived difficulty of implementation. In general, LEOs reported in both surveys that implementation of HAVA provisions was moderately difficult ( Figure 23 ). The level of difficulty declined for all but two provisions: The assessed level of difficulty increased for the process for certification of voting systems, and there was no significant change in perception about the difficulty of implementing provisions to facilitate participation by military and overseas voters. The comparatively large drop in support for the state matching-fund requirement suggests that the decrease in support for HAVA provisions overall in 2006 may have resulted in part from perceptions about costs and funding. Their importance is also supported by the responses to three questions in the 2006 survey: How has HAVA affected the cost of elections in your jurisdiction? To what degree is the funding your jurisdiction has received to implement HAVA requirements sufficient for their implementation? How concerned are you that limited funding in the future will leave you unable to comply with HAVA requirements for election administration? The results are presented in Figure 24 . About 90% of respondents believed that HAVA has increased the cost of elections, and only 2% believe the costs have decreased. LEOs were fairly evenly divided on whether current funding is sufficient to implement the requirements, but most expressed concerns about the sufficiency of future funding, with 30% stating that they were \"extremely concerned.\" LEOs were also asked in 2006 to respond to a set of statements about the impacts of HAVA ( Figure 25 ). While agreeing on average that HAVA has made elections more accessible for voters, they disagreed that the law has made elections fairer or more reliable. They did not believe that HAVA requirements are inconsistent with state requirements, but they strongly believed that the law has made elections more complex to administer. As Table 5 shows, with the exception of the statement on complexity of elections, responses were fairly evenly distributed, with about one-quarter to one-third of respondents expressing a neutral position. When HAVA created the Election Assistance Commission, the law gave it several specific responsibilities. The EAC carries out grant programs, provides for voluntary testing and certification of voting systems, studies election issues, and issues voluntary guidelines for voting systems and guidance for the requirements in the act. The EAC has no rule-making authority (other than very limited authority under the National Voter Registration Act, the \"motor-voter\" law, P.L. 103-31 ) and does not enforce HAVA requirements. In the 2006 survey, LEOs were asked about the EAC's responsibilities, helpfulness, and benefits. They were asked to rank the importance of the following four EAC responsibilities: Provide guidance to local election officials, Research issues related to election administration, Certify voting systems, and Ensure that local jurisdictions are in compliance with federal law. The results are presented in Figure 26 . LEOs regarded guidance to them as the most important of the listed responsibilities and ensuring compliance by them as the least. Research and certification were rated in the middle and the ratings for them did not differ significantly. However, more than 60% of LEOs reported that the EAC had not helped them understand or perform their duties during the preceding year. About 6% found the EAC to be \"extremely helpful\" to them overall ( Figure 27 ), whereas 13% found the agency \"not helpful at all.\" LEOs were also asked how they had benefitted from the four functions listed above plus the distribution of federal funds for use by local jurisdictions. The ratings ( Figure 28 ) generally reflect the pattern seen in the responses on overall helpfulness. On average, LEOs responded that they had benefitted only moderately overall. However, while they considered guidance as the most important responsibility, they rated it lowest in benefit, along with compliance, which they regarded as the least important responsibility. About a quarter rated EAC guidance as \"not beneficial at all,\" with about 7% rating it \"extremely beneficial.\" Perceived benefits from research and certification were somewhat higher, and funding, not surprisingly, was rated highest. The discrepancy in the ratings for EAC guidance have several possible explanations. For example, it could reflect frustration with the delays in start-up of the EAC and consequently in the issuance of guidance. It could reflect difficulties in understanding the guidance that was issued. It might reflect the fact that the purpose of the guidance is to assist states, not local jurisdictions, in meeting the title III requirements (\u00a7311(a)). Or it could simply be an expression of opposition to or uncertainty about the requirements themselves. Individual comments from LEOs suggest a diversity of views: - A clear and concise plan needs to be formulated as to what the EAC must do and definite timelines attached to the responsibilities. - Rating this committee is somewhat unfair; once finally appointed, funding was delayed; they really haven't had an opportunity to function in the capacity anticipated. - All I have received from them have been brochures that come too close to an election to be of any real use. - The EAC's information on their website can be very helpful. - At the local level we only deal with the Secretary of State and not with the EAC. - EAC commissioners and staff are very well aware of their situation and environment. I work closely with them on a regular basis and know they are doing the best they can, as a federal agency with no enforcement powers\u2026. - Exempt cities or other entities with less than 2,000 voters from the very expensive HAVA equipment requirements. - Get rid of it. Elections\u2026should be free of federal control. - I believe they need more power to correct election problems. HAVA required each state to implement a statewide, computerized voter registration list before the 2006 election. A few states were unable to meet that deadline, and that is reflected in the survey, with 6% of respondents indicating that their states had not yet met the requirement. Most LEOs were familiar with their state's database, with about a third assessing themselves as \"very familiar.\" Given the concerns expressed in the first survey about the burdens of HAVA implementation, the second survey asked LEOs whether the implementation of the computerized list had required the hiring of additional staff in the local jurisdiction. Four-fifths responded that it had not. Those that did hire additional staff were asked to identify all sources of funds. More than three-quarters received funding from local governments ( Figure 29 ), with about 70% receiving only local funding. To explore perceptions about the effectiveness of the computerized statewide voter registration database, LEOs were asked about security, contingency plans in case of failure on election day, and agreement or disagreement with a series of statements. Respondents were very confident about both security and contingency plans. The responses to the statements ( Figure 30 ), however, appear to conflict with the responses to the question on security, in that most LEOs agreed that an unauthorized person could remove the register from the polling station and access the database, although they were neutral about the risk of identity theft. LEOs also expressed concerns about matching drivers' licenses and Social Security numbers, and the difficulty of updating records in the new system, but they did not believe that the system places a heavy burden on local governments overall. They were neutral about whether the new systems would improve the election process. Issues relating to voter identification have been controversial. HAVA requires that first-time voters who register by mail must present a specified form of identification, either when registering or when voting. It does not require photo identification, although a few states have such requirements, and many states require some form of identification document. The kinds of identification accepted for all voters to register and to vote, as reported by respondents, is shown in Table 6 . About one quarter of LEOs reported no identification requirement whatsoever, and about one-third stated that signature comparison or personal information was sufficient. One of the principal policy arguments for tightening voter-identification requirements is concern about the risk of significant levels of voting by ineligible voters. Opponents counter that those risks are small and that requiring identification, especially photo IDs, would effectively disenfranchise eligible voters who would have difficulty obtaining such documents. To help determine the views of LEOs about this issue, the 2006 survey asked several additional questions about voter identification: As a local election official, how supportive are you of requiring all voters in your jurisdiction to provide valid photo identification? How often do non-eligible persons attempt to vote in your jurisdiction, either in person or by absentee ballot? Do you agree or disagree that deliberate voter fraud is a serious problem in your jurisdiction? Do you believe that requiring photo identification of all voters would make elections more secure, less secure, or have no impact on election security? Do you believe that asking for photo identification of all voters would increase turnout, decrease turnout, or have no impact on turnout? The results are presented in Figure 31 . On average, LEOs mildly supported a requirement for photo identification. However, 29% of respondents chose \"extremely supportive,\" 12% \"do not support at all,\" and the choices of the other 60% were spread across the scale of possible responses. Two-thirds also believed that requiring such identification will make elections more secure. These views do not, however, appear to be based on concerns about ineligible voters or voter fraud, which few believe are problems in their jurisdictions. In addition, 41% believe that requiring photo IDs would depress turnout, while 56%, almost all the rest, believe it would have no impact. The causes of this apparent discrepancy are unclear. It is possible that however low the risk of fraud, LEOs believe reducing it outweighs any negative impact on turnout. There might also be other reasons that the survey did not explore. In any case, the range of perspectives in the responses to the questions shows that the controversy is not settled, even among local election officials. The 2006 election was the first under which all HAVA requirements were in effect. Consistent with the perception of LEOs that HAVA has made elections more complex to administer ( Figure 24 ), three-quarters found that they spent more time preparing for the 2006 than the 2004 election, with 40% spending much more time. This perception was supported by comparing the number of hours per week LEOs reported spending on election duties in the 2004 and 2006 surveys. On average, the time spent increased 15%, from 21 to 24 hours. In 2006, LEOs also stated that they worked an additional 20 hours per week in the month before the election. This difference may be especially significant given that 2006 was not a presidential election year, with the additional work required for that contest. In addition, there were prominent issues of concern in 2006 such as voting-system malfunctions and problems with pollworkers, vendors, long lines, media coverage, and timely and accurate reporting of results. The survey therefore presented a list of 16 potential problems and other events and asked LEOs to indicate which, if any, had occurred. The results are presented in Table 7 and Figure 32 . Not surprisingly, this was most commonly reported by LEOs using DREs as the primary voting system ( Figure 32 ), but the differences were relatively small. Among DRE users, 53% reported that at least one repairable malfunction occurred, and 12% that at least one malfunction occurred that could not be repaired. More such machines would be used on average in jurisdictions where DREs are the primary voting system (as opposed to those where only one is used per polling place to meet the HAVA accessibility requirement). Therefore, the chance of at least one malfunction would be expected to be higher on average than in jurisdictions using another kind of primary system, such as precinct-count optical scan, where typically only one OS machine is used in a precinct. However, if DREs had lower failure rates per machine than optical scan systems, the difference would be correspondingly lower. In fact, the incidence of such occurrences was almost equally as high for users of both precinct- and central-count optical scan systems (47% and 36%, respectively, for repairable malfunctions, and 12% and 15% for unrepairable ones) as their primary systems. In comparison, the reported failure rates in jurisdictions using lever machines and paper ballots was much lower (9% and 10% for repairable malfunctions, and 5% and 6% for unrepairable ones). About one in seven users of optical scan and DREs as their primary systems were disappointed in the level of support provided by vendors. Those LEOs were twice as likely to have experienced unrepairable malfunctions of their voting systems as LEOs who were not disappointed with vendor support. The results suggest that current optical scan systems may not be significantly more reliable than DREs. They also contrast strikingly with the uniformly high ratings all users gave for the reliability of their voting systems (see Figure 13 above). LEOs did not appear to assess the malfunctions as being the result of tampering. In fact, only one reported a system being hacked, and that was a precinct-count optical scan user. Another notable result was the fairly high incidence of LEOs, 12%, who reported excessively long lines at the polling place. The prevalence was much higher in jurisdictions using DREs primarily, occurring in about one quarter. In those using other kinds of voting systems, long lines occurred in only about 6% ( Figure 32 ). Jurisdictions using DREs also reported more unfair media coverage (19%) than users of other systems (6% on average). The incidence of problems with accurate and timely reporting of election results was low and did not differ among users of the different kinds of voting systems. Reports of deliberate election fraud of any kind were also few\u20148 LEOs, one out of every 170 jurisdictions or 0.75%. Such a low rate might nevertheless be considered unacceptably high, depending on such factors as the seriousness of the offense, the impact of such attempts at fraud on the election, and the degree to which election officials are able to detect all such attempts. LEOs noticed no change on average in residual votes (overvotes plus undervotes plus spoiled ballots) from 2004 to 2006. About 60% reported no change, and about 20% each reported an increase or a decrease. This result suggests that the decreased confidence LEOs had in 2006 in the ability of voting systems to reduce voter error was not a result of a noticeable increase in such error. Alternatively, the decrease in confidence might have resulted from sources such as changes in media coverage of voting-system problems. The number of provisional ballots used varied greatly among jurisdictions in 2006. About 30% of that variability is explainable by the number of voters in the jurisdiction. Thus, jurisdictions with fewer than 1,000 registered voters used about 10 provisional ballots on average and those with more than 100,000 voters used 1,500. Across all jurisdictions, one provisional ballot was used for every 140 registered voters on average. About a quarter of jurisdictions, mostly small, used no provisional ballots, and about 4% used more than 1,000, with a maximum of 15,000 in a jurisdiction with about half a million voters. When asked whether these ballots were easier to use than in 2004, about three-quarters of LEOs reported no change, but more found them easier (16%) than harder (9%) to use in 2006. Three-quarters of jurisdictions used optical scan systems for absentee ballots, and most of the rest used hand-counted paper ballots. More than half of respondents indicated that their jurisdictions offered early voting. About a third each of those offering it used optical scan, a third DREs, and under 10% hand-counted paper ballots. The rate of absentee voting has been increasing nationally over the last several elections, as the number of states offering early and \"no excuse\" absentee voting has increased. The survey asked LEOs to provide information on the percentage of all votes cast by absentee voting in 2006. On average, respondents reported that about 14% of votes were cast by absentee ballot, with 1-5% being most commonly reported ( Figure 33 ). The average rate is very similar to the one reported in the EAC's election day survey (14.2%). Some observers have expressed concerns about early and \"no excuse\" absentee voting, arguing, among other things, that they do not increase turnout and pose some security risks. These concerns were largely not shared by LEOs ( Figure 34 ). Three-quarters agreed that absentee voting should be considered a voter's right, and more than half that early voting should be. Three-quarters also agreed that absentee voting is worth the costs, and that verification of authenticity is not difficult for those ballots. However, they were equivocal about whether early voting is worth the costs. Both absentee and early voting reduce the pressures of election day administration; it is possible that election officials support absentee voting over early voting because it is easier to administer in the pre-election period. About 10% of jurisdictions experienced one or more instances of pollworkers not reporting for duty. Since the average jurisdiction used more than 150 pollworkers, the impact may be small on average (although not in the affected polling places). Nevertheless, absenteeism among pollworkers has been cited as a significant problem on election day. Factors that might contribute include long hours, low pay, poor training, and age, but analysis of pay and training data from the survey did not point to those factors as being significant. More than 20% of LEOs reported instances of pollworkers who did not understand their jobs. The lowest rate, 5%, was in jurisdictions using hand-counted paper ballots. Results from LEOs using other kinds of voting systems ranged from 17-25%, but those differences were not statistically significant. It seems unlikely that the differences between the results for paper and those for other voting systems arose purely from differences in the roles of technology in the different voting systems, since the technology-related tasks of pollworkers in jurisdictions using central-count optical scan are unlikely to be much greater than those in jurisdictions using hand-counted paper ballots. There are several other possible factors. For example, the average total number of pollworkers, polling places, and registered voters reported by LEOs is far lower for jurisdictions using hand-counted paper than for any other voting system (see Figure 35 in the next section). The 2006 survey included several questions about pollworkers. All but 3% of LEOs reported using one or more pollworkers, with a mean number of 164 in a jurisdiction and a maximum of 4,000. The number of pollworkers in the jurisdictions was strongly correlated with the number of registered voters reported, as was the total number of polling places. The kind of voting system used also varied with the number of registered voters. Overall, jurisdictions using hand-counted paper ballots had the smallest number of registered voters, polling places, and pollworkers, and those using DREs and lever machines the highest ( Figure 35 ). On average, there were 5-6 pollworkers per polling place. Jurisdictions using paper ballots had the highest average number, and those using lever machines the lowest. Compensation of pollworkers also varied substantially. About 60% of respondents reported paying them a lump-sum amount for work on election day, $100 on average. The remainder of respondents reported an hourly wage of $7.25 on average. Very few respondents reported paying nothing to pollworkers, and few likewise reported paying more than $200 per day or $12 per hour. The results suggest that there is some regional variation. For example, the average rate of pay by state varied in New England from $50 to $106 per day, and in the West from $70 to $155. While LEOs who reported problems with pollworker performance paid them $5-10 less per day on average, the effect of pay on performance was not statistically significant. However, the survey did not explore potentially influential demographic factors such as age of pollworkers or average cost of living. Perhaps more surprisingly, the amount of training pollworkers received was also not associated statistically with reports of performance problems. However, more LEOs than not believed that inadequate training was responsible for problems with election administration, and most believed that training needs significant improvement ( Figures 36 and 37 ). Not surprisingly, those views were strongly correlated: LEOs who believed more strongly that inadequate training caused problems also tended to believe more strongly that improvements in training were needed . On average, pollworkers received 3.5 hours of training in 2006 ( Figure 38 ). In about 10% of jurisdictions, training was 1 hour or less. In three quarters, it was 2-4 hours, and in only 5% was it one day or more. Nevertheless, 70% of LEOs considered pollworker training \"extremely important,\" and only a few considered it \"not important at all.\" There appeared to be substantial uniformity among respondents in the areas in which pollworkers were trained ( Figure 39 ), with more than 90% of pollworkers being trained in voter check-in, accessibility, election laws, operation of voting machines, and election integrity. LEOs were not asked what areas of training should be improved, but another study that surveyed pollworkers in New Mexico found that many desired more training in voting-machine operation and election laws. Interestingly, that finding reflects the views of many LEOs about their own training, as discussed earlier in this report. LEOs also believed that HAVA is changing the nature of pollworker training, with 20% reporting that the changes were \"substantial.\" As reported earlier (see Table 5 and Figure 25 above), most LEOs believed that HAVA has made elections more complex to administer. Most also expressed concern that the increased complexity of elections will have a negative impact on recruitment of pollworkers, and more than a third of respondents were \"extremely concerned\" ( Figure 40 ). Some observers have suggested that the environment in which election officials operate is too politically contentious and that steps should be taken to make election administration more nonpartisan. For example, some believe that state election officials should not be permitted to be involved in political campaigns other than for their own positions. The 2006 survey asked LEOs several questions about this issue. In general, LEOs were satisfied with election administration at the state level ( Figure 41 ), with only about 10% expressing significant dissatisfaction. More LEOs than not also believed that election administration in their state is independent of partisan politics. However, more than half of elected LEOs (57%) indicated that they communicated their party affiliation during their election. There was more variation in the views of LEOs about the political contentiousness of the election administration environment, with about 18% believing it is \"not contentious at all,\" and 9% that it is \"extremely contentious.\" Nevertheless, on average LEOs rated the level of contentiousness relatively low. Finally, LEOs were asked whether election administration should be a civil service function in their state. About half had no opinion, but significantly more elected LEOs were opposed to the idea than favored it. Appointed LEOs were evenly divided ( Figure 42 ). As with any survey, care needs to be taken in drawing inferences from the results. One question that could arise is whether the sample is representative of LEOs as a whole. For example, simply drawing the sample at random from the nationwide pool of election administrators would have resulted in a disproportionately large number of jurisdictions from New England and the upper Midwest, where elections are administered by townships rather than counties. Steps were taken in the design of the studies to minimize the risk that the sample would not be representative (see the Appendix below). Overall, neither the sample design nor the characteristics of the responses suggest that the results are unrepresentative of the views and characteristics of local election officials. Another potential caution for interpretation relates to the inherent limits of surveys such as these. In particular, there is no way to guarantee that the responses of the election officials correspond to their actual beliefs. In addition, there is no way to be certain that any particular belief corresponds to reality. The question on voting-system characteristics (see Figure 13 ) provides an illustration of the possibility for disparity. For several reasons, LEOs might be reluctant to rate their voting systems low in reliability, accuracy, and security, despite the anonymity of the results. Alternatively, they might truly believe that their voting systems are highly reliable, accurate, and secure, even if independent evidence does not support that view. Also, some caution is needed in assigning cause and effect. The mere existence of an association or correlation between a factor and an effect does not necessarily mean that the factor caused the effect. For example, the survey showed a strong association between the kind of voting system used in a jurisdiction and the number of pollworkers (see Figure 35 ). However, while the kind of voting system may have some independent effect, a more important factor is the number of registered voters. A final caution involves how survey results might be used to inform policy decisions. On the one hand, the results could be used to support the shaping of policy in directions expressed by LEOs in their responses. In many cases, such policy changes might be appropriate. On the other hand, it is possible that at least some of those desired changes would not in fact yield the most effective or appropriate policies. In such cases, the results might more constructively be used to help policymakers identify issues for which improvements in communication and understanding are needed. The survey results may have policy implications for several issues at the federal, state, and local levels of government. Some issues that may be relevant for congressional deliberations are highlighted below. Many observers have commented favorably on the experience and dedication of the nation's local election officials. Survey results are consistent with that view. At the same time, other observers, including some election officials, have called for increased professionalism in election administration. Some survey results suggest areas of potential professional improvement, such as in education and in professional involvement at the national level. Congress could address this potential need by several means, for example facilitating educational and training programs for LEOs and promoting professional certification of election officials by entities accredited through the EAC. The seemingly unique demographic characteristics of LEOs as a group of government officials may have other policy implications, but they are not altogether clear. However, some observers may argue that efforts should be undertaken to ensure that LEOs reflect the diversity of the workforce or voting population as a whole, especially with respect to minority representation. The issue of partisanship among election officials has been controversial for several years. Most national attention has been on state officials, but, given that most LEOs are elected and only about half the local jurisdictions in the United States are administered on a nonpartisan or bipartisan basis, policymakers may wish to consider the influence of partisanship among LEOs. Since the enactment of HAVA, controversy has arisen over whether DRE voting systems are sufficiently secure and reliable. The survey revealed that LEOs who have experience with DREs are very confident in them, consider them superior for accessibility, and do not generally support the addition of a voter-verified paper audit trail (VVPAT) to address security concerns, although those who use a VVPAT are satisfied with its performance. However, LEOs using other systems are much less confident in DREs and more supportive of VVPAT. The strongly dichotomous results suggest that as Congress considers whether to require changes in the security mechanisms used in voting systems, it might be useful to determine whether DRE users are overconfident in the security of their systems and procedures in practice, or, alternatively, whether nonusers might need to be better educated about the reliability and security of DRE systems. The survey results suggest that HAVA is in the process of achieving several of its policy goals. The general support of HAVA provisions\u2014including those such as the creation of the EAC and the provisional ballot requirement that have been somewhat controversial\u2014implies that LEOs are in agreement with the goals of the act and are active partners in its implementation. The overwhelming choice of new voting systems that assist voters in avoiding errors indicates that the HAVA goal of reducing avoidable voter error is in the process of being met. The areas of concern expressed by LEOs\u2014such as how to meet the costs of ongoing implementation of HAVA requirements\u2014raise issues that Congress may wish to address as it considers HAVA appropriations and reauthorization. In addition, the reduction in the levels of support from 2004 for HAVA and the EAC, while small, and broader concerns about the effectiveness of the EAC, may raise concerns for Congress. The close relationship between LEOs and the vendors of their voting systems seems unlikely to change as a result of HAVA. However, with the codification by HAVA of the voting system standards and certification processes, the influence of the federal government in decisions about new voting systems might be expected to increase in relation to that of vendors and others. The increased concerns of LEOs in 2006 that vendors, media, political parties, and advocacy groups have too much influence on such decisions may raise concerns. Scientific opinion surveys of local election officials are rare, and additional research may be useful to address some of the matters raised by these studies. For example, a survey of state election officials might provide useful information and might additionally be helpful in assessing the most appropriate federal role in promoting the effective implementation of HAVA goals at all levels of government. One common suggestion of LEOs for improving HAVA was to provide a means of adjusting requirements to fit the needs of smaller jurisdictions. To determine what, if any, such adjustments would be appropriate, it may be useful to have specific information on how the needs and characteristics of different jurisdictions vary with size\u2014something that was beyond the scope of these surveys. It could also be useful to identify how the duties of LEOs vary with size and other characteristics of the jurisdiction. In many jurisdictions, election administration is only part of the LEO's job. It is not known to what degree these other responsibilities might affect election administration\u2014negatively or positively. Finally, these surveys have provided only snapshots of LEO characteristics and perceptions over a two-year period. It might be beneficial to perform similar surveys periodically to identify trends and explore new questions and issues. The results presented and analyzed in this report are from two surveys sponsored by CRS as part of its Capstone program and performed by graduate students and faculty at the George Bush School of Government and Public Service at Texas A&M University. The principal investigators for the 2004 survey were Donald P. Moynihan and Carol Silva for the 2004 study and Carol Silva for 2006. Ten graduate students participated in the first survey, and six in the second. For both studies the CRS project manager was Eric Fischer and the project liaison was Kevin Coleman. The topics for the two surveys were developed collaboratively by the CRS and Texas A&M participants. The major factor in choosing the topics was potential usefulness of the results for Congress. The Bush School team developed and administered the survey instrument in consultation with CRS and provided the authors with the data used in performing the analyses. The two surveys were conducted after the November 2004 and 2006 federal elections, between December and the following March. For each survey, a sample of approximately 3,800 LEOs was drawn from the roughly 9,000 election jurisdictions in the 50 states. To ensure that LEOs from all states were included, but that states with large numbers of LEOs were not disproportionately represented (see Figure A-1 ), a modified random-sampling regime was used, as follows: Surveys were sent to all LEOs in states with 150 or fewer local jurisdictions. For the ten states with more than 150 LEOs, a sample of 150 was chosen at random from the local jurisdictions, and surveys were sent to those LEOs. Most surveys were administered electronically, with respondents visiting a website to enter their responses. The remainder were paper surveys sent via the U.S. Postal Service. LEOs who did not respond were sent reminders or contacted by telephone. For each survey, the overall final response rate was 40% of the sample, or about 17% of all jurisdictions in the United States. Respondents answered 85-90% of questions, on average. The response was sufficiently high to permit statistical analysis and comparison of the results between the surveys. Individual response rates per state were between 25% and 50% for about three-quarters of states (see Figure A-2 ). The remainder were evenly split between those for which under 25% of LEOs responded, and those for which the rate was greater than 50%. Response rates were similar among states across the two surveys, and did not vary significantly for either survey with the number of local election jurisdictions in a state or its voting age population. About 70% of respondents worked in county election jurisdictions, with most of the remainder working in townships ( Figure A-3 ). The small difference between the two years in those choosing \"town/township\" and in those choosing \"other\" was almost certainly a result of a small change in the structure of the question for the 2006 survey. All the results presented in this report are from analyses by CRS of data provided from the surveys by researchers at Texas A&M University. The raw data were first examined for errors, and corrections were made where necessary, in a few cases, such as if a LEO claimed to work more hours per week than is physically possible. Where the correct answer could be reasonably discerned, the response was corrected. Otherwise it was discarded. Once cleaned, the data were analyzed using standard parametric methods, mainly analysis of variance, linear regression, and Student's t-tests as appropriate. Three kinds of hypotheses were tested: differences between groups, such as whether results for 2004 differed from those for 2006; differences from a hypothetical value, such as whether LEOs were neutral about, agreed with, or disagreed with a particular statement; and tests for associations, such as whether the number of pollworkers in a jurisdiction was correlated with the number of registered voters. Statistical significance was determined using a significance level (\u03b1) of .01. However, for display purposes, graphs with error bars were drawn showing 95% confidence intervals for the means. Most tests yielded highly statistically significant results\u2014p-values much lower than the significance level (p << .01). For tests where statistically significant effects were not found, the lack of effect is noted in the text, for example, by stating that no change was found between 2004 and 2006 for a particular survey item. Additional methodological details can be provided upon request."
}