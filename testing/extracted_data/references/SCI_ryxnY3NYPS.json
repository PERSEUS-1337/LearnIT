{
    "title": "ryxnY3NYPS",
    "content": "The ability to forecast a set of likely yet diverse possible future behaviors of an agent (e.g., future trajectories of a pedestrian) is essential for safety-critical perception systems (e.g., autonomous vehicles). In particular, a set of possible future behaviors generated by the system must be diverse to account for all possible outcomes in order to take necessary safety precautions. It is not sufficient to maintain a set of the most likely future outcomes because the set may only contain perturbations of a dominating single outcome (major mode). While generative models such as variational autoencoders (VAEs) have been shown to be a powerful tool for learning a distribution over future trajectories, randomly drawn samples from the learned implicit likelihood model may not be diverse -- the likelihood model is derived from the training data distribution and the samples will concentrate around the major mode of the data. In this work, we propose to learn a diversity sampling function (DSF) that generates a diverse yet likely set of future trajectories. The DSF maps forecasting context features to a set of latent codes which can be decoded by a generative model (e.g., VAE) into a set of diverse trajectory samples. Concretely, the process of identifying the diverse set of samples is posed as DSF parameter estimation. To learn the parameters of the DSF, the diversity of the trajectory samples is evaluated by a diversity loss based on a determinantal point process (DPP). Gradient descent is performed over the DSF parameters, which in turn moves the latent codes of the sample set to find an optimal set of diverse yet likely trajectories. Our method is a novel application of DPPs to optimize a set of items (forecasted trajectories) in continuous space. We demonstrate the diversity of the trajectories produced by our approach on both low-dimensional 2D trajectory data and high-dimensional human motion data. Forecasting future trajectories of vehicles and human has many useful applications in autonomous driving, virtual reality and assistive living. What makes trajectory forecasting challenging is that the future is uncertain and multi-modal -vehicles can choose different routes and people can perform different future actions. In many safety-critical applications, it is important to consider a diverse set of possible future trajectories, even those that are less likely, so that necessary preemptive actions can be taken. For example, an autonomous vehicle should understand that a neighboring car can merge into its lane even though the car is most likely to keep driving straight. To address this requirement, we need to take a generative approach to trajectory forecasting that can fully characterize the multimodal distribution of future trajectories. To capture all modes of a data distribution, variational autoencoders (VAEs) are well-suited generative models. However, random samples from a learned VAE model with Gaussian latent codes are not guaranteed to be diverse for two reasons. First, the sampling procedure is stochastic and the VAE samples can fail to cover some minor modes even with a large number of samples. Second, since VAE sampling is based on the implicit likelihood function encoded in the training data, if most of the training data is centered around a specific mode while other modes have less data ( Fig. 1 (a) ), the VAE samples will reflect this bias and concentrate around the major mode ( Fig. 1 (b) ). To tackle this problem, we propose to learn a diversity sampling function (DSF) that can reliably generate a diverse set of trajectory samples ( Fig. 1 (c) ). The proposed DSF is a deterministic parameterized function that maps forecasting context features (e.g., past trajectories) to a set of latent codes. The latent codes are decoded by the VAE docoder into a set of future trajectory samples, denoted as the DSF samples. In order to optimize the DSF, we formulate a diversity loss based on a determinantal point process (DPP) (Macchi, 1975) to evaluate the diversity of the DSF samples. The DPP defines the probability of choosing a random subset from the set of trajectory samples. It models the negative correlations between samples: the inclusion of a sample reduces the probability of including a similar sample. This makes the DPP an ideal tool for modeling the diversity within a set. In particular, we use the expected cardinality of the DPP as the diversity measure, which is defined as the expected size of a random subset drawn from the set of trajectory samples according to the DPP. Intuitively, since the DPP inhibits selection of similar samples, if the set of trajectory samples is more diverse, the random subset is more likely to select more samples from the set. The expected cardinality of the DPP is easy to compute and differentiable, which allows us to use it as the objective to optimize the DSF to enable diverse trajectory sampling. Our contributions are as follows: (1) We propose a new forecasting approach that learns a diversity sampling function to produce a diverse set of future trajectories; (2) We propose a novel application of DPPs to optimize a set of items (trajectories) in continuous space with a DPP-based diversity measure; (3) Experiments on synthetic data and human motion validate that our method can reliably generate a more diverse set of future trajectories compared to state-of-the-art generative models. Trajectory Forecasting has recently received significant attention from the vision community. A large portion of previous work focuses on forecasting 2D future trajectories for pedestrians (Kitani et al., 2012; Ma et al., 2017; Ballan et al., 2016; Xie et al., 2013) or vehicles (Jain et al., 2016a) . Some approaches use deterministic trajectory modeling and only forecast one future trajectory Yagi et al., 2018; . As there are often multiple plausible future trajectories, several approaches have tried to forecast distributions over trajectories Galceran et al., 2015; Gupta et al., 2018) . Recently, Rhinehart et al. (2018; propose a generative model that can accurately forecast multi-modal trajectories for vehicles. Soo Park et al. (2016) also use egocentric videos to predict the future trajectories of the camera wearer. Some work has investigated forecasting higher dimensional trajectories such as the 3D fullbody pose sequence of human motions. Most existing work takes a deterministic approach and forecasts only one possible future motion from past 3D poses (Fragkiadaki et al., 2015; Butepage et al., 2017; Li et al., 2017; Jain et al., 2016b) , static images (Chao et al., 2017; Kanazawa et al., 2018) or egocentric videos (Yuan and Kitani, 2019) . Differently, some probabilistic approaches (Habibie et al., 2017; Yan et al., 2018) use conditional variational autoencoders (cVAEs) to generate multiple future motions. In constrast to previous work, our approach can generate a diverse set of future motions with a limited number of samples. Diverse Solutions have been sought after in a number of problems in computer vision and machine learning. A branch of these methods aiming for diversity stems from the M-Best MAP problem (Nilsson, 1998; Seroussi and Golmard, 1994) , including diverse M-Best solutions and multiple choice learning Lee et al., 2016) . Alternatively, previous work has used submodular function maximization to select a diverse subset of garments from fashion images (Hsiao and Grauman, 2018) . Determinantal point processes (DPPs) (Macchi, 1975; are efficient probabilistic models that can measure both the diversity and quality of items in a subset, which makes it a natural choice for the diverse subset selection problem. DPPs have been applied for document and video summarization (Kulesza and Taskar, 2011; Gong et al., 2014) , recommendation systems (Gillenwater et al., 2014) , object detection (Azadi et al., 2017) , and grasp clustering (Huang et al., 2015) . Elfeki et al. (2018) have also used DPPs to mitigate mode collapse in generative adversarial networks (GANs). The work most related ours is (Gillenwater et al., 2014) , which also uses the cardinality of DPPs as a proxy for user engagement. However, there are two important differences between our approach and theirs. First, the context is different as they use the cardinality for a subset selection problem while we apply the cardinality as an objective of a continuous optimization problem in the setting of generative models. Second, their main motivation behind using the cardinality is that it aligns better with the user engagement semantics, while our motivation is that using cardinality as a diversity loss for deep neural networks is more stable due to its tolerance of similar trajectories, which are often produced by deep neural networks during stochastic gradient descent. The aim of multi-modal trajectory forecasting is to learn a generative model over future trajectories. Variational autoencoders (VAEs) are a popular choice of generative models for trajectory forecasting Walker et al., 2016) because it can effectively capture all possible future trajectories by explicitly mapping each data point to a latent code. VAEs model the joint distribution p \u03b8 (x, z) = p(z)p \u03b8 (x|z) of each data sample x (e.g., a future trajectory) and its corresponding latent code z, where p(z) denotes some prior distribution (e.g., Gaussians) and p \u03b8 (x|z) denotes the conditional likelihood model. To calculate the marginal likelihood p \u03b8 (x) = p \u03b8 (x, z)/p \u03b8 (z|x), one needs to compute the posterior distribution p \u03b8 (z|x) which is typically intractable. To tackle this, VAEs use variational inference (Jordan et al., 1999) which introduces an approximate posterior q \u03c6 (z|x) and decomposes the marginal log-likelihood as where L(x; \u03b8, \u03c6) is the evidence lower bound (ELBO) defined as During training, VAEs jointly optimize the recognition model (encoder) q \u03c6 (z|x) and the likelihood model (decoder) p \u03b8 (x|z) to maximize the ELBO. In the context of multi-modal trajectory forecasting, one can generate future trajectories from p(x) by drawing a latent code z from the prior p(z) and decoding z with the decoder p \u03b8 (x|z) to produce a corresponding future trajectory x. Our core technical innovation is a method to learn a diversity sampling function (DSF) that can generate a diverse set of future trajectories. To achieve this, we must equip ourselves with a tool to evaluate the diversity of a set of trajectories. To this end, we make use of determinantal point processes (DPPs) to model the diversity within a set. DPPs promote diversity within a set because the inclusion of one item makes the inclusion of a similar item less likely if the set is sampled according to a DPP. Formally, given a set of items (e.g., data points) Y = {x 1 , . . . , x N }, a point process P on the ground set Y is a probability measure on 2 Y , i.e., the set of all subsets of Y. P is called a determinantal point process if a random subset Y drawn according to P has where Y \u2286 Y, I is the identity matrix, L \u2208 R N \u00d7N is the DPP kernel, a symmetric positive semidefinite matrix, and The DPP kernel L is typically constructed by a similarity matrix S, where S ij defines the similarity between two items x i and x j . If we use the inner product as the similarity measure, L can be written in the form of a Gram matrix L = S = X T X where X is the stacked feature matrix of Y. As a property of the Gram matrix, det (L Y ) equals the squared volume spanned by vectors x i \u2208 Y . With this geometric interpretation in mind, one can observe that diverse sets are more probable because their features are more orthogonal, thus spanning a larger volume. In addition to set diversity encoded in the similarity matrix S, it is also convenient to introduce a quality vector r = [r 1 , . . . , r N ] to weigh each item according to some unary metric. For example, the quality weight might be derived from the likelihood of an item. To capture both diversity and quality of a subset, the DPP kernel L is often decomposed in the more general form: With this decomposition, we can see that both the quality vector r and similarity matrix S contribute to the DPP probability of a subset Y : Due to its ability to capture the global diversity and quality of a set of items, we choose DPPs as the probabilistic approach to evaluate and optimize the diversity of the future trajectories drawn by our proposed diversity sampling function. Safety-critical applications often require that the system can maintain a diverse set of outcomes covering all modes of a predictive distribution and not just the most likely one. To address this requirement, we propose to learn a diversity sampling function (DSF) to draw deterministic trajectory samples by generating a set of latent codes in the latent space of a conditional variational autoencoder (cVAE) and decoding them into trajectories using the cVAE decoder. The DSF trajectory samples are evaluated with a DPP-based diversity loss, which in turn optimizes the parameters of the DSF for more diverse trajectory samples. Formally, the future trajectory x \u2208 R T \u00d7D is a random variable denoting a D dimensional feature over a future time horizon T (e.g., a vehicle trajectory or a sequence of humanoid poses). The context \u03c8 = {h, f } provides the information to infer the future trajectory x, and it contains the past trajectory h \u2208 R H\u00d7D of last H time steps and optionally other side information f , such as an obstacle map. In the following, we first describe how we learn the future trajectory model p \u03b8 (x|\u03c8) with a cVAE. Then, we introduce the DSF and the DPP-based diversity loss used to optimize the DSF. In order to generate a diverse set of future trajectory samples, we need to learn a generative trajectory forecasting model p \u03b8 (x|\u03c8) that can cover all modes of the data distribution. Here we use cVAEs (other proper generative models can also be used), which explicitly map data x with the encoder q \u03c6 (z|x, \u03c8) to its corresponding latent code z and reconstruct the data from the latent code using the decoder p \u03b8 (x|z, \u03c8). By maintaining this one-on-one mapping between the data and the latent code, cVAEs attempt to capture all modes of the data. As discussed in Sec. 3.1, cVAEs jointly optimize the encoder and decoder to maximize the variational lower bound: We use multivariate Gaussians for the prior, encoder and decoder: , and p \u03b8 (x|z, \u03c8) = N (x;x, \u03b1I). Both the encoder and decoder are implemented as neural networks. The encoder network f \u03c6 outputs the parameters of the posterior distribution: (\u00b5, \u03c3) = f \u03c6 (x, \u03c8). The decoder network g \u03b8 outputs the reconstructed future trajectoryx: Detailed network architectures are given in Appendix B.1. Based on the Gaussian parameterization of the cVAE, the objective in Eq. 6 can be rewritten as where we take V samples from the posterior q \u03c6 (z|x, \u03c8), D z is the number of latent dimensions, and \u03b2 = 1/\u03b1 is a weighting factor. The training procedure for the cVAE is detailed in Alg. 2 (Appendix A). Once the cVAE model is trained, sampling from the learned future trajectory model p \u03b8 (x|\u03c8) is efficient: we can sample a latent code z according to the prior p(z) and use the decoder p \u03b8 (x|z, \u03c8) to decode it into a future trajectory x. Algorithm 1 Training the diversity sampling function (DSF) S \u03b3 (\u03c8) Initialize \u03b3 randomly 4: while not converged do 5: Generate latent codes Z = {z 1 , . . . , z N } with the DSF S \u03b3 (\u03c8) Generate the trajectory ground set Y = {x 1 , . . . , x N } with the decoder g \u03b8 (z, \u03c8) 8: Compute the similarity matrix S and quality vector r with Eq. 8 and 9 9: Compute the DPP kernel Calculate the diversity loss L diverse Update \u03b3 with the gradient \u2207L diverse 12: end for 13: end while As mentioned before, randomly sampling from the learned cVAE model according to the implicit likelihood function p \u03b8 (x|\u03c8), i.e., sampling latent codes from the prior p(z), does not guarantee that the trajectory samples are diverse: major modes (those having more data) with higher likelihood will produce most of the samples while minor modes with lower likelihood will have almost no sample. This prompts us to devise a new sampling strategy that can reliably generate a diverse set of samples covering both major and minor modes. We propose to learn a diversity sampling function (DSF) S \u03b3 (\u03c8) that maps context \u03c8 to a set of latent codes Z = {z 1 , . . . , z N }. The DSF is implemented as a \u03b3-parameterized neural network which takes \u03c8 as input and outputs a vector of length N \u00b7 D z (see Appendix B.1 for network details). The latent codes Z are decoded into a diverse set of future trajectories Y = {x 1 , . . . , x N }, which are denoted as the DSF trajectory samples. We note that N is the sampling budget. To solve for the parameters of the DSF, we propose a diversity loss based on a DPP defined over Y. In this section, we first describe how the DPP kernel L is defined, which involves the construction of the similarity matrix S and quality vector r. We then discuss how we use the DPP kernel L to formulate a diversity loss to optimize the parameters of the DSF. Recall that the DPP kernel is defined as L = Diag(r) \u00b7 S \u00b7 Diag(r), where r defines the quality of each trajectory and S measures the similarity between two trajectories. The DPP kernel L(\u03b3) is a function of \u03b3 as it is defined over the ground set Y output by the DSF S \u03b3 (\u03c8). Similarity. We measure the similarity S ij between two trajectories x i and x j as where d x is the Euclidean distance and k is a scaling factor. This similarity design ensures that 0 \u2264 S ij \u2264 1 and S ii = 1. It also makes S positive definite since the Gaussian kernel we use is a positive definite kernel. Quality. It may be tempting to use p(x|\u03c8) to define the quality of each trajectory sample. However, this likelihood-based measure will clearly favor major modes that have higher probabilities, making it less likely to generate samples from minor modes. This motivates us to design a quality metric that treats all modes equally. To this end, unlike the similarity metric which is defined in the trajectory space, the quality of each sample is measured in the latent space and is defined as Geometrically, let R be the radius of a sphere \u03a6 containing most samples from the Gaussian prior p(z). We treat samples inside \u03a6 equally and only penalize samples outside \u03a6. In this way, samples from major modes are not preferred over those from minor modes as long as they are inside \u03a6, while samples far away from the data manifold are heavily penalized as they are outside \u03a6. The radius R is determined by where \u03c1 percent of the Gaussian samples lie within, and we set \u03c1 = 90. To compute R, we use the percentage point function of the chi-squared distribution which models the distribution over the sum of squares of independent standard normal variables. The base quality \u03c9 is a hyperparameter which we set to 1 during training in our experiments. At test time, we can use a larger \u03c9 to encourage the DPP to select more items from the ground set Y. The hyperparameter \u03c1 (or R) allows for the trade-off between diversity and quality. When R is small, the quality metric is reduced to a pure likelihood-based metric (proportional to the latent likelihood), which will prefer samples with high likelihood and result in a less diverse sample set. When R is large, most samples will have the same quality, and the resulting samples will be highly diverse but less likely. In practice, the choice of R should be application dependent, as one could imagine autonomous vehicles would need to consider more diverse scenarios including those less likely ones to ensure robustness. We note that after the diverse samples are obtained, it is possible to reassign the quality score for each sample based on its likelihood to allow users to prioritize more likely samples. Diversity Loss. To optimize the DSF S \u03b3 (\u03c8), we need to define a diversity loss that measures the diversity of the trajectory ground set Y generated by S \u03b3 (\u03c8). An obvious choice for the diversity loss would be the negative log likelihood However, there is a problem with directly using the DPP log likelihood. The log likelihood heavily penalizes repeated items: if two trajectories inside Y are very similar, their corresponding rows in L will be almost identical, making det(L(\u03b3)) = \u03bb 1 \u03bb 2 . . . \u03bb N \u2248 0 (\u03bb n is the n-th eigenvalue). In practice, if the number of modes in the trajectory distribution p(x|\u03c8) is smaller than |Y|, Y will always have similar trajectories, thus making det(L(\u03b3)) always close to zero. In such cases, optimizing the negative log likelihood causes numerical issues, which is observed in our early experiments. Instead, the expected cardinality of the DPP is a better measure for the diversity of Y, which is defined as Intuitively, since the DPP discourages selection of similar items, if Y is more diverse, a random subset Y drawn according to the DPP is more likely to select more items from Y, thus having larger cardinality. The expected cardinality can be computed as (Eq. 15 and 34 in ): The main advantage of the expected cardinality is that it is well defined even when the ground set Y has duplicated items, since it does not require all eigenvalues of L to be non-zero as the log likelihood does. Thus, our diversity loss is defined as L diverse (\u03b3) = \u2212tr I \u2212 (L(\u03b3) + I) \u22121 . The training procedure for S \u03b3 (\u03c8) is outlined in Alg. 1. Inference. At test time, given current context \u03c8,we use the learned DSF S \u03b3 (\u03c8) to generate the future trajectory ground set Y. In some cases, Y may still contain some trajectories that are similar to others. In order to obtain a diverse set of trajectories without repetition, we aim to perform MAP inference for the DPP to find the most diverse subset Y * = arg max Y \u2208Y P L(\u03b3) (Y ). A useful property of DPPs is that the log-probability function is submodular (Gillenwater et al., 2012) . Even though submodular maximization is NP-hard, we use a greedy algorithm (Nemhauser et al., 1978) which is a popular optimization procedure that works well in practice. As outlined in Alg. 3, the output set Y f is initialized as \u2205, and at each iteration, the trajectory which maximizes the log probability is added to Y f , until the marginal gain becomes negative or Y f = Y. The primary focus of our experiments is to answer the following questions: (1) Are trajectory samples generated with our diversity sampling function more diverse than samples from the cVAE and other baselines? (2) How does our method perform on both balanced and imbalanced data? (3) Is our method general enough to perform well on both low-dimensional and high-dimensional tasks? Figure 2: In real data, contexts (past trajectories) are seldom the same due to noise. Metrics. A problem with trajectory forecasting evaluation is that in real data each context \u03c8 (i) usually only has one future trajectory x (i) , which means we only have one sample from a multi-modal distribution. Let us consider a scenario of three data examples as shown in Fig. 2 (red, purple, blue). The contexts (past trajectories) of the three examples are instances of the same trajectory but they are slightly different due to noise. As these three contexts have the same semantic meaning, they should share the future trajectories, e.g., the purple and blue future trajectories are also valid for the red context. If we evaluate each example (x (i) , \u03c8 (i) ) only with its own future trajectory x (i) , a method can achieve high scores by only forecasting the mode corresponding to x (i) and dropping other modes. This is undesirable because we want a good method to capture all modes of the future trajectory distribution, not just a single mode. To allow for multi-modal evaluation, we propose collecting multiple future trajectories for each example by clustering examples with similar contexts. Specifically, we augment each data example (x (i) , \u03c8 (i) ) with a future trajectory set . . , M } and metrics are calculated based on X (i) instead of x (i) , i.e., we compute metrics for each x \u2208 X (i) and average the results. Lee et al., 2017; Rhinehart et al., 2018; Gupta et al., 2018) . However, these two metrics do not penalize repeated samples. To address this, we introduce two new metrics ASD and FSD to evaluate the similarity between samples in the set of forecasted trajectories. Larger ASD and FSD means the forecasted trajectories are more non-repetitive and diverse. Baselines. We compare our Diversity Sampler Function (DSF) with the following baselines: (1) cVAE: a method that follows the original sampling scheme of cVAE by sampling latent codes from a Gaussian prior p(z). (2) MCL: an approach that uses multiple choice learning (Lee et al., 2016) to optimize the sampler S \u03b3 (\u03c8) with the following loss: L mcl = minx \u2208Y x \u2212 x 2 , where x is the ground truth future trajectory. (3) R2P2: a method proposed in (Rhinehart et al., 2018 ) that uses a reparametrized pushforward policy to improve modeling of multi-modal distributions for vehicle trajectories. (4) cGAN: generative adversarial networks (Goodfellow et al., 2014) conditioned on the forecasting context. We implement all baselines using similar networks and perform hyperparameter search for each method for fair comparisons. For methods whose samples are stochastic, we use 10 random seeds and report the average results for all metrics. We first use synthetic data to evaluate our method's performance for low-dimensional tasks. We design a virtual 2D traffic scene where a vehicle comes to a crossroad and can choose three different future routes: forward, left, and right. We consider two types of synthetic data: (1) Balanced data, which means the probabilities of the vehicle choosing one of the three routes are the same; (2) Table 1 : Quantitative results on synthetic data (numbers scaled by 10) when N = 10. Imbalanced data, where the probabilities of the vehicle going forward, left and right are 0.8, 0.1, 0.1, respectively. We synthesize trajectory data by simulating the vehicle's behavior and adding Gaussian noise to vehicle velocities. Each data example (x (i) , \u03c8 (i) ) contains future trajectories of 3 steps and past trajectories of 2 steps. We also add an obstacle map around the current position to the context \u03c8 (i) . In total, we have around 1100 training examples and 1000 test examples. Please refer to Appendix B for more implementation details. Table 1 summarizes the quantitative results for both balanced and imbalanced data when the sampling budget N is 10. We can see that our method DSF outperforms the baselines in all metrics in both test settings. As shown in Fig. 3 , our method generates more diverse trajectories and is less affected by the imbalanced data distribution. The trajectory samples of our method are also less repetitive, a feature afforded by our DPP formulation. Fig. 4 shows how ADE changes as a function of the sampling budget N . Table 2 : Quantitative results on for human motion forecasting when N = 10. To further evaluate our method's performance for more complex and high-dimensional tasks, we apply our method to forecast future human motions (pose sequences). We use motion capture to obtain 10 motion sequences including different types of motions such as walking, turning, jogging, bending, and crouching. Each sequence is about 1 minute long and each pose consists of 59 joint angles. We use past 3 poses (0.1s) to forecast next 30 poses (1s). There are around 9400 training examples and 2000 test examples where we use different sequences for training and testing. More implementation details can be found in Appendix B. We present quantitative results in Table 2 and we can see that our approach outperforms other methods in all metrics. As the dynamics model used in R2P2 (Rhinehart et al., 2018) does not generalize well for high-dimensional human motion, we find the model fails to converge and we do not compare with it in this experiment. Fig. 4 shows that our method achieves large improvement when the sampling budget is big (N = 50) . We also present qualitative results in Fig. 5 , where we show the starting pose and the final pose of all 10 forecasted motion samples for each method. We can clearly see that our method generates more diverse future human motions than the baselines. Please refer to Appendix C and our video for additional qualitative results. In this section, we perform additional experiments on a large human motion dataset (3.6 million frames), Human3.6M (Ionescu et al., 2013) , to evaluate the generalization ability of our approach. We predict future motion of 2 seconds based on observed motion of 0.5 seconds. Please refer to Appendix B.3 for implementation details. We also use a new selection of baselines including several variants of our method (DSF) and the cVAE to validate several design choices of our method, including the choice of the expected cardinality over the negative log likelihood (NLL) of the DPP as the diversity loss. Specifically, we use the following new baselines: (1) DSF-NLL: a variant of DSF that uses NLL as the diversity loss instead of the expected cardinality. (2) DSF-COS: a DSF variant that uses cosine similarity to build the similarity matrix S for the DPP kernel L. (3) DSF-NLL: a variant of the cVAE that samples 100 latent codes and performs DPP MAP inference on the latent codes to obtain a diverse set of latent codes, which are then decoded into trajectory samples. We present quantitative results in Table 3 when the number of samples N is 10 and 50. The baseline DSF-COS is able to achieve very high diversity (ASD and FSD) but its samples are overly diverse and have poor quality which is indicated by the large ADE and FDE. Compared with DSF-NLL, Table 3 : Quantitative results on Human3.6M (Ionescu et al., 2013) for N = 10 and N = 50. X means the method is unable to learn a model due to numerical instability. our method achieves better diversity (ASD and FSD) and similar ADE and FDE when the number of samples is small (N = 10) . For a larger number of samples (N = 50) , NLL becomes unstable even with a large (1e-3) added to the diagonal. This behavior of NLL, i.e., stable for small N but unstable for large N , matches our intuition that NLL becomes unstable when samples become similar (as discussed in Sec. 4.2), because when there are more samples, it is easier to have similar samples during the SGD updates of the DSF network. The baseline cVAE-LDPP also performs worse than DSF in all metrics even though it is able to outperfom the cVAE. We believe the reason is that diversity in sample space may not be well reflected in the latent space due to the non-linear mapping from latent codes to samples induced by deep neural networks. We proposed a novel forecasting approach using a DSF to optimize over the sample space of a generative model. Our method learns the DSF with a DPP-based diversity measure to generate a diverse set of trajectories. The diversity measure is a novel application of DPPs to optimize a set of items in continuous space. Experiments have shown that our approach can generate more diverse vehicle trajectories and human motions compared to state-of-the-art baseline forecasting approaches. 2: Output: cVAE encoder network f \u03c6 (x, \u03c8) and decoder network g \u03b8 (z, \u03c8) 3: Initialize \u03c6 and \u03b8 randomly 4: while not converged do 5: Compute parameters (\u00b5, \u03c3) of the posterior distribution q \u03c6 (z|x, \u03c8) using f \u03c6 (x, \u03c8) Sample V Gaussian noises { 1 , . . . , V } from N (0, I) Transform noises to latent samples from q \u03c6 (z|x, \u03c8): Decode latent samples into reconstructed trajectories {x 1 , . . . ,x V } using g \u03b8 (z, \u03c8) Calculate the cVAE loss L cvae according to Eq. 6 11: Update \u03c6 and \u03b8 with \u2207 \u03c6 L cvae and \u2207 \u03b8 L cvae 12: end for 13: end while Figure 6 : Network architectures for synthetic data and human motion. Top: for synthetic data, we use a CNN to process the obstacle map f and directly flatten trajectories x and h into vectors. The reconstructed trajectoryx is decoded with an MLP. Bottom: for human motion, we use Bi-LSTMs to extract temporal features for x and h and decode the reconstructed trajectoryx with a forward LSTM. Synthetic data. Fig. 6 (Top) shows the network architecture for synthetic data. The number of latent dimensions is 2. By default, we use ReLU activation for all networks. The future trajectory x \u2208 R 3\u00d72 consists of 3 future positions of the vehicle. The context \u03c8 contains past trajectories h \u2208 R 2\u00d72 of 2 time steps and a obstacle map f \u2208 {0, 1} 28\u00d728 spanning a 4 \u00d7 4 area around the current position of the vehicle (the road width is 2). For the encoder, we use a convolutional neural network (CNN) with three 32-channel convolutional layers to process f . The first two layers have kernel size 4 and stride 2 while the last layer has kernel size 6 and stride 1. The obtained CNN features are concatenated with flattened x and h into a unified feature, which is feed into a multilayer perceptron (MLP). The MLP has one 128-dim hidden layer and two heads outputing the mean \u00b5 and variance \u03c3 of the latent distribution. For the decoder, we concatenate the CNN feature from f with the latent code z \u2208 R 2 and flattened h into a unified feature. The feature is passed through an MLP with one 128-dim hidden layer which outputs the reconstructed future trajector\u1ef9 x \u2208 R 3\u00d72 . For the diversity sampler function (DSF), we concatenate the CNN feature from f with the flattened h and pass it through an MLP with one 128-dim hidden layer to obtain a set of latent codes {z 1 , . . . , z N } which are represented by a vector of length 2N . Human motion. Fig. 6 (Bottom) shows the network architecture for synthetic data. The number of latent dimensions is 8. The future trajectory x \u2208 R 30\u00d759 consists of future poses of 30 time steps (1s). The context \u03c8 contains past poses h \u2208 R 3\u00d759 of 3 time steps (0.1s). Each pose consists of 59 joint angles. For the encoder, we use two 128-dim bidirectional LSTMs (Bi-LSTMs) and mean pooling to obtain the temporal features for x and h. We then concatenate the temporal features into a unified feature and feed it into an MLP with two hidden layers (300, 200) and two heads to obtain the mean \u00b5 and variance \u03c3 of the latent distribution. For the decoder, we reuse the Bi-LSTM of the encoder for the context h and a 128-dim forward LSTM to decode the future trajectoryx. At each time step t, the forward LSTM takes as input the previous posex t\u22121 (h H for t = 0), the latent code z \u2208 R 8 and the temporal features from h, and outputs a 128-dim feature. The feature is then passed through an MLP with two hidden layers (300, 200) to generate the reconstructed posex t . For the DSF, we use a different 128-dim Bi-LSTM to obtain the temporal feature for h, which is feed into an MLP with a 128-dim hidden layer to produce a set of latent codes {z 1 , . . . , z N } which are represented by a vector of length 8N . When training the cVAE model using Eq. 7, we take V = 1 sample from the posterior q \u03c6 (z|x, \u03c8). The weighting factor \u03b2 for the KL term is set to 0.1 for synthetic data and 1e-4 for human motion. We use Adam (Kingma and Ba, 2014) to jointly optimize the encoder and decoder. The learning rate is set to 1e-4 and we use a mini batch size of 32 for synthetic data. We optimize the model for 500 epochs for synthetic data and 100 epochs for human motion. When training the DSF, the scale factor k for the similarity matrix S is set to 1 for synthetic data and 1e-2 for human motions. For both synthetic data and human motions, we use Adam with learning rate 1e-4 to optimize the DSF for 20 epochs. Recall that in the metrics section (Sec. 5.1), we need the grouping threshold \u03b5 to build the ground truth future trajectory set X (i) = {x (j) | \u03c8 (j) \u2212 \u03c8 (i) \u2264 \u03b5, j = 1, . . . , M }. For synthetic data, \u03b5 is set to 0.1 and we only use past trajectories h to compute the distance between contexts. For human motion, \u03b5 is set to 0.5. Following previous work (Martinez et al., 2017; Pavlakos et al., 2017; Pavllo et al., 2019) , we convert the motion sequences in the dataset into sequences of 3D joint positions, and adopt a 17-joint skeleton. We train on five subjects (S1, S5, S6, S7, S8), and test on two subjects (S9 and S11). We use the same network architectures (Fig.6 (Bottom)) in this experiment as the one used in the human motion forecasting experiment above. The number of latent dimensions is 128. When training the cVAE model, the weighting factor \u03b2 is set to 0.1. We sample 5000 training examples every epoch and optimize the cVAE for 500 epochs using Adam and a learning rate of 1e-4. We set the batch size to 64 for the optimization. The scale factor k for the similarity matrix S of the DPP kernel is set to 5. When learning the DSF, we use a batch size of 64 and sample 1000 training examples every epoch and optimize the DSF for 20 epochs using Adam and a learning rate of 1e-3. When computing the metrics, we set the grouping threshold \u03b5 to 0.1. We also show additional qualitative results for human motion forecasting in Fig. 7 . The quality and diversity of the forecasted motions are best seen in our video 2 . Figure 7: Additional visualization for human motion forecasting. The left shows the starting pose, and on the right we show for each method the final pose of 10 forecasted motion samples."
}