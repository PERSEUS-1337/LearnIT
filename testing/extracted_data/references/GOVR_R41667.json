{
    "title": "R41667",
    "content": "There are about 9,000 local election jurisdictions in the United States. In most states, they are counties or major cities, but in some New England and Upper Midwest states, they are small townships\u2014for example, more than 1,800 townships in Wisconsin. The number of registered voters and polling places in a jurisdiction reported by LEOs also varies greatly ( Figure 1 and Figure 2 ).  The reported number of registered voters ranged from fewer than 100 to more than 1 million, with a median of about 12,000 in 2006 and 13,000 in 2008. That 8% increase was consistent with the reported 7%-10% increase in the number of registered voters nationwide during that period.  Although LEOs were not asked to report the number of voters in their jurisdictions in the 2004 survey, in 2008 they were asked how the number changed from 2004 to 2008. About two-thirds reported that the number of registered voters had increased between 2004 and 2008, and about one-fifth reported a decrease ( Figure 3 ). The number of polling places in a jurisdiction averaged about a dozen, ranging from 0 to 1,000 or more, with about 15% of jurisdictions in each election having only one polling place and a similar percentage having more than 50. The number of election personnel working in a jurisdiction, in addition to the local election official, also varied greatly, from none to more than 10,000, including pollworkers. The 2008 survey also asked about the number of employees other than pollworkers. The median was 5, with a mean of 17 and a maximum of 800.  The number of registered voters, polling places, and pollworkers was about 10 times greater in county jurisdictions than in townships. LEOs from counties reported an average of about 56,000 registered voters, while those from townships averaged 6,000. There were 40 polling places per county on average, and 3 per township. Counties had about 290 pollworkers and townships 30. Given such diversity and other differences among states\u2014such as wealth, population, and the role of state election officials\u2014responsibilities and characteristics of LEOs are likely to vary greatly. Nevertheless, some patterns emerged from the surveys. According to the survey results, the typical LEO is a white woman between 50 and 60 years old who is a high school graduate. She was elected to her current office, works full-time in election administration, has been in the profession for about 10 years, and earns under $60,000 per year. She belongs to a state-level professional organization but not a national one, and she believes that her training as an election official has been good to excellent. As with any such description, the one above does not capture the diversity within the community surveyed: About one-quarter of LEOs are men, about 5% belong to minority groups, about 40% are college graduates, and about 10% have graduate degrees (see Table 1 ). LEOs range from under 25 to more than 80 years of age, and have served from 1 to 50 years. More than half were elected rather than appointed to their posts. Reported salaries range from under $10,000 to more than $120,000. Most belong to at least one professional organization. The demographic profile of LEOs is unusual, especially for a professional group. They differ from those of other local government employees. For example, according to U.S. Census figures, while women comprise a higher proportion of the local government workforce than men overall, men comprise a higher proportion of local government general and administrative managers. About 20% of those managers are members of minorities. The patterns do not appear to be a result of the fact that most LEOs are elected, as the demographic characteristics of legislators appear to be largely similar to those for local government managers. The average tenure in the current position declined by about one year from 2004 to 2008, with the proportion of LEOs who had served for two years or less in their current positions rising to 18% in 2008 from 11% in 2004 (see Figure 4 ). Thus, there appeared to be a small increase in job turnover over the three elections. However, there was no significant change in average age ( Figure 5 ). Other trends across the surveys included a decrease in the proportion of LEOs who were elected, an increase in both the percentage who worked full time and in the amount of time they spent working on elections, an increase in salary, and a decrease in the proportion who expressed a slightly to strongly conservative ideology.  The survey was not designed to identify the causes of such changes, but at least some appear to be consistent with the impacts of federal and state election reform on local jurisdictions. That reform led to increased funding for election administration, changes in voting systems used by many jurisdictions, and an increased workload for many election officials. For example, the survey found that those who reported that they worked full-time on election administration increased from 66% in 2004 to 72% in 2008, while those who reported that they spent more than twenty hours per week on election duties increased from 41% to 49%. The increasing complexity of elections and the increased federal role after the passage of HAVA have focused more attention on the role of professionalism in election administration. Given that change, it might be expected that election officials who began serving more recently would have more formal education than those who have served for longer periods. Such a pattern could yield a statistical association between the highest education level attained and the number of years in service as an election official. In fact, there was a small but significant relationship, with LEOs who did not have a college degree averaging 11-12 years of service and those with graduate degrees averaging 8-9 years. However, there was no significant change in the overall distribution of maximum education level over the three surveys ( Figure 6 ). Reported salaries of LEOs increased about 7% per year, from an estimated average of $45,000 in 2004 to $51,000 in 2008 ( Figure 7 ). LEOs in jurisdictions with larger numbers of voters tended to have somewhat higher salaries and education levels, and were more likely to be male. In 2008, the median salary for LEOs in jurisdictions below the median size in numbers of voters was $40-50,000; it was $50,000-$60,000 for LEOs in larger jurisdictions. More than 20% of LEOs in larger jurisdictions had attended graduate school, while 10% of those from smaller jurisdictions had. LEOs were male in about 20% of jurisdictions below the median size, and in 30% of those above. The survey also examined other factors related to election administration as a profession. More than two-thirds (70%-74%) of LEOs reported belonging to at least one professional association. Of those, more than three-fourths belonged to a state association, 30% to a regional one, and about 20% to the three major national or international associations (see Figure 8 ). Altogether, about 40% of LEOs who belonged to at least one association were members of a national or international one, with more than half belonging only to a state or regional association.  In 2006, the percentage of LEOs reporting that they had a written job description was 43% for those who had been elected and 70% for those who had been appointed. Most LEOs reported a broad range of election-administration responsibilities beyond solely running elections. Most are also responsible for budgeting, personnel, and purchasing, for example ( Table 2 ). Most LEOs received some initial training specifically designed to prepare them for their duties, but for most that training was less than 20 hours, and only one-fifth of LEOs were required to pass an examination ( Table 3 ). Most have also received additional training beyond that initially provided. More than two-thirds of LEOs assessed that their training was good to excellent and resulted in moderate to substantial improvement in their effectiveness and ability to solve problems. More than four-fifths believed that training and experience are equally important in ensuring a successful election. This result, shown in Figure 9 , might reflect the impact of HAVA requirements, most of which went into effect in 2006. For example, election officials might have felt less well prepared by their training to implement HAVA in 2006 than in 2004, but the survey did not address that possibility. Other possible factors include increasing public attention to problems in election administration, and recent controversies about the reliability and security of voting systems. Two-fifths of respondents to the 2006 survey, and a third of 2008 respondents, commented on what kinds of additional training would be useful. The most common suggestions were for more training in technical and legal aspects of elections, and more \"hands-on\" training. Given the increasing role of technology in elections, the surveys asked LEOs questions about their attitudes toward technology ( Figure 10 ). Respondents believed that technology can be useful for government services, but were cautious about implementation.  In 2004, more than half of jurisdictions used lever machines, punchcards, hand-counted paper ballots, or central-count optical scan (CCOS) as their primary voting systems. By 2008, that percentage had fallen by almost half, with lever machines decreasing by almost two-thirds, paper ballots by half, CCOS by one-quarter, and punchcards virtually disappearing by 2006 (see Figure 11 ). The proportion of jurisdictions using central-count optical scan (CCOS) decreased by almost half from 2004 to 2006, but that decline reversed in 2008.  Jurisdictions using PCOS and DREs increased substantially from 2004 to 2008, with a 50% increase for PCOS and more than two-thirds for DREs. From 2006 to 2008, respondents reported a 5% increase in PCOS and a similar decrease in DREs, although those changes were not statistically significant.  The observed patterns are consistent with results from other sources. The trends conform with expectations arising from HAVA requirements that emphasized improved usability, including prevention and correction of errors by voters in marking ballots, and accessibility of voting systems. The increase in use of CCOS from 2006 and 2008 appears to run counter to that explanation, because unlike PCOS and DRE systems, CCOS does not provide assistance to voters in preventing errors. The cause of the increase is not clear, but two possible factors are the increase in \"no-excuse\" absentee voting (see the section on \" Election Administration Issues \") and the controversy about the security and reliability of DREs that have led many states to adopt paper-ballot requirements.  The average length of time jurisdictions have been using a particular kind of voting system varies greatly with the kind of system ( Figure 12 ). The average length of use varies with the length of time a voting system has been available for use. At one extreme, jurisdictions with hand-counted paper ballots have used them for 80 to 100 years, on average. At the other, jurisdictions with DREs have had them under 10 years, on average. The pattern of use shown in Figure 12 suggests that jurisdictions do not readily change the kinds of voting systems they use. Before the 1990s, fewer than 10% of jurisdictions used optical scan and DRE voting systems. On the one hand, such reluctance to change creates stability that may be beneficial to voters and administrators. On the other hand, it may mean that a particular kind of technology is used far longer than it should be, with increasing risks of negative consequences. For example, many of the problems associated with the 2000 presidential election were attributed to the continued use of outmoded or flawed technology, such as the punchcard systems in widespread use at the time. The causes of such long-term use patterns are complex and may include factors such as legal and budgetary constraints and various forms of transaction costs that would be incurred with any change. Such factors, if they continue to be important, may impede jurisdictions from taking advantage of the kinds of improvements that are likely to occur in voting technology over the next decade. In 2008, LEOs were asked about the voting systems they used to meet the HAVA accessibility requirement. The options presented were (1) an electronic ballot marking device (BMD), which uses a touchscreen or other computer interface to mark an optical-scan ballot; (2) a DRE; (3) a vote-by-phone voting system, in which the voter uses an automated telephone system to fill out the ballot; and (4) some other system, which the LEO was asked to describe. As Figure 13 shows, the kinds of accessible voting systems used varied depending on the kind of primary voting system used in the jurisdiction. About 40% of responding jurisdictions reported using DREs as their accessible systems. Not surprisingly, most of those also used them as their primary systems.  A slightly lower percentage of respondents, 37%, reported using BMDs for accessibility, and it was most commonly used in lever-machine jurisdictions. While most optical-scan jurisdictions might be expected to use BMDs, only about half reported doing so. About 12% of jurisdictions used vote-by-phone, with the majority of those having hand-counted paper ballots as their primary system.  Three-quarters of jurisdictions reported having one accessible machine per polling place. About one-fifth used two, and about one in 20 used three. Most LEOs reported that voters without disabilities used accessible machines less than other machines, and about 40% reported that they used them much less. In jurisdictions using DREs as the accessible machines, the differences were less on average than in those using other technology (see Table 4 ). Some observers have argued that accessible voting systems should not be limited to use by voters with disabilities, because that would provide a way for election officials to determine the ballot choices made by that class of voters; it would therefore deprive them of the same degree of ballot secrecy that other voters have.  Most LEOs play a role in decisions on what voting systems to use in their jurisdictions (see Table 2 ). Many other stakeholders may also influence those decisions. To help provide an understanding of how LEOs assess the appropriateness of the roles other stakeholders play, the survey asked respondents to what extent they agreed or disagreed with statements about the influence of those stakeholders on the decision-making process. Two examples are \"The federal government has too great an influence,\" and \"Local level, elected officials should have greater influence.\" The results are presented in Figure 14 . On average, in fact, LEOs felt more strongly about the role of local elected officials than any other stakeholder. LEOs were largely neutral about the level of influence of state election officials and the public, and did not believe that nonelected officials, professional associations, and independent experts should have greater influence than they do now. Some of the differences among the surveys are notable. As Figure 14 shows, in 2004, LEOs were largely neutral about the influence of the media, political parties, and various advocacy groups. In 2006 and 2008, they thought those groups had too much influence. Also, in 2004 LEOs did not believe on average that vendors had too great an influence. That changed in 2006, when most believed that vendor influence was too high, and that number increased again in 2008.  In contrast, in 2008 LEOs were much less convinced than in 2004 and 2006 that professionals, experts, and nonelected state and local officials should not have greater influence. Their views did not change significantly on the roles of the federal government, elected state officials, local elected officials, and the public over the three surveys. In 2008, LEOs were also asked whether cost has too great an influence on the process of selecting voting systems. They agreed on average that it did, and the strength of that view was about the same as for the media, advocates, political parties, and vendors.  Overall, the observed patterns of response are not surprising. Support for greater influence by local elected officials is expected, because LEOs generally either report to elected local officials or are elected themselves. However, for some questions, elected LEOs and appointed ones had somewhat different views. The support of elected LEOs for greater influence by local elected officials was 20% higher than that of appointed LEOs; support for greater influence by state elected officials and the public was 5%-10% higher. Elected LEOs were 20% less supportive of influence by unelected officials, and 5%-10% less supportive of influence by the federal government, professional associations, and independent experts. The concerns of local officials about the influence of the federal government are well-known in many areas, not just election administration, and many local officials may have resented the HAVA requirements that led to changes in long-used voting systems. The concerns of LEOs about federal influence have not abated, despite improvements in the attitudes of LEOs about HAVA (see \" The Help America Vote Act (HAVA): Impacts\u00a0and\u00a0Attitudes \" below). Also, it is not surprising that LEOs have become more concerned about the roles of stakeholders such as the media, advocates, and political partisans, who are closely associated with the recent controversies about the reliability and security of voting systems. There has also been debate and uncertainty specifically about the role and influence of voting system manufacturers and vendors in the selection of voting systems by local jurisdictions. Some observers have argued that vendors have undue influence in what voting systems jurisdictions choose. Others believe that such concerns are unwarranted. But little has been known previously of how LEOs actually view vendors and their relationships with them. The results of the 2004 survey were mixed with respect to the importance of vendors. (These results are from more detailed questions on factors influencing the acquisition of voting systems that were not included in the 2006 or 2008 surveys.) LEOs in 2004 appeared to have high trust and confidence in vendors but did not rate them as being especially influential with respect to decisions about voting systems\u2014a view that changed over the next two surveys. Fewer than 10% in 2004 believed that there was insufficient oversight of vendors by the federal government and states, but about one in six believed that local governments did not exercise enough oversight. Most jurisdictions using computer-assisted voting reported in 2004 that they had interacted with their voting-system vendors within the last four years. More than 90% of LEOs considered their voting system vendors responsive and the quality of their goods and services to be high. They felt equally strongly that the recommendations of those vendors could be trusted. However, about a fifth of respondents thought that vendors were willing to sacrifice security for greater profit, although 60% disagreed. Also, a quarter felt that vendors were used for too many elements of election administration. When LEOs were asked in 2004 what sources of information they relied on with respect to voting systems, state election officials received the highest average rating, with about three-quarters of LEOs indicating that they rely on state officials a great deal. Next most important were other election officials, followed by the federal Election Assistance Commission (EAC) and advocates for the disabled. About one-third of LEOs stated that they relied on vendors a great deal, a level similar to their stated reliance on professional associations. Only 2% of LEOs rated vendors higher than any other source, whereas 20% rated state officials highest. Interest groups were rated lower than vendors, and political parties and media received the lowest ratings. When LEOs were asked in 2004 about the amount of influence different actors had on decisions about voting systems, the overall pattern of response was similar to that for information sources. Once again, state, local, and federal officials were judged the most influential, and political parties and the media the least, with vendors in between. An exception was that local nonelected officials were considered less influential on average than vendors. Both voters and advocates for the disabled were rated as more influential on average than vendors. No LEOs rated vendors as more influential than any other source. Those results contrast with the views of LEOs described above about whether the levels of influence of stakeholders were too little or too great in 2004 ( Figure 14 ). Of the three actors considered most influential, LEOs believed that local elected officials should have more influence and the federal government has too much, and they were neutral about state officials. They did not believe on average that those considered least influential should have more influence.  LEOs had strong opinions about the different kinds of voting systems used in the United States. Those whose jurisdiction used a particular kind of system, whatever it was, supported its use more strongly than any other system (see Figure 15 ). Thus, users of lever machines strongly supported their use, were fairly neutral about DREs and optical scan systems, and were opposed to the use of punchcard and hand-counted paper ballot systems.  In general, except for those using them, LEOs opposed the use of lever machines, punchcard systems, and paper ballots; supported the use of optical scan systems; and were neutral about DREs. Those views changed little across the three surveys. However, support of nonusers for DREs declined across the three surveys, from supportive to neutral. For other voting systems, the levels of preference were fairly consistent. From 2004 to 2006 there was a slight but significant decrease in the level of support for DREs among users of those systems. DREs were the only voting system for which support of users dropped across the first two surveys, although it still remained very high. It was not possible to determine if the change in support for users of DREs resulted from changes in the views of long-time users or from lower initial support among those who used DREs for the first time in the 2006 election. Whatever the cause, the decline reversed with the 2008 survey.  In 2008, LEOs were also asked about their support for vote-by-phone systems, which are used in several states to meet HAVA's accessibility requirements. Overall, three-quarters of LEOs opposed the use of such systems, and under 10% supported their use. However, opposition was not as strong in states using such systems, where about half of LEOs opposed their use and one-quarter supported it. These systems were only recently adopted, and it was not possible to determine to what extent experience with them influenced the attitudes of LEOs toward them.  Overall, and consistent with the above results, LEOs reported a high level of satisfaction with their voting systems in all three surveys and assessed that the systems performed very well during the election preceding each survey. On a scale of 0-10, average ratings were 8 or higher for each of those questions in all three surveys ( Figure 16 ). However, ratings for satisfaction with and performance of all systems except lever machines were significantly lower in 2006 but rebounded in 2008 to levels that were closer to the ratings in 2004. LEOs still rated DREs lower in 2008 than they had in 2004. There was no difference in ratings across the surveys for lever machines in either satisfaction or performance. In 2008, LEOs were asked to assess their degree of satisfaction with the performance of their accessible voting systems. Those ratings, with an average rating of 6.5 on a scale of 0-10, were lower than the ones for satisfaction with the primary voting system ( Figure 17 ). Among the different kinds of accessible system (DRE, ballot-marking device, vote-by-phone, and other), users of DREs were the most satisfied, with an average rating of 7.2. However, even LEOs who also used DRE as their primary voting system were less satisfied with their system in its accessibility performance (7.9) than in its overall performance (8.5).  LEOs who used DREs and precinct-count optical scan systems were more satisfied with them in 2004 than LEOs who used lever machines, paper ballots, or central-count optical scan, but in 2006 and 2008, there were no significant differences in satisfaction among users of different voting systems. However, users of PCOS systems were slightly more satisfied overall than users of either CCOS or DRE systems. There were also no significant differences in rated performance of different voting systems in any of the three surveys. To assess more directly how LEOs rated their own voting systems in 2006 and 2008, they were asked whether their current system is the best available, and what voting system they believed is best overall. About 80% agreed with the statement that their current voting system is the best available. The level of agreement among users of hand-counted paper ballots was lower than average and that of PCOS users was higher than average ( Figure 18 ). The same percentage believed that their current voting system was the best overall in 2006, with a significantly higher percentage of PCOS users holding that view than users of other systems.  In 2008, LEOs were asked to rank different types of voting systems in order of preference. Not surprisingly, the highest average preference by far was for the current voting system used in the jurisdiction\u2014about three-quarters of LEOs chose that as their top preference\u2014and the lowest was for Internet voting. More than half of PCOS users chose CCOS as their second preference, and more than half of CCOS users ranked PCOS second.  To further assess voting system preferences, the surveys asked LEOs to assess their primary voting systems on fifteen specific characteristics ( Figure 19 ). The high ratings for accuracy, security, reliability, and usability varied little among the different kinds of voting systems in each survey and changed little across the three surveys. Ratings for usability were slightly lower in 2006 and 2008 than in 2004, although those for multilingual capacity, which is a component of usability, were higher.  As the figure shows, for other characteristics, there were substantial differences in many cases both among voting systems in a survey and for a given voting system across the surveys. For most of those characteristics, LEOs were less happy with the performance of their voting system in 2006 and 2008 than in 2004, especially with respect to optical scan and DRE systems, which they rated lower for cost, size, storage requirements, and machine error in the second and third surveys. Optical scan systems, both central- and precinct-count, were rated higher for accessibility in 2006 and 2008 than in 2004. The reasons for this change are not clear. All systems were rated poorer for machine and voter error in 2006 and 2008\u2014LEOs switched from positive to more neutral about these performance characteristics. It was not surprising that DREs received the highest ratings of any system for accessibility and ability for use in multiple languages, or that hand-counted paper ballots were rated lowest for counting speed. Some of the comparisons among voting systems, however, did yield surprising results. In particular, the ratings for reliability, security, accuracy, and ease of use by voters were very high and were similar for all voting systems. Given media reports about problems with the reliability and security of electronic voting, somewhat different outcomes might have been expected\u2014namely, that DREs would have been rated lower in reliability and security. Also, given that modern DREs are often described as more voter-friendly than other systems, and certainly have the capability of providing higher levels of usability than other types, the lack of difference in ratings for usability is somewhat surprising.  With respect to accuracy, a lower rating might have been expected for punchcards, given the difficulties with recounts that were prominent during the 2000 presidential election. It is possible that such confidence exists because few jurisdictions use punch cards now, and those that still use them declined to replace them after 2000. Those jurisdictions kept the system, despite intense negative media coverage of system limitations, and opted not to take part in the punchcard buyout program offered through HAVA. The relative lack of difference in ratings of optical scan and DRE systems for acquisition and maintenance costs, and size and storage requirements, appears to run counter to widely held views. Many observers regard DREs as the most expensive voting systems, given that several machines may be needed for each polling place, whereas optical scan systems usually require one machine per polling place (PCOS) or none (CCOS). These differences from expectation suggest that LEOs' perceptions of how their voting systems perform may differ substantially in some ways from views about those systems that have often been depicted by the news media and activists. If the perceptions of election officials are accurate, then several of the criticisms leveled at specific voting systems could lead, if acted upon, to unnecessary and even counterproductive regulation and expenditure. For example, if in fact there is little difference in security between an optical scan system and a DRE, then the requirements for voter-verified paper records of votes that many states have imposed may be unnecessary. If, however, LEOs' perceptions are inaccurate, then understanding and addressing the causes of those inaccuracies may be beneficial. Unfortunately, the survey data do not permit an assessment of which interpretation is correct. Much of the recent controversy about election reform has focused on electronic voting systems. Questions about the security and reliability of those systems were a relatively minor issue until 2003. Two factors led to a sharp increase in public concerns about them: (1) HAVA promoted the use of both PCOS and DREs through its provisions on preventing voter error and making voting systems accessible to persons with disabilities; and (2) the security vulnerabilities of electronic voting systems, especially DREs, were widely publicized as the result of several studies released beginning in 2003. The surveys asked several questions designed to elicit the views of LEOs about aspects of that controversy. When asked in 2006 whether current federal and state guidelines and standards about electronic voting systems (both optical scan and DRE systems) are at the right degree of strictness, most LEOs\u2014about 60%\u2014replied in the affirmative. Those who did not were fairly evenly split among officials who believed that the current standards are too strict and those who believed they were not strict enough. There was no significant difference in the average assessment between users and nonusers of electronic voting systems, but nonusers were slightly more likely than users to believe that the standards were either too strict or not strict enough ( Figure 20 ). In all three surveys, LEOs were asked to what extent they agreed with several statements about DRE and optical scan systems. In 2004 those questions were asked of all LEOs, but in later surveys they were asked only of those who used DREs and optical scan as their primary voting systems. Also, two questions asked in 2004 were not asked in 2006 (see Figure 21 and Figure 22 ).  Not surprisingly, the opinions of nonusers of either kind of system were generally less strong than those of users. Nonusers were neutral on average with respect to several statements about DREs, including their level of knowledge about the systems, vulnerability to tampering, and the need for more public trust. LEOs whose primary voting systems were precinct-count optical scan were more neutral about DREs than were users of other voting systems. Users of DREs, in contrast, generally agreed that they had sufficient knowledge about the voting system, that certification procedures were adequate, that DREs are not vulnerable to tampering and security concerns can be addressed with good procedures, that the public should have greater trust in DREs, and that the media report too many criticisms of that voting system. Those views were similar in both surveys. Nonusers were less neutral about optical scan (OS) systems, but users nevertheless held stronger views than nonusers about these systems, except for the statement about media criticism, about which both users and nonusers were neutral on average in 2004. User beliefs about the media were similarly neutral in 2006, but in 2008, they believed that the media were overly critical. LEOs whose primary voting systems were DREs were less neutral about OS systems than users of other voting systems. The controversy about the security and reliability of DREs has led to widespread calls for the adoption of a paper trail of the ballot choices that a voter can verify before casting the ballot. These paper trails, printed as separate ballot records that the voter can examine, are usually called voter-verified paper audit trails, or VVPAT. LEOs whose primary voting system is a DRE were asked several questions in the surveys about VVPAT. The percentage who used them increased from 18% in 2004 to 36% in 2006 and 46% in 2008. In 2006, about 36% of LEOs whose jurisdictions used DREs as their primary voting system stated that voters who did not wish to use a DRE had the option of using a paper ballot instead. That number increased to 44% in 2008. However, it was not possible to determine which of those jurisdictions permitted that choice in the polling place rather than through the use of \"no excuse\" absentee balloting. Given concerns about the auditability of ballots recorded on DREs, users of DREs and OS systems were also asked in 2008 whether they agreed that in close elections the system they used was more open to questions about accuracy than other systems. DRE users were neutral on average about that statement, but OS users disagreed. About 100 LEOs reported in 2008 that they had recently switched from DREs to another voting system, mostly PCOS. About half of those who switched were more satisfied with their current than their previous voting system, a quarter preferred the DREs, and the rest were neutral about the switch. The most common reasons given for the change were a mandate from the state and the lack of a paper ballot with DREs.  About two-thirds of LEOs who did not use DREs supported a VVPAT requirement in 2004 and 2008, whereas one-third or fewer of users did.  Fewer than one in five LEOs who used DREs in 2004 believed they should have VVPAT. That number increased to one in three in 2008. The views of nonusers, however, did not change ( Figure 23 ). The views of DRE users varied depending on whether the machines used VVPAT ( Figure 24 ). Not surprisingly, LEOs who used DREs with VVPATs were more supportive of them than other DRE users, except in 2004, when there was no significant difference between the two groups. In 2006 and 2008, LEOs were also asked if they would be willing to use a VVPAT if reimbursed for the costs by the federal government, and about 60% answered in the affirmative. However, even those respondents (DRE users and nonusers) who expressed support for VVPAT in 2006 were generally willing (65%) to spend only $300 or less for the feature. LEOs were asked to choose one or more of several reasons for disagreeing or agreeing that DREs should produce a VVPAT. The results for DRE users are presented in Figure 25 . The most frequent reasons chosen varied across the surveys, but the risk of printer failure, the complexity of implementation, and risks to voter privacy were consistently among the most frequently chosen disadvantages, with about half of DRE users choosing them on average. Those LEOs appeared least concerned about risks of tampering. The degree of concern about potential disadvantages was highest in the 2006 survey and lowest in 2008. Only about one-third of LEOs chose any of the three potential advantages listed for this question in the 2006 and 2008 surveys\u2014recounts, checks on accuracy, and improved voter confidence. DRE users and nonusers differed strikingly in their views on the disadvantages and benefits of VVPAT. In 2008, DRE users expressed far greater concern about the disadvantages and far less agreement with the potential advantages than did nonusers ( Figure 26 ). The only exception was that neither group believed on average that risk of tampering was a significant concern in 2008. That was not the case in 2004, when concerns about tampering among users had been four times as high as among nonusers, consistent with differences in views for other potential disadvantages in that survey.  In 2008, LEOs with experience using VVPATs were less likely to express concerns about their disadvantages than were other DRE users and were more likely to agree with the potential advantages ( Figure 27 ). Their views were closer to those of LEOs who did not use DREs (see Figure 26 ). About three-quarters of LEOs who used a VVPAT were somewhat to very satisfied with it. About one-fifth were dissatisfied in 2006, and fewer than one in ten in 2008. More than four-fifths of LEOs had confidence in the accuracy of VVPAT, with fewer than one-tenth expressing concerns. More than two-thirds thought that voters reacted positively to them in 2006, but only half in 2008 ( Figure 28 ). Most LEOs, about 90%, considered themselves familiar with and knowledgeable about HAVA's requirements in the surveys. Those who were \"not familiar at all\" with HAVA decreased from 4% in 2004 to less than 0.1% in 2008. About 90% of respondents believed that almost all jurisdictions in their state were in full compliance with HAVA provisions in 2006. The strength of this view varied somewhat across the surveys ( Figure 29 ). The most favorable assessment was in 2008, and the least favorable in 2006. Also, in the first two surveys, about twice as many LEOs believed that the law resulted in no improvements than in major improvements, but the percentage choosing \"no improvement\" fell by more than half in 2008, while the percentage choosing \"major improvement\" was unchanged.  The views of LEOs in 2008 about the extent to which HAVA had improved elections nationally were similar to their views about local impacts. It might be expected that larger jurisdictions would find HAVA more beneficial than smaller ones, but in fact there was no association between the number of voters in a jurisdiction and how LEOs answered this question. However, the kind of voting system used did have an effect. In each of the surveys, DRE users rated improvements from HAVA highest, followed by users of PCOS, CCOS, and other systems.  Most LEOs regarded the major provisions of HAVA as advantageous. However, the average level of support varied among both the provisions and the surveys. LEOs were most supportive of federal funding and least supportive of the requirement for provisional voting and the creation of the EAC ( Figure 30 ). Provisional voting received substantially higher negative ratings than any other provision in the surveys, but the proportion of LEOs rating it as a disadvantage declined more than 40% from 2004 to 2008 ( Table 5 ). While remaining positive overall, the level of support decreased for seven provisions across the surveys, especially from 2004 to 2006. They were provision of federal funds, error-correction requirements, the certification process for voting systems, codification of voting-system standards in law, accessibility requirement, the requirement for state matching funds, and the creation of the EAC. However, even for the EAC, which, along with provisional ballots, had the lowest rating in 2008, half of LEOs regarded it as an advantage and fewer than one in seven as a disadvantage in that survey.  Decreased support for funding might have been caused simply by the decrease in availability of federal funds over the course of the three elections. Controversies about the security and reliability of different voting systems might have contributed to the decline in support for provisions relating to voting systems and the EAC.  There was no significant change for four provisions: facilitating participation for military and overseas voters, the requirement for centralized voter registration, the provision of information to voters, and identification requirements for certain first-time voters. Support for one provision\u2014the requirement for provision voting\u2014actually increased with each survey.  Support for HAVA's provisions also varied to some extent with the primary voting system used in the jurisdiction. DRE users exhibited the strongest support for the requirement on accessibility, provisional ballots, and military and overseas voters, and for the codification of standards. DRE and PCOS users expressed the strongest support for the error correction requirement.  Users of hand-counted paper ballots exhibited lower support than users of other systems for the provisions on federal funding, provisional ballots, facilitation of military and overseas voting, and the codification of standards. Nevertheless, all were regarded as advantages except provisional ballots, toward which users of paper ballots were neutral on average.  In general, LEOs reported in all three surveys that implementation of HAVA provisions was moderately difficult ( Figure 31 ). The level of difficulty for three provisions declined from 2004 to 2008: provisional voting, accessibility, and provision of information for voters. For one, the process for certification of voting systems, the reported difficulty of implementation increased. The other provisions exhibited no net change, although for voter identification and error correction, the perceived difficulty was lower in 2006 than in the presidential election years.  Not surprisingly, LEOs were less likely to support a provision they found difficult to implement. That is, there was an inverse relationship between the reported level of difficulty and the reported advantageousness of a provision. That pattern held for all provisions, but was most pronounced for provisional ballots, and least for the provision of information to voters.  Optical scan users found the accessibility requirement more difficult than did users of other voting systems. Perhaps surprisingly, DRE users did not find this provision significantly less difficult to implement than did users of hand-counted paper ballots, punch cards, or lever machines.  PCOS and DRE users found the voter error-correction requirement easier to implement than did users of other voting systems. That finding is consistent with the greater error prevention and correction features of those systems, although lever machines also possess error prevention features.  Users of paper ballots perceived the certification provision as less difficult to implement than users of other systems, as would be expected, given the acquisition of certified voting systems would likely be less important for them than for users of optical scan and DRE systems and lever machines in the process of being replaced. However, it is not clear why PCOS users reported similar levels of difficulty for that provision. Similarly, it is not clear why CCOS users found the voter registration requirement more difficult to implement than did users of other voting systems. Users of different kinds of systems did not differ in their assessments of the difficulty of implementing the provisions on military and overseas voters, provisional ballots, and voter identification. The decrease in support for most HAVA provisions across the three surveys may have resulted in part from perceptions about costs and funding. The importance of these factors is also supported by the responses to three questions in the 2006 and 2008 surveys: How has HAVA affected the cost of elections in your jurisdiction? To what degree is the funding your jurisdiction has received to implement HAVA requirements sufficient for their implementation? How concerned are you that limited funding in the future will leave you unable to comply with HAVA requirements for election administration? The results are presented in Figure 32 . About 90% of respondents in 2006 and 75% in 2008 believed that HAVA has increased the cost of elections, and only 2% believed the costs have decreased. LEOs were fairly evenly divided in both surveys on whether current funding is sufficient to implement the requirements, but most expressed concerns about the sufficiency of future funding, with 25%-30% stating that they were \"extremely concerned.\" LEOs were also concerned about the impact on election administration of the financial crisis that arose in 2008, with more than 60% indicating that they were moderately to very concerned, and only 4% reporting that they were not concerned at all.  LEOs were also asked in 2006 and 2008 to respond to a set of statements about the impacts of HAVA ( Figure 33 ). Their views changed significantly across the two surveys. They agreed on average in both that HAVA has made elections more accessible for voters, and they held that view more strongly in 2008. In 2006, they disagreed that the law has made elections fairer or more reliable, but agreed with those views on average in 2008. In 2006, they did not believe that HAVA requirements were inconsistent with state requirements, and they were neutral on average about that statement in 2008.  Their most strongly held view in both surveys was that HAVA has made elections more complex to administer. As Table 6 shows, responses to the statement on complexity of elections were the least evenly distributed, with about one-quarter to one-half of respondents expressing a neutral position. In 2008, LEOs were asked how much attention they thought Congress will pay to their views when considering legislation regarding election administration. In general, they appeared skeptical that their views would be heard ( Figure 34 ). About one in seven believed that Congress would pay no attention at all, and fewer than 3% believed that a great deal of attention would be paid. It could not be determined whether these views arose from their experiences relating to the development of HAVA or from some other source, such as a more general skepticism about government responsiveness. When HAVA created the Election Assistance Commission, the law gave it several specific responsibilities. The EAC carries out grant programs, provides for voluntary testing and certification of voting systems, studies election issues, and issues voluntary guidelines for voting systems and guidance for the requirements in the act. The EAC has no rule-making authority (other than very limited authority under the National Voter Registration Act, the \"motor-voter\" law, P.L. 103-31 ) and does not enforce HAVA requirements. In the 2006 and 2008 surveys, LEOs were asked about the EAC's responsibilities, helpfulness, and benefits. They were asked to rank the importance of the following four EAC responsibilities: Provide guidance to local election officials, Research issues related to election administration, Certify voting systems, and Ensure that local jurisdictions are in compliance with federal law. The results are presented in Figure 35 . LEOs regarded guidance to them as the most important of the listed responsibilities and ensuring compliance by them as the least. Research and certification were rated in the middle, and the ratings for them did not differ significantly. The results were consistent across both surveys. When asked in 2006 how many times the EAC had helped them understand or perform their duties during the previous year, about one third indicated that the EAC had helped at least once, and about 10% ten or more times.  The degree to which LEOs found the EAC helpful improved substantially from 2006 to 2008 ( Table 7 ). In 2006, almost half of LEOs had found the EAC not very helpful, with 13% finding it \"not helpful at all.\" In 2008, the proportion of more negative ratings dropped by more than half, with only about one-fifth finding the EAC not very helpful, and only 3% choosing \"not helpful at all.\" The proportion finding the EAC moderately helpful doubled, from about one-third to two-thirds. However, the proportion who found the EAC very helpful did not increase, but remained at about one-fifth.  LEOs were also asked how they had benefitted from the four functions listed above plus the distribution of federal funds for use by local jurisdictions. The ratings ( Figure 36 ) generally reflect the pattern seen in the responses on overall helpfulness. On average, LEOs responded that they had benefitted only moderately overall, but the average level of benefit for each category was higher in 2008 than in 2006. However, while they considered local guidance as the most important responsibility (see Figure 35 ), they rated it lowest in benefit, along with local compliance, which they regarded as the least important responsibility. About a quarter rated EAC guidance as \"not beneficial at all,\" with about 7% rating it \"extremely beneficial.\" Perceived benefits from research and certification were somewhat higher, and funding, not surprisingly, was rated highest. There might be several possible explanations for the discrepancy in the ratings for importance versus benefits of EAC guidance to local jurisdictions. For example, it could reflect frustration with the delays in the initial start-up of the EAC, an explanation that is consistent with the increase in ratings in 2008. It could reflect difficulties in understanding the guidance that the EAC issued. It might reflect the fact that the purpose of the guidance stated in HAVA is to assist states, not local jurisdictions, in meeting the title III requirements (\u00a7311(a)). Consistent with that explanation, when LEOs were asked in 2008 about guidance and compliance at the state level, they perceived each of those as being more beneficial than at the local level ( Figure 36 ). Or it could simply be an expression of opposition to or uncertainty about the requirements themselves. Individual comments from LEOs in 2006 and 2008 suggest a diversity of views about the EAC: - They need to move faster, the new system or changes to old systems need to get certified in a reasonable amount of time. - Much of the information received from the EAC either did not apply \u2026 or was already in practice for many years. - The EAC's information on their website can be very helpful. - My local jurisdiction does not really see anything from the EAC because the state usually takes care of it and then passes it on to us to comply. - EAC commissioners and staff are very well aware of their situation and environment. I work closely with them on a regular basis and know they are doing the best they can, as a federal agency with no enforcement powers\u2026. - I would like for the EAC to work more with states to have equipment certified and power to enforce that certification. I also wish the EAC members did not change so often\u2014it takes a long time to learn\u2026. - Exempt cities or other entities with less than 2,000 voters from the very expensive HAVA equipment requirements. - Get rid of it. Elections \u2026 should be free of federal control. - I believe they need more power to correct election problems. HAVA required each state to implement a statewide, computerized voter registration list before the 2006 election. A few states were unable to meet that deadline, and that is reflected in the survey, with 6% of respondents indicating that their states had not yet met the requirement in 2006, and 4% in 2008. Most LEOs were familiar with their state's database, with about a third assessing themselves as \"very familiar\" in 2006. Given the concerns expressed in the first survey about the burdens of HAVA implementation, the second survey asked LEOs whether the implementation of the computerized list had required the hiring of additional staff in the local jurisdiction. Four-fifths responded that it had not. Those that did hire additional staff were asked to identify all sources of funds. More than three-quarters received funding from local governments ( Figure 37 ), with about 70% receiving only local funding. To explore perceptions about the effectiveness of the computerized statewide voter registration database, LEOs were asked about security, accuracy, and contingency plans in case of failure on election day. Respondents were very confident about each ( Table 8 ).  LEOs were also asked about their agreement or disagreement with a series of statements about the voter registration database. The responses ( Figure 38 ) are generally consistent with the responses to the questions on accuracy and security. Most LEOs did not believe that the database could be accessed by unauthorized people or manipulated improperly. They did not believe it created problems for legitimately registered voters, and did not see challenges from political parties and others as a significant problem.  They were less concerned about reliability, administrative burden, matching problems, inadvertent removal of voters, and identity theft. Their views on security were unchanged. They continued to believe that the new databases were to some degree an improvement over the previous systems and were somewhat more accurate and fair. They remained neutral on average about whether the new systems would reduce the need for provisional ballots. However, for this statement, although not for any of the others, the number of voters in the jurisdiction had a significant impact. LEOs with larger jurisdictions were more likely to believe that the new databases reduced the need for provisional ballots than were those with small jurisdictions. In 2008, LEOs were asked about their use of electronic pollbooks, which provide immediate electronic access to the state's voter registration database at the polling place. About one in six reported that they used them. About two-thirds of those reported that electronic pollbooks were better than paper registers in resolving issues about voter eligibility ( Figure 39 ). About 10% considered them worse, and the rest were neutral.  Issues relating to voter identification have been controversial. HAVA requires that first-time voters who register by mail must present a specified form of identification, either when registering or when voting. The law does not require photographic identification, although a few states have such requirements, and many states require some form of identification document. About two-thirds of LEOs reported that their jurisdictions required some form of document identification from all voters. About one-third of jurisdictions used signature comparisons. Roughly one-quarter permitted the voter to provide identification verbally via some form of personal information, such as name and address ( Figure 40 ).  One of the principal policy arguments often cited for tightening voter-identification requirements is concern about the risk of significant levels of voting by ineligible voters. Opponents counter that those risks are small and that requiring identification, especially photo IDs, would effectively disenfranchise many eligible voters who would have difficulty obtaining such documents. To help determine the views of LEOs about this issue, the surveys asked several additional questions about voter identification: As a local election official, how supportive are you of requiring all voters in your jurisdiction to provide valid photo identification? How often do non-eligible persons attempt to vote in your jurisdiction, either in person or by absentee ballot? Do you agree or disagree that deliberate voter fraud is a serious problem in your jurisdiction? Do you believe that requiring photo identification of all voters would make elections more secure, less secure, or have no impact on election security? Do you believe that asking for photo identification of all voters would increase turnout, decrease turnout, or have no impact on turnout? The results are presented in Figure 41 . On average, LEOs mildly supported a requirement for photo identification. However, about 30% of respondents chose \"extremely supportive,\" 5%-10% \"do not support at all,\" and the choices of the other 60% were spread across the scale of possible responses. LEOs whose jurisdictions used hand-counted paper ballots were somewhat less supportive of photo ID than other jurisdictions, perhaps because those jurisdictions had many fewer voters on average than other jurisdictions (see Figure 49 below), and those LEOs therefore might be more likely to know voters personally. DRE users, who tended to have large jurisdictions, were more supportive on average of photo ID than were users of other systems. Two-thirds of LEOs also believed that requiring photo identification would make elections more secure. DRE users were more likely than users of other systems to believe that, but users of other systems did not differ significantly.  The support of LEOs for photo ID and their views about its impacts on security do not, however, appear to be based on concerns about ineligible voters or voter fraud, which few believed were problems in their jurisdictions. Furthermore, while about half of LEOs believed that requiring photo identification would have no impact on voter turnout, more than 40% believed that it would depress turnout. Views did not change greatly from 2006 to 2008. LEOs were slightly more supportive of photo ID in 2008 and somewhat more concerned about fraud, but they were significantly less confident that photo ID would improve the security of elections.  The results appear to suggest an apparent discrepancy between, on the one hand, the overall support of LEOs for photo ID and their average views about its effects on security, and, on the other hand, their views about impacts on turnout and the risk of voter fraud\u2014that is, they tended to support photo ID and believed it would increase security but at the same time they tended to believe that fraud was not a problem and that requiring photo ID would depress turnout. It is possible that however low the risk of fraud, LEOs believe reducing it outweighs any negative impact on turnout. Also, LEOs who supported photo ID were less likely than those who did not to believe that requiring photo ID would depress turnout, and they were more likely to believe that fraud was a problem and that photo ID would increase security. In any case, the range of perspectives in the responses to the questions shows that the controversy is not settled, even among local election officials. The 2006 election was the first under which all HAVA requirements were in effect. Consistent with the perception of LEOs that HAVA has made elections more complex to administer ( Figure 33 ), three-quarters found that they spent more time preparing for the 2006 than the 2004 election, and almost 90% reported spending more time in 2008 than 2006. For 2004 versus 2006, this perception was supported by comparing the number of hours per week LEOs reported spending on election duties. On average, the time spent increased 15%, from 21 to 24 hours. This difference may be especially significant given that 2006 was not a presidential election year, during which additional work may be required than in intervening elections. However, the time spent did not change from 2006 to 2008\u2014it was 24 hours in 2008 as well. There are several possible explanations for this discrepancy, and it was not possible to determine the cause. In 2008, LEOs were asked about voter education. About half reported that their jurisdictions had voter education programs intended to increase voters' knowledge of election rules and procedures. About 90% agreed that voter education about rules and procedures is important, and two-thirds that it is the responsibility of LEOs. About 60% believed that lack of voter knowledge creates problems in elections, and 80% that better voter education would improve the election-day process ( Figure 42 ). Support was somewhat weaker for all those statements, although still positive on average, among LEOs whose jurisdictions did not have voter education programs. The percentage of jurisdictions with voter-education programs varied with the kind of voting system ( Table 9 ). Fewer than 20% of those using hand-counted paper ballots had such programs, whereas most using DREs did. Similarly, paper-ballot users indicated lower support than users of other systems for the statements in Figure 42 , and they were neutral about whether educating voters is important or the responsibility of LEOs.  There have been several prominent issues of concern reported by the media in recent elections, such as voting-system malfunctions and problems with pollworkers, vendors, long lines, media coverage, and timely and accurate reporting of results. The surveys therefore presented a list of 16 potential problems and other events in 2006 and 2008 and asked LEOs to indicate which, if any, had occurred. The results are presented in Table 10 . About 65% of survey respondents in 2006 and 50% in 2008 reported experiencing at least one of the events listed in the table. In 2006, more than 100 LEOs reported five or more kinds of incidents, with a maximum of 11, and in 2008, more than 50 experienced five or more, with a maximum of 10. Not surprisingly, LEOs in more populous jurisdictions reported more events than those in less populous ones. In 2008, about 1 in 15 LEOs reported an \"uncontrollable\" event such as a fire or a power outage. In 2008 LEOs were asked to assess how successful the election process was in their jurisdictions. More than one-quarter reported a very successful process, and none considered it unsuccessful. However, the degree of success perceived was inversely related to the number of different types of incidents reported.  Given that 2008 was a presidential election, higher turnout was expected, and some variation in incidents might be related to whether a jurisdiction had higher turnout in 2008 than 2006. Seventy percent of LEOs reported higher turnout in 2008 ( Figure 43 ), and LEOs in jurisdictions using hand-counted paper ballots reported a greater increase in turnout than those using other kinds of systems. However, those reporting higher turnout were not more likely to experience incidents. About 65% of LEOs using DREs or PCOS as the primary voting system reported this problem. About 55% of CCOS users and about 40% of lever machine users reported this problem, with the lowest incidence, 20%, among LEOs using hand-counted paper ballots. There was no significant difference between the surveys in the incidence of this problem.  The reason for the low incidence among paper ballot users is not clear. It might be explained in part by the high proportion of those jurisdictions, about half, that used vote-by-phone to meet HAVA accessibility requirements (see Figure 13 above).  While DRE users reported a slightly higher incidence of malfunction (67% of those reporting at least one event and about 50% of all DRE users) than PCOS users (63% of those reporting at least one event and about 48% of all users), a larger difference might have been expected. In jurisdictions where DREs are the primary voting system, several might be used in each polling place, whereas in PCOS jurisdictions, typically only one OS machine is used. Therefore, the chance of at least one malfunction would be expected to be higher on average in jurisdictions using DREs. However, if DREs had lower failure rates per machine than optical scan systems, the difference would be correspondingly lower.  The results suggest that current optical scan systems may not be significantly more reliable than DREs. They also contrast strikingly with the uniformly high ratings all users gave for the reliability of their voting systems (see Figure 19 above). LEOs did not appear to assess the malfunctions as being the result of tampering. In fact, only one reported a system being hacked, in 2006, and that was a precinct-count optical scan user. About 10% of LEOs were disappointed in the level of support provided by vendors. Those LEOs were more than twice as likely to have experienced malfunctions of their voting systems as LEOs who were not disappointed with vendor support. In 2008, ballots were slightly longer on average than they had been in 2004, but half of LEOs reported no difference. More than half reported that confusing ballots were a problem for voters in their jurisdictions in 2008 ( Figure 44 ). About three-quarters believed that it would be beneficial to devote additional resources to ballot design. Not surprisingly, LEOs who were more concerned about ballot confusion were also more likely on average to believe that additional resources should be devoted to ballot design. About 40% of LEOs reported that they had little or no familiarity with ballot-design studies and best practices, about half were moderately familiar, and only about 10% reported a high level of familiarity.  Another notable result was the fairly high incidence of LEOs who reported excessively long lines at the polling place. About 11% of all respondents reported long lines in 2006, and 7% in 2008. The prevalence was much higher in jurisdictions using DREs primarily, occurring in about one quarter in 2006 and 14% in 2008. In those using other kinds of voting systems, long lines were reported by only about 5% of respondents in both surveys. Jurisdictions using DREs also reported more unfair media coverage (19% in 2006 and 7% in 2008) than users of other systems (5% in 2006 and 2% in 2008). The incidence of problems with accurate and timely reporting of election results was low. It did not differ among users of the different kinds of voting systems, except for lever machine users. They reported a much higher incidence, about 10%, of failure of polling places to report accurately in both surveys. That was about five times the rate of users of other voting systems.  Reports of deliberate election fraud of any kind were also few\u20148 LEOs in 2006 and 14 in 2008, under 1% of jurisdictions. Such a rate might nevertheless be considered unacceptably high, depending on such factors as the seriousness of the offense, the impact on the election of such attempts at fraud, and the degree to which election officials are able to detect all such attempts. In 2006, the number of elections requiring recounts that LEOs reported was much higher (264, which was 18% of all survey respondents and 27% of LEOs reporting incidents) than in 2008 (156, 12% of respondents and 23% of those reporting incidents). Not surprisingly, recounts were much more likely to be reported when a race was close. They were also more likely in jurisdictions using lever machines and hand-counted paper ballots than optical scan or DRE systems. LEOs noticed no change on average in residual votes (overvotes plus undervotes plus spoiled ballots) from 2004 to 2006. About 60% reported no change, and about 20% each reported an increase or a decrease. This result suggests that the decreased confidence LEOs had in 2006 in the ability of voting systems to reduce voter error was not a result of a noticeable increase in such error. Alternatively, the decrease in confidence might have resulted from sources such as changes in media coverage of voting-system problems. The number of provisional ballots used varied greatly among jurisdictions in 2006. About 30% of that variability was explainable by the number of voters in the jurisdiction. Thus, jurisdictions with fewer than 1,000 registered voters used about 10 provisional ballots on average and those with more than 100,000 voters used 1,500. Across all jurisdictions, one provisional ballot was used for every 140 registered voters on average. About a quarter of jurisdictions, mostly small, used no provisional ballots, and about 4% used more than 1,000, with a maximum of 15,000 reported by a jurisdiction with about half a million voters.  In 2008, LEOs were asked for the percentage of ballots cast that were provisional, rather than the number cast. About one-third used no provisional ballots. In about half of jurisdictions, some were cast but accounted for 1% or fewer of all ballots. In about 15%, they accounted for 1%-5% of all ballots, and in about 6% of jurisdictions, they accounted for more than 5%. About 2% of jurisdictions stated that at least one polling place had run out of provisional ballots during the election. The percentage of provisional ballots cast did not vary with the size of the jurisdiction. Also, 36% of LEOs reported an increase in the use of provisional ballots in comparison to 2006, while 26% reported a decrease.  When asked whether provisional ballots were easier to use than they had been in the previous election, LEOs found them slightly easier to use on average in 2006 and again in 2008. However, there was far more variability in the 2008 results, with higher proportions of LEOs finding them both easier and more difficult than in the previous election ( Table 11 ). The reasons for the increased variation are not clear.  The percentage of jurisdictions offering early voting increased from about half in 2006 to nearly two-thirds in 2008, and most LEOs reported that the number of early voters increased in 2008. In 2006, about a third each of jurisdictions offering early voting reported using optical scan, a third DREs, and fewer than one in ten paper ballots. In 2008, more than half used optical scan, with about a third offering CCOS and a quarter PCOS, while almost half used DREs and about one in six paper ballots. In 2008, a quarter of jurisdictions used two different kinds of voting systems for early voting, and a few offered three. Among those using more than one system, only about 10% did not use DREs. About half used CCOS and DREs, a quarter PCOS and DREs, and a fifth paper ballots and DREs. In 2008, a higher proportion of votes were cast early in jurisdictions using DREs as their main voting system (27%) than in those using other systems (14%) (see Figure 46 ). The rate of absentee voting has been increasing nationally over the last several elections, as the number of states offering early and \"no excuse\" absentee voting has increased. In both 2006 and 2008, 85%-90% of jurisdictions used only one kind of voting system for absentee ballots, with most of the rest using two, and a few three. About three-quarters of jurisdictions used optical scan systems, and about one-quarter used paper ballots. About 10% reported using DREs. In most cases these were for \"in-person absentee ballots,\" but in some cases, LEOs reported that election officials entered choices submitted on paper ballots into DREs.  The survey asked LEOs to provide information on the percentage of all votes cast by absentee voting in 2006 and 2008. The average reported was about 15% in each election, with 1%-5% being most common in both elections ( Figure 47 ). However, most LEOs reported that the number of absentee ballots increased in 2008. In contrast to early voting, CCOS jurisdictions had a higher proportion of ballots cast via absentee (26%) than did jurisdictions using other systems (13%) ( Figure 46 ). The overall average rate is very similar to the ones reported in the EAC's election day surveys (14.2% for 2006 and 17.3% for 2008).  In 2008, more than 95% of LEOs reported receiving requests for ballots from military and overseas voters. However, 62% also reported receiving voted ballots from such voters after the deadline for receiving ballots. Many LEOs provided suggestions for ways to improve participation by such voters, which varies by state. The most common by far was to permit greater use of electronic methods\u2014fax, e-mail, and Internet. Other common suggestions were more time for preparing, distributing, and processing ballots for such voters, improved training and awareness of voters and military personnel, and ways of improving the currency of address information.  Some observers have expressed concerns about early and \"no excuse\" absentee voting, arguing, among other things, that they do not increase turnout and that they pose some security risks. These concerns were largely not shared by LEOs ( Figure 48 ). About three-quarters agreed that absentee voting should be considered a voter's right, and about half that early voting should be. Most also agreed that absentee voting is worth the costs, and that verification of authenticity is not difficult for those ballots.  LEOs were equivocal about whether early voting was worth the costs in 2006 but supported it on average in 2008. Among users of different kinds of voting systems, lever-machine users were somewhat negative, DRE users were positive, and those using paper ballots and optical scan were neutral. All except lever-machine users believed on average that early voting should be a right, and users of all systems believed that absentee voting should be a right.  About 10% of jurisdictions experienced one or more instances of pollworkers not reporting for duty (see Table 10 above). Since the average jurisdiction used more than 150 pollworkers, the impact may be small on average (although not necessarily in the affected polling places). Nevertheless, absenteeism among pollworkers has been cited as a significant problem on election day. Factors that might contribute include long hours, low pay, poor training, and age or illness, but analysis of pay and training data from the survey did not point to those factors as being significant. About 20% of LEOs reported instances of pollworkers who did not understand their jobs. The lowest rate was in jurisdictions using hand-counted paper ballots. Results from LEOs using other kinds of voting systems were substantially higher, but did not differ significantly from one another. It seems unlikely that the differences between the results for paper and those for other voting systems arose purely from differences in the roles of technology in the different voting systems, since the technology-related tasks of pollworkers in jurisdictions using CCOS are unlikely to be much greater than those in jurisdictions using paper ballots. There are several other possible factors. For example, the average total number of pollworkers, polling places, and registered voters reported by LEOs is far lower for jurisdictions using paper ballots than for any other voting system (see Figure 49 ). Also, the quality of training and the background and experience of pollworkers are likely to vary among jurisdictions.  The 2006 and 2008 surveys included several additional questions about pollworkers. More than 95% of LEOs reported using one or more pollworkers, with a mean number of more than 200 in a jurisdiction and a maximum of more than 10,000. The number of pollworkers in the jurisdictions was strongly correlated with the number of registered voters reported, as was the total number of polling places. The kind of voting system used also varied with the number of registered voters. Overall, jurisdictions using hand-counted paper ballots had the smallest number of registered voters, polling places, and pollworkers, and those using DREs and lever machines the highest ( Figure 49 ). On average, there were 5-10 pollworkers per polling place. Jurisdictions using lever machines and DREs had the lowest number, and those using other voting systems did not differ significantly from each other. There were about 1,000 voters per polling place on average, with jurisdictions using paper ballots having the fewest, about 600. The pattern was similar for the number of registered voters per pollworker, with an overall average of 160, and 100 for paper-ballot jurisdictions.  While Figure 49 suggests that the number of registered voters, polling places, and pollworkers increased in 2008, the large variation among jurisdictions meant that the only statistically significant increase was for pollworkers per polling place, which increased slightly for PCOS jurisdictions.  Compensation of pollworkers also varied substantially. Respondents reported paying pollworkers $100 on average for work on election day. The results suggest that there is significant variation among the states, with averages ranging from a low of about $30 to a high of more than $200. Very few respondents reported paying nothing to pollworkers. Rates of pay did not vary significantly with the number of registered voters or type of voting system used, and it did not change significantly from 2006 to 2008.  Pay also did not vary with performance. LEOs who reported problems with pollworker performance paid them no less per day on average than those who did not. However, the survey did not explore potentially influential demographic factors such as age of pollworkers or average cost of living. Perhaps more surprisingly, the amount of training pollworkers received was also not associated statistically with reports of performance problems, in either survey. However, more LEOs than not believed that inadequate training was responsible for problems with election administration ( Figure 50 ), with DRE users expressing the most concern and paper-ballot users the least. Most also believed that training needs significant improvement ( Figure 51 ), with lever machine and DRE users expressing the most concern and paper-ballot users the least. The overall level of concern about the impact of inadequate training and the need to improve it was somewhat lower in 2008 than 2006. Not surprisingly, in both surveys LEOs who believed more strongly that inadequate training caused problems also tended to believe more strongly that improvements in training were needed.  In both surveys, 93% of LEOs reported that pollworkers received training, about two to three hours on average ( Figure 52 ). Seventy percent of LEOs considered pollworker training \"extremely important,\" and only a few considered it \"not important at all.\" The amount of training was about 20% lower on average for jurisdictions using paper ballots than other kinds of voting systems. In just under 10% of jurisdictions, training was 1 hour or less. In three quarters, it was 2-4 hours, and in only 5% was it one day or more.  In 2008, LEOs were asked their views about the best method for training pollworkers. Nine out of 10 believed that classroom training was most effective, with the rest preferring reading materials, Internet, or other methods, such as instruction at the polling place. There appeared to be substantial uniformity among jurisdictions in the areas in which pollworkers were trained ( Figure 53 ), with more than 90% being trained in voter check-in, accessibility, election laws, operation of voting machines, and election integrity. LEOs were not asked what areas of training should be improved, but another study that surveyed pollworkers in New Mexico found that many desired more training in voting-machine operation and election laws. Interestingly, that finding reflects the views of many LEOs about their own training, as discussed earlier in this report. LEOs also believed that HAVA is changing the nature of pollworker training, with 20% reporting that the changes were \"substantial.\" As reported earlier (see Table 6 and Figure 33 above), most LEOs believed that HAVA has made elections more complex to administer. In 2006, most also expressed concern that the increased complexity of elections would have a negative impact on recruitment of pollworkers, and more than a third of respondents were \"extremely concerned\" ( Figure 54 ). In 2008, most agreed with the statement that recruiting pollworkers was difficult, but nevertheless felt equally strongly that the number of pollworkers in their jurisdictions was adequate, and that the pollworkers had the necessary knowledge and skills to perform effectively. LEOs were also neutral about whether the increased technological complexity of voting systems has made it difficult for pollworkers to perform their election-day duties ( Figure 55 ). Users of hand-counted paper-ballot systems expressed the most positive views about their pollworkers. They felt most strongly that the number of pollworkers they had was adequate, and they were the only set of users who were neutral about the difficulty of recruiting pollworkers. DRE users might have been expected to have the highest concerns about pollworker knowledge and skills, but in fact lever-machine users expressed the most concern. HAVA established two programs to provide incentives for student participation in election administration, one for high school and the other for college students. To help identify what impacts those programs might have had, LEOs were asked in 2008 whether they had experienced an increase in high-school and college student volunteers. About one-quarter reported an increase ( Figure 55 ), but it could not be determined for this report which respondents were in jurisdictions that may have benefited from those programs. However, DRE users were the most likely to report an increase, and lever-machine and paper-ballot users the least likely.  Some observers have suggested that the environment in which election officials operate is too politically contentious and that steps should be taken to make election administration more nonpartisan. For example, some believe that state election officials should not be permitted to be involved in political campaigns other than for their own positions. The 2006 and 2008 surveys asked LEOs several questions about this issue. In general, LEOs were satisfied with election administration at the state level ( Figure 56 ), with only about 10% expressing significant dissatisfaction. More LEOs than not also believed that election administration in their state was independent of partisan politics. Those views did not change significantly from 2006 to 2008 and they did not vary depending on whether a LEO was elected or appointed.  In 2008, LEOs were asked whether the state role in local elections had changed in the last five years. Not surprisingly, three-quarters believed the state role had increased. About 60% of those who believed the state role had changed considered the effects of that change beneficial in their jurisdictions. There was more variation in the views of LEOs about the political contentiousness of the election-administration environment, with more believing it contentious in 2008 than 2006. LEOs who were appointed were more likely to find the environment contentious than those who were elected, although that difference was not significant in 2008. In 2008, LEOs were asked if the degree of contention had increased since the last election. While more than half believed there had been no change, a greater percentage believed it had increased than that it had decreased. About 40% believed that the political environment had made election administration more difficult, while half believed it had made no difference.  In 2006, LEOs were also asked whether election administration should be a civil service function in their state. About half had no opinion, but significantly more elected LEOs were opposed to the idea than favored it. Appointed LEOs were evenly divided ( Figure 57 ). As with all surveys, care needs to be taken in drawing inferences from the results. One question that could arise is whether the sample is representative of LEOs as a whole. For example, simply drawing the sample at random from the nationwide pool of election administrators would have resulted in a disproportionately large number of jurisdictions from New England and the upper Midwest, where elections are administered by townships rather than counties. Steps were taken in the design of the studies to minimize the risk that the sample would not be representative (see the Appendix ). Overall, neither the sample design nor the characteristics of the responses suggest that the results are unrepresentative of the views and characteristics of local election officials. Another potential caution for interpretation relates to the inherent limits of surveys such as these. In particular, there is no way to guarantee that the responses of the election officials correspond to their actual beliefs. In addition, there is no way to be certain that any particular belief corresponds to reality. The question on voting-system characteristics (see Figure 19 ) provides an illustration of the possibility for disparity. For several reasons, LEOs might be reluctant to rate their voting systems low in reliability, accuracy, and security, despite the anonymity of the results. Alternatively, they might truly believe that their voting systems are highly reliable, accurate, and secure, even if independent evidence does not support that view. Also, some caution is needed in assigning cause and effect. The mere existence of an association or correlation between a factor and an effect does not necessarily mean that the factor caused the effect. For example, the survey showed a strong association between the kind of voting system used in a jurisdiction and the number of pollworkers (see Figure 49 ). However, while the kind of voting system may have some independent effect, a more important factor is likely to be the number of registered voters. A final caution involves how survey results might be used to inform policy decisions. On the one hand, the results could be used to support the shaping of policy in directions expressed by LEOs in their responses. In many cases, such policy changes might be appropriate. On the other hand, it is possible that at least some of those desired changes would not in fact yield the most effective or appropriate policies. In such cases, the results might more constructively be used to help policymakers identify issues for which improvements in communication and understanding are needed. The survey results may have policy implications for several issues at the federal, state, and local levels of government. Some issues that may be relevant for congressional deliberations are highlighted below. Many observers have commented favorably on the experience and dedication of the nation's local election officials. Survey results are consistent with that view. At the same time, other observers, including some election officials, have called for increased professionalism in election administration. Some survey results suggest areas of potential professional improvement, such as in education and in professional involvement at the national level. Congress could address this potential need by several means, for example facilitating educational and training programs for LEOs and promoting professional certification of election officials by entities accredited through the EAC or a professional association. The seemingly unique demographic characteristics of LEOs as a group of government officials may have other policy implications, but they are not altogether clear. However, some observers may argue that efforts should be undertaken to ensure that LEOs reflect the diversity of the workforce or voting population as a whole, especially with respect to minority representation. The issue of partisanship among election officials has been controversial for several years. Most national attention has been on state officials, but, given that most LEOs are elected and only about half the local jurisdictions in the United States are administered on a nonpartisan or bipartisan basis, policymakers may wish to consider the influence of partisanship among LEOs. Since the enactment of HAVA, controversy has arisen over whether DRE voting systems are sufficiently secure and reliable. The survey revealed that LEOs who have experience with DREs are very confident in them, consider them superior for accessibility, and do not generally support the addition of a voter-verified paper audit trail (VVPAT) to address security concerns, although those who use a VVPAT are satisfied with its performance. However, LEOs using other systems are much less confident in DREs and more supportive of VVPAT. The strongly dichotomous results suggest that as Congress considers whether to require changes in the security mechanisms used in voting systems, it might be useful to determine whether DRE users are overconfident in the security of their systems and procedures in practice, or, alternatively, whether nonusers might be misinformed about the reliability and security of DRE systems. The survey results suggest that HAVA is in the process of achieving several of its policy goals. The general and increasing support of most HAVA provisions\u2014including those such as the creation of the EAC and the provisional ballot requirement that have been somewhat controversial\u2014implies that most LEOs are in agreement with the goals of the act and are active partners in its implementation. The overwhelming selection by jurisdictions of new voting systems that assist voters in avoiding errors indicates that the HAVA goal of reducing avoidable voter error is in the process of being met. The areas of concern expressed by LEOs\u2014such as how to meet the costs of ongoing implementation of HAVA requirements\u2014raise issues that Congress may wish to address as it considers HAVA appropriations and reauthorization.  The close relationship between LEOs and the vendors of their voting systems seems unlikely to change as a result of HAVA. However, with the codification by HAVA of the voting system standards and certification processes, the influence of the federal government in decisions about new voting systems might be expected to increase in relation to that of vendors and others. The increased concerns of LEOs in 2006 that vendors, media, political parties, and advocacy groups have too much influence on such decisions may bear consideration. Scientific opinion surveys of local election officials are rare, and additional research may be useful to address some of the matters raised by these studies. For example, a survey of state election officials might provide useful information and might additionally be helpful in assessing the most appropriate federal role in promoting the effective implementation of HAVA goals at all levels of government. One common suggestion of LEOs for improving HAVA was to provide a means of adjusting requirements to fit the needs of smaller jurisdictions. To determine what, if any, such adjustments would be appropriate, it may be useful to have specific information on how the needs and characteristics of different jurisdictions vary with size\u2014something that was beyond the scope of these surveys. It could also be useful to identify how the duties of LEOs vary with size and other characteristics of the jurisdiction. In many jurisdictions, election administration is only part of the LEO's job. It is not known to what degree these other responsibilities might affect election administration\u2014negatively or positively. Finally, these surveys have provided only snapshots of LEO characteristics and perceptions over three election cycles. It might be beneficial to perform similar surveys periodically to identify trends and explore new questions and issues. The results presented and analyzed in this report are from three surveys sponsored by CRS as part of its Capstone program and performed by graduate students and faculty at the George Bush School of Government and Public Service at Texas A&M University in 2004 and 2006, and the Department of Political Science at the University of Oklahoma in 2008. For both studies the CRS project manager was Eric Fischer and the project liaison was Kevin Coleman. The topics for the surveys were developed collaboratively by CRS and Texas A&M and University of Oklahoma participants. The major factor in choosing the topics was potential usefulness of the results for Congress. The Bush School and University of Oklahoma teams developed and administered the survey instruments in consultation with CRS and provided the authors with the data used in performing the analyses. The three surveys were conducted after the November 2004, 2006, and 2008 federal elections, between December and the following April. For each survey, a sample of approximately 3,800 LEOs was drawn from the roughly 9,000 election jurisdictions in the 50 states. To ensure that LEOs from all states were included, but that states with large numbers of LEOs were not disproportionately represented (see Figure A-1 ), a modified random-sampling regime was used, as follows: Surveys were sent to all LEOs in states with 150 or fewer local jurisdictions. For the ten states with more than 150 LEOs, a sample of 150 was chosen at random from the local jurisdictions, and surveys were sent to those LEOs. Each survey was initially distributed in the month following the election (December). Administration was mostly electronic, with respondents visiting a website to enter their responses. In cases where electronic administration was not possible, LEOs were sent paper surveys via the U.S. Postal Service. Those who did not respond were sent reminders or contacted by telephone, with the survey response period closing in March or April following the election.  For each survey, the overall final response rate was about 40% of the sample, or about 17% of all jurisdictions in the United States. Respondents answered 85%-90% of questions, on average. The response was sufficiently high to permit statistical analysis and comparison of the results among the surveys. The distribution of responses among states was similar across the surveys (see Figure A-2 ). Individual response rates per state were between 25% and 50% for about three-quarters of states. The remainder were evenly split between those for which under 25% of LEOs responded, and those for which the rate was greater than 50%. Response rates did not vary significantly for any survey with the number of local election jurisdictions in a state or its voting age population. About 70% of respondents worked in county election jurisdictions, with most of the remainder working in townships ( Figure A-3 ). The small difference among the surveys in those choosing \"town/township\" and in those choosing \"other\" was almost certainly a result of a small change in the structure of the question after the 2004 survey. However, as the figure implies, the proportion of respondents from county jurisdictions increased slightly over the course of the three surveys. All the results presented in this report are from analyses by CRS of data provided from the surveys by researchers at Texas A&M University (2004 and 2006) and the University of Oklahoma (2008). The raw data were first examined for errors, and corrections were made where necessary, in a few cases, such as if a LEO claimed to work more hours per week than is physically possible. Where the correct answer could be reasonably discerned, the response was corrected. Otherwise it was discarded. Once cleaned, the data were analyzed using standard parametric methods, mainly analysis of variance, linear regression, and Student's t-tests as appropriate. Three kinds of hypotheses were tested: differences between groups, such as whether results differed across the three surveys; differences from a hypothetical value, such as whether LEOs were neutral about, agreed with, or disagreed with a particular statement; and tests for associations, such as whether the number of pollworkers in a jurisdiction was correlated with the number of registered voters. Statistical significance was determined using a significance level (\u03b1) of .01. However, for display purposes, graphs with error bars were drawn showing 95% confidence intervals for the means. Most tests for which results are presented in this report yielded highly statistically significant results\u2014p-values much lower than the significance level (p << .01). For reported data where statistically significant effects were not found, the lack of effect is noted in the text, for example, by stating that no change was found between 2004 and 2006 for a particular survey item. Additional methodological details can be provided upon request."
}