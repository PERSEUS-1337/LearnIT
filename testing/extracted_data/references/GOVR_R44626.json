{
    "title": "R44626",
    "content": "The development of the Internet has revolutionized communications. It has never been easier to speak to wide audiences or to communicate with people who may be located more than half a world away from the speaker. However, like any neutral platform, the Internet can be used for many different ends, including illegal, offensive, or dangerous purposes. Terrorist groups, such as the Islamic State (IS, also referred to as ISIS or ISIL), Al Qaeda, Hamas, and Al Shabaab, use the Internet to disseminate their ideology, recruit new members, and take credit for attacks around the world. In addition, people who are not members of these groups may view such content and could begin to sympathize with or to adhere to the violent philosophies these groups advocate. They might even act on these beliefs. For example, it has been reported that the sermons of Anwar al Awlaki were instrumental in influencing the ideology of certain individuals accused of terrorist activities, including the perpetrators of the San Bernardino shooting and the Boston Marathon bombers. Awlaki was a U.S. citizen who was targeted and killed by a drone strike on foreign soil. Awlaki left behind numerous digital videos on websites like YouTube of himself preaching his interpretation of the Islamic faith. Some of his videos expound upon less controversial topics such as respect for the holy month of Ramadan, the nature of marriage, or the relationship between Islam and Jesus Christ. However, other videos depict Awlaki exhorting his followers never to trust a non-Muslim; that Muslims are at war with the United States; and, in a video entitled \"Call to Jihad,\" that \"it is every Muslim's religious duty to kill Americans.\" It was messages like these, particularly the \"Call to Jihad,\" that reportedly motivated the San Bernardino and Boston Marathon attackers.  More broadly, the Islamic State organization has been known to use popular Internet services such as Twitter and YouTube to disseminate videos of its fighters executing prisoners, claim credit for organizing terrorist attacks such as the attack that occurred in Paris in November of 2015, and recruit new members to their cause. IS personnel also disseminate high-quality electronic publications encouraging supporters to conduct violent attacks in their communities. Members of Hamas and Al Shabaab have reportedly used Facebook and Twitter to disseminate their ideology as well. The media arm of Al Shabaab used Twitter to claim credit for the terrorist attack on the Westgate Shopping Mall in Nairobi, Kenya, and distribute information and pictures of the attack while it remained ongoing. Speech advocating violence and terrorism is prohibited by the terms of service of Twitter, Facebook, and other social media outlets. Sites like Twitter reportedly have increased their efforts to disable accounts that are associated with terrorist groups or the advocacy of terrorist ideologies. However, these efforts have not been wholly successful. When one account is disabled, another might soon appear to replace it. Many policymakers, including some Members of Congress, have expressed concern about the influence the speech of terrorist groups and the speech of others who advocate terrorism can have on those who view or read it. Some policymakers have expressed particular concern regarding the ease by which persons who might otherwise not have been exposed to the ideology or recruitment efforts of terrorist entities may become radicalized. These concerns raise the question of whether it would be permissible for the federal government to restrict or prohibit the publication and distribution of speech that advocates the commission of terrorist acts when that speech appears on the Internet. Significant First Amendment freedom of speech issues are raised by the prospect of government restrictions on the publication and distribution of speech, even speech that advocates terrorism. However, government restrictions on advocacy that is provided to foreign terrorist organizations as material support have been upheld as permissible. This report will discuss relevant precedent that may limit the extent to which advocacy of terrorism may be restricted. The report will also discuss the potential application of the federal ban on the provision of material support to foreign terrorist organizations (FTOs) to the advocacy of terrorism and the dissemination of such advocacy by online service providers like Twitter or Facebook. The First Amendment to the Constitution states that \"Congress shall make no law ... abridging the freedom of speech.... \" According to the Supreme Court, \"the First Amendment [generally] means that government has no power to restrict expression because of its message, its ideas, its subject matter, or its content.\" However, the freedom of speech is not absolute. Some speech, including fighting words, incitements to imminent violence, child pornography, and obscenity can be restricted by the government without constitutional concern.  Furthermore, courts do allow the government to place restrictions on protected speech under certain circumstances. When a restriction applies to speech based upon its content or upon the viewpoint expressed, courts generally apply the highest level of scrutiny, known as strict scrutiny. In order to satisfy strict scrutiny, a speech restriction must directly advance a compelling government interest and it must be the least restrictive means for achieving that interest. It is rare that a law will survive this level of scrutiny. Generally, when a restriction is not directed at the content of speech or the viewpoint expressed, courts apply a less-exacting standard of scrutiny, known as intermediate scrutiny. Content-neutral restrictions on protected speech will be upheld if the government can show that the restriction advances a substantial government interest and is narrowly tailored to achieve that interest. In this way, the government is permitted to impose reasonable regulations on the time, place, and manner of speech. In Brandenb u rg v. Ohio , the Supreme Court held that the First Amendment can protect the advocacy of lawbreaking and violence. Brandenbu rg overturned a conviction under Ohio's criminal syndicalism statute, invalidating that statute. The statute, like other syndicalism laws, prohibited \"advocat[ing] ... the duty, necessity, or propriety of crime, sabotage, violence, or unlawful methods of terrorism.\" Members of the Ku Klux Klan had been convicted of violating that statute at a rally covered by a Cincinnati television station at the request of one of the Klan members. At the rally, among other incendiary comments, one of the members said \"We're not a revengent [sic] organization, but if our President, our Congress, our Supreme Court, continues to suppress the white, Caucasian race, it's possible that there might have to be some revengeance [sic] taken.\" Other statements advocating violence were made, as well.  The Supreme Court overturned the convictions at issue because \"the mere abstract teaching ... of the moral propriety or even moral necessity for a resort to force and violence is not the same as preparing a group for violent action\" and cannot be punished by the government in a manner consistent with the First Amendment. In order for speech inciting violence or lawlessness to fall outside of the ambit of the Free Speech Clause, the Court held that:  1. the speech must be directed at ... 2. inciting \"imminent lawless action\" and 3. the speech must also be likely to produce such action.  In other words, for punishment of speech advocating violence to be constitutional, the speaker must both intend to incite a violent or lawless action and that action must be likely to imminently occur as a result. In so holding, the Court invalidated Ohio's criminal syndicalism statute, reasoning that the statute failed to draw the distinction between \"mere abstract teaching\" and \"preparing a group for violent action\" and, therefore, swept too broadly. Consequently, in order for a statute that restricts the advocacy of violence or lawlessness to be constitutional, the statute must apply only to speech meeting the standard announced by the Court. As indicated by the Court in Brandenburg , speech that is intended to incite violent action and is likely to imminently produce such action is not protected by the First Amendment and may freely be proscribed by the government. However, the Court did not elaborate upon what it might mean for speech to be \"likely to imminently produce\" unlawful action. Therefore, it is unclear how imminent the violence advocated must be in order for speech to be able to be proscribed.  In Hess v. Indiana , the Supreme Court provided some guidance regarding \"imminence\" pursuant to Brandenburg . The defendant in Hess had been convicted of disorderly conduct. At an anti-war rally, he had been arrested for shouting \"[we'll] take the [expletive] street later.\" The Court overturned his conviction because his statement \"amounted to nothing more than advocacy of illegal action at some indefinite future time\" and his statements were not directed to any person or group of persons. In the Court's words, \"there was no evidence, or rational inference from the import of the language that his words were intended to produce and likely to produce imminent disorder.\"  Some argue that the Court's decision in Hess indicated the Court viewed the \"imminence\" requirement to mean that violence must be likely to occur immediately as a result of the speech at issue. The Hess Court apparently did not think that a threat to \"take the street\" at some later point was imminent or likely enough to be punished under Brandenburg .  However, state and federal courts have not always applied Hess or the imminence requirement of Brandenburg so strictly. For example, in People v. Rubin , a California state court ruling, Rubin was charged with solicitation of murder. During a press conference to protest a planned march by the Nazi Party through Skokie, Illinois, Rubin offered money to anyone who \"kills, maims, or seriously injures a member of the American Nazi Party.... The fact of the matter is that we're deadly serious. This is not said in jest, we are deadly serious.\" The trial court found that his speech was protected by the First Amendment, but the appeals court reversed. After reciting Brandenburg 's standard, the state appeals court held the defendant's speech was directed to inciting lawless action, and that such action was likely to imminently occur, even though the march in Skokie was not scheduled to take place until five weeks after the defendant had spoken. In justifying its holding, the court wrote that \"time is a relative dimension and imminence a relative term, and the imminence of an event is related to its nature.... We think solicitation of murder in connection with a public event of this notoriety, even though five weeks away, can qualify as incitement to imminent lawless action.\"  The only other Supreme Court case to apply the standard announced in Brandenburg was NAACP v. Claiborne Hardware . In that case, the Supreme Court overturned civil judgments against black defendants who had organized a boycott of white-owned businesses in a Mississippi town in order to protest discrimination and advocate for racial equality. According to the lawsuit, one of the defendants, Charles Evers, had advocated the use of violence to enforce the boycott against unwilling participants. Plaintiffs argued that Evers's advocacy of violence should make him liable to the plaintiffs for their losses resulting from the boycott. The Court disagreed, stating \"[this] Court has made clear ... that mere advocacy of the use of force or violence does not remove speech from the protection of the First Amendment.\" The Court specifically noted that Evers's speech primarily consisted of a plea for black people to unify wherein strong language was used that might have been construed as advocacy of violence. While the Court noted that \"a substantial question would be presented whether Evers could be held liable for the consequences of that unlawful conduct\" had immediate violence erupted from his speech, any violence that occurred happened weeks later. The Court therefore concluded that Evers's speech was protected under the First Amendment.  However, the Court has also found that First Amendment protection for speech related to illegal activity has its limits. In United States v. Williams , the Court upheld the constitutionality of a statute that outlawed knowing offers to provide or requests to receive child pornography. Citing Brandenburg , the Court noted that \"there remains an important distinction between a proposal to engage in illegal activity and the abstract advocacy of illegality.\" Distinguishing the statute from one that would raise issues under Brandenburg , the Court found that it did not ban the advocacy of the creation of child pornography, but instead prohibited what were essentially attempts to give or receive it. Child pornography is not protected by the First Amendment. In Williams , the Court held that offers to give or receive it are also categorically excluded from First Amendment protection. For that reason, the Court found that the statute \"[fell] well within constitutional bounds.\" Because the Court found that the statute did not raise issues regarding permissible restrictions on the pure advocacy of violence or lawlessness, the precise boundaries of the Brandenbu rg standard remain unclear.  Beyond the issue of regulating advocacy of imminent lawlessness or violence, the more recent 2010 case of Holder v. Humanitarian Law Project (\" H umanitarian Law Project \") is also relevant to questions regarding the advocacy of terrorism, as the opinion analyzes the permissibility of burdening speech that may more generally benefit terrorist organizations. In H umanitarian Law Project , the Supreme Court upheld the constitutionality of the federal criminal prohibition on the provision of material support to entities that have been officially designated as foreign terrorist organizations (FTOs) by the United States. The criminal prohibition applies to, among other forms of support, the provision of \"personnel,\" \"training,\" \"service,\" and \"expert advice and support\" to \"designated entities.\"  The plaintiffs in that case sought to provide certain services to FTOs, but feared that the provision of such services was barred by the law. While the plaintiffs did not claim that the statute violated the First Amendment in all instances, they alleged that the law was constitutionally invalid if applied to the assistance they contemplated providing the FTOs, which was intended to assist those groups' legitimate, non-terrorism-related activities. In particular, the plaintiffs sought pre-enforcement review in order to ensure that they could teach these organizations how to apply for certain humanitarian aid, engage in political advocacy on behalf of minority groups represented by these organizations, and give legal advice regarding the negotiation of peace agreements.  The Court agreed with the plaintiffs that the prohibition on the provision of material support extended not only to conduct, but also to speech in a manner that burdened the plaintiffs' First Amendment rights. The majority acknowledged that the restriction was content-based, and accordingly applied \"a more demanding standard\" of scrutiny to the provision than would otherwise have been employed if it reached only conduct. Nonetheless, the Court upheld the application of the statute to the speech in question.  The Court's assessment of the permissibility of the burden imposed on the plaintiffs' speech rights was informed by its reading of the underlying statute. The Court construed the material support statute as having been \"carefully drawn to cover only a narrow category of speech to, under the direction of, or in coordination with foreign groups that the speaker knows to be terrorist organizations.\" The fact that the statute covered speech coordinated with foreign terrorist groups, and not \"independent advocacy\" that happened to support those groups, made it easier for the government to demonstrate that the restriction was narrowly tailored to advance the government's interest. Turning to the government's justification, the Court began its analysis by reiterating that Congress has a compelling interest in combating terrorism and protecting national security. In banning the provision of all material support to foreign terrorist organizations, the Court observed that Congress had reasoned that any support provided to these organizations, even support not intended to aid in terrorist endeavors, can free resources to support terrorist activities. The Court noted congressional findings that if American citizens provided material support to entities the U.S. government had identified as terrorist groups that activity may strain diplomatic relationships between the United States and countries in which the FTOs operate. In the Court's view, official cooperation and interaction with non-governmental entities can lend legitimacy to terrorist groups, which might undermine the government's interest in combating those organizations. When examining the support that the plaintiffs wished to provide to FTOs, the Court observed that \"[a] foreign terrorist organization introduced to the structures of the international legal system might use the information to threaten, manipulate, and disrupt.\" According to the Court, prohibiting the provision of material support to FTOs, therefore, directly advanced the government's compelling interest in combating terrorism, and because the prohibition applied only to material support coordinated with FTOs, the statute was narrowly tailored to achieve the government's compelling interest. In reaching its conclusion upholding the statute, the Court emphasized that its holding applied only to the factual situation before the Court, and that the Court was not deciding the constitutionality of more difficult cases that might arise in other circumstances. The Court also stated that it \"in no way suggest[ed] ... that a regulation of independent speech\"\u2014that is, speech that is not coordinated with a FTO\u2013 \"would pass constitutional muster, even if the Government were to show that such speech benefits foreign terrorist organizations\" or that a similar statute banning the provision of material support to a domestic organization would survive review. The Court focused upon the significance of the fact that Congress had carefully crafted the statute to avoid burdening constitutional rights when enacting the law and emphasized that Congress's views on matters of national security are entitled to \"significant weight.\"  Some have argued that it should be permissible to restrict advocacy of terrorism disseminated via the Internet under the First Amendment, including perhaps in situations where current case law suggests that significant constitutional questions might be raised. Such advocates contend that eliminating or restricting such speech from the digital environment will reduce the risk of \"self-radicalization\" and will restrict the ability of terrorist groups to use social media to spread their propaganda. Under Brandenburg , it appears that laws that criminalize the dissemination of the pure advocacy of terrorism, without more, would likely be deemed unconstitutional. Despite the ambiguities in its application, Brandenburg remains controlling precedent and has been cited by the Supreme Court as such. Consequently, speech that does no more than independently advocate the moral propriety or the moral good of terrorist acts is likely protected by the First Amendment. According to Brandenburg , statutes that fail to draw the distinction between abstract advocacy of violence and incitements directed at and likely to produce imminent lawless action sweep too broadly to be upheld. Therefore, any law that would generally restrict the independent advocacy of terrorist action on the Internet, without narrowing its application to only that advocacy that meets Brandenburg 's definition of incitement, would likely be unconstitutional. The limiting language in the Supreme Court's majority opinion in H umanitarian L aw P roject appears to support this argument. The Court stressed that the application of the prohibition on material support to FTOs was properly tailored to withstand scrutiny, in part, because the statute did not apply to independent advocacy of terrorism. The Court stressed that it was not addressing whether Congress could burden independent advocacy, even if it could be shown that FTOs would benefit from that advocacy.  Some have argued that speech that advocates terrorist acts is so inherently dangerous that it should be distinguished from other speech that advocates violence or law breaking. These commentators posit that the government should be able to ban the dissemination of terrorist advocacy in the same way that the dissemination of child pornography is restricted. The comparison to child pornography is likely inapt, however. While the technology that permits the identification and filtering of child pornography might be adapted to filter the advocacy of terrorism, the constitutional justification for allowing the government to police the distribution of child pornography arguably does not justify treating the abstract advocacy of terrorism in a similar matter. Child pornography, the depiction of a minor engaged in sexual conduct that is not necessarily obscene, is unprotected by the First Amendment. The Supreme Court held that the possession and distribution of child pornography could be completely prohibited because the government has an overriding interest in destroying the market for speech that requires the injury and exploitation of children in order to create it. However, the Court has held that this reasoning does not extend to pornography that merely appears to, but does not in actuality depict a child engaging in sexual conduct (\"virtual child pornography\"). In reaching this holding, the Court explained that restrictions that apply to pornography depicting actual children were upheld because the laws targeted the production of the work and the harm that it caused children, not its content. In the case of virtual depictions of child pornography, no children are harmed in the creation of the content. The government had attempted to justify similar restrictions on virtual child pornography by arguing that such material, like actual child pornography, increased the risk that consumers of that content would victimize children in the future. Addressing that concern, the Supreme Court reiterated that the government \"may not prohibit speech because it increases the chance an unlawful act will be committed 'at some indefinite future time.'\" Applying this reasoning to the advocacy of terrorist activity, it does not appear that the creation of speech that advocates terrorism always inherently harms someone in the course of its production in a way that would be similar to the creation of actual child pornography. To be sure, some terrorist propaganda depicts terrorist attacks or executions, but terrorist advocacy does not necessarily require someone to be harmed in order for the speech to occur. Instead, the advocacy of terrorism, like virtual child pornography, arguably creates or increases a risk that a crime will be committed \"at some indefinite future time.\" And the Supreme Court has held that the government may not prohibit speech solely on the basis of that indefinite risk.  Speech that advocates terrorism that is distributed via the Internet may pose a significant danger to the public due to the ease of propagation to people who might be willing to act on those messages. For that reason, some lawmakers and scholars argue that courts should permit terrorist advocacy to be more easily restricted when the Internet is used to disseminate it. The Supreme Court has recognized that \"each medium of expression presents special First Amendment problems.\" For example, the Court has permitted broadcast speech to be more easily regulated than speech via other mediums because, among other factors, broadcasted speech is uniquely accessible to children.  The Supreme Court has yet to consider the specific question of whether the ease of dissemination of information over the Internet warrants treating advocacy of violence via that medium differently than the same speech communicated through other means. However, the Court has had the opportunity to examine what standard of review should be applied to restrictions on Internet speech more generally.  In Reno v. American Civil Liberties Union , the Supreme Court struck down restrictions on the communication of indecent speech to minors. In doing so, the Court held that content-based restrictions on Internet speech should be subject to strict scrutiny. The Court examined whether the medium of the Internet, like the broadcast medium, justified greater latitude for the government to restrict speech on that platform and concluded that it did not. Comparing the reasons for permitting greater restrictions on broadcasted speech to the medium of the Internet, the Court explained that broadcasted speech is uniquely accessible to children. Specifically, the Court noted that there is an appreciable risk that if indecent speech were broadcast at times when children would be likely to be in the audience, children might accidentally be exposed to that speech. In contrast, the risk of accidentally encountering indecent speech on the Internet was, in the Court's assessment, far lower and did not justify departing from the general rules regarding content-based restrictions on speech.  The Court therefore accorded the highest degree of protection to speech on the Internet because \"the interest in encouraging freedom of expression in a democratic society outweighs any theoretical but unproven benefit of censorship.\" Assuming that the Court would apply the same reasoning to a content-based restriction on the advocacy of terrorism, the fact that speech is distributed via the Internet would not seem to permit the government to more easily regulate its dissemination, under current case law.  Under current law, the two federal statutes criminalizing material support for terrorism or foreign terrorist organizations, 18 U.S.C. \u00a7\u00a7 2339A and 2339B, appear most relevant to online advocacy of terrorism. Neither statute squarely prohibits the advocacy of terrorism. But both statutes potentially cover non-tangible forms of support for terrorist activities or foreign terrorist groups, including through the recruitment of personnel or the provision of training, expert advice or assistance, funding, or financial services. The material support statutes have been the most often prosecuted anti-terrorism offenses. Section 2339A of Title 18 of the United States Code prohibits the provision of material support with the knowledge or intent that the support be used to carry out a terrorist attack. Section 2339B prohibits the provision of material support to designated foreign terrorist organizations. As previously discussed, the Supreme Court in H umanitarian L aw P roject held that material support provided in the form of certain kinds of speech under the direction or in coordination with foreign terrorist organizations in violation of Section 2339B may be punished consistent with the First Amendment even if such support is for purposes other than advancing the group's terrorist activities. Section 2339A of Title 18 of the U.S. Code prohibits: 1. (a) attempting to, (b) conspiring to, or (c) actually 2. (a) providing material support or resources, or (b) concealing or disguising i. the nature, ii. location, iii. source, or iv. ownership of material support or resources 3. knowing or intending that they be used (a) in preparation for, (b) in carrying out, (c) in preparation for concealment of an escape from, or (d) in carrying out the concealment of an escape from 4. an offense identified as a federal crime of terrorism, as enumerated by the statute. Material support or resources covers \"any property, tangible or intangible, or service,\" but excludes medicine and religious material. For the purposes of the discussion of whether the material support statutes can apply to the advocacy of terrorism, it is sufficient to note that the definition of material support explicitly includes \"training\" and \"expert advice or assistance.\" The statute defines training as the \"instruction or teaching designed to impart a specific skill, as opposed to general knowledge,\" whereas expert advice and assistance is defined to mean \"advice or assistance derived from scientific, technical, or other specialized knowledge.\" Unlike the material support statute at issue in Humanitarian Law Project, which potentially applied to activities done in furtherance of a foreign entity's activities unrelated to terrorism, a requisite for application of Section 2339A is that the support was given with the knowledge or intention that it would be used to facilitate a terrorist crime.  It seems that the provision of speech in the form of training or expert advice or assistance with the intent that it be used to support a specific act of terrorism can be constitutionally punished. Even when a violation of the law may take the form of speech, the Supreme Court has held that the Constitution is not necessarily a barrier to punishment. For example, an agreement to violate the law may be punished as a criminal conspiracy, and an agreement to fix prices in a market might constitute a violation of the antitrust laws. Constitutional challenges to the scope of Section 2339A, including those based on arguments that it is incompatible with the First Amendment, thus far have proven unsuccessful. Section 2339B of Title 18 of the United States Code predicates liability on material support provided to certain designated terrorist organizations, rather than to the commission of a specific crime of terrorism. As acknowledged by the Supreme Court in H umanitarian L aw P roject , this difference may create closer constitutional questions when the statute is applied to speech. Section 2339B outlaws: 1. (a) attempting to provide, (b) conspiring to provide, or (c) actually providing 2. material support or resources 3. to a foreign terrorist organization 4. knowing that the organization (a) has been designated a foreign terrorist organization, or (b) engages, or has engaged in \"terrorism\" or \"terrorist activity.\"  Section 2339B's definition for \"material support\" is the same definition that applies to Section 2339A and covers \"any property, tangible or intangible, or service\" and explicitly includes \"training\" and \"expert advice or assistance.\" The H umanitarian L aw P roject Court clarified that advocacy may only constitute material support when it is \"concerted activity,\" that is, activity in connection with or under the direction of an FTO.  To violate Section 2339B, one need not intend to aid in a terrorist attack or to further an organization's terrorist activities. One need only have \"knowledge that the organization is a designated terrorist organization ... that the organization has engaged in terrorist activity ... or that the organization has engaged or engages in terrorism.\" Assuming that a particular type of terrorist advocacy is within the scope of the \"material support\" proscribed by Section 2339B (e.g., it involves training or the giving of expert advice), the primary question that remains is whether the speech at issue would constitute advocacy \"directed to, coordinated with or controlled by\" a FTO. In examining the clarity of the statute in H umanitarian L aw P roject and holding that the statute was not impermissibly vague, the Court pointed out that, by its terms,  [the] statute prohibits providing a service \"to a foreign terrorist organization.\" The use of the word \"to\" indicates a connection between the service and the foreign group. We think a person of ordinary intelligence would understand that independently advocating for a cause is different from providing a service to a group that is advocating for that cause.  However, the Court did acknowledge that it was leaving open \"questions of exactly how much direction or coordination is necessary for an activity to constitute a 'service.'\" The majority decided that it would be more appropriate to address those questions when the particular factual situations arose.  A 2013 case decided by the First Circuit Court of Appeals may indicate that some courts could be inclined to broadly interpret what it means to direct speech to, coordinate with, or act under the direction of a FTO. In that case, Tarek Mehanna was convicted of several terrorism-related charges, including for providing material support to Al Qaeda, an organization Mehanna knew to be a designated FTO. Mehanna had traveled to Yemen in an attempt to join Al Qaeda, but had been unable to locate the training camp he sough t. Mehanna had also translated publicly available Arabic language documents, some of which were Al Qaeda-generated propaganda, into English and had posted his translations on a website that was sympathetic to Al Qaeda. Mehanna argued that his translations were independent advocacy, protected by the First Amendment and that the jury had not been properly instructed regarding what it means to coordinate with an FTO under Section 2339B. The First Circuit upheld his convictions. In doing so, the court examined the trial judge's instructions to the jury regarding the First Amendment and the defendant's translations. The First Circuit noted that the trial judge had defined \"coordination\" by explaining that \"[i]ndividuals who act entirely independently of the 'FTO' to advance its goals or objectives shall not be considered to be working under the FTO's direction.\" The First Circuit could find no legal error with these jury instructions. In response to the contention that the jury should have been instructed that a direct connection between a FTO and a defendant must be proven in order for the defendant to have acted in coordination with the organization, the appeals court stated that neither the statute nor the Supreme Court's decision in H umanitarian L aw P roject required \"a direct link\" between a defendant and a FTO for a violation to occur. Nonetheless, the appeals court did not explicitly hold that Mehanna's translational activities were sufficient to sustain his conviction. At the same time, the court held that, even if the defendant's translational activities did not constitute an attempt to provide material support, the evidence surrounding his trip to Yemen in an attempt to join Al Qaeda supported his convictions. The Mehanna case does not provide definitive answers as to when speech activity that may benefit an FTO is sufficiently directed to, coordinated with, or under the direction of a FTO to be considered material support. However, it does suggest that certain forms of speech-related activity might be considered to be material support, even if the defendant never actually has direct contact with the FTO. If speech can be material support when the defendant has never succeeded in making direct contact with the FTO, it seems unclear where the line might be drawn between independent advocacy of terrorism that the Supreme Court in H umanitarian L aw P roject suggested could not be restricted and advocacy of terrorism that constitutes a violation of Section 2339B. Some observers have suggested the possibility that when members of FTOs obtain accounts for social media sites like Twitter and Facebook, those sites are providing a service to FTOs that constitutes material support in violation of Section 2339B. Some FTOs have reportedly acquired social media accounts from social media companies. One recent study estimated that over 30,000 accounts on Twitter were controlled by the Islamic State organization alone as of 2014. Others have noted the apparent presence of other terrorist groups on Twitter and other social media outlets. The outstanding questions appear to be whether providing a social media account could constitute material support and whether a social media company has knowledge sufficient to support a conviction. However, it does not appear that the Department of Justice (DOJ) has ever brought a criminal or civil case against any social media outlet alleging such a violation. As a result, there is no case law clarifying whether the statute can properly be applied to social media companies whose generally available services are used by FTOs to communicate. If a court were to evaluate whether Section 2339B can be applied to social media companies, one of the most difficult questions presented would be whether a social media site could be said to be acting in coordination with or under the direction of an FTO. As noted above, H umanitarian L aw P roject did not provide guidance as to the level of coordination necessary to constitute the provision of a service to a FTO under the statute. Mehanna suggests that defendants need not have direct contact with the FTO in order for a violation to occur. Websites generally do not engage in background checks or any other form of verification prior to permitting an account to be created. Given the number of people who use their services, such verification may be impossible. And given the difficult burden that would be imposed on social media companies in performing background checks on every user, a court may simply conclude that providing an account to a user who may happen to be affiliated with a FTO may be insufficient in and of itself to rise to the level of \"coordination\" necessary to violate Section 2339B. Nonetheless, a number of social media sites have policies to remove terrorist content or the accounts of terrorist groups. Some have argued that because social media sites often fail to suspend accounts that are associated with FTOs, the government could argue that this failure is evidence of coordination with FTOs. Without case law interpreting this question, it remains unclear whether the fact that terrorist groups and their representatives often are able to obtain and use social media accounts represents a sufficient connection between social media services and the terrorist groups to support a finding of the provision of material support. In addition, in order to hold a social media company criminally or civilly liable for the provision of material support to an FTO under Section 2339B, the government must prove that the defendant knew that the organization to which the support was provided was a designated FTO or that the organization was engaged in terrorism. Social media companies could be expected to argue that they do not have sufficient knowledge of a new user's affiliation with a FTO upon the activation of an account. Over 1 billion people use Facebook, and millions also use Twitter. The companies do not, and might argue that they cannot, attempt to discover with any degree of certainty what users of its services will be terrorist affiliates prior to the activation of an account. Nonetheless, social media sites appear to be generally aware that their services are used by some percentage of their subscribers to disseminate terrorist advocacy and that they may be used by FTOs themselves. Twitter, Facebook, and other social media sites can and do disable accounts that violate their terms of service. Certain violent speech, including speech that advocates or glorifies terrorism, violates the terms of service of these sites. It has been reported that Twitter has recently increased the number of accounts that it has disabled for promoting terrorism. Facebook has also reportedly removed posts that advocate terrorism and has disabled accounts for the same reason. The fact that social media companies take steps to remove that content when it appears on their services may be evidence that they know that their services are being used by FTOs. On the other hand, a social media website might not be sure if an account actually belongs to a FTO or is operated by another user identifying itself as the FTO. It is unclear whether the general knowledge of social media sites that terrorist organizations are using their services, despite lacking actual knowledge that a particular account is used by a specific FTO, is sufficient to support a conviction for the provision of material support under Section 2339B. Section 2333 of Title 18 of the United States Code permits U.S. citizens injured in their persons, property, or business by acts of international terrorism to recover treble damages. Courts have interpreted violations of Section 2339A and 2339B to be acts of international terrorism for the purposes of Section 2333. Recently, a number of lawsuits have been filed by private plaintiffs against social media websites alleging that they are providing material support to terrorist groups in violation of 18 U.S.C. \u00a7 2339B. One such lawsuit was brought against Twitter and alleged that Twitter's dissemination of propaganda by the Islamic State organization led to a terrorist attack that caused the death of three government contractors at a training facility in Jordan. In another lawsuit, the father of one of the Americans killed in the orchestrated terrorist attack in Paris in 2015 similarly accused Twitter, Google, and Facebook of providing material support to the Islamic State in violation of Section 2339B, arguing that without the services provided by these sites, \"the explosive growth of ISIS over the last few years into the most-feared terrorist group in the world would not have been possible.\" Beyond the difficulty with determining whether social media companies can be held civilly liable for providing material support under the terms of Section 2339B, such private civil lawsuits may face an additional hurdle in attempting to hold social media services accountable for allowing FTOs to use them. Section 230(c) of the Communications Decency Act (CDA) prohibits holding interactive computer service providers liable for content provided by third parties. While the liability shield does not apply to violations of the federal criminal law, the U.S. Court of Appeals for the First Circuit recently held that, even when the civil lawsuit is based upon a violation of federal criminal law, Section 230's shield may bar recovery if the lawsuit seeks to treat a service provider as a publisher. Consequently, even if social media service providers do violate Section 2339B when providing accounts to FTOs, it is possible that Section 230 of the CDA would shield them from civil liability for that violation. Section 230(c)(1) of the CDA states, in pertinent part, that \"no provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.\" This language has been interpreted by courts to provide immunity from civil liability to providers and users of interactive computer services for content provided by third parties. In creating this liability shield, Congress sought to preserve the robust and vibrant communication that occurs on the Internet and to \"keep government interference to a minimum.\" However, Section 230 is not an absolute bar to liability. A three-part test has been developed to determine whether a defendant is eligible for Section 230's protection. If the lawsuit is  1. brought against an interactive computer service provider or user (e.g., a website like NYTimes.com, or a social media service, like Twitter or Facebook), 2. based upon information provided by another content provider, and 3. seeks to hold the defendant liable as a publisher or speaker of that content,  then Section 230's liability shield applies. If it can be shown that the interactive computer service provider contributed to the development of the illegal content, Section 230's liability shield is not available. To date, only one court has ruled with regard to Section 230's application to a lawsuit alleging material support of a FTO by a social media company. In Fields v. Twitter , the plaintiffs, family members of United States government contractors who were killed in a terrorist attack in Lebanon, alleged that the Islamic State organization used Twitter to spread propaganda, raise funds, and attract recruits, and that Twitter knowingly permitted such use of its services. The plaintiffs further alleged that Twitter's provision of these services generally caused their injuries. However, the plaintiffs did not specifically allege that the Islamic State used Twitter to recruit the person who committed the terrorist attack that injured the plaintiffs or that Twitter was used to plan the attack. Instead, the plaintiffs alleged only that the attacker was generally inspired by propaganda that he had seen on Twitter.  The United States District Court for the Northern District of California dismissed the plaintiffs' lawsuit, but gave the plaintiffs leave to amend their complaint. In doing so, the court did not reach the question of whether Twitter actually had provided material support to a foreign terrorist organization. Instead, the district court dismissed the lawsuit because the court found that Section 230 of the CDA shielded Twitter from liability. The central argument in Fields with regard to Section 230 was whether the lawsuit was attempting to hold Twitter liable as a publisher. To support their argument that the lawsuit was not targeting Twitter as a publisher, the plaintiffs offered two justifications. First, they argued that their lawsuit was not based upon the content of the speech disseminated by Twitter, but instead was based solely upon Twitter's provision of services in the form of Twitter accounts to the Islamic State organization. Second, they alleged that because much of the organization's recruiting communication is accomplished via Twitter's Direct Messaging services, which are private communications between individual users, those direct messages are not \"published\" to the public and recovery based upon those communications cannot be barred by Section 230. The district court rejected both arguments. In rejecting the plaintiffs' provision of accounts theory of liability, the court noted previous cases analyzing the breadth of Section 230's liability shield have defined publishing broadly to include any decision related to what third-party content might be made available on a site or removed from it. Generally, previous courts had applied that reasoning to specific offensive content and not to the decision of whether to provide access to a platform to specific persons. However, the district court did not see a substantive distinction between the two concepts for the purposes of whether Twitter was being treated as a publisher. In the court's view, granting permission to a particular person to post whatever content that person liked was no less a publishing decision than allowing content to be posted in the first place, or removing content that the site decided violated its rules. \"Twitter's decisions to structure and operate itself as a platform ... allowing for the freedom of expression [of] hundreds of millions of people around the world and to allow even ISIS to sign up for accounts on its social network,\" in the court's view, \"reflect choices about what [third-party] content can appear on Twitter and in what form.\" These were quintessential publishing decisions in the view of the court. Consequently, Section 230's liability shield applied. Turning to whether content that was not made publicly available was published for the purposes of Section 230, the court again was not convinced by the plaintiffs' arguments. In making this determination, the court noted that Section 230 was first enacted to provide a liability shield for defamatory content posted by third parties. Accordingly, the district court took into account that appeals courts have looked to defamation law when determining the scope of the shield provided by Section 230. Because, under defamation law, the term publication means to communicate to another person, other than the person defamed, the Fields court determined that in order for an interactive service provider to be treated as a publisher for the purposes of Section 230, the third-party content need not be made publicly available. Section 230's liability shield therefore also applied to content communicated via Twitter's Direct Messaging service. As noted above, similar private civil lawsuits alleging that social media sites provide material support to terrorist organizations are pending in court. It remains to be seen whether those cases will be decided similarly to Fields v. Twitter . However, Fields does suggest that reviewing courts may be inclined to continue the general trend of broadly applying the liability shield provided by Section 230 to civil suits brought against Internet platforms that display third-party content like Twitter, Facebook, and Google. If so, they may provide a barrier to attempts to curb the advocacy of terrorism on the Internet through civil litigation."
}