{
    "title": "R45650",
    "content": "Under current federal law, social media users may face at least two significant barriers if they attempt to sue a social media provider for its decisions about hosting or limiting access to users' content. The first, which likely applies only to lawsuits predicated on a platform's decision to remove rather than allow content, is the state action requirement of the First Amendment. The state action doctrine provides that constitutional free speech protections generally apply only when a person is harmed by an action of the government, rather than a private party. The second legal barrier is the CDA's Section 230, which offers broad immunity to \"interactive computer service\" providers. Section 230(c)(1) provides immunity from any lawsuit that seeks to hold a service provider liable for publishing information that was created by an \"information content provider,\" effectively protecting social media sites from liability for hosting content. By contrast, Section 230(c)(2) provides immunity for sites that take good faith action to restrict access to content that the provider or users deem \"obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable.\" Thus, federal law does not currently provide a recourse for many users who would like to challenge a social media site's decision to ban or restrict content, or to host content\u2014and may affirmatively bar liability in certain circumstances. The Free Speech Clause of the First Amendment provides that \" Congress shall make no law . . . abridging the freedom of speech\" and applies to the \" State[s] \" through the Fourteenth Amendment. Thus, the First Amendment, like other constitutional guarantees, generally applies only against government action. As the Supreme Court has said, \"while statutory or common law may in some situations extend protection or provide redress against a private corporation or person who seeks to abridge the free expression of others, no such protection or redress is provided by the Constitution itself.\" However, the Supreme Court has, in limited circumstances, allowed First Amendment claims to proceed against seemingly private parties that abridge protected speech. The clearest example of the Court extending the First Amendment to apply to the actions of a private party comes from Marsh v. Alabama , where the Court held that the First Amendment prohibited the punishment of a resident of a company-owned town for distributing religious literature. While the town in question was owned by a private corporation, \"it ha[d] all the characteristics of any other American town,\" including residences, businesses, streets, utilities, public safety officers, and a post office. Under these circumstances, the Court held that \"the corporation's property interests\" did not \"settle the question\" : \"[w]hether a corporation or a municipality owns or possesses the town[,] the public in either case has an identical interest in the functioning of the community in such manner that the channels of communication remain free.\" Consequently, the corporation could not be permitted \"to govern a community of citizens\" in a way that \"restrict[ed] their fundamental liberties.\" The Supreme Court has described Marsh as embodying a \"public function\" test, under which the First Amendment will apply if a private entity exercises \"powers traditionally exclusively reserved to the State.\" Since Marsh was issued in 1946, however, it has largely been limited to the facts presented in that case. The Supreme Court extended the Marsh decision in 1968: in Amalgamated Food Employees Union v. Logan Valley Plaza , the Court held that a private shopping mall could not prevent individuals from peacefully picketing on the premises, noting similarities between \"the business block in Marsh and the shopping center\" at issue in that case. However, the Court subsequently disclaimed Logan Valley in Hudgens v. NLRB , rejecting the idea that \"large self-contained shopping center[s]\" are \"the functional equivalent of a municipality.\" Instead, the Court held that in Hudgens , where a shopping center manager had threatened to arrest picketers for trespassing, \"the constitutional guarantee of free expression ha[d] no part to play.\" As a result, the picketers \"did not have a First Amendment right to enter this shopping center for the purpose of advertising their strike.\" In another decision in which the Supreme Court held that the First Amendment did not prevent a shopping center from banning the distribution of handbills, the Court distinguished Marsh by noting that \"the owner of the company town was performing the full spectrum of municipal powers and stood in the shoes of the State.\" By contrast, the disputed shopping center had not assumed \"municipal functions or power.\" The fact that the shopping center was generally open to the public did not qualify as a \"dedication of [the] privately owned and operated shopping center to public use\" sufficient \"to entitle respondents to exercise therein the asserted First Amendment rights.\"  Apart from the factual circumstances presented by the company town that exercises powers \"traditionally\" and \"exclusively\" held by the government, the Court has sometimes applied the First Amendment against private parties if they have a \"sufficiently close relationship\" to the government. Such circumstances may exist where a private company \"is subject to extensive state regulation\"\u2014although government regulation alone is not sufficient to establish the state action requirement. Instead, the inquiry in such a case is \"whether there is a sufficiently close nexus between the State and the challenged action of the regulated entity so that the action of the latter may be fairly treated as that of the State itself.\" In a 2001 case, the Supreme Court held that a state athletic association, while \"nominally private,\" should be subject to First Amendment standards because of \"the pervasive entwinement of public institutions and public officials in its composition and workings.\" Some plaintiffs have argued that various internet companies, including some social media sites, should be treated as state actors subject to the First Amendment when those companies take down or restrict access to their speech. Courts have rejected these claims. Many of these decisions have involved relatively terse applications of existing Supreme Court precedent. In a few cases, however, federal district courts have explored the application of these state action cases in more detail.  First, lower courts have repeatedly held that social media sites do not meet the \"exclusive public function test\" and are not akin to a company town. In so holding, courts have recognized that, under prevailing Supreme Court case law, private actors are not \"state actors subject to First Amendment scrutiny merely because they hold out and operate their private property as a forum for expression of diverse points of view.\" Accordingly, they have held that the mere fact that social media providers hold their networks open for use by the public is insufficient to make them subject to the First Amendment. Courts have rejected plaintiffs' efforts to characterize the provision of a public forum or \"the dissemination of news and fostering of debate\" as public functions that were traditionally and exclusively performed by the government. For example, in Cyber Promotions v. American Online (AOL) , a district court rejected the argument that \"by providing Internet e-mail and acting as the sole conduit to its members' Internet e-mail boxes, AOL has opened up that part of its network [to the public] and as such, has sufficiently devoted this domain for public use.\" The court said that \"[a]lthough AOL has technically opened its e-mail system to the public by connecting with the Internet, AOL has not opened its property to the public by performing any municipal power or essential public service and, therefore, does not stand in the shoes of the State.\" The challengers in that case, a company that had been blocked from sending unsolicited advertisements via email, also argued that AOL performed an exclusive public function because the company had \"no alternative avenues of communication . . . to send its e-mail to AOL members.\" The judge rejected this claim as well, concluding that the company did have alternative avenues to send its advertising to AOL members, including other places on the internet as well as \"non-Internet avenues.\" Similarly, in Prager University v. Google LLC , a district court held that by operating YouTube, \"a 'video-sharing website,'\" and then restricting access to some videos, Google had not \"somehow engaged in one of the 'very few' functions that were traditionally 'exclusively reserved to the State.'\" Trial courts have also held that social networks have failed to meet the joint participation, nexus, and entwinement tests for state action. In Cyber Promotions , the court held that there was no joint participation because the government was not involved in AOL's challenged decision. Another trial court, in Quigley v. Yelp, Inc. , similarly concluded joint participation did not exist between various social media sites and the government where the plaintiff failed to show that the state participated in the specific actions challenged in the lawsuit. That court also rejected an argument that there was \"a pervasive entwinement between defendants and the government because the government maintains accounts on the defendants' websites, and uses their websites to communicate with citizens.\" Even assuming that this allegation was true, the court held that this was not \"the sort of entwinement that . . . converts a private party's actions to state action,\" observing that the government did not participate \"in the operation or management of defendants' websites,\" but only used these sites \"in the same manner as other users.\"  Accordingly, lower courts have uniformly concluded that the First Amendment does not prevent social media providers from restricting users' ability to post content on their networks. However, the Supreme Court has not yet weighed in on this subject, and as will be discussed in more detail below, a number of legal commentators have argued that, notwithstanding these trial court decisions, courts should view social media platforms as equivalent to state actors, at least when they perform certain functions.  A constitutional injury is not the only type of harm that a social media user might suffer as a result of a social network's decisions about user content, and litigants have brought a wide variety of claims challenging these sorts of decisions. For example, plaintiffs have argued that sites' decisions to remove or restrict access to their content constituted unfair competition under the Lanham Act, discrimination under the Civil Rights Act of 1964, tortious interference with contractual relationships, fraud, and breach of contract. Other plaintiffs have attempted to hold online platforms liable for harm stemming from the sites' decisions not to remove content, claiming, for example, that by publishing certain content, the sites committed defamation or negligence, or violated state securities law. However, many of these suits are barred by the broad grant of immunity created by the CDA's Section 230.  Section 230, as seen in the text box above, distinguishes between \"interactive computer services\" and \"information content providers.\" An interactive computer service is \"any information service, system, or access software provider that provides or enables computer access by multiple users to a computer server.\" Courts have considered online platforms such as Facebook, Twitter, and Craigslist to be \"interactive computer service\" providers. An information content provider is \"any person or entity that is responsible, in whole or in part, for the creation or development of information provided through the Internet or any other interactive computer service.\" Section 230 contains two primary provisions creating immunity from liability. First, Section 230(c)(1) specifies that interactive service providers and users may not \"be treated as the publisher or speaker of any information provided by another information content provider.\" Second, Section 230(c)(2) states that interactive service providers and users may not be held liable for voluntarily acting in good faith to restrict access to objectionable material. Section 230 preempts state civil lawsuits and state criminal prosecutions to the extent that they are \"inconsistent\" with Section 230. It also bars certain federal civil lawsuits, but, significantly, not federal criminal prosecutions. Section 230(e) outlines a few exemptions: for example, Section 230 immunity will not apply in a suit \"pertaining to intellectual property\" or in claims alleging violations of certain sex trafficking laws. Section 230, and particularly Section 230(c)(1), distinguishes those who create content from those who provide access to that content, providing immunity to the latter group. An entity may be both an \"interactive computer service\" provider and an \"information content provider,\" but the critical inquiry for applying Section 230(c)(1) is whether, with respect to the particular actions alleged to create liability, the service provider developed the underlying content.  Courts have held that an interactive computer service provider may be subject to suit if it is also acting as a content provider. Frequently, the application of Section 230(c)(1) immunity turns not on the type of suit that is being brought\u2014that is, for example, whether it is a suit for libel or for breach of contract \u2014but on whether the facts establish that the interactive computer service provider was merely a publisher of another's content, or whether the service provider itself created or developed content. Courts have generally held that a site's ability to control the content posted on its website does not, in and of itself, transform an interactive computer service into an internet content provider. As one court said, \"a website does not create or develop content when it merely provides a neutral means by which third parties can post information of their own independent choosing online.\" A service provider may still be immune from suit under Section 230(c)(1) even if it makes small editorial changes to that content. Conversely, a \"website operator\" can be liable for \"content that it creates itself, or is 'responsible, in whole or in part' for creating or developing.\" Even if the service provider does not itself solely create the content, Section 230 immunity might be unavailable if the service provider \"augment[s] the content.\" For example, one state court held that, even assuming that Snapchat was a provider of interactive computer services, a plaintiff's claim against the company could proceed where the alleged harm was caused by a \"filter,\" or a graphic overlay on a user's photo, that was created by Snapchat itself. Because the plaintiff sought \"to hold Snapchat liable for its own conduct,\" the court held that \"CDA immunity does not apply.\"  Some courts have applied a \"material contribution test,\" asking whether a service provider \"materially contribute[d] to the illegality\" of the disputed content, or \"in some way specifically encourage[d] development of what is offensive about the content.\" Thus, for example, a federal appellate court concluded that Roommates.com, a site that \"match[ed] people renting out spare rooms with people looking for a place to live,\" was not wholly immune from claims that it had violated laws prohibiting housing discrimination. The court concluded that Roommates.com could be subject to suit for discrimination because the site required all users to respond to questions about their sex, family status, and sexual orientation by selecting among preset answers to those questions, and to state their \"preferences in roommates with respect to the same three criteria.\" Accordingly, in the court's view, as to these questions and answers, Roommates.com was \"more than a passive transmitter of information provided by others; it becomes the developer, at least in part, of that information.\" Each user's personal page was \"a collaborative effort between [Roommates.com] and the subscriber.\" This rendered it the \"'information content provider' as to the questions\" and the answers. Although courts frequently consider the immunity in Section 230(c)(1) and Section 230(c)(2) together, as one \"Section 230\" shield, the text of these provisions suggests they cover distinct circumstances. Section 230(c)(1) applies more broadly, to any suit in which the plaintiff seeks to hold the provider liable as the publisher of another's information. By contrast, Section 230(c)(2) applies only to good-faith, voluntary actions by a provider\u2014or a third party assisting providers\u2014to restrict access to \"obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable\" content.  There is an important difference in the language of the two provisions: as noted, Section 230(c)(2) requires a service provider to act in good faith for immunity to apply; Section 230(c)(1) does not contain a similar requirement. While courts frequently apply Section 230 to dismiss lawsuits premised on a service provider's decision to remove or restrict access to another's content, they are somewhat less likely to dismiss lawsuits where the good-faith requirement is involved, because a plaintiff who properly pleads and presents evidence regarding a lack of good faith creates a question of fact that may prevent the court from summarily dismissing the case. One trial court concluded that there was a question as to Google's good faith where the plaintiff alleged that Google was \"selectively enforcing\" a stated policy, and that the policy itself was \"entirely pretextual.\" Another trial court concluded that a company had sufficiently alleged bad faith where it argued that Google had \"falsely accused\" it of violating Google's stated policy, and that Google \"sought to punish [the company] because it\" refused to allow Google to embed advertising in the company's video. One view is that Section 230(c)(2) applies when a provider \" does filter out offensive material,\" while Section 230(c)(1) applies when providers \" refrain from filtering or censoring the information on their sites.\" At least one federal trial judge has noted that interpreting Section 230(c)(1) to bar suits in which a plaintiff seeks to hold a service provider liable for removing the plaintiff's own content would \"swallow[] the more specific immunity in (c)(2).\" The court explained that:  Subsection (c)(2) immunizes only an interactive computer service's \"actions taken in good faith.\" If the publisher's motives are irrelevant and always immunized by (c)(1), then (c)(2) is unnecessary. The Court is unwilling to read the statute in a way that renders the good-faith requirement superfluous. Lawsuits directly challenging a website's decision to restrict or remove content, rather than to publish it, often do invoke Section 230(c)(2). Thus, courts have considered the application of Section 230(c)(2), rather than Section 230(c)(1), in lawsuits involving the removal of an app from the Google Play Store, the removal of websites from Google's search results, the removal of videos from YouTube, and decisions to filter certain IP addresses or email addresses. However, this distinction between filtering content and publishing content does not always play out so neatly in the courts, and other decisions have applied Section 230(c)(1) immunity to bar suits that are grounded in an interactive service provider's decision to restrict content.  There is one additional circumstance under which Section 230(c)(2) immunity, as opposed to Section 230(c)(1) immunity, may apply. Section 230(c)(2)(B) protects those providers or users of computer services who \"enable or make available to information content providers or others technical means to restrict access to\" objectionable material. This provision may protect, for example, \"providers of programs that filter adware and malware.\" This immunity may apply even where an interactive computer service is not a publisher entitled to immunity under Section 230(c)(1). Thus, as a whole, Section 230 offers broad immunity to \"interactive computer service\" providers when a litigant seeks to hold them liable for publishing, or not publishing, a user's content. Section 230(c)(1) provides immunity from any lawsuit that seeks to hold a service provider liable for publishing information that was created by an \"information content provider,\" effectively protecting social media sites from liability for hosting content. And Section 230(c)(2) provides immunity for sites that take good faith action to restrict access to content that the provider or users deem \"objectionable.\" Consequently, to the extent that private litigants or state governments would have been able to hold social media companies liable under existing law for their decisions regarding presenting or restricting access to user content, those suits have largely been barred under Section 230. As discussed above, courts have often dismissed lawsuits attempting to hold social media providers liable for regulating users' content, whether because the court concludes that the First Amendment does not apply to the actions of these private actors or because the court holds that Section 230(c)(2) of the CDA bars the lawsuit. Additionally, Section 230(c)(1) may bar lawsuits that seek to hold these platforms liable because of their decisions to publish certain content. Particularly because of Section 230, there are few, if any, federal or state laws that expressly govern social media sites' decisions about whether and how to present users' content. Consequently, users' ability to post speech on social media platforms is governed primarily by the private moderation policies created by these companies. In response to broader public policy concerns about how social media entities are policing user content, some commentators and legislators have proposed federal regulation both to protect users' ability to speak freely on those platforms and to require these platforms to take down, deemphasize, or clarify certain content. While the First Amendment, as discussed above, may not apply in disputes between private parties, a federal law regulating internet content decisions would likely qualify as state action sufficient to implicate the First Amendment. After all, the First Amendment provides that \" Congress shall make no law . . . abridging the freedom of speech.\"  Once state action is established, the next consideration is to what extent the First Amendment protects social media platforms' content moderation decisions. Stated another way, the relevant question is when social media providers can assert that government regulation infringes on their own speech. Perhaps most obviously, if a social media site posts content that it has created itself, the site may raise First Amendment objections to a law expressly regulating that speech. Social media providers may also argue that they are exercising protected speech rights when they are choosing whether to publish content that was originally created by users and when they make decisions about how to present that content. However, the fact that a law affects speech protected by the First Amendment does not necessarily mean that it is unconstitutional. As explained below, the First Amendment allows some regulation of speech and does not prohibit regulation of conduct. While the First Amendment generally protects the \"freedom of speech,\" its protections do not apply in the same way in all cases. Not every government regulation affecting content posted on social media sites would be analyzed in the same way. A court's analysis would depend on a number of factors. First, a court would inquire into the nature of the precise action being regulated, including whether it is properly characterized as speech or conduct. Laws that target conduct and only incidentally burden speech may be permissible. But \"speech\" is not always easy to identify. Lower courts have held that computer code and programs may be entitled to First Amendment protection, so long as they communicate \"information comprehensible to human beings.\" Courts have also concluded that in some circumstances, domain names might constitute protected speech. And more generally, the Supreme Court has said that \"inherently expressive\" conduct can receive First Amendment protections. If a law does regulate speech, a court would consider the type of speech being regulated to determine how closely to scrutinize the regulation. For example, a court may ask whether that speech is commercial and, as such, deserving of less protection under the First Amendment. Advertisements posted on social media sites would likely qualify as commercial speech. If speech is not purely commercial and is instead, for example, political advocacy, that speech may receive greater protection. Certain categories of speech receive even less protection than commercial speech. For example, the Supreme Court has said that states may prohibit speech advocating violence if that \"advocacy is directed to inciting or producing imminent lawless action and is likely to incite or produce such action.\" Thus, certain types of threatening or violent speech posted on social media may not be entitled to First Amendment protection. However, perhaps in light of the fact that it can be difficult to determine whether speech is protected, the Court has sometimes held that criminal statutes targeting disfavored speech must include a mental state requirement. For example, in United States v. X-Citement Video , the Court noted that, with respect to a federal law prohibiting the distribution of child pornography, criminal liability turned on \"the age of the performers\"\u2014as did First Amendment protection for the materials, given that \"nonobscene, sexually explicit materials involving persons over the age of 17 are protected by the First Amendment.\" Accordingly, although the statute was unclear on this point, the Court held that the law applied only if a person distributing such materials knew that the performers were underage.  Even if a statute does target a category of speech that is traditionally proscribable, it may still be invalid if it is overbroad, in the sense that it prohibits a substantial amount of protected speech, as well. Thus, for example, in Ashcroft v. Free Speech Coalition , the Supreme Court held that a federal statute prohibiting \"sexually explicit images that appear to depict minors\" was unconstitutionally overbroad. The statute encompassed pornography that did \"not depict an actual child,\" prohibiting images that were \"created by using adults who look like minors or by using computer imaging.\" Thus, the Court held that the statute violated the First Amendment because it \"proscribe[d] a significant universe of speech that is neither obscene . . . nor child pornography,\" as those two categories had been defined in prior Supreme Court cases.  A court would also look to the nature of the regulation itself, and primarily whether it is content-neutral, or whether it instead discriminates on the basis of content or viewpoint, subjecting that law to strict scrutiny. The Court has said that \"a speech regulation is content based if the law applies to particular speech because of the topic discussed or the idea or message expressed.\" In a strict scrutiny analysis, the government must prove that the \"restriction 'furthers a compelling interest and is narrowly tailored to achieve that interest.'\" If a regulation is content-neutral, which is to say, \"justified without reference to the content of the regulated speech,\" a court employs an intermediate scrutiny analysis, asking whether the restriction is \"narrowly tailored to serve a significant governmental interest\" and \"leave[s] open ample alternative channels for communication of the information.\" Accordingly, for example, a federal court of appeals held in Universal City Studios, Inc. v. Corley that government restrictions on posting or linking to decryption computer programs did regulate speech protected by the First Amendment, but ultimately upheld those restrictions as permissible content-neutral regulations. These first two inquiries are distinct, although they do overlap. If a statute targets speech rather than conduct, it is likely that it will target that speech based on its content, and therefore will not be content-neutral. And by contrast, a statute that targets conduct will likely be content-neutral on its face. In Universal City Studios, Inc. , the court held that the challenged government regulations were content-neutral because they \"target[ed] only the nonspeech component\" of the prohibited actions by focusing on the \"functional\" aspects of computer code that operate without any human involvement. It is possible, though, that a law targeting speech would nonetheless be content-neutral. For example, the Court has said that \"a prohibition against the use of sound trucks emitting 'loud and raucous' noise in residential neighborhoods is permissible if it applies equally to music, political speech, and advertising.\"  A court might also look to the particular nature of the medium being regulated, asking whether there are special characteristics that might justify greater regulation. The Supreme Court has said that \"[e]ach medium of expression . . . must be assessed for First Amendment purposes by standards suited to it, for each may present its own problems.\" The Court has been willing to extend First Amendment protections that historically applied to speech communicated in traditional public forums such as streets and sidewalks to new mediums for communication, including video games and the internet. But the Court has also recognized that the principles developed \"in the context of streets and parks . . . should not be extended in a mechanical way to the very different context of\" newer media. While the Court has characterized social media as \"the modern public square,\" it has not fully clarified what standards should apply to government regulation of that medium\u2014particularly with respect to social media platforms' roles as hosts for others' speech.  The Supreme Court said in Reno v. ACLU that when considering government regulation of \"the Internet\" in general, factors that had previously justified greater regulation of other media did not apply. In that case, the Court held unconstitutional two provisions of the CDA that criminalized the transmission of certain \"indecent\" or \"patently offensive\" material to minors over the internet. The Court rejected the government's argument that the regulation was permissible because the internet is analogous to broadcast media, where the Court has permitted greater regulation of speech. The Court noted that unlike the broadcast industry, \"the vast democratic fora of the Internet\" had not traditionally \"been subject to the type of government supervision and regulation that has attended the broadcast industry,\" and said that \"the Internet is not as 'invasive' as radio or television.\" Accordingly, the Court stated that there was \"no basis for qualifying the level of First Amendment scrutiny that should be applied to this medium.\" However, as will be discussed in more detail below, some scholars have argued that Reno , decided in 1997, does not specifically address government regulation of modern social media sites, which may present unique concerns from those discussed in Reno . Social media sites provide platforms for content originally generated by users. In that capacity, social media sites decide whether to host users' content and how that content is presented, and may alter that content in the process. Whether these editorial functions are \"speech\" protected by the First Amendment presents an especially difficult question. As one federal appellate court noted, \"entities that serve as conduits for speech produced by others\" may \"receive First Amendment protection\" if they \"engage in editorial discretion\" when \"selecting which speech to transmit.\" On the other hand, the court said, such an entity might not be \"a First Amendment speaker\" if it indiscriminately and neutrally transmits \"any and all users' speech.\" Some have argued that social media sites' publication decisions are protected under the First Amendment. Until recently, academic debate focused largely on whether the algorithms employed by search engines to retrieve and present results are properly characterized as the speech of those search engines. One scholar argued that search engines' publication activities meet at least one of the criteria necessary to qualify for First Amendment protection: these sites are publishing \"sendable and receivable substantive message[s]\"\u2014or, in other words, they are communicating content. Another scholar countered this argument by saying that indexing search results is not equivalent to communicating protected ideas, arguing that to be entitled to First Amendment protections, content must be \"adopted or selected by the speaker as its own.\" There are not many court decisions evaluating whether a social media site, by virtue of reprinting, organizing, or even editing protected speech, is itself exercising free speech rights. While a few federal courts have held that search engine results and decisions about whether to run advertisements are speech protected by the First Amendment, these decisions are, so far, limited to trial courts and therefore not precedential beyond the facts of those cases. This relative dearth of cases is likely due in large part to the fact that, as discussed above, Section 230 of the CDA bars a significant number of lawsuits that seek to hold social media providers liable for publishing others' content, often making it unnecessary to consider whether the First Amendment protects these publication decisions. Section 230 has sometimes been described as an attempt to protect the freedom of speech on the internet, suggesting that its displacement of the First Amendment is an implicit consequence of Section 230's speech-protective nature. In other words, Section 230 creates immunity even where the First Amendment might not. Due to the lack of case law examining the issue, commentators have largely analyzed the question of whether a social media site's publication decisions are protected by the First Amendment by analogy to other types of First Amendment cases. At least one scholar has argued that there are three possible frameworks a court could apply to analyze governmental restrictions on social media sites' ability to moderate user content. The first analogy would treat social media sites as equivalent to company towns. Under this scenario, social media sites would be treated as state actors who are themselves bound to follow the First Amendment when they regulate protected speech. The second possible framework would view social media sites as analogous to special industries like common carriers or broadcast media, in which the Court has historically allowed greater regulation of the industries' speech in light of the need to protect public access for users of their services. The third analogy would treat social media sites like news editors, who generally receive the full protections of the First Amendment when making editorial decisions. It is likely that no one analogy can account for all social media platforms, or all activities performed by those platforms. Some social media platforms may exercise more editorial control over user-generated content than others, and any given social media company performs a wide variety of different functions. Consequently, determining which line of case law is most analogous will likely depend on the particular activity being regulated. As discussed in more detail above, although the First Amendment generally applies only to government action, the Supreme Court has held that in limited, special circumstances, private actors should be treated as the government and must comply with constitutional standards when interacting with others. The archetypal case is that of the company town: in Marsh v. Alabama , the Supreme Court held that the residents of a company-owned town\u2014a town that was functionally identical to any ordinary town, but for the fact of its ownership\u2014were entitled to the protections of the First Amendment when distributing religious literature on the streets and sidewalks in that town. Courts have largely held that, under existing Supreme Court precedent, social media providers do not meet the First Amendment's state action requirement. Commentators have argued, however, that dicta in Supreme Court cases may suggest that social media sites should be treated differently. As an initial matter, there is language in Marsh suggesting that privately owned property may be subject to the First Amendment if it is opened for public use:  Ownership does not always mean absolute dominion. The more an owner, for his advantage, opens up his property for use by the public in general, the more do his rights become circumscribed by the statutory and constitutional rights of those who use it. Thus, the owners of privately held bridges, ferries, turnpikes and railroads may not operate them as freely as a farmer does his farm. Since these facilities are built and operated primarily to benefit the public and since their operation is essentially a public function, it is subject to state regulation. At least one scholar has argued that, with respect to online forums, \" Marsh should be expanded and read functionally.\" He suggests that courts should ask whether a given online space is the \"functional equivalent\" of a traditional public forum and should engage in a First Amendment analysis that treats private ownership as \"one factor\" when balancing \"the autonomy rights of property owners against the expressive rights of property users.\" But courts, by and large, have rejected the broader implications of this language in Marsh , and the Supreme Court has held that the mere fact that a private space is open to the public is not sufficient to \"entitle\" the public to the protections of the First Amendment in that space. Another scholar, however, has argued that notwithstanding \"this more narrow conception of the public function exception,\" social media sites should still be treated as equivalent to the state under Marsh . He claims that social media sites perform a \"public function\" under Marsh by \"providing a space that has the primary purpose of serving as a forum for public communication and expression, that is designated for that purpose, and that is completely open to the public at large.\" In his view, \"[s]ince managing public squares and meeting places is something that has traditionally been done by the government, social network websites therefore serve a public function that has traditionally been the province of the state.\" As mentioned above, however, trial courts have declined to extend Marsh to social media sites, disagreeing that the provision of a public forum or \"the dissemination of news and fostering of debate\" are public functions that were traditionally and exclusively performed by the government. Others have argued that a more recent Supreme Court decision, Packingham v. North Carolina , might \"signal a shift\" in the state action analysis. In Packingham , the Court struck down a North Carolina law that prohibited a registered sex offender from accessing any \"commercial social networking Web site where the sex offender knows that the site permits minor children to become members or to create or maintain personal Web pages.\" Critically, the Court stated that \"cyberspace\" is today \"the most important place[] . . . for the exchange of views\" protected by the First Amendment, analogizing Facebook, LinkedIn, and Twitter to traditional public forums and characterizing social media sites as \"the modern public square.\" In light of the importance of these forums, the Court concluded that the statute was too broad and not sufficiently tailored to serve the government's asserted interest.  Some have suggested that, if the Court views social media as \"the modern public square,\" it may be more willing to say that social media companies \"count as state actors for First Amendment purposes.\" Indeed, Justice Alito declined to join the majority opinion in Packingham because he was concerned about the scope of the Court's \"musings that seem to equate the entirety of the internet with public streets and parks.\" He argued that this broader language was \"bound to be interpreted by some\"\u2014erroneously, in his view\u2014as limiting the government's ability to \"restrict . . . dangerous sexual predators\" from some activities online. At least one court, however, has rejected some of the broader implications of this case, noting that \" Packingham did not, and had no occasion to, address whether private social media corporations like YouTube are state actors that must regulate the content of their websites according to the strictures of the First Amendment. Instead, .\u00a0. . Packingham concerned whether North Carolina ran afoul of the First Amendment . . . .\" If social media sites were treated as state actors under the First Amendment, then the Constitution itself would constrain their conduct when they act to restrict users' protected speech. Under this framework, Congress could enact legislation to remedy violations of free speech rights by social media entities. For instance, Title III of the Civil Rights Act of 1964 authorizes the Attorney General to bring a civil action against governmental facilities that deny a person equal access \"on account of his race, color, religion, or national origin,\" essentially granting the Attorney General the power to sue to enjoin certain acts that would violate the Fourteenth Amendment's Equal Protection Clause. To take another example, 42 U.S.C. \u00a7 1983 allows any person who has been deprived by a state actor \"of any rights, privileges, or immunities secured by the Constitution\" to bring certain civil actions to vindicate those rights in court. By contrast, commentators have argued that under this framework, the problems associated with social media sites hosting too much speech\u2014that is, problems caused by the dissemination of things like misinformation and hate speech\u2014would be exacerbated. If these companies were considered equivalent to state actors and their sites were seen as equivalent to traditional public forums, their ability to regulate speech would be relatively circumscribed. And in turn, so would the government be limited in its ability to require these platforms to take down certain types of content, if that content qualified as protected speech. Thus, one scholar predicted that under this framework, \"[a]ll but the very basest speech would be explicitly allowed and protected\u2014making current problems of online hate speech, bullying, and terrorism, with which many activists and scholars are concerned, unimaginably worse.\" However, to the extent that a federal regulation infringed on speech properly attributed to the social media sites, rather than their users\u2014and this speech could include not only content originally generated by the social media companies, but also their editorial decisions about user-generated content\u2014it could implicate an open First Amendment question. State and local governments are constrained by the First Amendment when they interact with individuals, but the Supreme Court has never squarely resolved whether states and municipalities could themselves assert First Amendment rights against the federal government. At least one scholar has argued that the First Amendment should protect government speech in certain circumstances. And in a 2015 case, the Supreme Court said that a private party could not force a state to include certain messages in its own speech, suggesting that governments do have some right to speak for themselves. On the other hand, Justice Stewart argued in a 1973 concurring opinion that the government has no First Amendment rights, significantly, maintaining that the Court should not treat broadcasters as state actors because it would \"simply strip\" them of their First Amendment rights. Lower courts have largely followed Justice Stewart's view and assumed that state actors may not claim the protection of the First Amendment. Accordingly, it is possible that treating social media sites like state actors would \"strip [them] of their own First Amendment rights.\"  Alternatively, courts could analogize social media sites to certain industries, like broadcast media, where the Supreme Court has traditionally allowed greater regulation of protected speech. These cases have their roots in the common law doctrines related to common carriers. Historically, a common carrier is an entity that \"holds itself out to the public as offering to transport freight or passengers for a fee.\" Often, these companies received government licenses authorizing their operations. Common carriers have traditionally been subject to heightened legal duties and generally could not refuse paying customers. Some of these common law doctrines have been incorporated into modern regulation of communications industries: federal statutes treat providers of telecommunications services as common carriers that are subject to certain requirements, and authorize the regulation of radio and television broadcasters. While acknowledging that these companies are private entities who do retain First Amendment rights, the Supreme Court has nonetheless allowed some regulation of these rights, in light of the heightened government interests in regulating such entities. As one federal appellate court has put it, the general \"absence of any First Amendment concern\" with \"equal access obligations\" in this area \"rests on the understanding that such entities, insofar as they are subject to equal access mandates, merely facilitate the transmission of the speech of others rather than engage in speech in their own right.\" However, courts have not treated all entities equated to common carriers identically. In Red Lion Broadcasting Co. v. FCC , the Supreme Court approved of a specific application of the Federal Communication Commission's (FCC's) \"fairness doctrine.\" The FCC rule challenged in Red Lion required broadcasters to give political candidates a reasonable opportunity to respond to any personal attacks published by the broadcaster or to any editorials in which a broadcaster endorsed or opposed particular candidates. The broadcasters argued that these regulations violated the First Amendment, abridging \"their freedom of speech and press\" by preventing them from \"exclud[ing] whomever they choose\" from their allotted frequencies.  The Supreme Court noted the unique nature of the broadcast industry, stating that due to \"the scarcity of radio frequencies,\" \"it is idle to posit an unabridgeable First Amendment right to broadcast comparable to the right of every individual to speak, write, or publish.\" This is why, the Court said, it had previously allowed regulations of broadcast media\u2014namely, a licensing system\u2014that might otherwise violate the First Amendment. The Court emphasized that \"[i]t is the right of the viewers and listeners, not the right of the broadcasters, which is paramount,\" highlighting \"the right of the public to receive suitable access to social, political, esthetic, moral, and other ideas and experiences.\" Ultimately, the Court held that \"[i]n view of the scarcity of broadcast frequencies, the Government's role in allocating those frequencies, and the legitimate claims of those unable without governmental assistance to gain access to those frequencies for expression of their views,\" the challenged regulations were constitutional. In subsequent cases, the Supreme Court has reaffirmed that \"of all forms of communication, it is broadcasting that has received the most limited First Amendment protection.\" The Court has recognized that broadcasters do engage in speech activity protected by the First Amendment, most notably when a broadcaster \"exercises editorial discretion in the selection and presentation of its programming.\" The Court has said that \"[a]lthough programming decisions often involve the compilation of the speech of third parties, the decisions nonetheless constitute communicative acts.\" Notwithstanding this conclusion, however, the Court has said that in this area, when evaluating broadcasters' First Amendment claims, it will \"afford great weight to the decisions of Congress and the experience of the [FCC].\" Significantly, the Supreme Court has declined to extend this special deference to government regulation of broadcasters to other forms of media. For example, in Turner Broadcasting Systems v. FCC , the Court concluded that the \"less rigorous\" First Amendment scrutiny that applies to broadcast regulation should not be extended to the \"regulation of cable television.\" The Court was considering the FCC's \"must-carry\" regulations, which required cable television broadcasters to set aside a portion of their channels for the transmission of local broadcast television stations. The Court said that cable television \"does not suffer from the inherent limitations,\" in terms of the scarcity of frequencies, \"that characterize the broadcast medium,\" consequently concluding that the \"unique physical characteristics of cable transmission . . . . do not require the alteration of settled principles of our First Amendment jurisprudence.\" Accordingly, the Court has subjected laws that restrict cable providers' protected speech to greater scrutiny than restrictions on broadcast media . But the Court noted in a subsequent decision that \"[c]able television, like broadcast media, presents unique problems . . . which may justify restrictions that would be unacceptable in other contexts.\" And in Turner Broadcasting itself, the Court did cite \"special characteristics of the cable medium\" to justify applying a lower level of scrutiny. The Court recognized that \"[r]egulations that discriminate among media, or among different speakers within a single medium, often present serious First Amendment concerns\" that trigger strict scrutiny. But notwithstanding this general rule, the Court explained that \"heightened scrutiny is unwarranted where,\" as with the must-carry provisions, the \"differential treatment is 'justified by some special characteristic of' the particular medium being regulated.\" Courts have sometimes interpreted Turner Broadcasting to mean that at least certain types of regulations on cable television will receive less scrutiny than, for example, a regulation affecting speech in a traditional public forum.  Ultimately, however, the Turner Broadcasting Court cited two justifications for applying intermediate scrutiny, rather than strict scrutiny, to the FCC's must-carry provisions, making it unclear which rationale the Court relied on to uphold the regulations. Prior to its discussion of cable's special characteristics, the Court concluded that intermediate scrutiny was appropriate because the must-carry provisions were \"content-neutral restrictions that impose[d] an incidental burden on speech.\" The Court noted that while the rules did \"interfere with cable operators' discretion . . . , the extent of the interference [did] not depend upon the content of the cable operators' programming.\" Although the must-carry provisions did \"distinguish between speakers,\" that discrimination was \"based only upon the manner in which speakers transmit their messages to viewers, and not upon the messages they carry,\" and, therefore, the rules were content-neutral on their face. Thus, it is somewhat unclear to what extent the Court's decision to apply intermediate scrutiny in Turner Broadcasting rested on \"special characteristics of the cable medium\" and to what extent it depended on a more overarching First Amendment principle regarding content neutrality. While the Supreme Court has identified \"unique problems\" that may justify greater regulation of broadcast and cable, it has expressly held that the factors that justify more extensive regulation of the broadcast media \"are not present in cyberspace.\" In Reno v. ACLU , decided in 1997, the Court said that the internet had not historically \"been subject to the type of government supervision and regulation that has attended the broadcast industry,\" that the internet was not \"as 'invasive' as radio or television\" because a person had to take affirmative action to receive a particular communication on the internet, and that the internet could \"hardly be considered a 'scarce' expressive commodity.\" Consequently, in the Court's view, the factors that justified \"qualifying the level of First Amendment scrutiny that should be applied to\" broadcast media did not apply to the internet. In Reno , the Court ultimately held that two provisions of the CDA that criminalized speech based on its content were unconstitutionally vague and overbroad.  Several legal scholars have argued that, contrary to the Court's conclusion in Reno , the internet is analogous to traditional broadcast media and therefore should be subject to greater regulation. Scholars have argued that as the internet has developed, it has \"reproduce[d] the traditional speech-hierarchy of broadcasting\": \"small, independent speakers [are] relegated to an increasingly marginal position while a handful of commercial giants capture the overwhelming majority of users' attention and reemerge as the essential gateways for effective speech.\" Thus, as one scholar argued, \"the hold of certain platforms\" over \"certain mediums of speech\" has \"created scarcity.\" Further, especially as compared to the internet in the late 1990s, when Reno was decided, the internet is \"now more invasive in everyday life\"\u2014arguably more invasive even than television and radio. Another commentator has claimed that rather than traditional broadcast media, search engines might be more analogous to cable providers. In her view, search engines, \"like cable companies,\" \"provide access to the speech of others\" but also \"exercise some degree of editorial discretion over whom they provide access to.\" The analogy may be extended to social media sites, as well, because, like search engines, they also exercise editorial discretion regarding who can post and view content on their sites, and regarding how user-generated content is presented.  One lower court rejected these arguments, with respect to search engines, in Zhang v. Baidu .com, Inc . In that case, the plaintiffs argued that Baidu, a Chinese search engine, had violated federal and state civil rights laws by blocking \"from its search results . . . information concerning 'the Democracy movement in China' and related topics.\" Baidu argued that its decisions to block these search results were protected by the First Amendment. The judge noted that \"some scholars\" had argued that under Turner Broadcasting , search-engine results should receive a \"lower level of protection.\" However, in the court's view, the First Amendment \"plainly shield[ed]\" the search engine from this particular lawsuit because the plaintiff's own suit sought \"to hold Baidu liable for, and thus punish Baidu for, a conscious decision to design its search-engine algorithms to favor certain expression on core political subjects over other expression on those same political subjects.\" Accordingly, the court said that \" Turner 's three principal rationales for applying a lower level of scrutiny to the must-carry cable regulations\u2014namely, that cable companies were mere conduits for the speech of others, that they had the physical ability to silence other speakers, and that the regulations at issue were content-neutral\u2014[we]re inapplicable\" to the case before it. The court concluded that Baidu was acting as more than a conduit for others' speech, at least according to the plaintiffs' allegations, that Baidu lacked \"the physical power to silence anyone's voices,\" and that a judicial decision penalizing \"Baidu precisely because of what it does and does not choose to say\" would not be content-neutral.  If courts treated social media sites like broadcast media or like cable providers, they would be more likely to uphold government regulation of social media providers. As a preliminary inquiry, a court would likely ask what regulations could be justified by specific characteristics of the regulated medium. If a court believed that the internet in general, or social media in particular, shared relevant characteristics with either traditional broadcast media or with cable providers, then it would be more likely to allow the types of regulations that have traditionally been permitted in those contexts. Thus, a court might ask whether social media sites, like cable companies, exercise a \"bottleneck monopoly power\" or whether, like broadcast television or radio, social media platforms suffer from a \"scarcity\" problem in terms of the number of platforms for speech or are so \"invasive\" as to justify regulation to address these problems. Related, courts might also ask whether the regulations are intended to increase the amount of information or expression available to the public. Thus, if social media sites present distinct problems that threaten the use of the medium for communicative or expressive purposes, courts might approve of regulations intended to solve those problems\u2014particularly if those regulations are content-neutral. These same types of considerations would likely apply both to regulations requiring these platforms to carry certain content and to those requiring the platforms not to carry certain content. But, at least for the time being, without an intervening change in the law, lower courts seem likely to follow Reno and conclude that there is \"no basis for qualifying the level of First Amendment scrutiny that should be applied to\" the internet. The third analogy courts might use to analyze whether social media sites moderating user content are exercising protected speech rights is that of the newspaper editor. In Miami Herald Publishing Co. v. Tornillo , the Supreme Court held that when newspapers \"exercise . . . editorial control and judgment,\" such as choosing what \"material [will] go into a newspaper,\" and making \"decisions . . . as to limitations on the size and content of the paper, and treatment of public issues and public officials,\" they are exercising free speech rights protected by the First Amendment. The Court in that case was considering the constitutionality of a state law that gave political candidates the \"right to reply to press criticism\" of the candidate. A newspaper challenged this statute, arguing that forcing it to print content that it would not otherwise publish violated the First Amendment. The government argued that its law was necessary due to the fact that relatively few news outlets exercised essentially a \"monopoly\" on \"the 'marketplace of ideas.'\" The regulation, in the state's view, \"[e]nsure[d] fairness and accuracy\" and \"provide[d] for some accountability.\"  The Supreme Court unanimously rejected this argument, noting that while \"press responsibility\" may be a \"desirable goal,\" it was \"not mandated by the Constitution\" and could not \"be legislated.\" The state law impermissibly \"exact[ed] a penalty on the basis of the content of the newspaper\" by forcing newspapers to spend money to print the replies and by \"taking up space that could be devoted to other material.\" Further, the Court held, \"[e]ven if a newspaper would face no additional costs to comply with a compulsory access law and would not be forced to forgo publication of news or opinion by the inclusion of a reply,\" the law violated the First Amendment \"because of its intrusion into the function of editors.\" Because newspapers exercise \"editorial control and judgment,\" the Court said, they are \"more than a passive receptacle or conduit for news, comment, and advertising,\" and instead engage in protected speech. The Court has recognized this First Amendment protection for editorial judgments outside the context of newspapers, stating more generally that \"compelling a private corporation to provide a forum for views other than its own may infringe the corporation's freedom of speech.\" For example, the Supreme Court said in Arkansas Educational Television Commission v. Forbes that \"[w]hen a public broadcaster exercises editorial discretion in the selection and presentation of its programming, it engages in speech activity.\" And in Pacific Gas & Electric Co . v. Public Utilities Commission , the Court recognized that a utility company had a First Amendment interest in selecting the content contained in its monthly newsletter. The Court said in Pacific Gas & Electric Co. that a state regulatory commission could not require the utility to grant access to entities who disagreed with the utility's views. This regulation infringed on the utility company's First Amendment rights by compelling it \"to assist in disseminating the speaker's message\" and by requiring it \"to associate with speech with which [the company] may disagree,\" forcing the company to respond to those arguments.  To take another example, in Hurley v. Irish-American Gay, Lesbian and Bisexual Group of Boston , the Court held that the private organizers of a parade had a First Amendment right to exclude the Irish-American Gay, Lesbian and Bisexual Group of Boston (GLIB) from the parade. GLIB had sued the parade organizers, arguing that their exclusion violated Massachusetts's antidiscrimination laws by barring them from a public accommodation on the basis of sexual orientation, and state courts had agreed that GLIB's exclusion violated state law. The parade organizers, however, claimed that the parade was an expressive activity and that forcing them to include GLIB's speech in the parade violated their First Amendment rights. The Supreme Court held first that a parade did qualify as \"protected expression,\" even though most of the speech in the parade was not that of the organizers themselves. The Court said that \"a private speaker does not forfeit constitutional protection simply by combining multifarious voices, or by failing to edit their themes to isolate an exact message as the exclusive subject matter of the speech.\" As an example, the Court noted that \"[c]able operators . . . are engaged in protected speech activities even when they only select programming originally produced by others.\" Accordingly, the Court concluded that the selection of parade participants was protected activity under the First Amendment. Consequently, in the Hurley Court's view, characterizing the parade as a public accommodation under the state's antidiscrimination law \"had the effect of declaring the sponsors' speech itself to be the public accommodation,\" and this exercise of state power \"violate[d] the fundamental rule of protection under the First Amendment, that a speaker has the autonomy to choose the content of his own message.\" GLIB argued that this application of the state's public accommodation law should be upheld under Turner Broadcasting , claiming that the parade organizers, \"like a cable operator,\" were \"merely a conduit for the speech of participants in the parade rather than itself a speaker.\" The Court disagreed, saying that unlike the cable operators, \"GLIB's participation would likely be perceived as\" a decision of the parade organizers that GLIB's \"message was worthy of presentation and quite possibly of support as well.\" The better analogy, in the Court's view, was to a newspaper. The Court said that viewers understand that cable programming consists of \"individual, unrelated segments that happen to be transmitted together,\" but in contrast, \"the parade's overall message is distilled from the individual presentations along the way, and each unit's expression is perceived by spectators as part of the whole.\" By contrast, the Supreme Court has rejected the application of Tornillo in cases where compelling a private entity to grant access to third parties would not affect the entity's own speech. First, in PruneY ard Shopping Center v. Robins , a private shopping center, PruneYard, had \"a policy not to permit any visitor or tenant to engage in any publicly expressive activity,\" and pursuant to that policy, asked a number of students distributing pamphlets and seeking signatures on petitions to leave. In a suit brought by the students, the California Supreme Court held that PruneYard's action violated state law, holding that the students \"were entitled to conduct their activity on PruneYard property.\" PruneYard argued that this decision violated their own free speech rights, claiming that \"a private property owner has a First Amendment right not to be forced by the State to use his property as a forum for the speech of others.\" The Court rejected this argument, noting that the government was not forcing PruneYard itself to espouse any specific views, and that PruneYard could \"expressly disavow any connection with\" any particular message. The Court said that under the circumstances, \"[t]he views expressed by members of the public\" would \"not likely be identified with those of the owner.\" The Court distinguished Tornillo on similar grounds in Rumsfeld v. Forum for Academic and Institutional Rights, Inc. (FAIR) . In that case, a group of law schools represented by FAIR protested the Solomon Amendment, which specified \"that if any part of an institution of higher education denies military recruiters access equal to that provided other recruiters, the entire institution would lose certain federal funds.\" Prior to the passage of the Solomon Amendment, some law schools had restricted military recruiting on campus on the basis that the military, through its \"policy on homosexuals in the military,\" violated the schools' nondiscrimination policies. FAIR argued that forcing the schools to \"disseminate or accommodate a military recruiter's message\" violated their First Amendment rights. The Court first noted that the Solomon Amendment primarily regulated conduct and only incidentally compelled speech, in the form of recruiting assistance such as sending emails or posting notices.  Further, the Court held that \"accommodating the military's message does not affect the law schools' speech, because the schools are not speaking when they host interviews and recruiting receptions.\" Distinguishing Hurley , the Court said that \"[u]nlike a parade organizer's choice of parade contingents, a law school's decision to allow recruiters on campus is not inherently expressive.\" The Court said that \"the expressive component\" of the schools' decisions to bar military recruiters was \"not created by the conduct itself but by the speech that accompanies it.\" Instead, as in PruneYard , the Court said that \"[n]othing about recruiting suggests that law schools agree with any speech by recruiters,\" noting that the schools remained free to state that they disagreed with the military's policies. A number of federal trial courts have applied Tornillo to hold that search engines exercise editorial judgment protected by the First Amendment when they make decisions about whether and how to present specific websites or advertisements in search results. For example, in Zhang v. Baidu.com, Inc. , the trial court noted that when search engines \"retrieve relevant information from the vast universe of data on the Internet and . . . organize it in a way that would be most helpful to the searcher,\" they \"inevitably make editorial judgments about what information (or kinds of information) to include in the results and how and where to display that information.\" Ultimately, the court held that the plaintiff's \"efforts to hold Baidu accountable in a court of law for its editorial judgments about what political ideas to promote cannot be squared with the First Amendment.\"  In line with this view, some scholars have maintained that search engine results represent protected speech because search engines make editorial judgments, \"reporting about others' speech\" in a way that \"is itself constitutionally protected speech. Others have pointed out, however, that such actions would likely be protected only insofar as they do communicate something to listeners. Thus, some scholars have argued that search results\u2014at least if those results are automated \"and experienced as 'objective'\"\u2014would not be protected under the First Amendment because the \"dominant function\" of these results \"is not to express meaning but rather to 'do things in the world'; namely, channel users to websites.\" On this issue, the court in Zhang , said that, given governing Supreme Court precedent, \"the fact that search engines often collect and communicate facts, as opposed to opinions, does not alter the analysis\": \"As the Supreme Court has held, 'the creation and dissemination of information are speech within the meaning of the First Amendment. Facts, after all, are the beginning point for much of the speech that is most essential to advance human knowledge and to conduct human affairs.'\" Reaching the same result through different reasoning, a different district court held that Google's \"PageRanks,\" which rank \"the relative significance of a particular web site as it corresponds to a search query,\" were protected under the First Amendment as subjective opinions. Commentators have argued that Tornillo should apply when, for example, Facebook promotes certain viewpoints over others, as Facebook is exercising editorial judgment about how to present constitutionally protected speech. The trial court's opinion in Zhang suggests that social media sites would be engaging in protected speech insofar as they, like search engines, \"make editorial judgments about what information (or kinds of information)\" to display \"and how and where to display that information.\" On the other hand, the Supreme Court's decision in FAIR suggests that under some circumstances, an entity's decision \"to allow\" third parties to use their platforms might not be expressing a particular view. As with search results, one critical question may be whether the content presentation decisions themselves are communicative or expressive, or whether instead they only take on an expressive meaning when combined with other speech.  Related to the question of whether content presentation decisions themselves are expressive, one possible argument against extending the editorial analogy to social media sites is that users would be unlikely to attribute users' speech to the social media sites. In Tornillo itself, the Court held that the newspapers' editorial judgments were protected under the First Amendment without expressly analyzing whether readers would attribute the published content to the newspaper. One significant factor in the Supreme Court's various decisions about whether to extend First Amendment protection to the groups hosting others' speech was whether listeners would be likely to attribute that speech to the host, such as the parade organizer, in Hurley , the shopping center, in PruneY ard , or the law schools, in FAIR .  Accordingly, courts may be less likely to conclude that social media sites' decisions regarding users' content are protected by the First Amendment if third parties would be unlikely to attribute users' speech to the social media sites themselves. Whether third parties would attribute user-generated content to social media platforms will likely depend on the particular site or activity being regulated. In particular, where platforms aggregate or alter user-generated content, users may be more likely to see that as the platforms' speech. If the sites aggregate user-generated content, courts may ask, as in Hurley , whether viewers would understand that content to \"consist of individual, unrelated segments\" that are \"neutrally presented,\" or whether instead viewers would understand that each segment \"is understood to contribute something to a common theme,\" and that the aggregate communicates an \"overall message.\" Accordingly, if a site aggregates content into a single story, courts might hold that the sites are acting as more than a mere \"conduit for speech produced by others.\" By contrast, if a site published all user content without restrictions, users' communications, like \"the views expressed by members of the public\" in PruneY ard , might not reasonably be \"identified\" as the views \"of the owner.\" So far, the trial court decisions extending the editorial analogy to search engines have not analyzed this issue in significant detail. If social media sites were considered to be equivalent to newspaper editors when they make decisions about whether and how to present users' content, then those editorial decisions would protected by the First Amendment. Any government regulation of those protected editorial functions that forced social media sites to host content that they would not otherwise transmit, or otherwise restricting those sites' \"autonomy to choose the content\" of their \"own message,\" would likely be subject to strict scrutiny. Similarly, regulations requiring social media providers not to publish protected speech on the basis of the speech's content, or punishing them for publishing that speech, might also be subject to strict scrutiny. To satisfy strict scrutiny, the government must show that the speech restriction \"furthers a compelling interest and is narrowly tailored to achieve that interest.\" Government actions are unlikely to be upheld if a court applies strict scrutiny. Nevertheless, the Supreme Court has, in rare instances, said that the government may \"directly regulate speech to address extraordinary problems, where its regulations are appropriately tailored to resolve those problems without imposing an unnecessarily great restriction on speech.\" Additionally, even if a court held that social media sites' editorial decisions are protected under the First Amendment, it might review a government regulation affecting those decisions under a lower level of scrutiny if the regulation is content-neutral. Even in a traditional public forum, the government may impose \"reasonable time, place and manner restrictions\" on speech. Thus, for example, the Supreme Court has said that while the government may regulate noise by \"regulating decibels\" or \"the hours and place of public discussion,\" it may not bar speech solely \"because some persons were said to have found the sound annoying.\" Accordingly, courts may uphold government regulations if they have only an incidental effect on speech, \"serve a substantial governmental interest,\" and do not \"burden substantially more speech than is necessary to further that interest.\"  The permissibility of federal regulation of social media sites will turn in large part on what activity is being regulated. To the extent that federal regulation specifically targets communicative content\u2014that is, speech\u2014or social media platforms' decisions about whether and how to present that content, that regulation may raise constitutional questions. While the Supreme Court has not yet weighed in on the question, lower courts have held that when search engines make decisions regarding the presentation of search results, they are exercising editorial functions protected as speech under the First Amendment. If this reasoning were to be extended to social media sites' decisions regarding the presentation of users' content, Congress's ability to regulate those decisions would be relatively limited.  However, even assuming that Congress were to regulate the protected speech of social media companies, this would not necessarily doom a regulation. If, for example, the particular speech being regulated is commercial speech, such as advertisements, the regulation would likely be evaluated under a lower level of scrutiny. In addition, the Court has recognized certain, relatively limited categories of speech that can be more readily regulated: \"For example, speech that is obscene or defamatory can be constitutionally proscribed because the social interest in order and morality outweighs the negligible contribution of those categories of speech to the marketplace of ideas.\" But even with respect to these categories of speech, the government may violate the First Amendment if it engages in further content or viewpoint discrimination within that category. Thus, the Supreme Court has said as an example that while \"the government may proscribe libel,\" \"it may not make the further content discrimination of proscribing only libel critical of the government.\" In addition, if the law imposes criminal liability, the Court may require a mental state requirement, so that, for example, the government has to prove that the defendant knew the speech was obscene. Courts will also apply a lower level of scrutiny to content-neutral regulations. A content-neutral law that regulates only \"the time, place, or manner of protected speech\" may be constitutional if it is \"narrowly tailored to serve a significant governmental interest.\" If a law is not only content-neutral but also focused primarily on regulating conduct, imposing only an incidental burden on speech, a court will uphold the regulation if \"it furthers an important or substantial governmental interest; if the governmental interest is unrelated to the suppression of free expression; and if the incidental restriction on alleged First Amendment freedoms is no greater than is essential to the furtherance of that interest.\" Thus, for example, in Turner Broadcasting , the Supreme Court held that the FCC's must-carry provisions should be reviewed under an intermediate standard, rather than under strict scrutiny, because the rules were content-neutral: their application did not depend on \"the content of the cable operators' programming\" or the messages of the speakers carried. And in FAIR , the Court upheld the Solomon Amendment under intermediate scrutiny after concluding that the law regulated conduct that was not \"inherently expressive\" and only incidentally burdened speech. The Court said that the law did \"not focus on the content of a school's recruiting policy,\" but on \"the result achieved by the policy.\"  Additionally, if Congress highlights \"special characteristics\" of social media to justify heightened regulation, courts may be more willing to uphold those regulations. Although the Supreme Court in Reno rejected certain \"special justifications\" that the government argued should allow greater regulation of the internet at large, some have argued that special characteristics of social media might justify limited regulation to address those issues, particularly if those justifications are distinct from the ones rejected in Reno , or if there is evidence that conditions have changed since that decision was issued. To date, however, no courts have found that such special justifications exist, let alone approved of regulations addressing those issues. Finally, Congress may consider how any new regulation would fit into the existing legal framework of the CDA's Section 230. Section 230 creates immunity from most civil lawsuits that seek to treat service providers as the \"publisher or speaker\" of content created by another, and also provides that interactive service providers may not be held liable for taking good faith action to restrict access to content that the provider or users deem \"obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable.\" Insofar as any new federal regulations would subject social media providers to liability for publishing content created by users, or for restricting access to that content, those regulations might conflict with Section 230, and Congress may consider expressly setting out the relationship between those new regulations and Section 230. As a general principle of law, courts are reluctant to imply that new statutes repeal prior laws unless the \"two statutes are in 'irreconcilable conflict,' or . . . the latter act covers the whole subject of the earlier one and 'is clearly intended as a substitute.'\" Accordingly, if a new law does not explain how it relates to Section 230, courts will attempt to read the statutes harmoniously, giving effect to both. If Congress were to create an express exception from Section 230, one issue would be determining the proper scope of that exception, so that Congress is allowing liability only for certain specific activity that it is seeking to discourage. Section 230 was enacted, in part, in response to a trial court decision ruling that an internet service provider should be considered a \"publisher\" of defamatory statements that a third party had posted on a bulletin board that it hosted, and could therefore be subject to suit for libel. Critical to the court's decision was the fact that the service provider had moderated its message boards, qualifying the site as a publisher for purposes of the libel claim in the view of the court. By specifying that no provider of an interactive computer service \"shall be treated as the publisher or speaker\" of another's content, Congress sought, among other things, to overturn this decision. A number of Representatives, including one of the bill's sponsors, said at the time that they wanted to ensure that \"computer Good Samaritans\" would not \"tak[e] on liability\" by regulating offensive content. As discussed, courts subsequently interpreted this provision to bar liability for a wide variety of legal claims, not solely suits for defamation. Section 230, enacted in 1996, has often been described as central to the development of the modern internet. One scholar asserted that \"no other sentence in the U.S. Code . . . has been responsible for the creation of more value than that one.\" Therefore, while Congress may want to modify this broad immunity, it is important to first understand how that immunity currently operates, and why it was created in the first place."
}