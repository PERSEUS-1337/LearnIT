{
    "title": "BJlowyHYPr",
    "content": "This paper introduces CloudLSTM, a new branch of recurrent neural models tailored to forecasting over data streams generated by geospatial point-cloud sources. We design a Dynamic Point-cloud Convolution (D-Conv) operator as the core component of CloudLSTMs, which performs convolution directly over point-clouds and extracts local spatial features from sets of neighboring points that surround different elements of the input. This operator maintains the permutation invariance of sequence-to-sequence learning frameworks, while representing neighboring correlations at each time step -- an important aspect in spatiotemporal predictive learning. The D-Conv operator resolves the grid-structural data requirements of existing spatiotemporal forecasting models and can be easily plugged into traditional LSTM architectures with sequence-to-sequence learning and attention mechanisms.\n     We apply our proposed architecture to two representative, practical use cases that involve point-cloud streams, i.e. mobile service traffic forecasting and air quality indicator forecasting. Our results, obtained with real-world datasets collected in diverse scenarios for each use case, show that CloudLSTM delivers accurate long-term predictions, outperforming a variety of neural network models. Point-cloud stream forecasting aims at predicting the future values and/or locations of data streams generated by a geospatial point-cloud S, given sequences of historical observations (Shi & Yeung, 2018) . Example data sources include mobile network antennas that serve the traffic generated by ubiquitous mobile services at city scale (Zhang et al., 2019b) , sensors that monitor the air quality of a target region (Cheng et al., 2018) , or moving crowds that produce individual trajectories. Unlike traditional spatiotemporal forecasting on grid-structural data, like precipitation nowcasting (Shi et al., 2015) or video frame prediction (Wang et al., 2018) , point-cloud stream forecasting needs to operate on geometrically scattered sets of points, which are irregular and unordered, and encapsulate complex spatial correlations. While vanilla Long Short-term Memories (LSTMs) have modest abilities to exploit spatial features (Shi et al., 2015) , convolution-based recurrent neural network (RNN) models, such as ConvLSTM (Shi et al., 2015) and PredRNN++ (Wang et al., 2018) , are limited to modeling grid-structural data, and are therefore inappropriate for handling scattered point-clouds. : Different approaches to geospatial data stream forecasting: predicting over input data streams that are inherently grid-structured, e.g., video frames using ConvLSTMs (top); mapping of pointcloud input to a grid, e.g., mobile network traffic collected at different antennas in a city, to enable forecasting using existing neural network structures (middle); forecasting directly over point-cloud data streams using historical information (as above, but without pre-processing), as proposed in this paper (bottom). permutations for the features (Li et al., 2018) . Through this, the proposed PointCNN leverages spatial-local correlations of point clouds, irrespective of the order of the input. Notably, although these architectures can learn spatial features of point-clouds, they are designed to work with static data, thus have limited ability to discover temporal dependencies. Next, we describe in detail the concept and properties of forecasting over point cloud-streams. We then introduce the DConv operator, which is at the core of our proposed CloudLSTM architecture. Finally, we present CloudLSTM and its variants, and explain how to combine CloudLSTM with Seq2seq learning and attention mechanisms, to achieve precise forecasting over point-cloud streams. We formally define a point-cloud containing a set of N points, as S = {p 1 , p 2 , \u00b7 \u00b7 \u00b7 , p N }. Each point p n \u2208 S contains two sets of features, i.e., p n = {\u03bd n , \u03c2 n }, where \u03bd n = {v 1 n , \u00b7 \u00b7 \u00b7 , v H n } are value features (e.g., mobile traffic measurements, air quality indexes, etc.) of p n , and \u03c2 n = {c 1 n , \u00b7 \u00b7 \u00b7 , c L n } are its L-dimensional coordinates. At each time step t, we may obtain U different channels of S by conducting different measurements denoted by S Note that, in some cases, each point's coordinates may be unchanged, since the data sources are deployed at fixed locations. An ideal point-cloud stream forecasting model should embrace five key properties, similar to other point-cloud applications and spatiotemporal forecasting problems (Qi et al., 2017a; Shi et al., 2017) : (i) Order invariance: A point cloud is usually arranged without a specific order. Permutations of the input points should not affect the output of the forecasting (Qi et al., 2017a) . (ii) Information intactness: The output of the model should have exactly the same number of points as the input, without losing any information, i.e., N out = N in . (iii) Interaction among points: Points in S are not isolated, thus the model should be able to capture local dependencies among neighboring points and allow interactions (Qi et al., 2017a) . (iv) Robustness to transformations: The model should be robust to correlation-preserving transformation operations on point-clouds, e.g., scaling and shifting (Qi et al., 2017a) . (v) Location variance: The spatial correlations among points may change over time. Such dynamic correlations should be revised and learnable during training (Shi et al., 2017) . In what follows, we introduce the Dynamic Point Cloud Convolution (DConv) operator as the core module of the CloudLSTM, and explain how DConv satisfies the aforementioned properties. The Dynamic Point Cloud Convolution operator (DConv) generalizes the ordinary convolution on grids. Instead of computing the weighted summation over a small receptive field for each anchor point, DConv does so on point-clouds, while inheriting desirable properties of the ordinary convolution operation. The vanilla convolution takes U in channels of 2D tensors as input, and outputs U out channels of 2D tensors of smaller size (if without padding). Similarly, the DConv takes U in channels of a point-cloud S, and outputs U out channels of a point-cloud, but with the same number of elements as the input, to ensure the information intactness property (ii) discussed previously. For simplicity, we denote the i th channel of the input set as S and S j out are 3D tensors, of shape (N, (H +L), U in ) and (N, (H +L), U out ) respectively. We also define Q K n as a subset of points in S i in , which includes the K nearest points with respect to p n in the Euclidean space, i.e., Q n is the k-th nearest point to p n in the set S i in . Note that p n itself is included in Q K n as an anchor point, i.e., p n \u2261 p 1 n . Recall that each p n \u2208 S contains H value features and L coordinate features, i.e., p n = {\u03bd n , \u03c2 n }, where Here, each w k is a set of weights w with index k (i.e., k-th nearest neighbor) in Eq. 2, shared across different p. in S i in , the DConv sums the element-wise product over all features and points in Q K n , to obtain the values and coordinates of a point p n in S j out . Note that we assume the value features are related to their positions at the previous layer/state, to better exploit the dynamic spatial correlations. Therefore, we aggregate coordinate features c(p In the above, we define learnable weights W as 5D tensors with shape . The weights are shared across different anchor points in the input map. Each element w m,m ,k i,j \u2208 W is a scalar weight for the i-th input channel, j-th output channel, k-th nearest neighbor of each point corresponding to the m-th value and coordinate features for each input point, and m -th value and coordinate features for output points. Similar to the convolution operator, we define b j as a bias for the j-th output map. In the above, h and h are the h ( ) -th value features of the input/output point set. Likewise, l and l are the l ( ) -th coordinate features of the input/output. \u03c3(\u00b7) is the sigmoid function, which limits the range of predicted coordinates to (0, 1), to avoid outliers. Before feeding them to the model, the coordinates of raw point-clouds are normalized to (0, 1) by \u03c2 = (\u03c2 \u2212 \u03c2 min )/(\u03c2 max \u2212 \u03c2 min ), on each dimension. This improves the transformation robustness of the operator. The K nearest points can vary for each channel at each location, because the channels in the pointcloud dataset may represent different types of measurements. For example, channels in the mobile traffic dataset are related to the traffic consumption of different mobile apps, while those in the air quality dataset are different air quality indicators (SO 2 , CO, etc.). The spatial correlations will vary between different measurements (channels), due to human mobility. For instance, more people may use Facebook at a social event, but YouTube traffic may be less significant in this case. This will be reflected by the data consumption of each app. The same applies to air quality indicators affected by vehicle movement and factory working times. We want these spatial correlations to be learnable, so we do not fix the K nearest neighbors across channels, but encourage each channel to find the best neighbor set. This is also a contribution of the CloudLSTM, which helps improve the forecasting performance. We provide a graphical illustration of DConv in Fig. 2 . For each point p n , the DConv operator weights its K nearest neighbors across all features, to produce the values and coordinates in the next layer. Since the permutation of the input neither affects the neighboring information nor the ranking of their distances for any Q K n , DConv is a symmetric function whose output does not depend on the input order. This means that the property (i) discussed in Sec. 3.1 is satisfied. Further, DConv is performed on every point in set S i in and produces exactly the same number of features and points for its output; property (ii) is therefore naturally fulfilled. In addition, operating over a neighboring point set, irrespective of its layout, allows to capture local dependencies and improve the robustness to global transformations (e.g., shifting and scaling). The normalization over the coordinate features further improves the robustness to those transformations, as shown by the proof in Appendix C. This enables to meet the desired properties (iii) and (iv). More importantly, DConv learns the layout and topology of the cloud-point for the next layer, which changes the neighboring set Q K n for each point at output S j out . This enables the \"location-variance\" (property (v)), allowing the model to perform dynamic positioning tailored to each channel and time step. This is essential in spatiotemporal forecasting neural models, as spatial correlations change over time (Shi et al., 2017) . DConv can be efficiently implemented using simple 2D convolution, by reshaping the input map and weight tensor, which can be parallelized easily in existing deep learning frameworks. We detail this in Appendix A and provide a complexity analysis of the DConv operator in Appendix B. Relations with PointCNN (Li et al., 2018) and Deformable Convolution (Dai et al., 2017) . The DConv operator builds upon the PointCNN (Li et al., 2018) and deformable convolution neural network (DefCNN) on grids (Dai et al., 2017) , but introduces several variations tailored to pointcloud structural data. PointCNN employs the X -transformation over point clouds, to learn the weight and permutation on a local point set using multilayer perceptrons (MLPs), which introduces extra complexity. This operator guarantees the order invariance property, but leads to information loss, since it performs aggregation over points. In our DConv operator, the permutation is maintained by aligning the weight of the ranking of distances between point p n and Q K n . Since the distance ranking is unrelated to the order of the inputs, the order invariance is ensured in a parameter-free manner without extra complexity and loss of information. Further, the DConv operator can be viewed as the DefCNN (Dai et al., 2017) over point-clouds, with the differences that (i) DefCNN deforms weighted filters, while DConv deforms the input maps; and (ii) DefCNN employs bilinear interpolation over input maps with a set of continuous offsets, while DConv instead selects K neighboring points for its operations. Both DefCNN and DConv have transformation modeling flexibility, allowing adaptive receptive fields on convolution. The DConv operator can be plugged straightforwardly into LSTMs, to learn both spatial and temporal correlations over point-clouds. We formulate the Convolutional Point-cloud LSTM (CloudLSTM) as: Similar to ConvLSTM (Shi et al., 2015) , i t , f t , and o t , are input, forget, and output gates respectively. C t denotes the memory cell and H t is the hidden states. Note that i t , f t , o t , C t , and H t are all point cloud representations. W and b represent learnable weight and bias tensors. In Eq. 3, ' ' denotes the element-wise product, ' ' is the DConv operator formalized in Eq. 2, and ' * ' a simplified DConv that removes the sigmoid function in Eq. 2. The latter only operates over the gates computation, as the sigmoid functions are already involved in outer calculations (first, second, and fourth expressions in Eq. 3). We show the structure of a basic CloudLSTM cell in the left part of Fig. 3 . We combine our CloudLSTM with Seq2seq learning (Sutskever et al., 2014) and the soft attention mechanism (Luong et al., 2015) , to perform forecasting, given that these neural models have been proven to be effective in spatiotemporal modelling on grid-structural data (e.g., (Shi et al., 2015; ). We show the overall Seq2seq CloudLSTM in the right part of Fig. 3 . The architecture incorporates an encoder and a decoder, which are different stacks of CloudLSTMs. The encoder encodes the historical information into a tensor, while the decoder decodes the tensor into predictions. The states of the encoder and decoder are connected using the soft attention mechanism via a context vector (Luong et al., 2015) . Before feeding the point-cloud to the model and generating the final forecasting, the data is processed by Point Cloud Convolutional (CloudCNN) layers, which perform the DConv operations. Their function is similar to the word embedding layer in natural language processing tasks (Mikolov et al., 2013) , which helps translate the raw point-cloud into tensors and vice versa. In this study, we employ a two-stack encoder-decoder architecture, and configure 36 channels for each CloudLSTM cell, as we found that further increasing the number of stacks and channels does not improve the performance significantly. Beyond CloudLSTM, we also explore plugging the DConv into vanilla RNN and Convolutional GRU, which leads to a new Convolutional Point-cloud RNN (CloudRNN) and Convolutional Point-cloud GRU (CloudGRU), as formulated in the Appendix E. The CloudRNN and CloudGRU share a similar Seq2seq architecture with CloudLSTM, except that they do not employ the attention mechanism. We compare their performance in the following section. To evaluate the performance of our architectures, we employ measurement datasets of traffic generated by 38 mobile services and recorded at individual network antennas, and of 6 air quality indicators collected at monitoring stations. We use the proposed CloudLSTM to forecast future mobile service demands and air quality indicators in the target regions. We provide a comprehensive comparison with 12 baseline deep learning models, over four performance metrics. All models considered in this study are implemented using the open-source Python libraries TensorFlow (Abadi et al., 2016) and TensorLayer (Dong et al., 2017) . We train all architectures with a computing cluster with two NVIDIA Tesla K40M GPUs. We optimize all models by minimizing the mean square error (MSE) between predictions and ground truth, using the Adam optimizer (Kingma & Ba, 2015) . Next, we first introduce the datasets employed in this study, then discuss the baseline models used for comparison. Finally, we report on the experimental results obtained. We conduct experiments on two typical spatiotemporal point-cloud stream forecasting tasks over 2D geospatial environments, with measurements collected in two different scenarios for each use case. Note that, as the data sources have fixed locations in these applications, the coordinate features will be omitted in the final output. However, in different use cases, such as crowd mobility forecasting, the coordinate features would be necessarily included. Mobile Traffic Forecasting. We experiment with large-scale multi-service datasets collected by a major operator in two large European metropolitan areas with diverse topology and size during 85 consecutive days. The data consists of the volume of traffic generated by devices associated to each of the 792 and 260 antennas in the two target cities, respectively. The antennas are non-uniformly distributed over the urban regions, thus they can be viewed as 2D point clouds over space. At each antenna, the traffic volume is expressed in Megabytes and aggregated over 5-minute intervals, which leads to 24,482 traffic snapshots. These snapshots are gathered independently for each of 38 different mobile services, selected among the most popular apps for video streaming, gaming, messaging, cloud services, and social networking. Further details about the dataset can be found in Appendix G. Air Quality Forecasting. Air quality forecasting performance is investigated using a public dataset (Zheng et al., 2015) , which comprises six air quality indicators (i.e., PM2.5, PM10, NO 2 , CO, O 3 and SO 2 ) collected by 437 air quality monitoring stations in China, over a span of one year. The monitoring stations are partitioned into two city clusters, based on their geographic locations, and measure data on an hourly basis. The dataset includes 8,760 snapshots in total for each cluster. We conduct experiments on both clusters individually and fill missing data using linear interpolation. The reader is referred to Appendix G for details. Before feeding to the models, the measurements associated to each mobile service and air quality indicator are transformed into different input channels of the point-cloud S. All coordinate features \u03c2 are normalized to the (0, 1) range. In addition, for the baseline models that require grid-structural input (i.e., CNN, 3D-CNN, ConvLSTM and PredRNN++), the point-clouds are transformed into grids (Zhang et al., 2019a) using the Hungarian algorithm (Kuhn, 1955) . The ratio of training plus validation, and test sets is 8:2. We compare the performance of our proposed CloudLSTM with a set of baseline models, as follows. PointCNN (Li et al., 2018) performs convolution over point-clouds and has been employed for point-cloud classification and segmentation. CloudCNN is an original benchmark we introduce, which stacks the proposed DConv operator over multiple layers for feature extraction from pointclouds. PointLSTM is another original benchmark, obtained by replacing the cells in ConvLSTM with the X -Conv operator employed by PointCNN, which provides a fair term of comparison for other Seq2seq architectures. Beyond these models, we also compare the CloudLSTM with two of its variations, i.e., CloudRNN and CloudGRU, which were introduced in Sec. 3.3. Other baseline models, including MLP (Goodfellow et al., 2016) , CNN (Krizhevsky et al., 2012) , 3D-CNN (Ji et al., 2013) , LSTM (Hochreiter & Schmidhuber, 1997) , ConvLSTM (Shi et al., 2015) PredRNN++ (Wang et al., 2018) , along with the detailed configuration of all models are discussed in Appendix E. We quantify the accuracy of the proposed CloudLSTM in terms of Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). Since the mobile traffic snapshots can be viewed as \"urban images\" (Liu et al., 2015) , we also select Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) (Hore & Ziou, 2010) to quantify the fidelity of the forecasts and their similarity with the ground truth, as suggested by relevant recent work . Details about the metrics are discussed in Appendix F. For the mobile traffic prediction task, we employ all neural networks to forecast city-scale mobile traffic consumption over a time horizon of J = 6 sampling steps, i.e., 30 minutes, given M = 6 consecutive past measurements. For RNN-based models, i.e., LSTM, ConvLSTM, PredRNN++, CloudLSTM, CloudRNN, and CloudGRU, we then extend the number of prediction steps to J = 36, i.e., 3 hours, to evaluate their long-term performance. In the air quality forecasting use case, all models receive a half day of measurements, i.e., M = 12, as input, and forecast indicators in the following 12 hours, i.e., J = 12. As for the previous use case, the number of prediction steps are then extended to J = 72, or 3 days, for all RNN-based models. We perform 6-step forecasting for 4,888 instances across the test set, and report in Table 1 the mean and standard deviation (std) of each metric. We also investigate the effect of a different number of neighboring points (i.e., K = 3, 6, 9), as well as the influence of the attention mechanism. Observe that RNN-based architectures in general obtain superior performance, compared to CNNbased models and the MLP. In particular, our proposed CloudLSTM, and its CloudRNN, and CloudGRU variants outperform all other banchmark architectures, achieving lower MAE/RMSE and higher PSNR/SSIM on both urban scenarios. This suggests that the DConv operator learns features over geospatial point-clouds more effectively than vanilla convolution and PointCNN. Among our approaches, CloudLSTM performs better than CloudGRU, which in turn outperforms CloudRNN. Interestingly, the forecasting performance of the CloudLSTM seems fairly insensitive to the number of neighbors (K); it is therefore worth using a small K in practice, to reduce model complexity. Further, we observe that the attention mechanism improves the forecasting performance, as it helps capturing better dependencies between input sequences and vectors in decoders. This effect has also been confirmed by other NLP tasks. We provide a complete service-wise evaluation in Appendix H. Long-term Forecasting Performance. We extend the prediction horizon to up to J = 36 time steps (i.e., 3 hours) for all RNN-based architectures, and show their MAE evolution with respect to this horizon in Fig. 4 . Note that the input length remains unchanged, i.e., 6 time steps. In city 1, observe that the MAE does not grow significantly with the prediction step for most models, as the curves flatten. This means that these models are reliable in terms of long-term forecasting. As for city 2, we note that low K may lead to poorer long term performance for CloudLSTM, though not significant before step 20. This provides a guideline on choosing K for different forecast lengths required. We employ all models to deliver 12-step air quality forecasting on six indicators, given 12 snapshots as input. Results are in Table 2 . Also in this use case, the proposed CloudLSTMs attain the best performance across all 4 metrics, outperforming state-of-the-art methods (ConvLSTM) by up to 12.2% and 8.8% in terms of MAE and RMSE, respectively. Unlike in the mobile traffic forecasting results, a lower K yields better prediction performance, though the difference appears subtle. Again, the CloudCNN always proves superior to the PointCNN, indicating that CloudCNNs are better feature extractors over point-clouds. Overall, these results demonstrate the effectiveness of the CloudLSTM models for modeling spatiotemporal point-cloud stream data, regardless of the tasks to which they are applied. Performance evaluations of long-term forecasting, i.e., up to 72 future time steps, are conducted on RNN-based models and results are presented in Appendix I. Note that we conduct our experiments using strict variable-controlling methodology, i.e., only changing one factor while keep the remaining the same. Therefore, it is easy to study the effect of each factor. For example, taking a look at the performance of LSTM, ConvLSTM, PredRNN++, PointLSTM and CloudLSTM, which employ dense layers, and CNN, PointCNN and D-Conv as core operators but using LSTM as the RNN structure, it is clear that the D-Conv contributes significantly to the performance improvements. Further, by comparing CloudRNN, CloudGRU and CloudLSTM, it appears that CloudRNN CloudGRU < CloudLSTM. Similarly, by comparing the CloudLSTM and Attention CloudLSTM, we see that the effects of the attention mechanism are not very significant. Therefore, we believe the core operator > RNN structure > attention, ranked by their contribution. We introduce CloudLSTM, a dedicated neural model for spatiotemporal forecasting tailored to pointcloud data streams. The CloudLSTM builds upon the DConv operator, which performs convolution over point-clouds to learn spatial features while maintaining permutation invariance. The DConv simultaneously predicts the values and coordinates of each point, thereby adapting to changing spatial correlations of the data at each time step. DConv is flexible, as it can be easily combined with various RNN models (i.e., RNN, GRU, and LSTM), Seq2seq learning, and attention mechanisms. The DConv can be efficiently implemented using a standard 2D convolution operator, by data shape transformation. We assume a batch size of 1 for simplicity. Recall that the input and output of DConv, S in and S out , are 3D tensors with shape (N, (H + L), U in ) and (N, (H + L), U out ), respectively. Note that for each p n in S i in , we find the set of top K nearest neighbors Q K n . Combining these, we transform the input into a 4D tensor S i in , with shape (N, K, (H + L), U in ). To perform DConv over S i in , we split the operator into the following steps: Algorithm 1 Efficient algorithm for DConv implementation using the 2D convolution operator 1: Inputs: The weight tensor W. in , W) with step 1 without padding. S out becomes a 3D tensor with shape (N, 1, U out \u00d7 (H + L)) 6: Reshape the output map S out to (N, (H + L), U out ) 7: Apply the sigmoid function \u03c3(\u00b7) to the coordinates feature in S out This enables to translate the DConv into a standard convolution operation, which is highly optimized by existing deep learning frameworks. We study the complexity of DConv by separating the operation into two steps: (i) finding the neighboring set Q K n for each point p n \u2208 S, and (ii) performing the weighting computation in Eq. 2. We discuss the complexity of each step separately. For simplicity and without loss of generality, we assume the number of input and output channels are both 1. For step (i), the complexity of finding K nearest neighbors for one point is close to O(K \u00b7 L log N ), 1 if using KD trees (Bentley, 1975 ). For step (ii), it is easy to see from Eq. 2 that the complexity of computing one feature of the output p n is O((H + L) \u00b7 K). Since each point has (H + L) features and the output point set S j out has N points, the overall complexity of step 2 ). This is equivalent to the complexity of a vanilla convolution operator, where both the input and output have (H + L) channels, and the input map and kernel have N and K elements, respectively. This implies that, compared to the convolution operator whose inputs, outputs, and filters have the same size, DConv introduces extra complexity by searching the K nearest neighbors for each point O(K \u00b7 L log N ). Such complexity does not increase much even with higher dimensional point clouds. We show that the normalization of the coordinates features enables transformation invariance with shifting and scaling. The shifting and scaling of a point can be represented as: where A and B are a positive scaling coefficient and respectively an offset. By normalizing the coordinates, we have: This implies that, by using normalization, the model is invariant to shifting and scaling transformations. We combine our proposed CloudLSTM with the attention mechanism introduced in (Luong et al., 2015) . We denote the j-th and i-th states of the encoder and decoder as H j en and H i de . The context tensor for state i at the encoder can be represented as: where e i,j is a score function, which can be selected among many alternatives. In this paper, we choose e i,j = v We compared our proposal against a set of baselines models. MLP (Goodfellow et al., 2016) , CNN (Krizhevsky et al., 2012) , and 3D-CNN (Ji et al., 2013) are frequently used as benchmarks in mobile traffic forecasting (Zhang & Patras, 2018; Bega et al., 2019) . DefCNN learns the shape of the convolutional filters and has similarities with the DConv operator proposed in this study (Dai et al., 2017) . LSTM is an advanced RNN frequently employed for time series forecasting (Hochreiter & Schmidhuber, 1997) . While ConvLSTM (Shi et al., 2015) can be viewed as a baseline model for spatiotemporal predictive learning, the PredRNN++ is the state-of-the-art architecture for spatiotemporal forecasting on grid-structural data and achieves the best performance in many applications (Wang et al., 2018) . The CloudRNN and CloudGRU have can be formulated as: CloudGRU: (8) The CloudRNN and CloudGRU share a similar Seq2seq architecture with CloudLSTM, except that they do not employ the attention mechanism. We show in Table 3 the detailed configuration along with the number of parameters for each model considered in this study. Note that we used 2 layers (same as our CloudLSTMs) for ConvLSTM, PredRNN++ and PointLSTM, since we found that increasing the number of layers did not improve their performance. 3 \u00d7 3 filters are commonly used in image applications, where they have been proven effective. This yields a receptive field of 9 (3 \u00d7 3), which is equivalent to K = 9 in our CloudLSTMs. Thus this supports a fair comparison. In addition, the PredRNN++ follows a slightly different structure than that of other Seq2seq models, as specified in the original paper. 2-stack Seq2seq CloudLSTM, with 36 channels and K = 3 CloudLSTM (K = 6) 2-stack Seq2seq CloudLSTM, with 36 channels and K = 6 CloudLSTM (K = 9) 2-stack Seq2seq CloudLSTM, with 36 channels and K = 9 Attention CloudLSTM 2-stack Seq2seq CloudLSTM, with 36 channels, K = 9 and soft attention mechanism We optimize all architectures using the MSE loss function: Here v h n is the mobile traffic volume forecast for the h-th service, and respectively the forecast value of the h-th air quality indicator, at antenna/monitoring station n, at time t, while v h n is the corresponding ground truth. We employ MAE, RMSE, PSNR and SSIM to evaluate the performance of our models. These are defined as: (10) PSNR(t) = 20 log v max (t) \u2212 10 log 1 where \u00b5 v (t) and v max (t) are the average and maximum traffic recorded for all services/quality indicators, at all antennas/monitoring stations and time instants of the test set. VAR(\u00b7) and COV(\u00b7) denote the variance and covariance, respectively. Coefficients c 1 and c 2 are employed to stabilize the fraction in the presence of weak denominators. Following standard practice, we set 2 , where L = 2 is the dynamic range of float type data, and k 1 = 0.1, k 2 = 0.3. City 2 Figure 5 : The anonymized locations of the antenna set in both cities. The measurement data is collected via traditional flow-level deep packet inspection at the packet gateway (P-GW). Proprietary traffic classifiers are used to associate flows to specific services. Due to data protection and confidentiality constraints, we do not disclose the name of the operator, the target metropolitan regions, or the detailed operation of the classifiers. For similar reasons, we cannot name the exact mobile services studied. We show the anonymized locations of the antennas sets in both cities in Fig. 5 As a final remark on data collection, we stress that all measurements were carried out under the supervision of the competent national privacy agency and in compliance with applicable regulations. In addition, the dataset we employ for our study only provides mobile service traffic information accumulated at the antenna level, and does not contain personal information about individual subscribers. This implies that the dataset is fully anonymized and its use for our purposes does not raise privacy concerns. Due to a confidentiality agreement with the mobile traffic data owner, the raw data cannot be made public. As already mentioned, the set of services S considered in our analysis comprises 38 different services. An overview of the fraction of the total traffic consumed by each service and each category in both cities throughout the duration of the measurement campaign is in Fig. 6 . The left plot confirms the power law previously observed in the demands generated by individual mobile services. Also, streaming is the dominant type of traffic, with five services ranking among the top ten. This is confirmed in the right plot, where streaming accounts for almost half of the total traffic consumption. Web, cloud, social media, and chat services also consume large fractions of the total mobile traffic, between 8% and 17%, whereas gaming only accounts for 0.5% of the demand. The air quality dataset comprises air quality information from 43 cities in China, collected by the Urban Computing Team at Microsoft Research. In total, there are 2,891,393 air quality records from 437 air quality monitoring stations, gathered over a period of one year. The stations are partitioned into two clusters, based on their geographic locations, as shown in Fig. 7 . Cluster A has 274 stations, while Cluster B includes 163. Note that missing data exists in the records and gaps have been filled through linear interpolation. The dataset is available at https://www.microsoft.com/ en-us/research/project/urban-air/. We dive deeper into the performance of the proposed Attention CloudLSTMs, by evaluating the forecasting accuracy for each individual mobile service, averaged over 36 steps. To this end, we present the MAE evaluation on a service basis (left) and category basis (right) in Fig. 8 . Observe that the attention CloudLSTMs obtain similar performance over both cities at the service and category level. Jointly analyzing with Fig. 6 , we see that services with higher traffic volume on average (e.g., streaming and cloud) also yield higher prediction errors. This is because their traffic evolution exhibits more frequent fluctuations, which introduces higher uncertainty, making the traffic series more difficult to predict. Figure 9: MAE evolution wrt. prediction horizon achieved by RNN-based models on both city clusters for the air quality forecasting. We show the MAE for long-term forecasting (72 steps) of air quality on both city clusters in Fig. 9 . Generally, the error grows with time for all models, as expected. Turning attention to the CloudLSTM with different K, though the performance of different settings appears similar at the beginning, larger K can significantly improve the robustness of the CloudLSTM, as the MAE grows much slower with time when K = 9. This is consistent with the conclusion made in the mobile traffic forecasting task. We complete the evaluation of the mobile traffic forecasting task by visualizing the hidden features of the CloudLSTM, which provide insights into the knowledge learned by the model. In Fig. 10 , we show an example of the scatter distributions of the hidden state in H t of CloudLSTM and Attention CloudLSTM at both stacks, along with the first input snapshots. The first 6 columns show the H t for encoders, while the rest are for decoders. The input data snapshots are samples selected from City 2 (260 antennas/points). Recall that each H t has 1 value features and 2 coordinate features for each point, therefore each scatter subplot in Fig. 10 Step 1 Attention Cloud-LSTM Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Step 9 Step 10 Step 11 Step 12 Figure 11: NO 2 forecasting examples in City Cluster A generated by all RNN-based models. stack 2, as features are extracted at a higher level, exhibiting more direct spatial correlations with respect to the output. Lastly, in Fig. 11 and 12 and we show a set of NO 2 forecasting examples in both city cluster A and B considered for air quality prediction, generated by all RNN-based models, offering a performance comparison from a purely visual perspective. Point-clouds are converted into heat maps using 2D linear interpolation. The better prediction offered by (Attention) CloudLSTMs is apparent, as our proposed architectures capture trends in the point-cloud streams and deliver high long-term visual fidelity, whereas the performance of other architectures degrade rapidly in time. Step 1 Attention Cloud-LSTM Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Step 9 Step 10 Step 11 Step 12 Figure 12: NO 2 forecasting examples in Cluster B generated by the RNN-based models. The DConv uses Sigmoid functions to regularize the coordinate features of each point, such that those points which are far from others will move closer to each other and be more involved in the computation. Further, by stacking multiple DConv via dedicated structure (LSTM), the CloudLSTM has much stronger representability and therefore allows to refine the positions of each input point at each time step and each stack. Eventually, each point can learn to move to the position where it is best to be and therefore, our model continues to work well while forecasting with outlier points. For demonstration, we use the density-based spatial clustering of applications with noise (DBSCAN) to find those outliers (red points) in both clusters in the air quality dataset, as shown in Fig. 13 . For each city cluster, the DBSCAN algorithm finds 16 outlier points, which are relatively isolated and far from the point-cloud center. We recompute the MAE and RMSE performance especially for these outlier points, as shown in Table 4 . Observe that our CloudLSTM still obtains the lowest prediction error as compared to the other models considered. Taking a closer look at the CNN-based models, the CloudCNN, which employs the DConv operator, obtains the best forecasting performance relative to CNN, 3D-CNN, DefCNN and PointCNN. We dive deeper into the robustness of our CloudLSTM to outliers by conducting experiments under more controlled scenarios. To this end, we randomly selected 50 weather stations in each city cluster and construct a toy dataset. Among these weather stations, we randomly pick 10 as outliers, and move their positions away from the center by d = {0, 0.5, 1, 5} on both x and y axes. The direction of movement depends on the quadrant of each outlier. Note that the original position of each weather station is normalized to [0, 1], so d = 5 means the point is moved at a distance 5 times the maximum range of its original position. The positions of the remaining 40 weather stations remain unchanged. We show the positions of each weather stations after moving by different d for both city clusters in Fig. 14 and 15 . We retrain the CloudLSTM and PointLSTM under the same settings, and show the MAE and RMSE performance of each in Table. 5. Observe that the proposed CloudLSTM performs almost equally well when forecasting over inliers and outliers, irrespective of the distance to outliers. Importantly, CloudLSTM achieves significantly better performance over its counterpart PointLSTM. This further demonstrates that our model is robust to outliers, whose locations appear \"lone\". We further compare our proposal with simple baselines, which also perform forecasting based on knearest neighbors of each target point. To this end, we construct MLPs and LSTMs with the structures specified in Table 3 , but with different input form. Specifically, for each point, the models perform prediction using only the K nearest neighbors' data, with K from {1, 3, 6, 9, 25, 50, 100}. We show their performance along with that of our CloudLSTM on the air quality dataset in Table 6 . Observe that our CloudLSTM significantly outperforms MLPs and LSTMs, which conduct forecasting only relying on k-nearest neighbors. The number of neighbors K affects the receptive field of each model. A small K means the model only relies on limited local spatial dependencies, while global spatial correlations between points are neglected. In contrast, a large K enables looking around larger location spaces, while this might lead to overfitting. The results in the table suggest that the K does not affect the performance of each baseline significantly. Meanwhile our proposed CloudLSTM, which extracts local spatial dependencies through DConv kernels and merges global spatial dependency via stacks of time steps and layers, is superior to these simple baselines. Finally, we notice that seasonal information exists in the mobile traffic series, which can be further exploited to improve the forecasting performance. However, directly feeding the model with data spanning multiple days is infeasible, since, e.g., a 7-day window corresponds to a 2016-long sequence as input (given that data is sampled every 5 minutes) and it is very difficult for RNN-based models to handle such long sequences. In addition, by considering the number of mobile services (38) and antennas (792), the input for 7 days would have 60,673,536 data points. This would make any forecasting model extremely large and therefore impractical for real deployment. To capture seasonal information more efficiently, we concatenate the 30 minute-long sequences (sampled every 5 minutes) with a sub-sampled 7-day window (sampled every 2h). This forms an input with length 90 (6 + 84). We conduct experiments on a randomly selected subset (100 antennas) of the mobile traffic dataset (City 1), and show the forecasting performance without and with seasonal information (7-day window) in Table 7 . By incorporating the seasonal information, the performance of most forecasting models is boosted. This indicates that the periodic information is learnt by the model, which helps reduce the prediction errors. However, the concatenation increases the length of the input, which also increases the model complexity. Future work will focus on a more efficient way to fuse the seasonal information, with marginal increase in complexity."
}