{
    "title": "Sk7cHb-C-",
    "content": "We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.\n The method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed. When observing a particular interaction some behaviors tend to repeat over time following specific dynamics. Understand such behaviors and differentiating the dynamics that define them is a relevant task that allows to characterize the interactions, acquire knowledge from them, and build reactive systems that adapt to evolving situations. Those interactions could be, for example, human activities captured in video, data from a vehicle-mounted camera, or the motion of an agent of interest in a given environment.If we consider a video in which different kinds of action sequences can be observed, the task we aim at for a learning system would be to separate the diverse types of dynamics in the observed sequences and embed them in representational states. For example, imagine a camera mounted on a car. In a video from such device, one would observe predictable changes on the frames for particular actions, for instance, there would be a certain dynamics when the car goes straight, and other where it curves. Similarly, when observing a human performing different kinds of actions in a given scenario, the dynamics followed by the person for each action is to be differentiated. However, such separations should be performed actively during an on-line observation, therefore the system, and particularly its internal representations, should adapt dynamically to the changing data.A viable process to achieve that goal implies representing every observation, e.g., each frame, so that estimating the dynamic evolution of such representations consequently means abstracting the dynamics of the observations. For example, when observing people performing sets of actions, one would describe frames regarding the position and the pose of the person acting. Nonetheless, given an unsupervised framework, such information is not available. So, the way in which the representations are defined is to depend on the observed dynamics. That is so since the relevance of what is to be represented comes from its relation to the evolution of the observations, e.g., the actions being executed.Therefore we define our primary goal as to the acquisition of representational states observations and their dynamics simultaneously in an unsupervised way. Accordingly, the definition of representations is central and determines how learning is to be understood. In particular, representational states are to be defined as dynamic and capable of adjusting themselves to changing environments and uncertainty in sensory data. Taking into account such constraints, we consider an active process where changes in the world and internal states play a primary role interpreting the observed data. That is in opposition to an entirely passive process where an input is transformed into static representations, e.g., a classifier. So, the representational process should be understood in the temporal domain as a mechanism that responds to perceived changes.To implement that, it would be necessary that a system, e.g., a neural network (NN), adapts itself over time to the observed data. With NNs the primary way to achieve similar behaviors is through recurrent networks. When recurrence is involved, the states of previous time steps affect the interpretation of the current inputs, which could include information from different time steps as in the case of NNs based on LSTM units BID9 . Nonetheless, it is also possible to define the adaptability of a NN regarding its predictive accuracy. In general, the prediction error of the network's output is only used for adapting the NN during training by adjusting its parameters through, for example, backpropagation. However, a more dynamic view would include a capability of such kind as part of the inference process. That is, the NN could benefit from a feature that allows it to modify some of its internal states dynamically to model the sensed data based on feedback from its prediction error in a backpropagation-like way. That would allow an active process in which the interpretation of the environment depends also on previous states, or beliefs, therefore making the system capable of actively adapting to changing scenarios.The ideas of actively interpreting and adapting to observed data coincide with dynamic views on conceptual representations in the cognitive science. From such perspectives, representations are seen more as dynamic and distributed structures than as symbols or static categories. In particular, BID12 conclude from neuroimaging studies that concepts might be flexible, experience-dependent and modality-specific, while distributed across the sensory-motor systems. In particular, for them, the flexibility is crucial for the capability of adapting to diverse situations. Olier et al. (2017b) elaborate on how the definition of concepts has evolved and how it impacts the way in which learning is understood, and how that consequently affects the design of artificial learning agents. In particular, they argue that concepts are not to be seen as the encapsulation of knowledge in symbols, but as the structure on which the emergence of behavior occurs. Therefore, how we represent should be seen as dynamic and time dependent, that is, representations make sense only when embedded in the interaction process.Moreover, Olier et al. (2017b) analyze differences between several views on concepts by linking categorization based approaches to the computational views of cognition, while ideas of concepts as flexible, distributed and context-dependent to many aspects of embodied BID26 and grounded cognition BID0 . They describe an approach in which representing implies an act of actively interpreting and adapting to the world. BID0 , from the perspectives of grounded cognition, has elaborated on how simulation is fundamental for concept's acquisition and processing, referring to simulation as the re-enactment of sensorimotor modalities. That can be linked to the ideas on predictive coding BID22 , in which top-down information in the cortex carries predictions about lower levels, while feed-forward connections carry residual errors. Those notions are further developed by BID6 with the free energy principle, where it is argued that the primary function of the brain is to minimize free energy or suppress prediction error.Those ideas have been developed and interpreted in different ways as algorithms. Frequently, implementations aim at systems that update internal beliefs about causes of perceived information from prediction error. Some approaches, particularly given the probabilistic characteristics of the free energy principle, are based on Bayesian methods and generative models, which are argued to account for contextual reactions and causality given temporal relations BID3 . Here we explore some existing techniques and propose a method based on generative models that aims at constructing representations of observed and its dynamics. Particularly we propose a generative model that works simultaneously as an encoder, or its own inverse model, by the use of prediction error to update internal states. We have presented a method for representing dynamic data, and we have tested it on videos of interactions. The states are organized in two levels representing the observations and their dynamics respectively. It has been shown that the method proposed is capable of learning generative models by exploring the latent space through an active adaptation based on prediction error propagation. In the model, the representations make sense in the temporal domain, as to serve their function they have to evolve with the observed data dynamically.Two experiments have been performed to test the model. The first one on static data showing how the adaptation leads to better results than an entirely static model, e.g., a VAE. The process evaluated in that case takes more processing that the static method, yet it shows that the accuracy is not only dependent on the generalization capability of the model, but also on its ability to adapt temporally to the data. In a second experiment, videos of actions performed in a given scenario are used to learn representations of the images and the dynamics of the activities observed. The results show that the model is capable of extracting a semantics similar to the one defined as ground truth for the data used.These ideas have been connected with definitions positions from different branches of the cognitive and brain sciences, which state that interpreting the world is an active process. That suggests that a possible path towards better machine learning algorithms may imply understanding representations and their processing as a temporal process embedded in a dynamic interaction with the environment, or the evolution of the data itself."
}