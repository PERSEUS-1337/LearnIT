{
    "title": "SJd0EAy0b",
    "content": "Many types of relations in physical, biological, social and information systems can be modeled as homogeneous or heterogeneous concept graphs. Hence, learning from and with graph embeddings has drawn a great deal of research interest recently, but only ad hoc solutions have been obtained this far. In this paper, we conjecture that the one-shot supervised learning mechanism is a bottleneck in improving the performance of the graph embedding learning algorithms, and propose to extend this by introducing a multi-shot unsupervised learning framework. Empirical results on several real-world data set show that the proposed model consistently and significantly outperforms existing state-of-the-art approaches on knowledge base completion and graph based multi-label classification tasks. Recent studies have highlighted the importance of learning distributed representations for symbolic data in a wide variety of artificial intelligence tasks BID2 . Research on word embeddings BID14 has led to breakthroughs in many related areas, such as machine translation BID0 , question answering BID28 , and visual-semantic alignments BID10 . However, learning to predict for large-scale knowledge graphs (KGs) is still a challenging problem left, this is largely due to the diversity of the ontologies, and the semantic richness of the concepts, which makes it really hard to generate proper and universally applicable graph embeddings, simply based on word-level embeddings BID4 .Being able to generate reasonable and accurate distributed representations for large-scale knowledge graphs would be particularly valuable, in that it may help predict unobserved facts from limited concepts, uncover gaps in our knowledge, suggest new downstream applications, which clearly reflects the central concerns of the artificial intelligence BID18 BID9 . Therefore , massive attention has been devoted to the potential of embedding entities and relationships of multi-relational data in low-dimensional vector spaces in recent years BID26 .In this paper , we consider the problem of developing simple and efficient model for learning neural representation of generalized knowledge graphs, including the multi-relational heterogeneous graphs, and more specifically defined homogeneous graphs (such as social and biological networks).Following the pioneer work of BID17 and BID3 , almost all of the stateof-the-art approaches try to model the graph embedding learning problem as supervised binary classification problems, their objective functions are usually one-shot (single purpose) . We argue that prior research in this area might have been affected and biased by \" established priors\", which prevents the formulation of a methodology that is objective enough to cope with the highly sparse knowledge graphs. We propose to handle the embedded learning problem of knowledge graphs with an unsupervised neural network model, called the Graph Embedding Network (GEN). The proposed model consists of three simple multi-layer perceptron (MLP) cells, each cell operates in response to a different \"query\" with regard to the input fact, which will be trained sequentially. The formulation of the model is inspired by the neural sequence-to-sequence (seq2seq) model BID23 , except that we attempt to use the MLP cells to mimic the sequence learning capability of the recurrent neural network (RNN), to model the semantic structure of the knowledge graphs.The major contribution of this paper is that: (1) we propose GEN, a novel and efficient multishot framework for embedding learning in generalized knowledge graphs. (2) We show how GEN is in accordance with established principles in cognitive science, providing flexibility in learning representations that works on graphs conforming to different domains. Representation learning of knowledge graphs is a key concern for artificial intelligence and cognitive science. Many types of relations in physical, biological, social and information systems can be modeled with concept (knowledge) graphs. In this paper, we present an efficient scalable framework for learning conceptual embeddings of entities and relations in generalized knowledge graphs, including the homogeneous and heterogeneous graphs. We give evidence that the proposed model learns good representations of all these graphs for knowledge inference and supervised learning. For future work, we plan to investigate more thoroughly the efficacy of the proposed modeling framework, with respect to the decomposition of the semantic information conveyed by the linked concepts into elementary information, i.e. the four Q&A pairs. Also, we seek to enhance the quality of scientific investigations and theoretical conceptualizations on graph embedding learning in the context of semantic interoperability, for there is usually no possibility to interpret the embedded information meaningfully and accurately in order to produce useful results as defined by existing algorithms."
}