{
    "title": "HJeB0sC9Fm",
    "content": "We propose a new notion of 'non-linearity' of a network layer with respect to an input batch that is based on its proximity to a linear system, which is reflected in the non-negative rank of the activation matrix.\n We measure this non-linearity by applying non-negative factorization to the activation matrix.\n Considering batches of similar samples, we find that high non-linearity in deep layers is indicative of memorization. Furthermore, by applying our approach layer-by-layer, we find that the mechanism for memorization consists of distinct phases. We perform experiments on fully-connected and convolutional neural networks trained on several image and audio datasets. Our results demonstrate that as an indicator for memorization, our technique can be used to perform early stopping. A fundamental challenge in machine learning is balancing the bias-variance tradeoff, where overly simple learning models underfit the data (suboptimal performance on the training data) and overly complex models are expected to overfit or memorize the data (perfect training set performance, but suboptimal test set performance). The latter direction of this tradeoff has come into question with the observation that deep neural networks do not memorize their training data despite having sufficient capacity to do so BID38 , the explanation of which is a matter of much interest.Due to their convenient gradient properties and excellent performance in practice, rectified-linear units (ReLU) have been widely adopted and are now ubiquitous in the field of deep learning. In addition, the relative simplicity of this function (max(\u00b7, 0)) makes the analysis of ReLU networks more straight-forward than networks with other activation functions.We propose a new notion of 'non-linearity' of a ReLU layer with respect to an input batch. We show that networks that generalize well have deep layers that are approximately linear with respect to batches of similar inputs. In contrast, networks that memorize their training data are highly nonlinear with respect to similar inputs, even in deep layers.Our method is based on the fact that the main source of non-linearity in ReLU networks is the threshold at zero. This thresholding determines the support of the resulting activation matrix, which plays an important role in the analysis of non-negative matrices. As we discuss in Section 3, the non-negative rank of a matrix is constrained by the shape of the support, and is therefore indicative of the degree of non-linearity in a ReLU activation matrix with respect to the input.Although computing the non-negative rank is NP-hard (Vavasis, 2009), we can restrict it with approximate non-negative matrix factorization (NMF) BID20 . Consequently, we propose to estimate the 'non-linearity' of a ReLU layer with respect to an input batch by performing NMF on a grid over the approximation rank k, and measuring the impact on network performance. This procedure can be seen as measuring the robustness of a neural network to increasing compression of its activations. We therefore compare our NMF-based approach to two additional dimensionality reduction techniques, namely principal component analysis (PCA) and random ablations.We informally define memorization as the implicit learning of a rule that associates a specific sample (i.e., with index i) to a particular label (e.g., with index j). Such a rule does not benefit the network in terms of improving its performance on new data.We show that our NMF-based approach is extremely sensitive to memorization in neural networks. We report results for a variety of neural network architectures trained on several image and audio datasets. We conduct a layer-by-layer analysis and our results reveal interesting details on the internal mechanism of memorization in neural networks. Finally, as an indicator for memorization, we use our proposed measure to perform early stopping. We have introduced a notion of a ReLU layer's non-linearity with respect to an input batch, which is based on its proximity to a linear system. We measure this property indirectly via NMF applied to deep activations of single-class batches. While more analysis is required before definite guarantees could be given, we find that our approach is successful in detecting memorization and generalization across a variety of neural network architectures and datasets. The exact architectures we used for each dataset are given in Table 1 . We denote a linear or convolutional layer followed by a ReLU as Linear + and Conv + , respectively."
}