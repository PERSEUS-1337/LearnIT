{
    "title": "HJxeGb5pTm",
    "content": "Open information extraction (OIE) systems extract relations and their\n  arguments from natural language text in an unsupervised manner. The resulting\n  extractions are a valuable resource for downstream tasks such as knowledge\n  base construction, open question answering, or event schema induction. In this\n  paper, we release, describe, and analyze an OIE corpus called OPIEC, which was\n  extracted from the text of English Wikipedia. OPIEC complements the available\n  OIE resources: It is the largest OIE corpus publicly available to date (over\n  340M triples) and contains valuable metadata such as provenance information,\n  confidence scores, linguistic annotations, and semantic annotations including\n  spatial and temporal information. We analyze the OPIEC corpus by comparing its\n  content with knowledge bases such as DBpedia or YAGO, which are also based on\n  Wikipedia. We found that most of the facts between entities present in OPIEC\n  cannot be found in DBpedia and/or YAGO, that OIE facts \n  often differ in the level of specificity compared to knowledge base facts, and\n  that OIE open relations are generally highly polysemous. We believe that the\n  OPIEC corpus is a valuable resource for future research on automated knowledge\n  base construction. Open information extraction (OIE) is the task of extracting relations and their arguments from natural language text in an unsupervised manner BID3 . The output of such systems is usually structured in the form of (subject, relation, object)-triples. For example, from the sentence \"Bell is a telecommunication company, which is based in L. A.,\" an OIE system may yield the extractions (\"Bell\"; \"is\"; \"telecommunication company\") and (\"Bell\"; \"is based in\"; \"L. A.\"). The extractions of OIE systems from large corpora are a valuable resource for downstream tasks BID11 BID21 such as automated knowledge base construction BID28 BID34 BID33 BID30 , open question answering BID13 , event schema induction BID2 , generating inference rules BID18 , or for improving OIE systems themselves BID35 . A number of derived resources have been produced from OIE extractions, including as entailment rules BID18 , question paraphrases BID13 , Relgrams BID1 , and OIE-based embeddings BID32 .In this paper, we release a new OIE corpus called OPIEC. 1 The OPIEC corpus has been extracted from the full text of the English Wikipedia using the Stanford CoreNLP pipeline and the state-of-the-art OIE system MinIE BID15 . OPIEC complements available OIE resources BID12 BID19 BID26 BID24 BID9 : It is the largest OIE corpus publicly available to date (with over 340M triples) and contains valuable metadata information for each of its extractions not available in existing resources (see Tab. 1 for an overview). In particular , OPIEC provides for each triple detailed provenance information, syntactic annotations (such as POS tags, lemmas, dependency parses), semantic annotations (such as polarity, modality, attribution, space, time), entity annotations (NER types and, when available, Wikipedia links), as well as confidence scores.We performed a detailed data profiling study of the OPIEC corpus to analyze its contents and potential usefulness for downstream applications. We observed that a substantial fraction of the OIE extractions was not self-contained (e.g., because no anaphora resolution was performed) or overly specific (e.g., because arguments were complex phrases). Since these extractions are more difficult to work with, we created the OPIEC-Clean subcorpus (104M triples), in which we only retained triples that express relations between concepts. In particular , OPIEC-Clean contains triples in which arguments are either named entities (as recognized by an NER system), match a Wikipedia page title (e.g., concepts such as political party or movie), or link directly to a Wikipedia page. Although OPIEC-Clean is substantially smaller than the full OPIEC corpus, it is nevertheless four times larger than the largest prior OIE corpus.To gain insight into the information present in the OPIEC corpus, we compared its content with the DBpedia BID4 and YAGO BID17 knowledge bases, which are also constructed from Wikipedia (e.g., from infoboxes). Since such an analysis is difficult to perform due to the openness and ambiguity of OIE extractions, we followed standard practice and used a simple form of distant supervision. In particular, we analyze the OPIEC-Linked subcorpus (5.8M triples), which contains only those triples in which both arguments are linked to Wikipedia articles, i.e., where we have golden labels for disambiguation. We found that most of the facts between entities present in OPIECLinked cannot be found in DBpedia and/or YAGO, that OIE facts often differ in the level of specificity compared to knowledge base facts, and that frequent OIE open relations are generally highly polysemous.Along with the OPIEC corpus as well as the OPIEC-Clean and OPIEC-Linked subcorpora, we release the codebase used to construct the corpus as well as a number of derived resources, most notably a corpus of open relations between arguments of various entity types along with their frequencies. We believe that the OPIEC corpus is a valuable resource for future research on automated knowledge base construction. We created OPIEC, a large open information extraction corpus extracted from Wikipedia. OPIEC consists of hundreds of millions of triples, along with rich metadata such as provenance information, syntactic annotations, semantic annotations, and confidence scores. We reported on a data profiling study of the OPIEC corpus as well as subcorpora. In particular, we analyzed to what extent OPIEC overlaps with the DBpedia and YAGO knowledge bases. Our study indicates that most open facts do not have counterparts in the KB such that OIE corpora contain complementary information. For the information that overlaps, open relation are often more specific, more generic, or simply correlated to KB relations (instead of semantically equivalent). We hope that the OPIEC corpus, its subcorpora, derived statistics, as well as the codebase used to create the corpus are a valuable resource for automated KB construction and downstream applications (for example, an independent study showed the utility of OPIEC in entity-aspect linking BID27 )."
}