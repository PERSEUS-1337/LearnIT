{
    "title": "SkfhIo0qtQ",
    "content": "Convolution is an efficient technique to obtain abstract feature representations using hierarchical layers in deep networks. Although performing convolution in Euclidean geometries is fairly straightforward, its extension to other topological spaces---such as a sphere S^2 or a unit ball B^3---entails unique challenges. In this work, we propose a novel `\"volumetric convolution\" operation that can effectively convolve arbitrary functions in B^3. We develop a theoretical framework for \"volumetric convolution\" based on Zernike polynomials and efficiently implement it as a differentiable and an easily pluggable layer for deep networks. Furthermore, our formulation leads to derivation of a  novel formula to measure the symmetry of a function in B^3 around an arbitrary axis, that is useful in 3D shape analysis tasks. We demonstrate the efficacy of proposed volumetric convolution operation on a possible use-case i.e., 3D object recognition task. Convolution-based deep neural networks have performed exceedingly well on 2D representation learning tasks BID11 BID7 . The convolution layers perform parameter sharing to learn repetitive features across the spatial domain while having lower computational cost by using local neuron connectivity. However, most state-of-the-art convolutional networks can only work on Euclidean geometries and their extension to other topological spaces e.g., spheres, is an open research problem. Remarkably, the adaptation of convolutional networks to spherical domain can advance key application areas such as robotics, geoscience and medical imaging. Some recent efforts have been reported in the literature that aim to extend convolutional networks to spherical signals. Initial progress was made by BID1 , who performed conventional planar convolution with a careful padding on a spherical-polar representation and its cube-sphere transformation BID17 . A recent pioneering contribution by used harmonic analysis to perform efficient convolution on the surface of the sphere (S 2 ) to achieve rotational equivariance. These works, however, do not systematically consider radial information in a 3D shape and the feature representations are learned at specified radii. Specifically, estimated similarity between spherical surface and convolutional filter in S 2 , where the kernel can be translated in S 2 . Furthermore, BID23 recently solved the more general problem of SE(3) equivariance by modeling 3D data as dense vector fields in 3D Euclidean space. In this work however, we focus on B 3 to achieve the equivariance to SO(3).In this paper, we propose a novel approach to perform volumetric convolutions inside unit ball (B 3 ) that explicitly learns representations across the radial axis. Although we derive generic formulas to convolve functions in B 3 , we experiment on one possible use case in this work, i.e., 3D shape recognition. In comparison to closely related spherical convolution approaches, modeling and convolving 3D shapes in B 3 entails two key advantages: 'volumetric convolution' can capture both 2D texture and 3D shape features and can handle non-polar 3D shapes. We develop the theory of volumetric convolution using orthogonal Zernike polynomials BID3 , and use careful approximations to efficiently implement it using low computational-cost matrix multiplications. Our experimental results demonstrate significant boost over spherical convolution and that confirm the high discriminative ability of features learned through volumetric convolution.Furthermore, we derive an explicit formula based on Zernike Polynomials to measure the axial symmetry of a function in B 3 , around an arbitrary axis. While this formula can be useful in many function analysis tasks, here we demonstrate one particular use-case with relevance to 3D shape recognition. Specifically, we use the the derived formula to propose a hand-crafted descriptor that accurately encodes the axial symmetry of a 3D shape. Moreover, we decompose the implementation of both volumetric convolution and axial symmetry measurement into differentiable steps, which enables them to be integrated to any end-to-end architecture.Finally, we propose an experimental architecture to demonstrate the practical usefulness of proposed operations. We use a capsule network after the convolution layer as it allows us to directly compare feature discriminability of spherical convolution and volumetric convolution without any bias. In other words, the optimum deep architecture for spherical convolution may not be the same for volumetric convolution. Capsules, however, do not deteriorate extracted features and the final accuracy only depends on the richness of input shape features. Therefore, a fair comparison between spherical and volumetric convolutions can be done by simply replacing the convolution layer.It is worth pointing out that the proposed experimental architecture is only a one possible example out of many possible architectures, and is primarily focused on three factors: 1) Capture useful features with a relatively shallow network compared to state-of-the-art. 2) Show richness of computed features through clear improvements over spherical convolution. 3) Demonstrate the usefulness of the volumetric convolution and axial symmetry feature layers as fully differentiable and easily pluggable layers, which can be used as building blocks for end-to-end deep architectures.The main contributions of this work include:\u2022 Development of the theory for volumetric convolution that can efficiently model functions in B 3 .\u2022 Implementation of the proposed volumetric convolution as a fully differentiable module that can be plugged into any end-to-end deep learning framework.\u2022 The first approach to perform volumetric convolution on 3D objects that can simultaneously model 2D (appearance) and 3D (shape) features.\u2022 A novel formula to measure the axial symmetry of a function defined in B 3 , around an arbitrary axis using Zernike polynomials.\u2022 An experimental end-to-end trainable framework that combines hand-crafted feature representation with automatically learned representations to obtain rich 3D shape descriptors.The rest of the paper is structured as follows. In Sec. 2 we introduce the overall problem and our proposed solution . Sec. 3 presents an overview of 3D Zernike polynomials. Then, in Sec. 4 and Sec. 5 we derive the proposed volumetric convolution and axial symmetry measurement formula respectively. Sec. 6.2 presents our experimental architecture, and in Sec. 7 we show the effectiveness of the derived operators through extensive experiments. Finally, we conclude the paper in Sec. 8. In this work, we derive a novel 'volumetric convolution' using 3D Zernike polynomials, which can learn feature representations in B 3 . We develop the underlying theoretical foundations for volumetric convolution and demonstrate how it can be efficiently computed and implemented using low-cost matrix multiplications. Furthermore, we propose a novel, fully differentiable method to measure the axial symmetry of a function in B 3 around an arbitrary axis, using 3D Zernike polynomials. Finally, using these operations as building tools, we propose an experimental architecture, that gives competitive results to state-of-the-art with a relatively shallow network, in 3D object recognition task. An immediate extension to this work would be to explore weight sharing along the radius of the sphere.Let f (\u03b8, \u03c6, r) and g(\u03b8, \u03c6, r) be the object function and kernel function (symmetric around north pole) respectively. Then volumetric convolution is defined as, f * g(\u03b8, \u03c6) =< f, \u03c4 (\u03b8,\u03c6) g >Applying the rotation \u03b7 (\u03b1,\u03b2,\u03b3) to f , we get, \u03b7 (\u03b1,\u03b2,\u03b3) (f ) * g(\u03b8, \u03c6) =< \u03b7 (\u03b1,\u03b2,\u03b3) (f ), \u03c4 (\u03b8,\u03c6) g >By the result 33, we have, DISPLAYFORM0 However, since \u03b7 \u03b1,\u03b2,\u03b3 (g) = \u03c4 \u03b1,\u03b2 (g) we get, \u03b7 (\u03b1,\u03b2,\u03b3) (f ) * g(\u03b8, \u03c6) =< f, \u03c4 (\u03b8\u2212\u03b1,\u03c6\u2212\u03b2,) g >We know that, f * g(\u03b8, \u03c6) =< f, \u03c4 (\u03b8,\u03c6) g >= \u03b7 (\u03b1,\u03b2,\u03b3) (f ) * g(\u03b8, \u03c6) = (f * g)(\u03b8 \u2212 \u03b1, \u03c6 \u2212 \u03b2)\u03b7 (\u03b1,\u03b2,\u03b3) (f ) * g(\u03b8, \u03c6) = \u03c4 (\u03b1,\u03b2) (f * g) (Hence, we achieve equivariance over 3D rotations."
}