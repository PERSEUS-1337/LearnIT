{
    "title": "S1x63TEYvr",
    "content": "Multi-hop text-based question-answering is a current challenge in machine comprehension. \n This task requires to sequentially integrate facts from multiple passages to answer complex natural language questions.\n In this paper, we propose a novel architecture, called the Latent Question Reformulation Network (LQR-net), a multi-hop and parallel attentive network designed for question-answering tasks that require reasoning capabilities.\n LQR-net is composed of an association of \\textbf{reading modules} and \\textbf{reformulation modules}.\n The purpose of the reading module is to produce a question-aware representation of the document.\n From this document representation, the reformulation module extracts essential elements to calculate an updated representation of the question.\n This updated question is then passed to the following hop.\n We evaluate our architecture on the \\hotpotqa question-answering dataset designed to assess multi-hop reasoning capabilities.\n Our model achieves competitive results on the public leaderboard and outperforms the best current \\textit{published} models in terms of Exact Match (EM) and $F_1$ score.\n Finally, we show that an analysis of the sequential reformulations can provide interpretable reasoning paths. The ability to automatically extract relevant information from large text corpora remains a major challenge. Recently, the task of question-answering has been largely used as a proxy to evaluate the reading capabilities of neural architectures. Most of the current datasets for question-answering focus on the ability to read and extract information from a single piece of text, often composed of few sentences (Rajpurkar et al., 2016; Nguyen et al., 2016) . This has strengthened the emergence of easy questions in the sense of Sugawara et al. (2018) and influenced the recent state-of-the-art models to be good at detecting patterns and named entities (Devlin et al., 2018; Yu et al., 2018; Wang et al., 2017) . However they still lack actual reasoning capabilities. The problem of reasoning requires machine comprehension models to gather and compose over different pieces of evidence spread across multiple paragraphs. In this work, we propose an original neural architecture that repeatedly reads from a set of paragraphs to aggregate and reformulate information. In addition to the sequential reading, our model is designed to collect pieces of information in parallel and to aggregate them in its last layer. Throughout the model, the important pieces of the document are highlighted by what we call a reading module and integrated into a representation of the question via our reformulation module. Our contributions can be summarised as follows: \u2022 We propose a machine reading architecture, composed of multiple token-level attention modules, that collect information sequentially and in parallel across a document to answer a question, \u2022 We propose to use an input-length invariant question representation updated via a dynamic max-pooling layer that compacts information form a variable-length text sequence into a fixed size matrix, \u2022 We introduce an extractive reading-based attention mechanism that computes the attention vector from the output layer of a generic extractive machine reading model, \u2022 We illustrate the advantages of our model on the HOTPOTQA dataset. The remainder of the paper is organized as follows: Section 2 presents the multi-hop machine reading task, and analyses the required reasoning competencies. In Section 3, we detail our novel reading architecture and present its different building blocks. Section 4 presents the conducted experiments, several ablation studies, and qualitative analysis of the results. Finally, Section 5 discusses related work. Our code to reproduce the results is publicly available at (removed for review). 2 TEXT-BASED QUESTION-ANSWERING AND MACHINE REASONING Figure 1 : Examples of reasoning paths to answer two questions of the HOTPOTQA dataset. In this picture, we do not display the full paragraphs, but only the supporting facts. The task of extractive machine reading can be summarized as follows: given a document D and a question Q, the goal is to extract the span of the document that answers the question. In this work, we consider the explainable multi-hop reasoning task described in Yang et al. (2018) and its associated dataset: HOTPOTQA . We focus our experiments on the \"distractor\" configuration of the dataset. In this task, the input document D is not a single paragraph but a set of ten paragraphs coming from different English Wikipedia articles. Answering each question requires gathering and integrating information from exactly two paragraphs; the eight others are distractors selected among the results of a tf-idf retriever (Chen et al., 2017) . These required paragraphs are called the gold paragraphs. There are two types of questions proposed in this dataset: extractive ones where the answer is a span of text extracted from the document and binary yes/no questions. In addition to the answer, it is required to predict the sentences, also called supporting facts, that are necessary to produce the correct answer. This task can be decomposed in three subtasks: (1) categorize the answer among the three following classes: yes, no, text span, (2) if it is a span, predict the start and end positions of this span in the document, and (3) predict the supporting sentences required to answer the question. In addition to the \"distractor\" experiments, we show how our proposed approach can be used for opendomain question answering and evaluate the entire reading pipeline on the \"fullwiki\" configuration of the HotpotQA dataset. In this configuration, no supporting documents are provided, and it is required to answer the question from the entire Wikipedia corpus. Among the competencies that multi-hop machine reading requires, we identify two major reasoning capabilities that human readers naturally exploit to answer these questions: sequential reasoning and parallel reasoning. Sequential reasoning requires reading a document, seeking a piece of information, then reformulating the question and finally extracting the correct answer. This is called multi-hop question-answering and refers to the bridge questions in HOTPOTQA . Another reasoning pattern is parallel reasoning, required to collect pieces of evidence for comparisons or question that required checking multiple properties in the documents. Figure 1 presents two examples from HOTPOTQA that illustrate such required competencies. We hypothesize that these two major reasoning patterns should condition the design of the proposed neural architectures to avoid restricting the model to one or the other reasoning skill. In this paper, we propose a novel multi-hop reading model designed for question-answering tasks that explicitly require reasoning capabilities. We have designed our model to gather information sequentially and in parallel from a given set of paragraphs to answer a natural language question. Our neural architecture, uses a sequence of token-level attention mechanisms to extract relevant information from the paragraphs and update a latent representation of the question. Our proposed model achieves competitive results on the HOTPOTQA reasoning task and performs better than the current best published approach in terms of both Exact Match and F 1 score. In addition, we show that an analysis of the sequential attentions can possibly provide human-interpretable reasoning chains."
}