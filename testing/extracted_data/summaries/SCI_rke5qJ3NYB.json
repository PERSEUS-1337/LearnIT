{
    "title": "rke5qJ3NYB",
    "content": "Models of user behavior are critical inputs in many prescriptive settings and can be viewed as decision rules that transform state information available to the user into actions. Gaussian processes (GPs), as well as nonlinear extensions thereof, provide a flexible framework to learn user models in conjunction with approximate Bayesian inference. However, the resulting models may not be interpretable in general. We propose decision-rule GPs (DRGPs) that apply GPs in a transformed space defined by decision rules that have immediate interpretability to practitioners. We illustrate this modeling tool on a real application and show that structural variational inference techniques can be used with DRGPs. We find that DRGPs outperform the direct use of GPs in terms of out-of-sample performance. Models of user behavior are critical in many decision making problems and can be viewed as decision rules that transform state information (in set S) available to the user to actions (in set A). Formally, a user model is a function f : S \u2192 A. Gaussian processes (GPs) employed to learn functions on the action/target space (henceforth target GPs or TGPs for short) can thus be used to place a prior on user models and identify a posterior distribution over them supported by data in conjunction with approximate Bayesian inference techniques (Blei et al., 2017; Beaumont, 2019) . TGPs for user modeling would assume that user actions at a given set of finite states follow a multivariate Gaussian. To capture non-Gaussian action distributions, one could apply GPs to learn functions in a transformed space that is not the target. Examples include warped and chained GPs proposed in Snelson et al. (2004) and Saul et al. (2016) , respectively. Extending this literature, we study the application of GPs in a transformed space defined by decision rules. Such rules are known in several applications and depend on functions themselves. Specifically, a user model based on a decision rule takes the form g : \u03a0 k P k \u00d7 S \u2192 A, where the arguments are obtained using functions h k : S \u2192 P k , k = {1, . . . , K} that map from S to transformed spaces P k , possibly different from the target space A. Each such function has immediate interpretability to a practitioner, and we model them using GPs. We refer to such a user model {g, h 1 , ..., h k } as a decision-rule GP (DRGP). To make the notion of DRGPs concrete in this short article, we focus on the problem faced by a firm providing services to store ethanol -a real application that motivated this work. Suppose capacity (in gallons) is sold via annual contracts to N users. The contract of user n specifies the maximum amount of ethanol that can be stored, denoted by C n . User behavior corresponds to the injection of ethanol and the withdrawal of previously injected ethanol, which can be modeled as a time series. The inventory I n,t in storage associated with user n at time t is the net of past injections and withdrawals. A TGP approach would employ a GP to determine the next-period storage inventory level function I n,t+1 directly. In contrast, we propose a DRGP that leverages a well-known decision rule based on injection and withdrawal threshold functions (Charnes et al., 1966; Secomandi, 2010) . These threshold functions are learned as GPs instead of the (relatively less interpretable) inventory function. We focus on the following research questions in the context of the ethanol storage application: (Q1) Can existing exact and approximate Bayesian inference techniques be used for inference with DRGP? and (Q2) How does DRGP perform relative to TGP? We answer these questions by executing numerical experiments based on real data of aggregated ethanol storage injection and withdrawals. For Q1, we show that sparse vari-ational inference (Titsias, 2009; Hensman et al., 2013) , which can be applied to TGP on our data set, can also be used with DRGP, albeit heuristically, which is encouraging from an implementation standpoint. For Q2, we find that DRGP implemented in this manner leads to lesser out-of-sample error than TGP on most of our datasets, in addition to being more interpretable to practitioners. This preliminary finding is promising and suggests that applying GPs in the interpretable space of the decision rule threshold functions has potential value, which adds to the growing literature on interpretable machine learning and optimization (Letham et al., 2015; Bertsimas and Dunn, 2017) . In addition, the improvements we report are based on the heuristic use of sparse variational inference with DRGPs, which bodes well for additional potential improvements from the development of new inference techniques targeting DRGPs. Finally, several applications in energy, health care, and transportation, among other domains, have known interpratable decision rules, which can be leveraged in the DRGP framework proposed here. Snelson et al. (2004) show that modeling data using a warped GP, which is a non-linear transformation (aka warping) of a GP, can enhance predictive performance. Inference using a warped GP can be performed in closed-form provided the warping function satisfies certain properties, such as being invertible. L\u00e1zaro-Gredilla (2012) consider the case where the warping function is not fixed a priori. DRGPs differ from warped GPs as they are based on a potentially non-invertible transformation of multiple GPs."
}