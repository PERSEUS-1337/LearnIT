{
    "title": "HygPD4H22N",
    "content": "Claims from the fields of network neuroscience and connectomics suggest that topological models of the brain involving complex networks are of particular use and interest. The field of deep neural networks has mostly left inspiration from these claims out. In this paper, we propose three architectures and use each of them to explore the intersection of network neuroscience and deep learning in an attempt to bridge the gap between the two fields. Using the teachings from network neuroscience and connectomics, we show improvements over the ResNet architecture, we show a possible connection between early training and the spectral properties of the network, and we show the trainability of a DNN based on the neuronal network of C.Elegans. We have demonstrated three distinct approaches to applying work from network neurosciences and connectomics to deep learning. Our experiments show improvements over ResNet by the inclusion of skip connections which follow a connectivity pattern with small world properties, a possible connection between early training performance and spectral gap when using expander graphs as the participant graph topology with the node model proposed by BID14 , and the trainability of a DNN based on the neuronal network of C.Elegans with and without freezing the parameters of the convolutional and fully connected layers.In future work, we will examine the impact of other spectral properties of the graph topologies used both in the architectures we proposed and in the RandWire architecture proposed by BID14 . Additionally, we will explore parameter efficient connectivity patterns which could achieve similar performance to related networks with more parameters TAB0 Deep connectomics networks Figure 5 . Performance of C.ElegansNet with all parameters frozen except the C.Elegans graph edge weights."
}