{
    "title": "rke4HiAcY7",
    "content": "Information bottleneck (IB) is a method for extracting information from one random variable X that is relevant for predicting another random variable Y. To do so, IB identifies an intermediate \"bottleneck\" variable T that has low mutual information I(X;T) and high mutual information I(Y;T). The \"IB curve\" characterizes the set of bottleneck variables that achieve maximal I(Y;T) for a given I(X;T), and is typically explored by maximizing the \"IB Lagrangian\", I(Y;T) - \u03b2I(X;T). In some cases, Y is a deterministic function of X, including many classification problems in supervised learning where the output class Y is a deterministic function of the input X. We demonstrate three caveats when using IB in any situation where Y is a deterministic function of X: (1) the IB curve cannot be recovered by maximizing the IB Lagrangian for different values of \u03b2; (2) there are \"uninteresting\" trivial solutions at all points of the IB curve; and (3) for multi-layer classifiers that achieve low prediction error, different layers cannot exhibit a strict trade-off between compression and prediction, contrary to a recent proposal. We also show that when Y is a small perturbation away from being a deterministic function of X, these three caveats arise in an approximate way. To address problem (1), we propose a functional that, unlike the IB Lagrangian, can recover the IB curve in all cases. We demonstrate the three caveats on the MNIST dataset. The information bottleneck (IB) method BID29 provides a principled way to extract information that is present in one variable that is relevant for predicting another variable. Given two random variables X and Y , IB posits a \"bottleneck\" variable T that obeys the Markov condition Y \u2212 X \u2212 T . By the data processing inequality (DPI) BID9 , this Markov condition implies that I(X; T ) \u2265 I(Y ; T ), meaning that the bottleneck variable cannot contain more information about Y than it does about X. In fact, any particular choice of the bottleneck variable T can be quantified by two terms: the mutual information I(X; T ), which reflects how much T compresses X, and the mutual information I(Y ; T ), which reflects how well T predicts Y . In IB, bottleneck variables are chosen to maximize prediction given a constraint on compression BID32 BID1 BID13 , where \u2206 is the set of random variables T obeying the Markov condition Y \u2212 X \u2212 T . The values of F (r) for different r specify the IB curve. In order to explore the IB curve, one must find optimal T for different values of r. It is known that the IB curve is concave in r but may not be strictly concave. This seemingly minor issue of non-strict concavity will play a central role in our analysis.In practice, the IB curve is almost always explored not via the constrained optimization problem of Eq.(1), but rather by maximizing the so-called IB Lagrangian, Several recent papers have drawn connections between IB and supervised learning, in particular classification using neural networks. In this context, X represents input vectors, Y represents the output classes, and T represents intermediate representations used by the network architecture, such as the activity of hidden layer(s ) BID30 . Some of these papers modify neural network training algorithms so as to optimize the IB Lagrangian BID2 BID7 , thereby permitting the use of IB with high-dimensional, continuousvalued random variables. Some papers have also suggested that by controlling the amount of compression, one can tune desired characteristics of trained models such as generalization error BID23 BID30 BID31 , robustness to adversarial inputs BID2 , and detection of out-of-distribution data BID3 . Other research (ShwartzZiv & Tishby, 2017) has suggested -somewhat controversially BID22 -that stochastic gradient descent (SGD) training dynamics may implicitly favor hidden layer mappings that balances compression and prediction, with earlier hidden layers favoring prediction over compression and latter hidden layers favoring compression over prediction. Finally , there is the general notion that intermediate representations that are optimal in the IB sense correspond to \"interesting\" or \"useful\" compressions of input vectors BID4 .There are also numerous application domains of IB beyond supervised learning, including clustering BID25 , coding theory and quantization BID6 BID34 BID8 , and cognitive science BID33 . In most of these applications, it is of central interest to explore solutions at different points on the IB curve, for example to control the number of detected clusters, or to adapt codes to available channel capacity.In some scenarios, Y may be a deterministic function of X, i.e., Y = f (X) for some single-valued function f . For example , in many classification problems, it is assumed that any given input belongs to a single class, which implies a deterministic relationship between X and Y . In this paper , we demonstrate three caveats for IB that appear whenever Y is a deterministic function of X: 1. There is no one-to-one mapping between different points on the IB curve and maximizers of the IB Lagrangian L \u03b2 IB for different \u03b2, thus the IB curve cannot be explored by maximizing L \u03b2 IB while varying \u03b2. This occurs because when Y = f (X), the IB curve has a piecewise linear shape and is therefore not strictly concave. The dependence of the IB Lagrangian on the strict concavity of F (r) has been previously noted BID13 BID24 , but the implications and pervasiveness of this problem (e.g., in many classification scenarios) has not been fully recognized. We analyze this issue and propose a solution in the form of an alternative objective function, which can be used to explore the IB curve even when Y = f (X). 2. All points on the IB curve contain uninteresting trivial solutions (in particular, stochastic mixtures of two very simple solutions). This suggests that IB-optimality is not sufficient for an intermediate representation to be an interesting or useful compression of input data. 3. For a neural network with several hidden layers that achieves a low probability of error, the hidden layers cannot display a strict trade-off between compression and prediction (in particular, different layers can only differ in the amount of compression, not prediction). In Appendix B, we show that the above three caveats also apply to the recently proposed deterministic IB variant of IB BID26 , in which the compression term is quantified using the entropy H(T ) rather than the mutual information I(X; T ). In that Appendix, we propose an alternative objective function that can be used to resolve the first problem for dIB.We also show, in Appendix C, that our results apply when Y is not exactly a deterministic function of X, but -close to one. In this case: (1) it is hard to explore the IB curve by optimizing the IB Lagrangian, because all optimizers will fall within O(\u2212 log ) of a single \"corner\" point on the information plane; (2) along all points on the IB curve, there are \"uninteresting\" trivial solutions that are no more than O(\u2212 log ) away from being optimal; (3) different layers of a neural networks can trade-off at most O(\u2212 log ) amount of prediction.A recent paper BID4 ) also discusses several difficulties in using IB to analyze intermediate representations in supervised learning. That paper does not consider the particular 1 Note that optimizing L \u03b2 IB is still a constrained problem in that p(t|x) must be a valid conditional probability. However, this constraint is usually easier to handle, e.g., by using an appropriate parameterization.issues that arise when Y is a deterministic function of X, and its arguments are complementary to ours. BID24 [Sec. 2.4 ] discuss another caveat for IB in deterministic settings, concerning the relationship between sufficient statistics and the complexity of the inputoutput mapping, which is orthogonal to the three caveats analyzed here. Finally, BID22 and BID4 observed that when T is continuous-valued and a deterministic function of a continuous-valued X, I(X; T ) can be unbounded, making the application of the IB framework problematic. We emphasize that the caveats discussed in this paper are unrelated to that problem.Note that our results are based on analytically-provable properties of the IB curve, i.e., global optima of Eq. (1), and do not concern practical issues of optimization (which may be important in realworld scenarios). Our theoretical results are also independent of the practical issue of estimating MI between neural network layers, an active area of recent research BID5 BID14 BID10 BID12 , though our empirical experiments in Section 7 rely on the estimator proposed in . Finally, our results are also independent of issues related to the relationship between IB, finite data sampling, and generalization error BID23 BID30 BID31 .In the next section, we review some of the connections between supervised learning and IB. In Section 3, we show that when Y = f (X), the IB curve has a piecewise linear (not strictly concave) shape. In Sections 4, 5 and 6, we discuss the three caveats mentioned above. In Section 7, we demonstrate the caveats using a neural-network implementation of IB on the MNIST dataset. The information bottleneck principle has attracted a great deal of attention in various fields, including information theory, cognitive science, and machine learning, particularly in the context of classification using neural networks. In this work, we showed that in any scenario where Y is a deterministic function of X -which includes many classification problems -IB demonstrates behavior that is qualitatively different from when the mapping from X to Y is stochastic. In particular, in such cases: (1) the IB curve cannot be recovered by maximizing the IB Lagrangian I(Y ; T ) \u2212 \u03b2I(X; T ) while varying \u03b2; (2) all points on the IB curve contain \"uninteresting\" representations of inputs; (3) multi-layer classifiers that achieve zero probability of error cannot have a strict trade-off between prediction and compression among successive layers, contrary to a recent proposal.Our results should not be taken to mean that the application of IB to supervised learning is without merit. First, they do not apply to various non-deterministic classification problems where the output is stochastic. Second, even for deterministic scenarios, one may still wish to control the amount of compression during training, e.g., to improve generalization or robustness to adversarial inputs. In this case, however, our work shows that to achieve varying rates of compression, one should use a different objective function than the IB Lagrangian."
}