{
    "title": "HJIoJWZCZ",
    "content": "We present a domain adaptation method for transferring neural representations from label-rich source domains to unlabeled target domains. Recent adversarial methods proposed for this task learn to align features across domains by ``fooling'' a special domain classifier network. However, a drawback of this approach is that the domain classifier simply labels the generated features as in-domain or not, without considering the boundaries between classes. This means that ambiguous target features can be generated near class boundaries, reducing target classification accuracy. We propose a novel approach, Adversarial Dropout Regularization (ADR), which encourages the generator to output more discriminative features for the target domain. Our key idea is to replace the traditional domain critic with a critic that detects non-discriminative features by using dropout on the classifier network. The generator then learns to avoid these areas of the feature space and thus creates better features. We apply our ADR approach to the problem of unsupervised domain adaptation for image classification and semantic segmentation tasks, and demonstrate significant improvements over the state of the art. Transferring knowledge learned by deep neural networks from label-rich domains to new target domains is a challenging problem, especially when the source and target input distributions have different characteristics. Such domain shifts occurs in many practical applications. For example, while simulated driving images rendered by games provide a rich source of labeled data for semantic segmentation BID19 , deep models trained on such source data do not transfer well to real target domains ( FIG0 ). When target-domain labels are unavailable for fine-tuning, unsupervised domain adaptation must be applied to improve the source model. Recent methods for unsupervised domain adaptation attempt to reduce the discrepancy between the source and target features via adversarial learning BID28 ; BID4 ). They divide the base network into a feature encoder G and classifier C, and add a separate domain classifier (critic) network D. The critic takes the features generated by G and labels them as either source-or target-domain. The encoder G is then trained with an additional adversarial loss that maximizes D's mistakes and thus aligns features across domains.However, a major drawback of this approach is that the critic simply predicts the domain label of the generated point and does not consider category information. Thus the generator may create features that look like they came from the right domain, but are not discriminative. In particular, it can generate points close to class boundaries, as shown in FIG0 (e), which are likely to be misclassified by the source model. We argue that to achieve good performance on the target data, the adaptation model must take the decision boundaries between classes into account while aligning features across domains ( FIG0 ). Moreover, since our setting is unsupervised adaptation, this must be accomplished without labels on target data.In this paper, we propose a novel adversarial alignment technique that overcomes the above limitation and preserves class boundaries. We make the following observation: if the critic could detect points near the decision boundary, then the generator would have to avoid these areas of the feature space in order to fool the critic. Thus the critic would force the generator to create more discriminative features. How can we obtain such a critic? If we alter the boundary of the classifier C slightly and measure the change in the posterior class probability p(y|x), where y and x denote class and We propose to use the boundary information to achieve low-density separation of aligned points.input respectively, then samples near the decision boundary are likely to have the largest change. In fact, this posterior discrepancy is inversely proportional to the distance from the class boundary. We thus propose to maximize this posterior discrepancy to turn C into a critic sensitive to nondiscriminative points. We call this technique Adversarial Dropout Regularization. Here, dropout is not used in the standard way, which is to regularize the main classifier and make it insensitive to noise. Instead, we use dropout in an adversarial way, to transform the classifier into a critic sensitive to noise. Compared to previous adversarial feature alignment methods, where the distributions p(x) are aligned globally, our method aligns target features away from decision boundaries, as illustrated in FIG0 (f).Our ADR approach has several benefits. First , we train the generator G with feedback from the classifier C, in contrast to existing methods, which use an unrelated critic D. Second, our method is general and straightforward to apply to a variety of domain adaptation problems, such as classification and semantic segmentation. Finally , since ADR is trained to align distributions, it is also applicable to semi-supervised learning and training of generative models, such as Generative Adversarial Networks (GANs) BID6 ). Through extensive experiments, we demonstrate the benefit of ADR over existing domain adaptation approaches, achieving state-of-the-art results in difficult domain shifts. We also show an application to semi-supervised learning using GANs in appendix. In this paper, we introduced a novel approach for aligning deep representation, Adversarial Dropout Regularization, which learns to generate discriminative features for the target domain. The method Table 3 : Results on adaptation from GTA5 \u2192 Cityscapes. DANN and FCN Wild denote methods proposed by BID4 ) and BID10 respectively. consists of a critic network that can detect samples near the task decision boundary and a feature generator that fools the critic. Our approach is general, applies to a variety of tasks, and does not require target domain labels. In extensive domain adaptation experiments, our method outperformed baseline methods, including entropy minimization, and achieved state-of-the-art results on three datasets.We also show how to apply our method to train Generative Adversarial Networks for semisupervised learning in the appendix."
}