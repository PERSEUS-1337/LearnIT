{
    "title": "ryg7jhEtPB",
    "content": "The importance weighted autoencoder (IWAE) (Burda et al., 2016) is a popular variational-inference method which achieves a tighter evidence bound (and hence a lower bias) than standard variational autoencoders by optimising a multi-sample objective, i.e. an objective that is expressible as an integral over $K > 1$ Monte Carlo samples. Unfortunately, IWAE crucially relies on the availability of reparametrisations and even if these exist, the multi-sample objective leads to inference-network gradients which break down as $K$ is increased (Rainforth et al., 2018). This breakdown can only be circumvented by removing high-variance score-function terms, either by heuristically ignoring them (which yields the 'sticking-the-landing' IWAE (IWAE-STL) gradient from Roeder et al. (2017)) or through an identity from Tucker et al. (2019) (which yields the 'doubly-reparametrised' IWAE (IWAE-DREG) gradient). In this work, we argue that directly optimising the proposal distribution in importance sampling as in the reweighted wake-sleep (RWS) algorithm from Bornschein & Bengio (2015) is preferable to optimising IWAE-type multi-sample objectives. To formalise this argument, we introduce an adaptive-importance sampling framework termed adaptive importance sampling for learning (AISLE) which slightly generalises the RWS algorithm. We then show that AISLE admits IWAE-STL and IWAE-DREG (i.e. the IWAE-gradients which avoid breakdown) as special cases. Let x be some observation and let z be some latent variable taking values in some space Z. These are modeled via the generative model p \u03b8 (z, x) = p \u03b8 (z)p \u03b8 (x|z) which gives rise to the marginal likelihood p \u03b8 (x) = Z p \u03b8 (z, x) dz of the model parameters \u03b8. In this work, we analyse algorithms for variational inference, i.e. algorithms which aim to 1. learn the generative model, i.e. find a value \u03b8 which is approximately equal to the maximum-likelihood estimate (MLE) \u03b8 ml := arg max \u03b8 p \u03b8 (x); 2. construct a tractable variational approximation q \u03c6,x (z) of p \u03b8 (z|x) = p \u03b8 (z, x)/p \u03b8 (x), i.e. find the value \u03c6 such that q \u03c6 ,x (z) is as close as possible to p \u03b8 (z|x) in some suitable sense. A few comments about this setting are in order. Firstly, as is common in the literature, we restrict our presentation to a single latent representation-observation pair (z, x) to avoid notational clutter -the extension to multiple independent observations is straightforward. Secondly, we assume that no parameters are shared between the generative model p \u03b8 (z, x) and the variational approximation q \u03c6,x (z). This is common in neural-network applications but could be relaxed. Thirdly, our setting is general enough to cover amortised inference. For this reason, we often refer to \u03c6 as the parameters of an inference network. Two main classes of stochastic gradient-ascent algorithms for optimising \u03c8 := (\u03b8, \u03c6) which employ K \u2265 1 Monte Carlo samples ('particles') to reduce errors have been proposed. (Roeder et al., 2017) heuristically drops the problematic score-function terms from the IWAE \u03c6-gradient. This induces bias for the IWAE objective. -IWAE-DREG. The 'doubly-reparametrised' IWAE (IWAE-DREG) \u03c6-gradient (Tucker et al., 2019) unbiasedly removes the problematic score-function terms from the IWAE \u03c6-gradient using a formal identity. We have shown that the adaptive-importance sampling paradigm of the reweighted wake-sleep (RWS) (Bornschein & Bengio, 2015) is preferable to the multi-sample objective paradigm of importance weighted autoencoders (IWAEs) (Burda et al., 2016) because the former achieves all the goals of the latter whilst avoiding its drawbacks. A On the r\u00f4le of the self-normalisation bias within RWS/AISLE"
}