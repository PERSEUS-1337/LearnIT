{
    "title": "SkJd_y-Cb",
    "content": "Word embeddings extract semantic features of words from large datasets of text.\n Most embedding methods rely on a log-bilinear model to predict the occurrence\n of a word in a context of other words. Here we propose word2net, a method that\n replaces their linear parametrization with neural networks. For each term in the\n vocabulary, word2net posits a neural network that takes the context as input and\n outputs a probability of occurrence. Further, word2net can use the hierarchical\n organization of its word networks to incorporate additional meta-data, such as\n syntactic features, into the embedding model. For example, we show how to share\n parameters across word networks to develop an embedding model that includes\n part-of-speech information. We study word2net with two datasets, a collection\n of Wikipedia articles and a corpus of U.S. Senate speeches. Quantitatively, we\n found that word2net outperforms popular embedding methods on predicting held-\n out words and that sharing parameters based on part of speech further boosts\n performance. Qualitatively, word2net learns interpretable semantic representations\n and, compared to vector-based methods, better incorporates syntactic information."
}