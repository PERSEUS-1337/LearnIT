{
    "title": "Syr8Qc1CW",
    "content": "Disentangling factors of variation has always been a challenging problem in representation learning. Existing algorithms suffer from many limitations, such as unpredictable disentangling factors, bad quality of generated images from encodings, lack of identity information, etc. In this paper, we proposed a supervised algorithm called DNA-GAN trying to disentangle different attributes of images. The latent representations of images are DNA-like, in which each individual piece represents an independent factor of variation. By annihilating the recessive piece and swapping a certain piece of two latent representations, we obtain another two different representations which could be decoded into images. In order to obtain realistic images and also disentangled representations, we introduced the discriminator for adversarial training. Experiments on Multi-PIE and CelebA datasets demonstrate the effectiveness of our method and the advantage of overcoming limitations existing in other methods. The success of machine learning algorithms depends on data representation, because different representations can entangle different explanatory factors of variation behind the data. Although prior knowledge can help us design representations, the vast demand of AI algorithms in various domains cannot be met, since feature engineering is labor-intensive and needs domain expert knowledge. Therefore, algorithms that can automatically learn good representations of data will definitely make it easier for people to extract useful information when building classifiers or predictors.Of all criteria of learning good representations as discussed in BID1 , disentangling factors of variation is an important one that helps separate various explanatory factors. For example, given a human-face image, we can obtain various information about the person, including gender, hair style, facial expression, with/without eyeglasses and so on. All of these information are entangled in a single image, which renders the difficulty of training a single classifier to handle different facial attributes. If we could obtain a disentangled representation of the face image, we may build up only one classifier for multiple attributes.In this paper, we propose a supervised method called DNA-GAN to obtain disentangled representations of images. The idea of DNA-GAN is motivated by the DNA double helix structure, in which different kinds of traits are encoded in different DNA pieces. We make a similar assumption that different visual attributes in an image are controlled by different pieces of encodings in its latent representations. In DNA-GAN, an encoder is used to encode an image to the attribute-relevant part and the attribute-irrelevant part, where different pieces in the attribute-relevant part encode information of different attributes, and the attribute-irrelevant part encodes other information. For example, given a facial image, we are trying to obtain a latent representation that each individual part controls different attributes, such as hairstyles, genders, expressions and so on. Though annihilating recessive pieces and swapping certain pieces, we can obtain novel crossbreeds that can be decoded into new images. By the adversarial discriminator loss and the reconstruction loss, DNA-GAN can reconstruct the input images and generate new images with new attributes. Each attribute is disentangled from others gradually though iterative training. Finally, we are able to obtain disentangled representations in the latent representations.The summary of contributions of our work is as follows:1. We propose a supervised algorithm called DNA-GAN, that is able to disentangle multiple attributes as demonstrated by the experiments of interpolating multiple attributes on Multi-PIE BID5 and CelebA BID12 datasets.2. We introduce the annihilating operation that prevents from trivial solutions: the attributerelevant part encodes information of the whole image instead of a certain attribute.3. We employ iterative training to address the problem of unbalanced multi-attribute image data, which was theoretically proved to be more efficient than random image pairs. In this paper, we propose a supervised algorithm called DNA-GAN that can learn disentangled representations from multi-attribute images. The latent representations of images are DNA-like, consisting of attribute-relevant and attribute-irrelevant parts. By the annihilating operation and attribute hybridization, we are able to create new latent representations which could be decoded into novel images with designed attributes. The iterative training strategy effectively overcomes the difficulty of training on unbalanced datasets and helps disentangle multiple attributes in the latent space.The experimental results not only demonstrate that DNA-GAN is effective in learning disentangled representations and image editing, but also point out its potential in interpretable deep learning, image understanding and transfer learning.There also exist some limitations of our model. Without strong guidance on the attribute-irrelevant parts, some background information is encoded into the attribute-relevant part. As we can see in FIG3 , the background color gets changed when swapping attributes. Besides, our model may fail when several attributes are highly correlated with each other. For example, Male and Mustache are statistically dependent, which are hard to disentangle in the latent representations. These are left as our future work."
}