{
    "title": "rJxok1BYPr",
    "content": "Machine learning algorithms for generating molecular structures offer a promising new approach to drug discovery. We cast molecular optimization as a translation problem, where the goal is to map an input compound to a target compound with improved biochemical properties. Remarkably, we observe that when generated molecules are iteratively fed back into the translator, molecular compound attributes improve with each step. We show that this finding is invariant to the choice of translation model, making this a \"black box\" algorithm. We call this method Black Box Recursive Translation (BBRT), a new inference method for molecular property optimization. This simple, powerful technique operates strictly on the inputs and outputs of any translation model. We obtain new state-of-the-art results for molecular property optimization tasks using our simple drop-in replacement with well-known sequence and graph-based models. Our method provides a significant boost in performance relative to its non-recursive peers with just a simple \"``for\" loop. Further, BBRT is highly interpretable, allowing users to map the evolution of newly discovered compounds from known starting points. Automated molecular design using generative models offers the promise of rapidly discovering new compounds with desirable properties. Chemical space is large, discrete, and unstructured, which together, present important challenges to the success of any molecular optimization campaign. Approximately 10 8 compounds have been synthesized (Kim et al., 2015) while the range of potential drug-like candidates is estimated to between 10 23 and 10 80 (Polishchuk et al., 2013) . Consequently, new methods for intelligent search are paramount. A recently introduced paradigm for compound generation treats molecular optimization as a translation task where the goal is to map an input compound to a target compound with favorable properties (Jin et al., 2019b) . This framework has presented impressive results for constrained molecular property optimization where generated compounds are restricted to be structurally similar to the source molecule. We extend this framework to unconstrained molecular optimization by treating inference, vis-\u00e0-vis decoding strategies, as a first-class citizen. We observe that generated molecules can be repeatedly fed back into the model to generate even better compounds. This finding is invariant to the choice of translation model, making this a \"black box\" algorithm. This invariance is particularly attractive considering the recent emphasis on new molecular representations (G\u00f3mez-Bombarelli et al., 2018; Jin et al., 2018; Dai et al., 2018; Li et al., 2018; Kusner et al., 2017; Krenn et al., 2019) . Using our simple drop-in replacement, our method can leverage these recently introduced molecular representations in a translation setting for better optimization. We introduce Black Box Recursive Translation (BBRT), a new inference method for molecular property optimization. Surprisingly, by applying BBRT to well-known sequence-and graph-based models in the literature, we can produce new state-of-the-art results on property optimization benchmark tasks. Through an exhaustive exploration of various decoding strategies, we demonstrate the empirical benefits of using BBRT. We introduce simple ranking methods to decide which outputs are fed back into the model and find ranking to be an appealing approach to secondary property optimization. Finally, we demonstrate how BBRT is an extensible tool for interpretable and user-centric molecular design applications."
}