{
    "title": "SJePKo5HdV",
    "content": "Compressed representations generalize better (Shamir et al., 2010), which may be crucial when learning from limited or noisy labeled data. The Information Bottleneck (IB) method (Tishby et al. (2000)) provides an insightful and principled approach for balancing compression and prediction in representation learning. The IB objective I(X; Z) \u2212 \u03b2I(Y ; Z) employs a Lagrange multiplier \u03b2 to tune this trade-off. However, there is little theoretical guidance for how to select \u03b2. There is also a lack of theoretical understanding about the relationship between \u03b2, the dataset, model capacity, and learnability. In this work, we show that if \u03b2 is improperly chosen, learning cannot happen: the trivial representation P(Z|X) = P(Z) becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as \u03b2 varies. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, providing theoretical guidance for selecting \u03b2. We further show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the training examples. We give a practical algorithm to estimate the minimum \u03b2 for a given dataset. We test our theoretical results on synthetic datasets, MNIST, and CIFAR10 with noisy labels, and make the surprising observation that accuracy may be non-monotonic in \u03b2. Compressed representations generalize better (Shamir et al., 2010) , which is likely to be particularly important when learning from limited or noisy labels, as otherwise we should expect our models to overfit to the noise. Tishby et al. (2000) introduced the Information Bottleneck (IB) objective function which learns a representation Z of observed variables (X, Y ) that retains as little information about X as possible, but simultaneously captures as much information about Y as possible:min IB \u03b2 (X, Y ; Z) = min I(X; Z) \u2212 \u03b2I(Y ; Z)I(X; Y ) = dx dy p(x, y)log p(x,y) p(x)p(y ) is the mutual information. The hyperparameter \u03b2 controls the trade-off between compression and prediction, in the same spirit as Rate-Distortion Theory (Shannon, 1948) , but with a learned representation function P (Z|X) that automatically captures some part of the \"semantically meaningful\" information, where the semantics are determined by the observed relationship between X and Y .The IB framework has been extended to and extensively studied in a variety of scenarios, including Gaussian variables BID6 ), meta-Gaussians (Rey & Roth (2012) ), continuous variables via variational methods BID3 ; BID5 BID8 ), deterministic scenarios (Strouse & Schwab (2017a) ; BID12 ), geometric clustering (Strouse & Schwab (2017b) ), and is used for learning invariant and disentangled representations in deep neural nets BID0 b) ). However, a core issue remains: how should we select \u03b2? In the original work, the authors recommend sweeping \u03b2 > 1, which can be prohibitively expensive in practice, but also leaves open interesting theoretical questions around the relationship between \u03b2, P (Z|X), and the observed data, P (X, Y ). For example, under how much label noise will IB at a given \u03b2 still be able to learn a useful representation?This work begins to answer some of those questions by characterizing the onset of learning. Specifically:\u2022 We show that improperly chosen \u03b2 may result in a failure to learn: the trivial solution P (Z|X) = P (Z) becomes the global minimum of the IB objective, even for \u03b2 1.\u2022 We introduce the concept of IB-Learnability, and show that when we vary \u03b2, the IB objective will undergo a phase transition from the inability to learn to the ability to learn.\u2022 Using the second-order variation , we derive sufficient conditions for IB-Learnability, which provide theoretical guidance for choosing a good \u03b2.\u2022 We show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the training examples, reveal its relationship with the slope of the Pareto frontier at the origin on the information plane I(Y ; Z) vs. I(X; Z), and discuss its relation with model capacity.We use our main results to demonstrate on synthetic datasets, MNIST (LeCun et al., 1998) , and CIFAR10 BID13 ) under noisy labels that the theoretical prediction for IB-Learnability closely matches experiment. We present an algorithm for estimating the onset of IB-Learnability, and demonstrate that it does a good job of estimating the theoretical predictions and the empirical results. Finally, we observe discontinuities in the Pareto frontier of the information plane as \u03b2 increases, and those dicontinuities correspond to accuracy decreasing as \u03b2 increases. In this paper, we have presented theoretical results for predicting the onset of learning, and have shown that it is determined by the largest confident, typical and imbalanced subset of the examples. We gave a practical algorithm for predicting the transition, and showed that those predictions are accurate, even in cases of extreme label noise. We have also observed a surprising non-monotonic relationship between \u03b2 and accuracy, and shown its relationship to discontinuities in the Pareto frontier of the information plane. We believe these results will provide theoretical and practical guidance for choosing \u03b2 in the IB framework for balancing prediction and compression. Our work also raises other questions, such as whether there are other phase transitions in learnability that might be identified. We hope to address some of those questions in future work.M\u00e9lanie Rey and Volker Roth. Meta-gaussian information bottleneck. In Advances in Neural Information Processing Systems, pp. 1916 Systems, pp. -1924 Systems, pp. , 2012 .Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information bottleneck. The structure of the Appendix is as follows. In Appendix A , we provide preliminaries for the first-order and secondorder variations on functionals. Then we prove Theorem 1 in Appendix B. In Appendix C, we state and prove Sufficient Condition 1 for IB \u03b2 -learnability. In Appendix D , we calculate the first and second variations of IB \u03b2 [p(z|x)] at the trivial representation p(z|x) = p(z), which is used in proving the Sufficient Condition 2 IB \u03b2 -learnability (Appendix F). After these preparations, we prove the key result of this paper, Theorem 2, in Appendix G. Then two important corollaries 2.1, 2.2 are proved in Appendix H. We provide additional discussions and insights for Theorem 2 in Appendix I, and Algorithm 1 for estimation of an upper bound\u03b2 0 \u2265 \u03b2 0 in Appendix J. Finally in Appendix K, we provide details for the experiments. Similarity to information measures. The denominator of Eq. (2) is closely related to mutual information. Using the inequality x \u2212 1 \u2265 log(x ) for x > 0, it becomes: DISPLAYFORM0 where\u0128(\u2126 x ; Y ) is the mutual information \"density\" at \u2126 x \u2282 X . Of course, this quantity is also D KL [p(y|\u2126 x )||p(y) ], so we know that the denominator of Eq. FORMULA2 is non-negative. Incidentally , E y\u223cp (y|\u2126x) p (y|\u2126x) p(y) \u2212 1 is the density of \"rational mutual information\" BID15 DISPLAYFORM1 Similarly, the numerator is related to the self-information of \u2126 x : DISPLAYFORM2 so we can estimate the phase transition as: DISPLAYFORM3 Since Eq. (22) uses upper bounds on both the numerator and the denominator, it does not give us a bound on \u03b2 0 .Multiple phase transitions. Based on this characterization of \u2126 x , we can hypothesize datasets with multiple learnability phase transitions. Specifically, consider a region \u2126 x0 that is small but \"typical\", consists of all elements confidently predicted as y 0 by p(y|x), and where y 0 is the least common class. By construction , this \u2126 x0 will dominate the infimum in Eq. (2), resulting in a small value of \u03b2 0 . However, the remaining X \u2212 \u2126 x0 effectively form a new dataset, X 1 . At exactly \u03b2 0 , we may have that the current encoder, p 0 (z|x), has no mutual information with the remaining classes in X 1 ; i.e., I(Y 1 ; Z 0 ) = 0. In this case, Definition 1 applies to p 0 (z|x) with respect to I(X 1 ; Z 1 ). We might expect to see that , at \u03b2 0 , learning will plateau until we get to some \u03b2 1 > \u03b2 0 that defines the phase transition for X 1 . Clearly this process could repeat many times, with each new dataset X i being distinctly more difficult to learn than X i\u22121 . The end of Appendix F gives a more detailed analysis on multiple phase transitions.Estimating model capacity. The observation that a model can't distinguish between cluster overlap in the data and its own lack of capacity gives an interesting way to use IB-Learnability to measure the capacity of a set of models relative to the task they are being used to solve. Learnability and the Information Plane. Many of our results can be interpreted in terms of the geometry of the Pareto frontier illustrated in FIG1 , which describes the trade-off between increasing I(Y ; Z) and decreasing I(X; Z). At any point on this frontier that minimizes IB min \u03b2 \u2261 min I(X; Z) \u2212 \u03b2I(Y ; Z), the frontier will have slope \u03b2 \u22121 if it is differentiable. If the frontier is also concave (has negative second derivative), then this slope \u03b2 \u22121 will take its maximum \u03b2 \u22121 0 at the origin, which implies IB \u03b2 -Learnability for \u03b2 > \u03b2 0 , so that the threshold for IB \u03b2 -Learnability is simply the inverse slope of the frontier at the origin. More generally, as long as the Pareto frontier is differentiable, the threshold for IB \u03b2 -learnability is the inverse of its maximum slope. Indeed, Theorem 2 gives lower bounds of the slope of the Pareto frontier at the origin. This means that we lack IB \u03b2 -learnability for \u03b2 < \u03b2 0 , which makes the origin the optimal point. If the frontier is convex, then we achieve optimality at the upper right endpoint if \u03b2 > \u03b2 1 , otherwise on the frontier at the location between the two endpoints where the frontier slope is \u03b2 \u22121 ."
}