{
    "title": "rylU8oRctX",
    "content": "Deep learning has become a widely used tool in many computational and classification problems. \n Nevertheless obtaining and labeling data, which is needed for strong results, is often expensive or even not possible. \n In this paper three different algorithmic approaches to deal with limited access to data are evaluated and compared to each other. \n We show the drawbacks and benefits of each method. \n One successful approach, especially in one- or few-shot learning tasks, is the use of external data during the classification task. \n Another  successful approach, which achieves state of the art results in semi-supervised learning (SSL) benchmarks, is consistency regularization.\n Especially virtual adversarial training (VAT) has shown strong results and will be investigated in this paper. \n The aim of consistency regularization is to force the network not to change the output, when the input or the network itself is perturbed.\n Generative adversarial networks (GANs) have also shown strong empirical results. \n In many approaches the GAN architecture is used in order to create additional data and therefor to increase the generalization capability of the classification network.\n Furthermore we consider the use of unlabeled data for further performance improvement. \n The use of unlabeled data is investigated both for GANs and VAT. \n Deep neural networks have shown great performance in a variety of tasks, like speech or image recognition. However often extremely large datasets are necessary for achieving this. In real world applications collecting data is often very expensive in terms of cost or time. Furthermore collected data is often unbalanced or even incorrect labeled. Hence performance achieved in academic papers is hard to match.Recently different approaches tackled these problems and tried to achieve good performance, when otherwise fully supervised baselines failed to do so. One approach to learn from very few examples, the so called few-shot learning task, consists of giving a collection of inputs and their corresponding similarities instead of input-label pairs. This approach was thoroughly investigated in BID9 , BID33 , BID28 and gave impressive results tested on the Omniglot dataset BID12 ). In essence a task specific similarity measure is learned, that embeds the inputs before comparison.Furthermore semi-supervised learning (SSL) achieved strong results in image classification tasks. In SSL a labeled set of input-target pairs (x, y) \u2208 D L and additionally an unlabeled set of inputs x \u2208 D U L is given. Generally spoken the use of D U L shall provide additional information about the structure of the data. Generative models can be used to create additional labeled or unlabeled samples and leverage information from these samples BID26 , BID18 ). Furthermore in BID2 it is argued, that GAN-based semi-supervised frameworks perform best, when the generated images are of poor quality. Using these badly generated images a classifier with better generalization capability is obtained. On the other side uses generative models in order to learn feature representations, instead of generating additional data.Another approach in order to deal with limited data is consistency regularization. The main point of consistency regularization is, that the output of the network shall not change, when the input or the network itself is perturbed. These perturbations may also result in inputs, which are not realistic anymore. This way a smooth manifold is found on which the data lies. Different approaches to consistency regularization can be found in BID15 , BID23 , BID11 , and BID32 .The aim of this paper is to investigate how different approaches behave compared to each other. Therefore a specific image and sound recognition task is created with varying amount of labeled data. Beyond that it is further explored how different amounts of unlabeled data support the tasks, whilst also varying the size of labeled data. The possible accuracy improvement by labeled and unlabeled examples is compared to each other. Since there is a correlation between category mismatch of unlabeled data and labeled data BID20 ) reported, we investigate how this correlation behaves for different approaches and datasets. In this paper three methods for dealing with little data have been compared to each other. When the amount of labeled data is very little and no unlabeled data is available, siamese neural networks offer the best alternative in order to achieve good results in terms of accuracy. Furthermore when there is additional unlabeled data available using GANs or VAT offer a good option. VAT outperforms GAN when the amount of data is low. On contrast GANs should be preferred for moderate or high amounts of data. Nevertheless both methods must be tested for any individual use case, since the behavior of these methods may change for different datasets.Surprising results have been obtained on the class mismatch experiment. It was observed that adding samples, which do not belong to the target classes, not necessarily reduce the accuracy. Whether adding such samples improves or reduce the accuracy, may heavily depend on how closely these samples/ classes are related to the target samples/ classes. An interesting questions remains whether datasets which perform good in transfer learning tasks (e.g. transferring from ImageNet to CIFAR-10) also may be suitable for such semi-supervised learning tasks.Furthermore any combinations of three examined methods can bear interesting results, e.g.VAT could be applied to the discriminator in the GAN framework. Also a combination of GAN and siamese neural networks could be useful, in this case the siamese neural network would have two outputs, one for the source and one for the similarity."
}