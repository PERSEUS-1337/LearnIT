{
    "title": "HkxMG209K7",
    "content": "It is usually hard for a learning system to predict correctly on the rare events, and there is no exception for segmentation algorithms. Therefore, we hope to build an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. One plausible solution is to project the segmentation results into a low dimensional feature space, and then learn classifiers/regressors in the feature space to predict the qualities of segmentation results. In this paper, we form the feature space using shape feature which is a strong prior information shared among different data, so it is capable to predict the qualities of segmentation results given different segmentation algorithms on different datasets. The shape feature of a segmentation result is captured using the value of loss function when the segmentation result is tested using a Variational Auto-Encoder(VAE). The VAE is trained using only the ground truth masks, therefore the bad segmentation results with bad shapes become the rare events for VAE and will result in large loss value. By utilizing this fact, the VAE is able to detect all kinds of shapes that are out of the distribution of normal shapes in ground truth (GT). Finally, we learn the representation in the one-dimensional feature space to predict the qualities of segmentation results. We evaluate our alarm system on several recent segmentation algorithms for the medical segmentation task. The segmentation algorithms perform differently on different datasets, but our system consistently provides reliable prediction on the qualities of segmentation results.\n A segmentation algorithm usually fails on the rare events, and it is hard to fully avoid such issue. The rare events may occur due to the limited number of training data. To handle it, the most intuitive way is to increase the number of training data. However, the labelled data is usually hard to collect, e.g., to fully annotate a 3D medical CT scan requires professional radiology knowledge and several hours of work. In addition, the human labelling is unable to cover all possible cases. Previously, various methods have been proposed to make better use of training data, like sampling strategies paying more attention to the rare events BID17 . But still it may fail on the rare events which never occur in the training data. Another direction is to increase the robustness of the segmentation algorithm to the rare events. BID6 proposed the Bayesian neural network which can model the uncertainty as an additional loss to make the algorithm more robust to noisy data. These kinds of methods make the algorithm insensitive to certain types of perturbations, but the algorithms may still fail on other perturbations.Since it is hard to completely prevent the segmentation algorithm from failure, we consider to detect the failure instead: build up an alarm system cooperating with the segmentation algorithm, which will set off alarms when the system finds that the segmentation result is not good enough. This task is also called as quality assessment. Several works have been proposed in this field. BID5 applied Bayesian neural network to capture the uncertainty of the segmentation result and set off alarm based on that uncertainty. However, this system also suffers from rare events since the segmentation algorithms often make mistakes confidently on some rare events (Xie et al., 2017) . BID8 provided an effective way by projecting the segmentation results into a feature space and learn from this low dimension space. They manually design several heuristic features, e.g., size, intensity, and assume such features would indicate the quality of the segmentation results. After projecting the segmentation results into the feature space, they learned a classifier to CT image GT Recon-Prediction Recon-GT Prediction Entropy Alea-Uncertainty Epis-Uncertainty Figure 1 : The visualize on an NIH CT dataset for pancreas segmentation. The figures ReconPrediction and Recon-GT are reconstruction results from prediction and GT by VAE network respectively. The Dice score between the GT and prediction is 47.06 while the Dice score between the prediction and Recon-Prediction is 47.25. In our method, we use the later Dice score to predict the former real Dice score which is usually unknown at inference phase in real applications. This case shows how these two Dice scores are related to each other. On the other hand, for uncertainty based methods, different kinds of uncertainty distribute mainly on the boundary of predicted mask, which makes it a vague information when detecting the failure cases.predict its quality. Since the feature space is of relative low dimension now, it is able to distinguish good segmentation results from bad ones directly. In a reasonable feature space, when the segmentation algorithm fails, the failure output will be far from the ground truth. So the main problems is what these good features are and how to capture them. Many features that BID8 selected are actually less related with the quality of segmentation results, e.g., size.In our system, we choose a more representative feature, i.e., the shape feature. The shape feature is important because the segmenting objects (foreground in the volumetric mask) often have stable shapes among different cases, especially in 3D. So the shape feature is supposed to provide a strong prior information for judging the quality of a segmentation result, i.e., bad segmentation results tend to have bad shapes and vice versa. Furthermore, to model the prior from the segmentation mask space is much easier than in the image space and the shape prior can be shared among different datasets while the features like image intensity are affected by many factors. That means the shape feature can deal with not only rare events but also different data distributions in the image space, which shows great generalization power and potential in transfer learning. We propose to use the Variational Auto-Encoder(VAE) BID7 to capture the shape feature. The VAE is trained on the ground truth masks, and afterwards we define the value of the loss function as the shape feature of a segmentation result when it is tested with VAE network. Intuitively speaking, after the VAE is trained, the bad segmentation results with bad shapes are just rare events to VAE because it is trained using only the ground truth masks, which are under the distribution of normal shapes. Thus they will have larger loss value. In this sense we are utilizing the fact that the learning algorithms will perform badly on the rare events. Formally speaking, the loss function, known as the variational lower bound, is optimized to approximate the function log P (Y ) during the training process. So after the training, the value of the loss function given a segmentation result\u0176 is close to log P (\u0176 ), thus being a good definition for the shape feature.In this paper, we proposed a VAE-based alarm system for segmentation algorithms. The qualities of the segmentation results can be well predicted using our system. To validate the effectiveness of our alarm system, we test it on multiple segmentation algorithms. These segmentation algorithms are trained on one dataset and tested on several other datasets to simulate when the rare events occur. The performance for the segmentation algorithms on the other datasets (rather than the training dataset) drops quickly but our system can still predict the qualities accurately. We compare our system with other alarm systems on the above tasks and our system outperforms them by a large margin, which shows the importance of shape feature in alarm system and the great power of VAE in capturing the shape feature.2 RELATED WORK BID6 employed Bayesian neural network (BNN) to model the aleatoric and epistemic uncertainty. Afterwards, BID9 applied the BNN to calculate the aleatoric and epistemic uncertainty on medical segmentation tasks. BID5 utilized the BNN and model another kind of uncertainty based on the entropy of segmentation results. They calculated a doubt score by summing over weighted pixel-vise uncertainty. However we can see from Figure 1 that when the segmentation algorithm fails to provide correct prediction, the uncertainty still distributes mainly on the boundary of the wrong segmentation result, which means the algorithm is strongly confident on where it makes mistakes.Other method like Valindria et al. FORMULA0 used registration based method for quality assessment. It is a reliable method because it takes the prior of image by setting up a reference dataset. The problem of this method is inefficient testing. Every single case needs to do registration with all reference data to determine the quality but registration on 3D image is usually slow. Also the registration based method can hardly be transferred between datasets or modalities. Chabrier et al. FORMULA1 and BID3 use unsupervised method to estimate the segmentation quality using geometrical and other features. However the application in medical settings is not clear. Also BID14 tried a simple method using image-segmentation pair to directly regress the quality.Kohlberger et al. FORMULA0 introduced a feature space of shape and appearance to characterize a segmentation. The shape features in their system contain volume size, surface area, which are not necessarily related with the quality of the segmentation results. In our work we choose to learn a statistical prior of the segmentation mask and then determine the quality by how well a mask fits the prior. This is related with Out-of-Distribution (OOD) detection. Previous works in this field BID4 ) BID10 ) made use of the softmax output in the last layer of a classifier to calculate the out-of-distribution level. In our case, however, for a segmentation method, we can only get a voxel-wise out-of-distribution level using these methods. How to calculate the out-of-distribution level for the whole mask becomes another problem. In addition, the segmentation algorithm can usually predict most of background voxels correctly with a high confidence, making the out-of-distribution level on those voxels less representative.Auto-Encoder(AE), as a way of learning representation of data automatically, has been widely used in many areas such as anomaly detection BID21 , dimension reduction, etc. Variational autoencoder(VAE) BID7 , compared with AE, can better learn the representation for the latent space. We employ VAE to learn the shape representation from the volumetric mask. Unlike method of BID18 which needs to pre-train with RBM, VAE can be trained following an end-to-end fashion. BID13 learned the shape representation from point cloud form, while we choose the volumetric form as a more natural way to corporate with segmentation task. utilizes AE to evaluate difference between prediction and ground truth but not in an unsupervised way. We split NIH data into four folds and three of them are used for training segmentation algorithms and our pipeline; the remaining one, together with all training data from MSD and MLC forms the validation data to evaluate our evaluation method. First we learn the parameter of VAE using the training label of NIH dataset. Then we choose BNN as the preparation algorithm. The training strategy in section 3.3 is applied on it to learn the parameters of regression. For all the baseline methods, we employ the same training strategy of jackknifing as in our method and choose the BNN as preparation algorithm for fair comparison. Finally we predict the quality of predictive mask on the validation data for all the segmentation algorithms. Note that all segmentation algorithms are trained only on the NIH training set. Table 1 reports the results of using three baseline models and our method to evaluate the BNN model tested on three datasets. In general, our method achieves the lowest error and variance on all datasets. In our experiment, the BNN achieves 82.15, 57.10 and 66.36 average Dice score tested on NIH, MSD and MLC datasets respectively. The segmentation algorithm trained on NIH will fail on some cases of other datasets and that is why we need the alarm system. The spearman coefficient for direct regression method on NIH dataset is close to 0 because the testing results on NIH are all of high quality and the regression result is not sensitive to slight variation in quality. Uncertainty based methods can better predict the quality but as shown in Figure 1 , the uncertainty mainly distributes on the boundary of predictive mask but not on the missing parts or false positive parts. When the BNN is tested on the other two datasets, our method remains stable in predicting the quality. Table 2 shows the quality assessment results for 4 different segmentation algorithms. For each segmentation algorithm, When evaluating the segmentation results from DeepLab algorithm tested on MLC dataset, the accuracy is lower but the correlation between the predictive quality and real quality is high. In the paper we present a VAE based alarm system for segmentation algorithms which predicts the qualities of the segmentation results without using ground truth. We claim that the shape feature is useful in predicting the qualities of the segmentation results. To capture the shape feature, we train a VAE using only ground truth masks. We utilize the fact that rare events will achieve larger value for loss function, and successfully detect the out-of-distribution shape according to the value for loss function in the testing time. In the second step we collect the segmentation results of the segmentation algorithm on the training data and extract the shape feature of them to learn the parameters of regression. By applying jackknifing training on the segmentation algorithm, we will get segmentation results of different qualities on the training data, therefore obtain more accurate regression parameters.The reliable quality assessment results prove both that the shape feature capturing from VAE is meaningful and that the shape feature is useful for quality assessment in the segmentation task. Furthermore, our proposed method outperforms the uncertainty based methods and direct regression method, and possesses better transferability to other datasets and other segmentation algorithms."
}