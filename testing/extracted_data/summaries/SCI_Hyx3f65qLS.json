{
    "title": "Hyx3f65qLS",
    "content": "Blind document deblurring is a fundamental task in the field of document processing and restoration, having wide enhancement applications in optical character recognition systems, forensics, etc. Since this problem is highly ill-posed, supervised and unsupervised learning methods are well suited for this application. Using various techniques, extensive work has been done on natural-scene deblurring. However, these extracted features are not suitable for document images. We present SVDocNet, an end-to-end trainable U-Net based spatial recurrent neural network (RNN) for blind document deblurring where the weights of the RNNs are determined by different convolutional neural networks (CNNs). This network achieves state of the art performance in terms of both quantitative measures and qualitative results. With the advent of digitization, document and text based images have become very prominent in one's quotidian lifestyle, spanning over reports, certificates, receipts, handwritten documents, etc. During image acquisition, numerous unavoidable factors such as camera shake, focusing errors, and noise may corrupt the image, leading to loss of valuable information. Hence, image post-processing became mandatory. This step is especially vital in automated information retrieval and optical character recognition systems. The process of image degradation in single image deblurring is modelled as where y is the observed image, x is the original image, and k is the unknown blurring kernel, also known as the point spread function (PSF), and n denotes uncorrelated additive noise. Blind deconvolution is the method of obtaining the original image and, in some cases, the PSF, from the observed image. The problem of blind image deblurring is highly ill-posed and non-convex. Many techniques have been used for deblurring of text-based images. Early on, statistical and learning based methods were prominent for blur kernel estimation. With the emergence of deep learning, using CNN based approaches were proposed as function approximators to predict the deblurred image. Although these methods have proven to give admirable results, they still have certain pitfalls. We assume that the function modelled by the CNN for image restoration is a spatially invariant function, whereas this may not be true, as in the case of dynamic scenes [12] . Also, deconvolution of different types of blur kernels would inevitably increase the model parameters and computational expenses. Hence, model adjustment based on the PSF and the need for spatial variance became necessary. We propose SVDocNet, an end to end trainable spatially variant network based on the well known U-Net encoder-decoder architecture, consisting of recurrent layers in the skip connections between the encoder-decoder blocks. Additionally, we have three auxiliary networks that do not contribute to any intermediary features or outputs, but learn the internal adjustments that must be customized to each image in the form of the primary network's weights to guide the propagation of features. We evaluate the model on benchmark datasets and compare the results with state of the art solutions. We proposed SVDocNet, an end-to-end trainable spatially variant U-Net based architecture for blind document deblurring, replacing the skip connections between the encoder and decoder blocks with alternating convolutional and recurrent layers for efficient feature extraction. Three auxiliary U-Net networks are present to predict suitable weights for the recurrent layers by examining the input blurred image. We demonstrated the potency of this system both quantitatively and qualitatively."
}