{
    "title": "BJxpbREKvB",
    "content": "Few-shot learning is the process of learning novel classes using only a few examples and it remains a challenging task in machine learning. Many sophisticated few-shot learning algorithms have been proposed based on the notion that networks can easily overfit to novel examples if they are simply fine-tuned using only a few examples. In this study, we show that in the commonly used low-resolution mini-ImageNet dataset, the fine-tuning method achieves higher accuracy than common few-shot learning algorithms in the 1-shot task and nearly the same accuracy as that of the state-of-the-art algorithm in the 5-shot task. We then evaluate our method with more practical tasks, namely the high-resolution single-domain and cross-domain tasks. With both tasks, we show that our method achieves higher accuracy than common few-shot learning algorithms. We further analyze the experimental results and show that: 1) the retraining process can be stabilized by employing a low learning rate, 2) using adaptive gradient optimizers during fine-tuning can increase test accuracy, and 3) test accuracy can be improved by updating the entire network when a large domain-shift exists between base and novel classes. Previous studies have shown that high image classification performance can be achieved by using deep networks and big datasets (Krizhevsky et al., 2012; Simonyan & Zisserman, 2015; He et al., 2016; Szegedy et al., 2015) . However, the performances of these algorithms rely heavily on extensive manually annotated images, and considerable cost is often incurred in preparing these datasets. To avoid this problem, few-shot learning, which is a task of learning novel classes using only a few examples, has been actively researched. However, few-shot learning remains a considerably challenging task in machine learning, and classification accuracy in few-shot tasks is much lower than that of the many-shot regime. This is because a network pretrained using base classes must adapt to novel classes using only a few examples. The simplest means of overcoming this difficulty is to fine-tune the network using novel classes. However, the number of trainable parameters of deep networks is so large that we believe that networks can easily overfit to novel classes if we simply fine-tune the networks using only a few examples. For example, the number of trainable parameters in the ResNet-152 (He et al., 2016 ) is approximately 60 M, which is much greater than the number of novel examples (e.g., 25 for 5-way 5-shot learning), and this leads us to the idea of overfitting. Using various sophisticated methods, numerous studies have been conducted to prevent networks from overfitting. However, the performance of a naive fine-tuning method has not been well investigated, and Chen et al. (2019) has pointed out that performance of this method had been underestimated in previous studies. Therefore, in this study, we analyze the performance of a fine-tuning method and show that it can achieve higher classification accuracy than common few-shot learning methods and, in some cases, can achieve an accuracy approximating that of the state-of-the-art algorithm. We also experimentally show that: 1) a low learning rate stabilizes the retraining process, 2) using an adaptive gradient optimizer when fine-tuning the network increases test accuracy, and 3) updating the entire network increases test accuracy when a large domain shift occurs between base and novel classes. To evaluate accuracy in few-shot image classification tasks, the mini-ImageNet dataset (Vinyals et al., 2016) has been used in many previous studies. This is a subset of the ImageNet dataset (Deng et al., 2009) in which each image is resized to 84 \u00d7 84 to reduce computational cost.the high-resolution mini-ImageNet dataset and cross-domain dataset. Both datasets contain higherresolution images than the original mini-ImageNet dataset, and the cross-domain dataset represents a greater challenge because base and novel classes are sampled from different datasets. Thus, a larger domain shift occurs between these classes. In this study, we evaluate the performance of our method using the high-resolution mini-ImageNet dataset (high-resolution single-domain task) and cross-domain dataset (cross-domain task) as well as the common low-resolution mini-ImageNet dataset (low-resolution single-domain task). Details of these datasets are provided in Section 2.3. The main contributions of this study are as follows: 1) We show that in the common low-resolution single-domain task, our fine-tuning method achieves higher accuracy than common few-shot learning algorithms in the 1-shot task and nearly the same accuracy as that of the state-of-the-art method in the 5-shot task. We also show that our method achieves higher accuracy than common few-shot learning methods both in the high-resolution single-domain and cross-domain tasks. Note that we do not compare the performance of our method with the state-of-the-art algorithm in the high-resolution single-domain and cross-domain tasks because the performances for these tasks are not reported in the corresponding papers. 2) We further analyze the experimental results and show that a low learning rate stabilizes the relearning process, that test accuracy can be increased by using an adaptive gradient optimizer such as the Adam optimizer, and that updating the entire network can increase test accuracy when a large domain shift occurs. 2 OVERVIEW OF FEW-SHOT LEARNING 2.1 NOTATION Few-shot learning is a task of learning novel classes using only a few labeled examples. This task is also called N -way K-shot learning, where N denotes the number of novel classes and K is the number of labeled examples per class. We focus on the 5-way learning task such as in previous studies (Chen et al., 2019; Schwartz et al., 2018) . Labeled and unlabeled examples of novel classes are called support and query sets, respectively. A network is pretrained using base classes, which contain numerous labeled examples. Base and novel classes are mutually exclusive. Base classes are used for pretraining, and novel classes are used for retraining and testing. Validation classes are used to determine a learning rate and the number of epochs required to retrain the network. In this study, we showed that in the low-resolution single-domain task, our fine-tuning method achieved higher accuracy than common few-shot learning methods in the 1-shot task and nearly the same accuracy as the state-of-the-art method in the 5-shot task. We also evaluated our method with more practical tasks, such as the high-resolution single-domain and cross-domain tasks. In both tasks, our method achieved higher accuracy than common few-shot learning methods. We then experimentally showed that: 1) a low learning rate stabilizes the retraining process, 2) adaptive gradient optimizers such as Adam improve test accuracy, and 3) updating the entire network results in higher accuracy when a large domain shift occurs. We believe that these insights into fine-tuning for few-shot learning tasks will help our community tackle this challenging task."
}