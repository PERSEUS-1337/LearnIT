{
    "title": "BkloRs0qK7",
    "content": "We present a large-scale empirical study of catastrophic forgetting (CF) in modern Deep Neural Network (DNN) models that perform sequential (or: incremental) learning.\n A new experimental protocol is proposed that takes into account typical constraints encountered in application scenarios.\n As the investigation is empirical, we evaluate CF behavior on the hitherto largest number of visual classification datasets, from each of which we construct a representative number of Sequential Learning Tasks (SLTs) in close alignment to previous works on CF.\n Our results clearly indicate that there is no model that avoids CF for all investigated datasets and SLTs under application conditions. We conclude with a discussion of potential solutions and workarounds to CF, notably for the EWC and IMM models. This article is in the context of sequential or incremental learning in Deep Neural Networks (DNNs). Essentially, this means that a DNN is not trained once, on a single task D, but successively on two or more sub-tasks D 1 , . . . , D n , one after another. Learning tasks of this type, which we term Sequential Learning Tasks (SLTs) (see FIG0 ), are potentially very common in real-world applications. They occur wherever DNNs need to update their capabilities on-site and over time: gesture recognition, network traffic analysis, or face and object recognition in mobile robots. In such scenarios, neural networks have long been known to suffer from a problem termed \"catastrophic forgetting\"(CF) (e.g., BID7 ) which denotes the abrupt and near-complete loss of knowledge from previous subtasks D 1 , . . . , D k\u22121 after only a few training iterations on the current sub-task D k (see FIG0 compared to FIG0 ). We focus on SLTs from the visual domain with two sub-tasks each, as DNNs show pronounced CF behavior even when only two sub-tasks are involved. The sequential learning tasks used in this study only have two sub-tasks: D1 and D2. During training (white background) and re-training (gray background), test accuracy is measured on D1 (blue, ), D2 (green, ) and D1 \u222a D2 (red, ). The blue curve allows to determine the presence of CF by simple visual inspection: if there is significant degradation w.r.t. the red curve, then CF has occurred. DISPLAYFORM0 The field of incremental learning is large, e.g., BID20 and BID8 . Recent systematic comparisons between different DNN approaches to avoid CF are performed in, e.g., BID23 or . Principal recent approaches to avoid CF include ensemble methods BID22 BID6 , dual-memory systems BID24 BID11 BID21 BID9 and regularization approaches. Whereas BID10 suggest Dropout for alleviating CF, the EWC method BID14 proposes to add a term to the energy function that protects weights that are important for the previous sub-task (s) . Importance is determined by approximating the Fisher information matrix of the DNN. A related approach is pursued by the Incremental Moment Matching technique (IMM) (see ), where weights from DNNs trained on a current and a past sub-tasks are \"merged\" using the Fisher information matrix. Other regularization-oriented approaches are proposed in BID2 ; BID25 and BID13 which focus on enforcing sparsity of neural activities by lateral interactions within a layer.Number of tested datasets In general, most methods referenced here are evaluated only on a few datasets, usually on MNIST BID16 and various derivations thereof (permutation, rotation, class separation). Some studies make limited use of CIFAR10, SVHN, the Amazon sentiment analysis problem, and non-visual problems such as data from Q-learning of Atari games. A largescale evaluation on a huge number of qualitatively different datasets is still missing 1 . Model selection and prescience Model selection (i.e., selecting DNN topology and hyperparameters) is addressed in some approaches BID10 but on the basis of a \"prescient\" evaluation where the best model is selected after all tasks have been processed, an approach which is replicated in BID14 . This amounts to a knowledge of future sub-tasks which is problematic in applications. Most approaches ignore model selection BID25 BID2 BID13 , and thus implicitly violate causality. Storage of data from previous sub-tasks From a technical point of view, DNNs can be retrained without storing training data from previous sub-tasks, which is done in BID10 and BID25 . For regularization approaches, however, there are regularization parameters that control the retention of previous knowledge, and thus must be chosen with care. In BID14 , this is \u03bb, whereas two such quantities occur in : the \"balancing\" parameter \u03b1 and the regularization parameter \u03bb for L2-transfer. The only study where regularization parameters are obtained through cross-validation (which is avoided in other studies) is BID2 (for \u03bb SN I and \u03bb \u2126 ) but this requires to store all previous training data.This review shows that enormous progress has been made, but that there are shortcomings tied to applied scenarios which need to be addressed. We will formalize this in Sec. 1.2 and propose an evaluation strategy that takes these formal constraints into account when testing CF in DNNs. The original contributions of our work can be summarized as follows:\u2022 We propose a training and evaluation paradigm for incremental learning in DNNs that enforces typical application constraints, see Sec. 1.2. The importance of such an applicationoriented paradigm is underlined by the fact that taking application constraints into account leads to radically different conclusions about CF than those obtained by other recent studies on CF (see Sec. 1.1).\u2022 We investigate the incremental learning capacity of various DNN approaches (Dropout, LWTA, EWC and IMM) using the largest number of qualitatively different classification datasets so far described. We find that all investigated models are afflicted by catastrophic forgetting, or else in violation of application constraints and discuss potential workarounds.\u2022 We establish that the \"permuted\" type of SLTs (e.g., \"permuted MNIST\") should be used with caution when testing for CF.\u2022 We do not propose a method for avoiding CF in this article. This is because avoiding CF requires a consensus on how to actually measure this effect: our novel contribution is a proposal how to do just that. The primary conclusion from the results in Sec. 4 is that CF still represents a major problem when training DNNs. This is particularly true if DNN training happens under application constraints as outlined in Sec. 1.2. Some of these constraints may be relaxed depending on the concrete application: if some prior knowledge about future sub-task exists, it can be used to simplify model selection and improve results. If sufficient resources are available, a subset of previously seen data may be kept in memory and thus allow a \"best\" type evaluation/stopping criterion for re-training, see Alg. 1.Our evaluation approach is similar to , and we adopt some measures for CF proposed there. A difference is the setting of up to 10 sub-tasks, whereas we consider only two of them since we focus less on the degree but mainly on presence or absence of CF. Although comparable both in the number of tested models and benchmarks, BID23 uses a different evaluation methodology imposing softer constraints than ours, which is strongly focused on application scenarios. This is, to our mind, the reason why those results differ significantly from ours and underscores the need for a consensus of how to measure CF.In general application scenarios without prior knowledge or extra resources, however, an essential conclusion we draw from Sec. 4 is that model selection must form an integral part of training a DNN on SLTs. Thus, a wrong choice of hyper-parameters based on D 1 can be disastrous for the remaining sub-tasks, which is why application scenarios require DNN variants that do not have extreme dependencies on hyper-parameters such as layer number and layer sizes.Lastly, our findings indicate workarounds that would make EWC or IMM practicable in at least some application scenarios. If model selection is addressed, a small subset of D 1 may be kept in memory for both methods: to determine optimal values of \u03b1 for IMM and to determine when to stop re-training for EWC. FIG7 shows that small changes to \u03b1 do not dramatically impact final accuracy for IMM, and FIG4 indicates that accuracy loss as a function of re-training time is gradual in most cases for EWC. The inaccuracies introduced by using only a subset of D 1 would therefore not be very large for both algorithms.To conclude, this study shows that the consideration of applied scenarios significantly changes the procedures to determine CF behavior, as well as the conclusions as to its presence in latestgeneration DNN models. We propose and implement such a procedure, and as a consequence claim that CF is still very much of a problem for DNNs. More research, either on generic solutions, or on workarounds for specific situations, needs to be conducted before the CF problem can be said to be solved. A minor but important conclusion is that results obtained on permutation-type SLTs should be treated with caution in future studies on CF."
}