{
    "title": "HJerDj05tQ",
    "content": "Optimization on manifold has been widely used in machine learning, to handle optimization problems with constraint. Most previous works focus on the case with a single manifold. However, in practice it is quite common that the optimization problem involves more than one constraints, (each constraint corresponding to one manifold). It is not clear in general how to optimize on multiple manifolds effectively and provably especially when the intersection of multiple manifolds is not a manifold or cannot be easily calculated. We propose a unified algorithm framework to handle the optimization on multiple manifolds. Specifically,  we integrate information from multiple manifolds and move along an ensemble direction by viewing the information from each manifold as a drift and adding them together. We prove the convergence properties of the proposed algorithms. We also apply the algorithms into  training neural network with batch normalization layers and achieve preferable empirical results. Machine learning problem is often formulated as optimization problem. It is common that the optimization problem comes with multiple constraints due to practical scenarios or human prior knowledge that adding some of them help model achieve a better result. One way to handle these constraints is adding regularization terms to the objective, such as the 1 and 2 regularization. However, it is hard to adjust the hyper-parameters of the regularization terms to guarantee that the original constraints get satisfied.Another way to deal with the constraints is to optimize on manifolds determined by the constraints. Then the optimization problem becomes unconstrained on the manifold, which could be easy to solve technically. Furthermore, optimization on manifold indicates optimizing on a more compact space, and may bring performance gain when training neural networks, e.g., BID10 BID3 .Most previous works on manifold optimization focus on a single manifold BID13 . However , in practice, we often face more than one constraints, each of them corresponding to one manifold. If we still solve the optimization problem with multiple constraints by method on manifold, we need to handle it on the intersection of multiple manifolds, which may no longer be a manifold BID11 . Due to this, traditional optimization methods on manifold does not work in this case.In this paper, we consider the problem of optimization on multiple manifolds. Specifically , the problem is written as arg min DISPLAYFORM0 where each M i is a manifold. We propose a method solving this problem by choosing the moving direction as \u2212\u2207f (x)(on manifold is \u2212gradf (x)) with several drifts which are derived from the descent information on other manifolds. By this method , we get sequence that has information from all manifolds. In this paper, we derive an intuitively method to approach optimization problem with multiple constraints which corresponds to optimizing on the intersection of multiple manifolds. Specifically, the method is integrating information among all manifolds to determine minimum points on each manifold. We don't add extra conditions to constraints of optimization problem, as long as each constraint can be converted to a manifold. In the future, we may add some conditions to manifolds which derive a conclusion that minimum points on each manifold achieved by our algorithm are close with other. If this conclusion is established, the problem of optimization on intersection of multiple manifolds is solved.According to the updating rule (equation 3), we can derive many other algorithms, because the drift h k in (equation 3) is flexible. On the other hand, Retr x on our algorithm does not limit to a specific one. Since there are some results for Retr x = Exp x , for example Corollary 8 in , we may get more elegant results by using Exp x as retraction function in our algorithm.The manifolds we encounter in optimization are mainly embedded sub-manifold and quotient manifold BID1 . Embedded sub-manifold is F \u22121 (y) for a smooth function F : M 1 \u2192 M 2 , where M 1 , M 2 are two manifolds and y \u2208 M 2 . Quotient manifold is a quotient topology space generalized by a specific equivalence relationship \u223c. In this paper, we use Oblique manifold and Grassmann manifold which are embedded sub-manifold and quotient manifold respectively.The difficulty we faced in optimization on manifold is calculating tangent space T x M and Riemannian gradient gradf (x). Giving a exact formula of a tangent space T x M is not a easy problem. On the other hand, since Riemannian gradient is \u2207f (x) projected to a tangent space T x M, finding projection matrix to a specific space T x M is nontrivial."
}