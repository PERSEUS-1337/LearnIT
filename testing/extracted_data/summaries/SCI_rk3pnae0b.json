{
    "title": "rk3pnae0b",
    "content": "Asking questions is an important ability for a chatbot. This paper focuses on question generation. Although there are existing works on question generation based on a piece of descriptive text, it remains to be a very challenging problem. In the paper, we propose a new question generation problem, which also requires the input of a target topic in addition to a piece of descriptive text. The key reason for proposing the new problem is that in practical applications, we found that useful questions need to be targeted toward some relevant topics. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. To solve the problem, we propose a novel neural network that is able to generate topic-specific questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating topics in the questions or answers. Experimental results show that our model outperforms the state-of-the-art baseline. The goal of question generation is to generate questions according to some given information (e.g., a sentence or a paragraph). It has been applied in many scenarios, e.g., generating questions for reading comprehension BID8 and generating data for large scale question-answering training (Serban et al., 2016; BID7 . Since questioning is an important communication skill, question generation plays an important role in both general-purpose chatbot systems and goal-oriented dialogue systems. In the context of dialogue, many researchers have studied the problem BID15 BID1 . The generated questions are mainly used to start a conversation or to obtain some specific information.Earlier approaches to question generation mainly used human-crafted rules and patterns to transform a descriptive sentence to a related question BID14 BID2 . However, human-crafted rules are limited. They cannot effectively cover a large number of question generation scenarios. Deep neural networks learned by end-to-end methods can help overcome this problem. This approach has been successfully applied to many NLP tasks, e.g., neural machine translation BID0 BID19 , summarization BID9 , etc. At the same time, some training optimization studies have further guaranteed the performance and stability of end-to-end networks BID13 BID4 . For question generation, Serban et al. (2016) applied a neural network to the knowledge base Freebase to transduce facts to questions. introduced an attention-based sequence learning model, which outperformed state-of-the-art rule-based systems. Two approaches were proposed by BID7 . One is retrieval-based, and the other is generation-based. also studied question-worthy sentences in reading comprehension.Much of the existing question generation studies mainly focused on the task of generating questions from sentences, paragraph, or structured data only. In this paper, we argue that topic-based question generation is also very important. That is, in addition to the given sentence or paragraph, it is also useful to specify a relevant topic contained in the text. The main reason is that a sentence or paragraph often involves multiple topics or concepts that questions can be generated, only arbitrarily choose one or mixing them may be of limited use because we found that in practical applications, questions need to be targeted toward some topics related to the current conversation. One almost never asks a random question in a conversation. Generating a question without knowing what it is about is not very useful. To solve the proposed problem, we propose a novel neural network that can generate topic-based questions. One major advantage of our model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating the topics in the questions or answers. In summary, this paper makes the following contributions:\u2022 It proposes the new problem of question generation based on a given sentence and a topic (or concept) in the sentence. To our knowledge, this topic-based question generation has not been studied before. The model can also take a question type because for the same topic, different types of questions can be asked (see section 5.3).\u2022 It proposes a novel neural network model to solve the problem. A pre-decode mechanism is also explored to improve the model performance.\u2022 The proposed model can be directly trained using a normal question-answering corpus without requiring additional labeling of topics in each input sentence.\u2022 The proposed model is evaluated using the Amazon community question-answering corpus. Experimental results show that our model is effective. In this paper, we proposed the new task of topic-based question generation, which has not been investigated before. Based on our experiences, we believe this is a more useful question generation setting than the conventional setting without a given topic because a question without the knowledge of its topic is of limited use in actual conversations. We then proposed a novel network architecture to perform the task, and discussed its generalization ability. Experimental results showed that the proposed model performed slightly better than the state-of-the-art baseline in the conventional setting (although our model not designed for this setting), and performed markedly better in the proposed new setting."
}