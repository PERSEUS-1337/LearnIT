{
    "title": "H1BHbmWCZ",
    "content": "n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules. Can a robot learn from its environment? Can a robot learn to appreciate multiplicty, i.e. the concept of plurality of instances of objects? Can a robot have attention mechanisms that allow it to focus on a particular object in its visual field? Can a robot somewhat understand and communicate the concept of an object's location natively?We attempt to address those questions, particularly as pertains to a child robot that is open-ended and designed without a strict purpose. Our investigations stem from the motivation of creating autonomous child robots that learn in-the-wild, on-the-fly. We are not attempting to design elaborate or tailored algorithms to solve a particular problem. Instead , we attempt to tackle these difficult challenges with the simplest of solutions.Hand-engineering solutions can be, while necessary in some cases, a limiting factor in deriving solutions for autonomous development. As such , we want to equip our open-ended child robots with the capabilities to learn. We thus present some weakly-supervised and semi-supervised models, in attempt to share the insights we generated by runnning these experiments. In this section we present the results of applying our models to different in-house compiled datasets. We use our own datasets due to the limited computation resources available to us, in addition to the desire of fast prototyping.Furthermore, the use of non-standard datasets is permissible since we are not claiming to advance the state-of-the-art on any of the current Computer Vision fronts. We are only presenting alternative approaches that yield some promise, along with the sharing our insights. In the previous section we presented the different results we attained for our three experiments. We learned many insights which we would like to summarize below.First, the problem of object detection can be reformed into a regression problem. We first unsuccessfully tried to regress directly on bounding boxes. By using Soft Attention instead we were able to isolate some objects from the background. The approach needs a closer investigation to understand the dynamics involved in the process of selection and isolation of objects.We recognize the current limitation that the network was able to isolate only one object. We perceive this can be tackled by 'subtracting' detected objects from the original image and reiterating over the image.Second, the Object Location network has trained well, achieving a high validation accuracy in its classification task. It tells us that CNNs can indeed be used to provide qualitative labels for an object's location. We recognize the limitation of only using images with a single object against a plain background, as the real-world environment is cluttered. We perceive this can be tackled by creating more specialized CNNs for feature extraction that would be immune to noisy backgrounds.Third, we found that CNNs such as ResNet50 do indeed perceive and encode object plurality. We found that this information can be recovered as we demonstrated in FIG5 . To this end, it is thus plausible to further investigate why it was difficult for us to reframe counting objects as a classification problem.To conclude, we presented three thrusts in weakly and semi-supervised computer vision. The purpose of our experiments was to demonstrate the plausibility of tackling these problems in the way we do.Our work is not concerned with state-of-the-art accuracy orperformance. An open-ended child robot does not strictly need such capacities. What we are concerned with, however, is the potential for self-improvement under weakly or unsupervised conditions. For example, by reframing detecting an object's qualitative location into a classification problem, we can acquire a label from a human teacher in natural language, and use it to correct the robot's asseessment of the location of an object in its field of view. In such a way, we believe robots can scale their learnings and improve by consolidating knowledge over time."
}