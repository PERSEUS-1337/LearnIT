{
    "title": "B1eWu0NtDS",
    "content": "Convolutional neural networks (CNNs) in recent years have made a dramatic impact in science, technology and industry, yet the theoretical mechanism of CNN architecture design remains surprisingly vague. The CNN neurons, including its distinctive element, convolutional filters, are known to be learnable features, yet their individual role in producing the output is rather unclear. The thesis of this work is that not all neurons are equally important and some of them contain more useful information to perform a given task. Hence, we propose to quantify and rank neuron importance, and directly incorporate neuron importance in the objective function under two formulations: (1) a game theoretical approach based on Shapley value which computes the marginal contribution of each filter; and (2) a probabilistic approach based on what-we-call, the importance switch using variational inference. Using these two methods we confirm the general theory that some of the neurons are inherently more important than the others. Various experiments illustrate that learned ranks can be readily useable for structured network compression and interpretability of learned features. Neural networks have achieved state-of-the art results in various cognition tasks, including image and speech recognition, machine translation, reinforcement learning (Fergus et al., 2003; Mnih et al., 2013; Gu et al., 2018) . Many of these applications involved CNNs which excel in particular in the vision tasks due to its ability to capture visual by means of convolution filters. Although the effectiveness of convolutional networks is unquestionable, the details of the architecture design and what particularly makes neural network work in detail remain highly uncertain. The experimental results roughly confirm that the accuracy of the network and representational capacity is correlated with the depth of the network He et al., 2016; Montufar et al., 2014) . Interestingly, the deeper architecture also become wider, although the link between width and network expressivity is questionable (Poole et al., 2016) and the choice of the number of neurons is rather discretionary. As a result the discussion about the network architecture often revolves around the numbers of filters and layers and their relative positioning, putting aside the conversation about the quality of the information that it contains. The increasing size of the network architectures have faced scrutiny that made claims that the networks are overparametrized raising two main concerns: heavy computational load and potential overfitting . In response to the need to build networks that are smaller yet accurate, a stream of research attempted to remove redundant units, compress the networks and design lighter architectures (Iandola et al., 2016; . A widespread approach to network reduction has been removing weights that are small or even close to zero (Han et al., 2015) . This line of research implicitly discerns that nodes with larger weights are more significant for learning task than the small weights. As a result, broadly speaking, this approach divides features between those that are useful which are kept and those which are insignificant and therefore discarded, forming a sort of binary approach. In this work, we would like to scrutinize the individual filters and form an explicit theory that states that the units in the network (both convolutional filters and nodes in fully connected layers) are not equally important when it comes to performing an inference task. The corollary of this thesis is that CNNs learn features in a discriminative way so that some of them carry more significance than others, and the knowledge about the input is not uniformly distributed among the CNN features. This theory is in line of research that adding more filters does not make the network more expressive since learning relevant information to the network has already been addressed by other filters. Given the proposed theory, we would like to make a step forward in gaining insight what the CNN learns and propose to extend the binary approach to form a quantifiable ranking of features. In other words, we attempt to estimate the importance of each feature compared to the others with particular focus on convolutional filters, which may be visualized. We introduce a theoretical framework to quantify how important each feature is through proposing a feature ranking method based on two different approaches. The first approach derives from the game theoretical concept of Shapley value (Shapley, 1953) , which assesses the importance of an individual in a group of neurons based on its marginal contribution to the group. The second method takes a probabilistic approach and introduces additional learnable parameters, which we call importance switches, that take real values and are trained by means of variational inference to give more weight to the important features. The extensive experimental results using these approaches indicate that some features are inherently more significant than others. The theoretical underpinnings of the feature rankings have further direct practical implications we explore. Firstly, the knowledge of the ranking allows to know which features directly impact the score of our method and consequently a more informed way of building an effective model. Thus, we are able to build a network around the the relevant features and discard the less relevant ones, effectively compressing the network achieving state-of-the-art results. Secondly and perhaps more significantly, the feature ranking of convolutional features provides more interpretable information about the network and places meaning on particular features in the context of a given task, thus casting light on the black box models. To achieve human interpretability, we visualize the most significant features which significantly show the significance of repeated and complementary features. In summary, this work suggests a theory that the learnable CNN features contain inherent hierarchy where some of the features are more significant than others. This multidisciplinary work which builds on top of probability and game theoretical concepts proposes two methods to produce feature ranking and select most important features in the CNN network. The striking observation is that the different methods lead to similar results and allow to distinguish important nodes with larger confidence. The ranking methods allow to build an informed way to build a slim network architecture where the significant nodes remain and unimportant nodes are discarded. A future search for further methods which allow to quantify the neuron importance is the next step to develop the understanding of the feature importance in CNNs."
}