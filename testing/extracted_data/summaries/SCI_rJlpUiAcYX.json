{
    "title": "rJlpUiAcYX",
    "content": "We introduce an analytic distance function for moderately sized point sets of known cardinality that is shown to have very desirable properties, both as a loss function as well as a regularizer for machine learning applications. We compare our novel construction to other point set distance functions and show proof of concept experiments for training neural networks end-to-end on point set prediction tasks such as object detection. Parametric machine learning models, like artificial neural networks, are routinely trained by empirical risk minimization. If we aim to predict an output y \u2208 Y from an input x \u2208 X , we collect a training set D of (x, y) pairs and train a parametrized prediction function h \u03b8 : X \u2192 Y by minimizing DISPLAYFORM0 Here, L : Y \u00d7 Y \u2192 R is a loss function that assigns a scalar loss value to the prediction\u0177 = h \u03b8 (x) for the true value y. Classical machine learning problems allow for standard choices for the loss function. E.g., for regression problems, where y,\u0177 \u2208 R, it is common to use the squared loss L(\u0177, y) = (\u0177 \u2212 y) 2 .Assume , however, that we want to train a machine learning system which-given some inputpredicts a set of points. In particular , the ordering of the points is neither semantically meaningful nor in any way consistent across data instances. As an example , one may consider an object detection task such as finding the positions of the black stones on an image of a real-world game of Nine Men's Morris. What should the loss function be in such a case?Naively, we might just impose an arbitrary ordering to the sets and treat them as ordered tuples. However, this conceals an important property of the task, the permutation invariance, from our machine learning system. This property might in fact be crucial to learn such a task efficiently. Instead, we would like our loss function to define a meaningful distance between two sets, which requires such a loss to be permutation-invariant. We discussed a novel point set loss function, which is analytic everywhere, vis-a-vis two other simple alternatives with matching computational complexity for point set prediction tasks as alternatives to more involved approaches BID3 BID2 . Proof of concept experiments showed that end-to-end training with such simple loss functions is a viable approach for point set prediction tasks, such as object detection. We expect that simple constructions such as the \"holographic\" point set distance introduced here may turn out useful not only for point set predictions, but also as a regularizer, for example to encourage (unsupervised) clustering to align its clusters with the clusters found by an earlier version of the model. We will need the following Lemma, which states that the roots of a complex polynomial continuously depend on its coefficients. DISPLAYFORM0 k=0 c k u k be a monic complex polynomial and factor it as F (u) = (u \u2212 a 1 )(u \u2212 a 2 ) \u00b7 \u00b7 \u00b7 (u \u2212 a N ) with a k \u2208 C some ordering of the roots. Then, for every \u03b5 > 0 there exists \u03b4 > 0 such that every polynomial DISPLAYFORM1 Proof. This is a reformulation of the well-known continuity result, a proof of which can be found, for example, in\u0106urgus & Mascioni (2006) . One notes that, to first order in a small shift in the coefficients of a polynomial, the shift of the zeros can be found by a single step of Newton-Raphson iteration, except at higher-degree zeros (where the derivative of the polynomial in the denominator also has a zero).We can now prove the Proposition. DISPLAYFORM2 We already observed that L(\u1e90, Z) 2 = 0 if and only if\u1e90 = \u03c3(Z) for some \u03c3 \u2208 S N . Now assume L(\u1e90 , Z) 2 = 0. To see that\u1e90 can not be a local minimum, we need to show that for any \u03b5 > 0 there DISPLAYFORM3 To construct such a Z , we define the polynomial Q \u03bb : C \u2192 C, DISPLAYFORM4 which linearly interpolates between P\u1e90 and P Z . Note that Q \u03bb is monic for \u03bb \u2208 [0, 1] and Q 0 = P\u1e90. Let Z \u03bb be some ordering of the roots of Q \u03bb . Then DISPLAYFORM5 Since we assumed L(\u1e90, Z) > 0, this means that L(Z \u03bb , Z) < L(\u1e90, Z) for any \u03bb > 0. It remains to show that for any \u03b5 > 0 there is \u03bb \u03b5 > 0 and a permutation \u03c3 such that d(\u1e90, \u03c3(Z \u03bb\u03b5 )) < \u03b5. However, since the coefficients of Q \u03bb continuously depend on \u03bb, this follows as a simple consequence of Lemma 1."
}