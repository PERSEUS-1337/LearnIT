{
    "title": "HkxStoC5F7",
    "content": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n 1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n 2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n 3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task. Many applications require predictions to be made on myriad small, but related datasets. In such cases, it is natural to desire learners that can rapidly adapt to new datasets at test time. These applications have given rise to vast interest in few-shot learning BID9 BID32 , which emphasizes data efficiency via information sharing across related tasks. Despite recent advances, notably in meta-learning based approaches BID44 BID54 BID8 BID10 , there remains a lack of general purpose methods for flexible, data-efficient learning.Due to the ubiquity of recent work, a unifying view is needed to understand and improve these methods. Existing frameworks BID16 are limited to specific families of approaches. In this paper we develop a framework for meta-learning approximate probabilistic inference for prediction (ML-PIP), providing this view in terms of amortizing posterior predictive distributions. In Section 4, we show that ML-PIP re-frames and extends existing point-estimate probabilistic interpretations of meta-learning BID16 to cover a broader class of methods, including gradient based meta-learning BID10 BID44 , metric based meta-learning BID48 , amortized MAP inference BID43 and conditional probability modelling BID13 .The framework incorporates three key elements. First , we leverage shared statistical structure between tasks via hierarchical probabilistic models developed for multi-task and transfer learning BID18 BID0 . Second , we share information between tasks about how to learn and perform inference using meta-learning BID37 BID50 BID47 . Since uncertainty is rife in small datasets, we provide a procedure for metalearning probabilistic inference. Third , we enable fast learning that can flexibly handle a wide range of tasks and learning settings via amortization .Building on the framework, we propose a new method -VERSA -which substitutes optimization procedures at test time with forward passes through inference networks. This amortizes the cost of inference, resulting in faster test-time performance, and relieves the need for second derivatives during training. VERSA employs a flexible amortization network that takes few-shot learning datasets, and outputs a distribution over task-specific parameters in a single forward pass. The network can handle arbitrary numbers of shots, and for classification, arbitrary numbers of classes at train and test time (see Section 3). In Section 5, we evaluate VERSA on (i) standard benchmarks where the method sets new state-of-the-art results, (ii) settings where test conditions (shot and way) differ from training, and (iii) a challenging one-shot view reconstruction task. We have introduced ML-PIP, a probabilistic framework for meta-learning. ML-PIP unifies a broad class of recently proposed meta-learning methods, and suggests alternative approaches. Building on ML-PIP, we developed VERSA, a few-shot learning algorithm that avoids the use of gradient based optimization at test time by amortizing posterior inference of task-specific parameters. We evaluated VERSA on several few-shot learning tasks and demonstrated state-of-the-art performance and compelling visual results on a challenging 1-shot view reconstruction task. a We report the performance of Prototypical Networks when training and testing with the same \"shot\" and \"way\", which is consistent with the experimental protocol of the other methods listed. We note that Prototypical Networks perform better when trained on higher \"way\" than that of testing. In particular, when trained on 20-way classification and tested on 5-way, the model achieves 68.20 \u00b1 0.66%."
}