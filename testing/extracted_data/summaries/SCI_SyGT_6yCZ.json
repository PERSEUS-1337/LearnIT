{
    "title": "SyGT_6yCZ",
    "content": "The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches. The design of high-quality image features is essential to vision recognition related tasks. They are needed to provide high accuracy and scalability on processing large image data. Many approaches to building visual features have been proposed such as dictionary learning that aims to find a sparse representation of the data in the form of a linear combination of fundamental elements called atoms BID5 . Scattering approaches provide mathematical frameworks to build geometric image priors BID11 . Unsupervised bag of words methods identifies object categories using a corpus of unlabeled images BID15 . Unsupervised deep learning techniques are also used to extract features by using neural networks based models with many layers and frequently trained using contrastive divergence algorithms BID6 . All of them have been shown to improve the results of hand-crafted designed feature vectors such as SIFT BID10 or HOG BID1 with promising results BID0 BID11 .Another recent but very successful alternative is to use supervised Convolutional Neural Networks (CNN) to extract high-quality image features BID12 . These models take into consideration that images are symmetrical by a shift in position and therefore weight sharing and selective fields techniques are used to create filter banks that extract geometrically related features from the image dataset. The process is composed hierarchically over many layers to obtain higher level features after each layer. The network is typically trained using gradient backpropagation techniques. After the CNN training, the last layer (usually a fully connected layer) is removed to provide the learned features.A drawback of this approach is the time needed to thoroughly train a CNN to obtain high accuracy results. In this paper , we propose the Simple Fast Convolutional (SFC) feature learning technique to significantly reduce the time required to learning supervised convolutional features without losing much of the representation performance presented by such solutions. To accelerate the training time, we consider few training epochs combined with fast learning decay rate.To evaluate the proposed approach we combined SFC and alternative features methods with classical classifiers such as Support Vector Machines (SVM) BID18 and Extreme Learning Machines (ELM) . The results show that SFC provides better performance than alternative approaches while significantly reduces the training time. We evaluated the alternative feature methods over the MNIST (Lecun & Cortes) , CIFAR-10 and CIFAR-100 BID4 ). In this paper, we showed that convolutional feature learning can be performed in a fast way. Moreover, despite being very fast, it is still capable of generating representations that present better performance than other approaches. The proposed method is also flexible enough since a compromise can be obtained between the speed of the training and the final solution test accuracy. Naturally, the difference in test accuracy presented in this paper could be even greater if more training time is allowed to be used.We emphasize that transfer learning techniques can be used to extend the application of the proposed method. Finally, we show that despite efforts to the contrary, supervised convolutional method still provides state-of-the-art results for image feature generation. Moreover, the experiments showed that a quick change in the learning rate decay is a valid method to speed up the training of deep neural networks significantly."
}