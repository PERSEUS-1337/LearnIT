{
    "title": "Q7Cy_qHg6Y",
    "content": "We propose an approach to construct realistic 3D facial morphable models (3DMM) that allows an intuitive facial attribute\n editing workflow. Current face modeling methods using 3DMM suffer from the lack of local control. We thus create a 3DMM by\n combining local part-based 3DMM for the eyes, nose, mouth, ears, and facial mask regions. Our local PCA-based approach\n uses a novel method to select the best eigenvectors from the local 3DMM to ensure that the combined 3DMM is expressive\n while allowing accurate reconstruction. The editing controls we provide to the user are intuitive as they are extracted from\n anthropometric measurements found in the literature. Out of a large set of possible anthropometric measurements, we filter the\n ones that have meaningful generative power given the face data set. We bind the measurements to the part-based 3DMM through\n mapping matrices derived from our data set of facial scans. Our part-based 3DMM is compact yet accurate, and compared to\n other 3DMM methods, it provides a new trade-off between local and global control. We tested our approach on a data set of 135\n scans used to derive the 3DMM, plus 19 scans that served for validation. The results show that our part-based 3DMM approach\n has excellent generative properties and allows intuitive local control to the user.\n\n Authoring realistic 3D faces with intuitive controls is used in a broad range of computer graphics applications such as video games, person identification, facial plastic surgery, and virtual reality. This process is particularly time-consuming given the intricate details found in the eyes, nose, mouth, and ears. Consequently, it would be convenient to use high-level controls, such as anthropometric measurements, to edit human-like character heads. Many methods use 3D morphable face models (3DMM) for animation (blend shapes), face capture, and face editing. Even though face animation concerns are important, our work focuses on the editing of facial meshes. 3DMMs are typically constructed by computing a Principal Component Analysis (PCA) on a data set of scans sharing the same mesh topology. New 3D faces are generated by changing the relative weights of the individual eigenvectors. These methods are popular due to the simplicity and efficiency of the ap-proach, but suffer from two fundamental limitations: they impose global control to the new generated meshes, making it impossible to edit a localized region of the face, and they control mechanism is very unintuitive. Some methods compute localized 3DMM, but they focus on facial animation instead of face modeling. Furthermore, we compared our approach with such methods and saw that their automatic localized basis construction works well for animation purposes (considering a data set composed of animations for a single person), but perform worst than our approach for modeling purposes (considering a data set made of neutral faces from different persons). We propose an approach to constructs realistic 3DMMs. We increase the controllability of our faces by segmenting them into independent subregions and selecting the most dominant eigenvectors per part. Furthermore, we rely on facial anthropometric measurements to derive useful controls to use our 3DMM for editing faces. We propose a measurement selection technique to bind the essential measurements to the 3DMM eigenvectors. Our method allows the user to edit faces by adjusting the facial parts using sliders controlling the values of anthropometric measurements. The measurements are mapped to eigenvector weights, allowing us to compute the individual parts matching the values selected by the user. Finally, the reconstructed parts are seamlessly blended together to generate the desired 3D face. We present experimental evidence to demonstrate how these tailored 3DMMs are preferred over the global PCA models. In this section we discuss different aspects of our approach. We present different comparisons highlighting the impact of the eigenvector and measurement selection. We then discuss the choice of face segmentation, and we end by describing the procedure used to bring all of our scans to a common face mesh. In this paper, we designed a new local 3DMM used for face editing. We demonstrated the difficulty to locally edit the faces with global 3DMMs; we thus segmented the face in five parts and combined the 3DMMs for each part into a single 3DMM by selecting the best eigenvectors through prediction error measurements. We then proposed the use of established anthropometric measurements as a basis for the face editing. We mapped the anthropometric measurements to the 3DMM through a mapping matrix. We proposed a process to select the best set of anthropometric measurements, leading to an improve reconstruction accuracy and the removal of conflicting measurements. From the list of 33 anthropometric measurements that we surveyed from the literature, we identified 31 which lead to an improvement of the reconstruction and we rejected 2 as they decreased the quality of the reconstruction. Note that the anthropometric measurement selection process would apply as well even if using a different 3DMM than the one proposed in this paper, as well as if considering a different set of anthropometric measurements. We demonstrated this by applying our set of measurement to both SPLOCS [NVW*13] and clustered PCA [TDM11] . This also demonstrated that our approach produces results superior to those of established methods proposing automatic segmentation and different ways to construct the eigenvector basis. We also presented different experimental evidence to show the superiority of our approach, especially in terms of local control, compared to the typical global 3DMM. A limitation of our approach is the mapping matrices assuming a linear relationship between anthropometric measurements and the eigenvector weights. An interesting avenue for future work would be to apply machine learning to identify non-linear mappings. Our set of anthropometric measurements contains too few measures for the ears due to the scarcity of measurements within the ear compared to the nose. It would be interesting to identify more anthropometric measurements for ears, as well as, considering the measurements that specify the distribution of curvature over the face, such as the measurement specifying the angle formed at the tip of the chin. Another limitation comes from the blending of the different parts that. Compared to global 3DMMs, our fixed boundary does not allow as much deformation for the shape of the head. An additional avenue for future work would be to reconstruct a skull based on the anthropometric measurements, and then generate the facial mask based on an energy minimization of the skin thickness considering the skull and the measurements. Another avenue for future research is to create textures that would plausibly have the facial structure of generated 3DMMs. Using a Generative Adversarial Network that gets the 3DMM as well as some details such as anthropometric measurements to create a texture that fit to the generated face."
}