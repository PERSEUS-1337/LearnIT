{
    "title": "S1gvPPMVv4",
    "content": "Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets. Despite breakthroughs in supervised deep learning across a variety of challenging tasks, current techniques depend precariously on the i.i.d. assumption. Unfortunately, real-world settings often demand not just generalization to unseen examples but robustness under a variety of shocks to the data distribution. Ideally, our models would leverage unlabeled test data, adapting in real time to produce improved predictions. Unsupervised domain adaptation formalizes this problem as learning a classifier from labeled source domain data and unlabeled data from a target domain, to maximize performance on the target distribution.Without further assumptions, guarantees of target-domain accuracy are impossible BID3 . However, well-chosen assumptions can make possible algorithms with non-vacuous performance guarantees. For example, under the covariate shift assumption BID7 BID11 , although the input marginals can vary between source and target (p S (x) = p T (x)), the conditional distribution of the labels (given features) exhibits invariance across domains (p S (y|x) = p T (y|x)). Traditional approaches to the covariate shift problem require the source distributions' support to cover the target support, estimating adapted classifiers via importanceweighted risk minimization BID11 BID8 BID6 BID13 BID9 .Problematically , assumptions of contained support are violated in practice. A recent sequence of deep learning papers have proposed empirically-justified adversarial training schemes aimed at practical problems with non-overlapping supports BID5 BID12 . Example problems include generalizing from gray-scale images to colored images or product images on white backgrounds to photos of products in natural settings. While importance-weighting solutions are useless here (with non-overlapping support, weights are unbounded), domain-adversarial networks BID5 and subsequently-proposed variants report strong empirical results on a variety of image recognition challenges. The key idea of domain-adversarial networks is to simultaneously minimize the source error and align the two distributions in representation space. The scheme consists of an encoder, a label classifier, and a domain classifier. During training, the domain classifier is optimized to predict each image's domain given its encoding. The label classifier is optimized to predict labels from encodings (for source images). The encoder weights are optimized for the twin objectives of accurate label classification (of source data) and fooling the domain classifier (for all data).Although BID5 motivate their idea via theoretical results due to BID2 , the theory is insufficient to justify their method. Put simply, BID2 bound the test error by a sum of three terms. The domain-adversarial objective minimizes two among these, but this minimization may cause the third term to increase. This is guaranteed to happen when the label distribution shifts between source and target ( FIG0 ).In this paper, we propose asymmetrically-relaxed distribution alignment, a relaxed distance for aligning data across domains that can be minimized without requiring latent-space distributions to match exactly. The new distance is minimized whenever the density ratios in representation space from target to source are upper bounded by a certain constant, such that the target representation support is contained in the source representation's. The relaxed distribution alignment need not lead to a poor classifier on the target domain under label distribution mismatch FIG0 ). We demonstrate theoretically that the relaxed alignment is sufficient for a good target domain performance under a concrete set of assumptions on the data distributions. Further, we propose several practical ways to achieve the relaxed distribution alignment, translating the new distance into adversarial learning objectives. Empirical results on synthetic and real datasets show that incorporating our relaxed distribution alignment loss into adversarial domain adaptation gives better classification performance on the target domain. Due to space constraints, we only briefly state our results in the main text and append the full version of our paper after references."
}