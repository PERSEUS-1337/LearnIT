{
    "title": "BygbVL8KO4",
    "content": "Recently, Generative Adversarial Networks (GANs) have emerged as a popular alternative for modeling complex high dimensional distributions. Most of the existing works implicitly assume that the clean samples from the target distribution are easily available. However, in many applications, this assumption is violated. In this paper, we consider the observation setting in which the samples from a target distribution are given by the superposition of two structured components, and leverage GANs for learning of the structure of the components. We propose a novel framework, demixing-GAN, which learns the distribution of two components at the same time. Through extensive numerical experiments, we demonstrate that the proposed framework can generate clean samples from unknown distributions, which further can be used in demixing of the unseen test images. In this paper, we consider the classical problem of separating two structured signals observed under the following superposition model: DISPLAYFORM0 where X \u2208 X and N \u2208 N are the constituent signals/components, and X , N \u2286 R p denote the two structured sets. In general the separation problem is inherently ill-posed; however, with enough structural assumption on X and N , it has been established that separation is possible. Depending on the application one might be interested in estimating only X (in this case, N is considered as the corruption), which is referred to as denoising, or in recovering (estimating) both X and N which is referred to as demixing. Both denoising and demixing arise in a variety of important practical applications in the areas of signal/image processing, computer vision, machine learning, and statistics BID7 BID11 BID3 BID6 . Most of the existing demixing techniques assume some prior knowledge on the structures of X and N in order to recover the desired component signals. Prior knowledge about the structure of X and N can only be obtained if one has access to the generative mechanism of the signals and clean samples from the probability distribution defined over sets X and N . In many practical settings, none of these may be feasible.In this paper, we consider the problem of separating constituent signals from superposed observations when we do not have access to the clean samples from any of the distributions (fully unsupervised approach). In particular, we are given a set of superposed observations DISPLAYFORM1 where X i \u2208 X and Y i \u2208 N are i.i.d samples from their respective (unknowns) distributions. In this setup, we explore two questions: First, How can one learn the prior knowledge about the individual components from superposition samples? ; hence, we concern with a learning problem. Second, Can we leverage the implicitly learned constituent distributions for tasks such as demixing of a test image? . As a result, in the latter question, we deal with a inference task. In this paper, we considered a GAN framework for learning the structure of the constituent components in a superposition observation model. We empirically showed that it is possible to implicitly learn the underlying distribution of each component and use them in the downstream task such as demixing of a test mixed image. We also investigated the conditions under which the proposed demixing framework fails through extensive experimental simulations and provided some theoretical insights."
}