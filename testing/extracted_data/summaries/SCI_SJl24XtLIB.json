{
    "title": "SJl24XtLIB",
    "content": "Computational neuroscience aims to fit reliable models of in vivo neural activity and interpret them as abstract computations. Recent work has shown that functional diversity of neurons may be limited to that of relatively few cell types; other work has shown that incorporating constraints into artificial neural networks (ANNs) can improve their ability to mimic neural data. Here we develop an algorithm that takes as input recordings of neural activity and returns clusters of neurons by cell type and models of neural activity constrained by these clusters. The resulting models are both more predictive and more interpretable, revealing the contributions of functional cell types to neural computation and ultimately informing the design of future ANNs. The primary goal in the field of computational neuroscience is to build mathematical models that link the in vivo activity of our brains with the intelligent behavior they produce. The primary obstacles to accomplishing this stem from the brain's complexity. The large number and variable characteristics of individual neurons in a given brain produce highly nonlinear and high dimensional activity. This makes theoretical analysis difficult and limits our observations of the brain to a subset of neurons, making computational models fitted to data less reliable. Luckily, applying biological constraints to our models may help us understand the brain. The ANN trained to perform spatial localization by Cueva [3] required a metabolic constraint on total neural activity to reproduce patterns of neural responses in the Entorhinal Cortex. The ANN trained by Yamins [9] to recognize objects required a convolutional structural constraint to reproduce activity of the visual system. These works have strengthened the connection between AI and neuroscience by showing how the same constraints produce similar activity and behavior. In this work, we seek to make this connection with a different constraint, cell diversity limited to small variations within relatively few cell types. The Allen Institute for Brain Science has pioneered projects for identifying such cell types by looking at transcriptomic, morphological, and electrophyisiological features of individual neurons [5] , [6] . This idea of discrete cell types is also in line with theoretical results analyzing how simple point models of neural activity undergo bifurcations in parameter space between a few qualitatively different behaviors (see [4] for bifurcation analysis of the Izhikevich model, and [8] for evidence that the GLM has similar stereotypical behaviors). We take a bottom-up approach of inferring functional cell types from neural activity data and using these types to constrain single-cell activity models. By using cell types as a constraint, we can fit more reliable models for individual neurons and ultimately uncover the roles of functionally distinct cell types in computations by real and artificial brains. In this work, we make particular choices for the mixture model (GMM), single-cell model (GLM), and which parameters are related to cell type (Self-interaction filters, W i ), but our algorithm generalizes to any choices for these. In future work, we will perform model selection over other options. Ultimately, we seek to apply this algorithm to in vivo neural recordings, so testing the algorithm's robustness to noise is also important. When we apply the algorithm to in vivo data, it may be necessary to use other constraints present in the brain, as well as any available metadata (cell morphology, gene expression, spiking waveform, etc.). is the empirical probability that a cell with attribute a is in cluster i, N is the number of cells, and N (a) is the number of cells with attribute a. Neural Network models with functional cell types that this algorithm produces can support the growing body of theoretical literature regarding such networks, biological and artificial (e.g. [2] ). In return, such theoretical techniques can provide a guide for understanding the functional cell type network models our algorithm produces in terms of more abstract network operations."
}