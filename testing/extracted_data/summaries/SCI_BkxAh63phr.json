{
    "title": "BkxAh63phr",
    "content": "Humans can learn a variety of concepts and skills incrementally over the course of their lives while exhibiting an array of desirable properties, such as non-forgetting, concept rehearsal, forward transfer and backward transfer of knowledge, few-shot learning, and selective forgetting. Previous approaches to lifelong machine learning can only demonstrate subsets of these properties, often by combining multiple complex mechanisms.   In this Perspective, we propose a powerful unified framework that can demonstrate all of the properties by utilizing a small number of weight consolidation parameters in deep neural networks. In addition, we are able to draw many parallels between the behaviours and mechanisms of our proposed framework and those surrounding human learning, such as memory loss or sleep deprivation. This Perspective serves as a conduit for two-way inspiration to further understand lifelong learning in machines and humans. Humans have a sustained ability to acquire knowledge and skills, refine them on the basis of novel experiences, and transfer them across domains over a lifespan [1] [2] [3] . It is no surprise that the learning abilities of humans have been inspiring machine learning approaches for decades. Further extending the influence of human learning on machine learning, continual or lifelong learning (LLL) in particular [4] , is the goal of this work. To mimic human continual concept learning scenarios, in this paper we propose a new learning setting in which one concept-learning task is presented at a time. Each classification task and its corresponding labeled data are presented one at a time in sequence. As an example, assume we are given the task sequence of learning to classify hand-written characters of \"1\", \"2\", \"3\", and so on, by providing training examples of \"1\", \"2\", \"3\" in sequence (such as those in Figure 1 ). When learning \"1\", only data of \"1\" is available. When learning of \"2\", data of \"2\" becomes available, and so on. Preprint. Under review. We assume that these concepts are mutually exclusive (i.e. any sample can be a positive sample for at most one task). We also assume a set of \"background negative\" examples are given -they are presumably the previously learned concepts. This setting is in stark contrast to the standard setup in multi-class machine learning, where it is assumed that all training data of all classes is readily available, as a \"batch\" mode. For the example task sequence in this section, we can consider the four classes to be \"1\", \"2\", \"3\", and \"I\". The negative samples used when learning to identify the three positive classes can come from a domain-appropriate non-overlapping \"background\" set (in this case, lower-case letters). After a model is trained up to class i, it will not have access to those training samples unless absolutely necessary (see later). The samples shown are from the EMNIST dataset [5] . Under this continual learning setting, we hope than a LLL approach would exhibit the following properties: Non-forgetting: This is the ability to avoid catastrophic forgetting [6] of old tasks upon learning new tasks. For example, when learning the second task \"2\", with only training data on \"2\" (and without using the data of the task 1), \"2\" should be learned without forgetting how to classify task 1 learned earlier. Due to the tendency towards catastrophic forgetting, non-lifelong learning approaches would require retraining on data for \"1\" and \"2\" together to avoid forgetting. A skill opposite to non-forgetting is selective forgetting. As we will describe further, learning new tasks may require expansion of the neural network, and when this is not possible, the model can perform selective forgetting to free up capacity for new tasks. Forward transfer: This is the ability to learn new tasks easier and better following earlier learned tasks. For example, after learning the task of classifying \"1\", it would be easier (requiring less training data for the same or higher predictive accuracy) to learn to classify \"I\". Achieving sufficient forward transfer opens the door to few-shot learning of later tasks. Non-confusion: Machine learning algorithms need to find discriminating features for classification only as robust as they need to be to minimize a loss, thus, when more tasks emerge for learning, earlier learned features may not be sufficient, leading to confusion between classes. For example, after learning \"1\" and \"2\" as the first two tasks, the learned model may say \"with only straight stroke\" is \"1\" and \"with curved stroke\" is \"2\". But when learning \"I\" as a later new task, the model may rely only on the presence of a straight stroke again, leading to confusion between \"1\" and \"I\" when the model is finally tested. To resolve such confusion between \"1\" and \"I\", samples of both \"1\" and \"I\" are needed to be seen together during training so that discriminating features may be found. In humans, this type of confusion may be seen when we start learning to recognize animals for example. To distinguish between common distinct animals such as birds and dogs, only features such as size or presence of wings is sufficient, ignoring finer features such as facial shape. However, when we next learn to identify cats, we must use the previous data on dogs and new data on cats to identify finer features (such as facial shape) to distinguish them. Backward transfer: This is knowledge transfer in the opposite direction as forward transfer. When new tasks are learned, they may, in turn, help to improve the performance of old tasks. This is analogous to an \"overall review\" before a final exam, after materials of all chapters have been taught and learned. Later materials can often help better understand earlier materials. Past works on LLL have only focused on subsets of the aforementioned properties. For example, an approach inspiring our own, Elastic Weight Consolidation (EWC) [7] , focuses only on non- forgetting. The approach of [8] considers non-forgetting as well as forward and backward transfer and confusion reduction, but does not allow for selective forgetting. Figure 2 illustrates the scope of our framework compared with related previous approaches. Section 4 contains a more detailed comparison. In this paper, we provide a general framework of LLL in deep neural networks where all of these these abilities can be demonstrated. Deep neural networks, which have become popular in recent years, are an attractive type of machine learning model due to their ability to automatically learn abstract features from data. Weights (strengths of links between neurons) of a network can be modified by the back propagation algorithms to minimize the total error of the desired output and the actual output in the output layer. In our study, we consider fully-connected neural networks with two hidden layers to illustrate our LLL approach. The basic idea of our unified framework, similar to EWC [7] , is to utilize \"stiffness\" parameters of weights during training phases to achieve the various LLL properties such as nonforgetting, forward transfer, etc. For each lifelong learning property, a subset of its weights may be \"frozen\", another subset of weights may be \"free\" to be changed, and yet another subset of weights may be \"easily changed\", depending on the type of lifelong learning properties we are aiming to facilitate at the time. EWC and its conceptual successors [11] [12] [13] are lifelong learning approaches which estimate the importance of each weight in a network for maintaining task performance. By preventing already important weights from changing to accommodate new tasks (i.e. consolidating weights), catastrophic forgetting can be reduced. Generally speaking, each network weight, \u03b8 i , is associated with a remembering, BWT+: positive backward transfer, FWT: forward transfer. We expect our approach to be outperform the related approaches of EWC [7] and PNN [10] on a majority of the metrics. consolidation value, b i , which can be set or tuned for each stage of learning as we will soon discuss. When training a model with EWC, we combine the original loss L t with weight consolidation as follows: Here, \u03b8 target i is the consolidation target value for a weight, \u03b8 t i is the weight value being updated during training on task t, and \u03bb is used to balance the importance of the two loss components. Clearly, a large b value indicates that changing the weight is strongly penalized during training, whereas a value of 0 indicates that the weight is free to change. In our approach, we use three values for b to control the flexibility of different sets of network weights: \u2022 b nf for non-forgetting (ideally a very large value), \u2022 b tr for forward transfer (ideally very small or zero), \u2022 and b f ree for freely tunable weights (ideally very small). While the individual weights of the network are learned via back-propagation, these consolidation hyperparameters are set by several heuristic strategies. We will illustrate how changing these hyperparameters to control the stiffness of weights in different parts of the deep neural networks, our approach can achieve all of the LLL abilities mentioned above (Section 2). As we mentioned, these hyperparameters are determined during LLL by heuristic strategies, but one might wonder if these heuristics can be learned. Our comparison between lifelong learning of machines and humans suggests that our model hyperparameters are probably intrinsic to the physiology of the brain -a product of natural evolution. A person can consciously perform metalearning, such as during memory training and explicit rehearsal, whereas these heuristics may be explicitly learned or fine-turned. This would be our future study. In this work, we presented a unified approach for lifelong learning. This approach tackles a difficult problem that captures many important aspects of human learning, namely non-forgetting, forward transfer, confusion reduction, backward transfer, few-shot learning, and selective forgetting. Progress in this area is critical for the development of computationally efficient and flexible machine learning algorithms. The success at this problem reduces the demand for training data while a single model learns to solve more and more tasks. While previous works have focused on a subset of these lifelong learning skills, our proposed approach utilizes a single mechanism, controlling weight consolidation, to address all of the considered skills. We define only a small number of consolidation hyperparameters which are dynamically applied to groups of weights. In addition to describing the novel approach, we examine its parallels with human learning. We note several similarities in the response of our model to hyperparameter settings and the effects on human learning to analogous changes in the brain."
}