{
    "title": "rkxJgoRN_V",
    "content": "Transfer learning uses trained weights from a source model as the initial weightsfor the training of a target dataset.   A well chosen source with a large numberof labeled data leads to significant improvement in accuracy.   We demonstrate atechnique that automatically labels large unlabeled datasets so that they can trainsource models for transfer learning. We experimentally evaluate this method, usinga baseline dataset of human-annotated ImageNet1K labels, against five variationsof this technique.   We show that the performance of these automatically trainedmodels come within 17% of baseline on average. In many domains, the task performance of deep learning techniques is heavily dependent on the number of labeled examples, which are difficult and expensive to acquire. This demand for large labeled datasets has inspired alternative techniques, such as weak supervision or automated labeling, whose algorithms create plausible labels to be used to guide supervised training on other tasks.In this work, we develop a content-aware model-selection technique for transfer learning. We take an unlabeled data point (here, an unlabeled image), and compute its distance to the average response of a number of specialized deep learning models, such as those trained for \"animal\", \"person\", or \"sport\". We then create a \"pseudolabel\" for the point, consisting of a short ordered sequence of the most appropriate model names, like \"animal-plant-building\". We use these synthetic labels to augment the ground truth labels. We validate the technique by applying it to the ImageNet1K dataset, as well as on a number of other large, unlabeled datasets. We have shown that generation of content-aware pseudolabels can provide transfer performance approaching that of human labels, and that models trained on psuedolabels can be used as source models for transfer learning. The automated approach presented here suggests that the internal representations of content models trained on specialized datasets contain some descriptive features of those datasets. By treating each of these specialized representations as a \"word\" in a longer \"sentence\" that describes a category of images, we can create labels such as a \"music-weapon-person\" to describe a suit of armor, or a \"tree-animal-fungus\" to describe an elephant. These rich labels capture features of these objects such as visual information about the materials they are made out of, that better describe the contents than reliance on a single label would produce. Using multiple, content-aware models to achieve greater descriptive power may be a valuable future avenue of research."
}