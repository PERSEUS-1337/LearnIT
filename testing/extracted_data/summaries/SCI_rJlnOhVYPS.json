{
    "title": "rJlnOhVYPS",
    "content": "Person re-identification (re-ID) aims at identifying the same persons' images across different cameras. However, domain diversities between different datasets pose an evident challenge for adapting the re-ID model trained on one dataset to another one. State-of-the-art unsupervised domain adaptation methods for person re-ID transferred the learned knowledge from the source domain by optimizing with pseudo labels created by clustering algorithms on the target domain. Although they achieved state-of-the-art performances, the inevitable label noise caused by the clustering procedure was ignored. Such noisy pseudo labels substantially hinders the model's capability on further improving feature representations on the target domain. In order to mitigate the effects of noisy pseudo labels, we propose to softly refine the pseudo labels in the target domain by proposing an unsupervised framework, Mutual Mean-Teaching (MMT), to learn better features from the target domain via off-line refined hard pseudo labels and on-line refined soft pseudo labels in an alternative training manner.   In addition, the common practice is to adopt both the classification loss and the triplet loss jointly for achieving optimal performances in person re-ID models. However, conventional triplet loss cannot work with softly refined labels. To solve this problem, a novel soft softmax-triplet loss is proposed to support learning with soft pseudo triplet labels for achieving the optimal domain adaptation performance. The proposed MMT framework achieves considerable improvements of 14.4%, 18.2%, 13.1% and 16.4% mAP on Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT unsupervised domain adaptation tasks. In this work, we propose an unsupervised Mutual Mean-Teaching (MMT) framework to tackle the problem of noisy pseudo labels in clustering-based unsupervised domain adaptation methods for person re-ID. The key is to conduct pseudo label refinery to better model inter-sample relations in the target domain by optimizing with the off-line refined hard pseudo labels and on-line refined soft pseudo labels in a collaborative training manner. Moreover, a novel soft softmax-triplet loss is proposed to support learning with softly refined triplet labels for optimal performances. Our method significantly outperforms all existing person re-ID methods on domain adaptation task with up to 18.2% improvements. Two temporal average models are introduced in our proposed MMT framework to provide more complementary soft labels and avoid training error amplification. Such average models are more de-coupled by ensembling the past parameters and provide more independent predictions, which is ignored by previous methods with peer-teaching strategy (Han et al., 2018; Zhang et al., 2018b ). Despite we have verified the effectiveness of such design in Table 2 by removing the temporal average model, denoted as \"Baseline+MMT-500 (w/o E[\u03b8])\", we would like to visualize the training process by plotting the KL divergence between peer networks' predictions for further comparison. As illustrated in Figure 3 , the predictions by two temporal average models (\"Proposed MMT-500\") always keep a larger distance than predictions by two ordinary networks (\"Proposed MMT-500 (w/o E[\u03b8])\"), which indicates that the temporal average models could prevent the two networks in our MMT from converging to each other soon under the collaborative training strategy. We utilize weighting factors of \u03bb t tri = 0.8, \u03bb t id = 0.5 in all our experiments by tuning on Duketo-Market task with IBN-ResNet-50 backbone and 500 pseudo identities. To further analyse the impact of different \u03bb t tri and \u03bb t id on different tasks, we conduct comparison experiments by varying the value of one parameter and keep the others fixed. Our MMT framework is robust and insensitive to different parameters except when the hard classification loss is eliminated with \u03bb t id = 1.0. The weighting factor of hard and soft triplet losses \u03bb t tri . In Figure 4 (a-b) , we investigate the effect of the weighting factor \u03bb t tri in equation 9, where the weight for soft softmax-triplet loss is \u03bb t tri and the weight for hard triplet loss is (1 \u2212 \u03bb t tri ). We test our proposed MMT-500 with both ResNet-50 and IBN-ResNet-50 backbones when \u03bb t tri is varying from 0.0, 0.3, 0.5, 0.8 and 1.0. Specifically, the soft softmax-triplet loss is removed from the final training objective (equation 9) when \u03bb t tri is equal to 0.0, and the hard triplet loss is eliminated when \u03bb t tri is set to 1.0. We observe"
}