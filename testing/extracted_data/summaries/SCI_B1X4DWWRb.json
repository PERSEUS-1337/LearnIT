{
    "title": "B1X4DWWRb",
    "content": "Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation. A long-term goal in artificial intelligence is for agents to learn how to act. This endeavor relies on accurately predicting and optimizing for the outcomes of actions, and fundamentally involves estimating counterfactuals-what would have happened if the agent acted differently? In many applications, such as the treatment of patients in hospitals, experimentation is infeasible or impractical, and we are forced to learn from biased, observational data. Doing so requires adjusting for the distributional shift between groups of patients that received different treatments. A related kind of distributional shift arises in unsupervised domain adaptation, the goal of which is to learn predictive models for a target domain, observing ground truth only in a source domain.In this work, we pose both domain adaptation and treatment effect estimation as special cases of prediction across shifting designs, referring to changes in both action policy and feature domain. We separate policy from domain as we wish to make causal statements about the policy, but not about the domain. Learning from observational data to predict the counterfactual outcome under treatment B for a patient who received treatment A, one must adjust for the fact that treatment A was systematically given to patients of different characteristics from those who received treatment B. We call this predicting under a shift in policy. Furthermore, if all of our observational data comes from hospital P , but we wish to predict counterfactuals for patients in hospital Q, with a population that differs from P , an additional source of distributional shift is at play. We call this a shift in domain. Together, we refer to the combination of domain and policy as the design. The design for which we observe ground truth is called the source, and the design of interest the target.The two most common approaches for addressing distributional shift are to learn shift-invariant representations of the data BID0 or to perform sample re-weighting or matching (Shimodaira, 2000; BID13 . Representation learning approaches attempt to extract only information from the input that is invariant to a change in design and predictive of the variable of interest. Such representations are typically learned by fitting deep neural networks in which activations of deeper layers are regularized to be distributionally similar across designs BID0 BID15 . Although representation learning can be shown to reduce the error associated to distributional shift BID15 in some cases, standard approaches are biased, even in the limit of infinite data, as they penalize the use also of predictive information. In contrast, re-weighting methods correct for distributional shift by assigning higher weight to samples from the source design that are representative of the target design, often using importance sampling. This idea has been well studied in, for example, the causal inference BID20 , domain adaptation (Shimodaira, 2000) and reinforcement learning BID19 literature. For example, in causal effect estimation, importance sampling is equivalent to re-weighting units by the inverse probability of observed treatments (treatment propensity). Re-weighting with knowledge of importance sampling weights often leads to asymptotically unbiased estimators of the target outcome, but may suffer from high variance in finite samples (Swaminathan & Joachims, 2015) .A significant hurdle in applying re-weighting methods is that optimal weights are rarely known in practice. There are a variety of methods to learn these weights. Weights can be estimated as the inverse of estimated feature or treatment densities BID20 BID7 but this plug-in approach can lead to highly unstable estimates. More stable methods learn weights by minimizing distributional distance metrics BID8 BID13 BID4 Zubizarreta, 2015) . Closely related , matching (Stuart, 2010) produces weights by finding units in the source design that are close in some metric to units in the target design. Specifying a distributional or unit-wise metric is challenging, especially if the input space is high-dimensional where no metric incorporating all features can ever be made small. This has inspired heuristics such as first performing variable selection and then finding a matching in the selected covariates.Our key algorithmic contribution is to show how to combine the intuition behind shift-invariant representation learning and re-weighting methods by jointly learning a representation \u03a6 of the input space and a weighting function w(\u03a6) to minimize a) the re-weighted empirical risk and b) a re-weighted measure of distributional shift between designs. This is useful also for the identity representation \u03a6(x) = x, as it allows for principled control of the variance of estimators through regularization of the re-weighting function w(x), mitigating the issues of exact importance sampling methods. Further, this allows us to evaluate w on hold-out samples to select hyperparameters or do early stopping. Finally, letting w depend on \u03a6 alleviates the problem of choosing a metric by which to optimize sample weights, as \u03a6 is trained to extract information predictive of the outcome. We capture these ideas in an upper bound on the generalization error under a shift in design and specialize it to the case of treatment effect estimation. We have proposed a theory and an algorithmic framework for learning to predict outcomes of interventions under shifts in design-changes in both intervention policy and feature domain. The framework combines representation learning and sample re-weighting to balance source and target designs, emphasizing information from the source sample relevant for the target. Existing reweighting methods either use pre-defined weights or learn weights based on a measure of distributional distance in the input space. These approaches are highly sensitive to the choice of metric used to measure balance, as the input may be high-dimensional and contain information that is not predictive of the outcome. In contrast, by learning weights to achieve balance in representation space, we base our re-weighting only on information that is predictive of the outcome. In this work, we apply this framework to causal effect estimation, but emphasize that joint representation learning and re-weighting is a general idea that could be applied in many applications with design shift.Our work suggests that distributional shift should be measured and adjusted for in a representation space relevant to the task at hand. Joint learning of this space and the associated re-weighting is attractive, but several challenges remain, including optimization of the full objective and relaxing the invertibility constraint on representations. For example, variable selection methods are not covered by our current theory, as they induce a non-ivertible representation, but a similar intuition holds there-only predictive attributes should be used when measuring imbalance. We believe that addressing these limitations is a fruitful path forward for future work. We denote the re-weighted density p w \u00b5 (x, t) := w(x, t)p \u00b5 (x, t).Expected & empirical risk We let the (expected) risk of f measured by h under p \u00b5 be denoted DISPLAYFORM0 where l h is an appropriate loss function, and the empirical risk over a sample DISPLAYFORM1 We use the superscript w to denote the re-weighted risks DISPLAYFORM2 Definition A1 (Importance sampling). For two distributions p, q on Z, of common support, \u2200z \u2208 Z : p(z) > 0 \u21d0\u21d2 q(z) > 0, we call DISPLAYFORM3 the importance sampling weights of p and q. Definition 2 (Restated). The integral probability metric (IPM) distance, associated with the function family H, between distributions p and q is defined by DISPLAYFORM4 We begin by bounding the expected risk under a distribution p \u03c0 in terms of the expected risk under p \u00b5 and a measure of the discrepancy between p \u03c0 and p \u00b5 . Using definition 2 we can show the following result. Lemma 1 (Restated ). For hypotheses f with loss f such that f / f H \u2208 H, and p \u00b5 , p \u03c0 with common support, there exists a valid re-weighting w of p \u00b5 , see Definition 1, such that, DISPLAYFORM5 The first inequality is tight for importance sampling weights, w(x, t) = p \u03c0 (x, t)/p \u00b5 (x, t). The second inequality is not tight for general f , even if f \u2208 H, unless p \u03c0 = p \u00b5 .Proof. The results follows immediately from the definition of IPM. DISPLAYFORM6 Further, for importance sampling weights w IS (x, t) = \u03c0(t;x) \u00b5(t;x) , for any h \u2208 H, DISPLAYFORM7 and the LHS is tight.We could apply Lemma 1 to bound the loss under a distribution q based on the weighted loss under p. Unfortunately, bounding the expected risk in terms of another expectation is not enough to reason about generalization from an empirical sample. To do that we use Corollary 2 of BID6 , restated as a Theorem below.Theorem A1 (Generalization error of re-weighted loss BID6 ). For a loss function h of any hypothesis h \u2208 H \u2286 {h : X \u2192 R}, such that d = Pdim({ h : h \u2208 H}) where Pdim is the pseudo-dimension, and a weighting function w(x) such that E p [w] = 1, with probability 1 \u2212 \u03b4 over a sample (x 1 , ..., x n ), with empirical distributionp, DISPLAYFORM8 we get the simpler form DISPLAYFORM9 We will also need the following result about estimating IPMs from finite samples from Sriperumbudur et al. (2009) .Theorem A2 (Estimation of IPMs from empirical samples (Sriperumbudur et al., 2009) ). Let M be a measurable space. Suppose k is measurable kernel such that sup x\u2208M k(x , x) \u2264 C \u2264 \u221e and H the reproducing kernel Hilbert space induced by k, with \u03bd := sup x\u2208M,f \u2208H f (x) < \u221e. Then, wit\u0125 p,q the empirical distributions of p, q from m and n samples respectively, and with probability at least 1 \u2212 \u03b4, DISPLAYFORM10 We consider learning twice-differentiable, invertible representations \u03a6 : X \u2192 Z, where Z is the representation space, and \u03a8 : Z \u2192 X is the inverse representation, such that \u03a8(\u03a6(x)) = x for all x. Let E denote space of such representation functions . For a design \u03c0, we let p \u03c0,\u03a6 (z, t) be the distribution induced by \u03a6 over Z \u00d7 T , with p w \u03c0,\u03a6 (z, t) := p \u03c0,\u03a6 (z, t)w(\u03a8(z), t) its re-weighted form andp w \u03c0,\u03a6 its re-weighted empirical form, following our previous notation. Note that we do not include t in the representation itself , although this could be done in principle. Let G \u2286 {h : Z \u00d7 T \u2192 Y} denote a set of hypotheses h(\u03a6, t ) operating on the representation \u03a6 and let F denote the space of all compositions, F = {f = h(\u03a6(x), t) : h \u2208 G, \u03a6 \u2208 E}. We now restate and prove Theorem 1."
}