{
    "title": "B1ecYsqSuN",
    "content": "We explore ways of incorporating bilingual dictionaries to enable semi-supervised\n neural machine translation. Conventional back-translation methods have shown\n success in leveraging target side monolingual data. However, since the quality of\n back-translation models is tied to the size of the available parallel corpora, this\n could adversely impact the synthetically generated sentences in a low resource\n setting. We propose a simple data augmentation technique to address both this\n shortcoming. We incorporate widely available bilingual dictionaries that yield\n word-by-word translations to generate synthetic sentences. This automatically\n expands the vocabulary of the model while maintaining high quality content. Our\n method shows an appreciable improvement in performance over strong baselines. Neural Machine Translation (NMT) methods require large amounts of parallel data to perform well. This poses a significant challenge in low-resource and out-of-domain scenarios where the amount of parallel data is usually limited. A proven way to mitigate this issue has been by leveraging the vast amounts of monolingual data in conjunction with parallel data to improve performance. Prior work in the field has explored several methods to achieve this. One of the most successful approaches has been Back-Translation (BT) BID9 , that generates artificial parallel data from target monolingual corpora by training a translation model in the reverse direction. Another approach (COPY) proposed by BID3 directly copies target monolingual data to the source, focused on capturing entities that do not change across languages.The methods mentioned above suffer from a couple of limitations. The quality of the generated source translations in the BT model are dependent on the amount of parallel data. Furthermore, the vocabulary available to the model is also limited to that of the parallel data, which increases the probability of out-of-vocabulary words. The COPY model, on the other hand, adds vocabulary, albeit only on the target side. In this paper, we propose a simple yet effective data augmentation technique that utilizes bilingual dictionaries that expands vocabulary on both source and target sides, thus significantly reducing the probability of out-of-vocabulary words. Our method also ensures that correlations between the source and target languages are modelled in the monolingual data. In particular, our contributions are as follows:\u2022 We propose the Word-on-Word (WoW) data augmentation method, that outperforms previous data augmentation methods in a low-resource setting.\u2022 We show that our method benefits from both in-domain as well as out-of-domain monolingual data and shows encouraging results for domain-adaptation.\u2022 Finally, we also apply our method over other augmentation techniques and show its effectiveness in enhancing performance. We propose a simple yet effective data augmentation technique by utilizing bilingual dictionaries for low resource NMT. In this work, we used ground truth dictionaries. A direct line of future work is to create synthetic samples using induced dictionaries and also incorporating phrase tables."
}